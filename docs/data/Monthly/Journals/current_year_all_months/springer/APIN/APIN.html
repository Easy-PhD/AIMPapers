<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>APIN</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="apin">APIN - 948</h2>
<ul>
<li><details>
<summary>
(2025). PretopoMD: Pretopology-based mixed data hierarchical clustering. <em>APIN</em>, <em>55</em>(15), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06770-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel pretopology-based algorithm designed to address the challenges of clustering mixed data without the need for dimensionality reduction. Leveraging Disjunctive Normal Form, our approach formulates customizable logical rules and adjustable hyperparameters that allow for user-defined hierarchical cluster construction and facilitate tailored solutions for heterogeneous datasets. Through hierarchical dendrogram analysis and comparative clustering metrics, our method demonstrates superior performance by accurately and interpretably delineating clusters directly from raw data, thus preserving data integrity. Empirical findings highlight the algorithm’s robustness in constructing meaningful clusters and reveal its potential in overcoming issues related to clustered data explainability. The novelty of this work lies in its departure from traditional dimensionality reduction techniques and its innovative use of logical rules that enhance both cluster formation and clarity, thereby contributing a significant advancement to the discourse on clustering mixed data.},
  archive      = {J_APIN},
  author       = {Levy, Loup-Noé and Guerard, Guillaume and Djebali, Sonia and Amor, Soufian Ben},
  doi          = {10.1007/s10489-025-06770-1},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {PretopoMD: Pretopology-based mixed data hierarchical clustering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-discriminator generative adversarial networks with dynamic penalty to over-sample imbalanced credit datasets. <em>APIN</em>, <em>55</em>(15), 1-30. (<a href='https://doi.org/10.1007/s10489-025-06836-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of credit risk data imbalance reduces the effectiveness of assessment models. Existing oversampling methods focus only on a partial sample of a few classes, resulting in a lack of diversity in the types of data generated. This paper proposes an innovative GAN variant called Magnify-GAN. The originality of Magnify-GAN lies in the fact that it is equipped with a primary discriminator and multiple secondary discriminators, each of which employs a different loss function. This multi-discriminator approach not only improves the learning results, but also enriches the feedback received during the training process. In addition, we integrate an innovative dynamic coefficient mechanism to enable the model to dynamically adapt to changes in data distribution. To further improve stability and address the common modal collapse problem in GAN, a gradient penalty method is embedded in the training protocol. This integrated strategy ensures that Magnify-GAN can effectively generate samples representing various minority classes within the real data. Compared to ten classical imbalanced sampling methods, Magnify-GAN demonstrates superior performance in precision, F1-score, and AUC values across six synthetic and four real-world imbalanced datasets. Ablation studies, visualized through heatmaps, reveal the complementary synergy between the core modules. Furthermore, a complexity analysis shows that Magnify-GAN offers significant performance gains with moderate increases in computational cost compared to state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Dong, Xiaogang and Wang, Lifei and Qin, Xiwen and Shi, Hongyu},
  doi          = {10.1007/s10489-025-06836-0},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-30},
  shortjournal = {Appl. Intell.},
  title        = {Multi-discriminator generative adversarial networks with dynamic penalty to over-sample imbalanced credit datasets},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph convolutional network for time series classification using recurrence plots. <em>APIN</em>, <em>55</em>(15), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06841-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series classification (TSC) is a crucial task across various domains, and its performance heavily depends on the quality of input representations. Among various representations, the recurrence plot (RP) effectively captures topological recurrence, the unique property of time series data. However, conventional convolutional neural networks (CNNs) cannot fully exploit this property since they treat the RP as grid-like data. In this study, we propose RP-GCN, a novel approach that uses a graph convolutional network (GCN) to exploit topological recurrence inherent in the RP, thereby improving TSC performance. Our method transforms a multivariate time series into graphs where state matrices act as node feature matrices and RPs serve as adjacency matrices, enabling graph convolution to utilize recurrence relationships. We evaluated RP-GCN on 35 benchmark multivariate time series classification datasets and demonstrated superior accuracy and efficient inference time compared to existing methods.},
  archive      = {J_APIN},
  author       = {Kang, Hyewon and Lee, Taek-Ho and Lee, Junghye},
  doi          = {10.1007/s10489-025-06841-3},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {A graph convolutional network for time series classification using recurrence plots},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preprocessing method for shield operational parameters adaptable to geological survey data characteristic for predicting disc cutter wear. <em>APIN</em>, <em>55</em>(15), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06846-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shield operational parameters are inherently noisy and, relative to concurrent geological exploration data, contain considerable redundancy, they must be pre-processed before the datasets input to artificial intelligence models. This paper presents a denoising and compression method for preprocessing shield operational parameters, integrating it with the stratal slicing method for predicting disc cutter wear. The operational parameter signals affecting cutter wear are first denoised using wavelet transform, Fourier transform, rolling average, and autoencoder techniques. The proposed Ring-based Summation Averaging (RSA) and Piecewise Aggregate Averaging (PAA) methods are then used to compress the denoised signals, resulting in compressed sequences composed of key points equal to the number of tunnel rings, effectively matching the geological parameters expanded by the stratal slicing method. Furthermore, the prepared data were tested using the long short-term memory (LSTM) + attention mechanism (AM) model to evaluate its application effectiveness in the Guangzhou Metro Line 18 railway. The results show that data compressed using PAA not only better tracks signal variations but also allows for flexible control of the output length of the compressed sequence. The combination of wavelet transforms denoising (WTD) with PAA exhibited the best wear prediction results, achieving R2 / MSE = 0.95 / 2.21 mm. By integrating WTD, PAA, stratal slicing method, and sequence models, a comprehensive and universal methodology is established that can predict disc cutter wear based on initial geological data and shield operational parameters.},
  archive      = {J_APIN},
  author       = {Mo, Deyun and Bai, Liping and Liao, Wenjiang and Tian, Xinyuan and Huang, Weiran},
  doi          = {10.1007/s10489-025-06846-y},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Preprocessing method for shield operational parameters adaptable to geological survey data characteristic for predicting disc cutter wear},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic gradient accelerated by negative momentum for training deep neural networks. <em>APIN</em>, <em>55</em>(15), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06900-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fast and robust stochastic optimization algorithms for training deep neural networks (DNNs) are still a topic of heated discussion. As a simple but effective way, the momentum technique, which utilizes historical gradient information, shows significant promise in training DNNs both theoretically and empirically. Nonetheless, the accumulation of error gradients in stochastic settings leads to the failure of momentum techniques, e.g., Nesterov’s accelerated gradient (NAG), in accelerating stochastic optimization algorithms. To address this problem, a novel type of stochastic optimization algorithm based on negative momentum (NM) is developed and analyzed. In this work, we applied NM to vanilla stochastic gradient descent (SGD), leading to SGD-NM. Although a convex combination of previous and current historical information is adopted in SGD-NM, fewer hyperparameters are introduced than those of the existing NM techniques. Meanwhile, we establish a theoretical guarantee for the resulting SGD-NM and show that SGD-NM enjoys the same low computational cost as vanilla SGD. To further show the superiority of NM in stochastic optimization algorithms, we propose a variant of stochastically controlled stochastic gradient (SCSG) based on the negative momentum technique, termed SCSG-NM, which achieves faster convergence compared to SCSG. Finally, we conduct experiments on various DNN architectures and benchmark datasets. The comparison results with state-of-the-art stochastic optimization algorithms show the great potential of NM in accelerating stochastic optimization, including more robust to large learning rates and better generalization.},
  archive      = {J_APIN},
  author       = {Li, Xiaotian and Yang, Zhuang and Wang, Yang},
  doi          = {10.1007/s10489-025-06900-9},
  journal      = {Applied Intelligence},
  month        = {10},
  number       = {15},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Stochastic gradient accelerated by negative momentum for training deep neural networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GAN-CLC-DGSR: Generative adversarial network framework with contrastive learning classifier for simultaneous time series data generation and state recognition. <em>APIN</em>, <em>55</em>(14), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06856-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of abnormal states is crucial for the continuous stable operation of equipment and timely intervention. However, the scarcity of abnormal data leads to low recognition accuracy in traditional methods when handling the data imbalance problem. To address this issue, we propose a novel Generative Adversarial Network Framework with Contrastive Learning Classifier for Simultaneous Time Series Data Generation and State Recognition (GAN-CLC-DGSR). In this framework, the generator not only synthesizes realistic signals but also enables the conversion between different signal categories. In addition to the conventional discriminator used to distinguish real from fake data, we design a contrastive learning-based classification discriminator. This discriminator maps the time-domain and frequency-domain features of the signal to a unified space, capturing invariant characteristics of the signal. This aids the generator in producing samples with higher category distinguishability. The classification discriminator is also trained as a state recognizer. We conduct extensive experiments on the vibration screen dataset from a coal preparation plant, a bearing dataset, and an epilepsy dataset. The results demonstrate that the proposed method outperforms other comparative methods in both data generation and state recognition, and it exhibits strong generalization capability.},
  archive      = {J_APIN},
  author       = {Wang, Weidong and Wu, Yuxin and Song, Yang and Zhao, Xuan and Cui, Yao and Fan, Yuhan and Liu, Yanbo and Lv, Ziqi},
  doi          = {10.1007/s10489-025-06856-w},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {14},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {GAN-CLC-DGSR: Generative adversarial network framework with contrastive learning classifier for simultaneous time series data generation and state recognition},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A transfer learning-based fault diagnosis method for rolling bearings with variable operating conditions. <em>APIN</em>, <em>55</em>(14), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06811-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problem that fault feature information cannot be completely extracted and it is difficult to obtain a large amount of sample data for fault labeling in real production life, we propose a transfer learning-based fault diagnosis method for rolling bearings with variable operating conditions. First, in order to make up for the single limitation of the feature extraction of the original vibration signal, a new feature signal is formed by fusing the time domain features on the basis of the original vibration signal, which is used as the input of the model, and a lightweight one-dimensional convolutional neural network(1d-CNN) is constructed, and an efficient channel attention mechanism is introduced to extract the fault features, so as to get the source domain diagnostic model. Then, according to the idea of transfer learning, the vibration signals under different working conditions are input into the fine-tuned model to realize the rolling bearing fault diagnosis under multiple working conditions. The results show that the method can realize migration under different working conditions and accurately and efficiently realize rolling bearing fault diagnosis.},
  archive      = {J_APIN},
  author       = {Song, Cunli and Yuan, Xiaomeng},
  doi          = {10.1007/s10489-025-06811-9},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {14},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {A transfer learning-based fault diagnosis method for rolling bearings with variable operating conditions},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing multi-level cross-modal interaction with false negative-aware contrastive learning for text-video retrieval. <em>APIN</em>, <em>55</em>(14), 1-26. (<a href='https://doi.org/10.1007/s10489-025-06821-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-video retrieval (TVR) has become a crucial branch in multi-modal understanding tasks. Enhanced by CLIP, a well-known contrastive learning framework that connects text and image, TVR has made substantial progress, particularly in developing cross-grained methods that account for both coarse and fine granularity in text and video. Nonetheless, previous cross-grained approaches have overlooked two crucial aspects. First, they utilize text-agnostic video summaries by simply averaging frame-level embeddings, potentially failing to capture crucial frame-level information that is semantically relevant to the corresponding text. Second, these approaches employ contrastive learning that neglects the impact of false negatives containing semantically relevant information. To address the aforementioned aspects, we introduce a novel framework for TVR, referred to as X-MLNet, focusing on capturing multi-level cross-modal interactions across video and text. This is done by first incorporating cross-attention modules at various levels of granularity, ranging from fine-grained (i.e., frame/word-level) representations to coarse-grained (i.e., video/sentence-level) representations. Then, we apply a contrastive learning framework that utilizes a similarity score computed based on the multi-level cross-modal interactions, excluding potential false negatives based on intra-modal connectivity among samples. Our experiments on five real-world benchmark datasets, including MSRVTT, MSVD, LSMDC, ActivityNet, and DiDeMo, demonstrate state-of-the-art performance in both text-to-video and video-to-text retrieval tasks. Our code is available at https://github.com/celestialxevermore/X-VLNet .},
  archive      = {J_APIN},
  author       = {Kim, Eungyeop and Lee, Changhee},
  doi          = {10.1007/s10489-025-06821-7},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {14},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing multi-level cross-modal interaction with false negative-aware contrastive learning for text-video retrieval},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive deep shared latent representation enables novel multi-omics cancer subtype classification. <em>APIN</em>, <em>55</em>(14), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06848-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variations in outcomes among cancer patients are significant even when they have the same type of tumor. Identifying and classifying molecular subtypes of cancer offers a valuable opportunity to enhance prognosis and tailor treatment plans for individuals. Recent efforts have been made to generate extensive multidimensional genomic data to achieve this potential. However, existing algorithms still face challenges in integrating and analyzing such intricate datasets. In this study, we present Adaptive Deep Shared Latent Representation (ADSLR), a novel approach for cancer subtyping that utilizes shared latent representation to reveal distinct molecular subtypes in cancer. It incorporates a cycle autoencoder with a nonnegative matrix factorization layer, capturing consistent signals of nonlinear features at various omics levels. This enables the generation of adaptable representations for shared latent representation across multiple omics levels. We apply ADSLR to multi-omics data obtained from eight different cancer types in the “The Cancer Genome Atlas” dataset, demonstrating significant improvements in the identification of biologically meaningful cancer subtypes. These identified subtypes exhibit noteworthy variations in patient survival rates across seven out of the eight cancer types. Our analysis uncovers integrated patterns involving mRNA expression, miRNA expression, DNA methylation, and protein across multiple cancers while showcasing ADSLR’s versatility for integrating various other omics types.},
  archive      = {J_APIN},
  author       = {Li, Min and Qi, Zhifang and Deng, Shaobo and Wang, Lei and Yu, Xiang},
  doi          = {10.1007/s10489-025-06848-w},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {14},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive deep shared latent representation enables novel multi-omics cancer subtype classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view contrastive learning with static attributes and dynamic interests for sequential recommendation. <em>APIN</em>, <em>55</em>(14), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06816-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation plays a critical role in preference prediction by capturing the temporal evolution of user behavior. However, a key challenge lies in effectively integrating static attributes, such as stable user traits and item properties, with dynamic interests, which reflect the users’ transient and evolving preferences during interactions with various items. Current approaches typically focus on static attributes or recent interactions, neglecting the nuanced interplay between long-term stability and short-term variability. Additionally, the disparate encoding strategies for various data structures—such as bipartite interaction graphs, heterogeneous knowledge graphs, and sequential data streams—lead to fragmented user and item representations, hindering the development of a unified framework and reducing the system’s ability to holistically model user preferences. To address these challenges, we propose the multi-view contrastive learning with Static attributes and Dynamic interests for Sequential Recommendation (SDSR), a novel framework that integrates static and dynamic characteristics to enhance recommendation systems. SDSR employs graph-based encoders to capture static user and item features, while a sequence encoder models temporal changes in user behavior. By leveraging contrastive learning, SDSR aligns representations across multiple data views—such as interaction graphs, knowledge graphs, and sequential data—creating a unified user-item model that bridges long-term preferences with short-term trends. It also ensures consistency across various representations, yielding a cohesive and robust framework for synthesizing multi-perspective data. Empirical evaluations on benchmark datasets demonstrate that SDSR significantly outperforms state-of-the-art models, validating its effectiveness in integrating multi-view data and capturing both static and dynamic user preferences.},
  archive      = {J_APIN},
  author       = {Chen, Mukun and Wu, Jia and Pan, Shirui and Cai, Xiantao and Du, Bo and Hu, Wenbin and Xu, Huiting},
  doi          = {10.1007/s10489-025-06816-4},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {14},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Multi-view contrastive learning with static attributes and dynamic interests for sequential recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMSE: An efficient malicious traffic detection model based on deep multi-stacking ensemble learning. <em>APIN</em>, <em>55</em>(14), 1-29. (<a href='https://doi.org/10.1007/s10489-025-06819-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of increasing cyber threats, developing an efficient malicious traffic detection model to recognize the cyber attacks has become an urgent demand in the field of cyber security. This paper proposes an efficient malicious traffic detection model called DMSE based on deep multi-stacking ensemble learning, it is primarily consisted of feature representation module, base model detection module and multi-stacking ensemble learning module. In the feature representation phase, we propose a novel RGB image representation method, which hierarchically represents the global and local features of network traffic by allocating the information to three channels of RGB images. In the base model detection phase, we adopt five different deep learning models—CNN, TCN, LSTM, BiLSTM and BiTCN—as base models for the first-stage prediction. In the multi-stacking ensemble learning phase, we adopt the best-performing BiTCN from extensive experiments as the meta-learner to perform a second prediction using the results from the first stage, thereby obtaining the final detection result. Experiments conducted on USTC-TFC2016, CTU and ISAC datasets demonstrate that the proposed DMSE model significantly outperforms existing ensemble learning-based detection models in terms of accuracy, F1-score, false positive rate (FPR), true positive rate (TPR) and stability. The experimental results indicate that the proposed DMSE model can effectively identify and defend against network attacks, providing the new perspectives and technical support for maintaining a secure network environment.},
  archive      = {J_APIN},
  author       = {Cai, Saihua and Zhang, Yang and Li, Yanghang and Wang, Yupeng and Li, Jiayao and Zhou, Xiang},
  doi          = {10.1007/s10489-025-06819-1},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {14},
  pages        = {1-29},
  shortjournal = {Appl. Intell.},
  title        = {DMSE: An efficient malicious traffic detection model based on deep multi-stacking ensemble learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An unsupervised domain adaptation method for cross-domain deceptive reviews detection. <em>APIN</em>, <em>55</em>(14), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06825-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deceptive reviews seriously affect the interests of consumers, honest sellers, and e-commerce platforms. As e-commerce platforms often involve multiple domains (i.e., different products or services), in-domain deceptive review detection models trained and tested on a specific dataset may not perform well on other domains. Moreover, obtaining annotated data for so many individual domains is unrealistic. Cross-domain deceptive review detection aims to leverage labeled source domain data to improve the model’s performance on unlabeled target domain data. However, existing cross-domain deceptive review detection methods require labels for target domain data or do not consider domain-specific information. To further advance research, this paper proposes an unsupervised domain adaptation method for detecting cross-domain deceptive reviews. First, we propose a multiple mask views generation method to enhance domain-specific information to obtain different mask views of reviews. Secondly, the BERT and mask attention mechanisms are used sequentially to obtain contextual representations of the mask views and the original view of reviews. Thirdly, to maintain the consistency between the mask views and the original view of reviews, we use the intra-domain Kullback-Leibler divergence to constrain their learning process. Moreover, we use inter-domain dynamic maximum mean discrepancy and conditional maximum mean discrepancy to reduce differences between the distribution of source and target domains. Three sets of experiments on two datasets show that our method is superior to the baselines. In particular, the impact of domain differences on domain adaptability is further analyzed according to the quantified metric named domain distance defined in this paper.},
  archive      = {J_APIN},
  author       = {Cao, Ning and Ji, Shujuan and Zhuang, Fuzhen and Chiu, Dickson K. W. and Guo, Yajie and Gong, Maoguo},
  doi          = {10.1007/s10489-025-06825-3},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {14},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {An unsupervised domain adaptation method for cross-domain deceptive reviews detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Micro-dynamics prediction of well water level based on GRU and attention mechanism. <em>APIN</em>, <em>55</em>(14), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06855-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Well water level is an important precursor observation, which is expected to be used to extract information on subsurface stress and media changes. Real-time prediction of well water level can help prevent geological disasters, but there are few related experimental studies. This study aims to explore a short-term prediction model of well water level that is more pervasive than the GRU model, explore new methods to enhance the model’s capability, and provide scientific references for the application of deep learning models in the field of well water level prediction. Taking the measured data of the Three Gorges well network from 2012 to 2014 as an example, the performance of the GRU and its variant models on the RMSE, MAE and R² evaluation criteria are compared, and the results show that only the BiGRU-Attention model shows excellent performance at all well points, with better pervasiveness and stability; performing a single-step prediction and adding a 1% standard deviation noise to the training set can improve the robustness and generalisation of the model.},
  archive      = {J_APIN},
  author       = {Fang, Xiaoyu and Zhang, Lili and Li, Haoran and Zhang, Yaowen and Yao, Yunsheng},
  doi          = {10.1007/s10489-025-06855-x},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {14},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Micro-dynamics prediction of well water level based on GRU and attention mechanism},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A gradient inversion attack defense method based on data augmentation. <em>APIN</em>, <em>55</em>(14), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06533-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The gradient inversion attack presents a significant threat to the data privacy in federated learning, enabling malicious adversaries to reconstruct private training data from gradients. Among the various protection strategies, data augmentation-based approaches have emerged as particularly promising. These methods can be seamlessly incorporated into existing federated learning frameworks, offering both efficiency and minimal impact on model accuracy. In this paper, we propose a novel data protection technique that leverages data augmentation methods, specifically CutMix and SaliencyMix. These techniques work by mixing images, which allows for more efficient utilization of training pixels. This, in turn, aids the model in learning more robust and meaningful feature representations, thereby enhancing both the model performance and its resilience to adversarial attacks. To further strengthen data privacy, we integrate these data augmentation methods with data pruning techniques. Our empirical results demonstrate that the proposed approach not only improves the accuracy of federated learning models but also reduces the quality of reconstructed images, offering a higher level of data privacy protection.},
  archive      = {J_APIN},
  author       = {Li, Yingge and Wu, Xianlin and Chen, Yuwen and Yu, Haiyang and Yang, Zhen},
  doi          = {10.1007/s10489-025-06533-y},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {14},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {A gradient inversion attack defense method based on data augmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-3D pose tracking based on multi-view fusion feature correlation. <em>APIN</em>, <em>55</em>(14), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06774-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian 3D pose tracking in multi-view scenarios has extensive practical applications. However, existing methods often overlook the overall tracking accuracy of pedestrians, particularly the issues of missing and erroneous tracking caused by severe occlusions, disappearances, and reappearances. It further affects the accuracy of pose point association. To address these limitations, a two-stage method is proposed, involving tracking with an exceptionally low error rate, followed by obtaining higher precision 3D pose points. Firstly, a multi-object tracking model is introduced, which integrates feature association-validation-updating and employs dynamic thresholding strategy to achieve high-accuracy matching of multiple individuals in multi-view scenarios by computing similarity with feature pool templates. Additionally, a Gaussian Mixture-based feature pool updating model ensures the universality of stored features to solve the reappearance problem. Secondly, a pedestrian 2D pose detection and 3D pose reprojection method based on SMPL (Skinned Multi-Person Linear model) is proposed, which detects more complete pose points than OpenPose in complex scenes and better conforms to the distribution principles of human skeletal pose points. To validate the advancedness of the proposed method, the Shelf and Campus public datasets are re-annotated. Experimental results demonstrate the excellent performance of the proposed method in overall error control in complex environments, outperforming existing methods in multi-object tracking and pose point estimation accuracy and completeness.},
  archive      = {J_APIN},
  author       = {Chen, Kai and Huang, Yujie and Zhao, Xiaodong and Fang, Guoyu and Wang, Ziyuan},
  doi          = {10.1007/s10489-025-06774-x},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {14},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Multi-3D pose tracking based on multi-view fusion feature correlation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating noisy labels in long-tailed image classification via multi-level collaborative learning. <em>APIN</em>, <em>55</em>(14), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06809-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label noise and class imbalance are two types of data bias that have attracted widespread attention in the past, but few methods can address both of them simultaneously. Recently, some works have begun to explore handling the two biases concurrently. In this article, we combine feature-level sample selection with logit-level knowledge distillation and logit adjustment to form a more complete collaborative training framework using two neural networks, which is termed Dynamic Noise and Imbalance Weighted Distillation (DNIWD). Firstly, we construct two types of sample sets, which are dynamic high-confidence set and basic confidence set. Based on the former, we estimate the centroids for each class in the latent space and select clean and easy examples for the peer network based on the uncertainty. Secondly, based on the latter, we perform knowledge distillation between the existing two networks to facilitate the learning of all classes, letting the network adaptively adjust the weight of distillation loss based on its own outputs. Meanwhile, we add an auxiliary classifier to each network and apply an improved balanced loss to train it, in order to boost the generalization performance of tail classes in more severe cases of class imbalance and provide balanced predictions for constructing confidence sample sets. Compared to state-of-the-art methods, DNIWD achieves significant improvement on synthetic and real-world datasets.},
  archive      = {J_APIN},
  author       = {Zhou, Xinyang and Wen, Zhijie and Zhao, Yuandi and Shi, Jun and Ying, Shihui},
  doi          = {10.1007/s10489-025-06809-3},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {14},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Mitigating noisy labels in long-tailed image classification via multi-level collaborative learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-attention multisource precipitation fusion model for improving long-sequence precipitation estimation accuracy. <em>APIN</em>, <em>55</em>(14), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06832-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate precipitation estimation is essential in agricultural production, water resource management, and flood forecasting. However, high-precision precipitation data remain very hard to obtain due to the complex spatio-temporal distribution of precipitation. Most existing methods considering spatio-temporal correlations in precipitation rely on a convolutional neural network for spatial feature extraction. However, these methods are less efficient in capturing global spatial features due to the local receptive fields of convolutional operators. In this study, we designed a Self-LSTM cell structure capable of effectively capturing temporal and global spatial features. Based on this, a self-attention precipitation fusion model (SAPFM) is proposed. The results demonstrate that SAPFM outperforms basic models and the original precipitation products. SAPFM improves by 28.8% and 21.8% on the Kling-Gupta efficiency (KGE) and Correlation Coefficient (CC) compared to the best-performing precipitation product (GsMap), respectively. Additionally, SAPFM reduces the Root Mean Square Error (RMSE) by 12.5%.},
  archive      = {J_APIN},
  author       = {You, Shaojie and Zhang, Xiaodan and Wang, Hongyu and Quan, Chen and Zhao, Tong and Zhang, Yongkun and Liu, Chang},
  doi          = {10.1007/s10489-025-06832-4},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {14},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {A self-attention multisource precipitation fusion model for improving long-sequence precipitation estimation accuracy},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster-infused low-rank subspace learning for robust multi-label classification. <em>APIN</em>, <em>55</em>(14), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06837-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label learning in high-dimensional spaces Suffers from the curse of dimensionality, noisy labels, and complex feature-label dependencies. Traditional deep learning solutions for multi-label classification employ multi-layer networks but overfit and generalize poorly owing to ineffective high-order data dependencies. In this paper, we introduce a cluster-infused low-rank subspace learning framework that integrates low-rank subspace learning with cluster infusion to solve these issues. Our model resolves sensitivity to noise, overfitting and poor generalization in high-dimensional data by using low-rank subspace representation decomposition of the classifier for dimension reduction and low-rank classifier for discriminative classification. To enhance robustness, we reconstruct each data sample as a Linear combination of its neighbours, infusing clustering-derived features into the model. These facilitate feature robustness via local correlations, thereby improving noise resilience and discriminative power. Extensive experiments on benchmark high-dimensional datasets, compared against state-of-the-art approaches, indicate that our approach significantly improves classification accuracy and robustness, making it a good solution for noisy, high-dimensional multi-label classification tasks. This effectiveness is evidenced across datasets of various scales, including a 3.04% improvement in Example-F1 over CNN-RNN on the smaller 20NG dataset and a significant 9.9% gain in Micro-F1 against RethinkNet on the large-scale NUS-WIDE dataset, highlighting DL-CS’s superiority for diverse multi-label classification tasks.},
  archive      = {J_APIN},
  author       = {Zhu, Ziyue and Zhou, Conghua and Sun, Shijie and Ntaye, Emmanuel and Shen, Xiang-Jun and Liu, Zhifeng},
  doi          = {10.1007/s10489-025-06837-z},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {14},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Cluster-infused low-rank subspace learning for robust multi-label classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using composite attribute similarity multi-graph convolutional network for recommendation. <em>APIN</em>, <em>55</em>(14), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06840-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Convolutional Networks (GCNs) are frequently utilized and havel a significant role in recommender systems. This is attributed to their ability to capture signals of collaboration between higher-order neighbors using graph structures. GCN-based recommendation models have been greatly improved in improving recommendation performance, but continue to face serious data sparsity problems. Data sparsity can be effectively alleviated by introducing attribute information. However, current GCN-based models face challenges in effectively handling the diverse attribute information of users and items and capturing the complex relationships among users, items, and attributes. With the purpose of addressing aforementioned problems, this research proposes a Using Composite Attribute Similarity Multi-Graph Convolutional Network (UCASM-GCN) for recommendation. In concrete terms, an attribute fusion strategy based on the attention mechanism is first utilized to construct the composite attributes of users or items. Then, the user-user graph and the item-item graph are constructed using the composite attributes of nodes to mine the relationships between users and between items. Finally, two isomorphic graphs are injected into the user-item interaction graph as auxiliary information through a multi-graph convolution strategy to generate optimized embedding representations, which ultimately improve the recommendation performance. Extensive experiments on three public datasets demonstrate the effectiveness of the proposed UCASM-GCN, achieving performance gains of 2.48%, 8.20% and 5.52% over a competitive graph-based collaborative filtering model on the Movielens 100k, Movielens 1M and DoubanBook datasets, respectively.},
  archive      = {J_APIN},
  author       = {He, Weichao and Zhu, Yi and Song, Mei and Su, Yuheng and Hao, Guosheng},
  doi          = {10.1007/s10489-025-06840-4},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {14},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Using composite attribute similarity multi-graph convolutional network for recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EMERALD-O: Efficient multi-agent reinforcement learning framework for optimised deep learning hyperparameter tuning and selection. <em>APIN</em>, <em>55</em>(14), 1-28. (<a href='https://doi.org/10.1007/s10489-025-06878-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional hyperparameter tuning methods, such as Bayesian Optimization and Grid Search, often prove computationally expensive and inefficient for complex deep learning architectures. This paper introduces the Multi-Agent Reinforcement Learning (MARL) framework EMERALD-O to optimize deep learning networks. The MARL-based approach utilizes two specialized agents, Agent1 focuses on data augmentation and Agent 2 on managing the learning rate and optimizer selection. The agents operate within an environment that simulates the model’s training dynamics and uses validation accuracy as the reward signal. Agent performance is enhanced through epsilon-greedy exploration and experience replay mechanisms. EMERALD-O performs favorably 88.59 % with improved classification accuracy and training efficiency. The framework exhibits adaptability to diverse dataset characteristics, underscoring scalability and robustness. The framework was validated on different models built for image classification problem on Efficientnet, VGG16 and VGG19. The results highlight the potential of reinforcement learning to fine-tune complex neural network architectures and suggest that MARL can serve as a powerful tool to improve the performance of deep learning models. EMERALD-O can contribute by advancing the frontier of deep neural optimization, demonstrating that reinforcement learning can fundamentally transform the model-tuning approach. This framework establishes a new paradigm for automated hyperparameter optimization and provides a systematic lens for analyzing the behavior of the deep learning model across various hyperparametric configurations. By quantifying model responsiveness to parameter variations, this approach enables deeper insights into architectural characteristics and performance dynamics, facilitating both the theoretical understanding and practical optimization of deep learning systems.},
  archive      = {J_APIN},
  author       = {VH, Akhila and Chacko, Anu Mary and Kumaraguru, Ponnurangam},
  doi          = {10.1007/s10489-025-06878-4},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {14},
  pages        = {1-28},
  shortjournal = {Appl. Intell.},
  title        = {EMERALD-O: Efficient multi-agent reinforcement learning framework for optimised deep learning hyperparameter tuning and selection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PC-UNet: A pure convolutional UNet with channel shuffle average for medical image segmentation. <em>APIN</em>, <em>55</em>(14), 1-10. (<a href='https://doi.org/10.1007/s10489-025-06887-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a pure convolutional UNet with channel shuffle average, abbreviated as PC-UNet, has been proposed for medical image segmentation. Notably, the proposed PC-UNet is suitable for extracting context features, which is useful for model improvement. PC-UNet operates as an encoder-decoder network, where both the encoder and decoder are stacked with the proposed Pure Convolution (PC) modules. The PC module, containing a Channel Shuffle Average (CSA) component, is efficient in capturing context features without significant computational overhead. The CSA component transfers feature information from the channel dimension to the spatial dimension, enabling efficient computation. The effectiveness of the proposed PC-UNet has been rigorously validated on four widely used datasets, which are ISIC 2018, BUSI, GlaS, and Kvasir-SEG. Experimental results demonstrate that PC-UNet yields outstanding performance without imposing a significant computational load or increasing floating-point operations (FLOPs). When compared with eight mainstream models across all datasets, PC-UNet achieves the highest scores in both Dice and IoU metrics. The source code is available at: https://github.com/lwwant2sleep/PC-UNet.},
  archive      = {J_APIN},
  author       = {Liu, Wei and Dong, Qian and Li, Shiren and Wang, Cong and Xiong, Yongliang and Yang, Guangguang},
  doi          = {10.1007/s10489-025-06887-3},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {14},
  pages        = {1-10},
  shortjournal = {Appl. Intell.},
  title        = {PC-UNet: A pure convolutional UNet with channel shuffle average for medical image segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed epidemic prediction for irregularly sampled spatio-temporal sequence with missing values. <em>APIN</em>, <em>55</em>(14), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06802-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the task of predicting the spatiotemporal spread of the epidemic, a deep learning framework based on the discrete physics-informed neural network has been proposed, which integrates spatio-temporal dependency relationships and physical constraint mechanisms to address the limitations of traditional physics-informed neural networks. However, these methods typically assume that the spatiotemporal sequence is normally sampled at regular intervals and there are no missing values, without modeling the asynchronous spatiotemporal correlation present in irregularly sampled multivariate spatio-temporal sequences with missing values. The presence of missing values and variable time intervals in node variables in different regions may blur or distort the actual relationships between variables, which in turn affects the quality of loss-constrained learning of unknown parameters based on physical models. Therefore, this paper proposes a novel method for physics-informed spatiotemporal sequence prediction, named PEPIST. It utilizes a designed spatio-temporal sparse graph structure to effectively represent the irregularity of sampling time intervals and spatiotemporal missing values, and combines mechanisms such as graph spatiotemporal pattern capture and attention based physical spatiotemporal parameter interpolation to generate unknown parameter variable representations required for multi-region SEIR-informed loss constraints, as well as spatiotemporal characteristics of the variables to be predicted. Experimental results have shown that the method proposed in this paper exhibits high prediction accuracy in real COVID-19 epidemic prediction cases.},
  archive      = {J_APIN},
  author       = {Cheng, Haodong and Mao, Yingchi},
  doi          = {10.1007/s10489-025-06802-w},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {14},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Physics-informed epidemic prediction for irregularly sampled spatio-temporal sequence with missing values},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regret-theory-based three-way decision making in hesitant fuzzy environments: A multi-attribute approach and its applications. <em>APIN</em>, <em>55</em>(14), 1-29. (<a href='https://doi.org/10.1007/s10489-025-06801-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-making is intricately linked to the psychological behavior of decision-makers, particularly their susceptibility to risk uncertainty and the consequent emergence of regret psychology. The hesitant fuzzy information system is an effective mechanism for encapsulating the substantial uncertainty inherent in real-world data. While existing three-way multi-attribute decision-making (TWD-MADM) methods have made significant progress in handling uncertainty, they often overlook the psychological factors of decision-makers, such as regret aversion. This paper introduces a three-way decision-making method (TWD-MADM-RT-HFS), grounded in regret theory, for multi-attribute decision-making in a hesitant fuzzy environment. Unlike traditional TWD-MADM approaches, our method explicitly incorporates regret theory to model decision-makers’ psychological behavior, providing a more realistic framework for decision-making under uncertainty. The methodology involves computing a relative outcome matrix using the PROMETHEE-II method to assess the gains and losses of objectives. A novel regret-based perceived utility function is proposed to quantify decision-makers’ aversion to regret, followed by calculating satisfaction-based weight functions for different events across various states. The integration of these weight functions with the perceived utility function yields a new expected utility function, pivotal for ranking and classifying alternatives. To validate the effectiveness of the proposed methodology, the Algerian Forest Fires Dataset was selected for application testing and successfully classified into three categories: fire, possible fire and no fire. The results were then ranked in detail based on the probability of their occurrence. It is anticipated that this classification will help to predict fire risk more accurately in the future, so that timely measures can be taken to prevent and control fire hazards. The method’s feasibility, effectiveness, and superiority are validated through a comparative analysis with existing methods in real-case scenarios. The stability of the model is further confirmed by conducting sensitivity analyses under different parameter settings.},
  archive      = {J_APIN},
  author       = {Xu, Weihua and Luo, Wenxiu},
  doi          = {10.1007/s10489-025-06801-x},
  journal      = {Applied Intelligence},
  month        = {9},
  number       = {14},
  pages        = {1-29},
  shortjournal = {Appl. Intell.},
  title        = {Regret-theory-based three-way decision making in hesitant fuzzy environments: A multi-attribute approach and its applications},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy granularity entropy-based incremental attribute reduction for dynamic incomplete real-valued decision systems. <em>APIN</em>, <em>55</em>(13), 1-25. (<a href='https://doi.org/10.1007/s10489-025-06697-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough set-based incremental attribute reduction is a competitive technique for knowledge acquisition. Incremental methods stand out by efficiently leveraging previously acquired knowledge to obtain new knowledge and thereby significantly reducing repetitive computations for dynamic data sets. Nevertheless, most of them primarily focus on complete decision systems, exhibiting a notable deficiency in handling missing information within incomplete decision systems. In addition, most existing research focuses on handling symbolic data, whereas practical applications often involve large amounts of real-valued data, posing greater challenges for attribute reduction. Drawing inspiration from these observations, we introduce a novel approach to handle dynamic real-valued data with features that contain missing values. Specifically, we define fuzzy granularity entropy for quantifying uncertainty of an incomplete real-valued decision system (IRDS), and explore its extensions such as joint granularity entropy and conditional granularity entropy. Furthermore, conditional granularity entropy is demonstrated to exhibit the desirable property of monotonicity. Moreover, the incremental mechanisms and corresponding algorithms are investigated for IRDS with variations in the number of objects. Finally, comparative experiments are carried out on different data sets to verify the effectiveness of the presented algorithms. Compared to the corresponding comparative methods, the results show that our approach achieves shorter reduct size, higher classification accuracy, and notably require less computing time.},
  archive      = {J_APIN},
  author       = {Zhang, Chucai and Lu, Zhengxiang and Zhang, Yongkang and Dai, Jianhua},
  doi          = {10.1007/s10489-025-06697-7},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {Fuzzy granularity entropy-based incremental attribute reduction for dynamic incomplete real-valued decision systems},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximum group utility consensus and fairness-oriented cross-efficiency in multi-attribute group decision-making with a focus on inequality concern. <em>APIN</em>, <em>55</em>(13), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06714-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-attribute group decision making (MAGDM) constitutes an important subfield of group decision-making. Most existing studies on MAGDM focus on consensus reaching without considering irrational psychology of decision-makers (DMs), particularly their inequality concern. Meanwhile, research on MAGDM from inequality concern remains rather limited. Motivated by this, we develop a novel fairness-oriented MAGDM approach to alleviate the concern of DMs. First, a weighting model for DMs is developed, which can reflect disparities of the information entropy and fairness concern utility among DMs. Secondly, during the consensus-reaching process, we propose a maximized group consensus model that incorporates fairness concern, which accounts for individual tolerance levels and the consensus principle. Thirdly, we design a fairness-oriented multiplicative data envelopment analysis cross-efficiency (FMDEA) model for selection, with the objective of identifying the optimal alternative. Finally, we apply the approach in a case study involving the upgrade of an electrical system for the highway tunnel, and employ comparative and sensitivity analyses to demonstrate the advantages of the proposed approach.},
  archive      = {J_APIN},
  author       = {Liu, Jinpei and Xu, Wenqing and Shao, Longlong and Jin, Feifei and Hao, Jiangfeng},
  doi          = {10.1007/s10489-025-06714-9},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Maximum group utility consensus and fairness-oriented cross-efficiency in multi-attribute group decision-making with a focus on inequality concern},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A granular XGBoost classification algorithm. <em>APIN</em>, <em>55</em>(13), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06762-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes the first integration of multi-distance granular computing with XGBoost, significantly improving generalization in small-sample scenarios through enriched feature representations. XGBoost (eXtreme Gradient Boosting) is a machine learning algorithm primarily utilized to address classification and regression problems. It typically relies on the original features of the data or basic feature engineering, which does not fully exploit the internal structures and correlations inherent in the data. Meanwhile, due to the problems of data sparsity, category imbalance, and the presence of noise in small sample datasets, its performance often deteriorates, leading to a decrease in the model’s generalization ability. In this paper, we propose a granular XGBoost classification algorithm designed to enhance its classification accuracy in small-sample datasets. The algorithm initially extends the dimensionality of the dataset by combining multiple features and subsequently employs various distance metrics for granulation processing, generating multiple granularity levels of data representation, resulting in richer and more diverse feature representations. The feature representations at different granularity levels are then fused separately and fed into the XGBoost classifier for training and prediction. This approach to mitigate the bias and error associated with a single metric, thereby achieving a better balance in the representations of each category within the dataset. Experimental results indicate that the classification accuracy of the granular XGBoost classification algorithm, which utilizes the multi-distance metric method, is significantly improved across various datasets when compared to the traditional XGBoost algorithm but also reinforces its robustness and generalization capability across different datasets and feature distributions, providing novel insights and methodologies to address the overfitting challenges associated with small sample data.},
  archive      = {J_APIN},
  author       = {Lan, Biyun and Chen, Yumin and Wu, Keshou},
  doi          = {10.1007/s10489-025-06762-1},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {A granular XGBoost classification algorithm},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DATrack: Direction attention based transformer tracker. <em>APIN</em>, <em>55</em>(13), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06791-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For visual object tracking task, a tracked target only moves towards one of all possible directions within the search region of the current frame. However, existing one-stream transformer trackers treat all possible directions uniformly. This makes the information in the lower possible directions of the search region inevitably affect the tracking accuracy and stability. To solve this problem, we propose a direction attention based transformer tracker (DATrack), allowing the tracker to focus more on the search tokens in partial possible motion directions. Specifically, we first introduce direction tokens to provide direction information in various coarse-grained directions of the search region. After passing through the transformer backbone network, a direction token with greater correlation to the target template indicates a higher likelihood of the target moving in the corresponding direction. Then, we designed a direction attention to weight the search region tokens. In contrast to prior trackers, a search token related to the target motion direction can receive a higher attention. The search tokens weighted by direction attention are used for target localization. The experimental results show that our proposed tracker can effectively improve the robustness of tracking on multiple benchmark datasets, such as GOT-10k, LaSOT, TrackingNet, UAV123 and TNL2K.},
  archive      = {J_APIN},
  author       = {Liu, Jinfen and Gao, Yun and Shi, Zhijia and Wang, Tao},
  doi          = {10.1007/s10489-025-06791-w},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {DATrack: Direction attention based transformer tracker},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pedestrian flow prediction using a spatiotemporal multi-head attention graph convolutional network integrated with knowledge graph. <em>APIN</em>, <em>55</em>(13), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06793-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd flow prediction has become an important issue in urban management, especially in regulating crowd flow during congested periods. Accurately predicting future congestion on a road section requires in-depth analysis of crowd flow data and influencing factors. However, existing prediction methods fail to fully integrate spatiotemporal features and effectively utilize environmental and historical information. This paper proposes a spatiotemporal multi-head attention graph convolutional network for pedestrian flow prediction, enhanced with knowledge graphs for improved accuracy(STMHAGCN-KG). First, we build online and offline knowledge graphs based on external scene factors, and integrate historical pedestrian traffic with knowledge through a dedicated module to obtain a pedestrian traffic matrix that integrates knowledge. Secondly, we capture spatial features through multiple feature graphs, use enhanced LSTM and multi-head attention mechanisms to model spatiotemporal dependencies, fuse spatiotemporal features with the pedestrian traffic matrix, and finally generate traffic prediction values in the fully connected layer. Experiments on real-world pedestrian data show that the proposed method achieves superior performance compared to traditional and state-of-the-art models.},
  archive      = {J_APIN},
  author       = {Du, Linnan and Liu, Hong and Li, Wenhao},
  doi          = {10.1007/s10489-025-06793-8},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Pedestrian flow prediction using a spatiotemporal multi-head attention graph convolutional network integrated with knowledge graph},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explicit-implicit feature modeling in drama videos: Dataset and benchmark. <em>APIN</em>, <em>55</em>(13), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06699-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding complicated scenes in movies or dramas is a foundational yet challenging task in video analysis, with significant implications for cultural understanding and intelligent video applications. While recent multimodal learning approaches focus on explicit features (e.g., visual, audio, and text), they often neglect the implicit background knowledge, such as cultural, social, and historical contexts, which are pivotal for accurate video understanding. In this paper, we propose a new task, named Explicit-Implicit feature representation in Video Understanding (EIVU). To facilitate this task, we introduce the Explicit-Implicit Drama (EIDrama), a multimodal dataset based on traditional Chinese drama videos, comprising over one million frames sampled from hundreds of video hours. Besides the explicit visual and audio features, EIDrama also consists of abundant background information, enabling a comprehensive exploration of the interplay between explicit and implicit modalities. Additionally, we present EINet, a baseline model that aggregates explicit and implicit features using a local-global strategy. Extensive experiments demonstrate the effectiveness of EINet. We expect the proposed EIDrama and EINet as stepping stones towards bridging the gap between explicit-implicit modeling and fostering cross-cultural understanding in multimodal video analysis.},
  archive      = {J_APIN},
  author       = {Du, Zexing and Wu, Xiaojun},
  doi          = {10.1007/s10489-025-06699-5},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Explicit-implicit feature modeling in drama videos: Dataset and benchmark},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hierarchical interaction multimodal model for feature fusion based on RoBERTa-keyword-ViT. <em>APIN</em>, <em>55</em>(13), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06764-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern artificial intelligence research, multimodal learning has emerged as a crucial research area. It effectively integrates data from different modalities, allowing for a more comprehensive understanding of complex informational contexts. With the widespread application of large models, it is essential to conduct in-depth research on how to effectively fuse different data from different modalities using transformer architectures. To this end, this study proposes a hierarchical interaction multimodal model based on RoBERTa-Keyword-ViT. First, we proposed a method to effectively extract keywords, ensuring that the keyword information is not lost while preserving the semantic information of the text. Second, the modal primacy of pairs in cross-attention was discussed for the first time in this paper, and a residual primary–secondary cross-attention interaction mechanism was proposed. The proposed mechanism ensures that the features of the primary modal data are effectively preserved during the interactions among different modalities. Finally, we discussed the role of query, key, and value in the primary–secondary modality interaction and verified the advantages of using the primary modality as a carrier and the secondary modality as a query. These findings enhance the understanding of multimodal interaction mechanisms and provide an empirical basis for future research. This indicates that selecting appropriate primary–secondary modalities and their roles in attention mechanisms is crucial when designing multimodal interaction systems. Lastly, we conducted experiments on both relatively large- and small-scale public datasets. Compared with existing studies, the proposed approach achieved superior performance on slightly larger dataset leveraging the RoBERTa-Keyword-ViT model architecture.},
  archive      = {J_APIN},
  author       = {Wang, Yuanhang and Zhou, Yonghua and Zhong, Min and Mei, Yiduo and Fujita, Hamido and Aljuaid, Hanan},
  doi          = {10.1007/s10489-025-06764-z},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {A hierarchical interaction multimodal model for feature fusion based on RoBERTa-keyword-ViT},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SimRMKGC: Simple relational contrastive learning on multilingual knowledge graph completion. <em>APIN</em>, <em>55</em>(13), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06782-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph completion (KGC) is a task for predicting missing fact triples in an incomplete knowledge graph (KG), which is crucial for enhancing the comprehensiveness and utility of KGs. In recent years, multilingual KGs bridged with the same entities and relations have been introduced into KGC to alleviate the poor-resource issue in an individual KG, with popular multilingual KG completion (MKGC) methods demonstrating that multilingual KG alignment (MKGA) and KGC can be mutually beneficial. However, existing methods do not sufficiently address the relation alignment (RA) within MKGA. Even though some methods consider the importance of RA, the unbalanced training issue between EA and RA may harm MKGC. Motivated by efficient contrastive learning, we propose a contrastive learning framework based on relation alignment for MKGC, named SimRMKGC, which aims to improve both MKGC and MKGA and solve the unbalanced issue between the EA and the RA. Specifically, the RA is regarded as a central component in MKGA, employing a supervised contrastive learning optimization method to align well-designed positive relation pairs effectively. In addition, we introduce two types of negatives: in-batch sampling negative and generated area-wise mixup hard negatives to improve the learning effect. Experiments on DBPedia-5L and E-PKG demonstrate state-of-the-art results: For MKGC, SimRMKGC achieves an improvement of 3.5%∼7.0% Hits@1 and 4.0% ∼7.1% MRR on DBPedia-5L, and achieves an improvement of 0.5%∼1.3% Hits@1 and 0.5% ∼1.0% MRR on E-PKG.},
  archive      = {J_APIN},
  author       = {Fang, Xiaohan and Zang, Qian and Gong, Jibing and Fang, Tao and Xu, Yili and Wu, Xi},
  doi          = {10.1007/s10489-025-06782-x},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {SimRMKGC: Simple relational contrastive learning on multilingual knowledge graph completion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable breast cancer prediction from 3-dimensional dynamic contrast-enhanced magnetic resonance imaging. <em>APIN</em>, <em>55</em>(13), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06803-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models have been instrumental in extracting critical indicators for breast cancer diagnosis - the prevalent malignancy among women worldwide - from baseline magnetic resonance imaging. However, many existing models do not fully leverage the rich spatial information available in the 3D structure of medical imaging data, potentially overlooking important contextual details. This develops an explainable deep learning framework for classifying breast cancer that leverages the complete 3D and provides classification results alongside visual explanations of the decision-making process. The preprocessing pipeline is fed with 3D sequences containing ‘tumour’ and ‘non-tumour’ regions. It includes a 3D Adaptive Unsharp Mask (AUM) filter to reduce noise and augment image class, followed by normalisation and data augmentation. Classification is then achieved by training an augmented ResNet150 model. Three explainable artificial intelligence (XAI) techniques, including Shapley Additive Explanations, 3D Gradient-Weighted Class Activation Mapping, and Contextual Importance and Utility, are employed to provide improved interpretability. The model demonstrates state-of-the-art performance over the QIN-BREAST dataset, achieving testing accuracies of 98.861% for ‘tumours’ and 99.447% for ‘non-tumours’, as well as over the Duke Breast Cancer Dataset, where it achieves 99.104% for ‘tumours’ and 99.753% for ‘non-tumours’, while offering enhanced interpretability through XAI methods.},
  archive      = {J_APIN},
  author       = {Akbar, Arslan and Han, Suya and Urr Rehman, Naveed and Ahmed, Kanwal and Eshkiki, Hassan and Caraffini, Fabio},
  doi          = {10.1007/s10489-025-06803-9},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Explainable breast cancer prediction from 3-dimensional dynamic contrast-enhanced magnetic resonance imaging},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incomplete multi-view clustering based on enhanced view-feature learning and balanced consensus principle. <em>APIN</em>, <em>55</em>(13), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06767-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete multi-view clustering (IMC) is a challenging task in real-world applications. Its critical issue is to learn a reliable consensus representation to describe the cluster structure of complex incomplete multi-view data stably. To use the high-order correlations across different views, tensor learning (TL) has played an important role in IMC methods. However, existing TL-IMC methods commonly focus on the consistency of consensus representation, while ignoring the discriminative ability or diversity. This degrades the reliability of consensus representation. To ensure the consistency, discriminative ability and diversity of consensus representation at the same time, this paper proposes a novel TL-IMC method based on enhanced view-feature learning and balanced consensus principle (EVL-BCP). Specifically, EVL-BCP utilizes the fact that consensus representation is centralized from view-features. Firstly, EVL leverages both the intra-view low-rankness and inter-view low-rankness of graph tensor to strengthen the discriminative ability of all view-features, which facilitates to achieve the discriminative ability of consensus representation. Secondly, BCP integrates variance maximization mechanism and centralized constraint to seek for a stronger consistency between view-features in a diversity-induced partitionable view-subspace, which facilitates to introduce the consistency and diversity of consensus representation. Lastly, by aid of a shared feature subspace, EVL and BCP are coupled with each other to further exploit the coupling encouragements of discriminative ability, diversity and consistency. Abundant experiments are conducted on various multi-view datasets with several missing-view scenarios. The results demonstrate the superiority of EVL-BCP.},
  archive      = {J_APIN},
  author       = {Xie, Mengying and Huang, Pei and Liu, Xiaolan},
  doi          = {10.1007/s10489-025-06767-w},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Incomplete multi-view clustering based on enhanced view-feature learning and balanced consensus principle},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning applied for abnormal human behavior recognition in video surveillance systems: A systematic review. <em>APIN</em>, <em>55</em>(13), 1-25. (<a href='https://doi.org/10.1007/s10489-025-06797-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic recognition of human behavior is attracting more research attention, especially with the rapid progress of neural networks in recent years. The efficient detection and recognition of abnormal human behavior (AHB) are critical components of intelligent video surveillance systems, as they ensure human security and create safe environments. This paper presents a systematic literature review (SLR) of 140 studies published between 2016 and 2024, focusing on the application of deep learning for AHB recognition in videos. We formulate eight key research questions (RQs) that explore the types of AHB addressed in the literature, the historical progression of deep learning models, pre-trained architectures, existing methods, real-time applications, datasets, performance metrics, and future research directions. This review paper serves as a valuable guide for both academia and industry professionals seeking to understand this field and explore the top emerging trends.},
  archive      = {J_APIN},
  author       = {Saket, Olfa and Aicha, Anis Ben and Fathallah, Habib},
  doi          = {10.1007/s10489-025-06797-4},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {Deep learning applied for abnormal human behavior recognition in video surveillance systems: A systematic review},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new truncated non-convex loss based support vector machine for robust binary classification. <em>APIN</em>, <em>55</em>(13), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06799-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, support vector machines (SVMs) based on bounded loss functions have attracted significant attention due to their robustness. In this paper, we propose a novel non-convex, monotonic, and bounded loss function called the $$\epsilon$$ -insensitive truncated non-convex ( $$\epsilon$$ -TNC) loss, and construct our $$\epsilon$$ -TNCSVM model by replacing the hinge loss with the proposed $$\epsilon$$ -TNC loss in the standard SVM. The non-convexity and boundedness enhance the robustness of the model, and we innovatively use the influence function of the estimator to demonstrate this theoretically. Monotonicity ensures that the $$\epsilon$$ -TNCSVM retains the sparsity of the traditional SVM model. Besides, we demonstrate that $$\epsilon$$ -TNCSVM satisfies Fisher consistency and obtains the corresponding generalization error bound based on Rademacher complexity, guaranteeing its good generalization capability. However, the non-convexity of the proposed $$\epsilon$$ -TNC loss makes it difficult to optimize. Hence, a non-convex optimization method, the concave-convex procedure (CCCP) technique, is implemented to solve the proposed model. We conduct various experiments to verify the effectiveness of our proposed $$\epsilon$$ -TNCSVM model.},
  archive      = {J_APIN},
  author       = {Li, Feihong and Qi, Kai and Yang, Hu},
  doi          = {10.1007/s10489-025-06799-2},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {A new truncated non-convex loss based support vector machine for robust binary classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing image super-resolution reconstruction: The efficacy of the composite downsampling model based on wavelet transform and bicubic interpolation (CDWB). <em>APIN</em>, <em>55</em>(13), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06672-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Composite Downsampling Model Based on Wavelet Transform and Bicubic Interpolation (CDWB), an innovative technique devised to effectively reduce the loss of high-frequency information in images that is caused by the actively down sampling operation. This model is pivotal in enhancing the capabilities of neural network algorithms to reconstruct high-frequency image details, thereby significantly improving the perceptual quality of the images. Utilizing the image data generated by our CDWB model in the training of super-resolution reconstruction networks yields high-resolution images that effectively replicate the pixel distribution of actual images. These images demonstrate a superior perceptual quality compared to those reconstructed from datasets trained with standard single interpolation-based downsampling techniques.},
  archive      = {J_APIN},
  author       = {Jin, Xiaoshi and Li, Tianyu and Liu, Nan and Liu, Xi},
  doi          = {10.1007/s10489-025-06672-2},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Advancing image super-resolution reconstruction: The efficacy of the composite downsampling model based on wavelet transform and bicubic interpolation (CDWB)},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-head adaptive actor-critic algorithm for solving vehicle routing problems. <em>APIN</em>, <em>55</em>(13), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06778-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle routing problems (VRPs) pose significant challenges in intelligent transportation systems (ITSs) and play a crucial role in traffic routing planning. Deep reinforcement learning (DRL) models based on encoder-decoder structures have demonstrated considerable potential for VRPs applications. However, the encoder-decoder structure based on the traditional actor-critic (AC) algorithm is limited by its unsatisfactory adaptive capability of environmental information, static generation of control regulation parameters, and single decoding strategy, resulting in the low solving capability of DRL in VRPs. To address the aforementioned problems, a multi-head adaptive actor-critic (MHAAC) algorithm is put forward and then integrated into an end-to-end deep reinforcement learning framework. The proposed algorithm integrates a multi-head attention mechanism and a dynamic parameter generation strategy for the environment, which significantly enhances the information processing capability and the adaptability to the environment. Specifically, we introduce an additive attention layer between the encoder and decoder structure to generate dynamic contextual vectors and extract fine-grained feature embeddings. We then design a multi-head actor network to solve the solution construction process and regulate the actor network through the adaptive mechanism of the critic network. Furthermore, we put forward a hybrid solution search algorithm (HS) that integrates several traditional search methods, enhancing the quality of the solutions and optimizing the parameters of the whole framework using a gradient strategy. Finally, empirical evaluations on four standard datasets with 10, 20, 50, and 100 customer nodes demonstrate that MHAAC outperforms existing specialized solvers and other DRL methods in both solution quality and efficiency.},
  archive      = {J_APIN},
  author       = {Xia, Dawen and Jin, Youlong and Huang, Mingyue and Hu, Yang and Huo, Yujia and Wang, Ziqiang and Feng, Fujian and Li, Yantao and Li, Huaqing},
  doi          = {10.1007/s10489-025-06778-7},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {A multi-head adaptive actor-critic algorithm for solving vehicle routing problems},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review on the effectiveness of recent approaches to few-shot learning for image analysis. <em>APIN</em>, <em>55</em>(13), 1-55. (<a href='https://doi.org/10.1007/s10489-025-06676-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in Deep Neural Networks (DNN) have shown impressive performance in domains like image classification, machine translation, and natural language processing, particularly with abundant training data. DNNs face challenges with limited datasets, leading to overfitting and suboptimal generalization, especially in real-world scenarios with data scarcity. Few-Shot Learning (FSL) addresses the challenges by leveraging prior knowledge to enhance machine vision systems with limited training samples, enabling rapid generalization. The paper aims to address four key research questions concerning FSL, focusing on its impact on image analysis, the significance of existing FSL techniques, how FSL enhances performance in image analysis, and recommendations for the best FSL techniques across different domains. According to the literature review, the FSL approaches are categorized into five major categories: transfer learning, metric learning, data augmentation methods, meta-learning, and the Bayesian approach, highlighting the advantages and drawbacks of each technique. The paper also presents a brief overview of well-known datasets and prominent publications. A reference for choosing an appropriate FSL method is provided, utilizing a comparative examination of various techniques for image classification assignments. This paper serves as a concise resource to promptly understand the basics, benefits, and hurdles of diverse FSL methods applied to image analysis tasks, focusing on future research directions. It can be concluded from the study's findings that meta-learning, along with the attention approach and hybrid approach, can be utilized to enhance the overall efficiency of image classification tasks.},
  archive      = {J_APIN},
  author       = {Asudani, Deepak Suresh and Nagwani, Naresh Kumar and Singh, Pradeep},
  doi          = {10.1007/s10489-025-06676-y},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-55},
  shortjournal = {Appl. Intell.},
  title        = {A review on the effectiveness of recent approaches to few-shot learning for image analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved high-dimensional bayesian optimization algorithm. <em>APIN</em>, <em>55</em>(13), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06750-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Bayesian Optimization Algorithm, as an effective approach to addressing non-linear global optimization problems, is widely embraced in a myriad of machine learning application domains. With the development of big data, the presence of computational and statistical challenges in high-dimensional settings means that, despite the proposed improvements and enhancements, the applicability of the Bayesian Optimization Algorithm is still restricted to low-dimensional problems. Our algorithm (1) extracts an interesting nonlinear latent structure in the function by Kernal Principal Component Analysis(KPCA) to reduce the computational complexity, and (2) uses an improved Mutual-Information-Maximizing Input Clustering (MIMIC) algorithm to optimize only a low-dimensional subspace each iteration for more efficient and effective BO. The experiments demonstrate that the proposed algorithm can achieve a clear improvement in optimization accuracy and speed in high-dimensional space and can efficiently solve high-dimensional problems for Bayesian optimization algorithm.},
  archive      = {J_APIN},
  author       = {Guan, Juan and Wang, Yanhua},
  doi          = {10.1007/s10489-025-06750-5},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {An improved high-dimensional bayesian optimization algorithm},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-domain perspective trajectory prediction for autonomous driving. <em>APIN</em>, <em>55</em>(13), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06775-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle trajectory prediction (VTP) is critical for autonomous driving safety. However, most existing methods are confined to spatial and temporal features, limiting their ability to explore a broader feature space. To address this, we introduce frequency domain analysis for VTP and propose a novel multi-domain perspective method. Our framework effectively integrates frequency, spatial, and temporal features within a “Frequency-Spatial-Temporal" fusion architecture to enhance multi-vehicle trajectory prediction performance. Specifically, we reshape vehicle trajectories into the frequency domain using Fast Fourier Transform (FFT) and amplitude analysis to capture potential periodic patterns. A combination of 2D Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks then extracts these frequency features. Moreover, we construct a novel spatial topology graph based on relative vehicle states and actual distances for efficient spatial representation, leveraging stacked Graph Convolutional Networks (GCN) to capture interaction relationships. For temporal dimension, we establish time-dependent connections via a Circular Limited Penetrable Visibility Graph (CLPVG) to obtain rich temporal representations, extracted using a dedicated GCN. Finally, a Gated Recurrent Unit (GRU) encoder-decoder couples these multi-domain features to generate joint predicted trajectories. Extensive experiments on the NGSIM and HighD datasets demonstrate the effectiveness of our approach. It reduces the Root Mean Square Error (RMSE) within a 5-second prediction horizon by 32.13% and 15.45%, respectively, compared to the current state-of-the-art method, and significantly outperforms mainstream baseline models.},
  archive      = {J_APIN},
  author       = {Xu, Dongwei and Gu, Tongcheng and Sun, Chengju and Yu, Hao and Liu, Yewanze},
  doi          = {10.1007/s10489-025-06775-w},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Multi-domain perspective trajectory prediction for autonomous driving},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SSRepVM-UNet: A lightweight hybrid model for medical image segmentation based on channel parallelism. <em>APIN</em>, <em>55</em>(13), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06780-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation is constrained by the computational resources of mobile medical devices, making computation-intensive models unsuitable. State space models, represented by Mamba, can effectively model long-range interactions while maintaining linear computational complexity. However, current lightweight architectures based on Mamba struggle to balance segmentation accuracy. To address this, we propose SSRepVM-UNet. Specifically, we introduce the SS-RepVM module, which leverages the lightweight convolutional RepViT module and the SS2D module with a scan expansion strategy to process different channels of feature maps in parallel. Our network significantly reduces the number of parameters and computational load while ensuring excellent performance. We conducted extensive experiments on four public dermoscopy lesion datasets and two polyp segmentation datasets. The results demonstrate that our network is highly competitive in medical image segmentation tasks, achieving state-of-the-art (SOTA) performance on the ISIC2018 dataset with only 0.17M parameters and 0.18 GFLOPs, setting a new benchmark for lightweight models.},
  archive      = {J_APIN},
  author       = {Guo, Yijing and Li, Fuhang and Li, Kunhua and Wang, Huawei and Xu, Pengyu},
  doi          = {10.1007/s10489-025-06780-z},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {SSRepVM-UNet: A lightweight hybrid model for medical image segmentation based on channel parallelism},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion-augmented nematode dataset improves few-shot classification of nematodes. <em>APIN</em>, <em>55</em>(13), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06783-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of plant-parasitic nematodes is essential for mitigating crop losses and maintaining agro-ecological balance. While deep learning offers a promising automated solution, it is hindered by data scarcity. To address this, the present study introduces the Diffusion-Augmented Nematode Dataset (DA-Nema), a novel offline data augmentation strategy that leverages diffusion models. DA-Nema employs a combination of semantic adaptation, morphological constraints, and style transfer to generate high-fidelity images, thereby enriching nematode datasets. Experimental results reveal that images generated using DA-Nema exhibit the lowest Fréchet Inception Distance (FID) scores, indicating superior visual realism and close alignment with the original data distribution. Expert evaluation of the nematode images corroborated these findings, highlighting DA-Nema’s enhanced visual fidelity and feature discernment. In classification tasks, models trained on DA-Nema-augmented data demonstrated only a 2% reduction in accuracy on balanced datasets, even at 40% augmentation ratio, compared to models trained solely on authentic data. Under data imbalance conditions, DA-Nema achieved a 75.3% accuracy rate in identifying 18 species of plant-parasitic nematodes, which significantly impact crops and ecosystems, marking an 18.7% improvement over baseline models. These competitive results underscore DA-Nema’s robust capacity for dataset augmentation, effectively addressing the pervasive issue of data scarcity in plant-parasitic nematode identification. Consequently, this advances the state of the art in computational biology. Furthermore, DA-Nema introduces innovative methodologies in semi-supervised learning and automated feature extraction, with the potential to significantly enhance agricultural diagnostics and management practices.},
  archive      = {J_APIN},
  author       = {Zhu, Ying and Wang, Pengjun and Zhuang, Jiayan and Xiao, Jiangjian and Gu, Jianfeng and Ren, Weilun and Ouyang, Xiong},
  doi          = {10.1007/s10489-025-06783-w},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Diffusion-augmented nematode dataset improves few-shot classification of nematodes},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning-based distributed appointed-time optimal trajectory tracking formation control for quadrotor UAVs. <em>APIN</em>, <em>55</em>(13), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06784-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a reinforcement learning-based distributed appointed-time prescribed performance optimal formation control strategy is proposed for multiple-QUAVs with model uncertainties and unknown disturbances. By integrating appointed-time prescribed performance functions and neural networks, a reinforcement learning-based optimal formation controller is proposed to achieve prescribed transient and steady-state performance at an appointed time. An actor-critic reinforcement learning neural network and a self-structuring neural network (SSNN) are employed to address the Hamilton–Jacobi–Bellman (HJB) equation and unknown dynamics, respectively. Additionally, a self-structuring neuron update strategy is proposed for deployment in these neural networks to enable the optimal number of neurons to be adjusted online without affecting the approximation performance. The Lyapunov analysis method is used to prove that all the error signals are semiglobally uniformly ultimately bounded (SGUUB). Finally, the effectiveness of the proposed control strategy is demonstrated via numerical simulation experiments.},
  archive      = {J_APIN},
  author       = {Zheng, Hongji and Liu, Haitao and Tian, Xuehong and Mai, Qingqun},
  doi          = {10.1007/s10489-025-06784-9},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Reinforcement learning-based distributed appointed-time optimal trajectory tracking formation control for quadrotor UAVs},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Edge-based graph neighbor filtering network for recommendation. <em>APIN</em>, <em>55</em>(13), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06800-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural network-based recommendation models have achieved remarkable results by performing information propagation on a bipartite graph consisting of user nodes and item nodes. Nevertheless, these models typically focus on message passing between nodes iteratively, and pay insufficient attention to the intricate interactions encapsulated by the graph’s edges, which play a pivotal role in recommendation systems. Moreover, the process of node embedding learning often fails to consider the potential similarities between users or items. Such omission could curtail the representational learning efficacy of these models. To address these challenges, we propose an edge-based graph neighbor filtering network framework for recommendation. This framework introduces an edge-based message passing mechanism to capture the interaction information between users and items. Additionally, a penalty term that utilizes neighbor filtering is incorporated to coalesce nodes exhibiting analogous characteristics more proximally within the embedding space. This inclusion serves as a catalyst for augmenting the prowess of representation learning. Comprehensive experiments and ablation studies are conducted, and the results validate the effectiveness of our framework. For example, on the datasets book_crossing and df_modcloth, the proposed framework can achieve relative improvements of 3% and over 20%, respectively, compared to the strongest baseline in terms of NDCG@10 and Recall@10.},
  archive      = {J_APIN},
  author       = {Yan, Qian and Tang, Yunbo and Xue, Liang},
  doi          = {10.1007/s10489-025-06800-y},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Edge-based graph neighbor filtering network for recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-scale granular framework for detecting anomalies in time series data. <em>APIN</em>, <em>55</em>(13), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06810-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection aims to identify anomalies and uncover their potential implications, a challenging problem that has drawn significant research attention. This study presents a multi-scale framework based on the principle of justifiable granularity, incorporating two distinct multi-scale approaches: type-1 and type-2. The type-1 approach employs bottom-up granular representation to construct higher-order information granules, while the type-2 approach generates various higher-type granules iteratively from the original numeric data. Two similarity measurement algorithms are developed to support anomaly detection for each approach, respectively. Extensive experimental studies on various datasets, including periodic and non-periodic patterns, demonstrate the proposed framework’s robustness and versatility. The results show that the type-1 and type-2 multi-scale approaches outperform state-of-the-art methods across several performance metrics, effectively handling data with trends, instability, and diverse anomaly characteristics.},
  archive      = {J_APIN},
  author       = {Yang, Junjun and Yang, Bin and Zhou, Yanjun},
  doi          = {10.1007/s10489-025-06810-w},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {A multi-scale granular framework for detecting anomalies in time series data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-confidence alignment and clustering for multi-view clustering. <em>APIN</em>, <em>55</em>(13), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06812-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering aims to mine consistent and complementary information between views to achieve superior clustering performance. However, existing studies often neglect the fusion of sample attribute features and structural features, the similarity consistency of samples between views, and the comprehensive utilization of high-confidence semantic labels. To address these challenges, we propose a High-Confidence Alignment and Clustering (HCAC) for multi-view clustering. Specifically, HCAC employs autoencoders and graph neural networks to extract attribute features and structural features from different views, respectively. It performs intra-view and inter-view fusion to derive more discriminative feature representations. To ensure high-confidence alignment across views, HCAC achieves high-confidence alignment across views by employing triplet constraints, including sample-level and cluster-level contrastive learning and similarity consistency among samples. Finally, HCAC utilizes high-confidence semantic labels to assist in the distribution alignment of clustering branch for each view, ensuring high reliability of the clustering results. Extensive experiments on public datasets demonstrate that our method achieves state-of-the-art clustering performance.},
  archive      = {J_APIN},
  author       = {Xiang, You and Meng, Min and Liu, Jigang and Wu, Jigang},
  doi          = {10.1007/s10489-025-06812-8},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {High-confidence alignment and clustering for multi-view clustering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust dynamic spatio-temporal graph neural network for traffic forecasting. <em>APIN</em>, <em>55</em>(13), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06815-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction is crucial for traffic planning and the development of intelligent transportation systems. However, existing approaches often overlook the impact of abnormal signals, suffer from inadequate modeling of multi-scale temporal dependencies, and fail to fully capture spatial correlations. To address these challenges, we propose a Robust Dynamic Spatio-Temporal Graph Neural Network (RDSTGNN) aimed at enhancing prediction performance and robustness in complex traffic scenarios. The proposed model consists of two key modules: a periodic module designed for normal periodic signals, and a Gradient Spatio-Temporal Local Graph Convolutional Network (GSTLGCN) for capturing spatio-temporal dependencies. In the periodic module, we introduce an abnormality filtering gate to eliminate noise, leverage Recurrent Neural Networks (RNNs) to model short-term dependencies, and incorporate a global attention mechanism to capture long-term dependencies, thereby jointly enhancing the modeling of periodic signals. In the GSTLGCN module, mean gradients are employed to suppress abnormal disturbances. We integrate static graphs constructed from prior knowledge, adaptive graphs, and dynamic graphs to jointly model complex spatio-temporal relationships, and formulate this process as a diffusion mechanism to improve information propagation. We evaluate our model on six real-world datasets, and the experimental results demonstrate that RDSTGNN significantly outperforms existing baselines across multiple evaluation metrics, validating the effectiveness and robustness of the proposed approach.},
  archive      = {J_APIN},
  author       = {Huang, Yanguo and Han, Weilong and Xie, Yingmin},
  doi          = {10.1007/s10489-025-06815-5},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Robust dynamic spatio-temporal graph neural network for traffic forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RDM2: A two-stage model based on residual learning diffusion model and multi-scale convolution for low dose CT denoising. <em>APIN</em>, <em>55</em>(13), 1-12. (<a href='https://doi.org/10.1007/s10489-025-06604-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computed Tomography (CT) is widely used in clinical diagnosis, but large amount of radiation accompanied is not expected. Low Dose CT (LDCT) can reduce the radiation effect, however, noise and artifacts will be unavoidably produced. Low dose accompanies large noise intensity, which is difficult to effectively denoise while retaining the details. Aiming at this problem, a two-stage LDCT denoising model, named RDM2, is proposed. In the first stage, a residual learning diffusion model is constructed to eliminate the noise of LDCT. The residuals between LDCT and Normal Dose CT (NDCT) is a kind of complex mixed noise with unknown intensity. In order to fully utilize the residual information, the whole residual is equally divided into small pieces and added iteratively in the diffusion process. Considering even the best trained residual diffusion model may bring unavoidable error when it is used for prediction, a multi-scale convolution encoder decoder convolution neural network (MEDCNN) is proposed in the second stage to further reduce this part of error. The proposed model RDM2 is validated on both the Mayo2020 25% dose LDCT dataset and Mayo2020 10% dose LDCT dataset, the values of PSNR, SSIM, and RMSE on these two datasets are respectively 44.7651, 0.9939, 0.0068 and 35.5302, 0.9601, 0.0172. It is proved that RDM2 outperforms the traditional method, the supervised learning-based method and the GAN-based method, and has the potential to meet clinical needs. Code is available at: https://github.com/zhencunjiang/RDM2 .},
  archive      = {J_APIN},
  author       = {Jiang, Zhencun and Ren, Kangrui and Wang, Kefan and Wang, Zhongjie},
  doi          = {10.1007/s10489-025-06604-0},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {RDM2: A two-stage model based on residual learning diffusion model and multi-scale convolution for low dose CT denoising},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Industrial-application-oriented 2D image and 3D object anomaly detection technology: A comprehensive review. <em>APIN</em>, <em>55</em>(13), 1-39. (<a href='https://doi.org/10.1007/s10489-025-06689-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of deep learning technology, industrial anomaly detection technology has significantly improved its ability to handle large-scale images and point clouds. It has gradually been applied to complex industrial environments. However, current reviews of anomaly detection technology are often technology-oriented, and there is still a need for a systematic classification for practical industrial scenarios. Given these considerations, we will summarize and categorize the latest anomaly detection technologies from the perspective of specific industrial application scenarios, including 2D image anomaly detection, 3D object anomaly detection, and datasets. This application-oriented classification method can more effectively meet the practical needs of anomaly detection tasks in industrial production. Furthermore, we contribute to anomaly detection technology by delivering a comprehensive analysis of the current state and challenges in industrial anomaly detection, offering insights into the customization of deep learning for real-world industrial applications, and presenting an outlook for future research directions.},
  archive      = {J_APIN},
  author       = {Li, Gang and Jiang, Chengrun and Li, Min and Li, Jiachen and Han, Delong and Zhou, Mingle},
  doi          = {10.1007/s10489-025-06689-7},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-39},
  shortjournal = {Appl. Intell.},
  title        = {Industrial-application-oriented 2D image and 3D object anomaly detection technology: A comprehensive review},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Remote sensing image change detection method based on dual-branch multi-level feature difference interactive learning. <em>APIN</em>, <em>55</em>(13), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06728-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing (RS) image change detection (CD) is a key technology in environmental monitoring and geographic information systems (GIS). It can reveal the dynamic changes of surface features and is of great significance in fields such as urban planning, disaster assessment, and ecological research. However, the pseudo-change problem, that is, the image differences caused by non-actual surface changes, often affects the accuracy of detection, leading to false alarms and omissions, which limits the effectiveness of the CD technology. Traditional dual-branch CD methods often focus on basic feature extraction. This method independently processes the feature extraction of the bi-temporal phases and lacks a comparative interactive learning process for the features of the bi-temporal phases, thereby weakening its ability to identify pseudo-changes in complex environments. To solve the above problems, we propose a RS image CD method based on dual-branch multi-level feature difference interactive learning (DMFDIL). The model is built based on the siamese convolutional neural network (CNN) of deep learning and includes three parts: the dual-branch cooperative coding module (DCM), the dual-branch difference decoding module (DDDM), and the change output module (COM). Among them, the DCM innovatively introduces the tri-attention mechanism. Through this mechanism, the model can effectively interact on multi-level features, enhancing the ability to capture subtle changes in RS images, especially in distinguishing real changes from pseudo-changes. The DDDM, on the other hand, focuses on further optimizing the detection capability of the model by identifying real changes from pseudo-changes and integrating feature information at different scales. Finally, the validation was carried out on three public datasets, and the results were better than other popular methods. The experimental results on the LEVIR-CD dataset show that the proposed DMFDIL model achieved 95.80% in precision (Pre), 94.54% in recall (Rec), 95.16% in F1-score (F1), 91.10% in Intersection over Union (IoU), and 99.07% in overall accuracy (OA), which are significantly better than those of the state-of-the-art (SOTA) approaches. This method provides a new technical approach in the field of RS image CD, especially in improving detection accuracy and dealing with pseudo-change problems, and has important application value and broad application prospects.},
  archive      = {J_APIN},
  author       = {Ding, Songtao and Li, Xinyu and Wang, Hongyu and Gao, Shiwen},
  doi          = {10.1007/s10489-025-06728-3},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Remote sensing image change detection method based on dual-branch multi-level feature difference interactive learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ExQUAL: An explainable quantum machine learning classifier. <em>APIN</em>, <em>55</em>(13), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06732-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum machine learning (QML) holds the potential to solve complex tasks that classical machine learning is unable to handle. QML is a promising and emerging field which is in the state of continuous development. This necessitates a deeper comprehension of the intricate black-box nature of the quantum machine learning models. To address this challenge, the incorporation of explainable artificial intelligence becomes imperative. This paper introduces a novel approach - Explainable Quantum Classifier (ExQUAL) to integrate the Local Interpretable Model-agnostic Explanations (LIME) framework and SHapley Additive exPlanations (SHAP) with the Pegasos Quantum Support Vector Machine (QSVM) model for classification tasks. ExQUAL provides a methodology to integrate these frameworks with both binary and multi-class classification tasks and provides both local and global explanations. This approach seeks to enhance transparency and interpretability while advancing the applicability and trustworthiness of quantum machine learning methodologies.},
  archive      = {J_APIN},
  author       = {Kadian, Karuna and Garhwal, Sunita and Kumar, Ajay},
  doi          = {10.1007/s10489-025-06732-7},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {ExQUAL: An explainable quantum machine learning classifier},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep feature refinement self-supervised learning algorithm for medical image annotation. <em>APIN</em>, <em>55</em>(13), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06737-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biomedical image segmentation models heavily rely on large-scale annotated data for training, yet manual annotation notoriously labor-intensive, error-prone, and cost-prohibitive, especially in medical domains requiring expert knowledge. To address this limitation, we propose a self-supervised learning (SSL) framework that leverages unlabeled data to automatically extract discrim- inative features, thereby reducing dependence on human annotations. In this study, self-supervising refers to a learning paradigm where supervisory signals are generated directly from the data itself (e.g., spatial context, channel corre- lations) without external labels. Our goal is to design an SSL method tailored for medical image annotation tasks, enabling robust feature representation even with limited labeled data. This paper introduces a novel self-supervised learning algorithm for refining deep features in the context of medical image annotation tasks. By leveraging the self-supervised ability to learn from unlabeled data, the pro- posed approach aims to enhance feature representation. With the help of spatial and channel attention blocks, our method focuses on intricate feature details within medical images. The spatial attention component enables the network to selectively attend to relevant regions, while the channel attention mecha- nism fine-tunes feature maps for improved annotation accuracy. Both strengthen the model’s ability to capture intricate details and fine-grained information in medical images. To verify the effectiveness of the proposed model, we conducted exten- sive research on four benchmark datasets. The experimental results show that our approach achieves competitive performance compared with other state-of-the-art annotation methods. On the KDSB18(20%) dataset, the values of Precision, Dice and mIoU are 0.964, 0.888, 0.880 (without Barlow Twins Strategy), and 0.965, 0.888, 0.880 (with Barlow Twins Strategy). On the BUSIS dataset with 20% labeled data, the proposed framework achieves a Dice score of 0.861 and mIoU of 0.869, surpassing the baseline U-Net by 36.5% and 23.4%, respectively. For BraTS18 brain tumor segmentation under 10% supervision, our method attains a boundary localization accuracy (Dice) of 0.853, outperforming state-of-the-art models (e.g., RCA-IUNet) by 3.7%. This study develops a novel model that integrates spatial and channel attention, spatial information compression, and dilated convolutions. By leveraging a self-supervised pre-training network with BT strategy, the model optimizes its parameters for improved accuracy and stability on testing data. Experimental results on four datasets demonstrate that our framework consistently improves Dice scores by 12.8–29.8% compared to vanilla self-supervised methods (e.g., Barlow Twins) on medical image segmentation tasks with ≤ 20% annotations. The proposed lesion-aware contrastive loss reduces false positives by 18.5% (from 0.23 to 0.19) in small lesion detection, as validated on the ISIC18 dataset. In summary, the proposed model showcases competitive anno- tation performance compared with other models across multiple datasets, with the potential study for enhancing the accuracy, attention mechanisms, and deployment on resource-constrained platforms.},
  archive      = {J_APIN},
  author       = {Zhang, Jiyong and Li, Deguang and Wu, Yan and Zhao, Zhengwei and Wang, Yanlei and Li, Yang and Zhang, Binqing},
  doi          = {10.1007/s10489-025-06737-2},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {A deep feature refinement self-supervised learning algorithm for medical image annotation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent neighborhood coordinated and holistic optimized actor-critic framework for adaptive traffic signal control. <em>APIN</em>, <em>55</em>(13), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06758-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive Traffic Signal Control (ATSC) is a pivotal research area within intelligent transportation systems, aiming to enhance transportation efficiency and alleviate traffic congestion at signalized intersections. While multi-agent deep reinforcement learning has been extensively applied to ATSC, existing approaches commonly frame it as a fully cooperative problem, presupposing that all agents are committed to pursuing a collective optimal solution. However, achieving such altruistic cooperation is often impractical. Furthermore, as the number of agents escalates, challenges such as the curse of dimensionality and non-stationarity arise, complicating the learning process. To address these issues, we propose a novel perspective by framing ATSC as a competitive-cooperative game trade-off scenario and design a multi-agent framework, termed Neighborhood Coordinated and Holistic Optimized Actor-Critic (NcHo-AC). Specifically, we introduce a novel traffic state representation, design a sophisticated feature extraction network, develop a robust training algorithm, and leverage mean field approximation to model population-level agent interactions. These designs foster neighborhood-level cooperation and communication, facilitate the learning of the desired Nash equilibrium, and mitigate the noise caused by agents’ exploratory behaviors, thereby alleviating non-stationarity and the curse of dimensionality, while enhancing scalability to large-scale traffic networks. Comprehensive experiments conducted on both synthetic and real-world datasets demonstrate that NcHo-AC significantly outperforms state-of-the-art baselines across four key metrics: average travel time, average queue length, delay, and throughput, along with improved convergence, robustness, and interpretability.},
  archive      = {J_APIN},
  author       = {Deng, Qi and Wu, Lijun and Li, Zhiyuan and Su, Kaile and Wu, Wei and Duan, Weiwei},
  doi          = {10.1007/s10489-025-06758-x},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Multi-agent neighborhood coordinated and holistic optimized actor-critic framework for adaptive traffic signal control},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DynKGCL: Contrastive learning for recommendation with dynamic dual-channel positive expansion and adaptive negative sampling. <em>APIN</em>, <em>55</em>(13), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06766-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data sparsity and cold start problems remain critical challenges in the field of recommendation systems, significantly restricting the predictive accuracy and generalization capability of user preference modeling. To overcome this bottleneck, this paper proposes DynKGCL, a contrastive learning(CL)-based recommendation framework that integrates dynamic dual-channel positive expansion and adaptive negative sampling to enhance recommendation performance. In terms of positive sample generation, the proposed method dynamically adjusts the cross-user similarity propagation ratio based on the sparsity of user interactions and incorporates a dual-channel positive expansion mechanism along with knowledge graph(KG)-enhanced neighborhood mining to effectively expand the positive sample pool in sparse scenarios, thereby improving user-item representation learning. For negative sample selection, we employ a dataset-adaptive strategy, utilizing a hybrid negative sampling approach in relatively dense datasets and pure random sampling in sparse datasets to balance sample diversity and model generalization. Experimental results demonstrate that DynKGCL achieves state-of-the-art performance across multiple benchmark test sets. Theoretical analysis further confirms that the proposed method, through graph-enhanced representation learning and a unified optimization paradigm, effectively alleviates the data sparsity problem, significantly enhances the robustness and generalization ability of the recommendation system, and provides a reliable solution for personalized recommendations.},
  archive      = {J_APIN},
  author       = {Wen, Ling and Liang, Qihuiyang and Li, Shichao and Zhang, Yuanyuan},
  doi          = {10.1007/s10489-025-06766-x},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {DynKGCL: Contrastive learning for recommendation with dynamic dual-channel positive expansion and adaptive negative sampling},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memristive bi-path wavelet transformer for low-light image enhancement. <em>APIN</em>, <em>55</em>(13), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06771-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images captured under low-light conditions are characterized by poor quality and insufficient exposure, which adversely affects the performance of downstream tasks, such as autonomous driving and nighttime surveillance. Recently, Transformer-based methods have achieved notable success in low-light image enhancement. However, these methods exhibit limited local information modeling capabilities and encounter issues with outliers due to insufficient dynamic range, which curtail their performance in low-light image enhancement. Additionally, the quadratic computational complexity of their Softmax-based self-attention mechanisms renders these methods challenging to deploy on edge devices. To address these issues, we propose a memristor-based Bi-Path Wavelet Transformer (BWT) with linear computational complexity. Specifically, we design a novel Dual-path Wavelet Linear Attention (BWLA) to replace the Softmax-based self-attention, enabling efficient local and global information extraction and aggregation at linear complexity. We propose a hardware implementation scheme of BWT based on memristors, which reduces deployment complexity and offers an effective solution for deploying low-light enhancement algorithms on edge devices. Experiments on multiple low-light enhancement benchmark datasets demonstrate that our method outperforms multiple state-of-the-art (SOTA) methods.},
  archive      = {J_APIN},
  author       = {Xie, Dirui and Cheng, Qi and Zhou, Yue and Hu, Xiaofang},
  doi          = {10.1007/s10489-025-06771-0},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Memristive bi-path wavelet transformer for low-light image enhancement},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-feature fusion-based evolutionary algorithm for large-scale sparse multi-objective optimization problems. <em>APIN</em>, <em>55</em>(13), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06772-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale sparse multi-objective optimization problems are common and present significant challenges in scientific research and engineering practice. The primary characteristics of these problems include the high dimensionality of decision variables and the sparsity of the solution set, which greatly increase the problem’s difficulty. During the algorithmic solution process, the interference of non-critical variables reduces the algorithm’s solving efficiency and negatively impacts the quality of the solution set. Therefore, this paper proposes a large-scale sparse multi-objective evolutionary algorithm based on multi-feature fusion, comprehensively considering the importance of decision variables from multiple aspects. First, we introduce a reference point perturbation clustering method. By evenly distributing reference points in the decision space, we control the perturbation of decision variables. The perturbed decision variables are clustered, and an activation function is used to transform the clustering results into contribution values that assess the importance of the decision variables. Second, we propose a sparse feature detection method to mine sparse features from the sparse information of the decision variables, evaluating the informational content of the decision variables. This information is used to filter decision variables to reduce the search space. Finally, the filtered decision variables are competitively optimized using contribution values. Experiments on eight benchmark problems and three real-world applications demonstrate that the algorithm surpasses current state-of-the-art large-scale sparse multi-objective evolutionary algorithms in terms of convergence speed and solution set quality.},
  archive      = {J_APIN},
  author       = {Wang, Liping and Che, Bangjin and Qiu, Qicang and Gao, Yuyan and Zhao, Peipei},
  doi          = {10.1007/s10489-025-06772-z},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {A multi-feature fusion-based evolutionary algorithm for large-scale sparse multi-objective optimization problems},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D ME-net: Multi-scale and edge-guided enhancement network for intracranial aneurysm segmentation. <em>APIN</em>, <em>55</em>(13), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06779-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intracranial aneurysms are relatively common and life-threatening conditions, making precise segmentation during early diagnosis crucial. However, the challenges of poor imaging quality and high noise levels often result in unclear aneurysm edges. Additionally, the varying sizes of aneurysms further complicate accurate segmentation. To address these issues, we propose a Multiscale and Edge-guided enhanced 3D deep learning model. First, the asymmetrically larger network with enhanced hierarchical feature representation effectively captures subtle image features, thereby improving the localization of anatomical structures. Second, the multi-scale feature fusion mechanism within the encoder improves feature diversity and edge information, enhancing segmentation precision for aneurysms of different sizes. Finally, the edge-guided attention technique within the decoder combines local features with predicted heatmaps to extract comprehensive edge information. The experimental results demonstrate that the model outperforms general models in five key metrics on the internal dataset. External dataset testing confirms its adaptability and robustness across data from different acquisition protocols and hardware configurations. Clinical trials have further validated its practicality, assisting radiologists in more accurate intracranial aneurysm diagnosis.},
  archive      = {J_APIN},
  author       = {Wang, Jiaqi and Liu, Juntong and Li, Jun and Wu, Aiping and Zhou, Yunfeng and Ye, Mingquan},
  doi          = {10.1007/s10489-025-06779-6},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {3D ME-net: Multi-scale and edge-guided enhancement network for intracranial aneurysm segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid CNN-RWKV with high-frequency enhancement for real-world chinese-english scene text image super-resolution. <em>APIN</em>, <em>55</em>(13), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06785-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing scene text image super-resolution (STISR) methods primarily focus on the restoration of fixed-size English text images. Compared to English characters, Chinese characters present a greater variety of categories and more intricate stroke structures. In recent years, Transformer-based methods have achieved significant progress in image super-resolution task, but face the dilemma between global modeling and efficient computation. The emerging Receptance Weighted Key Value (RWKV) model can serve as a promising alternative to Transformer, enabling long-distance modeling with linear computational complexity. In this paper, we propose a Hybrid CNN-RWKV with High-Frequency Enhancement (HCR-HFE) model for STISR task. First, we design a recurrent bidirectional WKV (Re-Bi-WKV) attention which integrates bidirectional WKV (Bi-WKV) attention with a recurrent mechanism. Bi-WKV achieves global receptive field with linear complexity, while the recurrent mechanism establishes 2D image dependencies from different scanning directions. Additionally, a computationally efficient high-frequency enhancement module (HFEM) is incorporated to enhance high-frequency details, such as character edge information. Furthermore, we design a multi-scale large kernel convolutional (MLKC) block which integrates large kernel decomposition, gated aggregation and multi-scale mechanism to capture various-range dependencies with reduced computational cost. Finally, we introduce a multi-frequency channel attention (MFCA) which extends channel attention to the frequency domain, enabling the model to focus on critical features. Extensive experiments on real-world Chinese-English (Real-CE) dataset demonstrate that HCR-HFE outperforms previous methods in both quantitative metrics and visual results. Furthermore, HCR-HFE achieves excellent performance on natural image datasets, demonstrating its broad applicability.},
  archive      = {J_APIN},
  author       = {Liu, Yanbin and Zhu, Yu and Li, Hangyu and Ling, Xiaofeng},
  doi          = {10.1007/s10489-025-06785-8},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Hybrid CNN-RWKV with high-frequency enhancement for real-world chinese-english scene text image super-resolution},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simultaneous fault prediction in evolving industrial environments with ensembles of hoeffding adaptive trees. <em>APIN</em>, <em>55</em>(13), 1-26. (<a href='https://doi.org/10.1007/s10489-025-06786-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive Maintenance (PdM) emerges as a critical task of Industry 4.0, driving operational efficiency, minimizing downtime, and reducing maintenance costs. However, real-world industrial environments present unsolved challenges, especially in predicting simultaneous and correlated faults under evolving conditions. Traditional batch-based and deep learning approaches for simultaneous fault prediction often fall short due to their assumptions of static data distributions and high computational demands, making them unsuitable for dynamic, resource-constrained systems. In response, we propose OEMLHAT (Online Ensemble of Multi-Label Hoeffding Adaptive Trees), a novel model tailored for real-time, multi-label fault prediction in non-stationary industrial settings. OEMLHAT introduces a scalable online ensemble architecture that integrates online bagging, dynamic feature subspacing, and adaptive output weighting. This design allows it to efficiently handle concept drift, high-dimensional input spaces, and label sparsity, key bottlenecks in existing PdM solutions. Experimental results on three public multi-label PdM case studies demonstrate substantial improvements in predictive performance of OEMLHAT over previous batch-based and online proposals for multi-label classification, particularly with an average improvement in micro-averaged F1-score of 18.49% over the second most-accurate batch-based proposal and of 8.56% in the case of the second best online model. By addressing a critical gap in online multi-label learning for PdM, this work provides a robust and interpretable solution for next-generation industrial monitoring systems for fault detection, particularly for rare and concurrent failures.},
  archive      = {J_APIN},
  author       = {Esteban, A. and Cano, A. and Ventura, S. and Zafra, A.},
  doi          = {10.1007/s10489-025-06786-7},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Simultaneous fault prediction in evolving industrial environments with ensembles of hoeffding adaptive trees},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A non-adaptive segmentation algorithm for particle images in controlled environments with uniform backgrounds based on two-round superpixel segmentation and ensemble learning. <em>APIN</em>, <em>55</em>(13), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06792-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle image segmentation under controlled environments with uniform backgrounds remains a challenging task due to issues such as particle adhesion, low contrast, and uneven illumination. Existing methods often suffer from over-segmentation or under-segmentation, especially when applied to microscopic or industrial particles. To address these problems, this paper proposes a non-adaptive segmentation algorithm called TS-EL (Two-round Superpixel Segmentation and Ensemble Learning), which is specifically designed for particle images captured in controlled settings with homogeneous backgrounds. The TS-EL framework performs coarse-to-fine superpixel segmentation and easy-to-hard classification. It introduces a gradient distance-based superpixel segmentation algorithm (GradSE) to improve boundary alignment between superpixels and particle contours. A Gaussian model and dual-factor classification criteria are employed to categorize high-confidence superpixels into foreground and background, while low-confidence regions are refined using a second-round segmentation based on minimum bounding boxes. The final classification of ambiguous regions is achieved via the LogitBoost ensemble learning algorithm. Experimental results on three types of particle images (grain, color masterbatch, and cell images) demonstrate that the proposed method outperforms seven state-of-the-art comparative algorithms in terms of segmentation accuracy and boundary adherence. The method is non-adaptive and relies on empirically set parameters, making it well-suited for batch processing in controlled environments but less generalizable to natural or complex scenes.},
  archive      = {J_APIN},
  author       = {Zhang, Shiming and Ma, Zhikang and Ma, Yan},
  doi          = {10.1007/s10489-025-06792-9},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {A non-adaptive segmentation algorithm for particle images in controlled environments with uniform backgrounds based on two-round superpixel segmentation and ensemble learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Seeking fixed-time practical consensus tracking of networked nonlinear agent systems with saturation via improved extended state observer. <em>APIN</em>, <em>55</em>(13), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06794-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the adaptive fixed-time practical consensus tracking control problem of networked systems subject to unknown dynamics, external disturbances, and input saturations. At first, an Improved Extended State Observer (IESO) is developed to estimate state and external disturbances of the leader model accurately. Subsequently, neural networks are utilized to approximate the lumped uncertainties, which include the unknown dynamics and external disturbances of Euler-Lagrange Systems (ELSs), in real-time. Adaptive update laws are formulated to ensure the boundedness of the neural network estimation error. Additionally, an Auxiliary Dynamic System (ADS) is introduced to mitigate the effects of input saturation. A novel adaptive fixed-time controller is proposed and coupled with the ADS, ensuring that the tracking error converges to a predefined residual set. Through the fine-tuning of parameters within the observer and controller, the convergence time of the system can be precisely controlled. The fixed-time convergence of the proposed control scheme is rigorously demonstrated using Lyapunov stability theory. The efficacy of the proposed control strategy is substantiated through simulation examples.},
  archive      = {J_APIN},
  author       = {Han, Chenglin and Shi, Mengji and Li, Meng and Lin, Boxian and Li, Weihao and Qin, Kaiyu},
  doi          = {10.1007/s10489-025-06794-7},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Seeking fixed-time practical consensus tracking of networked nonlinear agent systems with saturation via improved extended state observer},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural-FCM: A deep learning approach for weight matrix optimization in fuzzy cognitive map classifiers. <em>APIN</em>, <em>55</em>(13), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06795-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demand for interpretable and accurate machine learning models continues to grow, especially in critical domains. The data-driven Fuzzy Cognitive Map (FCM) classifier is an interpretable and transparent decision-making method. Its core element, the weight matrix, is derived using predominantly population-based supervised learning methods which often suffer from degraded performance. Recent research has adopted gradient-based learning techniques to compete with the predictive performance of black-box models. Nonetheless, such methods modify foundational principles and compromise interpretability, highlighting the necessity to improve existing approaches. In this work, we introduce a novel learning and structural modeling method, termed Neural-FCM, which leverages deep neural networks and gradient descent to enhance the accuracy and robustness of FCM learning. Neural-FCM employs a hybrid network comprising both dense and convolutional layers and is trained using a categorical cross-entropy loss function specifically aligned with FCM reasoning. This hybrid model is trained to output instance-specific weight matrices for effective and targeted FCM inference, introducing structural adaptability, a feature not supported by previous static or globally optimized approaches. Focusing on generalization across domains, the Neural-FCM approach is evaluated on different classification tasks across six widely used public datasets and one proprietary medical dataset, consistently showing improved predictive performance. Notably, the comparative analysis against standard population-based FCM learning methods reveals consistent accuracy improvements, with gains of up to 34%. While less transparent gradient-based methods also yield improved accuracy, Neural-FCM demonstrates competitive or superior performance in most cases, with accuracy improvements ranging from 1 to 6% across different domains, while preserving the underlying interpretability. The performance enhancement and the use of instance-specific matrices contribute to the broader goal of developing gradient-based models that balance computational efficiency with the intrinsic FCM interpretability.},
  archive      = {J_APIN},
  author       = {Tziolas, Theodoros and Papageorgiou, Konstantinos and Apostolopoulos, Ioannis and Papageorgiou, Elpiniki},
  doi          = {10.1007/s10489-025-06795-6},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Neural-FCM: A deep learning approach for weight matrix optimization in fuzzy cognitive map classifiers},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Don’t get me wrong: How to apply deep visual interpretations to time series. <em>APIN</em>, <em>55</em>(13), 1-26. (<a href='https://doi.org/10.1007/s10489-025-06798-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The correct interpretation of convolutional models is a hard problem for time series data. While saliency methods promise visual validation of predictions for image and language processing, they fall short when applied to time series. These tend to be less intuitive and represent highly diverse data, such as the tool-use time series dataset. Furthermore, saliency methods often generate varied, conflicting explanations, complicating the reliability of these methods. Consequently, a rigorous objective assessment is necessary to establish trust in them. This paper investigates saliency methods on time series data to formulate recommendations for interpreting convolutional models and implements them on the tool-use time series problem. To achieve this, we first employ nine gradient-, propagation-, or perturbation-based post-hoc saliency methods across six varied and complex real-world datasets. Next, we evaluate these methods using five independent metrics to generate recommendations. Subsequently, we implement a case study focusing on tool-use time series using convolutional classification models. Our results validate our recommendations that indicate that none of the saliency methods consistently outperforms others on all metrics, while some are sometimes ahead. Our insights and step-by-step guidelines allow experts to choose suitable saliency methods for a given model and dataset.},
  archive      = {J_APIN},
  author       = {Löffler, Christoffer and Lai, Wei-Cheng and Zanca, Dario and Schmidt, Lukas and Eskofier, Björn M. and Mutschler, Christopher},
  doi          = {10.1007/s10489-025-06798-3},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Don’t get me wrong: How to apply deep visual interpretations to time series},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Dynamic preventive maintenance strategy for a heterogeneous multi-unit redundant system: A deep reinforcement learning approach with weighted network estimator. <em>APIN</em>, <em>55</em>(13), 1-2. (<a href='https://doi.org/10.1007/s10489-025-06804-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Xu, Deming and Wang, Yan and Liu, Xiang and Ma, Hao and Ji, Zhicheng},
  doi          = {10.1007/s10489-025-06804-8},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-2},
  shortjournal = {Appl. Intell.},
  title        = {Correction to: Dynamic preventive maintenance strategy for a heterogeneous multi-unit redundant system: A deep reinforcement learning approach with weighted network estimator},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TrajDiffRefine: Refinement of spatio-temporal stochastic trajectory prediction via diffusion. <em>APIN</em>, <em>55</em>(13), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06805-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To effectively respond to sudden events in dynamic and complex environments, trajectory prediction systems must have rapid inference capabilities and low error. This is challenging because it requires using low-complexity models to achieve high-precision predictions, which means having an appropriate balance between inference speed and prediction error. To address this challenge, we present a trajectory prediction model based on diffusion for optimizing predicted trajectories — TrajDiffRefine. The core of the proposed TrajDiffRefine is to construct a simple network for initial predictions, followed by diffusion which progressively refines the predictions. This approach significantly accelerates the inference process while ensuring the precision of the final predictions. Moreover, Initial Estimator accounts for the stochasticity and multi-modal nature of human behavior, including variability in individual decision-making, interaction dynamics, and environmental influences. The introduction of indeterminacy effectively improves prediction performance. Experiments on three real-world datasets—NBA, SDD, and ETH-UCY—show that the proposed method outperforms others in terms of both prediction error and efficiency.},
  archive      = {J_APIN},
  author       = {Tan, Xiangyun and Zou, Qi},
  doi          = {10.1007/s10489-025-06805-7},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {TrajDiffRefine: Refinement of spatio-temporal stochastic trajectory prediction via diffusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EGNet: Explainable graph neural network with similarity explanation for medication recommendation. <em>APIN</em>, <em>55</em>(13), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06806-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Giving medication recommendations is a crucial step in improving patient well-being and reducing adverse events. However, existing methods usually fail to capture the complex and dynamic relationships between patient health records, medication efficacy, safety, and drug-drug interactions (DDI), yielding inexplicable outcomes. In this study, we propose an innovative approach that uses graph convolution networks (GCN) with extra external knowledge graphs, attention modules, and an explanation to support prescription recommendations. While the attention system can determine the patient depiction in extended data, GCN can efficiently integrate the external information with the DDI graph into a low-dimensional embedding. We then evaluate our approach using the MIMIC-III and MIMIC-IV datasets, demonstrating that it outperforms several benchmarks in recommendation precision and Drug-Drug Interaction (DDI) prevention. Additionally, we include an explanation stage to illustrate the results and their significant potential impact on industrial applications. The findings confirm that EANet can deliver unparalleled performance while requiring less computational resources and providing enhanced interpretability.},
  archive      = {J_APIN},
  author       = {Nguyen, Minh-Van and Nguyen, Duy-Thinh and Le, Bac},
  doi          = {10.1007/s10489-025-06806-6},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {EGNet: Explainable graph neural network with similarity explanation for medication recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knee-cartilage segmentation from MR images using multi-view hypergraph convolutional neural networks. <em>APIN</em>, <em>55</em>(13), 1-26. (<a href='https://doi.org/10.1007/s10489-025-06808-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leveraging the increased capacities of hypergraphs to model complex data structures, we propose in this article the Multi-view Hyper-Graph Convolutional Network (MVHGCN) to yield automated knee-joint cartilage segmentations from MRIs. The main properties of our approach are presented as follows: 1) Node features are obtained from multi-view (MV) acquisitions, corresponding to different feature extractors or image modalities. 2) Node embeddings are generated using a distributive MV convolution scheme which combines the various view-specific convolutions. These results are aggregated via an attention-based fusion module to automatically learn the weights of the different views. 3) Our model integrates both local and global level learning, simultaneously. Local hypergraph convolutions explore the relationships across the spatially aligned node libraries, while global hypergraph convolutions search for global affinities between nodes located at different positions within the image. 4) We propose two different blending schemes to combine local and global convolutions, namely, the cross-talk (CT) and the collaborative (COL) blending units, respectively. Using these units as building blocks, we construct the MVHGCN model, a deep network with enhanced feature representation and learning capabilities. The suggested segmentation method is evaluated on the publicly available Osteoarthritis Initiative (OAI) cohort. Specifically, we have designed a thorough experimental setup, including parameter sensitivity analysis and comparative results against a series of existing traditional methods, deep CNN models, and graph convolutional networks. The results show that MVHGCN outperforms the competing methods, achieving an overall cartilage segmentation score of $$\mathcal {DSC} = 95.81\%$$ and $$\mathcal {DSC} = 96.33\%$$ , for the CT and the COL blending, respectively.},
  archive      = {J_APIN},
  author       = {Chadoulos, Christos and Theocharis, John and Symeonidis, Andreas and Moustakidis, Serafeim},
  doi          = {10.1007/s10489-025-06808-4},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Knee-cartilage segmentation from MR images using multi-view hypergraph convolutional neural networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated trajectory clustering based on multi-feature similarity calculation. <em>APIN</em>, <em>55</em>(13), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06813-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory clustering plays an important role in numerous real-world applications, such as urban transportation planning and tourist route recommendation. Existing trajectory clustering approaches primarily focus on the spatial and temporal features of trajectories but neglect the velocity feature. Therefore, it is difficult for them to distinguish trajectories sharing spatial and temporal features but diverging velocities. Furthermore, in the context of distributed trajectory clustering among multiple participants, individuals’ privacy, such as the travel routes or habits of a person, should never be violated, which necessitates the equipment of trajectory clustering with privacy-preserving techniques. In this paper, we propose a Federated and Multi-Feature-based Trajectory Clustering (FMFTC) algorithm to address the above issues. First, we develop a Multi-Feature-based Trajectory Clustering (MFTC) algorithm with a new multi-feature to vector encoder (MF2Vec) to capture spatial, temporal and velocity features during trajectory embedding generation. Second, we adapt MFTC to the federated learning paradigm to construct FMFTC for privacy-preserving distributed trajectory clustering. The experiments on real-world datasets demonstrate that FMFTC achieves up to $$\varvec{24.4\%}$$ higher accuracy than existing trajectory clustering algorithms and performs identically as MFTC with no accuracy loss.},
  archive      = {J_APIN},
  author       = {Guo, Kun and Hu, Xinglong and Zhang, Zhiyu and Liu, Chuyu and Zhang, Qishan},
  doi          = {10.1007/s10489-025-06813-7},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Federated trajectory clustering based on multi-feature similarity calculation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incomplete multiview clustering with bipartite tensors. <em>APIN</em>, <em>55</em>(13), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06814-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete Multi-view Clustering (IMC) serves as a pivotal approach in multi-view learning, as it effectively captures latent representations from incomplete multi-view data. This capability significantly enhances intelligent systems’ fault tolerance, reduces data acquisition costs, decreases dependency on data completeness in engineering applications, and improves overall robustness. However, existing incomplete multi-view clustering methods suffer from at least one of the following limitations: 1) they fail to fully explore the clustering structure of incomplete multi-view data; 2) they are sensitive to high missing ratios; 3) they treat different views equally, neglecting the inherent differences among views. This results in certain limitations for existing methods in practical applications, as they still rely on specific data completeness requirements. In this paper, we propose a novel tensor low-rank graph learning framework. First, we introduce a similarity matrix fitting module to construct independent low-dimensional representation matrices for different views under low-rank constraints and connectivity constraints. This method can effectively capture the clustering structure of the data. Furthermore, we introduce the tensor Schatten p-norm to reduce the sensitivity of the proposed method to high missing ratios. Then, we stack these low-dimensional representation matrices into a third-order tensor and leverage the advantages of rotation tensors in encoding higher-order correlations and complementary information between views to learn a low-dimensional consensus representation matrix for these low-dimensional representations. Additionally, we introduce an adaptive strategy to maximize the contribution of each view. Extensive experimental results indicate that IMCBT delivers superior performance in clustering tasks compared to various existing incomplete multi-view methods.},
  archive      = {J_APIN},
  author       = {Luo, Jiaquan and Zhu, Changming},
  doi          = {10.1007/s10489-025-06814-6},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Incomplete multiview clustering with bipartite tensors},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncovering connections: A reference network approach to statute law retrieval. <em>APIN</em>, <em>55</em>(13), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06818-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing volume and complexity of statute law data have led to a growing demand for efficient and effective retrieval methods. This paper presents a novel approach to statute law retrieval that utilizes reference networks to uncover connections between laws. By representing law articles as a network of references, our method allows users to quickly identify relevant direct and indirect articles. The key point is that the reference network can encode both internal and external legal relations, helping to integrate both the local and the long-range dependencies into the final retrieval model. The proposed approach is evaluated on several statute law corpora and shows that it performs better existing methods on the same tasks. In addition, our finding is that internal references help enhance the accuracy significantly while external links are also important. Our empirical study also suggests the optimal range of local window size to achieve a balance between retrieval accuracy and noise. Our approach can also contribute to the development of AI-assisted legal research tools, making it easier for legal practitioners to find relevant laws and precedents. Furthermore, by uncovering hidden connections between laws, our method can help identify inconsistencies and gaps in the legal system, ultimately improving its effectiveness and reliability.},
  archive      = {J_APIN},
  author       = {Vuong, Thi-Hai-Yen and Nguyen, Hai-Long and Nguyen, Tan-Minh and Nguyen, Ha-Thanh and Nguyen, Le-Minh and Phan, Xuan-Hieu},
  doi          = {10.1007/s10489-025-06818-2},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Uncovering connections: A reference network approach to statute law retrieval},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Crack segmentation network based on hybrid-window transformer and dual-branch fusion. <em>APIN</em>, <em>55</em>(13), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06822-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cracks are external manifestations of infrastructure damage, and routine inspections are crucial for assessing their structural safety. However, due to factors such as crack diversity, background noise interference, and information loss, high-precision crack segmentation still faces numerous challenges. To alleviate the influence of these factors, a crack segmentation network based on hybrid-window Transformer and dual-branch fusion (CSHD) is proposed. The CSHD network can effectively capture local texture details and global context modeling to achieve high-precision crack segmentation. First, a hybrid-window attention mechanism(HWA) is designed as the core component, which employs a dual-branch parallel architecture to integrate channel attention and multi-scale depth-wise convolution modules on the value path of window attention, achieving spatial receptive field expansion and cross-window feature interaction. Second, to enhance feature processing capabilities, a locally enhanced gated FeedForward network (LeGN) is proposed, which achieves adaptive feature aggregation through overlapping multi-scale deformable convolution, and a gated unit is designed to optimize the information flow. Thirdly, a dual-branch fusion module (DBF) is introduced in skip-connections of encoder-decoder layers to enhance cross-level feature interaction while effectively mitigating information loss during the downsampling process. Finally, comparative experimental results on three benchmark datasets (CrackLS315, DeepCrack537, and YCD776) with seven advanced networks demonstrate that the proposed network achieves excellent performance, obtaining mean intersection over union (mIoU) scores of 71.26%, 86.58%, and 83.93%, respectively. Code is available at: https://github.com/wjxcsust2024/CSHD .},
  archive      = {J_APIN},
  author       = {Wang, Jianxin and Wang, Jin and Li, Yi and Ge, Dongdong and Zhou, Siyuan},
  doi          = {10.1007/s10489-025-06822-6},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Crack segmentation network based on hybrid-window transformer and dual-branch fusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Survey on tabular data privacy and synthetic data generation in industry 4.0. <em>APIN</em>, <em>55</em>(13), 1-27. (<a href='https://doi.org/10.1007/s10489-025-06823-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic data is an emerging field that solves the raised need for privacy-preserving data sharing and the lack of real data. One of the most common data types used is tabular data, which is widely used to train machine learning models, especially in the industrial domain for better decision-making and edge case handling, two key points in Industry 4.0. In this paper, we present and evaluate state-of-the-art models for tabular data generation under a proposed taxonomy consisting of statistical models, generative adversarial networks (GANs)-based models, denoising diffusion probabilistic models (DDPMs), and large language models (LLMs). Additionally, we propose a revised evaluation taxonomy consisting of three dimensions, including realism, representativeness, and privacy. The results proved that analyzing models based on multiple metrics from each category could ensure a better understanding of the dataset when used for downstream tasks. Finally, we found that models based on GANs are still a solid option in multiple cases, such as a constrained computational environment. In contrast, models based on LLMs and DDPMs are more promising in terms of realism and representativeness. More research should be invested in overcoming limitations such as numerical data representation and long training times for LLMs. Our survey serves as a study for existing models and newer directions in the field, with guidelines for evaluation that can be applied to industrial and other domains.},
  archive      = {J_APIN},
  author       = {Koubeissy, Hadi and Amine, Amir and Kamradt, Marc and Makhoul, Abdallah},
  doi          = {10.1007/s10489-025-06823-5},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-27},
  shortjournal = {Appl. Intell.},
  title        = {Survey on tabular data privacy and synthetic data generation in industry 4.0},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning with graph attention mechanism for vehicle routing problem with time windows. <em>APIN</em>, <em>55</em>(13), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06829-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the logistics industry expands, the complexity of vehicle routing problems, particularly those with time window constraints, increases with the growing demand for services. The challenge of vehicle routing problems with time windows (VRPTW) lies in efficiently scheduling a fleet of vehicles to service a set of customers within specified time frames. This study introduces a deep reinforcement learning approach based on attention mechanisms to optimize vehicle routing and scheduling, aiming to meet specific time window requirements of customers while effectively reducing travel distances and costs, thereby enhancing the efficiency of logistics delivery. This method models the problem as a Markov decision process, defines actions, states, and rewards, and uses reinforcement learning for training to extract node information features and generate preliminary solutions. The model can focus on key information and optimize strategy selection by introducing an encoding-decoding structure and attention map neural network. Then, the large neighborhood search algorithm is used to iterative optimize the initial solution to obtain the optimal solution. The model is trained and tested on the Solomon data set. The experimental results show that the model is significantly better than other methods.},
  archive      = {J_APIN},
  author       = {Zhang, Fan and Hu, Huiling and Zhao, Yuqian},
  doi          = {10.1007/s10489-025-06829-z},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Deep reinforcement learning with graph attention mechanism for vehicle routing problem with time windows},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiview unsupervised domain adaptation through consensus augmented masking for subspace alignment. <em>APIN</em>, <em>55</em>(13), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06834-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain Adaptation (UDA) focuses on bridging the gap between source and target domain distributions. Existing UDA approaches often struggle to capture the diverse contextual dependencies required to address ambiguities in visual feature representations. To overcome these challenges, we propose a framework called Consensus Augmented Masking for Subspace Alignment (CAMSA) that leverages multiview representations to enhance contextual diversity and establish a consensus subspace for improved domain alignment. Firstly, multiple models are independently trained with distinct masking augmentations to ensure prediction consistency and extract specialized multiview features, each capturing a unique contextual perspective. These multiview features are unified into a low-rank structure via sparse subspace representation, enabling cross-view consensus and robust domain alignment. The unified representation is further optimized by constructing a consensus affinity matrix, which facilitates the learning of a projection matrix to embed multiview features into a latent subspace. Within this latent space, source domain prototypes and k-means clustering on the target domain are used to estimate conditional probabilities for downstream tasks. Extensive empirical evaluations on standard benchmark datasets highlight the exceptional performance of CAMSA, consistently surpassing state-of-the-art UDA methods across a variety of architectures and configurations, underscoring the importance of leveraging diverse contextual views for robust domain alignment.},
  archive      = {J_APIN},
  author       = {Zhu, Chenyang and Luo, Weibin and Xie, Yunxin and Fu, Lipei},
  doi          = {10.1007/s10489-025-06834-2},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Multiview unsupervised domain adaptation through consensus augmented masking for subspace alignment},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balanced loss function for long-tailed semi-supervised ship detection. <em>APIN</em>, <em>55</em>(13), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06838-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning (SSL) has significantly reduced the reliance of the ship detection network on labeled images. However, the more realistic and challenging issue of long-tailed distribution in SSL remains largely unexplored. While most existing methods address this issue at the instance level through reweighting or resampling techniques, their performance is significantly limited by their dependence on biased backbone representations. To overcome this limitation, we propose a Balanced Loss function (Bal Loss). Our approach consists of three key components. First, we introduce the BaCon Loss, which computes class-wise feature centers as positive anchors and selects negative anchors through a simple yet effective mechanism. Second, we posit an assumption that the normalized features in contrastive learning follow a mixture of von Mises-Fisher (vMF) distributions in the unit space. This assumption allows us to estimate the distribution parameters using only the first sample moment, which can be efficiently computed in an online manner across different batches. Finally, we incorporate a Jitter-Bagging module, adapted from prior literature, to provide precise localization information, thereby refining bounding box predictions. Extensive experiments demonstrate the efficacy of Bal Loss, achieving SOTA results on ship datasets with a 3.9 improvement over the baseline. Notably, our method attains an $$AP^{r}$$ of 44.1 on the ShipRSImageNet dataset, underscoring its robust detection capabilities.},
  archive      = {J_APIN},
  author       = {Hao, Li-Ying and Yang, Jia-Rui and Zhang, Yunze},
  doi          = {10.1007/s10489-025-06838-y},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Balanced loss function for long-tailed semi-supervised ship detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VAHMSE: An efficient anomaly detection model based on variational autoencoder and heterogeneous multi-stacking ensemble learning. <em>APIN</em>, <em>55</em>(13), 1-26. (<a href='https://doi.org/10.1007/s10489-025-06845-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of the information age, data has become an important resource and production factor. However, the existence of abnormal data causes the lose of personal privacy, business operations and national security, therefore, anomaly detection has received increasing attention in recent years. Most existing anomaly detection models are based on machine learning or deep learning models, but the use of a single model leads to the problems such as overfitting, weak generalization and poor stability. Meanwhile, there is a serious data imbalance problem due to the significantly few number of abnormal data compared to normal data, which reduces the detection performance. To address these issues, this paper proposes an anomaly detection model called VAHMSE based on variational autoencoder and heterogeneous multi-stacking ensemble learning to improve the detection performance. In the data augmentation phase, the variational autoencoder (VAE) is used to replace traditional oversampling and other class balancing techniques to solve the data imbalance problem, and the mutual information is added to the loss function of traditional VAE to solve the problem of posterior distribution collapsing to prior distribution, thereby improving the quality of data generation. In the anomaly detection phase, the heterogeneous multi-stacking ensemble learning-based anomaly detection method is proposed, where five machine learning models with good performance are selected as the base learners in the first layer stacking process, and the TCN is selected as the meta learner in the second layer stacking process; In addition, the Squeeze and Excitation module is integrated into the traditional TCN model to explicitly model the interdependence between convolutional feature channels and improve the representation ability of network. Extensive experiments on six widely used datasets show that compared with five state-of-the-art models, the proposed VAHMSE achieves better performance in accuracy, recall, precision and F1-score, and it also achieves better stability.},
  archive      = {J_APIN},
  author       = {Wang, Rui and Li, Jiayao},
  doi          = {10.1007/s10489-025-06845-z},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {VAHMSE: An efficient anomaly detection model based on variational autoencoder and heterogeneous multi-stacking ensemble learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Educational knowledge graph based intelligent question answering for automatic control disciplines. <em>APIN</em>, <em>55</em>(13), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06847-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the further development of education informatization, Educational Knowledge Graph (EKG) based intelligent Question Answering (KGQA) has attracted significant attention in smart education. However, current educational KGQA faces enormous challenges, such as the incomplete questions from students, the dispersed knowledge from EKG, and the scarce and imbalanced dataset. In this paper, a novel educational KGQA model was proposed for answering student’s questions on automatic control disciplines. Firstly, a topic entity detection algorithm was constructed based on BERT-BiLSTM-CRF and domain dictionary, and an intention recognition algorithm was built based on BERT and TextCNN to accurately locate the topic entity by formulating entity priority, entity completion rules, and similarity calculation. Then, a custom weighted cross-entropy loss function (CCL) was designed to alleviate the influence of imbalanced samples in the training dataset on the model classifier. In addition, the first Chinese dataset for educational KGQA in automatic control disciplines (ACKGQA) was constructed. Finally, extensive experiments are performed to evaluate the effectiveness and generalizations of the proposed KGQA model on the ACKGQA dataset and five benchmark public datasets. The proposed KGQA obtains the recognition precision of 87.5% and the recall of 86.25% on the ACKGQA dataset and exhibits better overall performance on other five benchmark datasets. Experimental results demonstrate that our educational KGQA model can achieve outstanding performance when facing the challenges posed by imbalanced datasets inherent in educational knowledge graphs.},
  archive      = {J_APIN},
  author       = {Cai, Zhiwei and Xu, Nuoying and Cai, Linqin and Ren, Bo and Xiong, Yu},
  doi          = {10.1007/s10489-025-06847-x},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Educational knowledge graph based intelligent question answering for automatic control disciplines},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instance-aware context with mutually guided vision-language attention for referring image segmentation. <em>APIN</em>, <em>55</em>(13), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06851-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Referring image segmentation, which integrates both visual and linguistic modalities, represents a forefront challenge in cross-modal visual research. Traditional approaches generally fuse linguistic features with visual data to generate multi-modal representations for mask decoding. However, these methods often mistakenly segment visually prominent entities rather than the specific region indicated by the referring expression, as the visual context tends to overshadow the multi-modal features. To address this, we introduce IMNet, a novel referring image segmentation framework that harnesses the Contrastive Language-Image Pre-training (CLIP) model and incorporates a mutually guided vision-language attention mechanism to enhance accuracy in identifying the referring mask. Specifically, our mutually guided vision-language attention mechanism consists of language-guided attention and vision-guided attention, which model bi-directional relationships between vision and linguistic features. Additionally, to accurately segment instances based on referring expressions, we develop an instance-aware context module within the decoder that focuses on learning instance-specific features. This module connects instance prototypes with corresponding features, using linearly weighted prototypes for final prediction. We evaluate the proposed method on three publicly available datasets, i.e., RefCOCO, RefCOCO+, and G-Ref. Comparisons with previous methods demonstrates that our approach achieves competitive performance.},
  archive      = {J_APIN},
  author       = {Sun, Qiule and Zhang, Jianxin and Zhang, Bingbing and Li, Peihua},
  doi          = {10.1007/s10489-025-06851-1},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Instance-aware context with mutually guided vision-language attention for referring image segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MDT: A multiscale differencing transformer with sequence feature relationship mining for robust action recognition. <em>APIN</em>, <em>55</em>(13), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06861-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton-based action recognition, which analyzes joint coordinates and bone connections to classify human actions, is important in understanding and analyzing human dynamic behaviors. However, actions in complex scenes have a high degree of similarity and variability, with the dynamic changes in human skeletons and subtle temporal variations in particular posing significant challenges to the accuracy and robustness of action recognition systems. To mitigate these challenges, we propose a novel multiscale differencing transformer (MDT) with sequence feature relationship mining for robust action recognition. MDT effectively mines inter-frame timing information and feature distribution differences across multiple scales, enabling a deeper understanding of the nuances between actions. Specifically, we first propose multiscale differential self-attention to handle the need for understanding action changes across multiple time scales, improving the capacity of the model to effectively capture the global and local dynamic features of actions. Then, we introduce a sequence feature relationship mining module to address complex data patterns in scenes that may span multiple sequences, exhibiting both similar and distinct characteristics. By utilizing coarse- and fine-grained sequence information, this module empowers the model to recognize intricate data patterns. On the NTU RGB+D 60 dataset, the proposed MDT model outperforms the recent STAR-Transformer by 1.6% on the Cross-Subject (CS) setting and 1.1% on the Cross-View (CV) setting, demonstrating its consistent effectiveness across different evaluation protocols.},
  archive      = {J_APIN},
  author       = {Chen, Zengzhao and Ma, Fumei and Liu, Hai and Huang, Wenkai and Liu, Tingting},
  doi          = {10.1007/s10489-025-06861-z},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {13},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {MDT: A multiscale differencing transformer with sequence feature relationship mining for robust action recognition},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SWADA: Slide-window-based active domain adaptation for cross-modality medical image segmentation. <em>APIN</em>, <em>55</em>(12), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06554-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation has emerged as an effective paradigm to address the domain shift issue in deep neural networks. Despite its success, achieving fully supervised performance remains a potential challenge. Recent efforts have introduced active learning to the domain adaptation problem, leveraging limited manual annotation costs to achieve near fully-supervised results. However, current methods still give rise to two main concerns: (1) annotation budget: existing methods tend to label excessive redundant regions within objects, potentially resulting in a waste of the annotation budget. (2) acquisition strategy: existing methods struggle to efficiently select representative samples, which could impede the network from learning information exclusive to the target domain. In light of these concerns, we propose a novel Slide-Window-Based Active Domain Adaptation (SWADA) method for cross-modality medical image segmentation. SWADA employs a slide-window mechanism to comprehensively explore the dependencies among different window regions, preventing redundant region selections and omissions of object boundaries. This ultimately minimizes the wastage of the annotation budget. Further, we present an innovative acquisition strategy that dynamically selects windows for annotation by considering inconsistency, uncertainty, and diversity. This guarantees the representative nature of the selected window regions, consequently enhancing the performance of cross-modality segmentation. Alongside this, we propose an inter-class distance optimization strategy to model and optimize the explicit category dependencies among various objects, strengthening the feature discriminability between different categories. Extensive empirical evidence demonstrates that SWADA consistently outperforms state-of-the-art methods across three public benchmarks.},
  archive      = {J_APIN},
  author       = {Wang, Yongjun and Wang, Yongmei and Zhou, Yifeng and Chen, Wenxi and Wen, Sijian},
  doi          = {10.1007/s10489-025-06554-7},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {SWADA: Slide-window-based active domain adaptation for cross-modality medical image segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time application employing back- or side-view images of individuals to search for specific faces. <em>APIN</em>, <em>55</em>(12), 1-24. (<a href='https://doi.org/10.1007/s10489-025-06668-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surveillance cameras frequently capture only the rear or side views of criminals, posing a challenge for investigators: how to utilize these suspect images without faces to swiftly locate the face of a suspect in vast surveillance video archives. This study introduces a pioneering YOLOv8-Reidentification + real-time search application (YRRSA) approach, which is a two-stage solution that efficiently processes raw surveillance video and conducts real-time searches for suspect faces. This system combines an enhanced YOLOv8 model with an improved person reidentification (ReID) model. In the first-stage subnetwork, the authors design a multispace-to-depth (MSTD) module and apply it to YOLOv8 to strengthen its ability to extract detailed features. A fusion-based ReID model is designed as the second-stage subnetwork; is composed of a ResNet backbone network and a designed dynamic deformable fusion (DDF) structure. This ReID model can overcome the most significant body and limb deformation issues encountered in person reidentification tasks. Although the performance of these two subnetworks cannot surpass that of the state-of-the-art (SOTA) networks, they have the fewest parameters and the fastest speed among the networks with the same level of performance. The enhanced YOLOv8 model achieves excellent accuracy while maintaining a very small number of parameters. The improved ReID model has a similar accuracy to that of the SOTA approaches but is more than twice as fast as them. This study improves the baseline model to achieve higher accuracy and a faster speed without considering computing resources. Moreover, the unique target matching algorithm (UTMA) is designed to implement facial detection-based criminal matching. Finally, this study conducts actual scenario tests by deploying the proposed system, further highlighting its significance for use in real-world applications. Criminal investigators often can capture only the backs or profiles of suspects, which contain limited information for case investigations. How to quickly find the frontal image of a suspect within massive surveillance video data by using back images, extract facial information, and compare this information with public security system data is crucial for conducting case investigations.},
  archive      = {J_APIN},
  author       = {Du, Cunwei and Deng, Jiali and Zixuan, Tong and Wang, Xiaomin and Cheng, Kai and Zhou, Xiaolong and Liu, Ming},
  doi          = {10.1007/s10489-025-06668-y},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {A real-time application employing back- or side-view images of individuals to search for specific faces},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Credibilistic skewness of LR power fuzzy numbers with applications in portfolio selection. <em>APIN</em>, <em>55</em>(12), 1-28. (<a href='https://doi.org/10.1007/s10489-025-06678-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel analytical expression to compute the crisp equivalent of the credibilistic skewness for an LR fuzzy number belonging to the power family. Using this expression, a novel multi-objective portfolio selection model is proposed within the credibilistic framework. The model simultaneously optimizes three key objectives–mean, semivariance, and skewness of the portfolio return–while incorporating practical constraints such as budget, cardinality, bounds on the assets allocations, and no short-selling. This work addresses a notable gap in the literature, where higher-order moments like skewness are seldom considered in the context of LR power fuzzy numbers under credibility theory. All the objectives have been evaluated by considering the returns of the entire portfolio instead of dealing explicitly with the returns of individual assets. It eliminates the need for computationally expensive simulations of diverse portfolio attributes resulting from aggregating individual asset returns. The proposed model is effectively solved using an adapted version of a highly efficient multi-objective genetic algorithm (MOGA), specially configured to handle complex portfolio selection problems under practical constraints. Empirical analysis using historical data from the NIFTY 50 Index of the National Stock Exchange (NSE), India, reveals that incorporating credibilistic skewness of LR power fuzzy numbers yields superior performance compared to existing models. Additionally, the proposed model demonstrates superior performance over benchmarks like the NIFTY 50 Index and the naïve 1/n investment strategy, underscoring its practical utility in real-world portfolio construction.},
  archive      = {J_APIN},
  author       = {Mandal, Pawan Kumar and Verma, Bhisham Dev and Thakur, Manoj and Mittal, Garima},
  doi          = {10.1007/s10489-025-06678-w},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-28},
  shortjournal = {Appl. Intell.},
  title        = {Credibilistic skewness of LR power fuzzy numbers with applications in portfolio selection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PointCoCa: Point contrastive captioner pre-trained with prompt-driven datasets generation enhances point cloud shape understanding. <em>APIN</em>, <em>55</em>(12), 1-12. (<a href='https://doi.org/10.1007/s10489-025-06680-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building large-scale 3D datasets for pre-training a 3D shape understanding model is costly and requires considerable resources including expensive equipment, highly skilled engineers and relatively long time. To address this challenge, we propose an efficient approach named Point Contrastive Captioner (PointCoCa) which pre-trains the model using generated 3D datasets. Our work consists of two major components: (1) a data generation pipeline, which combines a text-conditional 3D shape generative model and a systematic prompt generation process; (2) a 3D shape understanding model, which is a multi-modal point cloud-text contrastive learning model pre-trained on the generated 3D dataset. Instead of aligning the 3D data with a pre-trained CLIP model, we pre-train PointCoCa from scratch for a more straightforward point cloud-text representation. PointCoCa achieves a state-of-the-art zero-shot classification accuracy of 65.7% on ScanObjectNN dataset and competitive performance on the ModelNet datasets which shows the effectiveness of the proposed approach. Additionally, based on the encoder-decoder architecture, PointCoCa can be directly applied to the point cloud captioning task without further modification.},
  archive      = {J_APIN},
  author       = {Liu, Fenglin and Zhou, Tao and Wang, Wei and Ma, Jianliang and Li, Dong and Xi, Wei},
  doi          = {10.1007/s10489-025-06680-2},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {PointCoCa: Point contrastive captioner pre-trained with prompt-driven datasets generation enhances point cloud shape understanding},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale dual dynamic spatiotemporal graph convolutional network for traffic flow prediction. <em>APIN</em>, <em>55</em>(12), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06685-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problems that the multi-scale features and long-term dependencies of traffic flow are not easy to model synchronously and the higher-order hidden dynamic spatiotemporal features are challenging to capture, this paper proposes a multi-scale dual-dynamic spatiotemporal graph convolution network (MSD $$^{\varvec{2}}$$ GCN) for traffic flow prediction. The dual hypergraph is employed to efficiently capture the spatiotemporal dependencies of the edges of the traffic flow graphs. The dynamic interactive convolution (DIC) between the dual-dynamic GCNs propagation features, the spatiotemporal dynamic hypergraph convolutional network (STDHCN), and the spatiotemporal dynamic graph convolutional network (STDGCN) are used to model the dynamic properties of the traffic flow graph’s edges and nodes, respectively. The Multi-scale Axial Attention Module (MSCAM) utilizes bar convolution to incorporate multi-scale features into the axial attention computation. It establishes a double cross-attention between the two traffic flow spatial axial attentions to better capture different spatial flow scale features and improve the model’s long-term prediction capability. The experimental findings demonstrate that the MSD $$^{\varvec{2}}$$ GCN model outperforms the majority of the existing baseline models in terms of prediction performance.},
  archive      = {J_APIN},
  author       = {Zhang, Hong and Yi, Min and Zhang, Xijun and Wei, Jiaoyun},
  doi          = {10.1007/s10489-025-06685-x},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Multi-scale dual dynamic spatiotemporal graph convolutional network for traffic flow prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized clothing matching recommendation algorithm based on user portrait. <em>APIN</em>, <em>55</em>(12), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06701-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient clothing recommendation system can provide users with personalized and intelligent matching suggestions to meet their different needs and preferences. Currently, mainstream algorithms usually recommend best-selling apparel based on the user’s browsing history, purchase records and other information, however, the matching relationship between the clothing itself and the user portrait is not fully considered. Aiming at the above problems, this paper proposes a personalized clothing matching recommendation algorithm based on user portrait. First, the MobileNetV3 network integrated with migration learning is used to classify the user’s facial color, and the AB-CNN network is designed to classify the user’s age and face shape to establish a user objective attribute recognition model. Second, the face recognition technology is used to recognize the user and obtain the user’s history information, and the subjective preference model is designed to construct a high-precision user portrait by combining collaborative filtering and contextual information. Third, the theory of clothing matching is used to calculate the comprehensive score of clothing matching, and accurate recommendations are obtained through user preference feedback to improve user satisfaction. Finally, experiments are carried out on datasets such as AGFW-v2 [50], Polyvore [44], DressCode [41], and the experimental results showed that the maximum values of first match recommendation accuracy, system comprehensive performance, recommendation accuracy rate, recall rate and F1 value reached 88.47%, 96.35, 72.45%, 69.92% and 71.07%, respectively, which was superior to the existing algorithm.},
  archive      = {J_APIN},
  author       = {Su, Xueping and Lei, Yihang and Wang, Can and Li, Yunhong and Ren, Yingxuan},
  doi          = {10.1007/s10489-025-06701-0},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Personalized clothing matching recommendation algorithm based on user portrait},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid prediction model for stock trend based on gated recurrent unit and wavelet transform. <em>APIN</em>, <em>55</em>(12), 1-25. (<a href='https://doi.org/10.1007/s10489-025-06702-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The closing price of a stock is a crucial indicator for evaluating the stock market and aiding stock investors in making informed decisions. Accurately predicting the closing price of a stock is of utmost importance. This paper introduces the DW-SGA model, a hybrid prediction approach for accurately forecasting stock closing prices. It combines machine learning to select relevant stock data features with discrete wavelet decomposition, which can distinguish the high-frequency and low-frequency components in the feature sequence. The low-frequency part encapsulates overall stock price trends, while the high-frequency part captures timing details. These components are processed by stacked GRU units, creating a two-dimensional input that enhances the model’s ability to capture spatio-temporal characteristics and improve prediction accuracy. The model incorporates an attention mechanism to focus on crucial information within the hidden state sequence, enhancing its predictive capabilities. Utilizing single-step prediction, the model forecasts the closing price, and the results show superior accuracy and training efficiency, particularly for stocks with high volatility and uncertainty. This makes the DW-SGA model a valuable tool for forecasting the closing price of such stocks.},
  archive      = {J_APIN},
  author       = {Li, Zhuoxuan and Wang, Youxin and Cao, Jinde and Huang, Chuangxia},
  doi          = {10.1007/s10489-025-06702-z},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {A hybrid prediction model for stock trend based on gated recurrent unit and wavelet transform},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Imitation learning-driven approximation of stochastic control models. <em>APIN</em>, <em>55</em>(12), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06704-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive control is a widely adopted methodology in numerous industries to manage multi-variable control problems under constraints. Traditional predictive control methods, however, assume complete model knowledge and deterministic behavior, which is often unrealistic in practical applications due to uncertainties and disturbances. Stochastic predictive control addresses these limitations by incorporating probabilistic models to enhance robustness in uncertain environments, but this approach comes at the cost of significantly increased computational complexity, making real-time implementation challenging. This paper proposes a method based on imitation learning to approximate the solution of stochastic predictive control, significantly reducing computational burden while maintaining predictive capabilities and robustness. The effectiveness of the proposed method is first demonstrated on the cart-pole stabilization problem, followed by its application to optimal lithium-ion battery charging. Results from both case studies underscore the method’s robust approximation capabilities and substantial computational cost reduction, underscoring its potential for real-time applications in diverse domains, including robotics, energy management, and autonomous systems.},
  archive      = {J_APIN},
  author       = {Pozzi, Andrea and Incremona, Alessandro and Toti, Daniele},
  doi          = {10.1007/s10489-025-06704-x},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Imitation learning-driven approximation of stochastic control models},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-query network learning for hoi detection via vision-language models. <em>APIN</em>, <em>55</em>(12), 1-12. (<a href='https://doi.org/10.1007/s10489-025-06709-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human object interaction (HOI) is a core visual task in computer vision for understanding the static relationship between humans and objects. Recently, some approaches have achieved impressive results by Vision-Language Models (VLM) to provide prior knowledge for HOI detectors. However, such methods often fail to effectively extract knowledge features. In this paper, we propose a Multi-Query Network (MQN) to address the drawbacks of the prior query-based HOI detectors in two dimensions. For the breadth, the previous method assigning very few queries to a single instance reduces training efficiency. We design a multi-query branch that allows one instance to correspond to multiple queries while retaining the original query scheme. This approach greatly enhances knowledge transfer capabilities. For the depth, to address the cascading issues of decoding sequences, we introduce a Knowledge Representation Extractor (KRE) that accumulates intermediate features progressively through the decoding layers. Furthermore, we propose a Verb Attention (VA) module to enhance supervision over verb categories. Extensive experiments have shown that MQN is significantly more effective than the state of the art on multiple datasets.},
  archive      = {J_APIN},
  author       = {Shi, Leideng and Zhang, Juan},
  doi          = {10.1007/s10489-025-06709-6},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {Multi-query network learning for hoi detection via vision-language models},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). End-to-end multidimensional interpretable tourism demand combined forecasting model based on feature fusion. <em>APIN</em>, <em>55</em>(12), 1-32. (<a href='https://doi.org/10.1007/s10489-025-06715-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and interpretable tourism demand forecasting helps to improve the operation and management of tourism-related businesses and government departments. Although existing studies have proposed a variety of tourism demand forecasting models based on deep learning methods, which significantly improve the accuracy of tourism demand forecasting, there is a lack of a comprehensive interpretable forecasting method that provides a comprehensive, transparent, and reliable explanation of the forecasting process. In this study, a comprehensive method for multidimensional explainable tourism demand portfolio forecasting based on multi-source data is proposed. First, tree shapley additive explanations methods are used to select the feature data most relevant to tourism demand and provide an interpretable analysis. Then, attention - sparse autoencoder method is used to reduce the dimensionality of the selected important features. Meanwhile, an efficient and robust Informer - bidirectional long short-term memory neural network model is proposed in this study and optimized using polar lights optimizer. Finally, a multi-objective optimization algorithm enhanced by reinforcement learning is used to optimize the weights of the ensemble prediction model. In addition, the local interpretable model-agnostic explanations interpretability method is used in this study with the results of Tree shap to form a multidimensional interpretability framework. The experimental results show that the proposed method achieves higher accuracy in forecasting tourism demand, while providing managers with more reliable and comprehensive process and decision support.},
  archive      = {J_APIN},
  author       = {Wu, Binrong and Lin, Jiacheng and Lv, Sheng-Xiang and Wang, Lin},
  doi          = {10.1007/s10489-025-06715-8},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-32},
  shortjournal = {Appl. Intell.},
  title        = {End-to-end multidimensional interpretable tourism demand combined forecasting model based on feature fusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CProtoNet: A conceptual prototype network based on conceptual similarity. <em>APIN</em>, <em>55</em>(12), 1-27. (<a href='https://doi.org/10.1007/s10489-025-06719-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the remarkable performance of neural networks across various fields, their decision processes often lack transparency and interpretability. Consequently, explainable AI has become increasingly important. Many current studies on the interpretability of image recognition can analyze which regions within an image significantly influence the decision outcomes, but they struggle to simultaneously meet the requirements of interpretability and high accuracy. This paper introduces a neural network based on concept similarity in experience for decision, called the CProtoNet (Concept Prototype Network). Firstly, it incorporates a specialized network layer designed to learn the object features within the dataset. These object features are referred to as partial prototypes of the corresponding class for the image. Subsequently, a concept extractor within the network layer extracts the semantic concepts represented by these partial prototypes, termed prototype concepts. Finally, we impose specific constraints on the network to make decisions based on the similarity between prototype concepts. The experiments on the Stanford Dogs Dataset, the Category Flower Dataset and the CUB-200-2011 indicate that CProtoNet achieves a classification accuracy slightly higher than that of similar unexplainable networks. Additionally, CProtoNet can identify the concept prototypes that most significantly influence the neural network decisions. The experiments on the Stanford Dogs Dataset and the Category Flower Dataset.},
  archive      = {J_APIN},
  author       = {Gao, LiJun and Wang, SuRan and Gu, WenWen and Sun, ZeYang and Jin, Xiao and Zhang, YouZhi and Wu, JieHong},
  doi          = {10.1007/s10489-025-06719-4},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-27},
  shortjournal = {Appl. Intell.},
  title        = {CProtoNet: A conceptual prototype network based on conceptual similarity},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BinRec: Addressing data sparsity and cold-start challenges in recommender systems with biclustering. <em>APIN</em>, <em>55</em>(12), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06725-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender Systems help users in making decision in different fields such as purchases or what movies to watch. User-Based Collaborative Filtering (UBCF) approach is one of the most commonly used techniques for developing these software tools. It is based on the idea that users who have previously shared similar tastes will almost certainly share similar tastes in the future. As a result, determining the nearest users to the one for whom recommendations are sought (active user) is critical. However, the massive growth of online commercial data has made this task especially difficult. As a result, Biclustering techniques have been used in recent years to perform a local search for the nearest users in subgroups of users with similar rating behaviour under a subgroup of items (biclusters), rather than searching the entire rating database. Nevertheless, due to the large size of these databases, the number of biclusters generated can be extremely high, making their processing very complex. In this paper we propose BinRec, a novel UBCF approach based on Biclustering. BinRec simplifies the search for neighbouring users by determining which ones are nearest to the active user based on the number of biclusters shared by the users. Experimental results show that BinRec outperforms other state-of-the-art recommender systems, with a remarkable improvement in environments with high data sparsity. The flexibility and scalability of the method position it as an efficient alternative for common collaborative filtering problems such as sparsity or cold-start.},
  archive      = {J_APIN},
  author       = {Rodríguez-Baena, Domingo and Gómez-Vela, Francisco and Lopez-Fernandez, Aurelio and García-Torres, Miguel and Divina, Federico},
  doi          = {10.1007/s10489-025-06725-6},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {BinRec: Addressing data sparsity and cold-start challenges in recommender systems with biclustering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep semi-supervised echo state network-based distributed operating performance assessment framework for manufacturing processes optimized by enhanced black-winged kite algorithm. <em>APIN</em>, <em>55</em>(12), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06734-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operating performance assessment is critical for improving production efficiency and ensuring economic benefits. Traditional echo state networks (ESNs), despite their strong nonlinear and dynamic modeling capabilities, are limited by their reliance on labeled samples and high computational costs when expanded into deep networks. To overcome these challenges, we propose the first deep semi-supervised ESN (DSESN) framework that synergistically integrates unlabeled and labeled data. First, unsupervised learning is performed with both labeled data and unlabeled data in the multi-layer reservoir construction stage. Then, only labeled data are used for classification in the output optimization stage. Furthermore, we propose an enhanced black-winged kite algorithm (EBKA) incorporating weight-splitting with perturbation mechanism to efficiently optimize weight parameters of the network. On this foundation, we develop a distributed operating performance assessment strategy based on DSESN. Finally, the effectiveness and feasibility of DSESN-based assessment framework is validated on the case of hot strip mill process (HSMP). Compared with three popular ESN-based methods, the proposed DSESN has the highest accuracy in two cases, reaching 97.35% and 95.50%, respectively.},
  archive      = {J_APIN},
  author       = {Zhang, Chuanfang and Yin, Wenxiao and Peng, Kaixiang and Zhang, Xueyi},
  doi          = {10.1007/s10489-025-06734-5},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {A deep semi-supervised echo state network-based distributed operating performance assessment framework for manufacturing processes optimized by enhanced black-winged kite algorithm},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLO-MSD: A robust industrial surface defect detection model via multi-scale feature fusion. <em>APIN</em>, <em>55</em>(12), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06739-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is vital for automated surface defect inspection, yet most models suffer from bloated architectures and poor performance on multi‑class, multi‑scale tasks involving large‑size images, limiting their use on edge devices. We propose YOLO‑MSD, a lightweight surface defect detection model that integrates two key designs: (1) a novel four-scale backbone that effectively extracts small and multi-scale targets from large-size images by enhancing feature representation across different scale resolutions, and (2) a streamlined feature‑pyramid neck that boosts cross‑scale fusion while reducing parameters and computational cost. Extensive experiments on five public datasets verify the model’s effectiveness. On the PCB, HRIPCB and GC10‑DET datasets featuring high-resolution images, YOLO‑MSD achieves 96.67% mAP, 96.62% mAP and 69.09% mAP, respectively, while maintaining a low parameter count and computational complexity. It also outperforms most advanced models on two additional public datasets and achieves 20.82 FPS with a power consumption of 6.95 W on the PCB dataset when deployed on a Jetson Xavier NX edge device. These results demonstrate the accuracy, efficiency, and deployability of YOLO‑MSD for industrial surface‑defect detection.},
  archive      = {J_APIN},
  author       = {Ge, Yifei and Li, Zhuo and Meng, Lin},
  doi          = {10.1007/s10489-025-06739-0},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {YOLO-MSD: A robust industrial surface defect detection model via multi-scale feature fusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual cross transformer based on multi-scale fusion for fine-grained action recognition. <em>APIN</em>, <em>55</em>(12), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06742-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks demonstrate strong capability in local spatio-temporal modeling, but they have limitations in capturing global dependency. The transformer architecture has a strong ability to model global dependency but cannot effectively capture local features. For fine-grained action recognition,the combination of the two is beneficial to extract richer fine-grained features. To this end, we introduce a dual cross transformer framework. The multi-scale features from different levels of the convolutional network are extracted and divided into low-level features and high-level features, which are then fed into the dual cross transformer module. The dual cross transformer enables the information interaction of low-level features and high-level features, fuses multi-scale features and models global dependency. Our model achieves competitive performance across various challenging datasets, including FineGym and Diving48,highlighting its strong capability in modeling complex temporal data.},
  archive      = {J_APIN},
  author       = {Di, Jirui and Hu, Zhengping and Zhang, Hehao and Zhang, Qiming and Sun, Zhe},
  doi          = {10.1007/s10489-025-06742-5},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Dual cross transformer based on multi-scale fusion for fine-grained action recognition},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of multi-attribute large-scale group decision-making based on adaptive multi-threshold constraints in selecting the optimal site of a wastewater treatment plant. <em>APIN</em>, <em>55</em>(12), 1-26. (<a href='https://doi.org/10.1007/s10489-025-06540-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is challenging to achieve consensus under the constraint of a single threshold in multi-attribute large-scale group decision-making (MALSGDM) within a probabilistic linguistic environment, particularly in complex scenarios such as selecting the optimal site for a wastewater treatment plant (WWTP). The site selection process for a WWTP involves integrating the opinions of multiple decision-makers (DMs) and requires comprehensive consideration of environmental, economic, and social attributes, where decision information is often characterized by fuzziness and uncertainty. Consequently, a decision framework which integrates learning mechanism and feedback mechanism is proposed to ensure the completeness of evaluation information and maintain the consistency during the consensus reaching process (CRP). However, most existing methods rely on the constraint of a single threshold, which makes it difficult for DMs to reach consensus in a fuzzy environment, particularly for probabilistic linguistic term sets (PLTSs) information. Therefore, it is important to explore methods for ensuring that DMs reach consensus at a low range of adjustment with adaptive threshold constraints. To achieve this goal, a new learning mechanism based on PLSs is proposed for decision information processing, and a feedback mechanism with adaptive multi-threshold constraints is introduced into the consensus recognition rules. Moreover, an optimization method based on the minimum adjustment consensus model (MACM) is proposed for the CRP. Finally, a case study on selecting the optimal site for a WWTP demonstrates the effectiveness and flexibility of the proposed methods. This framework is not only applicable to WWTP’s site selection but can also be extended to other domains requiring MALSGDM.},
  archive      = {J_APIN},
  author       = {Yang, Shanshan and Jiang, Wenqi and Pedrycz, Witold and Tao, Xiwen and Wang, Jiali and Xu, Tianqi},
  doi          = {10.1007/s10489-025-06540-z},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Application of multi-attribute large-scale group decision-making based on adaptive multi-threshold constraints in selecting the optimal site of a wastewater treatment plant},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Empowering classroom behavior recognition through hybrid spatial-temporal feature fusion. <em>APIN</em>, <em>55</em>(12), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06638-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recognition of learners’ behaviors in classrooms is an important problem. It supports the assessment of the level of interest and engagement of students in the lecture, helping instructors to adjust their teaching methods promptly. This paper proposes a novel approach to human behavior analysis in educational settings by leveraging a combination of the Swin Transformer and skeleton-based LSTM networks. By effectively processing both RGB video data and skeletal sequences, the proposed combination model outperforms other models in capturing intricate spatial-temporal features, leading to improved accuracy in detecting student behaviors such as reading, writing, sleeping, and raising hands. To facilitate this research, a comprehensive dataset is also constructed, combining RGB frames and skeleton structures to provide a rich representation of human actions. The experimental results demonstrate the effectiveness of the proposed method in accurately identifying student behaviors. This research serves as a foundation for developing advanced techniques to diagnose learners’ psychological states, paving the way for personalized and adaptive learning experiences.},
  archive      = {J_APIN},
  author       = {Nguyen, Hung and Tran, Nha and Nguyen, Minh and D. Nguyen, Hien},
  doi          = {10.1007/s10489-025-06638-4},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Empowering classroom behavior recognition through hybrid spatial-temporal feature fusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Runtime analysis of adaptive selection variation operators in evolutionary algorithm with reinforcement learning. <em>APIN</em>, <em>55</em>(12), 1-9. (<a href='https://doi.org/10.1007/s10489-025-06687-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variation operators have great impact on the performance of evolutionary algorithms (EAs) because they determine the way of EAs constructing the new solutions during the evolutionary process. However, finding efficient variation operator for various kinds of optimization problems is a very challenge task in the field of evolutionary computation. This paper proposes an adaptive variation operator EA with using reinforcement learning. Specifically, the proposed EA adaptively selects variation operator from a set of simple operators to generate the offspring individuals by using Q-learning method in each generation. Theoretical analyses on a set of Pseudo-Boolean functions show that the expected runtime of the proposed algorithm is better than or equivalent to that of the well-studied $$\varvec{(1+1)\;\textrm{EA}}$$ . These results show the potential of the proposed method for solving complex problems in real-world applications. Moreover, this paper defines a new Pseudo-Boolean function, called Singular Point problem, which is showed to be rather challenge for several classic variation operators in conventional EAs and can be served as benchmark functions for theory analysis of EAs in future research.},
  archive      = {J_APIN},
  author       = {Tianyi, Yang and Yuren, Zhou},
  doi          = {10.1007/s10489-025-06687-9},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-9},
  shortjournal = {Appl. Intell.},
  title        = {Runtime analysis of adaptive selection variation operators in evolutionary algorithm with reinforcement learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving SMOTE via fusing conditional VAE for data-adaptive noise filtering. <em>APIN</em>, <em>55</em>(12), 1-31. (<a href='https://doi.org/10.1007/s10489-025-06692-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in a generative neural network model extend the development of data augmentation methods. However, the augmentation methods based on the modern generative models fail to achieve notable improvement in class imbalance data compared to the conventional model, Synthetic Minority Oversampling Technique (SMOTE). We investigate the problem of the generative model for imbalanced classification and introduce a framework to enhance the SMOTE algorithm using Variational Autoencoders (VAE s). Our approach systematically quantifies the density of data points in a low-dimensional latent space using the VAE, simultaneously incorporating information on class labels and classification difficulty. Then, the data points potentially degrading the augmentation are systematically excluded, and the neighboring observations are directly augmented on the data space. Empirical studies on several imbalanced datasets represent that this simple process innovatively improves the conventional SMOTE algorithm over the deep learning models. Consequently, we conclude that the selection of minority data and the interpolation in the data space are beneficial for imbalanced classification problems with a relatively small number of data points.},
  archive      = {J_APIN},
  author       = {Hong, Sungchul and An, Seunghwan and Jeon, Jong-June},
  doi          = {10.1007/s10489-025-06692-y},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-31},
  shortjournal = {Appl. Intell.},
  title        = {Improving SMOTE via fusing conditional VAE for data-adaptive noise filtering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-adaptive data-driven evolutionary algorithm based on random forest feature selection and incremental gaussian process regression on personalized antidepressant medication research. <em>APIN</em>, <em>55</em>(12), 1-56. (<a href='https://doi.org/10.1007/s10489-025-06698-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the challenges of personalized depression treatment, such as individual differences, diverse medications, long treatment cycles, and adverse interactions. We proposed a self-adaptive data-driven evolutionary algorithm based on random forest feature selection and incremental Gaussian process regression (SADDEA-RFFS-IGPR). The algorithm integrates feature selection, surrogate modeling, and adaptive adjustment. We evaluated SADDEA-RFFS-IGPR on samples from three depression subtypes through model benchmark testing, comparison with same type algorithms, and ablation experiments. Results showed it achieved the best surrogate performance, an average ranking below 1.1 and statistically significant improvements (p-value < 0.05). Performance declined when any component was removed. In addition, analysis of variance (ANOVA) identified key factors. These findings confirmed the algorithm’s effectiveness, and potential in optimizing personalized treatment strategies.},
  archive      = {J_APIN},
  author       = {Zhao, Ruxin and Zhang, Hongtan and Liu, Chang and Xie, Yulin and Cao, Yue and Shi, Yang},
  doi          = {10.1007/s10489-025-06698-6},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-56},
  shortjournal = {Appl. Intell.},
  title        = {Self-adaptive data-driven evolutionary algorithm based on random forest feature selection and incremental gaussian process regression on personalized antidepressant medication research},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic brain effective connectivity network for identifying neurological disorders. <em>APIN</em>, <em>55</em>(12), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06700-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain dynamic Effective Connectivity (dEC) captures the time-varying causal interactions among the brain regions, offering valuable insights into neural mechanisms. However, prevailing methods primarily focus on static or temporally invariant Effective Connectivity (EC), leaving a significant knowledge gap regarding dEC’s dynamic aspect. Moreover, the current methods either require strong prior assumptions about underlying brain connectivity or rely on predefined thresholds when modeling the brain network. Herein, we propose a novel neural network-based Dynamic Brain Effective Connectivity Network (DB-ECN) approach that infers the EC at each time step, characterizing the temporal evolution of connectivity patterns in the brain. Notably, our method incorporates two key features: a second-order smoothing mechanism to suppress abrupt changes and a reasonable aggregation scheme to obtain an overall brain representation. Moreover, a new thresholding scheme is introduced to adaptively select the most reliable brain connections. Our method is highly interpretable, highlighting the transition from normal to abnormal brain connectivities and facilitating the identification of potential biomarkers. The experimental results on two large-scale public datasets demonstrate that DB-ECN is superior to other state-of-the-art methods in learning the network structure and distinguishing abnormal from normal patterns of brain activities. Our proposed methodology offers promising insights into brain dynamics and disorder diagnosis, paving the way for advancements in neuroscience research and clinical applications.},
  archive      = {J_APIN},
  author       = {Mamoon, Saqib and Xia, Zhengwang and Alfakih, Amani and Lu, Jianfeng},
  doi          = {10.1007/s10489-025-06700-1},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Dynamic brain effective connectivity network for identifying neurological disorders},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep multi-scale multi-head attention network for aero-engine remaining useful life prediction. <em>APIN</em>, <em>55</em>(12), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06705-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An aero-engine serves as the “heart” of an aircraft, playing a pivotal role in its operation and performance. The primary research area in aero-engine prognostics and health management is the prediction of remaining useful life (RUL), a crucial aspect of aircraft navigation safety. This research proposes a deep multi-scale multi-head attention network (DMMAN) to predict aero-engine RUL. Firstly, a multiscale feature extraction module is designed by adopting convolution kernels of different sizes, which allows the network to focus on both global and local degradation information at the same time. Then, a feature enhancement module is proposed using a multi-head attention strategy, which amplifies the significance of pivotal features while mitigating the influence of superfluous ones. Finally, a bidirectional gate recurrent unit-based feature fusion module is constructed for feature fusion, which can consider both historical and future information. To verify the performance of the network, an extensively used dataset is employed for experimentation. The experimental results conclusively demonstrate the superior performance of DMMAN compared to contemporary state-of-the-art (SOTA) methods for RUL prediction.},
  archive      = {J_APIN},
  author       = {Xie, Lianbing and Jiang, Hongkai and Dong, Yutong and Liu, Yunpeng},
  doi          = {10.1007/s10489-025-06705-w},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Deep multi-scale multi-head attention network for aero-engine remaining useful life prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-step spatio-temporal passenger flow prediction based on a dual-layer convolutional long short-term memory model with residual correction. <em>APIN</em>, <em>55</em>(12), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06716-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mismatch between the supply and demand in the ride-hailing market often results in operational inefficiencies, such as low vehicle occupancy rates and prolonged passenger waiting times. This paper proposes a novel multi-step spatio-temporal prediction model, termed the ConvLSTM + model, which integrates a convolutional long short-term memory (ConvLSTM) network within a dual-layer architecture enhanced by a residual correction mechanism. The proposed model is specifically designed to predict passenger pick-ups and drop-offs. Using taxi datasets from New York City, Chengdu, and Beijing, the experimental results demonstrate that the ConvLSTM + model significantly outperforms several widely used passenger flow prediction models in terms of multi-step prediction accuracy. This study not only provides valuable decision-making support for ride-hailing drivers but also offers actionable insights for improving service quality and operational efficiency within the ride-hailing market.},
  archive      = {J_APIN},
  author       = {Chen, Zhi-Wei and Jiang, Xiao-Lan and Tian, Li-Jun and Wu, Peng},
  doi          = {10.1007/s10489-025-06716-7},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Multi-step spatio-temporal passenger flow prediction based on a dual-layer convolutional long short-term memory model with residual correction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An open-set image classification algorithm based on hardness-aware angular margin loss and label noise filtering. <em>APIN</em>, <em>55</em>(12), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06718-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning discriminative features is crucial for deep learning-based image classification, particularly in open-set scenarios. Current methods often aim to achieve this by increasing inter-class decision boundaries and compressing intra-class feature distances through the addition of a fixed margin to all samples. However, assigning the same margin to all samples disregards the varying learning difficulties among different samples. Moreover, label noise is almost unavoidable in large-scale classification datasets. To address these issues, we devise a novel loss function that adaptively adjusts the angular margin based on the difficulty of each sample. Specifically, this paper proposes a quantification function that helps the model identify sample difficulty during training and adaptively adjusts the angular margin for different samples based on these quantification results. Additionally, we propose an automatic detection method for anomalous labels during training, leveraging the Laplace kernel function, which significantly enhances model performance in the presence of noisy label data. To verify the effectiveness of the proposed method, we conduct several experiments using face recognition tasks and typical open-set image recognition as case studies, demonstrating that our method outperforms the state-of-the-art approaches. The source code is available at: https://github.com/TCCofWANG/Hardness-Aware-Angular-Margin-Loss .},
  archive      = {J_APIN},
  author       = {Cao, Jinpeng and Wang, Hao and Zhang, Wei and Ren, Shichao and Leung, Chi-Sing},
  doi          = {10.1007/s10489-025-06718-5},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {An open-set image classification algorithm based on hardness-aware angular margin loss and label noise filtering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overestimated stock market forecasts resulting from the one-time denoising. <em>APIN</em>, <em>55</em>(12), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06720-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate stock market forecasts are important for both investors and regulators. Prior research has argued the effectiveness of denoising-prediction models on stock market time series. However, the one-time denoising process may cause the in-sample series used for model training to be affected by the out-of-sample series, leading to overestimated accuracy. To test whether the denoising-prediction strategy contributes to improving stock market forecasts, this study introduces a sliding window to address the one-time denoising bias. The empirical mode decomposition (EMD) and variational mode decomposition (VMD) techniques are employed for denoising, and a non-iterative machine learning model, extreme learning machine (ELM), is employed as the predictor. Thus, a sliding denoising (SD)-EMD-ELM model and an SD-VMD-ELM model are developed. A comparison of the two models with individual and conventional denoising (D)-EMD-ELM and D-VMD-ELM models reveals that the superior performance of the denoising-prediction models is actually an overestimation due to the one-time denoising bias. This conclusion is corroborated by the technical implementation of the denoising process and the weak-form efficient market hypothesis.},
  archive      = {J_APIN},
  author       = {Xiong, Mengyuan and Xu, Kunliang and Yin, Jiayi and Wang, Weiqing},
  doi          = {10.1007/s10489-025-06720-x},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Overestimated stock market forecasts resulting from the one-time denoising},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FBP-diffusion: Diffusion model combining MobileViT and dynamic loss correction for facial beauty prediction. <em>APIN</em>, <em>55</em>(12), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06723-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial beauty prediction (FBP) is a frontier topic at the intersection of artificial intelligence and computational aesthetics, aiming to enable computers to autonomously predict or assess facial beauty. Currently, while FBP methods have achieved good results on well-processed datasets, they typically exhibit reduced prediction performance on datasets with more unavoidable noisy labels. Diffusion models (DMs) can denoise and reconstruct label encodings, capturing uncertainty in the prediction process through the randomness of their outputs. Therefore, we propose FBP-Diffusion, an improved diffusion model that integrates MobileViT and dynamic loss correction (DLC). Specifically, MobileViT, effective at modeling both detailed and global information, is employed as a conditional information encoder to produce preliminary predictions, which are then fed into the reverse process to guide label generation. DLC is introduced to enhance the model’s denoising capability and robustness, in which the cross-entropy loss is increased by the prediction probabilities of FBP-Diffusion obtained after the reverse process and probability transfer, and then dynamically integrated into the noise estimation loss. Experimental results on four representative facial beauty databases demonstrate that FBP-Diffusion outperforms both conventional DMs and FBP methods, particularly noting a 5.17% accuracy improvement on relatively noisy datasets over state-of-the-art FBP methods.},
  archive      = {J_APIN},
  author       = {Gan, Junying and Li, Huicong and Xie, Xiaoshan and Chen, Hantian and Zhuang, Zhenxin},
  doi          = {10.1007/s10489-025-06723-8},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {FBP-diffusion: Diffusion model combining MobileViT and dynamic loss correction for facial beauty prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple concepts and cross-attention based knowledge graph completion. <em>APIN</em>, <em>55</em>(12), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06727-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of the big data era, the rapid growth and diversity of information has led to the growing problem of incompleteness in knowledge graphs(KGs). Therefore, Knowledge Graph Completion (KGC) has garnered a focal point of recent research efforts. However, nowadays, most of the KGC uses the low-dimensional embedding of relations and entities to capture the interaction features, but most of the KGC techniques are difficult to capture the real interaction features between different entities and relations, and many hidden features are not captured. The present paper proposes a KGC based on cross-attention of multiple concepts with a view to capturing more hidden features. Specifically, multiple semantic feature representations are obtained by projecting the low-dimensional vectors of entities and relations. Then, each semantic feature is innovatively divided into multiple implicit features, which are more likely to capture hidden complex features. The cross-attention module employs sophisticated feature extraction to capture the interactions between features of entities and relations, as well as the internal hidden features of entities and relations, without compromising the complexity of the model. Extensive experimental results on multiple standard link prediction benchmark datasets demonstrate that the method proposed in this paper demonstrates competitive performance in comparison to other comparative methods. Our public implementation is available at github.com/xiaodong20182018/MRCCA2025.},
  archive      = {J_APIN},
  author       = {Cao, Sifan and Li, Xiaodong and Gong, Zhaozhe and Xiao, Fengjun and Chen, Jing and Yu, Zhengsheng},
  doi          = {10.1007/s10489-025-06727-4},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Multiple concepts and cross-attention based knowledge graph completion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human-object interaction detection based on adaptive contrastive learning and class-specific feature enhancement. <em>APIN</em>, <em>55</em>(12), 1-12. (<a href='https://doi.org/10.1007/s10489-025-06730-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The diversity and combinatorial complexity of real-world human-object interactions (HOI) make it impractical for any single dataset to encompass all variations. This requires models with robust zero-shot learning capabilities to infer unseen interactions. A novel approach for HOI detection is proposed, leveraging adaptive contrastive learning and class-specific feature enhancement. This method improves detection accuracy by assigning adaptive weights to challenging samples and incorporating additional human, object, and interaction-specific features. Adaptive contrastive learning computes dynamic weights based on the similarity between each HOI instance and its label, allowing the model to focus more on challenging and long-tail samples. Class-specific feature enhancement improves the matcher by separately calculating losses for humans, objects, and interactions. Experimental results on the HICO-DET and SWIG-HOI datasets demonstrate the effectiveness of the proposed method in detecting seen and unseen interactions. The code is available at https://github.com/small-code-cat/ACL-CFE (Adaptive Contrastive Learning-Class-specific Feature Enhancement).},
  archive      = {J_APIN},
  author       = {Peng, Huanchun and Xue, Kejun and Wang, Xincheng and Gao, Yongbin and Fang, Zhijun and Jiang, Xiaoyan and Yu, Wenjun and Wu, Chenmou},
  doi          = {10.1007/s10489-025-06730-9},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {Human-object interaction detection based on adaptive contrastive learning and class-specific feature enhancement},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NLPA-AD: Normal label propagation algorithm for zero-shot texture anomaly detection. <em>APIN</em>, <em>55</em>(12), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06733-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces the Normal Label Propagation Algorithm for zero-shot Anomaly Detection (NLPA-AD), a novel approach for anomaly detection in texture-based images without prior training. NLPA-AD mimics human perception by leveraging texture homogeneity to define regions of normality and establish a conceptual understanding of normalcy. The core of NLPA-AD involves a single-label-propagation mechanism that identifies normal areas within the image. This mechanism effectively prevents the propagation of normal labels into anomalous regions by introducing non-propagable points. The identified normal regions are then utilized to construct a normal feature gallery, which serves as a reference for subsequent anomaly detection tasks. To enhance NLPA-AD’s performance, we propose two complementary strategies: Padding and Filtering (P&F) and Dynamic Threshold Matrix Adjustments (DTMA). These strategies address the challenges posed by anomalies that often occur around the periphery of the similarity matrix, effectively mitigating their impact on the overall detection accuracy. Experimental results on the MVTec-AD and DAGM-2007 datasets demonstrate the superiority of NLPA-AD in a zero-shot setting. Specifically, NLPA-AD achieves impressive performance metrics, including 99.7% image-level AUROC and 98.98% image-level F1-max on five textures from the MVTec-AD dataset, and 99.91% image-level AUROC and 98.77% image-level F1-max on nine textures from the DAGM-2007 dataset. These results highlight the effectiveness of NLPA-AD in addressing the challenge of zero-shot anomaly recognition and localization in texture images.},
  archive      = {J_APIN},
  author       = {Zhang, Jiajun and Song, Yanzhi and Yang, Zhouwang and Wang, Chencheng},
  doi          = {10.1007/s10489-025-06733-6},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {NLPA-AD: Normal label propagation algorithm for zero-shot texture anomaly detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trans embedded encoding volume for stereo matching. <em>APIN</em>, <em>55</em>(12), 1-12. (<a href='https://doi.org/10.1007/s10489-025-06736-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of obtaining a disparity map from a pair of images is called stereo matching, which is a key technology in fields such as autonomous driving and augmented reality. However, few methods consider the problem of large errors in disparity maps caused by scene depth, and mis-matching and discontinuity in disparity are more likely to occur in areas of scene depth. Therefore, this paper designs a stereo matching network based on Transmission Embedding Encoding Volume (TEEV), aiming to emphasize the role of potential depth information. The main content includes constructing a TEEV that emphasizes the role of potential depth information, while making the network pay more attention to information from deeper areas. In addition, this paper have designed a sub-pixel optimization module that can further optimize disparities within the range of (-1, 1). On the Sceneflow dataset, the average endpoint error (EPE) reached 0.42, and TEEV also achieved state-of-the-art (SOTA) results on the KITTI2012 and KITTI2015 datasets. Furthermore, in the generalization performance test of Middlebury 2014, the 2-pixel error rate was only 6.62.},
  archive      = {J_APIN},
  author       = {Zhao, Xiaoyang and Wang, Zhuo and Deng, Zhongchao and Qin, Hongde and Zhu, Zhongben},
  doi          = {10.1007/s10489-025-06736-3},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {Trans embedded encoding volume for stereo matching},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-variational autoencoder for estimating individual treatment effect using causal inference framework. <em>APIN</em>, <em>55</em>(12), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06738-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal inference serves as a critical framework in diverse domains, including healthcare, economics, and the social sciences. Within this context, data-driven machine learning models have gained prominence for estimating individual treatment effects (ITEs). Recently, the Causal Effect Variational Autoencoder (CEVAE) was proposed to infer ITEs from observational data with unobserved confounders. However, CEVAE faces limitations in certain scenarios for instance, it struggles to accurately infer latent confounders in high-dimensional data, leading to biased causal effect estimates. To address these challenges, we introduce the Transformer Causal Effect Variational Autoencoder (TCE-VAE), a novel architecture that integrates transformer-based encoder-decoders with variational autoencoders. The core innovation of TCE-VAE lies in its use of a self-attention mechanism to directly estimate causal effects by capturing complex dependencies and interactions within the data. This approach enhances robustness in learning latent confounders, particularly in high-dimensional settings. We evaluate TCE-VAE on the Infant Health and Development Program (IHDP) dataset. Experimental results demonstrate that the proposed approach outperforms popular state-of-the-art models in terms of average treatment effect estimation. Furthermore, our method exhibits superior precision and robustness in individual treatment effect estimation compared to existing approaches.},
  archive      = {J_APIN},
  author       = {Ahmad, Sohail and Wang, Hong},
  doi          = {10.1007/s10489-025-06738-1},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Transformer-variational autoencoder for estimating individual treatment effect using causal inference framework},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models for predicting perioperative sepsis. <em>APIN</em>, <em>55</em>(12), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06741-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sepsis is a common critical illness in intensive care medicine, affecting millions of patients globally each year. It has a high mortality rate and is one of the leading causes of death in intensive care units (ICUs). Despite significant advancements in sepsis research through artificial intelligence technologies in recent years that have reduced mortality rates, the current mortality rate in patients with sepsis remains as high as 25%. Additionally, existing prediction models suffer from a lack of transparency (the so-called “black box effect”) and fail to fully capture the complexity of perioperative data, limiting the trust that medical professionals and patients have in their predictive outcomes. This study leverages the unique capabilities of large language models to characterize perioperative sepsis monitoring data. Through representation learning, it transforms sequential patient monitoring data into textual and visual formats, thereby developing a specialized, interpretable predictive diagnostic model dedicated to sepsis treatment. This model aims to enhance the robustness and interpretability of sepsis treatment models, thereby standardizing the diagnosis and treatment processes for sepsis, reducing mortality rates, and improving patient outcomes. This study provides novel insights into the application of large language models in the medical perioperative field, offering significant scientific relevance for advancing medical artificial intelligence. It promises substantial progress in the field of critical-care medicine by enhancing the accuracy and credibility of sepsis diagnosis and treatment.},
  archive      = {J_APIN},
  author       = {Chen, Yuwen and Zhang, Lijun and Liu, Jiang and Yi, Bin},
  doi          = {10.1007/s10489-025-06741-6},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Large language models for predicting perioperative sepsis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic preventive maintenance strategy for a heterogeneous multi-unit redundant system: A deep reinforcement learning approach with weighted network estimator. <em>APIN</em>, <em>55</em>(12), 1-41. (<a href='https://doi.org/10.1007/s10489-025-06744-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A redundant structure is often utilized to enhance the reliability of the long-run system, whereas the establishment of an appropriate maintenance decision framework will be conducive to achieving the long-term interests of the system. Thus, this paper develops a full-new maintenance decision framework for the multi-unit redundant system by integrating a customized deep reinforcement learning approach, and the deterioration process of each unit is delineated through a Wiener process with a drift model. Meanwhile, an agent is constructed to facilitate the maintenance decision process. Specifically, there are several important improvements: (i) An integrated dynamic maintenance decision framework is established for the multi-unit heterogeneous k-out-of-n: G systems by efficiently integrating multiple modules: the parameters estimation module, the environment model, and the DRL agent. (ii) A weighted double Q network estimator approach is employed to enhance the training performance, where the network estimator is designed as the weighted combination result of the online and target networks. (iii) An averaged approach of the target Q value is employed during the training process of the maintenance decision agent, which reutilizes the trained network parameters to achieve the average of the target Q value, thereby enhancing the training stability. In addition, a prioritized experience replay mechanism is incorporated into the integrated maintenance decision framework, which can further facilitate the training process by prioritizing learning some more valuable samples. Numerical experiments and comparison studies with practical deterioration datasets are conducted to verify the effectiveness and the results indicate a good performance for the presented approach.},
  archive      = {J_APIN},
  author       = {Xu, Deming and Wang, Yan and Liu, Xiang and Ma, Hao and Ji, Zhicheng},
  doi          = {10.1007/s10489-025-06744-3},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-41},
  shortjournal = {Appl. Intell.},
  title        = {Dynamic preventive maintenance strategy for a heterogeneous multi-unit redundant system: A deep reinforcement learning approach with weighted network estimator},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive structure graph embedding for unsupervised feature extraction. <em>APIN</em>, <em>55</em>(12), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06746-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature extraction (UFE) has attracted increasing attention in machine learning, data mining and pattern recognition, as it effectively uncovers the intrinsic low-dimensional structure of high-dimensional data. However, most existing UFE methods focus on either global structures or local structures, with few algorithms successfully balancing the two. In real-world applications, data frequently exhibit complex structures and noise, so learning models that rely solely on a single structure of data can easily lead to overfitting or introducing unnecessary biases, which greatly limits their applications. To address the issues, we propose a novel UFE method, called Adaptive Structure Graph Embedding (ASGE). ASGE jointly captures global and local structures by integrating distance constraints into low-rank representation learning. Specifically, it employs an $$\ell _2$$ Frobenius norm regularizer to model global correlations and an $$\ell _1$$ norm regularizer to enhance robustness against noise and outliers. In addition, ASGE imposes the nonnegative constraint on the representation to make the learned graph interpretable and reveal the intrinsic structure of the data. The experimental results on real-world datasets show that ASGE outperforms other state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Chen, Qiqi and Yin, Xuesong and Ding, Jianhao and Huang, Qi and Shu, Ting and Wang, Yigang},
  doi          = {10.1007/s10489-025-06746-1},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive structure graph embedding for unsupervised feature extraction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STFRCN: Spatial-temporal fusion residual convolutional network for traffic flow prediction. <em>APIN</em>, <em>55</em>(12), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06748-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction is essential for optimizing traffic management departments’ decision-making and improving road utilization efficiency. Previously, models focused on improving accuracy but demanded significant resources for large-scale node prediction, constraining their real-time applicability. To achieve an equilibrium between prediction accuracy and hardware resource consumption, we propose a Spatial-Temporal Fusion Residual Convolutional Network (STFRCN) for traffic flow prediction. STFRCN consists of a data embedding layer, a time fusion gated tanh unit (TF-GTU), a residual interactive convolution block (RICB), and an output layer. The data embedding layer consolidates diverse features along the time dimension, and then the TF-GTU further fuses and filters these features, thus effectively extracting spatial-temporal dependencies via the RICB. STFRCN is predominantly composed of convolution, thereby endowing the model with reduced computational costs. It sustains the model’s accuracy in predicting large-scale nodes while retaining high temporal efficiency. This lightweight convolution-based design bequeaths the model with diminished hardware resource consumption and affords it a broader application scope. Experiments are conducted on four real-world traffic flow datasets to validate the superiority of our model in large-scale node prediction. The effectiveness of each module is validated through ablation experiments. Ultimately, STFRCN achieves the highest prediction accuracy on the PEMS07 dataset, which has the largest number of nodes, while consuming less than 10% of the memory resources required by the most accurate baseline model.},
  archive      = {J_APIN},
  author       = {Chen, Ye and Yin, Xiang and Yu, Junyang and Liang, Xiaoli and Chen, Lei},
  doi          = {10.1007/s10489-025-06748-z},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {STFRCN: Spatial-temporal fusion residual convolutional network for traffic flow prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving retail sales through unsupervised collective-contextual anomaly detection: A deep reconstruction autoencoder for network-wide sales analysis. <em>APIN</em>, <em>55</em>(12), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06749-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vast sales data in the retail sector present opportunities to optimize operations and increase revenue. Consequently, studies have leveraged these data to predict sales, detect anomalies, segment customers, and similar. Anomaly detection techniques have been proposed to identify deviations in sales patterns at both the product and product-store levels. However, these studies focus on a single store or a few stores without considering sales patterns across similar stores, which could greatly benefit retailers. For instance, if a store outperforms similar stores in sales of a specific product, best practices could be established and shared throughout the retail network, ultimately increasing overall sales. Nevertheless, cross-store anomaly detection is challenging due to contextual differences among stores, diversity of sales patterns, and the variety of products. Consequently, this paper proposes an unsupervised collective-contextual anomaly detection framework for the identification of outperforming stores in massive sales data from a large retail network. In contrast to other studies, which consider intra-store patterns, we integrate intra- and inter-store anomaly detection. The proposed approach addresses the gap by decoupling the problem into two components. Collective anomalies are detected by leveraging a deep-vanilla autoencoder to identify patterns that deviate from normal behavior. Then, contextual anomaly detection leverages the designed product-level similarity metric, to identify similar stores and examine patterns among them. Experiments using a dataset from a major Canadian retailer demonstrate the success of the proposed approach, achieving 90% overall precision, with collective anomaly detection outperforming other conventional approaches by achieving 85% precision, 72% recall, and 79% F1-score.},
  archive      = {J_APIN},
  author       = {Fonseka, Tehara and Tulenkov, Anton and Grolinger, Katarina},
  doi          = {10.1007/s10489-025-06749-y},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Improving retail sales through unsupervised collective-contextual anomaly detection: A deep reconstruction autoencoder for network-wide sales analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive variable-length subsequence pattern extraction in time series. <em>APIN</em>, <em>55</em>(12), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06752-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One challenge of time series data mining is discovering diverse patterns of unknown and varying lengths in time series. To that end, we propose a flexible subsequence clustering framework to determine the appropriate subsequence lengths and segmentation positions adaptively, thereby extracting subsequence patterns of different unknown lengths and representations. In our clustering framework, we propose a subsequence similarity metric to minimize subsequence intra-cluster error while tending to minimize subsequence segmentation numbers. In addition, we also incorporate prior knowledge into our model framework naturally for practical use. Finally, a novel algorithm is adopted to optimize our model. Compared with the SOTA methods, our method achieves an accuracy of 100% in synthetic dataset and 98.37% in real dataset, which largely outperforms other methods. Quantitative and qualitative comparisons in various datasets demonstrate the effectiveness of our method for unknown variable length subsequence clustering.},
  archive      = {J_APIN},
  author       = {Zhang, Ke and Duan, Jiangyong and Yang, Tiantian and Guo, Lili and Lv, Congmin},
  doi          = {10.1007/s10489-025-06752-3},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive variable-length subsequence pattern extraction in time series},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal parameter-efficient fine-tuning via graph neural network. <em>APIN</em>, <em>55</em>(12), 1-12. (<a href='https://doi.org/10.1007/s10489-025-06754-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of the era of foundation models, pre-training and fine-tuning have become common paradigms. Recently, parameter-efficient fine-tuning (PEFT) has garnered widespread attention due to its better balance between the number of learnable parameters and performance. However, existing PEFT methods primarily focus on single-modal modeling, which limits their ability to leverage cross-modal complementary information, resulting in weaker generalization capabilities. Additionally, these methods often fail to effectively utilize structural knowledge in downstream tasks, a limitation that becomes particularly pronounced in scenarios requiring cross-modal interaction and hierarchical relationship modeling. To address this issue, this paper proposes a multi-modal parameter-efficient fine-tuning method based on graph networks, GA-Net. Each image is fed into a multi-modal large language model (MLLM) to generate a text description. The image and its corresponding text description are then encoded separately using frozen image and text encoders to extract visual and textual features. These features are fused through a cross-attention mechanism to form multi-modal features. A graph is constructed based on the cosine similarity of multi-modal feature nodes, and knowledge and associations between features are mined from each node of the graph. Furthermore, we innovatively introduce a multi-modal Elastic Weight Consolidation (EWC) regularization term into the loss function to mitigate catastrophic forgetting during task learning. Experimental results demonstrate that GA-Net achieves significant improvements over state-of-the-art (SOTA) methods, with test accuracy improvements of 5.32%, 3.05%, and 1.09% on the OxfordPets, Flowers102, and Food101 datasets, respectively.},
  archive      = {J_APIN},
  author       = {Cheng, Bin and Lu, Jiaxuan},
  doi          = {10.1007/s10489-025-06754-1},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {Multi-modal parameter-efficient fine-tuning via graph neural network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast micro-expression recognition method based on bi-directional optical flow. <em>APIN</em>, <em>55</em>(12), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06722-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro-expressions contain rich emotional and cognitive information, and can serve as important indicators of mental status. Systematic observation and precise recognition of facial micro-expressions in the elderly can provide critical and valuable clues for early diagnosis of dementia, dynamic monitoring of the disease, and evaluation of treatment effects. However, the micro-expression motion intensity is weak, and the traditional optical flow-based micro-expression recognition method is prone to extracting erroneous optical flow information, which affects the recognition accuracy of the system. This paper proposes a Bi-directional Optical flow-based Fast Micro-expression recognition method (BOFM), which employs forward and reverse bi-directional optical flow to capture facial movements and accurately recognize micro-expressions. Additionally, it introduces a keyframe extraction method that utilizes the variation effect of the optical flow field to eliminate unnecessary frames in video clips and enhance the real-time performance of the system. This method has been validated using public datasets such as SMIC and CASME. The verification results demonstrate that this method achieves approximately a 9.3% higher accuracy compared to the Sparse MDMO (Main Directional Mean Optical-flow) algorithm. Notably, the proposed algorithm showcases a significant running time reduction of approximately 36.5% when compared to the micro-expression recognition algorithm based on FlowNet2. These findings clearly indicate that the proposed algorithm possesses excellent capabilities in recognizing micro-expressions. This establishes a basis for future investigations into the connection between facial micro-expression patterns and early-stage Alzheimer’s disease, playing a crucial role in its early detection and prevention.},
  archive      = {J_APIN},
  author       = {Zhang, Yukun and Fei, Zixiang and Zhou, Wenju and Fei, Minrui},
  doi          = {10.1007/s10489-025-06722-9},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Fast micro-expression recognition method based on bi-directional optical flow},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive copy move forgery detection based on new keypoint feature and matching. <em>APIN</em>, <em>55</em>(12), 1-24. (<a href='https://doi.org/10.1007/s10489-025-06735-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Copy-move forgery, where an image region is copied into another part of the same image, is one of the most common and easy-to-implement image tampering techniques. Keypoint (also called feature point)-based detection methods exhibit remarkable performance in terms of computational cost and robustness. However, these methods have the following limitations to varying degrees: 1) Failure to extract keypoints from small or smooth regions; 2) Lack of robust and discriminative descriptors for keypoints; 3) Low accuracy and excessive computational cost of keypoints matching; 4) High false negative/positive rate caused by the defects of post processing. To overcome such limitations, we propose an adaptive copy move forgery detection based on new keypoint feature and matching in this paper. Firstly, based on the simple linear iterative clustering (SLIC) and the multi-directional multi-layer double-cross pattern (MDML-DCP), i.e., the segmentation method is adopted, and uniform key points are adaptively extracted from the whole image (including small and smooth regions) by fitting the MDML-DCP value-threshold function of superpixels. Then, due to the strong robustness of moment features to attacks and their stronger descriptive ability compared to traditional invariant moments. Secondly, texture features can get more distinctive features. Next, accurate quaternion fractional pseudo-Jacobi-Fourier moments (AQFPJFM) and gradient local ternary patterns (GLTP) describe the key points to obtain robust and discriminative features. Then, the ITQ-PTH algorithm is introduced for keypoint matching, which is more accurate than traditional locality-sensitive hashing algorithms and can improve the matching accuracy. Finally, the false negative rate and false positive rate are reduced by reliable post-processing methods. Experimental results show that the proposed method achieves an F-score of 96.61% and 95.18% on GRIP and MICC-F600 datasets, respectively, which is 2.71 and 3.07 percentage points higher than the latest method, and the accuracy is also higher.},
  archive      = {J_APIN},
  author       = {Wang, Xiangyang and Zhang, Huiying and Wang, Dawei and Niu, Panpan},
  doi          = {10.1007/s10489-025-06735-4},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive copy move forgery detection based on new keypoint feature and matching},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convolutional attention-based contrastive learning for partial label learning. <em>APIN</em>, <em>55</em>(12), 1-12. (<a href='https://doi.org/10.1007/s10489-025-06757-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Annotated data often includes ambiguous labels, posing a partial label learning (PLL) challenge. PLL aims to classify instances that have multiple potential labels but only one correct label. While recent studies have shown that contrastive learning methods are effective for learning image features, significant obstacles remain when applying these methods to PLL. In this work, we introduce contrastive learning for PLL and propose a convolutional attention contrastive learning for PLL (CACL-PLL) framework, designed to learn category-specific prototypes that represent category labels and assist in label disambiguation. Specifically, we incorporate a combination of strong and weak augmentation, and in the encoder component, we propose a convolutional attention encoder alongside a convolutional attention momentum encoder. The encoded features are then passed to the proposed convolutional attention projection head and a fully convolutional network classifier. Additionally, we introduce a new label disambiguation strategy, which involves updating a label confidence matrix and a label correction matrix, where the update of the label correction matrix is guided by the category prototype. Finally, we design a novel loss function that assigns weights to the classification loss of two strongly enhanced samples, working alongside the contrastive loss function to supervise model training. Extensive experiments demonstrate the effectiveness and superior performance of CACL-PLL in PLL.},
  archive      = {J_APIN},
  author       = {Gong, Bo and Zhou, Ruojin and Jing, Ling},
  doi          = {10.1007/s10489-025-06757-y},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {Convolutional attention-based contrastive learning for partial label learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Short-term traffic flow prediction model based on multi-attributes. <em>APIN</em>, <em>55</em>(12), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06760-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and real-time short-term urban traffic flow prediction is vital for traffic planning and resident commuting. To explore the complex internal and external attributes of traffic flow and establish their dependencies, this paper proposes a multi-attribute-based short-term traffic flow prediction mode. First, considering the heterogeneity of connection strengths between adjacent nodes in a road network, a node influence assessment method based on network representation learning (SDNE) is introduced to depict these connections. Second, addressing the complex spatio-temporal correlations of traffic flow, a spatio-temporal feature mining component based on node connection strength is constructed. It combines graph convolutional neural networks, which uncover hidden spatial relationships in road networks, with dilated causal convolutional neural networks, capturing long-term sequential dependencies. Finally, considering the significant impact of external attributes on traffic flow, a NCSMGCN model is proposed, leveraging multi-head attention mechanisms for efficient integration of spatio-temporal and external attribute features, further improving prediction accuracy. Experimental results show that the proposed model effectively mines the complex internal and external attributes and their dependencies, improving traffic flow prediction accuracy.},
  archive      = {J_APIN},
  author       = {Jia, Chaolong and Huang, Siyan and Peng, Gang and Jiang, Fu and Huang, Zigao and Wang, Rong and Xiao, Yunpeng},
  doi          = {10.1007/s10489-025-06760-3},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Short-term traffic flow prediction model based on multi-attributes},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint spatial-frequency deepfake detection network based on dual-domain attention-enhanced deformable convolution. <em>APIN</em>, <em>55</em>(12), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06761-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel Spatio-Frequency Deepfake Detection Network based on Dual-Domain Attention and Deformable Convolution (HFDCDNet). The core of the network is the HFDCD module, which simultaneously extracts spatial domain features and high-frequency information from the input feature maps. These two types of features are then fused using a specially designed bidirectional cross-attention mechanism. Specifically, the spatial features are extracted using a Deformable Convolution and Dual Attention-based module (DCD), which leverages deformable convolutions (DCN) and a spatial-channel attention mechanism to capture more comprehensive spatial representations. Meanwhile, high-frequency features are extracted using the High-Frequency Extraction (HFE) module, which learns frequency domain representations through high-pass filtering and frequency-aware convolutional learning. The bidirectional cross-attention mechanism facilitates complementary fusion and mutual enhancement of spatial and frequency features, enabling more fine-grained and holistic feature learning and improving detection performance. To evaluate the effectiveness of the proposed HFDCDNet, extensive experiments were conducted on two widely used public datasets: FaceForensics++ and Celeb-DF (V2). The results demonstrate that HFDCDNet achieves an accuracy (ACC) of 98.31% and an area under the curve (AUC) of 99.51% on the FaceForensics++ dataset, and 98.29% ACC and 99.13% AUC on the Celeb-DF (V2) dataset, outperforming many state-of-the-art methods. These results confirm that the proposed DCD module significantly enhances the model’s ability to detect manipulated facial content.},
  archive      = {J_APIN},
  author       = {Qiusong, Lan and Chengfu, Yang and Qinhua, A and Jianlong, Zhao and Jin, Li},
  doi          = {10.1007/s10489-025-06761-2},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Joint spatial-frequency deepfake detection network based on dual-domain attention-enhanced deformable convolution},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-dimensional feature driven GPU usage prediction model based on task and system environment classification. <em>APIN</em>, <em>55</em>(12), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06763-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of cloud computing and AI technologies, accurate GPU usage prediction has become crucial for resource scheduling in data centers. This paper proposes a Multi-dimensional feature driven GPU usage prediction model based on task and system environment classification that classifies tasks based on their GPU requirements before applying specialized prediction algorithms. We introduce two innovative sub-models: a Transformer model based on dynamic gating mechanism and cross-layer attention head fusion (DGCLA-Transformer) for non-expanding GPU tasks and a neural network model with linear integration of multiple decision trees for expanding scenarios. Experimental results demonstrate remarkable performance, achieving 91% classification accuracy, the RMSE of prediction performance without the need to expand GPU resources is not greater than 0.074; the RMSE of prediction performance is not greater than 0.24 when GPU resources need to be expanded. This work provides a new paradigm for GPU resource management by shifting focus from time-series to task-environment characteristics. The detailed code address of the method is https://github.com/zsdnr/GPU_prediction .},
  archive      = {J_APIN},
  author       = {Xu, Chunhui},
  doi          = {10.1007/s10489-025-06763-0},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Multi-dimensional feature driven GPU usage prediction model based on task and system environment classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TransSSVs: A transformer-based deep learning model for accurate detection of somatic small variants in paired tumor and normal sequencing data. <em>APIN</em>, <em>55</em>(12), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06607-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of somatic small variants in tumors plays a crucial role in cancer diagnosis. Various somatic mutation callers have been developed; however, existing methods face limitations in modeling mapping information of flanking genomic sites (genomic sites adjacent to a somatic site) that influence the state of the somatic site. Additionally, they are unable to analyze inter-site interactions within the context sequence centered around a somatic site or appropriately weigh the effects of flanking genomic sites on the somatic site. To address these limitations, the Transformer model is utilized to develop TransSSVs for detecting somatic small variants. The core functionality of TransSSVs relies on the multi-head attention mechanism, which generates a reliable representation of interactions between a candidate somatic site and its flanking genomic sites within the context sequence. TransSSVs effectively extract mapping features of various genomic sites in the context sequence to enhance prediction accuracy. Benchmarking experiments demonstrate that TransSSVs exhibit robust performance when compared with state-of-the-art methods on well-characterized real and simulated tumor datasets. Furthermore, the contributions of flanking genomic sites to the detection of somatic sites are assessed, and attention weight patterns for positive and negative somatic sites are analyzed.},
  archive      = {J_APIN},
  author       = {Meng, Jing and Wang, Jiangyuan and Liu, Jingze and Song, Wenkai and Li, Ming and Wu, Aiping and Jiang, Taijiao},
  doi          = {10.1007/s10489-025-06607-x},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {TransSSVs: A transformer-based deep learning model for accurate detection of somatic small variants in paired tumor and normal sequencing data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic image segmentation via dynamic curriculum learning. <em>APIN</em>, <em>55</em>(12), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06616-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manually annotating pixel-level labels for large-scale data in semantic segmentation tasks is not only time-consuming and laborious but also challenging to ensure consistent annotation quality. In this paper, we present a simple yet effective semantic segmentation framework, named Dynamic Curriculum Learning (DCL), to progressively learn the segmentation knowledge by harnessing synthetic and unlabeled images. Initially, a data generation strategy is proposed to generate large-scale synthetic images with pixel-level labels automatically. Subsequent iterations involve a dual optimization process wherein the model is refined using both the synthetic images with their inherent pixel-level labels and the target images augmented with the generated pseudo labels. After the training of each round, DCL dynamically revises the training dataset and the pseudo labels for the target domain through a tripartite strategy encompassing Image-level Sample Selection (ISS), image augmentation, and Conditional Random Fields (CRF) post-processing. Without using any labels (i.e., image-level labels, bounding-box labels, and pixel-level labels) of target data, our model yields state-of-the-art performance than most existing semi-supervised and synthetic image approaches.},
  archive      = {J_APIN},
  author       = {Zhang, Xiang and Zhao, Wanqing and Wang, Chenji and Luo, Hangzai and Zhong, Sheng and Tang, Lei and Peng, Jinye and Fan, Jianping},
  doi          = {10.1007/s10489-025-06616-w},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Semantic image segmentation via dynamic curriculum learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view fusion neural networks for heterogeneous graph representation learning. <em>APIN</em>, <em>55</em>(12), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06657-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous graphs can represent complex relationships in the real world through multiple types of nodes and connecting edges. The goal of heterogeneous graph representation learning is to embed the structural and semantic information of the target nodes into a low-dimensional vector representation, which can facilitate the analysis of downstream tasks (i.e., node classification, and node clustering). However, the majority of existing methods for learning heterogeneous graph representations focus primarily on single-view information, overlooking the multiview properties inherent in such graphs. To address these limitations, we propose multiview fusion neural networks (MVF-NNs) for heterogeneous graph representation learning. This model can be divided into two parts: a multiview feature extraction module and a multiview fusion module. The multiview feature extraction module learns representations from three views: a feature view, a metapath view, and a structure view. The multiview fusion module fuses representations of these views by using an attention mechanism, multihead self-attention, with an MLP and pairwise combinations to achieve the final weighted aggregation. To validate the practical effectiveness of the proposed method, we conduct node classification and clustering experiments on four real-world datasets. The results demonstrate average improvements of approximately 2% in both tasks compared to state-of-the-art models. The practical benefits of these improvements translated into real-world applications are manifested in the form of improved effectiveness of recommender systems and improved accuracy of social network analysis.},
  archive      = {J_APIN},
  author       = {Shi, Zhenquan and Wang, Bowen and Huang, Jiashuang},
  doi          = {10.1007/s10489-025-06657-1},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Multi-view fusion neural networks for heterogeneous graph representation learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated machine learning for positive-unlabelled learning. <em>APIN</em>, <em>55</em>(12), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06706-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Positive-Unlabelled (PU) learning is a field of machine learning that aims to learn classifiers from data consisting of labelled positive and unlabelled instances, which can be in reality positive or negative, but whose label is unknown. Many PU learning methods have been proposed over the last two decades, so many so that selecting an optimal method for a given PU learning task presents a challenge. Our previous work has addressed this by proposing GA-Auto-PU, the first Automated Machine Learning (Auto-ML) system for PU learning. In this work, we propose two new PU learning Auto-ML systems: BO-Auto-PU, based on a Bayesian Optimisation (BO) approach, and EBO-Auto-PU, based on a novel evolutionary/BO approach. We present an extensive evaluation of the three Auto-ML systems, comparing them to each other and to well-established PU learning methods across 60 datasets (20 datasets, each with 3 versions). The results of the comparison show statistically significant improvements in predictive accuracy over the baseline methods, as well as large improvements in computational time for the newly proposed Auto-PU systems over the original Auto-PU system.},
  archive      = {J_APIN},
  author       = {Saunders, Jack D. and Freitas, Alex A.},
  doi          = {10.1007/s10489-025-06706-9},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Automated machine learning for positive-unlabelled learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extracting cross-modal semantic incongruity with attention for multimodal sarcasm detection. <em>APIN</em>, <em>55</em>(12), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06717-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An inherent incongruity between the literal interpretation and the intended connotation characterizes sarcasm. Though several studies have targeted text-based unimodal sarcasm detection, multimodal sarcasm detection is still an evolving discipline. Emerging forms of multimodal data, such as memes, demonstrate that studying textual data alone may be insufficient for sarcasm detection. Additional contextual information conveyed by images can completely alter the perceived connotation of the text, thus indicating a sarcastic sentiment only when the text and image are studied in combination. This study presents a novel framework for multimodal sarcasm detection that can process input triplets, i.e., the input text and its associated image, as provided in the datasets, and a supplementary modality introduced in the form of image captions. The visual semantic representation provided by image captions offers an additional opportunity to capture the textual and visual content discrepancies. The key components of the proposed model are: (1) a textual feature extraction branch that utilizes a cross-lingual language model; (2) a visual feature extraction branch that incorporates a self-regulated residual ConvNet integrated with a lightweight spatially aware attention module; (3) image captions generated using an encoder-decoder architecture capable of reading text embedded in images; (4) distinct attention modules to effectively identify the incongruities between the text and two levels of image representations; (5) multi-level cross-domain semantic incongruity representation achieved through feature fusion. Compared with cutting-edge baselines, the proposed model achieves the best accuracy of 92.89% and 64.48%, respectively, on the Twitter multimodal sarcasm and MultiBully datasets.},
  archive      = {J_APIN},
  author       = {Aggarwal, Sajal and Pandey, Ananya and Vishwakarma, Dinesh Kumar},
  doi          = {10.1007/s10489-025-06717-6},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Extracting cross-modal semantic incongruity with attention for multimodal sarcasm detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient high utility itemsets mining over data streams with compact utility list structure. <em>APIN</em>, <em>55</em>(12), 1-24. (<a href='https://doi.org/10.1007/s10489-025-06729-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing prevalence of real-time data in various application domains, data streams have become an important focus in the field of data mining. High utility itemset mining (HUIM) over data streams is particularly challenging, as it must ensure both efficiency and accuracy in a continuously evolving environment. To address these challenges, this paper proposes a novel algorithm named CHUPM-Stream, which leverages Compact Utility Lists (CU-lists) to mine high utility itemsets within a sliding window model. The algorithm effectively captures transaction utility information using the CU-list structure and employs a Duplicate Transaction Merge (DTM) strategy to compress redundant transactions, thereby reducing memory consumption. To avoid repeated scanning of the entire window, CHUPM-Stream further introduces a Transaction weighted utility Maintenance Strategy (TMS), which reuses TWU values from the previous window. Additionally, it applies the LA-prune strategy, taking advantage of CU-list characteristics to reduce the search space. Experimental results on dense datasets demonstrate that CHUPM-Stream achieves superior performance compared to state-of-the-art algorithms in terms of both runtime and memory usage.},
  archive      = {J_APIN},
  author       = {Li, Gufeng and Wang, Jialong and Fang, Weiyi and Xiang, Jiawei and Shang, Tao},
  doi          = {10.1007/s10489-025-06729-2},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {Efficient high utility itemsets mining over data streams with compact utility list structure},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HM-DRL: Enhancing multi-agent pathfinding with a heatmap-based heuristic for distributed deep reinforcement learning. <em>APIN</em>, <em>55</em>(12), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06747-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of mobile robots into industrial environments, particularly in warehouse logistics, has led to an increasing need for efficient Multi-Agent Pathfinding (MAPF) solutions. These solutions are crucial for coordinating large fleets of robots in complex operational settings, yet several existing methods struggle with scalability issues in densely populated environments. Additionally, many existing learning-based approaches are computationally expensive and require excessive training time. In this paper, we propose a Deep Reinforcement Learning (DRL)-based approach that exploits on the strengths of DRL and graph-convolutional communication to efficiently coordinate fleets of mobile robots with limited communication range in partially observable environments. We introduce a novel heatmap-based heuristic that reduces the observation space while retaining the critical information needed for effective path planning and conflict resolution. Additionally, we use optimized training objectives that allow agents to reduce the training time by as much as 3.4 times compared to state-of-the-art DRL-based methods. Our approach also employs curriculum learning and distributed training to improve efficiency. To further enhance performance, we introduce mechanisms for resolving conflicts in constrained scenarios, resulting in a higher success rate and overall operational efficiency. Finally, we validate our approach through extensive simulation-based experiments, showing that it outperforms the state-of-the-art DRL-based MAPF methods and that it scales effectively to larger maps and densely populated environments.},
  archive      = {J_APIN},
  author       = {Boumediene, Mouad and Maoudj, Abderraouf and Christensen, Anders Lyhne},
  doi          = {10.1007/s10489-025-06747-0},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {HM-DRL: Enhancing multi-agent pathfinding with a heatmap-based heuristic for distributed deep reinforcement learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing suspicious object detection in unconstrained environments using computer vision. <em>APIN</em>, <em>55</em>(12), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06753-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Security surveillance systems in unconstrained environments deter criminal activities and safeguard public safety by enabling real-time monitoring of threats. Such environments, including protests, riots, and crowded venues, are particularly vulnerable to security breaches. Fast and accurate detection of dangerous objects is crucial for preventing incidents and ensuring public safety, especially in highly challenging environments such as protests and riots, where factors like tear gas, water, fire, moving crowds, and occlusions hinder object detection. This research presents a comprehensive object detection framework tailored for identifying suspicious objects in public disorder scenarios using a one-stage object detection model for optimal speed and accuracy. A key contribution of this study is the development of a benchmark dataset designed to evaluate object detection algorithms in unconstrained environments. Eight You Only Look Once (YOLO) versions (v3–v10) were evaluated using this dataset, comprising five object classes: knives, swords, axes, stones, and sticks. YOLOv10 achieved the highest mean average precision (mAP) of 82.50%, followed by YOLOv4 (80.91%), YOLOv8 (80.60%), and YOLOv5 (71.78%). YOLOv3 recorded the lowest mAP at 65.88%. For detection speed, YOLOv10 achieved 30 FPS, followed by YOLOv9 and YOLOv8 (29 FPS each). Additionally, YOLOv10 outperformed all models in average precision (81.96%), recall (83.82%), and F1-score (82.48%) across all object classes. With its superior speed and accuracy, YOLOv10 is ideal for real-time security surveillance, while YOLOv4 and YOLOv8 remain suitable for accuracy-focused scenarios. Our study represents a major advancement in AI-driven public security surveillance, offering both an optimized detection framework and a benchmark dataset for object detection in unconstrained environments.},
  archive      = {J_APIN},
  author       = {Thiruthanigesan, Kanagasabai and Nawarathna, Ruwan D. and Ragel, Roshan G.},
  doi          = {10.1007/s10489-025-06753-2},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Advancing suspicious object detection in unconstrained environments using computer vision},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MTS-net: Research on multi-modal, multi-task, multi-stage tumor segmentation model for PET/CT. <em>APIN</em>, <em>55</em>(12), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06759-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, PET/CT imaging technology is widely used in clinical medicine, with one of the main research areas being the automatic segmentation of lesion tissues by combining data from PET/CT scans. However, accurately identifying lesion tissues in PET/CT images remains challenging due to complex tumor boundaries and internal heterogeneity. To address this, we propose MTS-Net, a multi-stage, multi-modal, and multi-task segmentation model. MTS-Net integrates four core components: a Detection Attention Module (DAM) for assisting tumor localization and reducing missed detections, a Deformable Convolution Residual Block (DRconv) to enhance the receptive field during the downsampling phase, a Cross-Fusion Attention Module (CFAM) for multi-scale feature fusion, and an Edge-aware Multi-scale Supervision Module (EAMSM) utilizing deep supervision to refine boundary segmentation. The model effectively combines object detection with segmentation, leveraging cross-modal information and deep edge supervision. Experimental results demonstrate that MTS-Net significantly outperforms existing medical segmentation methods, showing superior accuracy and robustness on the neuroblastoma and HECKTOR2021 datasets.},
  archive      = {J_APIN},
  author       = {Zheng, Yongwei and Sun, Zhanquan and Chen, Suyun and Fu, Hongliang and Wang, Chaoli and Zhu, Ji},
  doi          = {10.1007/s10489-025-06759-w},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {MTS-net: Research on multi-modal, multi-task, multi-stage tumor segmentation model for PET/CT},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting faults in diesel engines with kernel machines regression techniques. <em>APIN</em>, <em>55</em>(12), 1-12. (<a href='https://doi.org/10.1007/s10489-025-06643-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive maintenance has become a vital tool in minimizing expenses and operational setbacks while proactively averting potential failures. Its scope extends across various sectors, encompassing critical component upkeep crucial for ensuring public safety. Addressing the challenge of preempting catastrophic failures in diesel engines, this study uses a simulated dataset featuring 3500 realistic failure scenarios considering the engine cylinder, coupled with a crankshaft torsional vibration model. The research proposes employing artificial intelligence regression techniques, specifically support vector regression and Gaussian processes, to forecast diesel engine faults. This methodology is applied in conjunction with an engine simulator to evaluate its efficacy and precision. Notably, the Gaussian process regressor exhibits superior performance, achieving an RMSE value of 0.015 ± 0.001%.},
  archive      = {J_APIN},
  author       = {Viana, Denys P. and de S. S. Martins, Dionísio H. C. and Haddad, Diego B. and e Silva, Fabrício L. and Pinto, Milena F. and Gutiérrez, Ricardo H. R. and Monteiro, Ulisses A. and Vaz, Luiz and Prego, Thiago de M. and Andrade, Fabio A. A. and Tarrataca, Luís and de Lima, Amaro A.},
  doi          = {10.1007/s10489-025-06643-7},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {Predicting faults in diesel engines with kernel machines regression techniques},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Open-vocabulary object detection with regionwise prompt selection and patch-based category-aware maximal activation. <em>APIN</em>, <em>55</em>(12), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06651-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detectors perform unseen class detection by fine-tuning frozen visual-language models with visual prompts and natural language supervision. However, the current visual prompt tuning methods struggle to learn categorywise shared knowledge when using only one single visual prompt, due to the inaccessibility of unseen classes referred to as novel classes during training. This leads to isolation between the unknown novel classes and the base classes. Inspired by the recently developed RPN-based open-vocabulary object detection (OVOD) methods, we propose a region-aware visual prompt selection (RVPS) module to adaptively combine region features with best-matched visual prompts based on decoupled proxy embeddings. Additionally, we introduce a category-aware patchwise maximal aggregation (CPMA) module to explore the relationships among visual patches with respect to the category-specific maximum activation patches contained within the target region. We evaluate the proposed approach on an open-vocabulary benchmarks: COCO and LVIS. Compared with other state-of-the-art approaches, our method achieves a 1.2% AP $$_{50}$$ improvement on COCO for novel classes and a 0.5% mask AP improvement on LVIS for rare categories.},
  archive      = {J_APIN},
  author       = {Xu, Zhaocheng and Wang, Ruili and Tian, Yan and Yang, Tao},
  doi          = {10.1007/s10489-025-06651-7},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Open-vocabulary object detection with regionwise prompt selection and patch-based category-aware maximal activation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Supervised deep learning algorithms for process fault detection and diagnosis under different temporal subsequence length of process data. <em>APIN</em>, <em>55</em>(12), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06711-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault detection and diagnosis (FDD) plays a vital role in abnormal situation management of chemical industrial processes. Current FDD technologies mostly rely on data-driven solutions by making full use of abundant process data collected by the state-of-the-art distributed process instruments and sensors. Deep learning algorithms were widely used among all the data-driven algorithms. Industrial process time series data could be processed with ease by deep learning algorithms, particularly transformer-based models because of their multi-head attention mechanism. Different lengths of snippets of sequence (or subsequence) would have a multitude of perspectives viewed by the deep learning algorithms, subsequently impacting their FDD performance. This study, therefore, aims to investigate the effects of varying subsequence lengths on the FDD performance of common deep learning algorithms, consisting of a multilayer perceptron, convolutional neural network, long short-term memory, transformer, industrial process optimisation—vision transformer (IPO-ViT) using two benchmark case studies, namely continuous stirred tank reactor (CSTR) and Tennessee Eastman Process (TEP). Additionally, faulty data are rare to occur, and the fault labelling process is generally tedious and expensive to perform. The effects of labelled training data sizes were also studied on the FDD performance. The findings clearly indicate that the IPO-ViT, a variant of transformer-based models, exhibited the best FDD performance under 10% and 50% subsequence length of data on CSTR and TEP case studies, respectively, for optimal feature extraction, even with 10% of fully labelled input data.},
  archive      = {J_APIN},
  author       = {Kai, Terence Chia Yi and Saptoro, Agus and Putra, Zulfan Adi and Lim, King Hann and Yeo, Wan Sieng and Sunarso, Jaka},
  doi          = {10.1007/s10489-025-06711-y},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Supervised deep learning algorithms for process fault detection and diagnosis under different temporal subsequence length of process data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active continual learning with energy alignment sampling strategy (EASS) for structural damage classification. <em>APIN</em>, <em>55</em>(12), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06743-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual learning aims to enable models to continuously acquire new knowledge without forgetting previously learned information—a fundamental yet challenging task in dynamic environments. Although recent memory selection strategies, such as those based on gradients and uncertainty, have advanced this field, they still suffer from sampling bias and limited generalizability across tasks. To address these limitations, we propose the Energy Alignment Sampling Strategy (EASS), an active continual learning framework that integrates energy-based modeling into both memory replay and active sample acquisition. The core principle of EASS lies in selecting memory and unlabeled samples based on their free energy, uncertainty, and diversity, and jointly training them using a dual-loss function that combines cross-entropy with free energy alignment loss to preserve old knowledge while adapting to new tasks. This approach helps mitigate the forgetting of old knowledge and boosts the efficiency of new knowledge acquisition. Our experimental results on the CIFAR-10 dataset demonstrate the effectiveness of our method. Additionally, we have applied our framework to two structural damage classification datasets—the Container Damage Dataset and the Building Structural Damage Dataset—with promising outcomes. This study advances the field of continual learning and highlights its practical applications in real-world scenarios, particularly in structural damage assessment.},
  archive      = {J_APIN},
  author       = {Zhang, Xingzhong and Loo, Chu Kiong and Chuah, Joon Huang},
  doi          = {10.1007/s10489-025-06743-4},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Active continual learning with energy alignment sampling strategy (EASS) for structural damage classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-temporal fuzzy cognitive maps based on adaptive graph learning for multivariate time series interpretable prediction. <em>APIN</em>, <em>55</em>(12), 1-26. (<a href='https://doi.org/10.1007/s10489-025-06745-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling multivariable time series remains a critical research area. Despite the numerous time series prediction models introduced, the development of models that balance interpretability and accuracy remains an open challenge. In this work, we propose a novel Spatial-Temporal Fuzzy Cognitive Map based adaptive Graph Learning model (STFCM-AGL) to achieve interpretable multivariate time series predictions. First, leveraging high-order fuzzy cognitive maps, we introduce granularity adjustment strategies to obtain dynamic interval weights such that the model’s capability can be improved in complex system. Second, the Adaptive-GraphSAGE module is designed based on the graph structure of the fuzzy cognitive map to capture subtle changes in node features and to fully leverage the deeper relationships between concepts. Moreover, leveraging node embeddings enriched with spatial information, the temporal convolution module enhances the model’s time-series representation capabilities. Finally, the parameters of the fuzzy cognitive map, graph neural network, and temporal convolution module are jointly learned within an end-to-end framework. Experimental results demonstrate that the proposed model outperforms state-of-the-art baseline methods across real-world datasets from transportation, finance, and environmental domains, while maintaining the interpretability of the foundational fuzzy cognitive graph model.},
  archive      = {J_APIN},
  author       = {Jiacheng, Tang and Fengqian, Ding and Rui, Shao and Chao, Luo},
  doi          = {10.1007/s10489-025-06745-2},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Spatial-temporal fuzzy cognitive maps based on adaptive graph learning for multivariate time series interpretable prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross patient seizure detection via unsupervised domain adaptation based on uncertainty estimation. <em>APIN</em>, <em>55</em>(12), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06755-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy ranks as the second most prevalent neurological disorder globally. Current EEG-based seizure detection methods struggle with inter-patient variability. While unsupervised domain adaptation (UDA) techniques can address this, existing approaches require source patient data access, violating privacy requirements. We propose a privacy-preserving UDA framework for cross-patient seizure detection that: (1) quantifies cross-patient domain discrepancy via distribution uncertainty distance, (2) enables channel-wise knowledge transfer through EEG channel-wise transferability assessment, (3) employs confidence-weighted pseudo-labeling based on distance-based confidence metric. Our method achieves an accuracy of 94.81%, a false detection rate of 0.39, and an average detection delay of 3.29 seconds on the CHB-MIT dataset. On the Siena dataset, an accuracy of 94.1% and a sensitivity of 90.77% are obtained. The results validate the effectiveness of our approach in achieving robust cross-patient seizure detection under privacy-preserving constraints.},
  archive      = {J_APIN},
  author       = {Wang, Shuai and Lv, Hongbin and Feng, Hailing and Peng, Hao and Feng, Wenqian and Nie, Chenxi and Zhao, Yanna},
  doi          = {10.1007/s10489-025-06755-0},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Cross patient seizure detection via unsupervised domain adaptation based on uncertainty estimation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OAN-DA: Online adaptive learning with distribution awareness for continuous time series forecasting. <em>APIN</em>, <em>55</em>(12), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06756-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting plays a crucial role in various fields including network traffic prediction and energy system forecasting. The primary challenge in long-term forecasting is temporal covariate shift (TCS) caused by dynamic changes in time series data. While numerous time series forecasting models have been successfully developed, most focus on learning complex patterns from historical data and lack the ability to dynamically adapt to future distribution shifts. Existing online adaptation methods, primarily designed for image classification tasks, are unsuitable for time series forecasting which requires rapid adaptation to small samples of rapidly changing time series data. In this work, we propose an Online Adaptive Network with Distribution Awareness (OAN-DA) framework. By pretraining a domain encoder to capture target domain distributions and utilizing domain embeddings to guide predictor adjustments, OAN-DA effectively adapts to continuously evolving target distributions using limited target samples. Experimental results demonstrate that when applied to various time series forecasting methods, OAN-DA achieves average performance improvements across three public datasets, reducing Mean Squared Error (MSE) by 61.8%, 65.2%, and 54.17% respectively, highlighting its superior generalization and online adaptation capabilities across temporal and spatial domains.},
  archive      = {J_APIN},
  author       = {Liu, Ren and Tao, Liwen and Zhou, Wenan},
  doi          = {10.1007/s10489-025-06756-z},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {OAN-DA: Online adaptive learning with distribution awareness for continuous time series forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). None of the above: Comparing scenarios for answerability detection in question answering systems. <em>APIN</em>, <em>55</em>(12), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06765-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question Answering (QA) is often used to assess the reasoning capabilities of NLP systems. For a QA system, it is crucial to have the capability to determine answerability– whether the question can be answered with the information at hand. Previous works have studied answerability by including a fixed proportion of unanswerable questions in a collection without explaining the reasons for such proportion or the impact on systems’ results. Furthermore, they do not answer the question of whether systems learn to determine answerability. This work aims to answer that question, providing a systematic analysis of how unanswerable question ratios in training data impact QA systems. To that end, we create a series of versions of the well-known Multiple-Choice QA dataset RACE by modifying different amounts of questions to make them unanswerable, and then train and evaluate several Large Language Models on them. We show that LLMs tend to overfit the distribution of unanswerable questions encountered during training, while the ability to decide on answerability always comes at the expense of finding the answer when it exists. Our experiments also show that a proportion of unanswerable questions around 30%– as found in existing datasets– produces the most discriminating systems. We hope these findings offer useful guidelines for future dataset designers looking to address the problem of answerability.},
  archive      = {J_APIN},
  author       = {Reyes-Montesinos, Julio and Rodrigo, Álvaro and Peñas, Anselmo},
  doi          = {10.1007/s10489-025-06765-y},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {None of the above: Comparing scenarios for answerability detection in question answering systems},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-modal genomic knowledge distillation framework for drug response prediction. <em>APIN</em>, <em>55</em>(12), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06768-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precision oncology utilizes genomic data to tailor treatment to individuals. Cancer drug sensitivity studies can predict the response levels of different drugs for the same cultured cancer cell line, which is beneficial for personalized medicine. Recent studies have demonstrated that integrating multi-modal genomic data, e.g., gene expression, mutation, copy number alteration, methylation, can provide comprehensive knowledge and improve drug response prediction. Although multi-modal genomic profiles are generally available from public datasets, only gene expression data is commonly used in clinical settings. In this study, we propose a framework for privileged information knowledge distillation to transfer knowledge from a multi-modal genomic teacher network, using only gene expression for inference. Specifically, we train a teacher network by feature re-weighting based on inter-modality dependencies and align the inter-sample correlations through our proposed relation-aware differentiation distillation. Experiments on the Genomics of Drug Sensitivity in Cancer (GDSC) dataset demonstrate that our framework improves drug response prediction by about 6% compared to the baseline and outperforms state-of-the-art methods. Transferable studies performed on missing GDSC data and clinical datasets further confirm the feasibility of our model for predicting drug responses using only gene expression data.},
  archive      = {J_APIN},
  author       = {Ge, Shuang and Sun, Shuqing and Xu, Huan and Cheng, Qiang and Ren, Zhixiang},
  doi          = {10.1007/s10489-025-06768-9},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {A multi-modal genomic knowledge distillation framework for drug response prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Source-free domain adaptation with aligned transfer and self-supervised learning. <em>APIN</em>, <em>55</em>(12), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06777-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing focus on data privacy and security, Unsupervised Domain Adaptation (UDA) needs to be performed under a more stringent “source-free” setting, where only the model trained on the source data is available without accessing the source data itself. While domain alignment is a core concern in conventional UDA, this objective is not formulated in most existing Source-Free UDA (SF-UDA) approaches due to the difficulty of measuring domain discrepancy under the source-free scenario. Missing this mechanism, however, restricts their capability to effectively handle negative impact caused by domain shift. In this paper, we propose a new approach for source-free cross-domain knowledge transfer in aligned feature spaces. We exploit the statistical information of source training data stored in the Batch Normalization (BN) layers of the target model to construct the source domain distribution in feature spaces. The distribution discrepancy between the two domains can then be measured and minimized like conventional UDA without source data. In addition to the explicit formulation of domain alignment, we also apply self-supervised learning to discover target domain knowledge with unlabeled target data to enhance the encoder’s feature extraction capability. We conducted domain adaptation experiments on several standard image datasets. Results show that our method further improves the accuracy of existing source-free domain adaptation methods in various cases.},
  archive      = {J_APIN},
  author       = {Weng, Yetao and Mei, Jian-Ping and Hu, Chengyang and Zhao, Hongbo},
  doi          = {10.1007/s10489-025-06777-8},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Source-free domain adaptation with aligned transfer and self-supervised learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Style-content progressive aggregation network with stable diffusion. <em>APIN</em>, <em>55</em>(12), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06751-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of text-to-image generation has matured significantly with the advancement of diffusion models; however, achieving precise control over the details and style of generated images remains a challenge. Existing methods often rely on complex text prompts to describe details while attempting to integrate style information. Nevertheless, the single-stage attention mechanism in diffusion models struggles to effectively capture multi-scale features and the relationship between style and content, resulting in feature amalgamation that compromises the quality of generated images. To address this issue, we propose a Style-Content Progressive Aggregation (SCPA) network, which integrates and aggregates multi-scale features from style images and text prompts through the coordinated design of two complementary modules. Specifically, the Style-Content Decoupling (SCD) module disentangles the style and content features of the style image, and reconstructs a learnable content template based on the extracted style features, thereby preventing the original content features from interfering with text understanding. The Style-Content Coupling (SCC) module then extracts multi-scale pixel-level content features from the text prompt and progressively integrates style elements into the template, enabling fine-grained fusion of content and style. This progressive aggregation strategy effectively enhances the quality of prior guidance provided to the diffusion model. Extensive experimental results demonstrate that the SCPA network can generate more artistically appealing images and offers a new direction for the integration of text-to-image generation models with traditional style transfer techniques.},
  archive      = {J_APIN},
  author       = {Yuan, Tiebiao and Yu, Yangyang and Ji, Ning},
  doi          = {10.1007/s10489-025-06751-4},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Style-content progressive aggregation network with stable diffusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving semi-decentralized matrix factorization for personalized recommendations with grouping and random transmission. <em>APIN</em>, <em>55</em>(12), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06781-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix factorization (MF) is a prevalent technique in recommender systems, its reliance on centralized storage raises significant privacy concerns. Federated learning (FL), as a distributed learning framework, has emerged as a promising solution. However, even in FL, the transmission of models or gradients can still pose risks to user privacy. To address this, we propose a privacy-preserving semi-decentralized matrix factorization (PSDMF) framework for personalized rating prediction, incorporating privacy-preserving grouping and random transmission to enhance privacy. PSDMF combines the advantages of decentralized and client-server architectures from FL, allowing users to directly exchange model parameters within groups for training while preserving the server’s aggregation role. Our framework comprises three key phases. Firstly, we introduce a privacy-preserving grouping approach to identify communication neighbors with similar preferences for users. Secondly, we employ a random transmission strategy to enable each group to build a group item latent matrix tailored to specific user group preferences, without compromising privacy. Finally, the server collects and aggregates all the group models to generate a global latent matrix that captures broader preferences. Experimental validation conducted on five real-world movie rating datasets demonstrates that PSDMF ensures better recommendation performance while preserving user privacy.},
  archive      = {J_APIN},
  author       = {Cai, Jinhua and Chen, Bilian and Cao, Langcai},
  doi          = {10.1007/s10489-025-06781-y},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Privacy-preserving semi-decentralized matrix factorization for personalized recommendations with grouping and random transmission},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic survey on explainable artificial intelligence (XAI) for plant health monitoring: Challenges and opportunities. <em>APIN</em>, <em>55</em>(12), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06790-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of Artificial Intelligence (AI) into agriculture has transformed plant health monitoring, yet challenges in interpretability and transparency hinder its broader adoption. Explainable Artificial Intelligence (XAI) addresses these limitations by providing clarity into AI-driven decision-making processes, fostering trust and understanding among stakeholders. Although several review papers explore XAI in general, there is limited focus on its specific applications in plant health monitoring. Moreover, existing surveys in plant health monitoring primarily focus on the technical development of models, often neglecting the critical aspect of explainability. The proposed survey bridges this gap by investigating diverse methodologies along with XAI techniques used specifically for disease detection, pest identification, and overall plant health assessment, offering a targeted perspective on this critical domain. This study also reviews some publicly available datasets, offering valuable insights into data resources supporting agricultural research. Additionally, the study discusses key challenges associated with implementing XAI in agriculture, including dataset limitations, model robustness and XAI integration with existing agricultural systems. Furthermore, the study also proposes future research directions, including integration of XAI in early model development, robustness of XAI against adversarial attacks, real time monitoring, development of benchmark datasets and so on. The purpose of this survey is to serve as a valuable asset for researchers, practitioners and policymakers aiming to grasp the present-day scenario of XAI in plant health monitoring and chart a course for future advancements in the field.},
  archive      = {J_APIN},
  author       = {Kaler, Blossom and Kaur, Amandeep},
  doi          = {10.1007/s10489-025-06790-x},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {A systematic survey on explainable artificial intelligence (XAI) for plant health monitoring: Challenges and opportunities},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PIGPVAE: Physics-informed gaussian process variational autoencoders. <em>APIN</em>, <em>55</em>(12), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06776-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in generative AI offer promising solutions for synthetic data generation but often rely on large datasets for effective training. To address this limitation, we propose a novel generative model that learns from limited data by incorporating physical constraints into a Variational Autoencoder (VAE) framework. Specifically, we extend VAE with a physics-based generator to capture underlying dynamics, while unmodeled dynamics are learned via a latent Gaussian Process VAE (GPVAE) component. We further introduce a regularization term that balances the physical model and data-driven discrepancy, promoting both interpretability and fidelity to real-world observations. We evaluate the proposed method on both real and simulated data, demonstrating that the Physics-Informed GPVAE (PIGPVAE) outperforms state-of-the-art methods in terms of diversity and accuracy of the generated samples, even under small-data conditions. Additionally, we demonstrate that PIGPVAE can produce realistic samples beyond the observed distribution, highlighting its robustness and usefulness under distribution shifts.},
  archive      = {J_APIN},
  author       = {Spitieris, Michail and Ruocco, Massimiliano and Murad, Abdulmajid and Nocente, Alessandro},
  doi          = {10.1007/s10489-025-06776-9},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {PIGPVAE: Physics-informed gaussian process variational autoencoders},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale feature extraction and gradient attention-based method for sketch extraction of painted cultural relics. <em>APIN</em>, <em>55</em>(12), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06788-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the limitations of existing sketch methods for damaged murals, such as insufficient detail preservation, edge blurring, and artifact interference, we propose a mural sketch extraction method based on Multi-Scale Feature Extraction and Gradient Attention Mechanism (MSFE-GAM). The method employs a Multi-Scale Feature Enhancement Module (MSFE) during the downsampling stage to capture cross-scale line details. It integrates gradient information as prior knowledge through a Gradient Attention Module (GAM), guiding the network to focus on critical line regions. In the feature fusion stage, an Adaptive Fusion Module (AFM) dynamically adjusts gradient attention weights via learnable parameters, balancing detail retention and background noise suppression. To address domain distribution discrepancies in damaged murals, an Unsupervised Domain Adaptation (UDA) strategy is proposed, enabling test-sample-driven parameter fine-tuning to enhance adaptability to unseen domain data. Experimental results demonstrate that compared with existing methods, this method improves the SSIM index by more than 7%, increases the AP value by 2.8%, and reduces the RMSE to 0.2071. The generated sketches exhibit rich details and clean backgrounds, particularly outperforming existing methods in complex damage scenarios. Additionally, the UDA strategy enables robustness in cross-domain generalization on unseen samples like Thangka murals, validating its applicability in data-scarce domains. This study provides an innovative, generalizable technical framework for cultural heritage digitization, with ablation experiments and cross-domain analysis confirming its practical utility in addressing damaged murals and data-limited scenarios.},
  archive      = {J_APIN},
  author       = {Peng, Shenglin and Cui, Shan and Zhao, Xingguo and Wang, Jun and Qu, Shuyi and Peng, Xianlin},
  doi          = {10.1007/s10489-025-06788-5},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Multi-scale feature extraction and gradient attention-based method for sketch extraction of painted cultural relics},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised prototype network with domain adversarial for few-shot fault diagnosis. <em>APIN</em>, <em>55</em>(12), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06789-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of deep learning, a variety of intelligent techniques have been successfully applied to fault diagnosis, yielding promising results. However, most existing methods rely on data collected under ideal conditions, which limits their applicability in real-world industrial settings characterized by limited data availability, difficulties in labeling, and significant operating condition discrepancies. To address these challenges, this paper proposes a Domain-Adversarial Semi-Supervised Prototypical Network (DA-SSPN). The proposed approach integrates the prototypical network architecture with a domain-adversarial training strategy, and employs a synergistic optimization of a feature extractor, a label classifier, and a domain discriminator to effectively extract domain-invariant features. During prototype construction, unlabeled samples are incorporated into the learning of class centers, and a shifting term is introduced to mitigate the distributional bias between the support set and the query set. This enhances classification stability and diagnostic accuracy across varying operating conditions. The proposed method is evaluated on several cross-domain tasks and compared with existing approaches. Experimental results demonstrate that DA-SSPN achieves superior classification performance and generalization capability.},
  archive      = {J_APIN},
  author       = {Song, Haohao and Yang, Jie and Wan, Xiaowei and Xue, Anke},
  doi          = {10.1007/s10489-025-06789-4},
  journal      = {Applied Intelligence},
  month        = {8},
  number       = {12},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Semi-supervised prototype network with domain adversarial for few-shot fault diagnosis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Casting defect-detection method based on multi-image feature of fusion artificial intelligence model. <em>APIN</em>, <em>55</em>(11), 1-26. (<a href='https://doi.org/10.1007/s10489-025-06429-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Casting defects in radiographic images often display unclear features, fuzzy contour boundaries, and uncertain locations, making accurate detection of defect targets highly challenging. Existing artificial intelligence (AI)-based defect-detection methods predominantly analyze single images, overlooking the dynamic observations encountered in practical applications. This limitation can lead to missed and false detections. To address these issues, this study proposes a low-semantic defect-detection method based on multi-image feature sequence fusion, combining the dynamic evaluation knowledge of technicians in analyzing radiographic testing images with the advanced YOLOv8 model. First, a multi-image decomposition strategy based on the gamma transform was developed to generate image sequences reflecting a pattern of dynamic changes, simulating the real-world process of defect evaluation. Second, a multi-image feature sequence fusion network was designed to capture spatiotemporal information, generating a feature matrix focused on the dynamic characteristics of defect targets, which was integrated with YOLOv8 for precise defect detection. Finally, degree-of-confidence similarity was employed to fine-tune candidate boxes, ensuring accurate localization of defect targets. Experimental comparisons with state-of-the-art methods, including RT-DETR, YOLOv10, and YOLOv11, demonstrate that the proposed method achieves superior defect-detection accuracy compared with existing methods, effectively addressing the issue of missed detections in casting defects. The proposed method achieves a recall rate of 96.71% and mean average precision of 77.09% for defect detection in casting-ray images, significantly enhancing the detection performance and localization accuracy for low-semantic defects.},
  archive      = {J_APIN},
  author       = {Yang, Deyan and Jiang, Hongquan and Yang, He and Wang, Yonghong and Liu, Zhen and Zhang, Xinguang and Cheng, Huyue},
  doi          = {10.1007/s10489-025-06429-x},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Casting defect-detection method based on multi-image feature of fusion artificial intelligence model},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive survey of imputation methods in medical missing data analysis. <em>APIN</em>, <em>55</em>(11), 1-27. (<a href='https://doi.org/10.1007/s10489-025-06602-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical big data analysis is crucial to advancing healthcare research and improving patient care. However, missing data in these datasets creates a significant challenge for understanding patient profiles and disease patterns. The absence of critical information caused by factors such as incomplete patient records or unreported variables introduces uncertainties that can compromise the accuracy and reliability of analytical results. Resolving the problem of missing data is therefore paramount to ensuring the efficiency of healthcare analyses and improving the overall quality of medical research. This study examines and reviews different methods of imputing missing data in the context of medical big data. Traditional imputation techniques, advanced statistical approaches, machine learning-based models and deep learning-based models are evaluated with regard to their relevance, scalability and performance. Particular emphasis is placed on the unique challenges presented by medical big data, such as high dimensionality and data heterogeneity, as well as the incorporation of domain-specific knowledge. This study further investigates the role of big data technologies in enabling efficient imputation for large-scale medical datasets and evaluates metrics designed to assess imputation quality. Finally, future directions are discussed with the aim of improving missing data imputation strategies and, by extension, data-driven decision-making in the era of medical big data.},
  archive      = {J_APIN},
  author       = {Benhamza, Karima and Benselim, Razane and Naidja, Hanane and Seridi, Hamid},
  doi          = {10.1007/s10489-025-06602-2},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-27},
  shortjournal = {Appl. Intell.},
  title        = {A comprehensive survey of imputation methods in medical missing data analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic optimal decision-making for scaling cleaning in the sodium aluminate solution evaporation process. <em>APIN</em>, <em>55</em>(11), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06624-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scaling on the evaporator severely impacts heat transfer efficiency, reducing both production efficiency and product quality. Optimizing the cleaning schedule of the evaporator is crucial for improving heat transfer performance. This paper proposes a dynamic optimal decision-making strategy for determining the optimal cleaning timing. Firstly, a mechanistic model is established that accounts for the variation in material concentration over time, providing an accurate representation of the scaling process in sodium aluminate solution evaporation. Secondly, an infinite time domain cleaning optimization model is proposed, which considers the continuity of scaling between cycles. Lastly, a rolling optimization decision approach based on prediction is designed. The results demonstrate that the proposed method significantly outperforms traditional single-cycle optimization, scaling threshold-based methods, and time threshold-based cleaning methods in reducing cleaning frequency, improving heat transfer efficiency, and increasing net profit.},
  archive      = {J_APIN},
  author       = {Zhu, Liang and Han, Jie and Zhao, Zhuo and Liu, Yishun and Wang, Kai and Yang, Chunhua},
  doi          = {10.1007/s10489-025-06624-w},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Dynamic optimal decision-making for scaling cleaning in the sodium aluminate solution evaporation process},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Increment and decrement consistency for semi-supervised endoscopic surgical instrument segmentation. <em>APIN</em>, <em>55</em>(11), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06625-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation of endoscopic surgical instruments can assist surgeons in making decisions to ensure surgical safety. Semantic segmentation based on deep learning relies heavily on large-scale annotated data, which is both time-consuming and labor-intensive. Fortunately, semi-supervised learning offers a means to alleviate this challenge. However, Existing semi-supervised segmentation methods are rarely specifically designed for endoscopic surgical instruments. To address the problem of insufficient presence of endoscopic surgical instruments within the visual field, leading to bias in model learning, we devise an image incremental augmentation strategy aimed at augmenting the presence of endoscopic surgical instruments within the images. Furthermore, to enhance the model’s focus on inconsistent regions within segmented targets, we devise an image decrement augmentation strategy aimed at improving the segmentation accuracy of endoscopic surgical instruments’ inconsistent regions. The adopted network has two different decoders and computes the consistency of their outputs. Several consistency losses are devised to reinforce supervision among networks employing different data augmentation strategies in their outputs. Extensive experiments on both a private dataset and a public dataset corroborates the effectiveness of the proposed method. Our method achieves a Dice similarity coefficient (DSC) of 92.96% and 93.36% on the EndoVis2017 dataset with 5% and 10% labeled data, respectively, outperforming state-of-the-art methods. On the private dataset, our method achieves a DSC of 97.64% and 97.78% with 5% and 10% labeled data, respectively, further demonstrating its superiority. Ablation studies confirm the effectiveness of the proposed data augmentation strategies, with incremental and decremental strategies contributing to a 0.72% and 0.41% improvement in DSC, respectively.},
  archive      = {J_APIN},
  author       = {Sun, Liping and Han, Xiaoxiang and Chen, Xiong},
  doi          = {10.1007/s10489-025-06625-9},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Increment and decrement consistency for semi-supervised endoscopic surgical instrument segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep integration of conditional gan, attention mechanism, and image clustering for automated color separation and correction in textile screen printing. <em>APIN</em>, <em>55</em>(11), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06628-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual color separation and image processing are needed for pretreatment in traditional textile screen printing but the shortage of engineers has created a significant bottleneck in improving printing quality. Therefore, this research aimed to introduce an innovative method by proposing the squeeze-excitation attention and Pix2PixHD (SEAPix) incorporating KMeans clustering algorithm, forming KMeans+SEAPix model. The proposed SEAPix integrates a squeeze and excitation attention (SEA) mechanism into the conditional generative adversarial network (cGAN), Pix2PixHD, architecture. KMeans algorithm facilitates the separation of similar colors into distinct branches. Furthermore, SEAPix method improves the accuracy of high-resolution image generation by focusing on important regions and reducing irrelevant noise. To verify the sequence of color separation and image processing, this research developed two different frameworks, namely the Image Generation-Separation Framework (PF1) and the Image Generation-Separation Framework (PF2). PF1 starts with image generation, followed by Kmeans color separation, while PF2 adopted a different method by using color separation first, followed by generating images with cGAN. The experimental results of this research showed that PF2 was superior to PF1. Specifically, PF2 had better structural similarity index measure (SSIM), peak signal-to-noise ratio (PSNR), intersection over union (IoU), and pixel accuracy increased by 15.5643%, 0.5249%, 11.3757%, and 1.6508%, respectively. PF2 also has lower learned perceptual image patch similarity (LPIPS) and mean squared error (MSE) decreased by 24.3518% and 2.5963% compared with PF1. In conclusion, the proposed KMeans+SEAPix could revolutionize traditional textile screen printing methods by providing automated color separation and image correction.},
  archive      = {J_APIN},
  author       = {Yang, Chao-Lung and Harjoseputro, Yulius and Chien, Chi-Hao and Chen, Yung-Yao},
  doi          = {10.1007/s10489-025-06628-6},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Deep integration of conditional gan, attention mechanism, and image clustering for automated color separation and correction in textile screen printing},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RA-EPNet: A novel network fusing residual axial attention and edge prediction for medical image segmentation. <em>APIN</em>, <em>55</em>(11), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06629-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the U-Net architecture and its Transformer-integrated variant, excellent performance has been demonstrated in medical image segmentation tasks. However, there still exists a semantic gap between the feature maps passed through the decoder and skip connections, while the network cannot effectively utilize inherent spatial information within the images. To address the above issues, we propose a medical image segmentation network that integrates residual axial attention and edge prediction. Firstly, for the challenges of blurred target boundaries and complex variations in medical images, a channel-spatial transformer based on residual axial attention is designed. This module enhances the feature maps transmitted through skip connections by introducing positional information and integrating features from multiple stages in the encoder. Secondly, a semantic alignment module based on residual axial attention is developed to mitigate the semantic gap issue in the encoder-decoder architecture. Additionally, by incorporating the edge prediction loss function, region information is used as a geometric constraint for the image segmentation task to encourage the model to generate continuous and clear target boundaries. Finally, the proposed method is evaluated on five different datasets, including binary and multi-class segmentation tasks. Experimental results demonstrate that compared to state-of-the-art segmentation methods, this approach achieves higher evaluation scores and finer segmentation results on various public datasets while reducing standard deviation.},
  archive      = {J_APIN},
  author       = {Yang, Lijun and Zhang, Hongying and Li, Xue and Qi, Ziyuan and Tang, Julei and Li, Xiaoxia},
  doi          = {10.1007/s10489-025-06629-5},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {RA-EPNet: A novel network fusing residual axial attention and edge prediction for medical image segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Angular triangle distance for ordinal metric learning. <em>APIN</em>, <em>55</em>(11), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06630-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep metric learning (DML) aims to automatically construct task-specific distances or similarities between data, resulting in a low-dimensional representation. Several significant DML methods have been proposed. However, no approach guarantees the preservation of the ordinal nature of the original data in a low-dimensional space. Ordinal data are ubiquitous in real-world problems, such as the severity of symptoms in biomedical cases, production quality in manufacturing, rating level in businesses, and ageing level in face recognition. This study proposes a novel angular triangle distance (ATD) and ordinal triplet network (OTN) to obtain an accurate and meaningful embedding space representation for ordinal data. The ATD projects the ordinal relation of data in the angular space, whereas the OTN learns its ordinal projection. We also demonstrate that our new distance measure mathematically satisfies the distance metric properties. The proposed method was assessed using various benchmarks with an ordinal nature in both dependent and independent variables. Extensive experiments have been conducted, and the results show that our proposed method not only semantically preserves the ordinal nature but is also more accurate than existing DML models. Furthermore, our study demonstrates that our proposed method can effectively address ordinal regression tasks, producing competitive outcomes achieved by current state-of-the-art techniques.},
  archive      = {J_APIN},
  author       = {Kamal, Imam Mustafa and Bae, Hyerim and Liu, Ling},
  doi          = {10.1007/s10489-025-06630-y},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Angular triangle distance for ordinal metric learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision-based real-time traffic flow monitoring system for road intersections in dhaka city. <em>APIN</em>, <em>55</em>(11), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06631-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Globally, traffic congestion impedes economic development. Dhaka, the fifth most crowded city in the world, faces significant traffic problems as a result of a lack of an intelligent monitoring and forecasting system. The lack of an efficient solution leads to unmanageable congestion, longer travel times, and economic losses. To address this issue, we propose a real-time traffic monitoring system capable of vehicle detection, counting all vehicle types, speed estimation, and traffic forecasting. A custom vehicle image dataset for Dhaka city was created by extracting images from videos of different road segments to build a robust model. This dataset is used with YOLOv8 (You Only Look Once) for vehicle detection, which quickly identifies objects in camera footage. Training YOLOv8 on five vehicle types in Dhaka city (truck, bus, car, motorcycle, and three-wheeler) achieves around 94% accuracy. The system can count vehicles and measure their speed in real time using very low-resolution cameras. Vehicle counts and average speeds are then collected to form a numerical dataset. This dataset trains machine learning models to predict traffic flow and aid traffic management decisions. Vehicles are tracked frame-by-frame with distance and time data recorded to calculate average speeds. Using LSTM, we achieve 83% accuracy for predicting average speed and 97% accuracy for predicting vehicle count. These insights enable authorities to optimize signal timings, reduce congestion, and improve overall road efficiency, ultimately leading to smoother transportation, reduced travel time and enhanced economic productivity.},
  archive      = {J_APIN},
  author       = {Arif, Taslim and Muhammad Mussa, Abu Salyh and Rahman, Moshiur and Joarder, Mahbubul Alam},
  doi          = {10.1007/s10489-025-06631-x},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Vision-based real-time traffic flow monitoring system for road intersections in dhaka city},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Focal weighting strategy with multi-label multi-scale granularity-aware for out-of-distribution detection. <em>APIN</em>, <em>55</em>(11), 1-12. (<a href='https://doi.org/10.1007/s10489-025-06633-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying out-of-distribution (OOD) samples is crucial for ensuring the safe implementation of machine-learning models in open environments. Although various algorithms for multi-class OOD detection have emerged, the exploration of multi-label OOD detection remains lacking. Current multi-label OOD algorithms ignore the inherent characteristic of label distribution imbalance in multi-label datasets, with limited attention paid to the scale imbalance issue between different objects in OOD detection. To address these challenges, we proposed a Multi-label Multi-scale Granularity-Aware OOD detection model (MMGA). Initially, a novel hierarchical multi-scale architecture was developed to extract critical information across various levels and granularities. This included the construction of a Scale-Aware Module (SAM) to align low-level details with high-level semantic features. Subsequently, to mitigate the negative impact of class-imbalanced data, a focal weighting strategy was introduced to exploit the potential of negative samples for OOD detection. Finally, we employed an energy function to calculate the OOD scores, thereby facilitating a reliable OOD uncertainty estimation. Experimental findings on the MS-COCO, PASCAL-VOC, and NUS-WIDE datasets confirm that our MMGA approach effectively addresses both imbalance issues, demonstrating superior performance compared to the JointEnergy method, with improvements of 7.62%, 9.52%, and 7.47% on the FPR95 metric, respectively.},
  archive      = {J_APIN},
  author       = {Peng, Xin and Cheng, Yifei and Cheng, Yusheng},
  doi          = {10.1007/s10489-025-06633-9},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {Focal weighting strategy with multi-label multi-scale granularity-aware for out-of-distribution detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IACFormer: A transformer framework with instantaneous average convolution for temporal action detection. <em>APIN</em>, <em>55</em>(11), 1-28. (<a href='https://doi.org/10.1007/s10489-025-06636-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Action Detection (TAD) in video understanding involves action detection and boundary localization. Accurately pinpointing the start and end times of action instances remains a major challenge. Although existing Transformer-based methods such as ActionFormer exhibit good detection performance, they are deficient in capturing local details and are not well-suited for temporal action localization. Specifically, the similarity of adjacent frames and the use of a single regression head lead to inaccurate boundary localization. To address these issues, we propose the IACFormer. It makes four key improvements: Firstly, the Instantaneous Average Convolution Module (IACM) and Instantaneous Average Dilated Convolution Module (IADCM) combined with Multi-head Global Self-attention Blocks enhance local feature learning. Secondly, incorporating nonlinear branches into IACM and IADCM sharpens the distinction of adjacent frame features. Thirdly, integrating dilated convolutions in deep IADCM promotes deep feature learning. Fourthly, employing start and end boundary regression heads on the detection head enables accurate positioning of start and end times. Additionally, through knowledge distillation, on the datasets THUMOS14, ActivityNet 1.3, and EPIC-Kitchens 100, the IACFormer significantly reduces the video memory overhead without sacrificing the average precision and recall rate. The IACFormer outperforms the baselines on the THUMOS14, ActivityNet 1.3, HACS and EPIC-Kitchens 100 datasets, achieving the state-of-the-art on THUMOS14 and EPIC-Kitchens 100.},
  archive      = {J_APIN},
  author       = {Zhang, Haiping and Xu, Dongyang and Lin, Haixiang and Wang, Dongjing and Yu, Dongjin and Guan, Liming and Zhang, Wanjun},
  doi          = {10.1007/s10489-025-06636-6},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-28},
  shortjournal = {Appl. Intell.},
  title        = {IACFormer: A transformer framework with instantaneous average convolution for temporal action detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How to learn new knowledge: A multimodal contrastive learning framework for open-world knowledge graph completion. <em>APIN</em>, <em>55</em>(11), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06642-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The real-world knowledge graph is continuously expanding with the emergence of new entities. Therefore, the Open-World Knowledge Graph Completion(OW-KGC) task has been proposed to represent these rapidly growing entities. Existing methods primarily rely on textual descriptions for entity embeddings, but research suggests that human perception of unknown entities benefits from multimodal information. To solve this question, we introduce MANNER, a Multimodal contrAstive framework for opeN-world kNowledgE gRaph completion. Specifically, MANNER first employs a closed-world KGC model to generate graph-based representations of known entities. It then extracts and integrates image and text features from pre-trained models as multimodal data. A transformation function is learned to map these multimodal features into a graph-based space, yielding embeddings for unknown entities. Additionally, a multimodal contrastive objective is incorporated during training to enhance model performance. The framework is designed to be pluggable with any closed-world KGC model. Furthermore, we introduce a new benchmark dataset, CoDEx-Mul, which incorporates both entity images and text descriptions, providing a more realistic simulation of real-world knowledge graphs. Experimental results demonstrate that our model achieves state-of-the-art performance, with improvements of 4-6% over existing methods in the OW-KGC task.},
  archive      = {J_APIN},
  author       = {Wang, Shensi and Fu, Kun and Sun, Xian and Zhang, Zequn and Jin, Li and Shang, Yuying and Yan, Shiyao},
  doi          = {10.1007/s10489-025-06642-8},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {How to learn new knowledge: A multimodal contrastive learning framework for open-world knowledge graph completion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised and semi-supervised learning for few-shot specific emitter identification using CNN-transformer with virtual adversarial training. <em>APIN</em>, <em>55</em>(11), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06645-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Specific emitter identification (SEI) is the process of extracting features from received signals to identify individual emitters, playing a crucial role in enhancing the security of wireless systems. Conventional deep learning-based SEI approaches heavily rely on large-scale datasets, but their performance significantly degrades under few-shot conditions. Existing few-shot SEI methods also face challenges, such as insufficient feature representation learning. In this paper, we propose a novel CNN-Transformer-based framework, FCR-CT (Feature Contrastive Reconstruction with CNN-Transformer), combined with virtual adversarial training (VAT) to improve SEI performance under few-shot conditions. During the pretraining phase, self-supervised learning is employed to optimize the encoder parameters, using a cascade of CNN and Transformer to construct an encoder-decoder structure that reconstructs unlabeled signals. By introducing feature contrastive loss, the model enhances intra-class compactness and interclass separability in the feature space, improving its representation learning capabilities. In the semi-supervised phase, the decoder is replaced with a classifier, and VAT is applied to refine the feature boundaries, further boosting classification accuracy in few-shot scenarios. Experimental results on the open-source ADS-B dataset demonstrate that the proposed FCR-CT(VAT) method achieves a 90.52% average recognition rate across 10 categories, a 1.92% improvement over the model without VAT. For 30 categories with 20 samples each, the recognition rate reached 68.65%, surpassing existing methods such as CVCNN, CNN-MAT, and SA-CNN by more than 5%. These results confirm the effectiveness and robustness of our approach in addressing the challenges of few-shot SEI in practical applications. The code is publicly available at: https://github.com/egglion/FCR-CT-_VAT .},
  archive      = {J_APIN},
  author       = {Sun, Minhong and Wei, Liang and Yu, Chunlai and Qiu, Zhaoyang and Teng, Jiazhong},
  doi          = {10.1007/s10489-025-06645-5},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Self-supervised and semi-supervised learning for few-shot specific emitter identification using CNN-transformer with virtual adversarial training},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple kernel subspace clustering with dual tensors learning. <em>APIN</em>, <em>55</em>(11), 1-11. (<a href='https://doi.org/10.1007/s10489-025-06648-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple kernel clustering (MKC) excels at integrating information from multiple kernels for effective data clustering. Multiple kernel subspace clustering (MKSC) further enhances this by incorporating subspace learning, achieving significant performance improvements. However, most of existing MKSC methods often learn the affinity graphs directly and overlook the rich high-order correlations between different kernels, leading to suboptimal clustering results. This paper introduces MKSC-DT, a novel approach that addresses this limitation by utilizing dual tensors to capture high-order correlations in both feature space and semantic space. MKSC-DT learns multiple new kernels in original feature spaces and projects them onto a clean subspace to generate candidate affinity graphs. These new kernels and candidate graphs are then stacked into two third-order tensors, enabling the exploration of high-order relationships. An efficient alternating optimization algorithm is proposed to solve the resulting objective function. Extensive experiments on benchmark datasets demonstrate the superiority of MKSC-DT compared to state-of-the-art MKC methods, showcasing its effectiveness in leveraging high-order correlations for improved clustering performance.},
  archive      = {J_APIN},
  author       = {Liao, Yinsong and Ren, Zhenwen and Wu, Bin and Zhao, Chunyu},
  doi          = {10.1007/s10489-025-06648-2},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-11},
  shortjournal = {Appl. Intell.},
  title        = {Multiple kernel subspace clustering with dual tensors learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MTAD-kanformer: Multivariate time-series anomaly detection via kan and transformer. <em>APIN</em>, <em>55</em>(11), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06650-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In numerous real-world IoT systems, sensing devices produce vast volumes of multivariate time series data. These infrastructures frequently become targets for cyber-attacks, underscoring the critical importance of anomaly detection in multivariate time series. Previous studies have predominantly addressed non-stationarity through stationarization techniques to facilitate feature extraction. However, this approach can obscure inherent non-stationary patterns, thereby impeding the model’s detection capabilities. Moreover, it has been associated with limitations in nonlinear representation and interpretability. To address these challenges, we introduce MTAD-Kanformer, a novel framework for multivariate time series anomaly detection that integrates the strengths of Transformer architecture with those of the Kolmogorov-Arnold Network (KAN). This combination not only boosts the framework’s capacity to express nonlinear features but also enhances its interpretability. Additionally, we propose the Gaussian De-stationary Attention (GDSA) mechanism, which mitigates the issue of data non-stationarity by integrating learnable Gaussian kernels with de-stationary attention, while simultaneously accentuating the significance of critical time points. Our experimental results demonstrate that MTAD-Kanformer excels on five benchmark datasets for real-world multivariate time series anomaly detection.},
  archive      = {J_APIN},
  author       = {Xie, Xin and Zheng, Wenbin and Xiong, Shenping and Wan, Tao},
  doi          = {10.1007/s10489-025-06650-8},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {MTAD-kanformer: Multivariate time-series anomaly detection via kan and transformer},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CAMFv2: Better, faster and stronger for electrochemiluminescence image denoising. <em>APIN</em>, <em>55</em>(11), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06652-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrochemiluminescence (ECL) is a phenomenon in which light is emitted when an electrochemical reaction occurs in a solution. ECL images are widely used in various fields. However, ECL images often carry considerable unavoidable noise. Prior to using ECL images, denoising it is very important. At present, the simplest and most valuable image denoising method is the center adaptive median filter (CAMF). However, in some images, CAMF does not work very well. There are three main kinds of images: images with excessive noise areas in the light spot, images with large differences in the size of the light spot, and images with different shapes of light spots. To make the CAMF problems easier to solve, we narrow the decision criteria for the current pixels inside and outside the spot, the selection of the filter size threshold, the selection of the nearest spot, the determination of the spot center, etc., and we then propose CAMFv2. Our experiments show that our CAMFv2 is better than CAMF.},
  archive      = {J_APIN},
  author       = {Li, Jun and Yang, Jun and Jiang, Xinhang and Yang, Bing and Chen, Guanyu},
  doi          = {10.1007/s10489-025-06652-6},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {CAMFv2: Better, faster and stronger for electrochemiluminescence image denoising},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Game-theoretic dynamic ensemble for oncogene diagnosis: Integrating neighborhood and precision rough sets. <em>APIN</em>, <em>55</em>(11), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06653-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oncogene diagnosis is a critical field that utilizes oncogene data for disease prognosis and informing treatment strategies. This study introduces an attribute reduction algorithm that combines attribute relevance with neighborhood rough set and variable precision rough set theories, and is carefully optimized for use with nine oncogene diagnosis datasets. To evaluate the effectiveness and performance of our algorithm, we conducted rigorous comparative assessments with a range of machine learning and deep learning algorithms. Additionally, we proposed a dynamic ensemble classifier model based on cooperative game theory, specifically designed for tumor classification and diagnosis. This model leverages the simplified data to improve diagnostic accuracy. Extensive experimental evaluations were conducted, comparing the performance of various algorithms across different datasets. The results highlight the significant advantages and promising applications of our proposed approach in tumor genetic diagnosis. Overall, this study opens a new pathway for tumor genetic diagnosis, demonstrating the ability to enhance diagnostic accuracy and efficiency, and shows that the proposed attribute reduction algorithm has certain advantages over existing rough set-based reduction methods. Comparative analyses with current machine learning and deep learning techniques indicate that our approach exhibits robustness and potential in advancing oncogene diagnosis.},
  archive      = {J_APIN},
  author       = {Xu, Weihua and Zhao, Xinpeng},
  doi          = {10.1007/s10489-025-06653-5},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Game-theoretic dynamic ensemble for oncogene diagnosis: Integrating neighborhood and precision rough sets},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond just saying it’s false: Explainable AI for multimodal misinformation detection. <em>APIN</em>, <em>55</em>(11), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06656-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demand for explainable AI in misinformation detection is crucial for building user trust and understanding model behavior. Many recent methods try to explain how they spot fake news using text, images, or both (multimodal). However, these methods often rely on fixed-size explanations (text and images) generated through ranking-based systems, which fail to effectively differentiate between explainable and non-explainable components. This shortcoming results in vague explanations and limited model performance. To overcome these aforesaid issues, we come up with a multimodal EXplainable misinformation detection method based on ACute Thresholding mechanism (mEXACT) that identifies a variable-size bucket of check-worthy information, when removed, can flip the model’s prediction from fake to real. Identifying minimal set of significant information enables our model to distinguish between contributing and non-contributing misinformation components, thereby enhancing interpretability while improving classification performance. Extensive experiments on two real-world multimodal COVID-19 misinformation datasets, ReCOVery and MMCoVaR, demonstrate that mEXACT significantly outperforms state-of-the-art techniques, achieving $$(6.8-8.7)\%$$ and $$(4.9-5.4)\%$$ higher Accuracy-F1 scores, respectively.},
  archive      = {J_APIN},
  author       = {Roy, Saswata and Bhanu, Manish and Priya, Shalini and Chandra, Joydeep and Dandapat, Sourav Kumar},
  doi          = {10.1007/s10489-025-06656-2},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Beyond just saying it’s false: Explainable AI for multimodal misinformation detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). X modality assisting RGBT object tracking. <em>APIN</em>, <em>55</em>(11), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06658-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing robust multi-modal feature representations is crucial for enhancing object tracking performance. In pursuit of this objective, a novel X Modality Assisting Network (X-Net) is introduced, which explores the impact of the fusion paradigm by decoupling visual object tracking into three distinct levels, thereby facilitating subsequent processing. Initially, to overcome the challenges associated with feature learning due to significant discrepancies between RGB and thermal modalities, a plug-and-play pixel-level generation module (PGM) based on knowledge distillation learning is proposed. This module effectively generates the X modality, bridging the gap between the two patterns while minimizing noise interference. Subsequently, to optimize sample feature representation and promote cross-modal interactions, a feature-level interaction module (FIM) is introduced, integrating a mixed feature interaction transformer and a spatial-dimensional feature translation strategy. Finally, to address random drifting caused by missing instance features, a flexible online optimization strategy called the decision-level refinement module (DRM) is proposed, which incorporates optical flow and refinement mechanisms. The efficacy of X-Net is validated through experiments on three benchmarks, demonstrating its superiority over state-of-the-art trackers. Notably, X-Net achieves performance gains of 0.47 $$\%$$ /1.2 $$\%$$ in the average of precise rate and success rate, respectively. Additionally, the research content, data, and code are pledged to be made publicly accessible at https://github.com/DZSYUNNAN/XNet.},
  archive      = {J_APIN},
  author       = {Ding, Zhaisheng and Li, Haiyan and Hou, Ruichao and Liu, Yanyu and Xie, Shidong},
  doi          = {10.1007/s10489-025-06658-0},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {X modality assisting RGBT object tracking},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image-based instance segmentation dense point cloud multimodal 3D object detection. <em>APIN</em>, <em>55</em>(11), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06661-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D object detection in autonomous driving systems must confront the problem of inaccurate detection of distant and small objects caused by sparse point clouds in complex environments. Especially in complex traffic environments, single-modal detection methods have difficulty meeting the high accuracy requirements. To address this challenge, this paper proposes a novel multimodal 3D object detection algorithm based on densified point clouds via image instance segmentation. The image is first segmented by instance, and then a virtual point cloud is generated based on the instance results and point cloud projection. Moreover, the class scores of the instances are encoded as additional dimensions of the point cloud to enhance the semantic information. This paper introduces dynamic voxel geometry encoding, which adjusts the size and position of the voxels based on the motion changes in the target object. This adjustment enhances the detection of distant and small objects. In addition, this paper presents a new data augmentation technique to effectively improve the training efficiency and detection performance of the model. Extensive experimental verification shows that this model achieves a 6.2% greater mean average precision (mAP) on the KITTI dataset than does the classic multimodal detection method PointPainting; it performs particularly well in detecting pedestrians and cyclists. These results demonstrate the method’s effectiveness and practicality.},
  archive      = {J_APIN},
  author       = {Xu, Yuxiang and Zhang, Rongyun and Shi, Peicheng and Zhou, Bingzhou and Ou, Hongwei and Wang, Rongxiang},
  doi          = {10.1007/s10489-025-06661-5},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Image-based instance segmentation dense point cloud multimodal 3D object detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven models for electricity theft and anomalous power consumption detection: A systematic review. <em>APIN</em>, <em>55</em>(11), 1-32. (<a href='https://doi.org/10.1007/s10489-025-06663-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To maintain the effectiveness, dependability, and security of modern energy systems, analyzing and detecting anomalies in energy usage, such as electricity theft and unusual power consumption, is crucial as Smart Grid (SG) technologies become increasingly common. This survey paper comprehensively reviews the literature on energy consumption analysis and detection, focusing on detecting electricity theft and anomalous power consumption. The works that are considered in this paper are classified based on Machine Learning (ML), Deep Learning (DL), and hybrid models, to identify electricity theft and unusual power usage. Privacy preservation-based methodologies in the context of energy consumption research and summarize the survey articles. Furthermore, datasets used in electricity theft and anomalous power consumption detection, applications, challenges, and limitations related to detecting abnormal power usage and electricity theft are also discussed, and suggested future research paths to push the boundaries of this field of work. This survey study offers a thorough overview of current research trends and directions in energy consumption analysis and detection by synthesizing ideas from various studies. It benefits researchers, practitioners, and policymakers in the energy sector.},
  archive      = {J_APIN},
  author       = {Nayak, Rajesh and C D, Jaidhar},
  doi          = {10.1007/s10489-025-06663-3},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-32},
  shortjournal = {Appl. Intell.},
  title        = {Data-driven models for electricity theft and anomalous power consumption detection: A systematic review},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label sparse self-representation for multi-label learning with missing labels. <em>APIN</em>, <em>55</em>(11), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06664-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recovering the ground-truth label matrix and generating a prediction function for multi-label learning with missing labels is a challenging task. To improve classification performance, label correlation is often leveraged to recover the missing labels. This paper proposes a new multi-label learning approach with missing labels based on label self-representation. In the proposed approach, the self-representation of labels is utilized to explore correlation among labels and recover the missing labels. Meanwhile, known labels are constrained to remain consistent with their ground-truth values during the recovery process. The resulting optimization problem can be efficiently solved using the ADMM method. Experimental results on seven multi-label datasets demonstrate that our algorithm outperforms other state-of-the-art algorithms in multi-label classification with missing labels.},
  archive      = {J_APIN},
  author       = {Xing, Zhiwei and Xi, Langjun and Yang, Xiaofei and Ma, Yingcang},
  doi          = {10.1007/s10489-025-06664-2},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Label sparse self-representation for multi-label learning with missing labels},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSTD: A multimodal vehicle trajectory prediction method based on multi-level spatiotemporal decoupling. <em>APIN</em>, <em>55</em>(11), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06665-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle trajectory prediction is a critical technology in autonomous driving, enhancing decision-making accuracy by forecasting the motion trajectories and behavioral intentions of surrounding agents through deep neural networks. Despite the advances in trajectory prediction models, significant challenges remain: current models inadequately capture the interactions between agents; the complexity of high-dimensional spatiotemporal data hinders feature learning; and trajectory prediction is inherently multimodal-identical historical trajectories can lead to varied future outcomes. To address these issues, this study proposes MSTD, a multimodal trajectory prediction method using multi-level spatiotemporal decoupling and spatiotemporal synchronous graph convolution. MSTD decouples different time series tasks across three levels-temporal, spatial, and spatiotemporal-allowing for the extraction of temporal features, spatial features, and critical spatiotemporal features, thereby enabling potential deep feature extraction from complex spatiotemporal data. To fully capture the interaction information among agents, a Spatial Attention Interaction Module is introduced, employing the multi-head attention mechanism from the Transformer to investigate interactions between vehicles at the same time step. Furthermore, multiple structurally consistent decoders are employed to generate predicted trajectories, with confidence levels accompanying each. The experimental section outlines the model’s parameter configurations and performance evaluations on datasets Argoverse. Results indicate that the minimum Average Displacement Error (minADE) of MSTD achieves 1.15, the minimum Final Displacement Error (minFDE) achieves 0.75, and the Miss Rate (MR) achieves 0.10, demonstrating a significant improvement in prediction accuracy over mainstream algorithms.},
  archive      = {J_APIN},
  author       = {Lu, Xinyu and Chen, Suting and Meng, Yong and Shu, Xiao and Zhou, Xuefen},
  doi          = {10.1007/s10489-025-06665-1},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {MSTD: A multimodal vehicle trajectory prediction method based on multi-level spatiotemporal decoupling},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel cognitive diagnosis system with attention residual mechanism and broad learning. <em>APIN</em>, <em>55</em>(11), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06666-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As machine learning and deep learning gain increasing prominence across diverse domains, the realms of intelligent education and computer-assisted educational technologies are constantly converging, facilitating the development of innovative pedagogical approaches. Simultaneously, with the escalating emphasis on personalized education, traditional test scores alone are no longer sufficient to comprehensively reflect students’ learning status and progress. Cognitive diagnosis aims to uncover the latent cognitive information and skills underlying students’ performance scores. By tapping into the educational data hidden beyond scores, it is possible to gain a deeper and more nuanced understanding of students’ learning profiles and abilities. Consequently, this paper proposes a novel cognitive diagnosis system based on Broad Learning System (BLS). Within this system, an attention residual block is designed to efficiently extract information from interrelated modules, taking into full consideration their interdependencies and correlations. To validate and assess the accuracy of the extracted diagnostic information as well as the rationality and effectiveness of the proposed model, student performance is predicted utilizing the Broad Learning System. Experimental results demonstrate that the proposed system exhibits excellent performance in both the extraction of latent cognitive information and the prediction of student performance.},
  archive      = {J_APIN},
  author       = {Wang, Jing and Miao, Jialin and Duan, Junwei and Jia, Xiping and Lin, Zhiyong},
  doi          = {10.1007/s10489-025-06666-0},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {A novel cognitive diagnosis system with attention residual mechanism and broad learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A spatiotemporal fusion method based on two-stream high temporal sensitive convolutional neural network. <em>APIN</em>, <em>55</em>(11), 1-24. (<a href='https://doi.org/10.1007/s10489-025-06667-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing spatiotemporal fusion is an effective method for generating high spatiotemporal resolution remote sensing images. Current spatiotemporal fusion models use a single pair of coarse-fine resolution images for prediction. They struggle to capture significant changes at the same location over short time intervals. This limitation makes it difficult to achieve high-accuracy image predictions. However, by using two pairs of coarse-fine resolution images for auxiliary prediction, continuous changes in data can be fully utilized, effectively addressing the issue of dramatic image changes. Therefore, this paper proposes the Two-Stream High Temporal Sensitive Convolutional Neural Network (TSCNN). TSCNN introduces the Long-Term Dynamic Capture module (LTDC), which incorporates the temporal variation information extracted from coarse-resolution images into fine-resolution images, enhancing the weight of post-prediction images and preserving the integrity of temporal information, thus reducing the uncertainty of image mutations. To address the issue of inconsistent multiscale features in remote sensing images and improve image accuracy, we design an encoder-decoder structure. The encoder uses a multiscale extraction module to extract features from remote sensing images, expanding the range of contextual information and enhancing the utilization of features at different scales. In the decoder, the Global-Local Attentional Feature Fusion module (GLAFF) is introduced to capture global and local semantic features, which are then fused and reconstructed. This approach improves the completeness of the acquired information. Based on the quantitative results of three datasets, the proposed method improves the quantitative indices of spectral angle mapper (SAM), relative dimensionless global error (ERGAS), correlation coefficient (CC), and structural similarity (SSIM) by up to 0.3360, 0.1111, 0.0308, and 0.0308 at most compared with the best comparison method. TSCNN improves the accuracy of prediction. It has a wide application prospect.},
  archive      = {J_APIN},
  author       = {Li, Yujia and Lei, Dajiang and Zhu, Qianwei and Wang, Junmin and Zhang, Liping and Li, Weisheng},
  doi          = {10.1007/s10489-025-06667-z},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {A spatiotemporal fusion method based on two-stream high temporal sensitive convolutional neural network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Kolmogrov anorld carbon informed network orchestration. <em>APIN</em>, <em>55</em>(11), 1-32. (<a href='https://doi.org/10.1007/s10489-025-06669-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Kolmogorov-Arnold Credit Informed Network Orchestration (KACINO), a novel framework proposed to comprehensively structure and analyze the carbon dynamic system. By synthesizing dynamic processes such as carbon emission and sequestration, a credit information of carbon dynamics is built accumulation, KACINO provides a holistic approach to model the complexities inherent in carbon dynamics. Through systematic analysis and scenario simulations, KACINO facilitates informed policy recommendations aimed at optimizing carbon credit utilization and achieving sustainable environmental outcomes. This paper outlines the theoretical foundation, methodology, and practical applications of KACINO, highlighting its potential to support transformative strategies in climate change mitigation and sustainable development.},
  archive      = {J_APIN},
  author       = {Liu, Charles Z. and Zhang, Ying and Qin, Lu and Hussain, Farookh},
  doi          = {10.1007/s10489-025-06669-x},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-32},
  shortjournal = {Appl. Intell.},
  title        = {Kolmogrov anorld carbon informed network orchestration},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic obstacle avoidance and grasping planning for mobile robotic arm in complex environment based on improved TD3. <em>APIN</em>, <em>55</em>(11), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06671-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the challenges of insufficient dynamic obstacle avoidance capability and limited grasping planning capabilities in complex environments for mobile robotic arms, this paper introduces a hybrid algorithm, COQNLS-TD3(GRU)-PER. This algorithm integrates the modified Constrained Optimization Quasi-Newton Least Squares (COQNLS) method with the enhanced Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm, which is further augmented by incorporating the Gated Recurrent Unit (GRU) module and a Prioritized Experience Replay mechanism (PER). Initially, COQNLS planning is designed for the robotic arm to obtain the pre-grasp posture. Subsequently, the problem is defined as a Markov Decision Process involving the design of state space, action space, and reward-penalty functions. Subsequently, the GRU module is integrated into the neural network to process temporal state space features, thus enhancing dynamic obstacle avoidance capabilities. The planning process unfolds in phases: the dynamic obstacle avoidance phase is driven by training with TD3(GRU), and the target planning phase is steered by the pre-grasp posture, complemented by a cooperative guidance mechanism for transitional control outputs. To enhance training sample efficiency and accelerate algorithm convergence, a Prioritized Experience Replay mechanism is incorporated, facilitating the efficient development of an effective policy model for planning. Finally, to validate the efficacy of the proposed algorithm, a three-dimensional experimental scenario is designed for comparative experiments with other algorithms. Experimental results reveal that compared to the traditional TD3 algorithm, the COQNLS-TD3(GRU)-PER algorithm offers substantial improvements in both training efficiency and the control performance of the policy model.},
  archive      = {J_APIN},
  author       = {Li, Yong and Ke, Linbing and Zhang, Chaoxing},
  doi          = {10.1007/s10489-025-06671-3},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Dynamic obstacle avoidance and grasping planning for mobile robotic arm in complex environment based on improved TD3},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DaptDiffusion: Enhancing pixel-level interactive editing with dense-UNet and adam point update in diffusion models. <em>APIN</em>, <em>55</em>(11), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06673-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a substantial amount of projects focused on the difficult task of editing images in a way that is both accurate and manageable. In image editing, pixel-level interactive editing is one of the research directions. A typical paradigm for interactive editing is proposed by the point-based editing framework that is represented by DragGAN (Pan et al. 2023). In more recent times, the integration of drag operations and interactive editing, along with the generative abilities of diffusion models, has resulted in the development of even more superior solutions (Shi et al. 2024). The generation impact of this strategy, on the other hand, continues to be plagued by problems of low editing efficiency and low resilience of the procedure. The purpose of this work was to propose a new technique called DaptDiffusion, which aims to enhance the process of editing latent space based on diffusion model by introducing two extra strategies. 1) a Dense-UNet latent space feature network, and 2) a point update approach that was inspired by Adam. In addition to enhancing the editing efficiency and robustness of the approach, this method also improves the semantic and information transmission capabilities of the latent space feature network. We conduct experiments to illustrate the high quality and high usefulness of DaptDiffusion in many different circumstances. The graphic abstract can be shown in Fig. 1. Accessible source code can be found at the following location: https://github.com/Gdw040199/DaptDiffusion},
  archive      = {J_APIN},
  author       = {Guan, Dawei and Li, Wei},
  doi          = {10.1007/s10489-025-06673-1},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {DaptDiffusion: Enhancing pixel-level interactive editing with dense-UNet and adam point update in diffusion models},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pulse-strategy collective learning swarm optimizer for large-scale global optimization. <em>APIN</em>, <em>55</em>(11), 1-30. (<a href='https://doi.org/10.1007/s10489-025-06674-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social Learning Particle Swarm Optimization (SLPSO) is an advanced variant of the PSO algorithm, designed to enhance optimization performance in Large-Scale Global Optimization (LSGO) problems. However, SLPSO encounters significant challenges, particularly in maintaining a balanced trade-off between exploration and exploitation, which limits its effectiveness in complex optimization tasks. In response to these limitations, this paper proposes the Pulse-based Collective Learning Swarm Optimizer (PCLSO). The PCLSO introduces two key innovations: collective learning, which replaces the traditional average position updates in SLPSO, thereby enhancing exploration by leveraging knowledge from multiple high-quality particles; and a pulse-strategy, which addresses convergence stagnation by dynamically perturbing the global best solution to improve exploitation capabilities. Extensive experimental evaluations on the CEC’2010 and CEC’2013 benchmark suites demonstrate that PCLSO significantly outperforms SLPSO, as well as several advanced and classical PSO and DE variants, and the latest cooperative coevolutionary (CC)-based algorithms. Furthermore, to validate its practical applicability, PCLSO is applied to the biological Multiple Sequence Alignment (MSA) problem using Hidden Markov Models (HMM), where it exhibits superior performance compared to other state-of-the-art metaheuristic algorithms. In summary, the study presents a robust optimization tool that advances the field of LSGO and shows promise for addressing complex real-world optimization challenges. The source code of the PCLSO algorithm is publicly available at https://github.com/tsingke/PCLSO .},
  archive      = {J_APIN},
  author       = {Liu, Xiaoyu and Zhang, Qingke and Pang, Shuzhao and Sun, Jiajun and Zhang, Huaxiang},
  doi          = {10.1007/s10489-025-06674-0},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-30},
  shortjournal = {Appl. Intell.},
  title        = {Pulse-strategy collective learning swarm optimizer for large-scale global optimization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised deep clustering for spammer group detection. <em>APIN</em>, <em>55</em>(11), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06675-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-commerce platforms face the issue of spammer groups that post many fraudulent reviews within a certain period. This practice misleads consumers and undermines fair competition among merchants. Researchers have proposed various methods to combat these spammers. However, these methods typically handle user feature representation and candidate group division independently, lacking an effective feedback mechanism between the two. Moreover, the vast discrepancy in the number of negative samples compared to positive samples in the data leads to reduced recognition accuracy in detection models, affecting the precision of detection outcomes. Therefore, we propose a spammer group detection method based on self-supervised deep clustering. Initially, the relationship between user review timing and product ratings is extracted from user review data, and user relevance is calculated and used as weights to construct a weighted user relationship graph. Subsequently, we integrate deep learning models with clustering algorithms to propose a self-supervised deep clustering model that jointly optimizes user representation and clustering distribution. This model employs graph and node autoencoders to capture global structural information and local preference information of user nodes, respectively, and designs a linear fusion method to enhance user feature representation. Additionally, we construct a reliable target distribution and introduce Kullback-Leibler(KL) divergence to form a self-supervised mechanism, continuously optimizing feature representation and clustering assignment to refine high-quality candidate groups. Finally, we propose an anomaly detection method based on the Gaussian Mixture Model (GMM), which designs a filtering mechanism to improve the detection efficiency of spammer groups. Experiments indicate that the proposed method outperforms baseline methods on the Amazon, Yelp, and YelpChi datasets.},
  archive      = {J_APIN},
  author       = {Wang, Changwu and Feng, Zhongkai and Zhang, Kun and Zhang, Fuzhi},
  doi          = {10.1007/s10489-025-06675-z},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Self-supervised deep clustering for spammer group detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FTA-DFI: A framework for generalizable deepfake detection based on distinctive features from various manipulations compared to genuine images. <em>APIN</em>, <em>55</em>(11), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06677-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deepfakes have attracted considerable attention due to their detrimental impact, notably the production of convincing fake images and their unregulated dissemination. However, existing detectors suffer from a common defect that obsessing with low-level local artifacts or predefined forgery patterns while neglecting the intrinsic differences between the forged and genuine images. This leads to significant performance decline when the model encounters with unseen domains and forgeries. To address this issue, this paper proposes a novel framework, named as FTA-DFI, which leverages disentanglement learning and adversarial learning to analyze forgery traces amplified from the perspective of key facial features and frequency domain. FTA-DFI consists of the Fake Trace Amplification Strategy (FTAS) and the Distinctive Feature Identification Strategy (DFIS). FTAS suppresses method-specific features and identity information using the Face Features Random Mask and amplifies manipulated artifacts through the Frequency Domain Converter. DFIS employs the Feature Separation Disentangler and Intrinsic-Adversarial Learning modules to discern distinctive features between fake and genuine images, thereby further mitigating the overfitting of forgery-irrelevant information and specific forgery approaches. Extensive experimental results demonstrate that FTA-DFI outperforms current state-of-the-art models in generalization evaluations across mainstream datasets, validating the superior performance of the proposed architecture in terms of generalization capability. The code is available at https://github.com/zouzhengcs/FTA-DFI .},
  archive      = {J_APIN},
  author       = {Zou, Zheng and Peng, Dunlu and Zhao, Yu and Tian, Zekun and Cai, Jun},
  doi          = {10.1007/s10489-025-06677-x},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {FTA-DFI: A framework for generalizable deepfake detection based on distinctive features from various manipulations compared to genuine images},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic dual mining framework for long-tailed out-of-distribution detection. <em>APIN</em>, <em>55</em>(11), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06679-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting out-of-distribution inputs is critical for the reliable and safe deployment of deep learning models in open-world environments. However, most out-of-distribution detection methods rely on the strict assumption of data balance, overlooking the reality that data often follows a long-tailed distribution in real scenarios, which negatively impacts model performance. To overcome this issue, we propose the Dynamic Dual Mining (DDM) framework, which optimally utilizes existing data by performing dual mining on in-distribution data and auxiliary outliers. DDM applies a stronger penalty to hard in-distribution samples and employs prototype-based mining strategy for outliers. Extensive experiments demonstrate that DDM effectively addresses the challenges of long-tailed out-of-distribution detection, achieving state-of-the-art results on CIFAR-10-LT and CIFAR-100-LT, while also exhibiting superior performance on the large dataset ImageNet-200-LT.},
  archive      = {J_APIN},
  author       = {Sheng, Bin and Pan, Dengye and Li, Xiaoqiang},
  doi          = {10.1007/s10489-025-06679-9},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Dynamic dual mining framework for long-tailed out-of-distribution detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal anomaly detection for microservice system through nested graph diffusion reconstruction. <em>APIN</em>, <em>55</em>(11), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06681-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately detecting anomalies in microservice systems has become increasingly important for rapidly growing microservice architectures. On the one hand, existing anomaly detection methods typically focus on a single type of data source (i.e., logs or traces) or overlook the correlations between different types of data, which can lead to missed anomalies and a high number of false positives. On the other hand, regarding the issue of imbalanced positive and negative samples in anomaly detection, existing research has not proposed effective solutions. To address these issues, in this paper, we propose MSNGAD, a microservice anomaly detection method based on nested graph diffusion reconstruction. MSNGAD uses nested graphs to uniformly describe the complex structure of traces and embedded log messages. It treats the log template temporal relationships as the inner graph of the nested graph, and the service invocations relationships as the outer graph. By capturing the correlations between different modalities of data, the system can detect anomalies comprehensively. Furthermore, to address the problem of imbalanced positive and negative samples in anomaly detection, MSNGAD trains a diffusion reconstruction model to augment the features of anomalous samples. This approach abandons traditional manual data augmentation strategies, effectively mitigating the unnatural disturbances to the graph structure caused by human intervention in data augmentation. Extensive evaluations were conducted on large-scale datasets, and the experimental results show that MSNGAD outperforms existing baseline models, achieving an F1-score of 0.96.},
  archive      = {J_APIN},
  author       = {Fan, Mengwei and Zhang, Xiuguo and Wang, Peipeng and Cao, Zhiying},
  doi          = {10.1007/s10489-025-06681-1},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Multi-modal anomaly detection for microservice system through nested graph diffusion reconstruction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural robust optimal tracking control for nonlinear state-constrained systems with input saturation and external disturbances. <em>APIN</em>, <em>55</em>(11), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06682-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenging problem of designing robust optimal tracking control for a class of nonlinear uncertain systems subjected to full-state constraints, input saturation and external disturbances. First, by leveraging neural network identification and nonlinear disturbance observation techniques, we develop a composite observer framework that enables the decoupling and simultaneous estimation of both uncertain dynamics and lumped disturbances. Second, to tackle the issue of input saturation in control design, a smooth approximation function is introduced in conjunction with an auxiliary variable to mitigate its adverse effects on system performance. Third, a novel barrier-type cost function, derived from barrier Lyapunov functions (BLFs), is proposed. This cost function incorporates both the tracking error and its derivative, effectively overcoming the unbounded nature of the traditional input quadratic cost function in tracking control over an infinite time horizon. Moreover, unlike typical actor-critic paradigms, the critic-only adaptive dynamic programming (ADP) algorithm with the novel barrier-type cost function is employed for each subsystem to determine the optimal virtual and actual controls, which together with the disturbance compensation signals constitute the corresponding robust optimal control schemes. Using Lyapunov’s direct method, it is proven that all closed-loop signals are semi-globally uniformly ultimately bounded, and the tracking error converges to a small neighborhood of the origin without transgressing any state constraints. Finally, the effectiveness of the proposed approach is further validated through simulation results.},
  archive      = {J_APIN},
  author       = {Huang, Yuzhu and Zhang, Zhaoyan and Zhao, Shuo},
  doi          = {10.1007/s10489-025-06682-0},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Neural robust optimal tracking control for nonlinear state-constrained systems with input saturation and external disturbances},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SC-COO: A feedback-based service composition algorithm combining offline and online reinforcement learning. <em>APIN</em>, <em>55</em>(11), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06683-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Faced with the current dynamic service environment, rapid and efficient service composition has attracted much attention in recent years. The service composition could complete the reuse of existing services and its ultimate goal is to better satisfy users. However, it is challenging to interact with the service environment to collect data in practical applications due to factors such as high cost and risk. To overcome this limitation, this paper proposes the SC-COO method: A feedback-based service composition algorithm combining offline and online reinforcement learning. The SC-COO method mainly consists of two stages: the offline training module (SC-COO-offline) is the main stage, and the online update module (SC-COO-online) is the auxiliary stage. The SC-COO-offline model is trained through collected offline data, avoiding the drawback of online learning requiring multiple iterations to converge. And online training (SC-COO-online) serves as an auxiliary stage to jointly make decisions and recommend services to users to better adapt to dynamic environments. Furthermore, our SC-COO method offers users’ score preferences in service composition by designing a feedback-based reward mechanism. Continuous interactive feedback with humans can significantly improve the robustness of the service composition system. Finally, some experiments on the RapidAPI dataset demonstrate that SC-COO outperforms other baselines in accuracy, scalability, and convergence. And some results of the ablation experiment also verify the efficiency and applicability of SC-COO.},
  archive      = {J_APIN},
  author       = {Yu, Xiaoming and Wu, Wenjun and Wang, Jiadong and Ji, Xin},
  doi          = {10.1007/s10489-025-06683-z},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {SC-COO: A feedback-based service composition algorithm combining offline and online reinforcement learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Res2coder: A two-stage residual autoencoder for unsupervised time series anomaly detection. <em>APIN</em>, <em>55</em>(11), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06684-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting anomalies in multivariate time series data is crucial for various industries. However, the increasing volume and dimensionality of data have driven up the cost of data labeling, making supervised or semi-supervised methods less effective. Unsupervised learning methods, which do not require labeled training data, have steadily gained importance due to their ability to reduce data processing costs. This paper proposes an unsupervised multivariate time series anomaly detection method - Res2coder. It decomposes time series data into trend and residual components for separate reconstruction, and incorporates frequency-domain analysis. Res2coder uses an MLP-based autoencoder module to reconstruct each component. Additionally, two error feedback mechanisms are designed in the reconstruction module to enable the model to more accurately capture the features and changing patterns of the data. This approach improves detection accuracy and reduces model training costs without relying on complex networks like convolutions or attention mechanisms. We compare Res2coder with several baseline models (e.g., TranAD and ATF-UAD) on six datasets (e.g., SWaT, WADI, and SMD). It achieves higher scores in six evaluation metrics—precision, recall, F1, ROC/AUC, Composite F-score (Fc1), and Real Under Point Adjustment %K Curve (PA%K). Moreover, Res2coder reduces training time by 50% to 90%.},
  archive      = {J_APIN},
  author       = {Wang, Hao and Liu, Yingjian and Yin, Haoyu and Zheng, Xiangyun and Zha, Zonghai and Lv, Minghuan and Guo, Zhongwen},
  doi          = {10.1007/s10489-025-06684-y},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Res2coder: A two-stage residual autoencoder for unsupervised time series anomaly detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving crowdsourced label quality by peer-to-peer federated learning. <em>APIN</em>, <em>55</em>(11), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06686-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourcing can help supervised learning obtain large quantities of labeled data. There are some issues with existing crowdsourcing methods from a user or a platform perspective. From the user perspective, annotating all data on only one crowdsourcing platform will make it difficult to guarantee his privacy as the platform has complete data. Furthermore, as the label quality is completely controlled by only one platform, the user then has difficulty to reject even the annotation quality is very poor. From the platform perspective, due to commercial secrets and privacy, data cannot be shared among crowdsourcing platforms, making it difficult to form a joint effort to improve label quality. In this study, we propose a new algorithm for crowdsourcing noise correction based on label distribution (LDNC) and further propose a new peer-to-peer federated learning (P2P-LDNC) algorithm to solve the above issues. Experiments show that the algorithms can collaboratively train multiple crowdsourcing platforms in a distributed environment, effectively improving the label quality.},
  archive      = {J_APIN},
  author       = {Lu, Xiangming and Qian, Jiangbo and Wang, Chong and Yan, Diqun and Zhang, Youhui},
  doi          = {10.1007/s10489-025-06686-w},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Improving crowdsourced label quality by peer-to-peer federated learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ISSMLCF: An inductive semi-supervised multi-label learning algorithm with co-forest paradigm. <em>APIN</em>, <em>55</em>(11), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06688-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label learning aims at training accurate predictive models to recognize the instance with multiple potential class labels. In this scenario, it is more difficult to collect sufficient labeled instances as each instance requires being annotated with several labels. Considering it is possibly easy to collect lots of unlabeled instances, but labeling them is expensive, the semi-supervised learning can be combined with multi-label data to be a leverage between the quality of predictive models and labeling costs. In this study, a novel semi-supervised multi-label learning algorithm called the inductive semi-supervised multi-label learning algorithm based on co-forest paradigm (ISSMLCF) was proposed. Specifically, the proposed ISSMLCF algorithm uses both instance bootstrap and random feature split techniques to promote the diversity among base learners in co-forest, adopts thresholds calibration strategy to improve the predictive performance of base learning model, and integrates three confidence measures, namely prediction disagreement, label cardinality consistency, and label correlation consistency, to communicate confidential instance and label information among classifiers during the iterative process of co-forest. To guarantee the stability and avoid an excessive of error accumulation during semi-supervised learning, a n-Top communication strategy based on confidence threshold is used by the ISSMLCF algorithm. Experimental results conducted on eight benchmark multi-label datasets show that the proposed ISSMLCF algorithm can not only produce better classification performance, but also consume less training time than several SOTA algorithms which include both transductive and inductive ones.},
  archive      = {J_APIN},
  author       = {Liu, Wenhao and Duan, Jicong and Shao, Changbin and Yang, Xibei and Xu, Sen and Yu, Hualong},
  doi          = {10.1007/s10489-025-06688-8},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {ISSMLCF: An inductive semi-supervised multi-label learning algorithm with co-forest paradigm},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new class correlation-based dynamic sample weighting method for medical image classification. <em>APIN</em>, <em>55</em>(11), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06690-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have achieved remarkable success in medical image classification tasks, but the performance of DNN-based methods in medical scenarios remains limited. Sample weighting has shown substantial promise in addressing this issue by assigning weights for each sample to assess its importance. However, existing methods rely on individual samples for weighting and neglect the relationships among samples, which limits their potential in medical image classification. To this end, we propose a new Class Correlation-based Dynamic Sample Weighting (CC-DSW) framework for medical image classification. CC-DSW model sample relationships both in feature and label space by leveraging the intra-class and inter-class correlations, capturing intra-class consistency and inter-class separability. It then maps the class correlations to the sample weights through a learnable sample weighting network, allowing for automatic weight assignment during training. The sample weighting network and the task network are optimized alternately using meta-learning for mutual adaptation. We evaluate the effectiveness of our method on three medical image classification benchmarks: PatchCamelyon for lymph node histopathology classification, ISIC 2020 for skin lesion classification, and MTC for medullary thyroid carcinoma classification. CC-DSW outperforms existing state-of-the-art sample weighting methods across all three datasets and significantly exceeds methods without sample weighting. Compared with the ACC, F1 and AUC of the baseline, our proposed CC-DSW improves by 5.00%, 4.61% and 3.23% in PCam, 2.30%, 1.81% and 2.62% in ISIC 2020, and 5.63%, 6.88% and 3.55% in MTC. Experimental results demonstrate that CC-DSW leverages class correlation for dynamic weighting, which makes the model focus on samples at the decision boundary and improves the performance in medical image classification tasks.},
  archive      = {J_APIN},
  author       = {Yi, Guanxiu and Ma, Ling and Liu, Xiabi and Hai, Zhaoyang and Li, Yunlong and Han, Mengqiao and Chao, Yang and Niu, Lijuan and Song, Yuehao},
  doi          = {10.1007/s10489-025-06690-0},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {A new class correlation-based dynamic sample weighting method for medical image classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reducing the value function over-estimation by kullback-leibler divergence regularized distributional actor-critic. <em>APIN</em>, <em>55</em>(11), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06693-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a novel distributional reinforcement learning (RL) approach, Kullback-Leibler Divergence regularized Distributional Actor-Critic (KDAC), to simultaneously address two fundamental challenges in off-policy RL: value function overestimation bias and accumulated approximation errors. Unlike existing multi-critic solutions, clipping the high-value quantiles in the distributional value function enables KDAC to suppress overestimation with a single critic network. Additionally, we introduce Kullback-Leibler divergence regularization between current and previous policies to mitigate accumulated approximation errors. The proposed lightweight KDAC efficiently reduces overestimated values while accelerating and stabilizing the learning process, ultimately enhancing sample efficiency. We evaluate on several benchmark tasks with different levels of complexity, where KDAC demonstrates significant competitive advantage in learning capability, overestimation reduction and sample efficiency compared with various traditional and advanced RL baselines, expanding the potential for more complicated control scenarios.},
  archive      = {J_APIN},
  author       = {Gong, Mingrong and Yi, Zhengkun and Chen, Yidong and Li, Huiyun and Cui, Yunduan},
  doi          = {10.1007/s10489-025-06693-x},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Reducing the value function over-estimation by kullback-leibler divergence regularized distributional actor-critic},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel path planning scheme based on fast-IBi-RRT* algorithm for industrial robots. <em>APIN</em>, <em>55</em>(11), 1-12. (<a href='https://doi.org/10.1007/s10489-025-06694-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The informed bidirectional rapidly-exploring random tree (IBi-RRT*) algorithm, in path planning for robotic arms in complex environments, has some drawbacks such as high path cost, excessive redundant nodes, long planning time, and low path smoothness. To this end, in this paper we propose a Fast-IBi-RRT* algorithm, which enhances the previous IBi-RRT* algorithm in both the sampling and path parts. In regard to the sampling component, two additional strategies have been incorporated: probabilistic target point region sampling and redundant node deletion. Meanwhile, two strategies have been introduced for the path section: an adaptive step size strategy and a reconnecting grandfather node strategy. To illustrate the efficiency and practicality, the Fast-IBi-RRT* algorithm is simulated in three different environments, and applied to an industrial robot arm. The experimental results demonstrate that the proposed Fast-IBi-RRT* algorithm can track a superior path with shorter planning time, lower path cost, and better path smoothness.},
  archive      = {J_APIN},
  author       = {Zhang, Miao and Liu, Shengwei and Zhou, Quan and Han, Xiaoguang},
  doi          = {10.1007/s10489-025-06694-w},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {A novel path planning scheme based on fast-IBi-RRT* algorithm for industrial robots},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TFFC: Time-frequency fusion consistency for semi-supervised time series classification. <em>APIN</em>, <em>55</em>(11), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06695-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning (SSL) time series classification (TSC) is more in line with actual data scenarios. Existing methods have gradually transitioned from focusing only on time-domain features to exploring time-frequency invariant representations via contrastive learning. In this paper, we find class invariance between time-domain and frequency-domain features. Therefore, we propose a semi-supervised Time-Frequency Fusion Consistency (TFFC) model for Time Series Classification (TSC). Specifically, for the labeled data, we conduct supervised TSC training. For the unlabeled data, we design a fine-grained time-frequency fusion consistency strategy and use the confidence prediction of the classifier on the time-domain features to generate pseudo-labels for constraining the class invariance of temporal and fused features. Meanwhile, we design a trick of domain discrepancy minimization to mitigate the confirmation bias of the classifier due to the imbalance of labeled/unlabeled data in SSL. We perform TSC experiments on eight time series datasets with different characteristics. TFFC significantly outperforms the state-of-the-art baselines in all cases of labeled/unlabeled data on each dataset, and has an overall mid-range classification efficiency, which could verify the effectiveness of TFFC.},
  archive      = {J_APIN},
  author       = {Xi, Liang and Meng, Xianglong and Liu, Han},
  doi          = {10.1007/s10489-025-06695-9},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {TFFC: Time-frequency fusion consistency for semi-supervised time series classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SFNS: Spatial-frequency image noise suppression for low-power industrial cone-beam computed tomography. <em>APIN</em>, <em>55</em>(11), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06703-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread use of industrial computed tomography (CT) in semiconductor manufacturing, the noise in tomographic images from low-power radiation sources has become an increasingly prominent issue, which severely impacts the detection and processing tasks. In this paper, a spatial-frequency image noise suppression model (SFNS) is proposed to suppress noise while maintaining structural details in the image. A hybrid loss with spatial-frequency dual-domain information is designed to resolve spatial-domain limitations in optimization through complex-discrepancy-based spherical region separation criterion. To address the coupled noise characteristics in low-power CT systems, a stochastic noise degradation training strategy is designed to dynamically emulate fluctuations in real noise environments, and the network architecture integrates checkerboard sampling with cascaded residual stacks to enhance detail perception and reduce computational overhead. Experimental results demonstrate that SFNS achieves PSNR 32.14dB and SSIM 0.8896. Both quantitative metrics and qualitative evaluations validate the effectiveness of the proposed method in balancing structural fidelity and noise suppression.},
  archive      = {J_APIN},
  author       = {Zhu, Yimin and Wu, Xing and Yao, Junfeng and Qian, Quan and Song, Jun and Gao, Shouwei},
  doi          = {10.1007/s10489-025-06703-y},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {SFNS: Spatial-frequency image noise suppression for low-power industrial cone-beam computed tomography},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Capturing spatio-temporal patterns of falls individuals using efficient graph convolutional network model. <em>APIN</em>, <em>55</em>(11), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06316-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Falls are a major worldwide health concern among people, and the ability to detect and prevent falls can have significant implications for their safety and well-being. This paper uses an Efficient-Graph Convolutional Network (Efficient-GCN) model to extract discriminative features of fall actions. The proposed model is designed to handle the complex and dynamic nature of human movements during a fall event. The main problem in fall events is to capture spatiotemporal information that results from falls, plus the insufficient data size for training. To address this problem, we suggest a protocol to collect a fall dataset. The Kinect camera is used to collect skeleton data, which is then processed using the Efficient-Graph Convolutional Network (Efficient-GCN) algorithm to identify fall individual patterns. We present a comparative study between three methods Efficient-Graph Convolutional Network (Efficient-GCN), Support Vector machine (SVM), and k-nearest neighbor (KNN) for improving skeletal-based fall detection and deep convolutional neural network (DCNN) for depth data. To have a more global view we compare our results with public dataset on the three baselines variant noted as Baseline coefficient (Bx) where “x” denotes scaling coefficient, where Efficient-Graph Convolutional Network Baseline with coefficient 2 (Efficient-GCN-B2) on our collected dataset outperforms achieving 98,50% accuracy on the cross-subject. The Efficient-Graph Convolutional Network with coefficient 2 (Efficient-GCN-B2) algorithm achieves remarkably satisfactory results in detecting fall events on the robust representation which is a skeleton and Deep Convolutional Neural Network (DCNN) attains 97% on depth data.},
  archive      = {J_APIN},
  author       = {Guendoul, Oumaima and Zobi, Maryem and Ait Abdelali, Hamd and Tabii, Youness and Oulad Haj Thami, Rachid and Bourja, Omar},
  doi          = {10.1007/s10489-025-06316-5},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Capturing spatio-temporal patterns of falls individuals using efficient graph convolutional network model},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive weighted noise constraint-based low-rank representation learning for robust multi-view subspace clustering. <em>APIN</em>, <em>55</em>(11), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06502-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-rank representation is popular and effective in multi-view subspace clustering. It explores the comprehensive correlation relationships to characterize the intrinsic structure of multi-view data. However, most existing methods are limited by the performance of rank approximation and ignore the adaptability of noise, resulting in unstable clustering performance and weak generalization ability in practical applications. To tackle the mentioned issues, we propose a robust multi-view subspace clustering algorithm based on credible rank approximation and adaptive noise penalty matrix (RLRMVSC). Specifically, RLRMVSC explores the consistency and diversity of different views and proposes a higher-order rank approximation function to optimize low rank constraints. At the same time, the adaptive penalty matrix is introduced to describe the impact of noise on multi-view data. It can be done without the prior knowledge of noise and therefore reduces the dependence on noise types. The augmented Lagrange multiplier method is utilized to solve the proposed RLRMVSC model. The experiments on six real-world datasets have demonstrated the effectiveness of RLRMVSC.},
  archive      = {J_APIN},
  author       = {Liu, Xiaolan and Wu, Wenyuan and Xie, Mengying},
  doi          = {10.1007/s10489-025-06502-5},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive weighted noise constraint-based low-rank representation learning for robust multi-view subspace clustering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). R2GAN: Enhancing unseen image fusion with reconstruction-guided generative adversarial network. <em>APIN</em>, <em>55</em>(11), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06610-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) have gained prominence in computer vision, with applications that extend to image fusion. Existing fusion methods often require extensive labeled data and task-specific training, limiting their generalizability. To address these limitations, this paper presents the Reconstruction-Guided Generative Adversarial Network (R2GAN), a generic GAN-based approach designed for generic image fusion, including visible-infrared, medical, and multi-focus image fusion. The proposed R2GAN architecture consists of a primary generator to improve fusion capabilities and auxiliary generators to ensure accurate reconstruction of source image features. To optimize the model, we propose a reconstruction-guided loss function to preserve the feature distribution of the source images and improve the consistency between the fused and source images. Additionally, we introduce a semantic segmentation-guided approach to generate a comprehensive and realistic Paired Multi-Focus image dataset (PMF) to train the R2GAN model. Experimental results in multiple fusion tasks demonstrate that R2GAN delivers superior performance, outperforming state-of-the-art image fusion methods. The R2GAN framework source code is available for access on GitHub at https://github.com/CHAHI24680/R2GAN .},
  archive      = {J_APIN},
  author       = {Chahi, Abderrazak and Kas, Mohamed and Kajo, Ibrahim and Ruichek, Yassine},
  doi          = {10.1007/s10489-025-06610-2},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {R2GAN: Enhancing unseen image fusion with reconstruction-guided generative adversarial network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Textual similarity calculation techniques in the medical field: A retrospective review. <em>APIN</em>, <em>55</em>(11), 1-31. (<a href='https://doi.org/10.1007/s10489-025-06634-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration and application of digital technology in the medical field are accelerating the development of medical technology and generating a large amount of information resources. Such information resources are characterized by large-scale, heterogeneous, and scattered distribution, including medical guidelines, academic literature, electronic medical records, medical databases, and diagnostic reports. Text similarity computing is an intelligent technology that mines intrinsically related information, supports the integration of medical digital resources, explores the potential value of medical data, and directly or indirectly promotes the development of medical research, clinical diagnosis, and decision support technology. With the development of artificial intelligence technology and large models, medical text similarity computation has achieved remarkable results with this support. Similarity calculation, from the original string rule template matching to today’s highly accurate neural network models, has achieved significant performance improvements. Throughout the medical field, text similarity computing has achieved significant results in advancing the development of medicine and improving the doctor-patient relationships. Text similarity computing in the medical field also provides the basis and necessary foundation for the intelligent development of medical treatment in the new era. In this paper, we systematize the development of text similarity computation in the medical field and comprehensively review more than 200 related studies. We summarize and compare the traditional statistical methods, machine learning, and neural network models for medical text similarity computation. In particular, typical cases are analyzed for each text similarity computation method in the medical field to highlight their advantages and potential research value. In this paper, after an extensive surveys and summary, we discuss the research methods of text similarity computation in the medical field, commonly used datasets, and the analysis of the research results. Finally, it summarizes and looks forward to the future development of text similarity computing in the medical field.},
  archive      = {J_APIN},
  author       = {Cui, Hongzhen and Wang, Shichao and Ma, Haoming and Zhu, Xiaoyue and Zhang, Longhao and Piao, Meihua and Peng, Yunfeng},
  doi          = {10.1007/s10489-025-06634-8},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-31},
  shortjournal = {Appl. Intell.},
  title        = {Textual similarity calculation techniques in the medical field: A retrospective review},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-free sliding mode resilient control of cyber-physical system based on reinforcement learning. <em>APIN</em>, <em>55</em>(11), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06649-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the security control issue of intelligent terminals undergoing changes due to task variations, a model—free sliding mode (SM) resilient controller is developed for uncertain nonlinear cyber—physical systems (CPSs) under the influence of Denial—of—Service (DoS) attacks and False Data Injection (FDI) attacks. Firstly, the unified mathematical model of cyber—attacks is formulated. An initial—value error conversion function is incorporated to transform the error with an arbitrary initial value into a variable having an initial value of zero. Subsequently, a reinforcement learning (RL) algorithm built on a single hidden—layer neural network is constructed. This algorithm is capable of real—time estimation of the CPS model and perturbation, which exhibits strong time—varying characteristics. Leveraging the prescribed performance control method (PPCM) and the predefined time convergence (PTC) theory, a novel model—free sliding mode resilient controller is designed for the CPS under cyber—attacks. The predefined time convergence of the control system is rigorously proven through theoretical analysis. Simulation results indicate that this control strategy can guarantee that the CPS with an arbitrary initial state converges to the desired trajectory within the specified time. Moreover, the trajectory tracking error satisfies the prescribed performance requirements. The steady—state error is less than 0.0008, and the intensity of cyber—attacks has no impact on the control effectiveness.},
  archive      = {J_APIN},
  author       = {Yin, Chun-Wu},
  doi          = {10.1007/s10489-025-06649-1},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Model-free sliding mode resilient control of cyber-physical system based on reinforcement learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-UAV intelligent decision-making method with layer delay dual-center MAPPO for air combat. <em>APIN</em>, <em>55</em>(11), 1-24. (<a href='https://doi.org/10.1007/s10489-025-06654-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative air combat involving multiple Unmanned Aerial Vehicles (Multi-UAV) represents a significant evolution in the future of warfare. While the Multi-Agent Proximal Policy Optimization (MAPPO) algorithm demonstrates strong performance in intelligent air combat decision-making tasks, its fixed policy characteristics during online learning may lead to overestimation issues during the training and optimization process, thereby reducing policy reliability and slowing convergence. Additionally, environmental complexity and unpredictability may lead to error accumulation in the decision-making process, making it difficult for agents to generate effective decisions. This significantly increases training difficulty, which is further exacerbated by the inherent randomness of reinforcement learning. To address these challenges, this paper proposes an improved decision-making method, Multi-Agent Proximal Policy Optimization based on Layer Delay Dual-Center (MAPPO-LDC). This approach employs dual-center critic networks to curb policy overestimation, introduces a delayed update strategy to reduce errors caused by critic network fluctuations in early training stages, and designs a layered training strategy to progressively increase task complexity. This structured approach thereby enables agents to adapt to the environment incrementally and enhances training efficiency. Experimental results indicate that compared to MAPPO, the MAPPO-LDC algorithm achieves an 89% improvement in win rate (peaking at 93%) and an 84% reduction in draw rate, further demonstrating the potential and value of the proposed method.},
  archive      = {J_APIN},
  author       = {Ding, Zhengkun and Wang, Xingmei and Cai, Chengtao and Jia, Luyu and Xu, Zhou},
  doi          = {10.1007/s10489-025-06654-4},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {Multi-UAV intelligent decision-making method with layer delay dual-center MAPPO for air combat},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trajectory tracking control for robotic manipulator with disturbances: A double-Q reinforcement learning method. <em>APIN</em>, <em>55</em>(11), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06655-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study uses a reinforcement learning (RL) algorithm to address the trajectory tracking control problem for a robotic manipulator subject to disturbances. A disturbance observer is developed to estimate and counteract external disturbances and model inaccuracies, thereby enhancing the manipulator’s control precision and disturbance rejection capability. A tracking controller is devised to improve tracking performance while maintaining control costs by leveraging the double Q-learning algorithm within reinforcement learning. Utilizing double Q-learning mitigates the issue of Q value overestimation encountered in traditional Q-learning approaches. This method significantly improves the robustness and adaptive ability of the control strategy by introducing a double Q network structure. It provides a new solution for accurate trajectory tracking of the robotic manipulator in unknown and changing environments. At the same time, the robotic manipulator can learn the optimal control strategy more quickly in the face of external disturbance and system uncertainty to achieve better trajectory tracking performance. Simulation and experiment results affirm the efficacy of the proposed control strategy, demonstrating superior trajectory tracking performance and disturbance attenuation capabilities for the manipulator system.},
  archive      = {J_APIN},
  author       = {Yu, Dehai and Sun, Weiwei and Li, Yongshu and Luan, Zhuangzhuang and Zhang, Zhongcai},
  doi          = {10.1007/s10489-025-06655-3},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Trajectory tracking control for robotic manipulator with disturbances: A double-Q reinforcement learning method},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep graph clustering method with improved cluster structure feature learning. <em>APIN</em>, <em>55</em>(11), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06662-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep graph clustering is a fundamental task of graph data analysis, which aims to partition nodes into different clusters based on the node attributes and structural features of the clusters. Related research mainly focuses on unsupervised graph representation learning and clustering algorithms. Existing work is limited by the shallow graph neural networks’ scope of neighborhood information aggregation. The structural features captured by these methods are usually local and noisy, and cannot represent the global cluster structure well, leading to suboptimal clustering performance. To address this issue, this paper proposes a novel deep graph clustering method with improved cluster structure features learning, which enhances the cluster structure features learning by continuously separating the distribution between the enhanced graph and various structure-damaged graphs to guide the model to learn more structural feature information from the whole graph. Moreover, it uses the node embeddings obtained from representation learning to reconstruct and update the graph structure, thereby integrating the learned cluster structure features into the graph structure, and iteratively enhancing the cluster structure features learning. Finally, it uses traditional shallow clustering algorithms to divide nodes into different clusters according to the similarity of node embeddings. Compared with eight state-of-the-art clustering methods, extensive experiments on four benchmark datasets demonstrate the effectiveness of the proposed method for conducting clustering tasks on graph data, especially on the amap dataset, a dense graph where accuracy is improved by 1.5% compared to the current best algorithm. More supplementary materials and the implementation code are available for access at the following link: https://github.com/BluessSkies/GCIS .},
  archive      = {J_APIN},
  author       = {Lv, Peng and Zhang, Chenghan and Jia, Mengmeng and Liu, Yan},
  doi          = {10.1007/s10489-025-06662-4},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Deep graph clustering method with improved cluster structure feature learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overview on evidential fusion approaches in the context of collaborative perception for occupancy modeling. <em>APIN</em>, <em>55</em>(11), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06670-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this paper is to provide a review of the literature on collaborative perception, with a special focus on evidential fusion and combination approaches for both reliable and unreliable information sources. In addition, a study on uncertainty estimation tools is considered in order to integrate them in the global fusion architecture. To do so, we focus on the powerful tools of data fusion and conflict management offered within the Dempster-Shafer framework. Hence, we start by modeling occupancy on scenarios from the Carla simulator using belief functions by varying combination operators proposed in the literature. We add some experimentation using probabilistic approach using the same scenario to extract more conclusions.},
  archive      = {J_APIN},
  author       = {Ben Ayed, Safa and Dachraoui, Jihed and Laghmara, Hind and Boutteau, Rémi},
  doi          = {10.1007/s10489-025-06670-4},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Overview on evidential fusion approaches in the context of collaborative perception for occupancy modeling},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dynamic graph-based multiscale spatio-temporal feature enhancement network applied to ENSO prediction. <em>APIN</em>, <em>55</em>(11), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06691-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The El Niño-Southern Oscillation (ENSO) is an important climate phenomenon, a large-scale coupled ocean-atmosphere interannual variability. It mainly occurs in the equatorial eastern Pacific region and has profound impacts on global climate and ecosystems. Conventional graph convolutional networks (GCNs) perform well in ENSO prediction, but they rely on static adjacency matrices and are difficult to adapt to dynamic changes in node characteristics and relationships. To address this problem, we design an adaptive dynamic graph learning structure that enables the model to adapt to these dynamic changes by explicitly modeling the information flow of edge connections. This approach not only improves the interpretability of the forecasting process, but also characterizes the feedback mechanisms and the impact of the North Pacific Oscillation (NPO) on ENSO events through connections between nodes. To capture the seasonal variations of ENSO, we introduce the Transformer to capture the long-term dependencies in the series. In addition, the fused spatio-temporal feature representation is enhanced and redundant information is suppressed by introducing the node feature attention module. Experiments on CMIP5 and SODA datasets show that the proposed DGL-GT method achieves correlation coefficients of more than 79% over six forecast lead times and is able to forecast ENSO up to 15 months ahead of most state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Shao, Wei and Tong, Guoxiang},
  doi          = {10.1007/s10489-025-06691-z},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {A dynamic graph-based multiscale spatio-temporal feature enhancement network applied to ENSO prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conformal prediction for out-of-distribution time-series classification. <em>APIN</em>, <em>55</em>(11), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06708-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine the problem of handling uncertainty in the predictions for out-of-distribution data (OOD) when classifying time series with distortions, such as gaps, that can occur due to operating conditions in production environments. This problem can find several application domains, including predictive maintenance. We focus on Conformal Prediction (CP) as a framework for handling the uncertainty in predictions for OOD time series that occurs due to distortions. Our study focuses on the potential impact of OOD time series on the performance of CP, by assessing the size and coverage of the resulting prediction sets. The motivation for this study is that neural networks, which are widely used for time-series classification, may suffer from overconfidence. This fact negatively impacts CP when faced with OOD data, because incorrect predictions with high confidence can have catastrophic consequences in high-risk applications. To alleviate this problem, we propose two model-agnostic methods: the use of various forms of label smoothing as well as the use of hybrid classifiers. Our experimental findings in the context of prominent time-series classifiers demonstrate that the coverage of CP may be maintained around a desirable level without needlessly expanding the size of the prediction sets.},
  archive      = {J_APIN},
  author       = {Nanopoulos, Alexandros and Buza, Krisztian},
  doi          = {10.1007/s10489-025-06708-7},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Conformal prediction for out-of-distribution time-series classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMDMN: Distraction mining and dual mutual network for curvilinear structure segmentation. <em>APIN</em>, <em>55</em>(11), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06710-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Curvilinear Structure Segmentation (CSS) aims to predict the binary masks of curvilinear objects in photographs, such as blood vessels and road cracks. Despite impressive segmentation results, current CSS methods often struggle with disconnected segmentations and inaccurate edges, essentially caused by the distractions in the feature domain, which are from image domain-specific challenges, and by the imbalance of scales of thicker and thinner branches. To address these problems, we propose Distraction Mining and Dual Mutual Network (DMDMN) based on reverse attention and mutual learning to improve CSS. Specifically, DMDMN first extracts various levels of features from an input image using a plain network. Then, a Reverse Attention Module (RAM) is designed at each level to enhance the extracted features by identifying and removing false positive and negative distractions. Next is a Three-Head Fusion Module (THFM) at a separate level, which serves as an exchanger to mutually integrate the features from the branch segmentation head with those from the heads of skeleton extraction and edge detection. With the segmented results flowing back to RAMs, the previous two steps alternate several times till the final prediction of a high-quality segmentation, which is topologically connective along branches and pixel-wise accurate at edges. In addition, extensive experiments on five public datasets have demonstrated the superiority of the proposed DMDMN over state-of-the-art approaches both qualitatively and quantitatively.},
  archive      = {J_APIN},
  author       = {Wu, Qingbo and Meng, Shuofei and Huang, Wei and Chen, Shengyong},
  doi          = {10.1007/s10489-025-06710-z},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {DMDMN: Distraction mining and dual mutual network for curvilinear structure segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain adaptation with category-level contrastive learning for semi-supervised cross-modal hashing. <em>APIN</em>, <em>55</em>(11), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06712-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal hashing(CMH) is a key technique in information retrieval, valued for its efficiency, low dimensionality, and minimal storage requirements. Despite notable progress in this field, challenges persist, particularly the reliance on large labeled datasets. This paper presents a novel domain adaptation framework that leverages a limited set of labeled data from the source domain to guide the training of a large quantity of unlabeled data in the target domain. Our approach incorporates pseudo-label generation to iteratively refine semantic representations in the target domain, progressively narrowing the semantic gap between domains. Additionally, we propose a category-level contrastive learning(CLCL) method to address class conflict issues common in traditional instance-based contrastive learning. By generating category prototype representations, we enhance the model’s ability to discriminate between categories effectively. Moreover, our framework includes a comprehensive optimization objective that integrates pseudo-label generation loss, contrastive learning loss, and hash code learning loss, ensuring that the generated hash codes are both discrete and discriminative. Experimental results on benchmark datasets demonstrate the superiority of our approach over existing CMH methods.},
  archive      = {J_APIN},
  author       = {Han, Zhichao and Azman, Azreen and Rina Mustaffa, Mas and Khalid, Fatimah},
  doi          = {10.1007/s10489-025-06712-x},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Domain adaptation with category-level contrastive learning for semi-supervised cross-modal hashing},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSSLNet: Dual-stream self-supervised learning network for end-to-end speech recognition. <em>APIN</em>, <em>55</em>(11), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06713-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {End-to-end speech recognition has benefited from large-scale labeled corpora to achieve great success, and limited labeled data hardly meets performance requirements in specific scenarios. Self-supervised learning provides a compelling solution for addressing this issue. However, existing self-supervised methods cannot balance context-semantic relationships and differentiated information between speech features, which are crucial for ASR. To address this issue, we propose a novel Dual-Stream Self-Supervised Learning Network (DSSLNet) to combine the complementary advantages of both parties. Concretely, the dual-stream structure consists of a reconstruction prediction module and a contrastive prediction module in parallel, where reconstruction prediction is jointly trained with contrastive prediction and as an auxiliary task of the latter. Furthermore, a novel GRU feature fusion module is also designed for fusing speech representations, which adaptively explores the latent structure of speech through a parameter learning strategy. Our DSSLNet is first pre-trained on Multi-Audio (600h) and Librispeech (960h), then fine-tuned on Aishell-1, HKUST and subsets of Librispeech for the ASR task. Experiment results show that our DSSLNet achieves state-of-the-art compared to other advanced works while achieving comparable accuracy in limited labeled data scenarios.},
  archive      = {J_APIN},
  author       = {Lyu, Boyang and Fan, Chunxiao and Ming, Yue and Hu, Nannan},
  doi          = {10.1007/s10489-025-06713-w},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {DSSLNet: Dual-stream self-supervised learning network for end-to-end speech recognition},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topological fusion model for molecular property prediction. <em>APIN</em>, <em>55</em>(11), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06721-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prominence of 3D molecular property prediction arises from its ability to provide insights into the drug discovery and design, material science and chemical synthesis. Transformer-based models have been widely adopted to autonomously learn long-range atom-to-atom interactions on a global scale, resulting in significant success. However, these models may struggle to capture intricate substructure details (e.g.,  covalent bond and functional group). In this work, topological simplices defined on nodes, links, triangles are extracted from the atoms’ 3D positional information to provide comprehensive representations of the local substructure information, such as atoms, covalent bonds and functional groups. We then propose a topological fusion network, which enhances each atom’s features not only through global atom-to-atom interactions but also by incorporating the fine-grained topological substructure information. In comparison to existing popular methods, our proposed method outperforms the state-of-the-art (SOTA) method by 1.2%, 3.0%, 2.4%, 2.7% on BBBP, BACE, ClinTox, MUV datasets for classification task and 0.048, 0.022, 3.8 on FreeSolv, Lipo and QM7 datasets for regression task, respectively. The code will be released soon.},
  archive      = {J_APIN},
  author       = {Rong, Xia and Haotian, Xu and Junwei, Wu and Shufei, Zhang and Mingjie, Sun and Jiejie, Liu and Quan, Zhang},
  doi          = {10.1007/s10489-025-06721-w},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {11},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Topological fusion model for molecular property prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metallic surface defect detection via NWD-WIoU based on grayscale co-generation entropy gain. <em>APIN</em>, <em>55</em>(10), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06363-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial metallic manufacturing, detecting defects is essential to ensure safety and prolong the lifespan of products. However, current systems often have difficulty accurately identifying small and subtle defects. To address this issue, this paper proposes a dual-channel algorithm for metallic defect detection that utilizes gray-level co-occurrence entropy gain. In one channel, an approach to increase gray-level co-occurrence entropy processes the input image, generating a gray-level feature vector and defect feature map. The feature vector is then input into a classification to obtain classification outcomes and posterior probabilities, while the defect feature map is fused with deep features from the backbone network in the other channel. This paper also introduces a new loss function, NWD-WIoU, which combines normalized Wasserstein distance (NWD) with dynamic non-monotonic focusing boundary box loss (WIoU) to improve tiny target identification. Experimental findings reveal that our algorithm achieves superior performance in detecting metal surface defects, with an accuracy of 87.9 mAP on NEU-DET and 88.4 mAP on ZJU-MP, outperforming current dominant techniques.},
  archive      = {J_APIN},
  author       = {Xu, Jinghua and Ye, Deliang and Zhang, Shuyou and Wang, Kang and Chen, Shenghao},
  doi          = {10.1007/s10489-025-06363-y},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Metallic surface defect detection via NWD-WIoU based on grayscale co-generation entropy gain},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SGEU: Enhancing LLM reasoning via backward exemplar generation and verification. <em>APIN</em>, <em>55</em>(10), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06529-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-context learning has emerged as an effective method to enhance the reasoning capabilities of Large Language Models (LLMs) across diverse applications, eliciting chain-of-thought abilities through reasoning exemplars with rationales. Nevertheless, methods relying on limited, expert-annotated exemplars hinder the continual adaptation of LLMs to emerging challenges. Automatic exemplar construction methods based on forward reasoning may yield flawed rationales, particularly for tasks in which LLMs underperform. Additionally, few-shot CoT exhibit sensitivity to the exemplar selection, especially for the flawed exemplars. To automatically generate high-quality rationale exemplars for reasoning enhancement, we propose a self-enhancement framework, including the Self-Generation, Evaluation, and Utilization (SGEU) of exemplars from historical data, facilitating LLMs in acquiring high-quality rationales for the self-enhancement. Specifically, in the exemplar collection stage, given historical data, LLMs first perform backward reasoning, rather than forward reasoning, to avoid the answer reasoning and generate more accurate rationales, resulting in an initial sample-rationale dataset. Subsequently, we propose a self-verification module and a mutual verification module to filter high-quality exemplars for the final sample-rationale collection. In the testing stage, SGEU employs a text embedding model to retrieve similar reasoning exemplars for in-context learning, enabling precise reasoning. Experiments across four complex tasks demonstrate the superior performance of SGEU, outperforming competitive methods of 4.8, 6.9, 2.1, and 0.7 on legal judgment prediction, social bias prediction, arithmetic reasoning, and commonsense reasoning, respectively. Furthermore, we demonstrate that backward reasoning outperforms the forward reasoning in rationale generation through human evaluation and verification methods effectively filter high-quality exemplars. The code will be made publicly available ( https://drive.google.com/file/d/1GcFINcMLpuj-3RxzGst4dFmxX5XCPyrF/view?usp=sharing ).},
  archive      = {J_APIN},
  author       = {Wang, Zhen and Zhou, Xi and Yang, Yating and Ma, Bo and Wang, Lei and Dong, Rui},
  doi          = {10.1007/s10489-025-06529-8},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {SGEU: Enhancing LLM reasoning via backward exemplar generation and verification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ECLNet: Enhancing the CNN-LSTM networks for multivariate long-term time series forecasting. <em>APIN</em>, <em>55</em>(10), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06537-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural network (CNN)-long short-term memory (LSTM) models have been extensively utilized in time-series forecasting (TSF) owing to their robust capabilities in feature extraction and capturing temporal dependencies. However, they face challenges in long-term time series forecasting (LTSF), because the recurrent iterations inherent to LSTM over extended lookback and forecast horizons result in the accumulation of errors. Based on the PatchTST method, this study introduces ECLNet, a novel approach for LTSF. ECLNet is an enhanced CNN-LSTM framework that improves forecasting accuracy and efficiency. ECLNet incorporates a hidden state parallel forecasting (HSPF) strategy to reduce the number of recurrent iterations, thereby decreasing cumulative errors, improving predictive accuracy, and enhancing training speed. Distinct from the prevalent channel-independent strategies in existing models, we propose a dual ConvFFN interrelation module (DCIM) to model the complex relationships among multiple variables and channels, thereby enhancing the capture of intricate dependencies, while leveraging LSTM units to capture temporal dependencies within the data. This approach improved the forecasting performance and robustness of the model. We further compared our ECLNet model with all baselines through experiments on six public datasets, which indicated that our proposed model demonstrated a competitive performance comparable to state-of-the-art models on the evaluated benchmarks.},
  archive      = {J_APIN},
  author       = {Xie, Jiachen and Qin, Jiwei and Qin, Xizhong and Li, Qiang and Cui, Daishun and Sun, Dezhi},
  doi          = {10.1007/s10489-025-06537-8},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {ECLNet: Enhancing the CNN-LSTM networks for multivariate long-term time series forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HANE-SHC: Heterogeneous attributed network embedding with structural homophily contents. <em>APIN</em>, <em>55</em>(10), 1-40. (<a href='https://doi.org/10.1007/s10489-025-06545-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous attributed networks (HANs) are ubiquitous in real-world, spanning domains from the academic network to the movie network. Heterogeneous attributed network embedding (HANE), a promising analytical technique in recent years, aims to generate low-dimensional dense vectors containing network structure and attribute content. Compared to the embedding approaches that only consider topology structure, researchers embed the network by leveraging both network topology and content to improve the quality of embedding vectors. However, when two nodes with a connected edge may have a small content similarity value, while two nodes without a connected edge may have a large content similarity value, so, in this situation, it is not appropriate to utilize the network topology and nodes’ content to generate embedding vectors. To overcome this challenge, we propose a novel approach of Heterogeneous Attributed Networks Embedding based on Structural Homophily Contents, abbreviated as HANE-SHC, which is based on convolutional neural networks to leverage both the network structure and the content of nodes connected with the embedded node to generate the representation vectors of the embedded node. To our knowledge, this is the first study that proposes the Structural Homophily Contents to enhance the heterogeneous attributed network embedding. Through comprehensive evaluations on downstream tasks including clustering, classification, link prediction, and visualization, the experimental results demonstrate that the HANE-SHC outperforms the baselines. On the artificial synthetic networks with various network structure-content dissimilarity scores, the HANE-SHC model consistently produces high-quality embedding vectors regardless of the network dissimilarity scores between structure and content, significantly outperforming existing approaches.},
  archive      = {J_APIN},
  author       = {Fu, Yue and Zhao, Shuliang and Wu, Yongliang},
  doi          = {10.1007/s10489-025-06545-8},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-40},
  shortjournal = {Appl. Intell.},
  title        = {HANE-SHC: Heterogeneous attributed network embedding with structural homophily contents},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An unsupervised software bug count prediction model based on selected software metrics. <em>APIN</em>, <em>55</em>(10), 1-27. (<a href='https://doi.org/10.1007/s10489-025-06557-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software Bug Count Vector (SBCV) prediction technique is a regression model that aims to predict the precise number of bugs in each module of a software system. In contrast, a Software Bug Prediction (SBP) model focuses on predicting whether a module is buggy or not. Predicting the exact number of bugs in each module brings efficiency in software test resource allocation, maintenance, and release time. Many researchers have conducted empirical studies to predict SBCV using regression algorithms on labeled datasets only. However, accurately collecting and labeling buggy data poses multiple challenges, such as maintaining historical information, a version control system, an issue tracking system, and the need for experienced software experts. To address the limitation of labeled datasets and the absence of an unsupervised SBCV prediction model, we propose a novel unsupervised SBCV prediction model based on software metrics (SMs) thresholds. We have analyzed that previously proposed unsupervised SBP models calculated independent software metrics threshold using different techniques, but they did not consider skewness behaviors of software metrics distribution. To overcome this, we reduce the skewness of the SMs distribution using log transformation and then derive the threshold of each selected SM. Based on these thresholds and robust linear regression algorithm, we propose a SBCV prediction model. The proposed SBCV prediction model does not require labeled datasets and predicts software bug count in each module by self-learning approach. The average performance of our proposed technique over 22 datasets surpasses the majority of state-of-the-art regression techniques (8 standard supervised algorithms) in terms of mean absolute error (0.45), mean relative error (0.20), and Pred(l)_Error (0.29). The results of statistical tests, including the Wilcoxon signed-rank test, CohenD test, and Nemenyi test, demonstrate the significance of SBCV prediction models.},
  archive      = {J_APIN},
  author       = {Kumar, Rakesh and Chaturvedi, Amrita},
  doi          = {10.1007/s10489-025-06557-4},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-27},
  shortjournal = {Appl. Intell.},
  title        = {An unsupervised software bug count prediction model based on selected software metrics},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Telling fortunes? evaluation of traffic forecasting models using traffic and context features. <em>APIN</em>, <em>55</em>(10), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06565-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need for efficient and reliable logistics solutions has increased significantly in the last decade. Traffic forecasts are a promising source of information that can be used to improve the planning of delivery schedules. However, most existing traffic forecasting approaches only support a forecasting horizon of up to an hour, which is insufficient for per-day-based schedule planning. In this paper, we focus on short-term traffic forecasting for up to four hours. We first propose a data collection process integrating traffic speed, incidents, weather, and holiday information. We have used this process to collect real-world traffic data for 115 days. We then define and evaluate twelve models for vehicle traffic forecasting, including well-known time series forecasting approaches and state-of-the-art deep learning models. Our results show that the best model in our comparison improved the accuracy by approximately 30% compared to a naive forecaster that repeats the last known value. The evaluation also shows that LSTM-based approaches are competitive to state-of-the-art models. Overall, the proposed deep-learning-based models perform best while requiring a smaller input timeframe than statistical models.},
  archive      = {J_APIN},
  author       = {Hadry, Marius and Bauer, André and Leppich, Robert and Lesch, Veronika and Kounev, Samuel},
  doi          = {10.1007/s10489-025-06565-4},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Telling fortunes? evaluation of traffic forecasting models using traffic and context features},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic anchor-based tensor learning for incomplete multi-view clustering. <em>APIN</em>, <em>55</em>(10), 1-33. (<a href='https://doi.org/10.1007/s10489-025-06569-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete multi-view clustering aims to utilize the correlation and complementarity between multiple perspectives to fill in the missing information, thereby improving the accuracy and robustness of clustering. Nevertheless, current researches often need to pay more attention to the divergences and high-order correlated information between views. They also have high computational complexity and memory requirements. To tackle these problems, we propose a novel method called Dynamic Anchor-based Tensor Learning for Incomplete Multi-view Clustering (DATL-IMC). Specifically, DATL-IMC designs a consensus anchor graph learning algorithm to obtain the consensus anchor graph by exploiting dynamic anchor learning and applies the low-rank tensor to optimize the anchors further. Meanwhile, DATL-IMC exploits projection learning to learn the latent representation of each view to get the consensus latent representation. Then, DATL-IMC utilizes graph regularization to collaborate the consensus latent representation and the consensus anchor graph to improve the clustering results. Finally, experiments conducted on nine real-world datasets demonstrate that DATL-IMC surpasses fifteen state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Dong, Yao and Fu, Yixue and Dong, Yongfeng and Shi, Jin and Guo, Zhihao},
  doi          = {10.1007/s10489-025-06569-0},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-33},
  shortjournal = {Appl. Intell.},
  title        = {Dynamic anchor-based tensor learning for incomplete multi-view clustering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SCANSleepNet: A spatial-channel attention network for sleep stage classification. <em>APIN</em>, <em>55</em>(10), 1-11. (<a href='https://doi.org/10.1007/s10489-025-06587-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sleep stages refer to the distinct processes within a person’s sleep cycle. They are essential for assessing mental and physical health. Existing sleep stage classification models typically improve performance through increased computation complexity or be trained with more labeled data. These models may result in overly heavy models that are unrealistically not applicable in real-world scenarios. To address this issue, this paper proposes a Spatial-Channel Attention Network for Sleep Stage Classification (SCANSleepNet). This framework is built on the time-frequency characteristics of EEG signals and the conversion rules of sleep stages. It constructs a lightweight deep-learning system that integrates multi-scale frequency analysis and dynamic feature enhancement. Its improvements lie in two main aspects. First, a Spatial-Channel Dimensional Attention (SCDA) block is designed to model the dynamic transition among stages while requiring fewer parameters. Second, a weighted cross-entropy loss function is introduced to address class imbalance without dependence on extra data augmentation. It enhances the model’s lightness and suitability for clinical applications. Experimental results show that the SCANSleepNet achieved 85.52% accuracy in the Fpz-Cz channel and 82.16% in the Pz-Oz channel on the Sleep-EDF dataset. It makes a good balance between classification accuracy and efficiency.},
  archive      = {J_APIN},
  author       = {Liu, Yuyun and Li, Qilei and Gao, Mingliang and Guo, Xiangyu and Zhai, Wenzhe},
  doi          = {10.1007/s10489-025-06587-y},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-11},
  shortjournal = {Appl. Intell.},
  title        = {SCANSleepNet: A spatial-channel attention network for sleep stage classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ClotheDreamer: Text-guided garment generation with 3D gaussians. <em>APIN</em>, <em>55</em>(10), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06596-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-fidelity 3D garment synthesis from text is desirable yet challenging for digital avatar creation. Recent diffusion-based approaches via Score Distillation Sampling (SDS) have enabled new possibilities but either intricately couple with human body or struggle to reuse. We introduce ClotheDreamer, a 3D Gaussian-based method for generating wearable, production-ready 3D garment assets from text prompts. We propose a novel representation Disentangled Clothe Gaussian Splatting (DCGS) to enable separate optimization. DCGS represents clothed avatar as one gaussian model but freezes body Gaussian splats. To enhance quality and completeness, we incorporate bidirectional SDS to supervise clothed avatar and garment RGBD renderings respectively with pose conditions and propose a new pruning strategy for loose clothing. Our approach can also support custom clothing templates as input. Benefiting from our design, the synthetic 3D garment can be easily applied to virtual try-on and support physically accurate animation. Extensive experiments showcase our method’s superior and competitive performance. Our project page is at https://ggxxii.github.io/clothedreamer .},
  archive      = {J_APIN},
  author       = {Liu, Yufei and Tang, Junshu and Zheng, Chu and Zhu, Junwei and Wang, Chengjie and Huang, Dongjin},
  doi          = {10.1007/s10489-025-06596-x},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {ClotheDreamer: Text-guided garment generation with 3D gaussians},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised outlier detection based on multi-granularity neighborhood information. <em>APIN</em>, <em>55</em>(10), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06598-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised outlier detection is an important part of data mining. It analyzes the inherent structure, distribution, and relationships in the data to detect unusual patterns or samples that deviate significantly from the norm without relying on labeled information. Neighborhood information provides an effective and intuitive solution idea for unsupervised outlier detection, which has received increasing attention. However, most of the existing methods cannot effectively utilize the multi-granularity information in the data and suffer from high computational complexity and susceptibility to noise. The performance of outlier detection has to be further improved. Granular-ball computing is a novel multi-granularity granular computing model. It uses multi-granularity granular-balls as new processing units and provides an effective paradigm for utilizing multi-granularity information in data. Many recent studies have validated that it can further improve the performance and efficiency of existing machine learning methods. In this study, we propose an unsupervised Outlier Detection method based on multi-Granularity Neighborhood Information (ODGNI). This method first constructs a novel multi-granularity neighborhood granular structure based on multi-granularity granular-balls and neighborhood rough sets. Next, the importance of different attributes is calculated to construct the sequence of attribute sets and multi-granularity neighborhood information granule sets. Finally, the outlier degree is calculated by fusing multiple multi-granularity neighborhood information granules of the granular-ball to which the sample belongs. In the experimental results, ODGNI achieves better outlier detection results than the recently proposed methods, which validates the effectiveness of our method.},
  archive      = {J_APIN},
  author       = {Li, Yi and Su, Xinyu and Yuan, Zhong and Zhang, Benwen and Liu, Jiabin and Tan, Xingqiang},
  doi          = {10.1007/s10489-025-06598-9},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Unsupervised outlier detection based on multi-granularity neighborhood information},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-block local outlier factor anomaly detection of complex industrial systems. <em>APIN</em>, <em>55</em>(10), 1-25. (<a href='https://doi.org/10.1007/s10489-025-06603-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is critical in industrial systems for ensuring equipment reliability and improving product quality, especially with the increasing complexity of electronic board production. However, traditional anomaly detection approaches often fail when dealing with high-dimensional data and limited system knowledge. To address this gap, this article aims to develop an effective unsupervised method for anomaly detection suitable for large-scale industrial contexts with minimal prior knowledge. The proposed Multi-block Local Outlier Factor (MLOF) method combines a variable decomposition technique based on Mutual Information and spectral clustering with a local anomaly detection algorithm using the Local Outlier Factor. The method was validated on the Tennessee Eastman Process and real-world industrial cases from Surface Mount Technology production lines, notably by comparing its results with 5 other methods in the literature. Results demonstrate a 15% improvement in anomaly detection performance compared to classical LOF on benchmark data and effective application in detecting anomalies in real production scenarios. The MLOF method represents a significant step forward in anomaly detection for complex systems, offering robust, scalable, and accurate solutions even in data-intensive and knowledge-scarce environments.},
  archive      = {J_APIN},
  author       = {Gaffet, Alexandre and Ribot, Pauline and Chanthery, Elodie and Merle, Christophe},
  doi          = {10.1007/s10489-025-06603-1},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {Multi-block local outlier factor anomaly detection of complex industrial systems},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing few-shot class-incremental learning through prototype optimization. <em>APIN</em>, <em>55</em>(10), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06605-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot class-incremental learning (FSCIL) aims to incrementally learn new classes with limited samples while avoiding the forgetting of previously learned ones. Nevertheless, the limited samples in new classes often lead the model towards overfitting and may trigger catastrophic forgetting. In response to these challenges, we propose the Prototype Optimization-based Method (POM) for FSCIL. Given the critical role of prototypes in classification, POM aims to optimize classification performance from the perspective of enhancing prototype representativeness. First, the quality of prototypes is directly determined by the capacity of the feature extractor. A powerful feature extractor is capable of extracting more discriminative features, while the accuracy of the prototype relies on the high-quality features provided by the feature extractor. Therefore, in the basic training phase, we design a hybrid loss function to adequately train the feature extractor, enhancing the discriminative power of the prototype representation. Second, we propose a prototype optimization strategy that dynamically adjusts the positions of prototypes by identifying highly similar pairs in the feature space, ensuring sufficient separation between them and reducing confusion between prototypes of new and old classes. Experimental results on miniImageNet, CIFAR100, and CUB200 show that POM achieves outstanding performance across several key metrics, particularly in terms of accuracy and performance retention, significantly surpassing existing methods and demonstrating its effectiveness and advantages in incremental learning tasks. Compared to TOPIC, POM achieves a 20.40% improvement in average accuracy on miniImageNet.},
  archive      = {J_APIN},
  author       = {Jiang, Mengjuan and Fan, Jiaqing and Li, Fanzhang},
  doi          = {10.1007/s10489-025-06605-z},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing few-shot class-incremental learning through prototype optimization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differential evolution with dual-space-based population size adaptation and dynamic classification-based mutation strategy. <em>APIN</em>, <em>55</em>(10), 1-28. (<a href='https://doi.org/10.1007/s10489-025-06609-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of the differential evolution (DE) algorithm is highly dependent on the setting of parameters and the design of mutation strategy. This paper proposes a DE algorithm based on a dual-space-based population size adaptive (DSPSA) method and a dynamic classification strategy (DSDCDE) to adaptively adjust population diversity during the evolutionary process and balance the algorithm’s exploration and exploitation capabilities. DSPSA is the first method to use the fitness space information and search space information to adapt to the population size. Unlike other DE variant population size adjustment strategies, DSPSA adaptively adjusts population size using dual-space information. This helps to delete individuals who lack prospects while retaining those with more significant potential, thus enhancing the individual’s ability to escape local optima. We propose an enhanced mutation operator based on dynamic classification that uses elite individuals to guide population evolution and introduces information about inferior individuals to increase population diversity. In addition, dynamic classification-based improved update methods are employed for scale factor and crossover rate, introducing individual information to provide tailored parameters for individuals at different optimization stages. This ensures a proper balance between global exploration and local exploitation capabilities. The Wilxoncon signed-rank test results compared with LSHADE-cnEpSin, jSO, IMODE, AL-SHADE, LADE, IDE-EDA, APSM-jSO in the CEC 2017 benchmark suite were 96/68/39 at 30D, 111/42/50 at 50D and 106/43/54 at 100D. The numerical results indicate that DSDCDE exhibits competitiveness regarding convergence speed and final accuracy.},
  archive      = {J_APIN},
  author       = {Deng, Libao and Meng, Zhihui and Li, Chunlei and Zhang, Lili},
  doi          = {10.1007/s10489-025-06609-9},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-28},
  shortjournal = {Appl. Intell.},
  title        = {Differential evolution with dual-space-based population size adaptation and dynamic classification-based mutation strategy},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-granularity decision information integration network for hierarchical classification via local and global constraints. <em>APIN</em>, <em>55</em>(10), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06611-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical classification learning is an effective means of solving large-scale classification problems, which models classification problems at different levels of granularity according to a hierarchical structure. In hierarchical classification tasks, classification results at different levels of granularity are mutually beneficial, where coarse-grained results can reduce the number of fine-grained candidate categories, and fine-grained results can provide a basis for coarse-grained classification. However, in the final decision-making process, the contributions of different granularity levels within the hierarchy vary and are not explicitly known. Therefore, it is essential to flexibly integrate feedback from multiple granularity levels to enhance classification performance. In addition, errors in hierarchical classification are not equally significant; some misclassifications can lead to severe consequences in practical applications, highlighting the need for a more refined error-handling strategy. In order to address the above challenges, we propose a new hierarchical network to integrate multi-granularity knowledge for decision making. On the one hand, the network computes the decision scores of instances at each granularity level and learns a set of weights to combine all scores. Based on the learnable weights, the model can effectively utilize the multi-granularity classification results to obtain the final decision. On the other hand, we design local and global classification losses to guide model optimization, which allows the model to gain a hierarchical perspective and the ability to understand the degree of hierarchical misclassification. As a result, the extent to which the method results in misclassification consequences is limited. Experimental results on five benchmark datasets show that our method arises as a state-of-the-art hierarchical classification method.},
  archive      = {J_APIN},
  author       = {Liu, Haoyang and Li, Peipei and Hu, Xuegang and Bai, Shengxing and Lin, Yaojin},
  doi          = {10.1007/s10489-025-06611-1},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Multi-granularity decision information integration network for hierarchical classification via local and global constraints},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CLCFE: Complementary loss coupling for feature-enhanced few-shot fine-grained visual recognition. <em>APIN</em>, <em>55</em>(10), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06613-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning aims to generate a classifier capable of identifying novel concepts with limited instances. While most existing approaches in this field focus on general object recognition, the ability to quickly identify novel concepts with subtle differences using scarce annotation is crucial for perceptual understanding in real-world scenarios. To address this issue, the paper presents a Complementary Loss Coupling for Feature-Enhanced (CLCFE) few-shot fine-grained visual recognition. In this approach, a dual-stream attention module is utilized to enhance the embedded features extracted from the query and support images. This module builds global contextual relations by incorporating structural and semantic information. Additionally, a complementary loss coupling module is designed to obtain intensified discriminative prototypes, through mining fine-grained differences among inter-class features and exploring the correlation among intra-class features. To validate the effectiveness of the proposed modules, interpretable visualizations and detailed ablations are conducted. Comparative experiments demonstrate that the CLCFE approach outperforms the previous models by a large margin in 4 few-shot fine-grained benchmarks.},
  archive      = {J_APIN},
  author       = {Wu, Heng and Zheng, Zijun and Lv, Laishui and Zhang, Changchun and Xu, Yifeng and Bardou, Dalal and Niu, Shanzhou and Yu, Gaohang},
  doi          = {10.1007/s10489-025-06613-z},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {CLCFE: Complementary loss coupling for feature-enhanced few-shot fine-grained visual recognition},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MaskMatch: Uncertainty calibration for dynamic masking in semi-supervised image segmentation. <em>APIN</em>, <em>55</em>(10), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06614-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning for image segmentation using pseudo-labels is promising. However, current methods typically use strict thresholds to select reliable pseudo-labeled pixels, leading to limited use of these labels. Relying only on highly reliable pseudo-labeled pixels can also hinder the model’s learning ability in challenging regions such as edges and minority categories. In order to explore other regions in unlabeled datasets, especially the transition region between objects and backgrounds, we propose an effective semi-supervised segmentation method called MaskMatch. Specifically, we introduce two methods to enhance the segmentation of the transition region between objects and backgrounds. First, we propose a dynamic background region mask. For labeled data, a potential error area mask (MPEA) is created, directing the model to focus on samples that are prone to segmentation error regions. For unlabeled data, an Uncertainty Correction Mask (MU) is introduced to explore the correct segmentation regions in regions below a specified threshold, thus improving the efficiency of pseudo-labeling. Second, the feature space gap between objects and backgrounds is increased by Object-Background Contrast Learning (OBCL), which improves the segmentation results in these transition regions. Extensive experiments on datasets such as PASCAL VOC 2012, COCO, LEVIR, and WHU have shown that MaskMatch delivers excellent results.},
  archive      = {J_APIN},
  author       = {Liao, Aihua and Hao, Kuangrong and Wei, Bing and Tang, Xuesong},
  doi          = {10.1007/s10489-025-06614-y},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {MaskMatch: Uncertainty calibration for dynamic masking in semi-supervised image segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time manufacturing process monitoring using GRU with PSO algorithm. <em>APIN</em>, <em>55</em>(10), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06617-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process monitoring plays a vital role in controlling manufacturing processes and ensuring product quality by enabling early detection of process shifts. This study proposes a novel multivariate monitoring method that integrates a stacked gated recurrent unit (S-GRU) with a self-adaptive particle swarm optimization (PSO) called S-GRU-PSO. In this framework, PSO is employed to automatically optimize hyperparameters of the S-GRU architecture, enhancing its learning capability and adaptability. The proposed model was evaluated using synthetic datasets with both normal and non-normal (gamma) distributions across various data dimensions and shift magnitudes. It was also validated on a real-world wine production dataset to assess its industrial applicability. Comparative experiments were conducted against benchmark monitoring methods, including distance-based support vector machine (D-SVM), random forest with real-time contrast (RF-RTC), D-SVM optimized by differential evolution (D-SVM-DE), Stacked long short-term memory (S-LSTM), and stacked gated recurrent unit (S-GRU). The results demonstrate that the S-GRU-PSO model achieves superior performance, with a 26.9% improvement in shift detection for normal data, 11.35% for gamma-distributed data, and 16.6% for the wine dataset, as measured by reductions in average run length ( $$ARL_{1}$$ ). These findings confirm not only the model’s effectiveness in quickly detecting process changes but also its novel integration of temporal deep learning and adaptive optimization, offering a robust and scalable solution for real-time industrial monitoring applications.},
  archive      = {J_APIN},
  author       = {Yilma, Atinkut Atinafu and Yang, Chao-Lung and Woldegiorgis, Bereket Haile},
  doi          = {10.1007/s10489-025-06617-9},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Real-time manufacturing process monitoring using GRU with PSO algorithm},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards automation of warehouse management: Counting boxes on pallets via 3D reconstruction from a single image. <em>APIN</em>, <em>55</em>(10), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06621-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The merging of artificial intelligence and industrial applications has proved its worth in many fields. Logistics is one area that could benefit from this innovation. In particular, automating the task of detecting the number of boxes on pallet significantly streamlines logistics and enhances the overall shipping experience for consumers. However, the high complexity of this task, combined with the lack of publicly available datasets depicting pallets in a warehouse, has limited advancements in the literature. To address this challenge, we propose a new lightweight framework for 2D/3D reconstruction, designed to count the number of missing boxes on a pallet. Our method efficiently infers the 3D positions of individual objects from a 2D image by reconstructing a sparse 3D point cloud. This object-centric approach prioritizes computational efficiency and practical utility, enabling accurate counting of missing boxes on the pallet, even in scenarios involving occluded objects. Moreover, to overcome the lack of open databases in the logistics domain, we release a new synthetic dataset designed to simulate boxes on a pallet within a warehouse setting. Extensive experiments demonstrate the ability of our proposed framework in accurately reconstructing the exact position of each box and consequently counting the number of missing boxes on a pallet with an accuracy of $$\varvec{98\%}$$ . The code is available at https://github.com/ikramedd/-3D-PRNet--2D-3D-Reconstruction .},
  archive      = {J_APIN},
  author       = {Eddahmani, Ikram and Napoléon, Thibault and Pham, Chi-Hieu and Badoc, Isabelle and EL-Bouz, Marwa},
  doi          = {10.1007/s10489-025-06621-z},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Towards automation of warehouse management: Counting boxes on pallets via 3D reconstruction from a single image},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted cross-integrated fusion network based on knowledge distillation for multi-modal personality recognition. <em>APIN</em>, <em>55</em>(10), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06623-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personality recognition is crucial for deeply understanding social relationships. Although significant advancements have been made in personality recognition research in recent years, challenges still need to be addressed, particularly the heterogeneity in cross-modal information sharing. To address this, we propose a framework based on the Weighted Cross-Integrated Fusion Network (WCIF-Net). This framework comprises five modules and integrates three modalities (visual, audio, and text) to fuse multi-modal features for accurate personality recognition. Our proposed Weighted Frame Allocation Module optimizes the quality of input video frames by strategically allocating weight calculations. We also incorporate knowledge distillation and contrastive learning into the network, effectively resolving the heterogeneity problem in cross-modal information sharing. We evaluate our method on the ChaLearn First Impressions V2 and ELEA datasets, comparing it with several state-of-the-art methods using different architectures. The experimental results confirm the functionality of the individual modules and their combinations as designed. Based on two key evaluation metrics (ACC and PCC), our performance surpasses the state-of-the-art networks based on the three modalities. Furthermore, our work demonstrates the significant role that Transformers can play in understanding mental phenomena, indicating that our method has broad applicability in multi-modal affective computing.},
  archive      = {J_APIN},
  author       = {Bao, Yongtang and Liu, Xiang and Li, Xiao and Wang, Zhihui and Qi, Yue},
  doi          = {10.1007/s10489-025-06623-x},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Weighted cross-integrated fusion network based on knowledge distillation for multi-modal personality recognition},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time dynamic path planning for distributed unmanned surface vehicles in coordinated formations with maneuverability constraints. <em>APIN</em>, <em>55</em>(10), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06626-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the application of unmanned surface vehicles (USVs) in marine environments increases, existing path planning methods face challenges such as high computational complexity, insufficient real-time decision-making capabilities, and poor adaptability. To address these challenges, this paper adopts the multi-agent soft actor-critic (MASAC) algorithm to investigate cooperative formation path planning for USVs in real-time dynamic environments. Inspired by Dubins path planning methods, a minimum turning radius action space is proposed to address the turning constraints in the navigation process of underactuated USVs, avoiding overly sharp turns, thereby making the path planning more realistic and easier to control. A multi-USV system consisting of a leader USV and follower USVs is constructed, and different reward mechanisms are designed for the leader and follower USVs to enhance the system’s formation capability, with a centralized training and distributed execution framework used to improve sample utilization efficiency. The algorithm enhances strategy exploration through an entropy regularization term. Simulation experiments validate the effectiveness of the proposed algorithm, demonstrating its superiority over multi-agent deep deterministic policy gradient and multi-agent proximal policy optimization algorithms in terms of mission completion, obstacle avoidance, and formation maintenance. Therefore, the MASAC algorithm effectively achieves cooperative formation path planning for multiple USVs in complex dynamic environments, providing a more efficient and reliable solution for a multi-USV system.},
  archive      = {J_APIN},
  author       = {Chen, Xizhe and Yin, Shihong and Li, Yujing and Xiang, Zhengrong},
  doi          = {10.1007/s10489-025-06626-8},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Real-time dynamic path planning for distributed unmanned surface vehicles in coordinated formations with maneuverability constraints},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review of federated learning technology and its research progress in healthcare applications. <em>APIN</em>, <em>55</em>(10), 1-30. (<a href='https://doi.org/10.1007/s10489-025-06627-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven medical applications, powered by big data and artificial intelligence, generate scalable models from extensive datasets. This innovation attracts both academia and industry, significantly enhancing healthcare quality while posing integration challenges. Federated learning emerges as a transformative approach in healthcare, facilitating collaborative machine learning while preserving data privacy. This article reviews research on federated learning in healthcare, utilizing the "Web of Science" database to examine development trends and application progress. Initially, the federated learning system is dissected, and its application methods are analyzed, summarizing 18 federated learning frameworks and 9 privacy-preserving methods suitable for federated learning, and exploring its limitations in healthcare applications. Subsequently, recent literature on federated learning in four major areas—disease diagnosis and risk assessment, medical image analysis, drug discovery and development, and disease management—is reviewed, summarizing the general process of applying Federated Learning in healthcare. Finally, the challenges faced by federated learning in the medical field and the solutions currently being explored by scholars are summarized. This article aims to comprehensively summarize the research progress and application trends of federated learning technology in the medical field, analyze its limitations and challenges, and anticipate its future development to further promote sustainable advancement in the healthcare industry.},
  archive      = {J_APIN},
  author       = {Ma, Zezhong and Ruhaiyem, Nur Intan Raihana and Zhang, Meng and Musa, Kamarul Imran and Hanis, Tengku Muhammad and Xiao, Tianyun and Hua, Dianbo and Li, Hao},
  doi          = {10.1007/s10489-025-06627-7},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-30},
  shortjournal = {Appl. Intell.},
  title        = {A review of federated learning technology and its research progress in healthcare applications},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DedustNet: A frequency-dominated swin transformer-based wavelet network for agricultural dust removal. <em>APIN</em>, <em>55</em>(10), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06635-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dust has an adverse effect on the environmental sensors of automated agricultural machinery. This issue highlights the need for further investigation. Refining existing deep learning methods for dust removal is critical for improving the performance and reliability of these machines in dusty environments. We propose an end-to-end trainable learning network (DedustNet) to address the challenge of agricultural dust removal in real-world scenarios. To our knowledge, DedustNet represents the first application of Swin Transformer-based units in wavelet networks for agricultural image dusting. DedustNet leverages frequency-dominated Swin Transformer-based blocks, namely, DWTFormer and IDWTFormer, in tandem with wavelet transforms. Acting as fundamental encoding and decoding units, these blocks enable the retrieval of intricate details, such as image structural and textural components. This approach effectively overcomes the limitations of the global receptive field in Swin Transformer under complex, dusty backgrounds. In addition, DedustNet incorporates a cross-level information fusion module (CIFM). This module adeptly integrates features from different levels, thereby facilitating the capture of global and long-range feature relationships. Moreover, DedustNet is enhanced by a dilated convolution module (DCM). This module leverages the guidance of wavelet transforms to extract contextual information at multiple scales. Compared with those of existing state-of-the-art methods, DedustNet achieves superior performance and more reliable results in agricultural image dedusting, validating the powerful application of applied intelligence in agriculture. Additionally, the impressive performance on real-world hazy datasets and application tests highlights DedustNet’s superior generalizability and computer vision-related application performance.},
  archive      = {J_APIN},
  author       = {Zhang, Shengli and Tao, Zhiyong and Lin, Sen},
  doi          = {10.1007/s10489-025-06635-7},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {DedustNet: A frequency-dominated swin transformer-based wavelet network for agricultural dust removal},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view semi-supervised feature selection based on adaptive graph and tensor learning. <em>APIN</em>, <em>55</em>(10), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06637-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view feature selection has gained popularity as a study area in the machine learning field, because it can effectively reduce the dimensionality of data. Due to the scarcity of labeled information, numerous algorithms for unsupervised feature selection have surfaced, while supervised or semi-supervised feature selection algorithms are relatively few. However, when there is a certain amount of labeled information, unsupervised learning algorithms fail to explore the true structure of samples due to their inherent limitations. A multi-view semi-supervised feature selection method based on adaptive graph and tensor learning is proposed to effectively reduce the dimension of data with few labels. The method completes the feature selection task by exploring high-order connections between views and discriminative label information. An efficient algorithm is designed to solve the resulted optimization problem. Compared with other mainstream methods, we have achieved a certain improvement in classification accuracy on multiple basic datasets which proves the superiority and universality of our method. We also conducted experiments such as convergence analysis to prove the effectiveness of our proposed method.},
  archive      = {J_APIN},
  author       = {Chen, Hangyu and Xie, Xijiong and Chao, Guoqing},
  doi          = {10.1007/s10489-025-06637-5},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Multi-view semi-supervised feature selection based on adaptive graph and tensor learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GTIBS: Secure smart home monitoring through gateway traffic analysis and behavioral signature identification. <em>APIN</em>, <em>55</em>(10), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06639-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, smart home devices from different vendors rely on isolated cloud platforms and proprietary application services, resulting in a lack of unified and localized supervision mechanisms for users to manage devices and their behaviors. Although traffic-based device and behavior identification methods offer promising third-party oversight capabilities, they often depend on large-scale traffic data collection for model training or signature extraction. Furthermore, such approaches typically require the construction of extensive signature libraries, making local deployment at the household level impractical. Even pre-trained models struggle to address traffic feature drift across different environments. This paper proposes a gateway traffic-based IoT device behavior monitoring and signature identification method (GTIBS). It can be directly deployed online at the gateway, targeting a limited number of devices on the network. It automatically segments different behavior traffic from the devices’ encrypted traffic, extracting features such as packet length and frequency of occurrences, inter-arrival time, and protocol type for clustering to generate unique signatures for each behavior. Experimental results on multiple smart home traffic datasets confirm the distinctiveness and reliability of the generated signatures. Furthermore, we introduce a packet-level online behavior identification mechanism that enables real-time signature matching. The evaluation results show that GTIBS achieves an average identification accuracy exceeding 97%. Additionally, GTIBS demonstrates low resource consumption when deployed in real-world environments, offering efficient signature construction and continuous monitoring of device behaviors.},
  archive      = {J_APIN},
  author       = {Hu, Yingjie and Wang, Weiping and Zhang, Shigeng},
  doi          = {10.1007/s10489-025-06639-3},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {GTIBS: Secure smart home monitoring through gateway traffic analysis and behavioral signature identification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion-based high dimensional subspace mapping for ECG generation with structured state space models. <em>APIN</em>, <em>55</em>(10), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06640-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrocardiogram (ECG) plays a critical role in diagnosing cardiac diseases by analyzing essential information from the ECG waves. Its convenience has been appreciated by many people. However, like other forms of medical data, ECG gives rise to privacy concerns when distributed and analyzed. Generating synthetic data offers a potential strategy for addressing the privacy issues when sharing sensitive and confidential health information. Recent advancements in diffusion models have opened up exciting possibilities for generating synthetic data that closely resembles real-world data without compromising individual privacy. In this paper, we have developed an innovative electrocardiogram data generation model that harnesses the power of conditional diffusion models. Our approach seamlessly integrates several advanced techniques to effectively capture both long-term temporal dependencies and short-range signal information by incorporating structured state space model and patch-transformer. To enhance the model’s ability of distinguishing subtle features of different diseases, we have mapped 71 different diagnosis features into 71 different high-dimensional subspaces. Furthermore, we have leveraged the capabilities of cross-transformer to capture information from dual perspectives and employed multi-scale convolutional technology to process data at various resolutions. We performed the experiments on the PTB-XL dataset to generate synthetic 12-lead 10s electrocardiograms conditioned on more than 70 different ECG diagnostic statements. We evaluated the results of our experiment using both quantitative and qualitative criteria to provide a comprehensive analysis of our model’s performance.},
  archive      = {J_APIN},
  author       = {Zhu, Baofeng and Peng, Chengbao and Zhang, Xia and Liu, Jiren},
  doi          = {10.1007/s10489-025-06640-w},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Diffusion-based high dimensional subspace mapping for ECG generation with structured state space models},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An emotional preference ensemble clustering based on directional increment and non-linear cosine adaptive crossover and mutation. <em>APIN</em>, <em>55</em>(10), 1-26. (<a href='https://doi.org/10.1007/s10489-025-06647-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm intelligence optimization has been widely utilized in many fields with the growth of scientific engineering and mathematics, and clustering is a data mining problem that requires settling theoretically. Since the emotional preference and migration behavior clustering (EPMC) model has efficiently solved the clustering tasks, it also suffers from premature convergence and the population diversity problem. Besides, the solution searching range of EPMC is too broad, and the evolution process is entirely random. Therefore, in order to enhance the optimization ability of the EPMC algorithm, we incorporate several evolution strategies such as the non-linear position weight, the directional position increment, and the novel non-linear cosine adaptive crossover and mutation method into the emotional preference and migration behavior clustering (EPMC) model. As a result, an emotional preference migration clustering model based on position increment nonlinear cosine adaptive crossover and mutation strategy (DPNG-EPMC) was proposed. The DPNG-EPMC can further prevent the algorithm from prematurely falling into local optimality similar to gradient descent, improve the diversity of the population, and enrich the family of the clustering methods. The proposed DPNG-EPMC is compared with the other nine clustering algorithms through numerous experiments, and the results of several criteria show the effectiveness of our proposed ensemble algorithm. Besides, theoretical analysis has verified the convergence of the DPNG-EPMC algorithm.},
  archive      = {J_APIN},
  author       = {Dai, Mingzhi and Feng, Xiang and Yu, Huiqun and Guo, Weibin},
  doi          = {10.1007/s10489-025-06647-3},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {An emotional preference ensemble clustering based on directional increment and non-linear cosine adaptive crossover and mutation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GraphCKSA: Innovative dual-strategy GNN for imbalanced node classification with CENN-KCQ resampling and dual-view edge optimization. <em>APIN</em>, <em>55</em>(10), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06660-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Graph Neural Networks (GNNs) have demonstrated exceptional performance in graph node classification tasks by effectively modeling complex relationships between nodes. However, real-world graphs often exhibit significant class imbalance, with minority class nodes being underrepresented, which leads to biased classification results that favor majority class. To address this challenge, we propose GraphCKSA, a novel graph resampling framework designed to tackle imbalanced node classification by CENN-KCQ resampling and dual-view edge optimization strategies. Specifically, our contributions are as follows: (i) We propose an innovative CENN undersampling method to address issues of noise and over-compression in majority class nodes, improving undersampling accuracy and efficiency. (ii) We design a KCQ-SMOTE oversampling method that combines KMeans clustering with intra-cluster SMOTE, while leveraging Q-learning to intelligently determine the optimal number of clusters K. This ensures high-quality and diverse oversampling of minority class nodes. (iii) We propose a dual-view edge optimization strategy, optimizing edge connections from both local and global perspectives. Locally, a resampled graph structure is built using cluster centers and k-nearest neighbors. Globally, a graph attention network reinforces key edges and filters out irrelevant ones. GraphCKSA constructs a high-quality, balanced augmented dataset, which significantly boosting the performance of GNN in imbalanced node classification tasks. Experimental results on three public benchmarks—Cora, Citeseer, and PubMed—demonstrate that GraphCKSA outperforms state-of-the-art models across ACC, AUC-ROC, and F1. Further ablation studies, imbalance ratios, oversampling scales and hyperparameter analysis validate the robustness and effectiveness of GraphCKSA, showcasing its potential for addressing imbalanced graph classification challenges.},
  archive      = {J_APIN},
  author       = {Zhang, Liying and Chen, Lumeng and Zou, Tianbo and Wang, Zhiguang and Zheng, Xinzhu},
  doi          = {10.1007/s10489-025-06660-6},
  journal      = {Applied Intelligence},
  month        = {7},
  number       = {10},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {GraphCKSA: Innovative dual-strategy GNN for imbalanced node classification with CENN-KCQ resampling and dual-view edge optimization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NSE: Node sequence encoding for link prediction in heterogeneous graphs. <em>APIN</em>, <em>55</em>(9), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06622-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In complex network analysis, link prediction is crucial for understanding the structure and dynamics of networks, as it helps identify potential connections. Existing heterogeneous graph distance encoding models based on shortest path often lose important topological features during the encoding process. To handle this dilemma, we propose a novel distance encoding method based on node sequences, aimed at improving both the accuracy and efficiency of link prediction in heterogeneous graphs. Our method first uses one-hot encoding to represent different node types, encoding the nodes in the order they appear along the shortest path between neighboring nodes and the target nodes, thereby forming the node sequence encoding. We then introduce a custom graph neural network architecture and employ a multi-layer perceptron to perform the link prediction task based on node sequence encoding.To demonstrate the effectiveness of our algorithm, we conducted extensive experiments on 4 public heterogeneous graph datasets, involving the prediction of 5 types of connection relationships. The results show that our model, which relies solely on the graph structure, achieves an average accuracy improvement of 1.3% compared to existing state-of-the-art models in link prediction tasks for heterogeneous networks. This research not only offers a new solution for link prediction in heterogeneous graphs but also provides a fresh perspective for analyzing and utilizing complex network structures.},
  archive      = {J_APIN},
  author       = {Tang, Ying and Chen, Xi and Zeng, Chenggang and Ma, Ji},
  doi          = {10.1007/s10489-025-06622-y},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {9},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {NSE: Node sequence encoding for link prediction in heterogeneous graphs},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage effective attentional generative adversarial network. <em>APIN</em>, <em>55</em>(8), 1-11. (<a href='https://doi.org/10.1007/s10489-025-06576-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although GAN models have succeeded in relevant tests, text-to-image modelling using GANs to synthesize high-quality images is still challenging. Existing multi-stage models face several problems: first, the scale is too large, and the model has a large number of redundant structures. Second, the model often generates duplicate images without progress and cannot update the parameters efficiently. In this paper, we propose a two-stage model to solve the above problem. 1)We remove the redundancy structure and use an improved network structure that reduces the scale of the model size. 2)Our method employs a model trained in two stages instead of simultaneously, which shortens the training time and ensures that the model does not have vanishing gradients or mode collapse. In addition, we added an attention mechanism to the model to help optimize details. Experimental results show that our model saw excellent results in terms of generation quality and reduced model size on CUB(IS 4.83, FID 15.13) and COCO dataset(FID 33.74).},
  archive      = {J_APIN},
  author       = {Jin, Mingyu and Yu, Qinkai and Zhang, Chong and Xue, Haochen and Zhao, Shuliang},
  doi          = {10.1007/s10489-025-06576-1},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-11},
  shortjournal = {Appl. Intell.},
  title        = {Two-stage effective attentional generative adversarial network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Small sample pipeline DR defect detection based on smooth variational autoencoder and enhanced detection head faster RCNN. <em>APIN</em>, <em>55</em>(8), 1-29. (<a href='https://doi.org/10.1007/s10489-025-06590-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The safe operation of gas pipelines is crucial for the safety of residents’ lives and property. However, accurately detecting defects within these gas pipelines is a challenging task. To improve the accuracy of defect detection in pipeline DR images with small sample sizes, we propose an enhanced Faster RCNN model based on a Smooth Variational Autoencoder and Enhanced Detection Head (S-EDH-Faster RCNN). This model leverages a smooth variational autoencoder to reconstruct features and enhances classification scores through an improved detection head, thereby boosting overall detection accuracy. In detail, to address the issue of scarce training samples for new categories, we design a smooth variational autoencoder to reconstruct features that better fit the distribution of training data. Furthermore, to refine classification precision, we present an enhanced detection head that incorporates a convolutional block attention-based center point classification calibration module, which strengthens classification-related portions of the RoI features and adjusts classification scores accordingly. Finally, to effectively learn characteristics of novel class samples, we introduce an adaptive fine-tuning method that adaptively updates key convolutional kernels during the fine-tuning stage, enabling the model to generalize better to novel classes. Experimental results demonstrate that our approach achieves superior detection performance over state-of-the-art models on both the home-made PIP-DET dataset and the publicly available NEU-DET dataset, demonstrating its effectiveness.},
  archive      = {J_APIN},
  author       = {Zhang, Ting and You, Tianyang and Liu, Zhaoying and Rehman, Sadaqat Ur and Shi, Yanan and Munshi, Amr},
  doi          = {10.1007/s10489-025-06590-3},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-29},
  shortjournal = {Appl. Intell.},
  title        = {Small sample pipeline DR defect detection based on smooth variational autoencoder and enhanced detection head faster RCNN},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning unified denoised representations for sequential recommendation. <em>APIN</em>, <em>55</em>(8), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06597-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential Recommendation (SR) has been widely used in many internet applications, such as e-commerce, social platforms and hot news. User behavior sequential data in SR typically contains complex patterns of short-term dependencies, long-term dependencies and noise, which may lead SR models to misinterpret user intentions and overfit noisy patterns, but existing methods cannot solve them simultaneously. To address this problem, we propose a model to learn Unified Denoised Representations (UniDR) for the SR task, which consists of three modules. The first module employs Graph Neural Networks (GNNs) with adaptive learning mechanisms to capture short-term dependencies by dynamically weighting item transitions. The second module utilizes self-attention mechanisms to effectively model long-term dependencies across the entire item sequence. The third module focuses on extracting long-term sequential patterns from contextual information through feed-forward networks. Each module independently generates denoised representations, either through weak edge removal in GNNs or through frequency domain transformations. UniDR integrates these denoised representations by jointly optimizing a BPR loss, an alignment loss and a uniformity loss. Extensive experiments on five public benchmark datasets demonstrate UniDR’s superiority in recommendation performance and robustness to interaction noise. Compared to the strongest state-of-the-art baseline, UniDR achieves significant improvements, with average increases of 10.63% in Hit Rate (HR), 21.47% in Normalized Discounted Cumulative Gain (NDCG) and 23.71% in Mean Reciprocal Rank (MRR).},
  archive      = {J_APIN},
  author       = {Jiang, Runsen and Huang, Jiajin and Xiao, Yadong and Yang, Jian},
  doi          = {10.1007/s10489-025-06597-w},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Learning unified denoised representations for sequential recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-decoupling inter-correction multitemporal framework for high-, medium-, and low-resolution optical remote sensing image reconstruction. <em>APIN</em>, <em>55</em>(8), 1-26. (<a href='https://doi.org/10.1007/s10489-025-06522-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing missing information due to cloud occlusion is an effective means of enhancing the utilization of low-, medium-, and high-resolution optical remote sensing images. However, singletemporal-based methods have limitations regarding the demand for cloud-free reference data and the applicability of specific datadriven models to real-world scenarios. It is more unable to realize mutitemporal reconstruction. To address this, we propose the Dual-Decoupling Inter-correction Multitemporal Reconstruction network (DDIM-RecNet), a unified framework designed for single- and multitemporal cloud occlusion reconstruction of low-, medium-, and high-resolution images. DDIM-RecNet innovatively decouples remote sensing images into ground object and imaging environment components using dedicated inter-correction modules, coupled with targeted loss functions. Additionally, an imaging environment enhancement module ensures spatial consistency between reconstructed and original regions. Compared with classical models, such as U-Net, RFR-Net, STGAN, PSTCR, BSN, GLDF-RecNet, and IDF-CR, DDIM-RecNet achieved excellent visual reconstruction results and the best quantitative evaluation indicators under Gaofen-1 (2 m), Sentinel-2 (10 m), Landsat-8 (30 m) single/multitemporal images. Taking Gaofen-1 (2 m) as an example, compared with the suboptimal model, the clarity of the DDIM-RecNet model in the three bands was improved by 0.44, 0.70, and 0.85 respectively under singletemporal reconstruction; the clarity of DDIM-RecNet was improved by 0.55, 0.43, and 0.35 respectively under mutitemporal cloud occlusion.},
  archive      = {J_APIN},
  author       = {Liu, Weiling and Huang, Changqing and Jiang, Yonghua and Wang, Jingyin and Zhang, Guo and Song, Huaibo and Li, Xinghua},
  doi          = {10.1007/s10489-025-06522-1},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Dual-decoupling inter-correction multitemporal framework for high-, medium-, and low-resolution optical remote sensing image reconstruction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-numbered singular matrix transformation for non-invertible and cancelable biometric templates. <em>APIN</em>, <em>55</em>(8), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06534-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancelable biometrics mitigate privacy and security concerns in biometric-based user authentication by transforming biometric data into non-invertible templates. However, achieving non-invertibility often comes at the cost of reduced discriminability. This paper presents RP-SmXOR, a novel approach for generating cancelable biometric templates, leveraging person-specific real-numbered singular matrices for non-invertible transformation. By combining random permutation, Bitwise-XOR, and the Hadamard product, RP-SmXOR retains and enhances the discriminative information in the templates while addressing the privacy and security concerns associated with traditional biometric authentication. The proposed method was extensively evaluated on seven diverse biometric databases, demonstrating superior performance compared to state-of-the-art random permutation-based techniques. A thorough privacy and security analysis, including brute-force, false acceptance, Attack via Record Multiplicity (ARM), and inverse attacks, along with similarity metrics, confirms the non-invertibility, security, and robustness of the generated templates. Thus, RP-SmXOR adheres to the key principles of cancelable biometrics while significantly improving recognition accuracy and establishing it as a promising solution for secure biometric authentication.},
  archive      = {J_APIN},
  author       = {Singh, Onkar and Jaiswal, Ajay and Kumar, Naveen},
  doi          = {10.1007/s10489-025-06534-x},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Real-numbered singular matrix transformation for non-invertible and cancelable biometric templates},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selective output smoothing regularization: Regularize neural networks by softening output distributions. <em>APIN</em>, <em>55</em>(8), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06539-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) often exhibit overfitting due to overconfident predictions, which limits the effective utilization of training samples. Inspired by the diverse effects of training from different samples, we propose selective output smoothing regularization(SOSR) that improves model performance by encouraging the generation of equal logits on incorrect classes when handling samples that are correctly and overconfidently classified. This plug-and-play approach integrates seamlessly into diverse CNN architectures without altering their core design. SOSR demonstrates consistent improvements on various benchmarks, such as a 1.1% accuracy gain on ImageNet with ResNet-50 (77.30%). It synergizes effectively with several widely used techniques, such as CutMix and label smoothing, achieving incremental benefits, highlighting its potential as a foundational tool in advancing deep learning applications. Overall, SOSR effectively alleviates underutilization of high-confidence samples, enhances the generalizability of CNNs, and emerges as a robust tool for improving deep learning applications.},
  archive      = {J_APIN},
  author       = {Cheng, Xuan and Xie, Tianshu and Wang, Xiaomin and Yang, Meiyi and Deng, Jiali and Liu, Minghui and Liu, Ming},
  doi          = {10.1007/s10489-025-06539-6},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Selective output smoothing regularization: Regularize neural networks by softening output distributions},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TsAFN: A two-stage adaptive fusion network for multimodal sentiment analysis. <em>APIN</em>, <em>55</em>(8), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06577-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis (MSA) provides a more accurate understanding of human emotional states than unimodal. However, the different modalities are limited by semantic expression in expressing emotion, leading to inconsistency in the importance of unimodal influence on the fused modal sentiment polarity, as well as sentiment polarity biases resulting from the interaction between multiple modalities. This can make MSA less accurate. To address this problem, we propose a two-stage adaptive fusion network (TsAFN) in this paper. The first stage is an adaptive fusion network based on the joint of modal features. Feature extraction is based on Bert and LSTM network. An importance metric adaptive benchmark is presented for proposing a feature planning method to jointly represent multimodal features to form fused modal features, which automatically equalizes the importance of unimodal influence on the fused modal sentiment polarity. The second stage is an adaptive fusion network based on modal interaction. A distance metric adaptive benchmark is defined, based on which a representation reconstruction method is proposed to take into account inter-modal interactions. The relationship and sentiment polarity biases of the modalities are adjusted to reconstruct unimodal sentiment polarity and a more accurate representation of the fused modality. Finally, the loss function is defined and the model is trained on three datasets MOSI, MOSEI, and CH-SIMS. The results of comparative experiments show that TsAFN can achieve better accuracy in MSA.},
  archive      = {J_APIN},
  author       = {Liu, Jiaqi and Wang, Yong and Yang, Jing and Yu, Xu and Zhao, Meng},
  doi          = {10.1007/s10489-025-06577-0},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {TsAFN: A two-stage adaptive fusion network for multimodal sentiment analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFPN: A dynamic fusion prototypical network for few-shot learning. <em>APIN</em>, <em>55</em>(8), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06581-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prototypical networks have been widely adopted for few-shot image classification. However, due to data scarcity, these methods often suffer from bias and struggle to capture discriminative features effectively. To address the problem, we propose a novel dynamic fusion prototypical network (DFPN) that learns more representative prototypes from limited training samples. In particular, we present a dynamic prototypical network that leverages dynamic routing within a meta-learning framework, effectively mapping sample representations to prototype representations. To further enhance prototype estimate, we design a distribution-based fusion strategy that mitigates biased distributions by integrating mean-based prototypes with adaptively generated dynamic prototypes. Moreover, we employ the Yeo-Johnson transformation to make the feature distribution more Gaussian-like, thereby improving representation quality. Extensive experiments on five benchmark datasets demonstrate the effectiveness of our method. Notably, our DFPN achieves state-of-the-art performance on the miniImageNet dataset, reaching 74.34% accuracy in the 5-way 1-shot setting and 86.56% in the 5-way 5-shot setting. These results demonstrate DFPN can learn more expressive prototypes, significantly advancing few-shot image classification performance.},
  archive      = {J_APIN},
  author       = {Dong, Mengping and Li, Fei and Li, Zhenbo and Liu, Xue},
  doi          = {10.1007/s10489-025-06581-4},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {DFPN: A dynamic fusion prototypical network for few-shot learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quadruped robot locomotion via soft actor-critic with muti-head critic and dynamic policy gradient. <em>APIN</em>, <em>55</em>(8), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06584-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quadruped robots’ nonlinear complexity makes traditional modeling challenging, while deep reinforcement learning (DRL) learns effectively through direct environmental interaction without explicit kinematic and dynamic models, becoming an efficient approach for quadruped locomotion across diverse terrains. Conventional reinforcement learning methods typically combine multiple reward criteria into a single scalar function, limiting information representation and complicating the balance between multiple control objectives. We propose a novel multi-head critic and dynamic policy gradient SAC (MHD-SAC) algorithm, innovatively combining a multi-head critic architecture that independently evaluates distinct reward components and a dynamic policy gradient method that adaptively adjusts weights based on current performance. Through simulations on both flat and uneven terrains comparing three approaches (Soft Actor-Critic (SAC), multi-head critic SAC (MH-SAC), and MHD-SAC), we demonstrate that the MHD-SAC algorithm achieves significantly faster learning convergence and higher cumulative rewards than conventional methods. Performance analysis across different reward components reveals MHD-SAC’s superior ability to balance multiple objectives. The results validate that our approach effectively addresses the challenges of multi-objective optimization in quadruped locomotion control, providing a promising foundation for developing more versatile and robust legged robots capable of traversing complex environments.},
  archive      = {J_APIN},
  author       = {Fan, Yanan and Pei, Zhongcai and Shi, Hongbing and Li, Meng and Guo, Tianyuan and Tang, Zhiyong},
  doi          = {10.1007/s10489-025-06584-1},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Quadruped robot locomotion via soft actor-critic with muti-head critic and dynamic policy gradient},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive unsupervised deep learning denoising for medical imaging with unbiased estimation and hessian-based regularization. <em>APIN</em>, <em>55</em>(8), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06591-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces an adaptive, unsupervised deep learning model for denoising Gaussian noise in Magnetic Resonance Imaging (MRI) images. The model is combined with Deep Image Prior (DIP) and Stein's Unbiased Risk Estimate (SURE) and incorporates a regularization term based on the Frobenius norm of the Hessian matrix. Leveraging the SURE criterion, the observed noisy image is used as the network input, significantly accelerating convergence speed and achieving more than a tenfold improvement over DIP. The real-time, adaptive adjustment of regularization intensity, driven by SURE, ensures robust performance across varying noise levels while effectively balancing the preservation of fine image details with noise elimination. The Hessian-based regularization captures second-order variations, promoting smoothness while preserving critical structural details. Experimental results demonstrate the model's superiority, with an average 8.7% increase in PSNR and a 10.1% increase in SSIM compared to DIP achieved. Furthermore, by the 25th iteration, the SSIM value of the proposed method had already surpassed the peak value reached by DIP at the 700th iteration and by DIP variants at the 2000th iteration. These advantages, coupled with the adaptive regularization strength adjustment, demonstrate the model's potential to enhance diagnostic accuracy and efficiency in medical applications.},
  archive      = {J_APIN},
  author       = {Zhang, Cheng and Yen, Kin Sam},
  doi          = {10.1007/s10489-025-06591-2},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive unsupervised deep learning denoising for medical imaging with unbiased estimation and hessian-based regularization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear self-attention with multi-relational graph for knowledge graph completion. <em>APIN</em>, <em>55</em>(8), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06592-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph completion (KGC) aims to infer missing facts based on the existing knowledge. Graph Convolutional Networks (GCNs) have gained significant traction due to their proficiency in effectively modeling graph structures, especially within the realm of Knowledge Graph Completion (KGC). In GCN-based KGC methodologies, GCNs are initially employed to generate comprehensive representations of entities, followed by the application of Knowledge Graph Embedding (KGE) models to elucidate the interactions among entities and relations. However, most GCN-based KGC models ignore the long-range pairwise relationships in the graph. To address these limitations and enhance KGC, we propose a model called Linear Self-Attention with Multi-Relational Graph Network (LTRGN). Specifically, this model merges GCN and linear self-attention to serve as the encoder. This model introduces a linear self-attention that can capture long-range node dependencies without introducing excessive computational overhead. Furthermore, we implement an attention mechanism designed to better assess the significance of various neighboring nodes relative to the source node. We demonstrate the effectiveness of the proposed LTRGN on the standard FB15k-237, WN18RR, Kinship, and UMLS datasets. On the dense graphs Kinship and UMLS, the MRR of our model improves by 1.3% and 4.1%, respectively, while Hits@1 increases by 1.7% and 6.4% compared to the best-performing model. The results show the efficacy of the model for the KGC task. The code is released at https://github.com/lixianqingliuyan/LTRGN .},
  archive      = {J_APIN},
  author       = {Liu, Weida and Qiang, Baohua and Chen, Ruidong and Xie, Yuan and Chen, Lirui and Chen, Zhiqin},
  doi          = {10.1007/s10489-025-06592-1},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Linear self-attention with multi-relational graph for knowledge graph completion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NLC-block: Enhancing neural network training robustness with noisy label reweighting. <em>APIN</em>, <em>55</em>(8), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06594-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Noisy labels pose a major challenge in supervised learning, often undermining the reliability and generalization of deep neural networks. Addressing this issue requires mitigating the adverse impact of mislabeled samples and avoiding overly complex architectures or extended training procedures. To this end, this paper proposes the NLC block (Noisy Label Correction), a lightweight, plug-and-play module inspired by the $$\gamma $$ -divergence weighting principle. Unlike traditional parameter-dependent methods, the NLC block integrates a feed-forward layer with a closed-form formula computation layer to dynamically reweight samples without introducing additional learnable parameters. This paper provides a theoretical analysis demonstrating its robustness and shows, through extensive experiments on real-world datasets, that the NLC block significantly improves model accuracy and stability under label noise. The implementation is publicly available at https://github.com/DebtVC2022/NLC-block .},
  archive      = {J_APIN},
  author       = {Liu, Ben and Hu, Qiao},
  doi          = {10.1007/s10489-025-06594-z},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {NLC-block: Enhancing neural network training robustness with noisy label reweighting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep RGB-guided generative network for unsupervised hyperspectral image super-resolution. <em>APIN</em>, <em>55</em>(8), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06595-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image (HSI) super-resolution (SR) aims to mathematically generate a high spatial resolution hyperspectral (HR-HS) image by merging the degraded observations: a low spatial resolution hyperspectral (LR-HS) image and a high spatial resolution multispectral or RGB (HR-MS/RGB) image. Currently, deep convolution network-based paradigms have been extensively explored to automatically learn the inherent priors of the latent HR-HS images and have shown remarkable performance progress. However, existing methods usually are realized in a fully supervised manner and have to previously prepare a large external dataset containing the degraded observations: the LR-HS/HR-RGB image and its corresponding HR-HS ground truth, which are difficult to collect, especially in the HSI SR scenario. To this end, this study proposes a novel unsupervised HSI SR method by using only the observed degradation data without any other external sample. Specifically, we use a deep RGB-guided generative network to generate the target HR-HS image with an encoder-decoder-based network. Since the observed HR-RGB image has a more detailed spatial structure, which may have better compatibility with the 2D convolution operation, we take the observed HR-RGB image as the network input to serve as the conditional guidance, while using the degraded observations to construct the loss function to guide the network learning. Experimental results on several benchmark HS image datasets demonstrate that the proposed unsupervised method achieves superior performance over various SoTA paradigms.},
  archive      = {J_APIN},
  author       = {Han, Xian-Hua and Liu, Zhe},
  doi          = {10.1007/s10489-025-06595-y},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Deep RGB-guided generative network for unsupervised hyperspectral image super-resolution},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One-bit distributed compressed sensing with partial gaussian circulant matrices. <em>APIN</em>, <em>55</em>(8), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06599-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-bit distributed compressed sensing has been widely used in multi-node networks and many other fields. Conventional approaches often employ random Gaussian measurement matrices, but these unstructured matrices demand significant memory and computational resources. To address this limitation, we propose the use of structured partial Gaussian circulant matrices. This kind of matrix facilitates faster matrix operations and permits low storage, making it more practical. To the best of our knowledge, we are the first to theoretically prove that these matrices satisfy the $$\ell _1/\ell _{2,1}$$ -RIP in one-bit distributed compressed sensing. We prove that the required number of measurements under partial Gaussian circulant measurements enjoys the same order with that of Gaussian, which, however, is more computational efficient. Furthermore, numerical experiments confirm that partial Gaussian circulant matrices and random Gaussian matrices exhibit comparable reconstruction performance. Additionally, partial Gaussian circulant matrices spend less recovery time, offering higher computational efficiency.},
  archive      = {J_APIN},
  author       = {Leng, Yuke and Hou, Jingyao and Liu, Xinling and Wang, Jianjun},
  doi          = {10.1007/s10489-025-06599-8},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {One-bit distributed compressed sensing with partial gaussian circulant matrices},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adventurer: Exploration with BiGAN for deep reinforcement learning. <em>APIN</em>, <em>55</em>(8), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06600-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent developments in deep reinforcement learning have been very successful in learning complex, previously intractable problems. Sample efficiency and local optimality, however, remain significant challenges. To address these challenges, novelty-driven exploration strategies have emerged and shown promising potential. Unfortunately, no single algorithm outperforms all others in all tasks and most of them struggle with tasks with high-dimensional and complex observations. In this work, we propose Adventurer, a novelty-driven exploration algorithm that is based on Bidirectional Generative Adversarial Networks (BiGAN), where BiGAN is trained to estimate state novelty. Intuitively, a generator that has been trained on the distribution of visited states should only be able to generate a state coming from the distribution of visited states. As a result, novel states using the generator to reconstruct input states from certain latent representations would lead to larger reconstruction errors. We show that BiGAN performs well in estimating state novelty for complex observations. This novelty estimation method can be combined with intrinsic-reward-based exploration. Our empirical results show that Adventurer produces competitive results on a range of popular benchmark tasks, including continuous robotic manipulation tasks (e.g. Mujoco robotics) and high-dimensional image-based tasks (e.g. Atari games).},
  archive      = {J_APIN},
  author       = {Liu, Yongshuai and Liu, Xin},
  doi          = {10.1007/s10489-025-06600-4},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Adventurer: Exploration with BiGAN for deep reinforcement learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural decomposition-based learning of large bayesian networks for detecting conditionally independent overlapping superstructure communities. <em>APIN</em>, <em>55</em>(8), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06601-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection is an advanced technique that is employed to facilitate the structural decomposition of large Bayesian networks and enable their learning processes. According to the nonoverlapping community characteristics of Bayesian networks, these networks are broken down into several nonoverlapping smaller subgraphs for learning. However, the learning results of this method are still poor because Bayesian networks are composed of overlapping subgraphs that share causal nodes. A unique decomposition method is introduced in this paper for learning large Bayesian network structures; this approach relies on the principles of overlapping community detection and superstructures. First, to preserve more true dependence relationships so that adjacent nodes are not separated, we present an algorithm for constructing a superstructure, which is an undirected independent graph. Second, to prevent the common parent nodes from being separated, we present a conditionally independent overlapping community detection algorithm to break the superstructure into some overlapping subgraphs. Finally, the subgraphs are individually learned and eventually combined into a whole network. To validate the effectiveness of our method, we conduct a comparative analysis against other famous methods using benchmark networks and large real-world datasets with thousands of variables. The experimental results demonstrate that our method outperforms the state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Jia, Xiaolong and Li, Hongru},
  doi          = {10.1007/s10489-025-06601-3},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Structural decomposition-based learning of large bayesian networks for detecting conditionally independent overlapping superstructure communities},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSR-GAN: Multi-scales decomposition representations for unsupervised anomaly detection. <em>APIN</em>, <em>55</em>(8), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06606-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection is crucial in many fields due to the unique combinations and complex multi-scale time-varying features of time series data, which require accurate analysis. However, previous research has failed to adequately address these complexities, lacking effective decomposition and multi-scale modeling to comprehensively capture differences between normal and abnormal time points at various scales. To address this, our study aims to propose an innovative approach, the Multi-Scale Reconstruction Network (MSR-GAN). It features a Multi-Scale Decoupling Module (MTD) to separate input time series into different-scale components and models the reconstruction as parallel full-scale time series recovery. Furthermore, a Reconstructed Residual Collaborative Learning Module (RRCL) is constructed to perform inter-scale interactions by adaptively calculating importance scores for generator weight control. Extensive experiments demonstrate MSR-GAN’s state-of-the-art performance on multiple benchmark datasets for time series anomaly detection, thus providing a more effective solution, enhancing monitoring and handling of abnormal situations in related fields, and promoting the further development of time series analysis techniques.},
  archive      = {J_APIN},
  author       = {Xu, Dongwei and Xia, Tianhao and Hou, Jiaye and Xiang, Yun and Xuan, Qi},
  doi          = {10.1007/s10489-025-06606-y},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {MSR-GAN: Multi-scales decomposition representations for unsupervised anomaly detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMC-watermark: A backdoor richer watermark for dual identity verification by dynamic mask covering. <em>APIN</em>, <em>55</em>(8), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06608-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing use of neural networks, the importance of copyright protection for these models has gained significant attention. Backdoor watermarking is one of the key methods for protecting copyright. However, on the one hand, most existing backdoor watermarks are triggered by visual images, making them easily detectable, and therefore vulnerable to various attacks. On the other hand, it is difficult for these methods to carry information related to the creator’s identity which can easily lead to fraudulent claims of ownership. These factors contribute to the vulnerability and limitations of backdoor watermarking. In this paper, we propose DMC-Watermark, a backdoor richer watermarking method that uses dynamic mask-covered image structures as triggers. Leveraging the semantic preservation of image structure in transformation attacks, we select image structure as triggers. Furthermore, we convert the author-related information into an array of color information and apply it as a mask to the extracted image structures, allowing it to serve as a second layer of verification during the validation phase to resist fraudulent claims of ownership. The final trigger pattern, embedded with author-related image structures, is applied to the selected images in the trigger set, generating a final trigger set that is trained together with clean samples to produce a protected model. The experiments show that the proposed DMC-Watermark performs well in terms of fidelity, invisibility, undetectability, functionality, dual verification and robustness on three different datasets and four representative DNNs, and it has wide applicability and excellent results in high-resolution images.},
  archive      = {J_APIN},
  author       = {Zhu, Yujia and Wang, Ruoxi and Xia, Daoxun},
  doi          = {10.1007/s10489-025-06608-w},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {DMC-watermark: A backdoor richer watermark for dual identity verification by dynamic mask covering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AEP: An adaptive ensemble p300-BCI classifier based on user-feedback and knowledge-transfer. <em>APIN</em>, <em>55</em>(8), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06612-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a stable and reliable paradigm, P300-based brain-computer interface (P300-BCI) is expected to play an important role in efforts to replace, restore, enhance, supplement, or improve the natural output of the brain. However, the costly calibration of P300-BCI limits its development. The calibration-free approaches for P300-BCI have become a research focus in the field. In this work, we forwarded our previous study, transferred P300 linear upper confidence bound (TPLUCB), to propose an adaptive ensemble P300-BCI classifier (AEP). This renovation mainly includes a simplified calculation method and a dynamical update strategy. The competitive calculation model in TPLUCB was simplified as a linear calculation model. Based on this, a dynamical update strategy was proposed to facilitate the growth of target domain model and optimize the weights, by which the source domain models and the target domain model are combined as a P300-BCI classifier, i.e. AEP. We conducted the performance evaluation by observing the classifier’s dynamical development and overall performance. The comparison in the two aspects between AEP and TPLUCB demonstrates AEP’s clear advantage over TPLUCB. Without prior calibration, AEP achieved an average ITR exceeding 40 bit/min on electroencephalogram (EEG) data of 20 subjects. This work has provided a better calibration-free approach for P300-BCI and is an important step towards promoting the research on calibration-free BCIs.},
  archive      = {J_APIN},
  author       = {Huang, Zhihua and Chen, Qingzhi and Chen, Xuewei and Zheng, Wenming and Lin, Zhixiong and Luo, Tian-jian},
  doi          = {10.1007/s10489-025-06612-0},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {AEP: An adaptive ensemble p300-BCI classifier based on user-feedback and knowledge-transfer},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An intelligent MIMO run-to-run controller for semiconductor manufacturing processes based on an enhanced twin-delayed deep deterministic policy gradient algorithm. <em>APIN</em>, <em>55</em>(8), 1-25. (<a href='https://doi.org/10.1007/s10489-025-06615-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving accurate target tracking in semiconductor manufacturing processes with complex nonlinearities, strong coupling, and uncertain disturbance environments poses a formidable challenge to run-to-run (RtR) control. In this study, we propose an innovative approach for the online refinement of multi-input multi-output double exponentially weighted moving average (dEWMA) controllers by applying deep reinforcement learning (DRL) techniques. This method harnesses the dynamic interaction capabilities of DRL with the operational environment, facilitating the adaptive tuning of dEWMA parameters to improve the control performance. To further enhance the learning efficiency of the DRL agent, a lightweight DRL model is proposed by combining the structural control network (SCN) with the twin-delayed deep deterministic policy gradient (TD3) algorithm. The SCN component improves the control efficiency by partitioning the policy network into linear and nonlinear modules, enabling the extraction of both local and global features for more effective control. Accordingly, a composite control strategy that synergizes SCN-TD3 with dEWMA is developed. The effectiveness and superiority of the proposed method are rigorously validated through comprehensive comparisons over various disturbance scenarios in both linear and nonlinear chemical mechanical polishing processes. These findings highlight the potential of the proposed DRL-based approach for intelligent RtR control and contribute to yield improvement in semiconductor manufacturing.},
  archive      = {J_APIN},
  author       = {Ma, Zhu and Chen, Yonglin and Pan, Tianhong},
  doi          = {10.1007/s10489-025-06615-x},
  journal      = {Applied Intelligence},
  month        = {6},
  number       = {8},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {An intelligent MIMO run-to-run controller for semiconductor manufacturing processes based on an enhanced twin-delayed deep deterministic policy gradient algorithm},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling the frontiers of deep learning: Innovations shaping diverse domains. <em>APIN</em>, <em>55</em>(7), 1-55. (<a href='https://doi.org/10.1007/s10489-025-06259-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) allows computer models to learn, visualize, optimize, refine, and predict data. To understand its present state, examining the most recent advancements and applications of deep learning across various domains is essential. However, prior reviews focused on DL applications in only one or two domains. The current review thoroughly investigates the use of DL in four different broad fields due to the plenty of relevant research literature in these domains. This wide range of coverage provides a comprehensive and interconnected understanding of DL’s influence and opportunities, which is lacking in other reviews. The study also discusses DL frameworks and addresses the benefits and challenges of utilizing DL in each field, which is only occasionally available in other reviews. DL frameworks like TensorFlow and PyTorch make it easy to develop innovative DL applications across diverse domains by providing model development and deployment platforms. This helps bridge theoretical progress and practical implementation. Deep learning solves complex problems and advances technology in many fields, demonstrating its revolutionary potential and adaptability. CNN-LSTM models with attention mechanisms can forecast traffic with 99% accuracy. Fungal-diseased mango leaves can be classified with 97.13% accuracy by the multi-layer CNN model. However, deep learning requires rigorous data collection to analyze and process large amounts of data because it is independent of training data. Thus, large-scale medical, research, healthcare, and environmental data compilation are challenging, reducing deep learning effectiveness. Future research should address data volume, privacy, domain complexity, and data quality issues in DL datasets.},
  archive      = {J_APIN},
  author       = {Ahmed, Shams Forruque and Alam, Md. Sakib Bin and Kabir, Maliha and Afrin, Shaila and Rafa, Sabiha Jannat and Mehjabin, Aanushka and Gandomi, Amir H.},
  doi          = {10.1007/s10489-025-06259-x},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-55},
  shortjournal = {Appl. Intell.},
  title        = {Unveiling the frontiers of deep learning: Innovations shaping diverse domains},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated interpretation and clustering model based on attribute grouping. <em>APIN</em>, <em>55</em>(7), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06262-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a technique in unsupervised learning used to group unlabeled data. However, traditional clustering algorithms cannot provide explanations for the clustering process and its results, which limits their applicability in certain fields. Existing methods to address the lack of interpretability in clustering algorithms typically focus on explaining the results after the clustering process is complete. Few studies explore embedding interpretability directly into the clustering process, and most of these methods rely on data prototypes to express interpretability, which often leads to explanations that are not intuitive and user-friendly. To address this, a feature-based method is proposed to embed interpretability into the clustering process. This approach provides users with intuitive and easy-to-understand explanations and introduces a new direction for research on embedding interpretability into clustering. The method operates in two stages: in the first stage, all attributes are grouped; in the second stage, an optimization formula is used to complete both the clustering and the weighting of each attribute group. The proposed method was evaluated on multiple synthetic and real-world datasets and compared with other methods. The experimental results show that the method improves clustering accuracy by approximately 5 percent and interpretability by around 40 percent compared to existing approaches.},
  archive      = {J_APIN},
  author       = {Chen, Liang and Sun, Leming and Zhong, Caiming},
  doi          = {10.1007/s10489-025-06262-2},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {An integrated interpretation and clustering model based on attribute grouping},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep attribute graph clustering based on bisymmetric network information fusion and mutual influence. <em>APIN</em>, <em>55</em>(7), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06295-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep attribute graph clustering has always been a challenging task and an important research topic for real-world data. In recent years, there has been a growing trend in using multi-network information fusion for deep attributed graph clustering. However, existing methods in deep attributed graph clustering have not effectively integrated representations learned from multiple networks and failed to construct a joint loss function that could impact the overall network model, resulting in poor clustering results. To address the aforementioned issues, we proposed AGC-BNIFI, an attribute graph clustering method based on dual symmetric network information fusion and mutual influence. The network of this method consists of a symmetric graph autoencoder and an autoencoder. The two different encoders are combined to improve the attribute learning ability. First, a symmetric graph autoencoder with a symmetric structure is proposed to capture complex linear and adapt to complex graph structure relationships and propagate heterogeneous information of joint embedding and structural features, and can reconstruct the attribute matrix and adjacency matrix; secondly, a layer-by-layer adaptive dynamic fusion module is designed to adaptively fuse the representations learned by each layer of the two encoders, and then learn a better joint representation for clustering tasks; finally, a multi-distribution self-supervision module with soft clustering assignments obtained from different networks that learn from each other and influence each other is proposed, which integrates representation learning and clustering tasks into an end-to-end framework, and jointly optimizes representation learning and clustering tasks by designing a joint loss function. Extensive experimental results on four graph datasets demonstrate the superiority of AGC-BNIFI over state-of-the-art methods. On the Coauthor-Physics dataset, compared to MBN, AGC-BNIFI achieved improvements of 2.6%, 1.1%, 4.3%, and 6.3% in four clustering metrics, respectively.},
  archive      = {J_APIN},
  author       = {Tan, Shuqiu and Zhang, Lei and Liu, Yahui and Zhang, Jianxun},
  doi          = {10.1007/s10489-025-06295-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Deep attribute graph clustering based on bisymmetric network information fusion and mutual influence},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic linguistic hesitant fuzzy multi-attribute decision making for rural revitalization project selection of china. <em>APIN</em>, <em>55</em>(7), 1-41. (<a href='https://doi.org/10.1007/s10489-025-06305-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rural revitalization strategy has pointed out the right direction for solving Chinese "three rural" problems. Selecting the most suitable rural revitalization project can be regarded as a multi-attribute decision making (MADM) problem. This paper utilizes the probabilistic linguistic (PL) hesitant fuzzy sets (PLHFSs) to characterize the uncertain information of evaluating rural revitalization projects. PLHFS introduces the characteristics of linguistic hesitant fuzzy set (LHFS) into probabilistic linguistic term set (PLTS), which can represent the membership degrees of linguistic terms (LTs) and the associated probabilities to the set, simultaneously. The normalized and ordered PLHFS is proposed. Some new operation laws for PLHFSs are defined by using Archimedean T-norm and T-conorm (ATT) functions. By employing the Maclaurin symmetric mean (MSM) operator and power average (PA) operator, this paper develops a probabilistic linguistic hesitant fuzzy Archimedean power Maclaurin symmetric mean (PLHFAPMSM) operator and a probabilistic linguistic hesitant fuzzy Archimedean power weighted Maclaurin symmetric mean (PLHFAPWMSM) operator. Some desirable properties of the PLHFAPMSM and PLHFAPWMSM operators are discussed deeply. For MADM with PLHFSs, the individual attribute weight vector for each alternative is derived by data envelopment analysis (DEA). Further, the comprehensive attribute weight vector is determined by a linear goal programming model. Thereby, using the PLHFAPWMSM operator, a new method for MADM with PLHFSs is proposed. Finally, a practical example of rural revitalization project selection is analyzed to illustrate the effectiveness and feasibility of the proposed method.},
  archive      = {J_APIN},
  author       = {Dong, Jiu-Ying and Gong, Si-Hang and Wan, Shu-Ping},
  doi          = {10.1007/s10489-025-06305-8},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-41},
  shortjournal = {Appl. Intell.},
  title        = {Probabilistic linguistic hesitant fuzzy multi-attribute decision making for rural revitalization project selection of china},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep reinforcement learning approach and its application in multi-USV adversarial game simulation. <em>APIN</em>, <em>55</em>(7), 1-24. (<a href='https://doi.org/10.1007/s10489-025-06380-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the progression of unmanned surface vehicle (USV) intelligence and the maturation of cluster control technologies, intelligent decision-making methods for multi-USV adversarial games have become pivotal technological focuses. Deep reinforcement learning (DRL), a prominent subset of artificial intelligence, has recently achieved notable advancements, heralding significant potential for this field. The intrinsic curiosity module (ICM), self-play (SP), and posthumous credit assignment (POCA) are integrated with proximal policy optimization (PPO) to address the challenges of sparse reward, low sample utilization, and credit assignment in multi-USV adversarial games, and a novel proximal policy optimization algorithm (PPO-ICMSPPOCA) is finally constructed. The algorithm generates intrinsic rewards through iterative training during multi-USV adversarial games while simultaneously addressing the evaluation of each USV's specific contribution to the team and the challenge of varying numbers of USVs. A perturbation mathematical model for a USV with three degrees of freedom is established, considering the influence of external environmental disturbances and variations in the USV's state on its hydrodynamic performance in this paper. With the Unity3D and ML-Agents toolkit platforms, multi-USV adversarial game simulation scenes, which can integrate and load various reinforcement learning (RL) algorithms, have been developed. Symmetric or asymmetric game experiments of different scales are conducted in adversarial games. The experiments show that the red teams with our algorithms can learn adversarial tactics more quickly, such as troop dispersion and coordinated attacks. Over 100 episodes, the red teams with ICM, SP, and POCA achieved win rates of 88.25%, 86.75%, and 91.33%, respectively, exhibiting higher game intelligence while obtaining higher cumulative rewards.},
  archive      = {J_APIN},
  author       = {Rao, Jinjun and Wang, Cong and Liu, Mei and Chen, Jinbo and Lei, Jingtao and Giernacki, Wojciech},
  doi          = {10.1007/s10489-025-06380-x},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {A deep reinforcement learning approach and its application in multi-USV adversarial game simulation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New 2D hyperchaotic cubic-tent map and improved 3D hilbert diffusion for image encryption. <em>APIN</em>, <em>55</em>(7), 1-25. (<a href='https://doi.org/10.1007/s10489-025-06414-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In image encryption, the effectiveness of chaotic maps significantly affects the effect of image encryption technology. However, existing chaotic maps have an issue of uneven value distribution when generating chaotic sequences, which could pose a threat to information security. To address this issue, a new two-dimensional Cubic-Tent map (2D-CTM) has been developed based on the Cubic and Tent maps. A series of comparative experiments on the 2D-CTM effectively validate its excellent chaotic properties. A novel image encryption algorithm utilizing 2D-CTM (CTM-IEA) is developed to encrypt images. This algorithm includes bit-level random scrambling, bit-level flipping, and improved 3D Hilbert diffusion process. First, the binary elements corresponding to different pixels in the plaintext image are randomly scrambled. Subsequently, the scrambled binary elements are flipped using a chaotic matrix, thoroughly obfuscating the binary information of the plaintext image and successfully hiding the plaintext information. Finally, the improved 3D Hilbert diffusion is applied to the image, eliminating pixel correlation in the original image and enhancing its security. Additionally, bit-level scrambling and diffusion are carried out in three rounds, which bolster the image’s defense against differential attacks. Compared to traditional encryption methods, this approach offers improved security by ensuring more uniform chaotic sequences and integrating a multi-round, bit-level encryption process. The security analysis shows that the key space reaches $${2}^{471}$$ , with correlation coefficients of 0.0006, 0.00004, and $$-$$ 0.0010, and an information entropy of 7.9998. The NPCR is 99.6084%, and the UACI is 33.4620%, which prove the effectiveness and reliability of the algorithm.},
  archive      = {J_APIN},
  author       = {Xu, Xin-li and Song, Xin-guang and Liu, Si-hang and Zhou, Nan-run and Wang, Meng-meng},
  doi          = {10.1007/s10489-025-06414-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {New 2D hyperchaotic cubic-tent map and improved 3D hilbert diffusion for image encryption},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Demystifying the black box: AI-enhanced logistic regression for lead scoring. <em>APIN</em>, <em>55</em>(7), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06430-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To mitigate interpretability challenges in business decision-making due to the black-box nature of generative Artificial Intelligence(AI), and to address high information processing costs and inconsistent feature collection standards, a novel marketing lead evaluation framework integrating large language models (LLMs) and classical machine learning algorithms was developed. The framework encompasses three modules: (1) a multi-agent question-answering system leveraging Retrieval-Augmented Generation(RAG) and LLMs; (2) a feature extraction and memory module for precise natural language and public data processing; and (3) a logistic regression (LR) model, trained on 540,000 automotive lead records, with associated calculation logic for decision support. Results indicate that the multi-agent system accurately identifies intentions and routes modules, the feature extraction module reduces manual follow-up costs, and the LR-guided LLM output enhances interpretability. These findings highlight the framework’s potential for auditing abnormal events and advancing marketing intelligence and business systematization.},
  archive      = {J_APIN},
  author       = {LIU, Bingran},
  doi          = {10.1007/s10489-025-06430-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Demystifying the black box: AI-enhanced logistic regression for lead scoring},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual heterogeneous graph contrastive learning for QoS prediction. <em>APIN</em>, <em>55</em>(7), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06431-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of Web Services leads to homogeneity issues, making accurate Quality of Service (QoS) prediction extremely helpful for inexperienced users to choose suitable services. However, the complex relationship between users and services in service invocation poses numerous challenges on QoS prediction. Given the capability of graph neural networks in modeling diverse relationships, a Dual Heterogeneous Graph Contrastive Learning method (DHGCL) is proposed in this paper to achieve high-accuracy QoS prediction. First, a dual heterogeneous graph is innovatively constructed, in which a global interaction graph is generated by a proposed graph learning to enable the direct interactions concerning the distant neighbors, while a local relationship graph is simultaneously constructed to enhance the close associations between users and services through spectral clustering. On this basis, the graph convolution network on the meta-paths is further designed to acquire the embedding of nodes for both of these two graphs. Finally, the global-local contrastive learning is served as a self-supervised mechanism to balance global interaction and local relationship information, and to complete the final QoS prediction. Extensive experiments have proven that our DHGCL method can achieve significantly higher accuracy than most of existing methods with the help of the dual heterogeneous graph.},
  archive      = {J_APIN},
  author       = {Xiu, Yuting and Ding, Ding and Wu, Ziteng and Zhao, Yuekun and Liu, Jiaqi},
  doi          = {10.1007/s10489-025-06431-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Dual heterogeneous graph contrastive learning for QoS prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel classification method based on an online extended belief rule base with a human-in-the-loop strategy. <em>APIN</em>, <em>55</em>(7), 1-26. (<a href='https://doi.org/10.1007/s10489-025-06434-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification methods, such as fault diagnosis and intrusion detection, are widely used in modeling complex systems. The accuracy and credibility of these methods directly affect the reliability of the modeling results, which in turn determines the effectiveness of engineering decisions. Additionally, the model's ability to be dynamically updated should be considered, given the intricate and ever-changing nature of engineering environments. For online models, adding new training samples without considering their suitability can lead to problems such as poor model performance and increased rule base complexity. Furthermore, amid constantly arriving new samples in a dynamic environment, modeling based only on initial expert knowledge can result in new samples not being fully used. Therefore, a novel classification method based on an online extended belief rule base with a human-in-the-loop strategy (OEBRB-H) is proposed in this paper. First, a fuzzy c-means algorithm based on expert knowledge (FBE) is designed to evaluate model parameters online. Second, a human-in-the-loop strategy for dividing the new sample set and a domain-value-based rule updating method are proposed for model optimization. Finally, two case studies, namely, aeroengine inter-shaft bearing fault diagnosis and industrial control intrusion detection, are performed. The results indicate that the model proposed in this paper can maintain both credibility and high accuracy in dynamic environments.},
  archive      = {J_APIN},
  author       = {Li, Jinyuan and Qian, Guangyu and He, Wei and Zhu, Hailong and Zhou, Guohui},
  doi          = {10.1007/s10489-025-06434-0},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {A novel classification method based on an online extended belief rule base with a human-in-the-loop strategy},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IAMTrack: Interframe appearance and modality tokens propagation with temporal modeling for RGBT tracking. <em>APIN</em>, <em>55</em>(7), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06438-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGBT tracking has emerged as a robust solution for various applications, including surveillance, autonomous driving, and robotics, owing to its resilience in challenging environments. However, existing RGBT tracking approaches often overlook target appearance changes, location shifts, and the dynamic significance of modality features, limiting long-term tracking accuracy. To address these limitations, we propose IAMTrack, a novel transformer-based framework that achieves sequential tracking by propagating modality and appearance tokens across frames. The method compresses the discriminative features of each modality into modality tokens to transmit modality quality and target location information in real time, allowing the model to focus more on features with high modality quality and features with high target probability, while suppressing noise and redundant information. It also compresses the appearance features of objects similar in appearance across frames into appearance tokens to convey changes in appearance. To further enhance the token learning capability, we design a temporal generalized relation modelling approach that guides future predictions based on past information. The experimental results show that IAMTrack outperforms existing methods in various RGBT tracking scenarios, especially in UAV tracking tasks. Compared with those of previous methods, the MPRs and MSRs of the VTUAV short-term and long-term subdatasets are improved by $$1.7\%/2.1\%$$ and $$2.5\%/2.2\%$$ , respectively.},
  archive      = {J_APIN},
  author       = {Shi, Huiwei and Mu, Xiaodong and He, Hao and Zhong, Chengliang and Zhang, Bo and Zhao, Peng},
  doi          = {10.1007/s10489-025-06438-w},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {IAMTrack: Interframe appearance and modality tokens propagation with temporal modeling for RGBT tracking},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine sound anomaly detection based on dual-channel feature fusion variational auto-encoder. <em>APIN</em>, <em>55</em>(7), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06449-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing intelligence and automation of industrial equipment, the technology for detecting equipment anomalies has become increasingly important. Compared to image-based anomaly detection methods, sound-based anomaly detection methods have the advantages of being non-intrusive, real-time and having lower data collection costs. These advantages make them highly valuable for research. Currently, deep learning methods that focus on spectrogram reconstruction have become widely utilized in the field of machine sound anomaly detection research. However, previous methods only attempted to mitigate the impact of noise without enabling the model to fully learn the distribution of sound features during the reconstruction process. In this paper, a novel Dual-Channel Feature Fusion Variational Autoencoder (DCFF-VAE) is proposed to effectively improve its reconstruction ability and help it better learn the normal sound features. In this method, the deep features extracted from the convolution layer and bidirectional gated cycle unit in the encoder are integrated by means of concatenation to make full use of the important features in the sound. Subsequently, grouped deconvolution is applied in the decoder to reduce model complexity while enhancing its perceptual ability for features. Additionally, during the anomaly detection phase, anomaly scores are calculated based on the Mahalanobis distance to better capture the differences between normal and abnormal sounds. Anomaly detection experiments conducted on five types of machines demonstrate that DCFF-VAE not only achieves the best stability but also surpasses the best comparison method by 3.14% and 1.21% in AUC and pAUC metrics, respectively.},
  archive      = {J_APIN},
  author       = {Zhang, Chen and Wei, Yongkang and Wang, Xiaofeng and Wu, Xiaoxuan and Zhu, Xuhui},
  doi          = {10.1007/s10489-025-06449-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Machine sound anomaly detection based on dual-channel feature fusion variational auto-encoder},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Harmful data enhanced anomaly detection for quasi-periodic multivariate time series. <em>APIN</em>, <em>55</em>(7), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06461-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate quasiperiodic time series (MQTS) anomaly detection has demonstrated significant potential across various practical applications, including health monitoring, intelligent maintenance, and quantitative trading. Recent research has introduced diverse methods based on autoencoders (AEs) and generative adversarial networks (GANs) that learn latent representations of normal data and subsequently detect anomalies through reconstruction errors. However, anomalous training set data can cause model pollution, which harms the ability to of the utilized model reconstruct normal data. The current data extreme imbalance creates an enormous challenge in terms of stripping out these anomalies. In this paper, we propose a GAN-based multivariate quasiperiodic time series anomaly detection method called IGANomaly (I represents isolation). This method isolates normal and harmful samples via pseudolabeling and then learns harmful data patterns to enhance the process of reconstructing of normal samples. First, the reconstruction error and potential feature distribution are jointly analyzed. Bimodal dynamic alignment is achieved through multiview clustering, thus overcoming the limitation of unidimensional determination. Second, dual reconstruction constraints for the generator and a gradient penalty mechanism for the discriminator are constructed. While maintaining the reconstruction quality achieved for normal samples, the propagation path of abnormal features is actively perturbed through a gradient inversion strategy. On three public datasets, IGANomaly achieves $$F1\ scores$$ of 0.811, 0.846, and 0.619, demonstrating an average improvement of 18.9% over the best baseline methods.},
  archive      = {J_APIN},
  author       = {Wang, Liyuan and Zhou, Yong and Ke, Wuping and Zheng, Desheng and Min, Fan and Li, Hui},
  doi          = {10.1007/s10489-025-06461-x},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Harmful data enhanced anomaly detection for quasi-periodic multivariate time series},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical-enhanced graph convolutional networks leveraging causal inference for aspect-based sentiment analysis. <em>APIN</em>, <em>55</em>(7), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06465-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) aims to determine the sentiment polarity of a particular aspect in a sentence. Existing research focuses on shortening the distance between opinion words and aspect words, resulting in spurious correlations. At the same time, the use of different dependent tools will bring different types of noise, destroying the effectiveness of the model. To address these issues, we propose a causal model of hierarchically augmented graph convolutional networks (CausalGCN). Specifically, we subdivide the language features into four relationships and then construct their corresponding mask matrices based on different relationships. At the same time, we introduce an instrumental variable to eliminate the confounders generated by the tool. Our model then combines the resulting mask matrix with localized attention at multiple levels. We treat the relationships between words and adjacent tensors as nodes and edges respectively, resulting in a multi-channel graph. Finally, we utilize graph convolutional networks to enhance relationship-aware node representations. Experimental results on three benchmark datasets demonstrate the effectiveness of the proposed model.},
  archive      = {J_APIN},
  author       = {Zhou, Fengling and Li, Zhixin and Zhang, Canlong and Ma, Huifang},
  doi          = {10.1007/s10489-025-06465-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Hierarchical-enhanced graph convolutional networks leveraging causal inference for aspect-based sentiment analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRHGNN: A dynamic residual hypergraph neural network for aspect sentiment triplet extraction. <em>APIN</em>, <em>55</em>(7), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06466-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect Sentiment Triple Extraction (ASTE) is an emerging sentiment analysis task. Many existing methods focus on designing a new labeling scheme to enable end-to-end operation of the model. However, these methods overlook the relationships between words in the ASTE task. In this paper, we propose the Dynamic Residual Hypergraph Neural Network (DRHGNN), which fully considers the relationships between words. Specifically, based on the pre-defined ten types of word pair relationships, we employ a graph attention network to model sentence features as a relational graph matrix. Subsequently, we use a dynamic hypergraph network to learn deep features from the transformed graph structure, then constructing relation-aware node representations. Furthermore, we integrate a residual connection to improve the performance of our DRHGNN model. Finally, we design a relationship constraint to dynamically control the number of hyperedges, thereby enhancing the effectiveness of the dynamic hypergraph neural network. Extensive experimental results on benchmark datasets show that our proposed model significantly outperforms state-of-the-art methods, demonstrating the effectiveness and robustness of the model.},
  archive      = {J_APIN},
  author       = {Guo, Peng and Yu, Zihao and Li, Chao and Sun, Jun},
  doi          = {10.1007/s10489-025-06466-6},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {DRHGNN: A dynamic residual hypergraph neural network for aspect sentiment triplet extraction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ResU-KAN: A medical image segmentation model integrating residual convolutional attention and atrous spatial pyramid pooling. <em>APIN</em>, <em>55</em>(7), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06467-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of medical imaging data, precise segmentation and analysis of medical images face unprecedented challenges. Addressing small sample sizes, significant variations, and structurally complex medical imaging data to improve the accuracy of early diagnosis has become a key issue in the medical field. This study proposes a Residual U-KAN model (ResU-KAN) to tackle this challenge and improve medical image segmentation accuracy. First, to address the model’s shortcomings in capturing long-distance dependencies and issues like potential gradient vanishing (or explosion) and overfitting, we introduce a Residual Convolution Attention (RCA) module. Second, to expand the model’s receptive field while performing multi-scale feature extraction, we introduce an Atrous Spatial Pyramid Pooling module (ASPP). Finally, experiments were conducted on three publicly available medical imaging datasets, and comparative analysis with existing state-of-the-art methods demonstrated the effectiveness of the proposed approach. Project page: https://github.com/Alfreda12/ResU-KAN},
  archive      = {J_APIN},
  author       = {Wang, Haibin and Zhao, Zhenfeng and Liu, Qi and Wang, Shenwen},
  doi          = {10.1007/s10489-025-06467-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {ResU-KAN: A medical image segmentation model integrating residual convolutional attention and atrous spatial pyramid pooling},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-temporal context-aware network for 3D-craft generation. <em>APIN</em>, <em>55</em>(7), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06468-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generative modeling of 3D objects in the real world is an interesting but challenging task commonly constrained by process and order. Most existing methods focus on spatial relations to address this issue, neglecting the rich information between temporal sequences. To close this gap, we deliver a spatial-temporal context-aware network to explore the prediction of ordered actions for 3D object construction. Specifically, our approach is mainly formed by two modules, i.e., the spatial-context module and the temporal-context module. The spatial-context module is designed to learn the physical constraints in 3D object construction, such as spatial constraints and gravity. Meanwhile, the temporal-context module integrates the temporal context of action orders in history on the fly toward more accurate predictions. After that, the features of such two modules are merged to finalize the perdition of the following action’s position and block type. The entire model is optimized by the stochastic gradient descent optimization (SGD) method in an end-to-end manner. Extensive experiments conducted on the 3D-Craft dataset demonstrate that the proposed method surpasses the state-of-the-art methods with a large margin, i.e., improving $$4.5\%$$ absolute ACC@1, $$3.3\%$$ absolute ACC@5, and $$4.1\%$$ absolute ACC@10. Moreover, the comprehensive ablation studies and insightful analysis further validate the effectiveness of the proposed method.},
  archive      = {J_APIN},
  author       = {Ji, Ruyi and Wang, Qunbo and Wang, Boying and Zhang, Hangu and Zhang, Wentao and Dai, Lin and Wang, Yanni},
  doi          = {10.1007/s10489-025-06468-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Spatial-temporal context-aware network for 3D-craft generation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effective selection of public IoT services by learning uncertain environmental factors using fingerprint attention. <em>APIN</em>, <em>55</em>(7), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06472-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scope of the Internet of Things (IoT) environment has been expanding from private to public spaces, where selecting the most appropriate service by predicting the service quality has become a timely problem. However, IoT services can be physically affected by (1) uncertain environmental factors such as obstacles and (2) interference among services in the same environment while interacting with users. Using the traditional modeling-based approach, analyzing the influence of such factors on the service quality requires modeling efforts and lacks generalizability. In this study, we propose Learning Physical Environment factors based on the Attention mechanism to Select Services for UsERs (PLEASSURE), a novel framework that selects IoT services by learning the uncertain influence and predicting the long-term quality from the users’ feedback without additional modeling. Furthermore, we propose fingerprint attention that extends the attention mechanism to capture the physical interference among services. We evaluate PLEASSURE by simulating various IoT environments with mobile users and IoT services. The results show that PLEASSURE outperforms the baseline algorithms in rewards consisting of users’ feedback on satisfaction and interference.},
  archive      = {J_APIN},
  author       = {Baek, KyeongDeok and Ko, In-Young},
  doi          = {10.1007/s10489-025-06472-8},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Effective selection of public IoT services by learning uncertain environmental factors using fingerprint attention},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable multi-agent reinforcement learning via multi-head variational autoencoders. <em>APIN</em>, <em>55</em>(7), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06473-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent deep reinforcement learning (RL) is increasingly proficient at making collective decisions in complex systems. However, the black-box nature of DRL decision networks often renders agent behaviors difficult to interpret, thereby undermining human trust. Although several reinforcement learning explanation methods have been proposed, most mainly identify factors influencing decisions without elucidating the underlying causal mechanisms based on physical models. Moreover, these methods do not address the generalizability of interpretability within multi-agent system settings. To overcome these challenges, we propose a multi-agent RL network based on multi-head variational autoencoders (MVAE), which generates decisions with interpretable physical semantics for unmanned systems. The MVAE directly encodes multiple types of semantically meaningful features with physical interpretations from the latent space and generates decisions by integrating these semantics according to physical models. Furthermore, considering the different latent variable distributions in continuous and discrete action scenarios, we design two distinct MVAE models based on Gaussian and Dirichlet distributions, respectively, and design training frameworks using deterministic policy gradient networks and proximal policy optimization networks in a multi-agent environment. Additionally, we develop a visualization method to intuitively convey interpretability in both continuous and discrete action scenarios. Simulation experiments comparing our method with existing baselines demonstrate that our approach achieves superior decision-making performance under interpretability conditions, and further validate its performance in large-scale scenarios.},
  archive      = {J_APIN},
  author       = {Li, Peizhang and Fei, Qing and Chen, Zhen},
  doi          = {10.1007/s10489-025-06473-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Interpretable multi-agent reinforcement learning via multi-head variational autoencoders},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A filter-wrapper model for high-dimensional feature selection based on evolutionary computation. <em>APIN</em>, <em>55</em>(7), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06474-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In machine learning, feature selection plays an important role in improving prediction accuracy and reducing time complexity. This paper proposes a filter-wrapper model to obtain a feature subset from high-dimensional data in a short time. Firstly, features are ranked by information gain and Fisher Score. Secondly, the feature search is realized by binary evolutionary computation based on wrapper. To avoid wasting a lot of searches on low-ranked features, an adaptive feature selection strategy is adopted to guide population search and position update. Finally, a learning strategy is proposed, in which learners study from exemplars and complete position update, and the exemplars are constituted by optimal solutions to balance exploration and exploitation. To demonstrate the effectiveness and efficiency of the proposed model, three binary evolutionary computations, including particle swarm optimization, grey wolf optimizer, and fish migration optimization, are applied to the model, and they present excellent performance in high-dimensional data sets.},
  archive      = {J_APIN},
  author       = {Hu, Pei and Zhu, Jiulong},
  doi          = {10.1007/s10489-025-06474-6},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {A filter-wrapper model for high-dimensional feature selection based on evolutionary computation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust stochastic quasi-newton algorithm for non-convex machine learning. <em>APIN</em>, <em>55</em>(7), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06475-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic quasi-Newton methods have garnered considerable attention within large-scale machine learning optimization. Nevertheless, the presence of a stochastic gradient equaling zero poses a significant obstacle to updating the quasi-Newton matrix, thereby impacting the stability of the quasi-Newton algorithm. To address this issue, a checkpoint mechanism is introduced, i.e., checking the value of $$\textbf{s}_k$$ before updating the quasi-Newton matrix, which effectively prevents zero increments in the optimization variable and enhances algorithmic stability during iterations. Meanwhile, a novel gradient incremental formulation is introduced to satisfy curvature conditions, facilitating convergence for non-convex objectives. Additionally, finite-memory techniques are employed to reduce storage requirements in large-scale machine learning tasks. The last iteration of the proposed algorithm is proven to converge in a non-convex setting, which is better than average and minimum iteration convergence. Finally, experiments are conducted on benchmark datasets to compare the proposed RSLBFGS algorithm with other popular first and second-order methods, demonstrating the effectiveness and robustness of RSLBFGS.},
  archive      = {J_APIN},
  author       = {Liu, Hanger and Liang, Yuqing and Liu, Jinlan and Xu, Dongpo},
  doi          = {10.1007/s10489-025-06475-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {A robust stochastic quasi-newton algorithm for non-convex machine learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view clustering with filtered bipartite graph. <em>APIN</em>, <em>55</em>(7), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06476-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key challenge of graph-based multi-view clustering methods lies in how to capture a consensus clustering structure. Although existing methods have achieved good performances, they still share the following limitations: 1) The high computational complexity caused by large graph leaning. 2) The contaminated information in different views reduces the consistency of the fused graph. 3) The two-stage clustering strategy leads to sub-optimal solutions and error accumulation. To solve the above issues, we propose a novel multi-view clustering algorithm termed Multi-View Clustering with Filtered Bipartite Graph (MVC-FBG). In the graph construction stage, we select representative anchors to construct anchor graphs with less space complexity. Then we explicitly filter out the contaminated information to preserve the consistency in different views. Moreover, a low-rank constraint is imposed on the Laplacian matrix of the unified graph to obtain the clustering results directly. Furthermore, we design an efficient alternating optimization algorithm to solve our model, which enjoys a linear time complexity that can scale well with the data size. Extensive experimental results on different scale datasets demonstrate the effectiveness and efficiency of our proposed method.},
  archive      = {J_APIN},
  author       = {Ji, Jintian and Peng, Hailei and Feng, Songhe},
  doi          = {10.1007/s10489-025-06476-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Multi-view clustering with filtered bipartite graph},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WMFusion: A W-shaped dual encoder and single decoder network for multimodal medical image fusion. <em>APIN</em>, <em>55</em>(7), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06477-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current deep learning-based multimodal medical image fusion algorithms usually use a single feature extractor to extract features from images of different modalities. However, these approaches tend to overlook the distinctive features of different modality medical images, resulting in feature loss. In addition, applying complex network structures to low-level image-processing tasks would waste computational power. Therefore, we innovatively design an end-to-end multimodal fusion network with a dual encoder and single decoder structure, which resembles the letter ‘W’, and we have termed WMFusion. Specifically, we first develop a multi-scale context dynamic feature extractor (MCDFE) that employs context-gated convolution to extract multiscale features from different modalities effectively. Subsequently, we propose a local-global feature fusion module (LGFM) for fusing features of different scales, and we design a cross-modality bidirectional interaction structure in the local branch. Finally, feature redundancy is suppressed and the fusion image is reconstructed by a spatial channel reconstruction module (SCRM) with a spatial and channel reconstruction unit. A large number of experimental results demonstrate that our proposed WMFusion method is superior to some state-of-the-art algorithms in terms of both subjective and objective evaluation metrics, and has satisfactory computation efficiency.},
  archive      = {J_APIN},
  author       = {Shao, Yu and Yu, Lei and Tang, Haozhe},
  doi          = {10.1007/s10489-025-06477-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {WMFusion: A W-shaped dual encoder and single decoder network for multimodal medical image fusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximizing diversity in k-pattern set mining through constraint programming and entropy. <em>APIN</em>, <em>55</em>(7), 1-24. (<a href='https://doi.org/10.1007/s10489-025-06482-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting diverse and frequent closed itemsets from large datasets is a core challenge in pattern mining, with significant implications across domains such as fraud detection, recommendation systems, and machine learning. Existing approaches often lack flexibility and efficiency, and struggle with initial itemset selection bias and redundancy. This paper addresses these research gaps by introducing a compact and modular constraint programming model that formalizes the search for diverse patterns. Our approach incorporates a novel global constraint derived from a relaxed Overlap diversity measure, using tighter lower and upper bounds to improve filtering capabilities. Unlike traditional methods, we leverage an entropy-based optimization framework that combines joint entropy maximization with top-k pattern mining to identify the maximally k-diverse pattern set. Our approach ensures more comprehensive and informative pattern discovery by minimizing redundancy and promoting pattern diversity. Extensive experiments validate the effectiveness of the proposed method, demonstrating significant performance gains and superior pattern quality compared to state-of-the-art approaches. Implemented in both sequential and parallel versions, the framework offers an efficient and adaptable solution for anytime pattern mining tasks in various domains.},
  archive      = {J_APIN},
  author       = {Douad, Mohamed El Amine and Aribi, Noureddine and Loudni, Samir and Hien, Arnold and Lebbah, Yahia},
  doi          = {10.1007/s10489-025-06482-6},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {Maximizing diversity in k-pattern set mining through constraint programming and entropy},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-layer contrastive learning for aspect-aligned multimodal sentiment analysis. <em>APIN</em>, <em>55</em>(7), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06483-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal Aspect-Based Sentiment Analysis (MABSA) aims to identify the sentiment polarity of aspects by incorporating visual information into text. Image and text are two types of modality information with significant modality gaps in both data form and semantic expression. Narrowing the modality gaps and feature fusion are two crucial challenges in MABSA. To address these issues, this paper introduces an aspect-enhanced alignment and fusion strategy with dual-layer contrastive learning to tackle the cross-modal fusion problem. Unlike traditional contrastive learning methods, our approach increases the number of negative samples, enabling the model to learn more discriminative features and better capture fine-grained cross-modal relationships. The proposed approach leverages overlapping aspect information as multi-modal pivots to first bridge the modality gaps and then integrate visual and text information in the multi-modal feature space, thereby improving multi-modal sentiment analysis performance. We first introduce an aspect-guided modality alignment strategy that narrows the fundamental modality gaps between image and text using modality contrastive learning. Then, we design an aspect-oriented multi-modal fusion approach to promote cross-modal feature fusion through symmetric cross-modal interaction. Extensive experiments demonstrate that the proposed approach outperforms other state-of-the-art (SOTA) MABSA methods on three MABSA benchmark datasets. In-depth analysis further validates the effectiveness of the proposed multi-modal fusion approach for MABSA.},
  archive      = {J_APIN},
  author       = {Guo, Junjun and Yan, Zida and Zhang, Guanghua},
  doi          = {10.1007/s10489-025-06483-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Dual-layer contrastive learning for aspect-aligned multimodal sentiment analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale spatiotemporal normality learning for unsupervised video anomaly detection. <em>APIN</em>, <em>55</em>(7), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06485-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection aims to automatically identify abnormal spatiotemporal patterns in surveillance videos. While unsupervised methods avoid the high cost of collecting abnormal data by learning from regular events, they often struggle to effectively model the inherent multiscale nature of video data. To address this challenge, we propose Multi-Scale Spatiotemporal Normality Learning (MS $$^2$$ NL), a unified framework that systematically processes and integrates multiscale features across both spatial and temporal dimensions. Our framework employs an attention-enhanced stepwise fusion module to aggregate spatial features at different resolutions, enabling comprehensive modeling of appearance patterns from local textures to global structures. For temporal information processing, we design a dynamic aggregation module based on one-dimensional dilated convolutions that effectively captures motion dependencies across multi-scale feature maps while maintaining computational efficiency. These multiscale features are processed through dual decoders: a temporal decoder that learns motion normality through RGB-to-optical-flow mapping, and a spatial decoder that models appearance normality via future frame prediction, with multiscale prototype features stored in an external memory network. This sophisticated handling of multiscale information enables MS $$^2$$ NL to capture subtle spatial deviations while maintaining sensitivity to temporal anomalies. Extensive experiments on benchmark datasets demonstrate the effectiveness of our approach, achieving state-of-the-art frame-level AUROCs of 98.3%, 91.5%, and 74.9% on the UCSD Ped2, CUHK Avenue, and ShanghaiTech datasets, respectively.},
  archive      = {J_APIN},
  author       = {Liu, Caitian and Gong, Linxiao and Chen, Xiong},
  doi          = {10.1007/s10489-025-06485-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Multi-scale spatiotemporal normality learning for unsupervised video anomaly detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive federated deep reinforcement learning for edge offloading in heterogeneous AGI-MEC networks. <em>APIN</em>, <em>55</em>(7), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06486-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To support massive applications of mobile terminals (MTs), the combination of air-ground integrated (AGI) networks and mobile edge computing (MEC) technology has emerged. However, how to intelligently manage MTs to satisfy their performance requirements faces several challenges, such as the high communication burden of collaborative decision-making, real-time changes in environmental information, MT mobility, and heterogeneous performance requirements. To deal with these challenges, we propose an adaptive federated deep deterministic policy gradient (AFDDPG) algorithm tailored to the edge offloading problem. Specifically, an adaptive federated training framework is first constructed to acquire global knowledge by sharing model parameters instead of original data among agents. This framework enables the algorithm to maintain a low communication burden while achieving high solution accuracy. Then, a hybrid reward function is proposed to enhance the exploration intensity in the action space by jointly considering the group interests and the unique features of each agent. Accordingly, the convergence performance of the algorithm in complex environments with multiple constraints is improved. Subsequently, an adaptive local update method is presented, which generates personalized local models through biased model aggregation to cope with the heterogeneous requirements of MTs. Finally, the convergence of the proposed AFDDPG algorithm is analysed, and the effectiveness of the algorithm is demonstrated by extensive simulations.},
  archive      = {J_APIN},
  author       = {Fan, Chenchen and Wang, Qingling},
  doi          = {10.1007/s10489-025-06486-2},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive federated deep reinforcement learning for edge offloading in heterogeneous AGI-MEC networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated text annotation: A new paradigm for generalizable text-to-image person retrieval. <em>APIN</em>, <em>55</em>(7), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06487-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieving specific person images based on textual descriptions, known as Text-to-Image Person Retrieval (TIPR), has emerged as a challenging research problem. While existing methods primarily focus on architectural refinements and feature representation enhancements, the critical aspect of textual description quality remains understudied. We propose a novel framework that automatically generates stylistically consistent textual descriptions to enhance TIPR generalizability. Specifically, we develop a dual-model architecture employing both captioning and retrieval models to quantitatively evaluate the impact of textual descriptions on retrieval performance. Comparative analysis reveals that manually annotated descriptions exhibit significant stylistic variations due to subjective biases among different annotators. To address this, our framework utilizes the captioning model to generate structurally consistent textual descriptions, enabling subsequent training and inference of the retrieval model based on automated annotations. Notably, our framework achieves a 18.60% improvement in Rank-1 accuracy over manual annotations on the RSTPReid dataset. We systematically investigate the impact of identity quantity during testing and explore prompt-guided strategy to enhance image caption quality. Furthermore, this paradigm ensures superior generalization capabilities for well-trained retrieval models. Extensive experiments demonstrate that our approach improves the applicability of TIPR systems. Comparison framework of manual and automated annotation performance. The left panel illustrates the process of generating automated annotations and the details of captioner training and testing. The right panel demonstrates the training and testing processes using different image-text pairs and compares the final results on the RSTPReid dataset. This results show that the performance of automated annotations surpasses that of manual annotations on this dataset},
  archive      = {J_APIN},
  author       = {Liu, Delong and Wang, Peng and Zhao, Zhicheng and Su, Fei},
  doi          = {10.1007/s10489-025-06487-1},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Automated text annotation: A new paradigm for generalizable text-to-image person retrieval},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). COFA: Counterfactual attention framework for trustworthy wafer map failure classification. <em>APIN</em>, <em>55</em>(7), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06488-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifying wafer map failure pattern plays a crucial role in semiconductor manufacturing, as it can help identify the underlying cause of abnormalities, thus reducing production costs. Existing works have shown that deep learning methods have great advantages in recognizing failure patterns. However, recent studies mainly focus on utilizing attention mechanisms to pinpoint critical regions as salient features, while ignoring the imperceptible underlying features and the causal relationship between prediction results and attention. This paper introduces a model-agnostic classification framework that leverages counterfactual explanations to enhance attention. Our approach consists of two steps: counterfactual example generation (Explain) and attention-based classifier refinement (Reinforce). The counterfactual explainer is designed to identify key pixel-level features, the adjustment of which could lead to different predictions. These generated counterfactual examples reveal hidden causal factors in the classifier’s decision-making process. Then the classifier utilizes these pixel features as attention, conducting reliable classification under the guidance of counterfactual examples. Through extensive experiments on real-world datasets, we demonstrate the effectiveness of our proposed model. It achieves an accuracy of 98.125 $$\%$$ in the defect classification task on the WM-811K dataset and 92.544 $$\%$$ on the MixedWM38 dataset, outperforming state-of-the-art attention methods such as SENet, CBAM, and Vision Transformer by over 5%. Our results highlight the superiority of our approach and its potential for practical implementation in the semiconductor manufacturing domain.},
  archive      = {J_APIN},
  author       = {Feng, Kaiyue and Wang, Jia and Yin, Chenke and Li, Andong},
  doi          = {10.1007/s10489-025-06488-0},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {COFA: Counterfactual attention framework for trustworthy wafer map failure classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LPPSLF: A lightweight privacy-preserving split learning framework for smart surveillance systems. <em>APIN</em>, <em>55</em>(7), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06489-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In smart surveillance systems, cameras often have limited computational capacity, which necessitates the offloading of captured images or videos to cloud servers for analysis, raising significant privacy concerns. To address these challenges, we propose a lightweight privacy-preserving split learning framework tailored for smart surveillance systems. In this framework, an upper model is deployed on resource-constrained cameras to extract intermediate features from image segments, which are then transmitted to a lower model on the cloud for further analysis and training. This approach reduces the likelihood of sensitive data exposure by avoiding the transmission of raw images or videos. Furthermore, our framework incorporates adversarial training to defend against reconstruction attacks, preventing adversaries from deducing private information from the intermediate features. Compared to traditional split learning methods, the proposed solution significantly reduces client-side memory usage and computation time, making it well-suited for deployment on low-resource devices. Experimental results on CIFAR10, CIFAR100, and SVHN datasets demonstrate the effectiveness of our framework, with reductions in the server-side decoder’s reconstruction classification accuracy to 12.18%, 2.18%, and 13.09%, respectively. These results validate the framework’s ability to enhance privacy while maintaining computational efficiency.},
  archive      = {J_APIN},
  author       = {Wang, Liang and Chen, Hao and Zuo, Lina and Liu, Haibo},
  doi          = {10.1007/s10489-025-06489-z},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {LPPSLF: A lightweight privacy-preserving split learning framework for smart surveillance systems},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced frustrum multi-scale VoteNet for 3D object detection in cluttered indoor scene. <em>APIN</em>, <em>55</em>(7), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06492-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The low-cost Kinect sensor is capable of simultaneously acquiring RGB images and depth information, providing a comprehensive representation of 3D scenes. However, a significant drawback of the Kinect sensor is its susceptibility to low perception accuracy, particularly in cluttered indoor scenes. To tackle these issues, we introduce a novel EF-MSVoteNet framework for Kinect-based indoor 3D object detection. This framework integrates two key modules: The Enhanced Frustum (EF) and Multi-Scale Voting Network (MSVoteNet). After obtaining 2D bounding boxes via a 2D detector, the EF module no longer segments the scene but instead accumulates all frustum regions within a three-dimensional space. The EF module not only enhances the resolution of point clouds within the frustum in relation to the background but also substantially enhances the feature representation of object-related point clouds within the 3D scene. In addition, the proposed MSVoteNet module is a structurally flexible multi-scale voting network. It enhances feature extraction and integration across different scales by incorporating a multi-scale structure into the traditional VoteNet. The performance analysis is carried out on the SUN RGB-D and ScanNet datasets, which were collected using RGB-D sensors in cluttered indoor environments, and it demonstrates the efficacy and effectiveness of our proposed methods. The source code is available at: https://github.com/zerrows2/EF-MSVoteNet},
  archive      = {J_APIN},
  author       = {Zhang, Xuesong and He, Yu and Song, Cunli and Zhuang, Yan},
  doi          = {10.1007/s10489-025-06492-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Enhanced frustrum multi-scale VoteNet for 3D object detection in cluttered indoor scene},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AuGQ: Augmented quantization granularity to overcome accuracy degradation for sub-byte quantized deep neural networks. <em>APIN</em>, <em>55</em>(7), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06495-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deployment of neural networks on IoT devices unleashes the potential for various innovative applications, but the sheer size and computation of many deep learning (DL) networks prevented its widespread. Quantization mitigates this issue by reducing model precision, enabling deployment on resource-constrained edge devices. However, at extremely low bit-widths, such as 2-bit and 4-bit, the aggressive compression leads to significant accuracy degradation due to the reduced representational capacity of the neural network. A critical aspect of effective quantization is identifying the range of real values (FP32) that impact model accuracy. To address accuracy loss at sub-byte levels, we introduce Augmented Quantization (AuGQ), a novel granularity technique tailored for low bit-width quantization. AuGQ segments the range of real-valued (FP32) weight and activation distributions into small uniform intervals, applying affine quantization in each interval to enhance accuracy. We evaluated AuGQ using both post-training quantization (PTQ) and quantization-aware training (QAT) methods, achieving accuracy levels comparable to full precision (32-bit) DL networks. Our findings demonstrate that AuGQ is agnostic to the training pipeline and batch normalization folding, distinguishing it from conventional quantization techniques. Furthermore, when integrated into state-of-the-art PTQ algorithms, AuGQ necessitates only 64 training samples for fine-tuning which is $$16\times $$ fewer than traditional methods. This reduction facilitates the application of high-accuracy quantization at sub-byte bit-widths, making it suitable for practical IoT deployments and enhancing computational efficiency on edge devices.},
  archive      = {J_APIN},
  author       = {Mujtaba, Ahmed and Lee, Wai Kong and Ko, Byoung Chul and Chang, Hyung Jin and Hwang, Seong Oun},
  doi          = {10.1007/s10489-025-06495-1},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {AuGQ: Augmented quantization granularity to overcome accuracy degradation for sub-byte quantized deep neural networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual learning with selective nets. <em>APIN</em>, <em>55</em>(7), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06497-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread adoption of foundation models has significantly transformed machine learning, enabling even straightforward architectures to achieve results comparable to state-of-the-art methods. Inspired by the brain’s natural learning process-where studying a new concept activates distinct neural pathways and recalling that memory requires a specific stimulus to fully recover the information-we present a novel approach to dynamic task identification and submodel selection in continual learning. Our method leverages the power of the learning robust visual features without supervision model (DINOv2) foundation model to handle multi-experience datasets by dividing them into multiple experiences, each representing a subset of classes. To build a memory of these classes, we employ strategies such as using random real images, distilled images, k-nearest neighbours (kNN) to identify the closest samples to each cluster, and support vector machines (SVM) to select the most representative samples. During testing, where the task identification (ID) is not provided, we extract features of the test image and use distance measurements to match it with the stored features. Additionally, we introduce a new forgetting metric specifically designed to measure the forgetting rate in task-agnostic continual learning scenarios, unlike traditional task-specific approaches. This metric captures the extent of knowledge loss across tasks where the task identity is unknown during inference. Despite its simple architecture, our method delivers competitive performance across various datasets, surpassing state-of-the-art results in certain instances.},
  archive      = {J_APIN},
  author       = {Tung Luu, Hai and Szemenyei, Marton},
  doi          = {10.1007/s10489-025-06497-z},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Continual learning with selective nets},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decomposition dynamic multi-graph convolutional recurrent network for traffic forecasting. <em>APIN</em>, <em>55</em>(7), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06503-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction is crucial for urban traffic management. Traffic data is typically collected from sensors deployed along roadways, which often record both valid and erroneous data. However, most existing studies assume that the collected data is perfectly accurate, overlooking the existence of erroneous data. Meanwhile, graph neural networks are widely applied in traffic forecasting due to their ability to effectively capture correlations between nodes in a network. However, existing methods often rely solely on either static or dynamic graph structures, which may not accurately reflect the complex spatial relationships between nodes. To address these issues, we propose a decomposition dynamic multi-graph convolutional recurrent network (DDMGCRN). DDMGCRN utilizes a residual decomposition mechanism to separate erroneous data from valid data, thereby mitigating its impact. Additionally, DDMGCRN introduces sensor-specific spatial identity embeddings and timestamp embeddings to construct dynamic graphs. It further integrates static graphs for multi-graph fusion, facilitating more effective spatial feature extraction. Furthermore, to address the limitations of RNN-based models in capturing global temporal dependencies, DDMGCRN incorporates a global temporal attention module. Experimental results on four real-world datasets show that DDMGCRN outperforms all baseline models on the PEMS08 dataset, achieving a mean absolute error (MAE) of 14.13, which improves performance by approximately 4.85% compared to the best baseline model. The source code is available at https://github.com/hulongfei123/DDMGCRN .},
  archive      = {J_APIN},
  author       = {Hu, Longfei and Wei, Lai and Lin, Yeqing},
  doi          = {10.1007/s10489-025-06503-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Decomposition dynamic multi-graph convolutional recurrent network for traffic forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convolution-aware networks for random missing traffic data imputation. <em>APIN</em>, <em>55</em>(7), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06506-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integrity of traffic data is fundamental to alleviating the challenges in urban cities by computing. However, traffic data often exhibits a random missing characteristic due to sensor failure or network packet loss. Existing methods endowed too much prior knowledge on random missing data, such as data decay over time or data distribution correlation analysis. Thus, there is an urgent need for a data-driven and efficient traffic data interpolation method to assist downstream urban computing. Therefore, this paper proposes a fully convolutional spatial-temporal graph neural network (FC-STGNN) for traffic data imputation. Specifically, we apply a temporal convolutional network (TCN) to extract temporal features. Due to the dilated causal convolutions, it is possible to extract temporal features across time nodes, effectively alleviating the impact of data loss at a certain moment. Furthermore, we design a graph convolutional network (GCN) with residual connections to aggregate traffic data between adjacent road segments in the road network. Combining these two components enables spatiotemporal modeling of traffic data in data-missing environments. Finally, we conduct experiments on two real-world traffic datasets. The experiments demonstrate that our proposed method outperforms most baseline methods and owns a modest computational cost.},
  archive      = {J_APIN},
  author       = {Zhao, Zhenzhen and Shen, Guojiang and Zhou, Wenfeng and Gu, Wenjie and Chen, Chao and Kong, Xiangjie},
  doi          = {10.1007/s10489-025-06506-1},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Convolution-aware networks for random missing traffic data imputation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel three-way heterogeneous multi-attribute group decision method based on LINMAP for college teacher introduction. <em>APIN</em>, <em>55</em>(7), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06369-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With dramatic development of Chinese social economics and higher education, college teacher introduction has become an urgent and important problem, which is a type of heterogeneous multi-attribute group decision-making (HMAGDM). This article erects a novel three-way decision (TWD) model based on LINMAP (Linear Programming Technique for Multidimensional Analysis of Preference) to handle HMAGDM and applies to college teacher introduction. Firstly, combining evaluation matrices with alternatives’ preferences offered by decision makers (DMs), we define the individual consistency and inconsistency indexes, group consistency and inconsistency indexes. In terms of the individual consistency and inconsistency indexes, the weights of DMs are determined through establishing a bi-objective mathematical optimization model. As per the group consistency and inconsistency indexes, we build a bi-objective optimization model to derive the attribute weights and the fuzzy ideal solutions (FISs) which are employed to calculate the relative profit functions. Using the DMs’ weights, we could obtain the collective overall profit functions of alternatives and the thresholds. The conditional probability of each alternative is acquired according to the relative closeness coefficient. The classification rules and decision results are further induced based on maximum-profit decision principle. An example of college teacher introduction is illustrated to verify the efficacy of the erected method.},
  archive      = {J_APIN},
  author       = {Wan, Shu-Ping and Gao, Yu and Dong, Jiu-Ying},
  doi          = {10.1007/s10489-025-06369-6},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {A novel three-way heterogeneous multi-attribute group decision method based on LINMAP for college teacher introduction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAGAF: A directed acyclic generative adversarial framework for joint structure learning and tabular data synthesis. <em>APIN</em>, <em>55</em>(7), 1-27. (<a href='https://doi.org/10.1007/s10489-025-06410-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the causal relationships between data variables can provide crucial insights into the construction of tabular datasets. Most existing causality learning methods typically focus on applying a single identifiable causal model, such as the Additive Noise Model (ANM) or the Linear non-Gaussian Acyclic Model (LiNGAM), to discover the dependencies exhibited in observational data. We improve on this approach by introducing a novel dual-step framework capable of performing both causal structure learning and tabular data synthesis under multiple causal model assumptions. Our approach uses Directed Acyclic Graphs (DAG) to represent causal relationships among data variables. By applying various functional causal models including ANM, LiNGAM and the Post-Nonlinear model (PNL), we implicitly learn the contents of DAG to simulate the generative process of observational data, effectively replicating the real data distribution. This is supported by a theoretical analysis to explain the multiple loss terms comprising the objective function of the framework. Experimental results demonstrate that DAGAF outperforms many existing methods in structure learning, achieving significantly lower Structural Hamming Distance (SHD) scores across both real-world and benchmark datasets (Sachs: 47%, Child: 11%, Hailfinder: 5%, Pathfinder: 7% improvement compared to state-of-the-art), while being able to produce diverse, high-quality samples.},
  archive      = {J_APIN},
  author       = {Petkov, Hristo and MacLellan, Calum and Dong, Feng},
  doi          = {10.1007/s10489-025-06410-8},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-27},
  shortjournal = {Appl. Intell.},
  title        = {DAGAF: A directed acyclic generative adversarial framework for joint structure learning and tabular data synthesis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards accurate post-training quantization for reparameterized models. <em>APIN</em>, <em>55</em>(7), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06418-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model reparameterization is a widely accepted technique for improving inference speed without compromising performance. However, current Post-training Quantization (PTQ) methods often lead to significant accuracy degradation when applied to reparameterized models. This is primarily caused by channel-specific and sample-specific outliers, which appear only at specific samples and channels and impact on the selection of quantization parameters. To address this issue, we propose RepAPQ, a novel framework that preserves the accuracy of quantized reparameterization models. Different from previous frameworks using Mean Squared Error (MSE) as a measurement, we utilize Mean Absolute Error (MAE) to mitigate the influence of outliers on quantization parameters. Our framework consists of two core components: Quantization Protecting Reparameterization and Across-block Calibration. For effective calibration, Quantization Protecting Reparameterization combines multiple branches into a single convolution with an affine layer. During training, the affine layer accelerates convergence and amplifies the output of the convolution to better accommodate samples with outliers. Additionally, Across-block Calibration leverages the measurement of stage output as supervision to address the gradient problem introduced by MAE and enhance the interlayer correlation with quantization parameters. Comprehensive experiments demonstrate the effectiveness of RepAPQ across various models and tasks. Our framework outperforms previous methods by approximately 1% for 8-bit PTQ and 2% for 6-bit PTQ, showcasing its superior performance. The code is available at https://github.com/ilur98/DLMC-QUANT .},
  archive      = {J_APIN},
  author       = {Zhang, Luoming and He, Yefei and Fei, Wen and Lou, Zhenyu and Wu, Weijia and Ying, Yangwei and Zhou, Hong},
  doi          = {10.1007/s10489-025-06418-0},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Towards accurate post-training quantization for reparameterized models},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SentimentMapper: A framework for mapping of sentiments towards disaster response using social media data. <em>APIN</em>, <em>55</em>(7), 1-25. (<a href='https://doi.org/10.1007/s10489-025-06442-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networking platforms have been generating a massive amount of data in real-time that can be analysed and used to support government and relief organizations in preparing quick and effective action plans for disaster response. Effective disaster response requires a broad understanding of disaster situations, such as the emergency necessities of the people, their sentiments towards emergency needs, and the geographical distribution of their requirements and opinions. However, in literature, many studies exist that estimate the emotions and sentiments of the people during a disaster; they are inept in identifying and mapping the public sentiments toward emergency needs. This paper proposes a framework called SentimentMapper. This framework quickly maps the sentiments of people toward emergency needs using social media data to plan for effective disaster response. In order to perform an automatic analysis of sentiments using Twitter (re-branded to X since July 2023) data, we introduce a BERT Convolutional Neural Network (BCNN). BCNN performs the sentiment analysis of the collected data from the disaster-affected people regarding essential needs like food, shelter, medical emergency, and rescue during different disasters. Next, we present a tweet-text independent approach to detect the location of the tweets posted on Twitter and discover the impacts in different areas due to any disaster event. Furthermore, we also study the variations in public attitudes about the essential needs during identical or different disasters. As a case study, the proposed framework has been used on the dataset collected from Twitter during the Assam flood 2021 in India and validated with the corresponding survey reports published by the government agency. The detailed results of the analytics in the proposed framework and its validation with the case study data confirm that it is capable of providing credible situational information quickly required for the disaster responses.},
  archive      = {J_APIN},
  author       = {Gupta, Tanu and Rai, Aman and Roy, Sudip},
  doi          = {10.1007/s10489-025-06442-0},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {SentimentMapper: A framework for mapping of sentiments towards disaster response using social media data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging BiLSTM-GAT for enhanced stock market prediction: A dual-graph approach to portfolio optimization. <em>APIN</em>, <em>55</em>(7), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06462-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock price prediction remains a critical challenge in financial research due to its potential to inform strategic decision-making. Existing approaches predominantly focus on two key tasks: (1) regression, which forecasts future stock prices, and (2) classification, which identifies trading signals such as buy, sell, or hold. However, the inherent limitations of financial data hinder effective model training, often leading to suboptimal performance. To mitigate this issue, prior studies have expanded datasets by aggregating historical data from multiple companies. This strategy, however, fails to account for the unique characteristics and interdependencies among individual stocks, thereby reducing predictive accuracy. To address these limitations, we propose a novel BiLSTM-GAT-AM model that integrates bidirectional long short-term memory (BiLSTM) networks with graph attention networks (GAT) and an attention mechanism (AM). Unlike conventional graph-based models that define edges based solely on technical or fundamental relationships, our approach employs a dual-graph structure: one graph captures technical similarities, while the other encodes fundamental industry relationships. These two representations are aligned through an attention mechanism, enabling the model to exploit both technical and fundamental insights for enhanced stock market predictions. We conduct extensive experiments, including ablation studies and comparative evaluations against baseline models. The results demonstrate that our model achieves superior predictive performance. Furthermore, leveraging the model’s forecasts, we construct an optimized portfolio and conduct backtesting on the test dataset. Empirical results indicate that our portfolio consistently outperforms both baseline models and the S&P 500 index, highlighting the effectiveness of our approach in stock market prediction and portfolio optimization.},
  archive      = {J_APIN},
  author       = {Lu, Xiaobin and Poon, Josiah and Khushi, Matloob},
  doi          = {10.1007/s10489-025-06462-w},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Leveraging BiLSTM-GAT for enhanced stock market prediction: A dual-graph approach to portfolio optimization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generality-aware self-supervised transformer for multivariate time series anomaly detection. <em>APIN</em>, <em>55</em>(7), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06481-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient identification of anomalies within multivariate time series data holds significant relevance in contemporary industrial settings. The challenge lies in swiftly and accurately pinpointing anomalous data points. This challenge is further compounded by factors such as the absence of labeled anomalies, data volatility, and the need for ultra-fast inference times. While previous approaches have introduced advanced deep learning models to address these challenges, comprehensive efforts to tackle all these issues simultaneously have been limited. Recent developments in unsupervised learning-based models have demonstrated remarkable performance. However, many of these models rely on reconstruction error as an anomaly score, making them sensitive to unseen normal data patterns. To address this limitation, we propose a novel framework, generality-aware self-supervised transformer for multivariate time series anomaly detection, which utilizes a transformer that effectively generalizes normal data patterns through self-knowledge distillation. Furthermore, we incorporate an auxiliary decoder to compute generality-based anomaly scores, thereby enhancing the differentiation between anomalous and normal data points in testing datasets. In our study, encompassing a diverse range of publicly available datasets and our own extracted data from linear motion (LM) guides and reducers built to model the vertical and rotational motions of robots, we establish the superior anomaly detection performance of our framework compared to existing state-of-the-art models. Notably, we verify that this improved performance is achieved while also considering time efficiency.},
  archive      = {J_APIN},
  author       = {Cho, Yucheol and Lee, Jae-Hyeok and Ham, Gyeongdo and Jang, Donggon and Kim, Dae-shik},
  doi          = {10.1007/s10489-025-06481-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Generality-aware self-supervised transformer for multivariate time series anomaly detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structured 3D gaussian splatting for novel view synthesis based on single RGB-LiDAR view. <em>APIN</em>, <em>55</em>(7), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06494-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D scene reconstruction is a critical task in computer vision and graphics, with recent advancements in 3D Gaussian Splatting (3DGS) demonstrating impressive novel view synthesis (NVS) result. However, most 3DGS methods rely on multi-view images, which are not always available, particularly in outdoor environments. In this paper, we explore 3D scene reconstruction using only single-view data, comprising an RGB image and sparse point clouds from a LiDAR sensor. To address the challenges posed by limited reference and LiDAR sensor insufficient point clouds, we propose a voxel-based structured 3DGS framework enhanced with depth prediction. We introduce a novel depth prior guided voxel growing and pruning algorithm, which leverages predicted depth maps to refine scene structure and improve rendering quality. Furthermore, we design a virtual background fitting method with an adaptive voxel size to accommodate the sparse distribution of LiDAR data in outdoor scenes. Our approach surpasses existing methods, including Scaffold-GS, Gaussian-Pro, 3DGS, Mip-splatting and UniDepth, in terms of PSNR, SSIM, LPIPS and FID metrics on the KITTI and Waymo datasets, demonstrating its effectiveness in single-viewpoint 3D reconstruction and NVS.},
  archive      = {J_APIN},
  author       = {Liu, Libin and Zhao, Zhiqun and Ma, Wei and Zhang, Siyuan and Zha, Hongbin},
  doi          = {10.1007/s10489-025-06494-2},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Structured 3D gaussian splatting for novel view synthesis based on single RGB-LiDAR view},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive patch selection to improve vision transformers through reinforcement learning. <em>APIN</em>, <em>55</em>(7), 1-26. (<a href='https://doi.org/10.1007/s10489-025-06516-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Transformers have revolutionized the management of Natural Language Processing tasks, and Vision Transformers (ViTs) promise to do the same for Computer Vision ones. However, the adoption of ViTs is hampered by their computational cost. Indeed, given an image divided into patches, it is necessary to compute for each layer the attention of each patch with respect to all the others. Researchers have proposed many solutions to reduce the computational cost of attention layers by adopting techniques such as quantization, knowledge distillation and manipulation of input images. In this paper, we aim to contribute to the solution of this problem. In particular, we propose a new framework, called AgentViT, which uses Reinforcement Learning to train an agent that selects the most important patches to improve the learning of a ViT. The goal of AgentViT is to reduce the number of patches processed by a ViT, and thus its computational load, while still maintaining competitive performance. We tested AgentViT on CIFAR10, FashionMNIST, and Imagenette $$^+$$ (which is a subset of ImageNet) in the image classification task and obtained promising performance when compared to baseline ViTs and other related approaches available in the literature.},
  archive      = {J_APIN},
  author       = {Cauteruccio, Francesco and Marchetti, Michele and Traini, Davide and Ursino, Domenico and Virgili, Luca},
  doi          = {10.1007/s10489-025-06516-z},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive patch selection to improve vision transformers through reinforcement learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A modified SimRank++ approach for searching crash simulation data. <em>APIN</em>, <em>55</em>(7), 1-22. (<a href='https://doi.org/10.1007/s10489-024-05945-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data searchability has been utilized for decades and is now a crucial ingredient of data reuse. However, data searchability in industrial engineering is essentially still at the level of individual text documents, while for finite element (FE) simulations no content-based relations between FE simulations exist so far. Additionally, the growth of data warehouses with the increase of computational power leaves companies with a vast amount of engineering data that is rarely reused. Search techniques for FE data, which are in particular aware of the engineering problem context, is a new research topic. We introduce the prediction of similarities between simulations using graph algorithms, which for example allows the identification of outliers or ranks simulations according to their similarities. With that, we address searchability for FE-based crash simulations in the automotive industry. Here, we use SimRank-based methods to predict the similarity of crash simulations using unweighted and weighted bipartite graphs. Motivated by requirements from the engineering application, we introduce SimRankTarget++ an alternative formulation of SimRank++ that performs better for FE simulations. To show the generality of the graph approach, we compare component-based similarities with part-based ones. For that, we introduce a method for automatically detecting components in the vehicle. We use a car sub-model to illustrate the similarity ansatz and present results on data from real-life development stages of an automotive company.},
  archive      = {J_APIN},
  author       = {Pakiman, Anahita and Garcke, Jochen and Schumacher, Axel},
  doi          = {10.1007/s10489-024-05945-6},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {A modified SimRank++ approach for searching crash simulation data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-scale stochastic sparse subspace representation with consensus anchor guidance. <em>APIN</em>, <em>55</em>(7), 1-29. (<a href='https://doi.org/10.1007/s10489-025-06392-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subspace clustering (SC) is a hotspot in data analysis and machine learning. There exists much literature addressing this topic and most of which cannot handle large scale data. Although anchor graph learning is introduced to SC, there is still a problem that anchors cannot preserve the subspace structure of original data and spectral clustering process is still implemented slowly. To address these issues, an Anchor Graph Regularization based Large-Scale Stochastic Sparse Subspace Representation with Consensus Anchor Guidance (AGLS $$^4$$ RA) is proposed in this paper, which integrates three modules, including sparse self-representation, anchor graph regularization, and sparse coding into a unified framework. These modules are collaboratively worked to learn an optimal, high-quality anchor matrix under the row sparse constraint. Furthermore, the random sampling and label propagation techniques are also introduced to accelerate the clustering task. AGLS $$^4$$ RA is capable of processing data in linear time, which is beneficial to the execution of large-scale tasks. A series of comparative experiments on benchmark datasets verify the effectiveness of the proposed method.},
  archive      = {J_APIN},
  author       = {Yang, Ge and Deng, Tingquan and Yang, Ming and Wang, Changzhong},
  doi          = {10.1007/s10489-025-06392-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-29},
  shortjournal = {Appl. Intell.},
  title        = {Large-scale stochastic sparse subspace representation with consensus anchor guidance},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cutting-edge framework for industrial intrusion detection: Privacy-preserving, cost-friendly, and powered by federated learning. <em>APIN</em>, <em>55</em>(7), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06404-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the networking of industrially deployed facilities in distributed environments, industrial control systems (ICS) are facing an escalating number of attacks, emphasizing the criticality of intrusion detection systems. Currently, machine learning-based intrusion detection systems have been extensively researched. However, the sensitivity of ICS data poses a challenge of scarce labeled data for these systems. Additionally, distributed ICS necessitate privacy-preserving collaborative detection. To address these challenges, some solutions combining federated learning and transfer learning have been proposed. Nonetheless, these solutions often overlook the clustering characteristics of factory equipment and the constraints posed by limited computational and communication resources. Therefore, we propose GC-FADA, a chained cross-domain collaborative intrusion detection framework, to effectively address the interplay between labeled data scarcity, privacy protection, and resource constraints in ICS intrusion detection techniques. Firstly, GC-FADA used the adversarial domain adaptation scheme to train the local model to alleviate the performance limitation of intrusion detection model caused by labeled data scarcity. Then, to reduce the communication overhead between the nodes in the factory communication network and protect client privacy, GC-FADA utilizes the geographical clustering characteristics of the factory devices and proposes a FL-based grouped chain learning structure to achieve collaborative training. Finally, GC-FADA achieves privacy protection with low computational overhead by utilizing patterns from lightweight pseudo-random generators instead of complex cryptographic primitives. Extensive experiments conducted on real industrial SCADA datasets validate the effectiveness and rationality of the proposed approach, proving that GC-FADA outperforms major domain adaptation methods in terms of accuracy while reducing computation and communication costs. In the cross-domain learning task on the two data sets, the detection accuracy of our GC-FADA reaches 88.7% and 98.29% respectively, and the detection accuracy of various network attacks is mostly more than 90%.},
  archive      = {J_APIN},
  author       = {Zhu, Lingzi and Zhao, Bo and Guo, Jiabao and Ji, Minzhi and Peng, Junru},
  doi          = {10.1007/s10489-025-06404-6},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {A cutting-edge framework for industrial intrusion detection: Privacy-preserving, cost-friendly, and powered by federated learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced IDS: A comparative study of datasets and machine learning algorithms for network flow-based intrusion detection systems. <em>APIN</em>, <em>55</em>(7), 1-34. (<a href='https://doi.org/10.1007/s10489-025-06422-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Globally, cyberattacks are growing and mutating each month. Intelligent Intrusion Network Detection Systems are developed to analyze and detect anomalous traffic to face these threats. A way to address this is by using network flows, an aggregated version of communications between devices. Network Flow datasets are used to train Artificial Intelligence (AI) models to classify specific attacks. Training these models requires threat samples usually generated synthetically in labs as capturing them on operational network is a challenging task. As threats are fast-evolving, new network flows are continuously developed and shared. However, using old datasets is still a popular procedure when testing models, hindering a more comprehensive characterization of the advantages and opportunities of recent solutions on new attacks. Moreover, a standardized benchmark is missing rendering a poor comparison between the models produced by algorithms. To address these gaps, we present a benchmark with fourteen recent and preprocessed datasets and study seven categories of algorithms for Network Intrusion Detection based on Network Flows. We provide a centralized source of pre-processed datasets to researchers for easy download. All dataset are also provided with a train, validation and test split to allow a straightforward and fair comparison between existing and new solutions. We selected open state-of-the-art publicly available algorithms, representatives of diverse approaches. We carried out an experimental comparison using the Macro F1 score of these algorithms. Our results highlight each model operation on dataset scenarios and provide guidance on competitive solutions. Finally, we discuss the main characteristics of the models and benchmarks, focusing on practical implications and recommendations for practitioners and researchers.},
  archive      = {J_APIN},
  author       = {Mondragon, Jose Carlos and Branco, Paula and Jourdan, Guy-Vincent and Gutierrez-Rodriguez, Andres Eduardo and Biswal, Rajesh Roshan},
  doi          = {10.1007/s10489-025-06422-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-34},
  shortjournal = {Appl. Intell.},
  title        = {Advanced IDS: A comparative study of datasets and machine learning algorithms for network flow-based intrusion detection systems},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual attention-guided distillation for class incremental semantic segmentation. <em>APIN</em>, <em>55</em>(7), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06436-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class Incremental Semantic Segmentation (CISS) aims at segmenting the incremental new classes without losing the ability on old classes. Currently, some CISS methods based on feature knowledge distillation suffer from the stability-plasticity dilemma, i.e., excessive knowledge distillation may impede models from learning new classes. Besides, distilling without emphasis fails to preserve old knowledge effectively. To address these issues, a more fine-grained and focused approach to knowledge transfer, named dual attention-guided distillation (DAGD), is proposed for the CISS task. This approach not only ensures that the inherited knowledge is distilled in a targeted manner but also allows the model to adapt and learn new knowledge more efficiently. DAGD model contains a channel attention-guided distillation module and a spatial attention-guided distillation module. The former distills channel-wise attention maps to improve the knowledge transfer of essential channels while accommodating new knowledge learning. The latter encodes a weight coefficient map to highlight important regions in the spatial dimension, which further decouples old knowledge retention and new knowledge entry. Furthermore, a dynamic temperature strategy is introduced to facilitate logit knowledge distillation, specifically sharpening the predictive distribution produced by the output of the old model, thus achieving more accurate knowledge transfer. Extensive experimental results on Pascal VOC 2012 and ADE20K datasets demonstrate that our method achieves competitive results.},
  archive      = {J_APIN},
  author       = {Xu, Pengju and Wang, Yan and Wang, Bingye and Zhao, Haiying},
  doi          = {10.1007/s10489-025-06436-y},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Dual attention-guided distillation for class incremental semantic segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal feature adaptive fusion for anchor-free 3D object detection. <em>APIN</em>, <em>55</em>(7), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06454-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LiDAR and camera are two key sensors that provide mutually complementary information for 3D detection in autonomous driving. Existing multimodal detection methods often decorate the original point cloud data with camera features to complete the detection, ignoring the mutual fusion between camera features and point cloud features. In addition, ground points scanned by LiDAR in natural scenes usually interfere significantly with the detection results, and existing methods fail to address this problem effectively. We present a simple yet efficient anchor-free 3D object detection, which can better adapt to complex scenes through the adaptive fusion of multimodal features. First, we propose a fully convolutional bird’s-eye view reconstruction module to sense ground map geometry changes, for improving the interference of ground points on detection results. Second, a multimodal feature adaptive fusion module with local awareness is designed to improve the mutual fusion of camera and point cloud features. Finally, we introduce a scale-aware mini feature pyramid networks (Mini-FPN) that can directly regress 3D bounding boxes from the augmented dense feature maps, boosting the network’s ability to detect scale-varying objects, and we additionally construct a scene-adaptive single-stage 3D detector in an anchor-free manner. Extensive experiments on the KITTI and nuScenes datasets validate our method’s competitive performance.},
  archive      = {J_APIN},
  author       = {Wu, Yanli and Wang, Junyin and Li, Hui and Ai, Xiaoxue and Li, Xiao},
  doi          = {10.1007/s10489-025-06454-w},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Multimodal feature adaptive fusion for anchor-free 3D object detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global and local co-attention networks enhanced by learning state for knowledge tracing. <em>APIN</em>, <em>55</em>(7), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06463-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In intelligent tutoring systems, knowledge tracing (KT) stands as a pivotal technology for facilitating personalized learning among students. Effectively capturing the continually evolving knowledge mastery states of students poses a formidable challenge in KT prediction. Traditional KT methods typically model students’ global knowledge mastery states solely based on the chronological sequence of their historical interactions, neglecting the significance of their current learning state and the inherent interplay between global and local knowledge mastery states. To bridge these gaps, this paper introduces a novel Learning State Enhanced Co-attention Model (LSEKT) for knowledge tracing. In terms of methodology, we contend that a student’s recent answering behavior is intricately tied to implicit learning states. Consequently, we devise a learning state extraction network to capture the student’s current learning state. Furthermore, to construct a more robust and interdependent representation of both global and local knowledge mastery states, we integrate a co-attention network. This network enhances the attention paid to pertinent knowledge points across both global and local scales, thereby adeptly capturing the underlying connections between global and local interaction sequences. Concurrently, we incorporate contrastive learning as an auxiliary task within our model to bolster its predictive prowess. Ultimately, we evaluated our approach through extensive experiments on four widely used datasets. The experimental outcomes underscore the remarkable performance of our model across diverse evaluation metrics, emphasizing the effectiveness of our proposed LSEKT model.},
  archive      = {J_APIN},
  author       = {Wang, Xinhua and Cao, Yibang and Xu, Liancheng and Sun, Ke},
  doi          = {10.1007/s10489-025-06463-9},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Global and local co-attention networks enhanced by learning state for knowledge tracing},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised learning with physics informed graph networks for partial differential equations. <em>APIN</em>, <em>55</em>(7), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06479-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural physical phenomena are commonly expressed using partial differential equations (PDEs), in domains such as fluid dynamics, electromagnetism, and atmospheric science. These equations typically require numerical solutions under given boundary conditions. There is a burgeoning interest in the exploration of neural network methodologies for solving PDEs, mainly based on automatic differentiation methods to learn the PDE-solving process, which means that the model needs to be retrained when the boundary conditions of PDE are changed. However, automatic differentiation requires substantial memory resources to facilitate the training regimen. Moreover, a learning objective that is tailored to the solution process often lacks the flexibility to extend to boundary conditions; thereby limiting the solution’s overall precision. The method proposed in this paper introduces a graph neural network approach, embedded with physical information, mainly for solving Poisson’s equation. An approach is introduced that reduces memory usage and enhances training efficiency through an unsupervised learning methodology based on numerical differentiation. Concurrently, by integrating boundary conditions directly into the neural network as supplementary physical information, this approach ensures that a singular model is capable of solving PDEs across a variety of boundary conditions. To address the challenges posed by more complex network inputs, the introduction of graph residual connections serves as a strategic measure to prevent network overfitting and to elevate the accuracy of the solutions provided. Experimental findings reveal that, despite having 30 times more training parameters than the Physics-Informed Neural Networks (PINN) model, the proposed model consumes 2.2% less memory than PINN. Additionally, generalization in boundary conditions has been achieved to a certain extent. This enables the model to solve partial differential equations with different boundary conditions, a capability that PINN currently lacks. To validate the solving capability of the proposed method, it has been applied to the model equation, the Sod shock tube problem, and the two-dimensional inviscid airfoil problem. In terms of the solution accuracy of the model equations, the proposed method outperforms PINN by 30% to four orders of magnitude. Compared to the traditional numerical method, the Finite Element Method (FEM), the proposed method also shows an order of magnitude improvement. Additionally, when compared to the improved version of PINN, TSONN, our method demonstrates certain advantages. The forward problem of the Sod shock tube, which PINN is currently unable to solve, is successfully handled by the proposed method. For the airfoil problem, the results are comparable to those of PINN.},
  archive      = {J_APIN},
  author       = {Lu, Lin and Zou, Yiye and Wang, Jingyu and Zou, Shufan and Zhang, Laiping and Deng, Xiaogang},
  doi          = {10.1007/s10489-025-06479-1},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Unsupervised learning with physics informed graph networks for partial differential equations},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topology-preserving and structure-aware (hyper)graph contrastive learning for node classification. <em>APIN</em>, <em>55</em>(7), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06491-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, graph contrastive learning (GCL) has attracted considerable attention, establishing a new paradigm for learning graph representations in the absence of human annotations. While notable advancements have been made, simultaneous consideration of both graphs and hypergraphs remains rare. This limitation arises because graphs and hypergraphs encode connectivity differently, making it challenging to develop a unified structure augmentation strategy. Conventional structure augmentation methods like adding or removing edges risk imperiling intrinsic topological traits and introducing adverse distortions such as disconnected subgraphs or isolated nodes. In this work, we propose a framework of contrastive learning on graphs and hypergraphs, named as UniGCL, to address these challenges by leveraging a unified adjacency representation that enables simultaneous modeling of pairwise and higher-order relationships. In particular, two structure augmentation methods are developed to perturb graph structure weights instead of altering connectivity, thereby preserving both graph and hypergraph topology while generating diverse augmented views. Furthermore, a structure-aware contrastive loss is proposed, which incorporates gradient perturbation techniques to enhance the model’s ability to capture fine-grained structural dependencies in (hyper)graphs. Extensive experiments are conducted on six real-world graph datasets and nine representative hypergraph datasets to evaluate the performance of the proposed framework. The results demonstrate that UniGCL achieves superior node classification performance compared to the advanced graph and hypergraph contrastive learning methods, across datasets with different homophilic extents and limited annotations. Additionally, ablation studies validate the effectiveness of our structure-preserving augmentations and structure-aware contrastive loss in enhancing performance.},
  archive      = {J_APIN},
  author       = {Zou, Minhao and Gan, Zhongxue and Wang, Yutong and Zhang, Junheng and Guan, Chun and Leng, Siyang},
  doi          = {10.1007/s10489-025-06491-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Topology-preserving and structure-aware (hyper)graph contrastive learning for node classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SiamYOLOv8: A rapid conditional detection framework for one-shot object detection. <em>APIN</em>, <em>55</em>(7), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06513-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning networks typically require vast amounts of labeled data for effective training. However, recent research has introduced a challenging task called One-Shot Object Detection, which addresses scenarios where certain classes are novel and unseen during training and represented by only a single labeled example. In this paper, we propose a novel One-Shot Object Detection model applicable to Conditional Detection without over-training on novel classes. Our approach leverages the strengths of YOLOv8 (You Only Look Once v8), a popular real-time object detector. Specifically, we incorporate a Siamese network and a matching module to enhance One-Shot Object Detection capabilities. Our proposed model, SiamYOLOv8, enables exploration of new applications without being limited by its training data. To evaluate the performance, we introduce a novel methodology for using the Retail Product Checkout (RPC) dataset “( https://github.com/MatD3mons/Conditional-Detection-datasets/tree/main/RPC )”, and extend our evaluation using the Grozi-3.2k dataset “( https://github.com/MatD3mons/Conditional-Detection-datasets/tree/main/GROZI-3.2k )”. In such contexts, new products often lack sufficient data for continuous Deep Learning methods, making individual case identification difficult. Our model outperforms SOTA models, achieving a significant performance improvement of 20.33% increase in Average Precision (+12.41 AP) on the Grozi-3.2k dataset and 25.68% increase (+17.37 AP) on the RPC dataset.},
  archive      = {J_APIN},
  author       = {Desmarescaux, Matthieu and Kaddah, Wissam and Alfalou, Ayman and Badoc, Isabelle},
  doi          = {10.1007/s10489-025-06513-2},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {SiamYOLOv8: A rapid conditional detection framework for one-shot object detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple disease diagnoses using heterogeneous EHR curated knowledge graph and machine learning models. <em>APIN</em>, <em>55</em>(7), 1-17. (<a href='https://doi.org/10.1007/s10489-024-05952-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) can play a significant role by assisting healthcare professionals in disease diagnosis, which is a critical step towards a patient’s treatment. Most of the research work in disease diagnosis systems predicts the presence or absence of a given single disease in a patient. However, there are only a few studies on multiple disease diagnoses, i.e., on detecting the presence of more than one disease at the same time. In this paper, we propose a framework for diagnosing multiple diseases using Knowledge Graph (KG), Knowledge embeddings and Machine Learning (ML). KG is created to semantically organize heterogeneous clinical details extracted from Electronic Health Records (EHRs). Additionally, we present a detailed comparison and analysis of three disease diagnosis systems, Single Disease Single Diagnosis (SDSD), Multiple Disease Single Diagnosis (MDSD), and Multiple Disease Multiple Diagnosis (MDMD) using the MIMIC-III dataset on Chronic Heart Failure (CHF), Acute Respiratory Failure (ARF) and Acute Kidney Failure (AKF) diseases. The above disease diagnosis systems have been implemented and analysed with different ML algorithms, such as Logistic Regression (LR), Random Forest (RF), Naïve Bayes (NB), and Support Vector Machine (SVM). Besides, detecting the probability of having multiple diseases at a time, the MDMD shows comparable results in comparison to SDSD and MDSD. This is being evaluated by using the Area Under Receiver Operating Characteristic (AUROC) and the Area Under Precision-Recall Curve (AUPRC) metrics. The MDMD system based on the proposed framework for multiple disease diagnosis predicts CHF, ARF and AKF in 91%, 74% and 79% of positive cases, respectively.},
  archive      = {J_APIN},
  author       = {Dhiman, Shivani and Thukral, Anjali and Bedi, Punam},
  doi          = {10.1007/s10489-024-05952-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Multiple disease diagnoses using heterogeneous EHR curated knowledge graph and machine learning models},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DBFF-GRU: Dual-branch temporal feature fusion network with fast GRU for multivariate time series forecasting. <em>APIN</em>, <em>55</em>(7), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06447-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series (MTS) forecasting involves the use of multiple interrelated sequential data to predict future trends, necessitating the extraction of potential associative information from complex historical data. Currently, Transformers dominate the field of MTS prediction due to their core mechanism of self-attention, which effectively captures long-range dependencies. However, self-attention is inherently permutation-invariant, leading to the loss of sequential information. To address this issue, we propose the Dual-Branch Temporal Feature Fusion Network with Fast GRU (DBFF-GRU). In the feature fusion module, a dual-branch convolutional structure is employed to extract local and global features from the time series data separately, and a lightweight attention module is integrated into the global feature branch to capture dependencies among variables. Additionally, we introduce a fast iterative GRU structure to further capture long-term dependencies and enhance model efficiency. Extensive experiments on real-world data demonstrate the effectiveness of DBFF-GRU compared to state-of-the-art techniques.},
  archive      = {J_APIN},
  author       = {Li, Jinglei and Liu, Dongsheng and Ma, Guofang and Chen, Yaning and Jiang, Hongwei},
  doi          = {10.1007/s10489-025-06447-9},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {DBFF-GRU: Dual-branch temporal feature fusion network with fast GRU for multivariate time series forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DCSR: A deep continual learning-based scheme for image super resolution using knowledge distillation. <em>APIN</em>, <em>55</em>(7), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06490-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have revolutionized the design of image super resolution schemes, in view of their capability of learning suitable features of high-resolution images. The performance of the deep image super resolution networks is very dependent on the distribution of the samples used for their training process. When the deep super resolution networks try to learn super-resolving the low-resolution images from different distributions in a sequential manner, they can only provide high performance for the most recent low-resolution image distribution used in their training process. In view of this, and in order to address the forgetting problem of the super resolution networks during learning from a new distribution of the low-resolution images, in this paper, we propose a continual learning-based scheme, which is developed based on the knowledge distillation technique. Specifically, our proposed deep continual learning-based image super resolution method aims at retaining the knowledge obtained from the previously learned distribution of the training samples, while learning the new distribution as efficiently as possible. To achieve this, the proposed scheme employs the supervision of the signals produced by multiple teacher networks. The results of the extensive experimentation show the effectiveness of the various ideas employed in the development of the proposed method. Further, it is shown that the proposed scheme outperforms the various state-of-the-art image super resolution methods when they are subjected to learning different distributions of the low-resolution images.},
  archive      = {J_APIN},
  author       = {Esmaeilzehi, Alireza and Zaredar, Hossein and Ahmad, M. Omair},
  doi          = {10.1007/s10489-025-06490-6},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {DCSR: A deep continual learning-based scheme for image super resolution using knowledge distillation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the application of ChatGPT in scientific topic analysis: A novel paradigm for enhanced analysis and efficiency. <em>APIN</em>, <em>55</em>(7), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06498-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Latent Dirichlet Allocation (LDA) is a powerful text analysis tool that has been widely used in literature to reveal the development trends of disciplines and fields, thereby greatly broadening the frontier of text mining and knowledge discovery. However, as a probability model based on word frequency statistics, LDA has inherent limitations in its inability to deeply understand the deep meaning of words in a document set. Although some researchers have attempted to combine LDA with other deep learning models, such as BERT and BiLSTM, in order to improve the effectiveness of topic modeling, the progress achieved has not been significant. In this study, we innovatively propose to combine the text comprehension ability of ChatGPT with the statistical ability of LDA model, aiming to further improve the accuracy and depth of topic modeling. Specifically, we first conduct topic modeling on the target text using the LDA topic model to obtain a topic-word matrix. Then, we input the word set corresponding to each topic in the matrix into the ChatGPT model with an appropriate prompt template to obtain a topic name-description table that accurately describes the topic. Finally, we input the content of each target text and the corresponding topic name-description table into the ChatGPT model to obtain the topic classification result for each text. In addition, we also conduct quantitative evaluation on the proposed method through calculating similarity based on BERT's word embedding vector. The experimental results show that our proposed ChatGPT + LDA method can significantly enhance the effectiveness of topic modeling, bringing new breakthroughs to the field of text analysis and knowledge discovery.},
  archive      = {J_APIN},
  author       = {Muhetaer, Muretijiang and Hao, Fan},
  doi          = {10.1007/s10489-025-06498-y},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Exploring the application of ChatGPT in scientific topic analysis: A novel paradigm for enhanced analysis and efficiency},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FutuTP: Future-based trajectory prediction for autonomous driving. <em>APIN</em>, <em>55</em>(7), 1-12. (<a href='https://doi.org/10.1007/s10489-025-06510-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory prediction is an essential aspect of autonomous driving technology. Based on the historical trajectories and environmental information, trajectory prediction methods predict the future trajectory of a vehicle. Goal-based methods have been successful because of their excellent interpretability. However, these methods ignore future lane information and interactions in future trajectories, which leads to prediction failures in some scenes. In this paper, we propose an encoder-decoder model called future-based trajectory prediction (FutuTP). The encoder fuses the interactions of future trajectories through a transformer module. The decoder predicts the future lane area and applies the results to generate a trajectory. The experimental results show that FutuTP achieves more accurate predictions than does the SOTA method on Argoverse 1. Especially in terms of the $$\text {minFDE}_6$$ metric, FutuTP outperforms the SOTA method by approximately 6%. The code can be accessed via the following link: https://github.com/Qingchao-Xu/FutuTP.},
  archive      = {J_APIN},
  author       = {Xu, Qingchao and Liu, Yandong and Wen, Shixi and Yang, Xin and Zhou, Dongsheng},
  doi          = {10.1007/s10489-025-06510-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {FutuTP: Future-based trajectory prediction for autonomous driving},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). StealthMask: Highly stealthy adversarial attack on face recognition system. <em>APIN</em>, <em>55</em>(7), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06511-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) based on deep learning algorithms are widely used in real-world scenarios. However, these networks are vulnerable to adversarial examples-maliciously crafted inputs that can cause the model to make incorrect predictions. The existence of adversarial examples presents a significant challenge to the field of deep learning, with profound implications for various aspects of our lives. In face recognition technology, adversarial examples pose a substantial security risk. In this paper, we propose a novel method for generating adversarial patches designed to be worn as masks. The perturbed mask is crafted to deceive face recognition models, thereby highlighting the security vulnerabilities inherent in this technology. Our experimental results demonstrate that the mask generated by the proposed method effectively misleads the face recognition system, achieving high attack success rates while maintaining necessary stealthiness and transferability. Moreover, our method successfully attacks commercial face recognition systems and real-world access control systems, exposing the vulnerabilities of existing face recognition technologies in security-critical applications. Notably, compared to traditional methods, our proposed method emphasizes the stealthiness of the adversarial mask more than traditional methods. To account for physical-world factors, such as distortion, rotation, and deformations, we integrate a specifically designed loss function, thereby enhancing the method’s stability and reliability in practical scenarios.},
  archive      = {J_APIN},
  author       = {Mi, Jian-Xun and Chen, Mingxuan and Chen, Tao and Cheng, Xiao},
  doi          = {10.1007/s10489-025-06511-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {StealthMask: Highly stealthy adversarial attack on face recognition system},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-branch contrastive learning for weakly supervised object localization. <em>APIN</em>, <em>55</em>(7), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06514-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The weakly supervised object localization task uses image-level labels to train object localization models. Traditional convolutional neural network (CNN)-based methods usually localize objects using a class activation map. However, the class activation map usually suffers from the problem of activating a small part of the object that is most discriminative. Meanwhile, the methods based on the Vision Transformer can capture long-range feature dependencies but tend to ignore local feature details. In this paper, we innovatively propose a dual-branch contrastive learning (DBC) method that consists of a Transformer and a CNN branch. The method can effectively separate the background and foreground of an image and fuse the features of Transformer and CNN through contrastive learning. Specifically, the method separates the background and foreground representations of the image using the initially generated class-agnostic activation maps. Then, the representations of the same image from different branches form positive pairs for contrastive learning. The background and foreground representations from the same branch form negative pairs. Finally, the DBC method forces the model to separate the background and foreground representations through negative contrastive loss and makes the model fuse the features of two branches through positive contrastive loss. Experiments on the ILSVRC benchmark show that the proposed method can achieve a Top-1 localization accuracy of 59.9% and a GT-known localization accuracy of 71.7%, which are better metrics than those of the state-of-the-art methods with the same parameter complexity.},
  archive      = {J_APIN},
  author       = {Guo, Zebin and Li, Dong and Du, Zhengjun and Seng, Bingfeng},
  doi          = {10.1007/s10489-025-06514-1},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Dual-branch contrastive learning for weakly supervised object localization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intra-frame scan-free video state spaces model for video moment retrieval. <em>APIN</em>, <em>55</em>(7), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06517-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity of video moment retrieval tasks, effectively handling temporal and spatial information in video data has become a central challenge. This paper proposes a novel Intra-frame Scan-free Video State Spaces Model to address the spatiotemporal modeling problem in video moment retrieval. The model eliminates the dependency on the scanning order of intra-frame patches, overcoming the dual temporal limitations of frame order and within-frame patch sequence, which enhances the flexibility and efficiency of video understanding. To better model temporal information, we introduce the concept of video moment boundaries and propose the Weighted Relative Center Difference Loss, which ensures that the predicted center regions are closer to the ground truth, thereby improving retrieval accuracy. Extensive experiments on three public video datasets (ActivityNet Captions, TACoS, and Charades-STA) show that the model achieves superior or near-optimal performance across multiple metrics. The ablation study compares the performance loss when removing different components, the effect of different scanning methods on performance and inference throughput, and the effect of hyperparameters such as the number of SSM layers and the weighted relative centre difference loss threshold on retrieval performance. These results validate the effectiveness and robustness of our approach for video moment retrieval.},
  archive      = {J_APIN},
  author       = {Yu, Fengzhen and Gu, Xiaodong},
  doi          = {10.1007/s10489-025-06517-y},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Intra-frame scan-free video state spaces model for video moment retrieval},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intention-aware neural networks with session disentanglement for noise filtering in session-based recommendation. <em>APIN</em>, <em>55</em>(7), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06519-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation is a significant and practical approach in predicting the next action of anonymous users within a recommendation system. However, accurate recommendations remain challenging due to limited information. Recently, many works based on neural networks have been proposed to address this task. Nevertheless, these works tend to focus solely on modeling item relationships while neglecting the importance of sessions and exhibiting suboptimal performance in handling noise items within current sessions. To address these issues, this paper proposes an Intention-Aware Neural Networks with Session Disentanglement (IANNSD) that incorporates session modeling and user intent as key factors. Specifically, in the local relationship encoder (LRE), we compute the similarity between the current session and its neighboring items to alleviate the impact of noise neighbor items on recommendation accuracy. In the global relationship encoder (GRE), sessions serve as a constraint for refining the intent distribution of each item, and a highway network is utilized to optimize the outputs of GRE. Additionally, we design a label optimization module to assist model training. Extensive experiments are carried out on three real datasets, and the experimental results demonstrate that IANNSD surpasses state-of-the-art models in session-based recommendation performance.},
  archive      = {J_APIN},
  author       = {Huang, Feihu and Xu, Haoyu and Yang, Ning and Wang, Jince and Yi, Peiyu and Jiang, Yuan},
  doi          = {10.1007/s10489-025-06519-w},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Intention-aware neural networks with session disentanglement for noise filtering in session-based recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-perspective semantic decoupling and enhancement in graph attention network for knowledge graph completion. <em>APIN</em>, <em>55</em>(7), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06520-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs (KGs) are semantic repositories that describe the real world and have been widely applied in various downstream applications. However, KGs still have many incomplete facts, so Knowledge Graph Completion (KGC) is proposed to infer missing facts. Among them, Graph Attention Network-based models (GATs) show great power. However, GATs have two flaws in handling multiple semantics of entities in relational context: (1) Current GATs fail to distinguish the various semantics of the entity which are exhibited by the relations from different perspectives. (2) Existing GATs cannot capture the similar semantics of different entities which are presented by the relations from the same perspective. Hence, we propose a graph attention network based on multi-perspective semantic decoupling and enhancement (MSDE). To capture diverse semantics in the relational context, we classify relations to partition entity multi-perspective semantics, and then we use graph attention networks to obtain multi-perspective decoupled embeddings of entities. To capture semantically similar entities, we select multi-perspective similar entities based on multi-perspective conditional entropy and high-order similar neighbors based on multi-perspective decoupled embedding. Finally, we use an attention decay network to aggregate multi-perspective similar entities and high-order similar neighbors to update entity feature embeddings. Experimental results show that MSDE exhibits marked performance gains compared to other state-of-the-art (sota) models. Significantly, the MRR indicator improves by 6.5% on the FB15K-237 dataset, by 2.3% on the WN18RR dataset, by 7.3% on the Kinship dataset and by 9.2% on the YAGO3-10 over the sota models.},
  archive      = {J_APIN},
  author       = {Xu, Tianyi and Wang, Yan and Zhang, Wenbin and Zhao, Yue and Yu, Jian and Yu, Mei and Guo, Jiujiang and Zhao, Mankun},
  doi          = {10.1007/s10489-025-06520-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Multi-perspective semantic decoupling and enhancement in graph attention network for knowledge graph completion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How to find opinion leader on the online social network?. <em>APIN</em>, <em>55</em>(7), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06525-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks (OSNs) provide a platform for individuals to share information, exchange ideas, and build social connections beyond in-person interactions. For a specific topic or community, opinion leaders are individuals who have a significant influence on others’ opinions. Detecting opinion leaders and modeling influence dynamics is crucial as they play a vital role in shaping public opinion and driving conversations. Existing research have extensively explored various graph-based and psychology-based methods for detecting opinion leaders, but there is a lack of cross-disciplinary consensus between definitions and methods. For example, node centrality in graph theory does not necessarily align with the opinion leader concepts in social psychology. This review paper aims to address this multi-disciplinary research area by introducing and connecting the diverse methodologies for identifying influential nodes. The key novelty is to review connections and cross-compare different multi-disciplinary approaches that have origins in: social theory, graph theory, compressed sensing theory, and control theory. Our first contribution is to develop cross-disciplinary discussion on how they tell a different tale of networked influence. Our second contribution is to propose trans-disciplinary research method on embedding socio-physical influence models into graph signal analysis. We showcase inter- and trans-disciplinary methods through a Twitter case study to compare their performance and elucidate the research progression with relation to psychology theory. We hope the comparative analysis can inspire further research in this cross-disciplinary area.},
  archive      = {J_APIN},
  author       = {Jin, Bailu and Zou, Mengbang and Wei, Zhuangkun and Guo, Weisi},
  doi          = {10.1007/s10489-025-06525-y},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {How to find opinion leader on the online social network?},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated fine-grained prompts for vision-language models based on open-vocabulary object detection. <em>APIN</em>, <em>55</em>(7), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06527-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-language models can be used for open-vocabulary object detection. The existing methods suffer from low matching accuracy between prompt and image regions, as well as limited generalization capability as they adopt a data-centralized model training approach that ignores data heterogeneity. To alleviate these issues, we propose a federated fine-grained prompts learning method called FFPLearning, for open-vocabulary object detection using vision-language models. Specifically, FFPLearning quantifies the quality of proposals using pre-fused EoG (Energy of Gradient) and IoU (Intersection over Union) scores and organizes them into individual groups. Then learnable fine-grained prompts are trained to align the grouped region proposals in the feature space. A momentum update algorithm is designed to assess the quality of each participating client in the federated learning. Additionally, a Transformer-based feedback aggregation algorithm is designed to thoroughly leverage the semantic information from prompts and aggregate them based on the qualities of clients. Comprehensive evaluations on COCO and LVIS datasets demonstrate that FFPLearning is very effective, with +5.8 Novel AP50 and +3.3 APr improvements compared with existing state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Li, Yu},
  doi          = {10.1007/s10489-025-06527-w},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Federated fine-grained prompts for vision-language models based on open-vocabulary object detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). E-GAIL: Efficient GAIL through including negative corruption and long-term rewards for robotic manipulations. <em>APIN</em>, <em>55</em>(7), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06335-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning an effective manipulation policy with high efficiency in robotics continues to be a significant challenge. In this paper, we propose E-GAIL, which aims to learn manipulation policies efficiently from a limited set of demonstrations with negative corruption and long-term rewards under the framework of GAIL. Specifically, we propose two techniques: 1) Utilizing both short-term and long-term observations to offer additional rewards for training, accelerating convergence. 2) Incorporating negative actions into generated trajectories for corruption to improve data effectiveness and increase success rates. E-GAIL achieves a 25% improvement in success rates across multiple manipulation tasks, requiring 70% fewer episodes for policy convergence, highlighting its efficiency with limited demonstrations. Our video is available at https://youtu.be/bIDfOjYcY54 .},
  archive      = {J_APIN},
  author       = {Tan, Jiayi and Chen, Gang and Huang, Zeyuan and Liu, Haofeng and H. Ang Jr, Marcelo},
  doi          = {10.1007/s10489-025-06335-2},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {E-GAIL: Efficient GAIL through including negative corruption and long-term rewards for robotic manipulations},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pgcnn: An interpretable graph convolutional neural network for predicting the mechanical properties of ti-6Al-4V alloy. <em>APIN</em>, <em>55</em>(7), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06401-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a polycrystalline graph convolutional network (PGCNN) to predict the mechanical properties of Ti-6Al-4V alloy’s dual-phase polycrystalline microstructure. The model captures complex inter-grain interactions. It integrates node features and graph structural information to map microstructures to macroscopic mechanical properties. The PGCNN model demonstrated exceptional predictive performance (mean absolute relative error, MARE = 0.369%). It remained robust in handling nonlinear relationships and capturing high-order inter-grain interactions, even with limited datasets (MARE = 1.985%). We evaluated the interpretability of the PGCNN model through analyses at the node, edge, and graph structure levels, offering comprehensive insights. At the node level, the influence of each grain (node) on the output was quantified, clarifying the direct link between individual grains and macroscopic performance. Edge level analysis emphasized the importance of inter-grain interactions. It laid the groundwork for identifying grain boundaries that significantly affect mechanical properties. Graph level analysis quantified the overall impact of microstructural features on macroscopic performance. This provided insights into the complex “microstructure–mechanical property” relationship in dual-phase polycrystals.},
  archive      = {J_APIN},
  author       = {Gao, Zihao and Zhu, Changsheng and Shu, Yafeng and Wang, Canglong and Chen, Yupeng and Wang, Shaohui},
  doi          = {10.1007/s10489-025-06401-9},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Pgcnn: An interpretable graph convolutional neural network for predicting the mechanical properties of ti-6Al-4V alloy},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reducing oversmoothing through informed weight initialization in graph neural networks. <em>APIN</em>, <em>55</em>(7), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06426-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we generalize the ideas of Kaiming initialization to Graph Neural Networks (GNNs) and propose a new scheme (G-Init) that reduces oversmoothing, leading to very good results in node and graph classification tasks. GNNs are commonly initialized using methods designed for other types of Neural Networks, overlooking the underlying graph topology. We analyze theoretically the variance of signals flowing forward and gradients flowing backward in the class of convolutional GNNs. We then simplify our analysis to the case of the GCN and propose a new initialization method. Results indicate that the new method (G-Init) reduces oversmoothing in deep GNNs, facilitating their effective use. Our approach achieves an accuracy of 61.60% on the CS dataset (32-layer GCN) and 69.24% on Cora (64-layer GCN), surpassing state-of-the-art initialization methods by 25.6 and 8.6 percentage points, respectively. Extensive experiments confirm the robustness of our method across multiple benchmark datasets, highlighting its effectiveness in diverse settings. Furthermore, our experimental results support the theoretical findings, demonstrating the advantages of deep networks in scenarios with no feature information for unlabeled nodes (i.e., “cold start” scenario).},
  archive      = {J_APIN},
  author       = {Kelesis, Dimitrios and Fotakis, Dimitris and Paliouras, Georgios},
  doi          = {10.1007/s10489-025-06426-0},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Reducing oversmoothing through informed weight initialization in graph neural networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recommendation system for frequent item sets using multi-objective chaotic optimization with convolutional BiLSTM model. <em>APIN</em>, <em>55</em>(7), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06432-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recommendation system offers a creative way to handle the limitations of e-commerce services by using item and user details. It is used to ascertain the user’s preferences in order to suggest products they would likely purchase and identify frequently used items from the data. The recommender model is designed with several common collaborative filtering techniques, but it has some complications. To overcome this drawbacks, a novel technique is proposed to find the frequent item in the given dataset. This research paper used two types of data, namely the product image data and user rating matrix data. Initially, image characteristics are retrieved using a residual dense network (RDN) to extract relevant features from the images. Then, the extracted features are fed into Multi-Objective Chaotic Horse Herd Optimization (MO-CHHO) to find common item sets from many items. Here, support, confidence, lift, and conviction are considered multi-objective functions. The text data is classified using Convolutional BiLSTM (CBiL) model based on significant sentiment features like All-caps, hashtags, emoticons, negation, elongated units, bag-of-units, punctuation, and numerical values to identify whether the item is common or not. Finally, the fusion process is performed using correlation to find the final frequent item sets from the image and data sets. The evaluation results show that the proposed method achieved 98% accuracy, precision of 99%, 98.3% of sensitivity, 99.5% of specificity, and 98.7% F-1 score using the amazon product review dataset.},
  archive      = {J_APIN},
  author       = {D, Sudha and Krishnamurthy, M.},
  doi          = {10.1007/s10489-025-06432-2},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Recommendation system for frequent item sets using multi-objective chaotic optimization with convolutional BiLSTM model},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HT-STNet: A hierarchical tucker decomposition and spatio-temporal LSTM network for accurate and efficient shared mobility demand forecasting on sparse data. <em>APIN</em>, <em>55</em>(7), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06500-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes an innovative framework that combines spatiotemporal long- and short-term memory networks (ST-LSTM) with hierarchical Tucker decomposition (HTD), aiming at efficiently processing and predicting complex spatiotemporal data, such as the demand for shared trips. The framework compresses the original tensor data into low-rank cores and factor matrices through a recursive hierarchical decomposition strategy, which not only significantly reduces the storage and computation overheads, but also improves the data processing efficiency, especially in sparse data scenarios showing superior performance. In addition, ST-LSTM achieves accurate modeling of multi-scale features through a lightweight spatio-temporal gating mechanism, capturing the long-term and short-term dependencies in time series.HT-STNet also proposes a dynamic feature selection and gradient masking mechanism, which effectively solves the problem of localized sparsity in traffic data, and avoids redundant computation of invalid information and zero-valued elements through sparsity-aware decomposition of rank adjustment. The experimental results show that HT-STNet outperforms multiple mainstream baseline models in terms of prediction accuracy, computational efficiency, and sparse data processing capability, especially in multi-scale feature extraction and dimensionality reduction. The method provides an efficient and robust solution for high-dimensional spatio-temporal data modeling, which is especially suitable for complex travel demand prediction tasks and breaks through the bottleneck of traditional models in characterizing complex spatio-temporal relationships.},
  archive      = {J_APIN},
  author       = {Yan, Hongyu and Li, Jianbo and Chu, Benjia and Xu, Zhihao},
  doi          = {10.1007/s10489-025-06500-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {HT-STNet: A hierarchical tucker decomposition and spatio-temporal LSTM network for accurate and efficient shared mobility demand forecasting on sparse data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Upgraded decision making in continuous domains for autonomous vehicles in high complexity scenarios using escalated DDPG. <em>APIN</em>, <em>55</em>(7), 1-25. (<a href='https://doi.org/10.1007/s10489-025-06505-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous vehicles (AVs) have gained attention for their safety enhancements and comfortable travel. Ongoing research targets improvements in AV technology, addressing challenges like road uncertainties, weather changes, and continuous state-actions. In this paper, we propose “Escalated DDPG,” an extension of the Deep Deterministic Policy Gradient (DDPG) algorithm, designed mainly for autonomous vehicle (AV) decision-making. Our novel approach tackles key challenges encountered with DDPG, including instability, slow convergence, and the growing complexity of AV environments. By upgrading action selection and learning policies based on consecutive actions and states, Escalated DDPG enhances convergence speed while maintaining a balanced exploration-exploitation trade-off. We conduct experiments in a gym environment, comparing the performance of our method with traditional DDPG. Results illustrate the superior accuracy and adaptability of Escalated DDPG in handling decision-making tasks involving continuous action and state spaces, even in complex scenarios. The findings in this paper contribute to advancing AV technology, enhancing their decision-making capabilities, and enabling more efficient and reliable autonomous driving systems.},
  archive      = {J_APIN},
  author       = {Zouaidia, Khouloud and Rais, Med Saber and Bougueroua, Lamine},
  doi          = {10.1007/s10489-025-06505-2},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {Upgraded decision making in continuous domains for autonomous vehicles in high complexity scenarios using escalated DDPG},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A digital twin-based framework for load identification using odd harmonic current plots. <em>APIN</em>, <em>55</em>(7), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06512-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-intrusive Load Monitoring (NILM) techniques are becoming more and more widespread, because of the interest that consumers have in efficient energy consumption and management. At the same time, NILM application along with Demand Side Management (DSM) schemes could face Distribution Network (DN) operational issues like congestion management. The advent of Digital Twin (DT) technology offers a sustainable solution for more effective energy management in real-time applications. In addition, recent developments in NILM suggest that high sampling rates of the aggregated extracted signal could enable better performance for load disaggregation. This work explores DT integration with NILM for a real-time appliance classification scheme. More specifically, a Convolutional Neural Network (CNN) model fed with images that depict odd current harmonics is utilized to classify the appliance(s) operation. The images are extracted exploiting the high sampling measurements provided by the PLAID dataset. Three different scenarios that include various residential appliances are examined comprising both single and combined appliance operation, as well as event detection (appliance’s activation/de-activation). The results of the proposed high sampling DT-based NILM framework show: (a) a remarkably good performance of the model, despite the limited data, proving that the utilization of harmonics contributes to an improved classification, and (b) the applicability of the model to real-time applications given that the whole procedure from initial data processing to image classification (i.e., appliance identification) lasts less than 1 s.},
  archive      = {J_APIN},
  author       = {Mylona, Dimitra N. and Bouhouras, Aggelos S.},
  doi          = {10.1007/s10489-025-06512-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {A digital twin-based framework for load identification using odd harmonic current plots},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tensorized graph-guided view recovery for incomplete multi-view clustering. <em>APIN</em>, <em>55</em>(7), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06515-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering (MVC) methods have demonstrated remarkable success when all samples are available across multiple views by leveraging consistency and complementary information. However, real-world multi-view data often suffers from incompleteness, where some samples are missing in one or more views. This incompleteness makes MVC challenging, as it becomes difficult to uncover consistency and complementary relationships among the view data. As a result, Incomplete Multi-View Clustering (IMVC) has emerged to address the limitations posed by missing data. An intuitive approach to tackle this issue is view recovery-effectively leveraging consistency information from multiple views to impute missing data. However, the quality of view recovery heavily depends on the learned consistency information, making it crucial to learn high-quality consistency representations. To address this challenge, we propose a novel approach called Tensorized Graph-Guided View Recovery (TGGVR), which integrates view recovery and tensorized graph learning within a unified framework. The tensorized graph learning estimate a similarity graph for each view by exploiting consistency and complementary information through tensorized learning. In addition, high-quality neighborhood structures are exploited to obtain a more accurate consensus graph. This high-quality consensus graph then guides the more accurate recovery of missing data, establishing a cyclical procedure in which tensorized graph learning and data imputation mutually reinforce each other. Experimental results demonstrate that our proposed method outperforms several state-of-the-art approaches in tackling the challenging task of IMVC. Notably, our method significantly outperforms representative competing methods by more than 5% and 10% on the BBC and Caltech datasets, respectively.},
  archive      = {J_APIN},
  author       = {Zheng, Li and Yan, Guanghui and Tang, Chunyang and Yan, Tianfeng},
  doi          = {10.1007/s10489-025-06515-0},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Tensorized graph-guided view recovery for incomplete multi-view clustering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel hybrid statistical and neural network model for forecasting multivariate time series parameters in forging process. <em>APIN</em>, <em>55</em>(7), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06523-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time forecasting of multivariate time series parameters in forging processes is essential for precise control, but existing models often struggle with transient dynamics and multivariate interdependencies. This study proposes a hybrid statistical and neural network (HSNN) model that integrates autoregressive integrated moving average (ARIMA) module with hierarchical deep learning blocks to incrementally refine linear trends and nonlinear residuals. The HSNN uniquely combines dual attention mechanisms (feature and temporal) with ARIMA-deep learning residual blocks, dynamically weighting multivariate parameter relationships while progressively correcting errors through residual propagation. Validated on 28,800 industrial samples, the HSNN achieves the mean absolute error (MAE) values as low as 0.0153 for vertical clamping percentage and 0.0458 for forging force, outperforming ten benchmarks by 56.52% ~ 78.94% in MAE. Generalization tests on an external dataset from our previous work confirm a 67.27% reduction in MAE compared to traditional backpropagation networks. This research bridges the gap between statistical efficiency and deep learning adaptability, providing a deployable solution for real-time forging control.},
  archive      = {J_APIN},
  author       = {Zeng, Ning-Fu and Lin, Yong-Cheng and Wan, Miao and Wu, Gui-Cheng and Chen, Ming-Song and Li, Chao},
  doi          = {10.1007/s10489-025-06523-0},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {A novel hybrid statistical and neural network model for forecasting multivariate time series parameters in forging process},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Power-GNN: A graph over-sampling method to mitigate power-law distribution in graph neural networks. <em>APIN</em>, <em>55</em>(7), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06421-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the advent of Graph Neural Networks (GNNs), they have been widely applied in the analysis and processing of graph data, especially demonstrating outstanding performance in semi-supervised node classification tasks. However, the class distribution in real-world graph data often exhibits a long-tail, imbalanced distribution, posing significant challenges to the classification performance of GNNs. Graph over-sampling methods address this by synthesizing new nodes for minority classes and creating corresponding edges, thus aiming to balance class representation and enhance model accuracy. Nonetheless, the degree distribution of nodes in reality also follows a power-law distribution, leading to synthesized nodes becoming low-degree tail nodes under existing edge construction strategies. This restricts their ability to acquire sufficient aggregation information, thereby degrading their representation quality and impacting classification outcomes. To address these challenges, this paper introduces Power-GNN, a novel graph data over-sampling framework tailored to tackle the dual challenges of imbalanced class distribution and the power-law distribution of node degrees. Power-GNN innovatively utilizes the power-law distribution of node degrees in a reverse manner. It strategically adds edges with high similarity to nodes with fewer connections, thereby amplifying the aggregation capability of synthesized nodes and boosting overall model performance. Through evaluations on multiple public benchmark datasets, Power-GNN has demonstrated superior performance over existing baselines across three common GNN architectures.},
  archive      = {J_APIN},
  author       = {Li, Peidong and Zhong, Zhenghong and Zhao, Yangguang and Shao, Changheng and Sui, Yi and Sun, Rencheng},
  doi          = {10.1007/s10489-025-06421-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Power-GNN: A graph over-sampling method to mitigate power-law distribution in graph neural networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 2D-variation convolution-based generative adversarial network for unsupervised time series anomaly detection: A MSTL enhanced data preprocessing approach. <em>APIN</em>, <em>55</em>(7), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06469-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection (TSAD) is a critical task in various research fields such as quantitative trading, cyber attack detection, and semiconductor outlier detection. As a binary classification task, the performance of TSAD is significantly influenced by the data imbalance problem, where the datasets heavily skew towards the normal class due to the extreme scarcity of abnormal data. Furthermore, the limited availability of anomaly data makes it challenging to perform manual labeling, which leads to the development of unsupervised anomaly detection approaches. In this paper, we propose a novel generative adversarial network (GAN) with Multiple-Seasonal-Trend decomposition using Loess (MSTL) data preprocessing algorithm for unsupervised anomaly detection on time series data. With the MSTL data preprocessing algorithm, the network architecture is simplified, thereby alleviating computational burden. A 2D-variation convolution-based method is integrated into the GAN to enhance feature extraction and generalization capabilities. To avoid the model collapse problem caused by data deficiency, multiple generators are employed, and a joint loss function is designed to improve the robustness of the training process. Experiments on several benchmark datasets from various domains demonstrate the efficacy and superiority of our approach compared to existing competitive approaches.},
  archive      = {J_APIN},
  author       = {Wang, Qingdong and Zou, Lei and Liu, Weibo},
  doi          = {10.1007/s10489-025-06469-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {2D-variation convolution-based generative adversarial network for unsupervised time series anomaly detection: A MSTL enhanced data preprocessing approach},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An innovative deep learning-driven technique for restoration of lost high-density surface electromyography signals. <em>APIN</em>, <em>55</em>(7), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06471-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-density surface electromyography (HD-sEMG) plays a crucial role in medical diagnostics, prosthetic control, and human-machine interactions. Compared to traditional bipolar sEMG, HD-sEMG employs smaller electrode spacing and sizes. This configuration not only reduces the signal collection area but also increases sensitivity to individual variations in skin impedance. Additionally, smaller high-density electrodes are more susceptible to environmental electromagnetic interference, thereby increasing the risk of signal loss and limiting the further development and application of HD-sEMG technology. To address this issue, this study introduces a novel deep learning-based technique specifically designed to restore lost HD-sEMG signals. Through an improved novel convolutional neural network (CNN), our method can reconstruct HD-sEMG signals both efficiently and accurately. Experimental results demonstrate that the proposed CNN algorithm effectively reconstructs lost HD-sEMG signals with high fidelity. The average root mean square error (RMSE) across all participants was 0.108, the mean absolute error (MAE) was 0.070, and the coefficient of determination ( $$R^2$$ ) was 0.98. Furthermore, the model achieved an average structural similarity index measure (SSIM) of 0.96 and a peak signal-to-noise ratio (PSNR) of 29.13 dB, indicating high levels of structural similarity and signal clarity in the reconstructed data. These findings highlight the robustness and effectiveness of our method, suggesting its potential for enhancing the reliability and utility of HD-sEMG signals in real applications.},
  archive      = {J_APIN},
  author       = {Mao, Juzheng and Li, Honghan and Zhao, Yongkun},
  doi          = {10.1007/s10489-025-06471-9},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {An innovative deep learning-driven technique for restoration of lost high-density surface electromyography signals},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EnsembleSleepNet: A novel ensemble deep learning model based on transformers and attention mechanisms using multimodal data for sleep stages classification. <em>APIN</em>, <em>55</em>(7), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06484-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifying sleep stages using biological signals is an important and challenging task in sleep medicine. Combining deep learning networks with transformers and attention mechanisms represents a powerful approach for achieving high-performance results in classification tasks. Multimodal learning, which integrates various types of input data, can significantly enhance the classification performance of these networks. However, many existing studies either rely on single-modal data or design a single model to handle different signals and modalities without considering the unique characteristics of each data type, which often fails to capture optimal features. To address this limitation, we propose an ensemble model for sleep stage classification that leverages multimodal data, including raw signals, spectrograms, and handcrafted features. We utilize the Sleep Heart Health Study (SHHS) dataset by selecting multiple signals from polysomnography recordings. Our approach develops three specialized sub-models with different layers and components, each designed based on the unique characteristics of specific data types and signals, and integrates them into a unified ensemble deep learning framework. The proposed EnsembleSleepNet achieved comparable performance against existing methods by obtaining high values of 0.897, 0.852, and 0.831 in accuracy, Cohen's kappa (κ), and Macro F1 score (MF1) respectively. Additionally, ablation studies revealed the impact of the selected signals and components in our developed model.},
  archive      = {J_APIN},
  author       = {Mostafaei, Sahar Hassanzadeh and Tanha, Jafar and Sharafkhaneh, Amir},
  doi          = {10.1007/s10489-025-06484-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {EnsembleSleepNet: A novel ensemble deep learning model based on transformers and attention mechanisms using multimodal data for sleep stages classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DF $$^2$$ net: Deformable fourier filter network for hyperspectral image classification. <em>APIN</em>, <em>55</em>(7), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06493-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MLP-like architectures in hyperspectral image (HSI) classification flourish recently. However, these methods face challenges such as insufficient spectral-spatial feature extraction capability and excessive consumption of network computing resources. To address these problems, a deformable Fourier filter network (DF $$^{\varvec{2}}$$ Net) is proposed as an innovative lightweight MLP framework for HSI classification. DF $$^{\varvec{2}}$$ Net employs Fourier transform filters and spatial deformable operations to efficiently capture spectral-spatial features while maintaining a lightweight design. Specifically, two modules in DF $$^{\varvec{2}}$$ Net are developed to extract and facilitate the deep integration of spectral-spatial features, namely the spectral discrete Fourier transform filter (SeDFT) module and the spatial deformable discrete Fourier transform filter (SaD $$^{\varvec{2}}$$ FT) module. The SeDFT module employs a one-dimensional discrete Fourier transform filter (1D $$^{\varvec{2}}$$ FT) to extract spectral features in the frequency domain, effectively capturing detailed information from the original spectrum. Additionally, the parameter-free design of the SeDFT module streamlines the feature processing pipeline and improves computational efficiency. The SaD $$^{\varvec{2}}$$ FT module performs a two-dimensional deformable discrete Fourier transform (2D $$^{\varvec{3}}$$ FT) filter, enabling low-parameter feature extraction by transforming spatial features into frequency domain representations. Moreover, the spatial deformable operation enhances the capacity of the network to perceive spatial structural variations by introducing learnable offsets. Experimental results on four public HSI datasets demonstrate that DF $$^{\varvec{2}}$$ Net consistently achieves superior performance in lightweight classification. Compared to other state-of-the-art models, DF $$^{\varvec{2}}$$ Net significantly reduces both the number of parameters and computational resource requirements while preserving high performance.},
  archive      = {J_APIN},
  author       = {Zhong, Chengcheng and Zhang, Kai and Zhang, Zitong and Jiang, Yanan and Zhang, Chunlei},
  doi          = {10.1007/s10489-025-06493-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {DF $$^2$$ net: Deformable fourier filter network for hyperspectral image classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward imperceptible and robust image watermarking against screen-shooting with dense blocks and CBAM. <em>APIN</em>, <em>55</em>(7), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06496-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cross-media information communication, it is essential to embed watermarks imperceptibly while also robustly resisting screen- shooting attacks. However, existing robust watermarking methods often struggle to achieve both objectives simultaneously. Therefore, this paper proposes a novel end-to-end screen-shooting resistant image watermarking method based on dense blocks and the convolutional block attention module (CBAM) attention mechanism. In the watermark embedding phase, an encoder that integrates dense connections and CBAM is employed. This approach effectively extracts features from the cover image, enhancing the visual quality of watermarked images while ensuring a certain level of robustness. The noise layer simulated by differentiable function not only contains moiré patterns, illumination, and perspective distortions—factors that significantly impact the screen-shooting process—but also encompasses Gaussian noise, which is commonly present. During the watermark extraction phase, a gradient mask is utilized to guide the encoder in generating watermarked images that facilitate more effective decoding, thereby enabling accurate extraction of the watermark. Ultimately, the robustness is improved by the encoder, the introduced noise layer, and the decoder through joint training. Experimental results demonstrate that the proposed method not only achieves excellent visual quality, with a PSNR value of 36.04 dB for the watermarked images, but also maintains a watermark extraction rate exceeding 95% under various shooting conditions (including different distances, angles, and devices). Notably, the extraction rate reaches 100% at shooting distances of 20 cm and 30 cm, showcasing strong robustness.},
  archive      = {J_APIN},
  author       = {Wang, Jiamin and Kang, Xiaobing and Li, Wei and Geng, Jing and Miao, Yalin and Chen, Yajun},
  doi          = {10.1007/s10489-025-06496-0},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Toward imperceptible and robust image watermarking against screen-shooting with dense blocks and CBAM},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TRSD: Tensor spatial reconstruction and spectral metric decision fusion for hyperspectral anomaly detection with noise. <em>APIN</em>, <em>55</em>(7), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06504-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unique and detailed spectral information in hyperspectral images (HSI) provides an advantage for distinguishing different targets in anomaly detection (AD). However, most traditional HSI-AD methods primarily focus on the inherent spectral structure information, often overlooking the strong spatial-spectral synergy present in HSI. An increase in spectral resolution typically leads to a decrease in the number of photons received per channel, which increases the likelihood of correlated noise during image formation. To address these issues and significantly improve detection performance, a method called Tensor Space Reconstruction and Spectral Local Correlation Metric Decision Fusion (TRSD) is proposed for HSI-AD in the presence of noise. First, three-dimensional principal component (PC) extraction, based on information entropy, is performed to obtain a denoised purified image for reconstruction. The initial feature detection image is generated by calculating the purified image using the local Mahalanobis distance. To compensate for the loss of spectral information caused by PC analysis in the spectral dimension during Tucker reconstruction, the feature map is extracted using the local spectral correlation metric. Finally, the two detection feature images are adaptively fused to generate the final AD image, which highlights anomaly targets and improves detection accuracy.The proposed algorithm is experimentally validated through comparisons with current typical AD algorithms, using real HSIs captured in four different complex noise-added scenarios. The effectiveness of the algorithm is demonstrated through experiments. The source code for TRSD will be made publicly available at https://github.com/muzhenhuam/TRSD .},
  archive      = {J_APIN},
  author       = {Mu, Zhenhua and Wang, Yihan and Wang, Xianghai},
  doi          = {10.1007/s10489-025-06504-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {TRSD: Tensor spatial reconstruction and spectral metric decision fusion for hyperspectral anomaly detection with noise},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal transport-based fusion of two-stream convolutional networks for action recognition. <em>APIN</em>, <em>55</em>(7), 1-12. (<a href='https://doi.org/10.1007/s10489-025-06518-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding human actions in a given video requires spatial and temporal cues for human action recognition. Several deep learning approaches have been explored to extract effective spatio-temporal features. Specifically, two-stream networks have shown prominent performance due to the efficient capturing of motion information by optical flow estimation methods. Here, spatial and temporal paths with RGB & optical flow inputs, respectively, are trained independently and fused at the softmax layer for the classification of actions. However, the conventional two-stream networks exhibit sub-optimal performance mainly due to two reasons: (i) lack of interaction among the streams and (ii) disregard of diverse distributions of RGB & optical flow while fusion. To overcome these limitations, we propose an optimal transport-based fusion of the two-stream networks for action recognition in order to facilitate the alignment of distributions of two streams. First, feature maps from the last layers of CNN are extracted to preserve the pixel-level correspondence between the streams. Next, we calculate the optimal transportation matrix between the feature maps of spatial and temporal streams to map the features from one distribution to the other. Finally, the transformed features are fused to classify the actions. The effectiveness of the proposed approach is demonstrated on widely used action recognition datasets, namely, UCF-101, HMDB-51, SSV2,and Kinetics-400.},
  archive      = {J_APIN},
  author       = {Yenduri, Sravani and Gudavalli, Madhavi and C, Gayathri},
  doi          = {10.1007/s10489-025-06518-x},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {Optimal transport-based fusion of two-stream convolutional networks for action recognition},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient seizure detection by lightweight informer combined with fusion of time–frequency–spatial features. <em>APIN</em>, <em>55</em>(7), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06521-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic seizure detection based on electroencephalogram (EEG) signals is essential for monitoring and diagnosing epilepsy, as well as reducing the workload of neurologists who visually inspect long-term EEGs. In this work, a novel framework for automatic seizure detection is proposed by integrating the Stockwell transform (S-transform) with a lightweight Informer model. The S-transform is firstly used to convert EEG signals into multi-level time–frequency features. Subsequently, an Informer encoder is deployed to capture spatial and long-term dependencies of these EEG time–frequency features and perform classification for seizure detection. Both the segment-based evaluation and event-based evaluation were conducted on the CHB-MIT EEG database and the QH-SDU database in patient-specific scenarios. Due to the efficient multi-resolution time–frequency analysis capability of the S-transform and the Informer’s ability to measure spatio-temporal correlation with lower time complexity and memory usage, the proposed method achieved state-of-the-art outcomes over the two EEG databases. The experimental results substantiate the model's ability to generalize across different databases and potential for clinical application.},
  archive      = {J_APIN},
  author       = {Zhong, Xiangwen and Jia, Guijuan and Cui, Haozhou and Li, Haotian and Li, Chuanyu and Liu, Guoyang and Li, Yi and Zhou, Weidong},
  doi          = {10.1007/s10489-025-06521-2},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Efficient seizure detection by lightweight informer combined with fusion of time–frequency–spatial features},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PSCNet: Long sequence time-series forecasting for photovoltaic power via period selection and cross-variable attention. <em>APIN</em>, <em>55</em>(7), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06526-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous expansion of photovoltaic installation capacity, accurate prediction of photovoltaic power generation is crucial for balancing electricity supply and demand, optimizing energy storage systems, and improving energy efficiency. With the help of deep learning technologies, the stability and reliability of the photovoltaic power generation prediction have been significantly improved. However, existing methods primarily focus on temporal dependencies and often fall short in capturing the multivariate correlations between variables. In this paper, we propose a novel long-sequence time-series forecasting network for photovoltaic power via period selection and Cross-variable attention, named PSCNet. Specifically, we first propose the Top-K periodicity selection module (TPSM) to identify the Top-K principal periods for decoupling overlapped multi-periodic patterns, enabling the model to attend to periodic changes across different scales simultaneously. Then, we design a time-variate cascade perceptron to capture both temporal change patterns and variate change patterns in the time series. It contains two elaborate modules named Time-mixing MLP (TM-MLP) and Cross-variable Attention Module (CvAM). The former module aims to capture long-short term variations in time series while the latter one integrates the effective information from different auxiliary variates that have an impact on photovoltaic power forecasting to enhance the feature representation for better power prediction. Extensive experiments on the DKASC, Alice Springs dataset demonstrate that our model can outperform existing state-of-the-art photovoltaic power forecasting methods in terms of three common-used metrics including Mean Average Error (MAE), Mean Squared Error (MSE), and Mean Absolute Percentage Error (MAPE).},
  archive      = {J_APIN},
  author       = {Tan, Hao and Qin, Jinghui and Li, Zizheng and Wu, Weiyan},
  doi          = {10.1007/s10489-025-06526-x},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {PSCNet: Long sequence time-series forecasting for photovoltaic power via period selection and cross-variable attention},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance-based active learning (PbAL) for imbalanced data with nonparametric logistic regression. <em>APIN</em>, <em>55</em>(7), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06531-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world data often exhibit asymmetric class distributions, where certain target values have significantly fewer observations compared to the others. This lack of uniform distribution across categories can substantially affect model performance in classification problems. This research introduces the performance-based active learning (PbAL) scheme to address the class imbalance problem considering the nonlinear decision boundary. PbAL is designed to sequentially select the most beneficial samples from an imbalanced data set by directly evaluating a performance metric on a pool of data. While parametric logistic regression offers a fundamental classification model with ease of interpretation, the assumption of linear relationship in the logit function is often questionable. The use of nonparametric logistic regression with smoothing splines allows for a more flexible classification boundary. Experiments with several data sets demonstrate that PbAL often outperforms traditional active learning approaches based on D-optimality and A-optimality. Additionally, the proposed method yields superior results compared to other resampling techniques commonly used for imbalanced classification problems even with a smaller sample size. These findings suggest that PbAL effectively mitigates bias caused by training on imbalanced classes, which can severely impact model’s ability to accurately predict class labels for new observations.},
  archive      = {J_APIN},
  author       = {Lee, Wonjae and Seo, Kangwon},
  doi          = {10.1007/s10489-025-06531-0},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Performance-based active learning (PbAL) for imbalanced data with nonparametric logistic regression},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent fault diagnosis method based on data generation and long-patch vision transformer under small samples. <em>APIN</em>, <em>55</em>(7), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06535-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rotating machinery is an important part of modern industry, and bearings are one of the most important things. However, bearing fault data are difficult to collect, and bearing fault diagnosis under small samples has significant research potential. In this paper, we proposed a fault diagnosis framework that combines diffusion modeling and improved Vision Transformer. First, the short-time Fourier transform is applied to the original one-dimensional vibration signals to convert the data into time-frequency maps. Second, the conditional diffusion model was applied to generate the required samples and expand the dataset. Finally, the Long-patch Vision Transformer (LVT) proposed in this paper is used to classify the mixed samples. LVT designs a long-patch division method for time-frequency maps with dense transverse features. The LVT contains denser features in each patch, and this method is more suitable for time-frequency maps. Validating the method proposed in this paper on two datasets and comparing it with other methods, our method achieved the highest accuracy among the compared methods.},
  archive      = {J_APIN},
  author       = {Cen, Jian and Si, Weiwei and Liu, Xi and Zhao, Bichuang and Huang, Hankun and Liu, Junfu},
  doi          = {10.1007/s10489-025-06535-w},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Intelligent fault diagnosis method based on data generation and long-patch vision transformer under small samples},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trajectory optimization of train cooperative energy-saving operation using a safe deep reinforcement learning approach. <em>APIN</em>, <em>55</em>(7), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06542-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy-efficient optimization of train speed profiles can effectively reduce the traction energy consumption of urban rail transit systems. Existing reinforcement learning (RL) optimization models for optimizing train operation profiles do not proactively handle the utilization constraints of regenerative braking energy (RBE). For this reason, this paper proposes an optimization model of train energy-saving profiles under multi-train cooperative operations. A novel safe deep reinforcement learning algorithm, guided by heuristic rules, is developed to optimize energy-saving train driving strategies in various scenarios. To ensure safety during the agent’s learning processes, a two-layer protection mechanism with soft constraint and truncation penalties is employed. Dynamic energy constraints are also introduced to enable the RBE utilization between trains. The simulation experiments using a real metro line data show that the proposed model and algorithm not only generate safe and energy-efficient profiles that meet metro operational constraints but also maximize the RBE utilization between trains, significantly reducing traction energy consumption.},
  archive      = {J_APIN},
  author       = {Niu, Wenguang and Zhou, Yonghua and Jiao, Xiangmeng and Fujita, Hamido and Aljuaid, Hanan},
  doi          = {10.1007/s10489-025-06542-x},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Trajectory optimization of train cooperative energy-saving operation using a safe deep reinforcement learning approach},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diagnosis test selection for distributed systems under communication and privacy constraints. <em>APIN</em>, <em>55</em>(7), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06543-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distribution is often necessary for large-scale systems because it makes monitoring and diagnosis more manageable from both computational and communication costs perspectives. Decomposing the system into subsystems may also be required to satisfy geographic, functional, or privacy constraints. The selection of diagnosis tests guaranteeing some level of diagnosability must adhere to this decomposition by remaining as local as possible in terms of the required sensor variables. This helps minimize communication costs. In practical terms, this means that the number of interconnections between subsystems should be minimized while keeping diagnosability, i.e., fault isolation capability, at its maximum. This paper differentiates itself from existing literature by leveraging flexibility in forming the subsystems. Through structural analysis and graph partitioning, we address the combined challenges of constrained decomposition of a large-scale system into subsystems and the selection of diagnosis tests that achieve maximal diagnosability with minimal subsystem interconnection. The proposed solution is implemented through an iterative algorithm, which is proven to converge. Its efficiency is demonstrated using a case study in the domain of water networks.},
  archive      = {J_APIN},
  author       = {Sztyber-Betley, Anna and Chanthery, Elodie and Travé-Massuyès, Louise and Pérez-Zuñiga, Gustavo},
  doi          = {10.1007/s10489-025-06543-w},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Diagnosis test selection for distributed systems under communication and privacy constraints},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal subgraph contrastive learning for anomaly detection on dynamic attributed graphs. <em>APIN</em>, <em>55</em>(7), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06402-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A dynamic attributed graph exists in which features and structures evolve. Some researchers have focused on the study of anomaly detection methods under such complex evolution patterns. However, they cannot address the discrepancy problem of coupled evolution of multitemporal features, i.e., how to portray and capture the anomaly patterns under coupled evolution is a key problem that needs to be solved. Therefore, in this paper, we propose the Temporal Subgraph Contrastive Learning (TSCL) method for anomaly detection on dynamic attributed graphs, which learns node representations by sampling and comparing temporal subgraphs and uses the statistical results of multiround comparison scores to predict node anomalies. In particular, the Temporal Features Evolving module and the Temporal Subgraph Sampling module capture the coupled evolutionary patterns of features and structures, and the combination of the Temporal Contrastive Learning module and the Statistical Anomaly Estimator module implements an end-to-end working approach between representation learning and anomaly detection. Finally, extensive comparative experiments and analyses on real datasets demonstrate the effectiveness of our proposed TSCL approach for anomaly detection on dynamic attributed graphs.},
  archive      = {J_APIN},
  author       = {Yu, Yang and Li, Xin and Shao, Minglai and Sun, Ying and Wang, Wenjun},
  doi          = {10.1007/s10489-025-06402-8},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Temporal subgraph contrastive learning for anomaly detection on dynamic attributed graphs},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Novel ensemble bagging-logistic regression algorithm for NoSQL database security. <em>APIN</em>, <em>55</em>(7), 1. (<a href='https://doi.org/10.1007/s10489-025-06456-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Kanade, Anuradha and Vibhute, Amol D. and Kanade, Shantanu},
  doi          = {10.1007/s10489-025-06456-8},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Correction to: Novel ensemble bagging-logistic regression algorithm for NoSQL database security},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Radial-based oversampling based on differential evolution for imbalanced data. <em>APIN</em>, <em>55</em>(7), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06460-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data imbalance remains a significant obstacle in many real-world applications. Although the Synthetic Minority Over-sampling Technique (SMOTE) and its variants are widely used to mitigate this issue, they often suffer from noise sensitivity, over-constraint, and over-generalization. In this paper, we introduce Radial-Based Oversampling based on Differential Evolution (DERBO), a novel algorithm that combines the global search strength of differential evolution (DE) with a radial basis function (RBF)-guided fitness strategy. By generating synthetic samples that are both diverse and closely aligned with the original minority distribution, DERBO effectively overcomes the limitations of existing methods. Extensive comparisons across 32 datasets against nine state-of-the-art imbalanced learning techniques demonstrate DERBO’s consistently superior performance, establishing it as a highly competitive and robust solution for addressing data imbalance.},
  archive      = {J_APIN},
  author       = {Chen, Jun and Xia, Meng and Wang, Zhijie},
  doi          = {10.1007/s10489-025-06460-y},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Radial-based oversampling based on differential evolution for imbalanced data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emp-EEK: Generating empathetic responses via exemplars and external knowledge. <em>APIN</em>, <em>55</em>(7), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06464-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Empathy plays a crucial role in human communication, and empathetic dialogue systems have garnered increasing research interest. However, accurately modeling and quantifying empathy remains challenging due to its inherently complex and multifaceted nature. Exemplar-based guidance has shown promise in enhancing empathetic response generation, yet existing approaches suffer from limitations such as noisy or irrelevant exemplars. To address these challenges, we propose Emp-EEK, an Empathetic response generation model guided by Exemplars and External Knowledge. Specifically, we employ a fine-tuned Dense Passage Retriever to jointly retrieve relevant exemplars based on both utterance-exemplar similarity and contextual proximity, ensuring more precise guidance for response generation. Furthermore, to enhance the system’s understanding of the speaker, we integrate external knowledge into the dialogue history, enriching contextual comprehension. To further elevate the level of empathy in responses, we introduce a multi-expert system that incorporates three independent decoders at the decoding stage. This design enables the model to effectively learn and capture the three key psychological mechanisms of empathetic communication: emotional reaction, interpretation, and exploration. Experimental results on the Empathetic-Dialogues dataset, evaluated through both automatic metrics and human judgments, demonstrate the effectiveness of our approach. Additionally, case studies analyzing the decoding process of different decoders highlight the strong interpretability of our model. Our code is publicly available at https://github.com/NEUWzk/Emp-EEK .},
  archive      = {J_APIN},
  author       = {Wang, Zikun and Li, Jing and Lai, Jinshui and Han, Donghong and Qiao, Baiyou and Wu, Gang},
  doi          = {10.1007/s10489-025-06464-8},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Emp-EEK: Generating empathetic responses via exemplars and external knowledge},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MKDFusion: Modality knowledge decoupled for infrared and visible image fusion. <em>APIN</em>, <em>55</em>(7), 1-25. (<a href='https://doi.org/10.1007/s10489-025-06470-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of infrared and visible fusion is to integrate useful information from both infrared and visible images into a single image. The fused image should possess rich texture details and salient target information of the two images. Current image fusion algorithms primarily face two limitations: 1) The lack of decoupling between modality-agnostic and modality-specific knowledge during the feature extraction stage hinders the alignment of modality-agnostic knowledge and the differentiation of modality-specific knowledge. 2) The interaction between modality features is not sufficiently explored in the feature fusion stage, which inhibits the exploitation of complementary information. To address the above challenges, we propose a Modality Knowledge Decoupled (MKD) module in the feature extraction stage and a Cross-Modality Mamba Fusion (CMF) module in the feature fusion stage. In MKD, we first utilize a dual-branch network to extract modality-agnostic and modality-specific knowledge separately. Then, a pair of Knowledge Discriminators (KD) is constructed to minimize inter-modality irrelevant knowledge and maximize inter-modality relevant knowledge. In CMF, the interactions between different modality knowledge are learnt in a hidden state space, which not only reduces the inter-modality knowledge differences but also enhances the texture information of the image. Experiments on three datasets demonstrate that our method outperforms existing methods, highlighting less salient targets and texture information more effectively. In addition, MKDFusion has demonstrated excellent generalization performance and enormous potential in high-level vision tasks in medical image fusion and object detection applications. The code is available at https://github.com/SEU-ZYC/MKDFusion .},
  archive      = {J_APIN},
  author       = {Zhang, Yucheng and Ma, You and Chai, Lin},
  doi          = {10.1007/s10489-025-06470-w},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {MKDFusion: Modality knowledge decoupled for infrared and visible image fusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFF-HGNN: Dual-feature fusion heterogeneous graph neural network. <em>APIN</em>, <em>55</em>(7), 1-26. (<a href='https://doi.org/10.1007/s10489-025-06480-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous graph neural networks (HGNNs) have gained significant attention in deep learning due to their superior capability in processing heterogeneous graph data. However, existing HGNNs often fail to explicitly leverage relational information among nodes when utilizing the attribute information of nodes for graph representation learning, thus constraining their performance. To address this limitation, we introduce two approaches for utilizing relational information explicitly: a Relation-based Feature Enhancement Strategy (RFE-Strategy) for non-attributed heterogeneous graphs, and a Dual-Feature Fusion Heterogeneous Graph Neural Network (DFF-HGNN) for attributed heterogeneous graphs. The RFE-Strategy enhances HGNNs performance on non-attributed heterogeneous graphs through a three-step process: relational feature extraction, identity feature encoding, and feature enhancement. Meanwhile, DFF-HGNN integrates both attribute and relational features to effectively capture the heterogeneity and complexity of the graph, employing four components: separate pre-transformation, intra-type feature encoder, inter-type feature encoder, and embedding update encoder. Extensive experiments on multiple benchmark datasets demonstrate that the RFE-Strategy significantly improves the performance of HGNNs, while DFF-HGNN outperforms the state-of-the-art models.},
  archive      = {J_APIN},
  author       = {Xue, Shengen and Duan, Hua and Zhao, Yufei and Fan, Wei},
  doi          = {10.1007/s10489-025-06480-8},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {DFF-HGNN: Dual-feature fusion heterogeneous graph neural network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Out-of-distribution detection using normalizing flows on the data manifold. <em>APIN</em>, <em>55</em>(7), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06499-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using the intuition that out-of-distribution data have lower likelihoods, a common approach for out-of-distribution detection involves estimating the underlying data distribution. Normalizing flows are likelihood-based generative models providing a tractable density estimation via dimension-preserving invertible transformations. Conventional normalizing flows are prone to fail in out-of-distribution detection, because of the well-known curse of dimensionality problem of the likelihood-based models. To solve the problem of likelihood-based models, some works try to modify likelihood for example by incorporating a data complexity measure. We observed that these modifications are still insufficient. According to the manifold hypothesis, real-world data often lie on a low-dimensional manifold. Therefore, we proceed by estimating the density on a low-dimensional manifold and calculating a distance from the manifold as a measure for out-of-distribution detection. We propose a powerful criterion that combines this measure with the modified likelihood measure based on data complexity. Extensive experimental results show that incorporating manifold learning while accounting for the estimation of data complexity improves the out-of-distribution detection ability of normalizing flows. This improvement is achieved without modifying the model structure or using auxiliary out-of-distribution data during training.},
  archive      = {J_APIN},
  author       = {Razavi, Seyedeh Fatemeh and Mehmanchi, Mohammadmahdi and Hosseini, Reshad and Tavassolipour, Mostafa},
  doi          = {10.1007/s10489-025-06499-x},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Out-of-distribution detection using normalizing flows on the data manifold},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot segmentation combined with domain adaptation: A flexible paradigm for parsing astronaut work environments. <em>APIN</em>, <em>55</em>(7), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06508-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capacity to perform few-shot segmentation of the astronaut work environment (AWE) is of critical importance, especially for tasks that cannot be predetermined. The challenging task of transferring FSS models, which are trained on natural datasets, to the AWE—referred to as cross-domain few-shot segmentation (CD-FSS)—holds substantial importance. Rather than devising an entirely novel model, we propose an approach that integrate domain adaptation (DA) with extant FSS models, herein termed meta learners. Specifically, a prior learner based on generative adversarial networks (GAN) is devised to impart semantic guidance to the meta learner. To discern challenging samples, a loss function incorporating a scaling factor is employed during the training stage of the prior learner. Furthermore, a metric-based fusion module is proposed to mitigate bias in accordance with the association between the prior learner and the meta learner. The results evince that our method can be seamlessly integrated with different types of existing FSS models, thereby enhancing their cross-domain performance.},
  archive      = {J_APIN},
  author       = {Sun, Qingwei and Chao, Jiangang and Lin, Wanhong and Chen, Wei and Xu, Zhenying and Yang, Jin},
  doi          = {10.1007/s10489-025-06508-z},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Few-shot segmentation combined with domain adaptation: A flexible paradigm for parsing astronaut work environments},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dueling double deep Q-network-based stamping resources intelligent scheduling for automobile manufacturing in cloud manufacturing environment. <em>APIN</em>, <em>55</em>(7), 1-27. (<a href='https://doi.org/10.1007/s10489-025-06524-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of intelligent manufacturing, the automobile manufacturing industry has entered the"AI +"era, and the cloud manufacturing paradigm for the application of the automobile manufacturing industry is also in progress. As a key of automobile manufacturing, the stamping resources scheduling for automobile manufacturing (SRSAM) in the cloud manufacturing (CMfg) is characterized by unique domain-specific attributes concerning task architecture, the particularities of resource allocation, and the agility in transitioning between service types, which impedes the effective transference of classical manufacturing resource scheduling methodologies. Concurrently, the prevalent approaches to stamping scheduling concentrate predominantly on resources within the confines of stamping workshops and production lines, which are limited in scope. Such approaches are ill-suited for coping with the volatile and extensive resource landscape inherent to cloud manufacturing environments. To handle the above issues, this paper proposes to solve the SRSAM problem in CMfg with a novel scheduling model and intelligent scheduling method based on Dueling Double Deep Q-network (DDDQN). Firstly, we propose a stamping resource multi-objective scheduling model within the in-depth analysis of the SRSAM problem in CMfg and introduce a novel task structure to articulate the dependencies within the stamping tasks. Secondly, addressing the static and dynamic scheduling requirements, we construct a scheduling framework based on deep reinforcement learning, propose the strategy combination based on 5 resource selections and 12 task selections to generate Agent's actions. Finally, integrating the proposed scheduling framework and model, the DDDQN algorithm is designed to solve the optimal scheduling scheme. Experimental results indicate that the proposed method consistently matches or exceeds other DRL algorithms, including proximal policy optimization (PPO), Q-learning, Deep Q-network (DQN), Double DQN (DDQN), and Dueling DQN in terms of scheduling performance and model training.},
  archive      = {J_APIN},
  author       = {Hu, Yanjuan and Pan, Leiting and Wen, Zhongxian and Zhou, You},
  doi          = {10.1007/s10489-025-06524-z},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-27},
  shortjournal = {Appl. Intell.},
  title        = {Dueling double deep Q-network-based stamping resources intelligent scheduling for automobile manufacturing in cloud manufacturing environment},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rapid deployment of digital twin for life prediction of rolling bearings. <em>APIN</em>, <em>55</em>(7), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06536-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finite element modeling (FEM) is widely recognized as a relatively accurate approach for constructing digital twin (DT) models for predicting remaining useful life (RUL). However, FEM suffers from long computation times, high operational complexity, and an inability to meet the real-time requirements of DT. This study proposes a k-nearest neighbor Kriging Radial basis function Digital Twin (KKR-DT) system. Initially, the full working condition results of the roller bearing were calculated using Ansys software. Subsequently, a reduced-order (OR) model was developed following the agent model approach. KNN was used to find neighboring values near the OR points, and Kriging was employed to interpolate at the OR points, obtaining an OR model with a single working condition. Finally, using RBFs all single-working condition OR models were transformed into full-working condition OR models, thereby establishing a five-dimensional DT model and DT user interface. The stress-life (S–N) degradation curve of the material was used to predict the roller bearing RUL. The proposed stress field diagram addressed the challenge of reverse validation in interpolation models. Ultimately integrated as the KKR-DT system. Compared the full working condition average accuracy of KKR-DT was 96.6938%, with maximum and minimum average accuracies of 99.9993% and 99.9978%, respectively. Real-time dynamic operation calculation time for a single instance was achieved within 0.35 s. Remote DT testing was conducted using actual spinning frame equipment, to demonstrate the accuracy and real-time DT capabilities of the system, a solution is provided for the practical application of digital twins in dynamic operation and prediction.},
  archive      = {J_APIN},
  author       = {Wang, Jun and Xiao, Lei and Liu, Ximing},
  doi          = {10.1007/s10489-025-06536-9},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Rapid deployment of digital twin for life prediction of rolling bearings},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An attributed network features learning method for over-indebtedness prediction. <em>APIN</em>, <em>55</em>(7), 1-29. (<a href='https://doi.org/10.1007/s10489-025-06538-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over-indebtedness represents a financial anomaly and is widely regarded as an early indicator of financial distress. The recent advancements in machine learning techniques have enabled more accurate prediction of over-indebtedness. While existing forecasting models have contributed to mitigating the negative impacts of over-indebtedness, they typically fail to account for the influence of external factors on corporate debt decisions, which consequently limits their predictive accuracy. In response, this paper introduces a novel prediction model for over-indebtedness based on an attributed network feature learning approach for early warning. Building on previous research, the proposed model incorporates external information, such as interlocking directorate networks and product competition networks, as additional data sources for feature construction. By leveraging descriptive analytics and deep attributed network embedding methods, the model captures both individual and external features from social network data. To optimize the model’s performance, a generative classifier—specifically, the locally-weighted Expectation Maximization method for Naïve Bayes learning—is employed to handle the network-based features. The experimental results demonstrate that the proposed model performs effectively and offers valuable insights for integrating external information into financial prediction models.},
  archive      = {J_APIN},
  author       = {Chen, Fengzhang and Long, Zewei and Wang, Wei and Qi, Kai},
  doi          = {10.1007/s10489-025-06538-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-29},
  shortjournal = {Appl. Intell.},
  title        = {An attributed network features learning method for over-indebtedness prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast approach based on divide-and-conquer for instance selection in classification problem. <em>APIN</em>, <em>55</em>(7), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06541-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance selection is a data preprocessing method in data mining that aims to reduce the volume of the training dataset. Reducing samples from a large dataset offers benefits such as lower storage requirements, reduced computational costs, increased processing speed, and, in some cases, improved accuracy for learning algorithms. However, reducing samples from large datasets is also a challenging task due to their sheer volume. Recently, numerous instance selection methods for big data have been proposed, often facing challenges such as low accuracy and slow processing speed. In this research, we propose a fast and efficient three-step method based on the divide-and-conquer approach. In the first step, the training set is divided based on the number of classes. Next, representative summaries of each class are extracted. Finally, samples from each class are reduced independently while considering the representatives of other classes. By using a proposed ranking-based method, it is possible to accurately identify less important and noisy samples. For a comprehensive evaluation, we utilized 20 well-known large datasets and three synthetic datasets featuring challenging structures. The results demonstrate the superiority of the proposed method over four recent related methods.},
  archive      = {J_APIN},
  author       = {Saadatfar, Hamid and Nawin, Sayed Iqbal and Hosseini Gol, Edris},
  doi          = {10.1007/s10489-025-06541-y},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {A fast approach based on divide-and-conquer for instance selection in classification problem},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multilevel attention network with sub-instructions for continuous vision-and-language navigation. <em>APIN</em>, <em>55</em>(7), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06544-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of vision-and-language navigation (VLN) is to develop agents that navigate mapless environments via linguistic and visual observations. Continuous VLN, which more accurately mirrors real-world conditions than its discrete counterpart does, faces unique challenges such as real-time execution, complex instruction understanding, and long sequence prediction. In this work, we introduce a multilevel instruction understanding mechanism and propose a multilevel attention network (MLANet) to address these challenges. Initially, we develop a nonlearning-based fast sub-instruction algorithm (FSA) to swiftly generate sub-instructions without the need for annotations, achieving a speed enhancement of 28 times over the previous methods. Subsequently, our multilevel attention (MLA) module dynamically integrates visual features with both high- and low-level linguistic semantics, forming multilevel global semantics to bolster the complex instruction understanding capabilities of the model. Finally, we introduce the peak attention loss (PAL), which enables the flexible and adaptive selection of the current sub-instruction, thereby improving accuracy and stability achieved for long trajectories by focusing on the relevant local semantics. Our experimental findings demonstrate that MLANet significantly outperforms the baselines and is applicable to real-world robots.},
  archive      = {J_APIN},
  author       = {He, Zongtao and Wang, Liuyi and Li, Shu and Yan, Qingqing and Liu, Chengju and Chen, Qijun},
  doi          = {10.1007/s10489-025-06544-9},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {A multilevel attention network with sub-instructions for continuous vision-and-language navigation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Measurement of adulteration in liquids by optical interferograms analysis and deep learning. <em>APIN</em>, <em>55</em>(7), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06550-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We demonstrate the use of a proposed deep learning model to detect six different degrees of adulteration in alcoholic beverages by classifying interferograms captured through a dual aperture common-path interferometer (DACPI). The proposed two-arm convolutional neural network (TA-CNN) classifier is based on the extraction of linear and non-linear local features by principal components analysis (PCA) and t-distributed stochastic neighbor embedding (t-SNE), respectively. Then, the features of the reduced vectors are extracted individually with convolutional layers for the classification of three balanced sets of interferograms, with different initial calibration and external perturbation characteristics. In addition, an empirical study of the extracted vectors demonstrates the viability of our interferograms as candidates to be classified by the TA-CNN. The performance of the TA-CNN is compared with modern deep learning models adapted by transfer learning for this specific application. The results show a high average accuracy for all the deep models tested, both for separate and combined sets of 96% and 96.5%, respectively. The proposed TA-CNN is the best performance model, reaching an accuracy of 99.15% for the combined sets. Furthermore, an analysis based on the fast Fourier transform (FFT) corroborates the fact that the relevant information for the classification of interferograms lies in their phase. This approach represents a novel method in optical instrumentation without the use of traditional phase measurement interferometry, the need for highly optimized optical calibration, high-precision optical components, and the obtaining of interferograms datasets with the same DACPI setting up.},
  archive      = {J_APIN},
  author       = {Prieto-Cortés, P. and López-Meléndez, E. and Álvarez-Tamayo, R. I. and Barcelata-Pinzón, A. and Lara-Rodriguez, L.D.},
  doi          = {10.1007/s10489-025-06550-x},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Measurement of adulteration in liquids by optical interferograms analysis and deep learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning solutions for audio event detection in a swine barn using environmental audio and weak labels. <em>APIN</em>, <em>55</em>(7), 1-12. (<a href='https://doi.org/10.1007/s10489-025-06555-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for animal protein products has led to the emergence of Precision Livestock Farming (PLF) and the adoption of sensing technologies, big data solutions, and Machine Learning (ML) methods in modern livestock farming. At the same time, the audio signal processing field has undergone notable advancements in recent years, transitioning from traditional techniques to more sophisticated ML approaches, with open challenges in detecting and classifying complex, low-quality, and overlapping sounds in real-world scenarios. In this paper, we evaluate deep learning methods, conceived from computer vision to attention-based approaches, for Audio Event Detection (AED) on a novel audio dataset from a swine farming environment with challenging characteristics, such as weak annotations and high amounts of noise. The primary purpose of our study is to prospect effective AED solutions for the development of tools for auditing livestock farms, which could be used to improve animal welfare. Our results show that, despite inherent limitations in the dataset’s size, class imbalance, and sound quality, Convolutional Neural Network (CNN) and attention-based architectures are respectively effective and promising for detecting complex audio events. Further research may explore avenues for optimizing model performance in similar, real-life datasets while simultaneously amplifying annotated events and reducing annotation costs, thereby enhancing the broader applicability of AED methods in diverse audio processing scenarios.},
  archive      = {J_APIN},
  author       = {Souza, André Moreira and Kobayashi, Livia Lissa and Tassoni, Lucas Andrietta and Garbossa, Cesar Augusto Pospissil and Ventura, Ricardo Vieira and Machado de Sousa, Elaine Parros},
  doi          = {10.1007/s10489-025-06555-6},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {Deep learning solutions for audio event detection in a swine barn using environmental audio and weak labels},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-stage knowledge graph completion based on LLMs’ data augmentation and atrous spatial pyramid pooling. <em>APIN</em>, <em>55</em>(7), 1-12. (<a href='https://doi.org/10.1007/s10489-025-06556-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of information technology, a large amount of unstructured and fragmented data is generated. Knowledge graphs can effectively integrate these fragmented data. Due to the difficulty of domain knowledge mining, knowledge graphs have problems of data sparseness and data missing. In addition, standard convolutional neural networks have limited capability in capturing feature interactions. To address data sparsity and the limitations of standard convolutional models, we propose DA-ARKGC, a two-stage knowledge graph completion model using wheat as a case study. In the first stage, to address the data sparsity problem, the rule mining data augmentation module (DA) based on large language models expands the wheat knowledge graph. In the second stage, the knowledge completion module (ARKGC) of the atrous spatial pyramid pooling with residual is introduced to achieve knowledge completion. The DA-ARKGC model was verified on the constructed wheat knowledge graph (Wheat_KG). Compared with ConvE, its MRR, Hits@1, Hits@3 and Hits@10 increased by 10% and 10.2%, 10.1% and 9.3%, respectively. In order to verify the effectiveness and generalization of the ARKGC module, experiments were conducted on the open-source datasets WN18 and FB15k. The results demonstrated that the model achieved optimal or sub-optimal performance compared with other baseline models.},
  archive      = {J_APIN},
  author       = {Zhou, Na and Yuan, Yuan and Chen, Lei},
  doi          = {10.1007/s10489-025-06556-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {A two-stage knowledge graph completion based on LLMs’ data augmentation and atrous spatial pyramid pooling},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MGMP: Multi-granularity semantic relation learning and meta-path structure interaction learning for fake news detection. <em>APIN</em>, <em>55</em>(7), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06560-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes the joint learning model Multi-Granularity Semantic Relation Learning and Meta-Path Structure Interaction Learning for fake news detection (MGMP). The MGMP improves global semantic relation learning through a multi-granularity process involving coarse-grained and fine-grained learning modules, along with meta-path based global interaction learning. It begins by refining global semantic recognition accuracy at the word-level and document-level through attention mechanisms and convolutional neural networks. Furthermore, it enhances global interaction learning by enhancing meta-path instance representations with various meta-paths and employing multi-head self-attention mechanisms within the network structure. Experimental findings on real datasets confirm the effectiveness of the MGMP in fake news detection by enhancing global semantic recognition accuracy in news nodes and recognizing network structural characteristics.},
  archive      = {J_APIN},
  author       = {Lee, Baozhen and Cao, Dandan and Zhang, Tingting},
  doi          = {10.1007/s10489-025-06560-9},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {MGMP: Multi-granularity semantic relation learning and meta-path structure interaction learning for fake news detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalization of neural network for manipulator inverse dynamics model learning. <em>APIN</em>, <em>55</em>(7), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06564-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inverse dynamics model of manipulators learned from recurrent neural networks demonstrates higher precision than those obtained through analytical modeling methods. Variations in end-effector loads and previously unseen trajectory points can lead to inaccurate torque estimations in dynamic models of manipulators. This paper integrates innovative feature expansion, feature enhancement, and regularization into an end-to-end inverse dynamics model learning framework. The proposed model employs a bidirectional long short-term memory (BiLSTM) network, augmented by a spatial attention mechanism with Convolutional Neural Networks (CNN) and a Max-Pooling method, which enhances the extraction of latent spatial features, and a multi-scale parallel temporal attention mechanism, which captures the dynamic changes of objects in the temporal dimension. A novel motion residual vector is designed to expand features, and a motion residual module is proposed to assist the network in perceiving changes in end-effector loads. To prevent overfitting, novel spatial attention standard deviation regularization are implemented. Experimental results across different trajectories and end-effector loads validate the generalization capability of the proposed method. The proposed method is compared with five methods, experimental results across different trajectories and end-effector loads validate the generalization capability of the proposed method. It surpasses state-of-the-art methods, achieving the highest overall accuracy. In cross-validation experiments, the validation loss remains stable as the training loss decreases, demonstrating the proposed approach’s strong generalization performance in dynamics model learning.},
  archive      = {J_APIN},
  author       = {Wenhui, Huang and Yunhan, Lin and Jie, Chen and Mingxin, Liu and Huasong, Min},
  doi          = {10.1007/s10489-025-06564-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Generalization of neural network for manipulator inverse dynamics model learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Context-dependent probabilistic linguistic multi-attribute decision-making methods. <em>APIN</em>, <em>55</em>(7), 1-18. (<a href='https://doi.org/10.1007/s10489-024-06059-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of decision-making, the accurate assessment and integration of multiple attributes, particularly in scenarios characterized by uncertainty and subjectivity, pose a substantial challenge. Traditional decision-making methods within the probabilistic linguistic framework typically treat these as a series of independent single-attribute evaluations, thereby neglecting the crucial contextual information present within the attribute space. This paper introduces a context-dependent multi-attribute decision-making method, specifically designed for environments characterized by uncertainty and linguistic ambiguity. Our primary aim is to establish a decision-making framework that not only recognizes but also effectively utilizes the interdependencies and contextual subtleties among various attributes. To facilitate easier quantification of uncertainty in practical data, we initially define the Gaussian probabilistic linguistic term set and its corresponding generation algorithm. We then establish matrices that elucidate the dominant and dominated relationships between options across different attribute sets. These matrices are then incorporated into prospect theory, providing a comprehensive approach to multi-attribute decision-making. The effectiveness of our proposed method is demonstrated through a case study focusing on investment decision-making for countries participating in the Belt and Road Initiative.},
  archive      = {J_APIN},
  author       = {Zhang, Yaojia and Hao, Zhinan and Gong, Zaiwu and Zhang, Ren},
  doi          = {10.1007/s10489-024-06059-9},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Context-dependent probabilistic linguistic multi-attribute decision-making methods},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Breaking barriers in hotspot mining: A novel approach to reflecting domain characteristics and correlations. <em>APIN</em>, <em>55</em>(7), 1-22. (<a href='https://doi.org/10.1007/s10489-024-06136-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hotspot mining is essential for acquiring information on hotspots and knowledge in a given domain, and it is also of great value for improving the efficiency and quality of scientific research work in the profession. Previous literature on hotspot mining did not take into account the domain characteristics of the literature and the diverse associations of the domain-specific literature itself. It is a challenging task to reflect the domain characteristics of the literature and use multiple correlations among the literature in the model. In this study, we depict each association link using a heterogeneous network of metallurgical literature and simultaneously fuse metallurgical domain-specific knowledge by aggregating the knowledge graph data of the neighbors into the term nodes of the heterogeneous network of the literature. A proposed heterogeneous academic network metallurgical literature hotspot mining method incorporates domain-specific knowledge. This method reflects various types of associational relation information in the literature via the heterogeneous network. In the meantime, it weights and analyzes the paths in the heterogeneous network, identifies the most critical paths for vectorized representation, and highlights the impact of essential paths and domain knowledge on representation learning, enhancing the information representation of diverse data in the model and improving its accuracy. The suggested model is compared with GCN, the MAGNN standard model, and its ablation model as applied to public and metallurgical literature datasets. The findings on the public dataset show that the proposed method is superior to the other two approaches. In contrast, the results for the metallurgical literature dataset are more conspicuous, with the proposed method exhibiting a more remarkable improvement in HR and NGCC.},
  archive      = {J_APIN},
  author       = {Chen, Wei and Yu, Zhengtao and Gao, Shengxiang and Xian, Yantuan},
  doi          = {10.1007/s10489-024-06136-z},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Breaking barriers in hotspot mining: A novel approach to reflecting domain characteristics and correlations},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-channel context-aware contrastive learning graph neural networks for session-based recommendation. <em>APIN</em>, <em>55</em>(7), 1-18. (<a href='https://doi.org/10.1007/s10489-024-06140-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation (SR) aims to predict the next most likely interaction item based on the current sequence of anonymous behaviors. How to learn short- and long-term user preferences is the key to SR research. However, current research ignores the impact of contextual information on users’ short- and long-term preferences when obtaining user preferences. Herein, we propose a Dual-Channel Context-aware Contrastive Learning Graph Neural Networks (DCC-GNN) model for SR. DCC-GNN constructs a time-aware session graph representation learning channel, modeling sessions with temporal context information to learn users’ short-term preferences. To better capture users’ long-term preferences, it also constructs a position correction global graph representation learning channel and uses global session information to learn users’ long-term preferences. To address the issue of data sparsity, contrastive learning techniques are employed to both channels for data augmentation. Finally, a linear combination of the dual-channel session representations serves as the user’s ultimate preference for accurate recommendations. Herein, we performed extensive experiments on three real-world datasets. Experimental results reveal that the performance of the proposed DCC-GNN model demonstrates a considerable improvement compared to baseline models.},
  archive      = {J_APIN},
  author       = {Cao, Jiawei and Fan, Yumin and Zhang, Tao and Liu, Jiahui and Yuan, Weihua and Zhang, Xuanfeng and Zhang, Zhijun},
  doi          = {10.1007/s10489-024-06140-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Dual-channel context-aware contrastive learning graph neural networks for session-based recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding and leveraging vocoder fingerprints for synthetic speech attribution. <em>APIN</em>, <em>55</em>(7), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06272-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancements in generative adversarial networks (GANs), neural vocoders have emerged as critical components for synthesizing intelligible speech. The rise of fake audio poses significant challenges and risks to national security due to malicious abuse. Although countermeasures have been proposed to detect deepfakes, attributing audio to specific vocoder architectures remains a challenging task. Existing approaches that directly input handcrafted features into sophisticated deep neural networks (DNNs) tend to neglect the misguidance of content-relevant features, which leads to poor generalization and efficacy. In this paper, we propose a novel framework that focuses on disentangling the vocoder fingerprint from audio to identify fake audio. To this end, we introduce an audio reconstructor based on the U-Net architecture that minimizes the preservation of the content-relevant features of the original audio. The residual between the raw and reconstructed latent vectors is then calculated to eliminate content-relevant features. The residual is finally fed into a classifier to determine the vocoder’s architecture. The extensive experiments demonstrate the effectiveness of our proposed method in attributing fake audio in various cross-test setups on large-scale datasets. Additionally, we apply our approach to binary fake audio detection and observe its remarkable generalizability even with unseen vocoders.},
  archive      = {J_APIN},
  author       = {Ke, Jianpeng and Wang, Lina},
  doi          = {10.1007/s10489-025-06272-0},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Understanding and leveraging vocoder fingerprints for synthetic speech attribution},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal graph convolution neural differential equation for spatio-temporal time series prediction. <em>APIN</em>, <em>55</em>(7), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06287-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series prediction has attracted wide research interest in recent decades. However, implicit spatial topology information and rich temporal evolution information bring many challenges to multivariate time series prediction. In this paper, a novel graph convolution module based on Granger causality is introduced to adaptively learn the causality between nodes. In detail, the ordinary differential equation (ODE) of a graph is used to model the propagation of spatial information between its nodes, and a temporal neural differential equation (NDE) is used to model the temporal evolution of the given nonlinear system. The Granger causality between multivariate time series is revealed by applying a multilayer perceptron (MLP) while imposing the $$L $$ 2 regularization constraint on the weights. A long short-term memory (LSTM)-based network is used as the nonlinear operator to reveal the underlying evolution mechanism of the input spatio-temporal time series. Furthermore, the forward Euler integration method is used to solve the graph ODE, which aims to enhance the representation ability of the proposed model while solving over-smoothing when the graph convolutional network (GCN) becomes too deep. The Euler trapezoidal integration method is used to simulate the evolution processes of dynamical systems and obtain the high-dimensional states of the medium and long-term prediction by solving the temporal NDE. The proposed model can explicitly discover the spatial correlations through its GCN-based causality module. We also combine the graph ODE module and the temporal NDE module to model the spatial information aggregation and temporal dynamic evolution processes, respectively, thus making the proposed model more interpretable. The experimental results demonstrate the effectiveness of our method in terms of spatio-temporal dynamic discovery and prediction performance.},
  archive      = {J_APIN},
  author       = {Wang, Qipeng and Feng, Shoubo and Han, Min},
  doi          = {10.1007/s10489-025-06287-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Causal graph convolution neural differential equation for spatio-temporal time series prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ATTD and ATDS detecting abnormal trajectory detection for urban traffic data. <em>APIN</em>, <em>55</em>(7), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06370-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abnormal trajectory detection is pivotal for ensuring safety and optimizing operations in urban traffic management. Despite the progress in this field, current anomaly detection methods, such as the Spatial-Temporal Relationship (STR) algorithm, face limitations including high computational complexity due to simultaneous model calculations, delayed anomaly detection, and an inability to estimate anomalies in the remaining route during online detection. These limitations can lead to inefficiencies and reduced safety in real-world applications. In this paper, we address these limitations by introducing two novel algorithms: Anomaly Trajectory Detection based on Temporal model (ATTD) and Abnormal Trajectory Detection based on Dual Standards (ATDS). The ATTD algorithm simplifies the detection process by integrating a unified spatio-temporal model, which reduces computational complexity and accelerates the detection of anomalies. Furthermore, the ATDS algorithm introduces a proactive approach to anomaly detection that not only identifies anomalies in real-time but also predicts potential deviations in the remaining trajectory, thus providing a more comprehensive and timely detection mechanism. Through extensive experiments on real taxi trajectory datasets, we demonstrate that our algorithms significantly outperform the STR algorithm and other existing methods in terms of detection accuracy and computational efficiency. Our work contributes to the field by providing a more robust and efficient approach to anomaly trajectory detection.},
  archive      = {J_APIN},
  author       = {Wang, Xi-Te and Xu, Zheng and Liao, Xiao-Yue and Bai, Mei and Ma, Qian},
  doi          = {10.1007/s10489-025-06370-z},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {ATTD and ATDS detecting abnormal trajectory detection for urban traffic data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multistage decomposition transformer network for predicting complex long time series of heavy oil parameters. <em>APIN</em>, <em>55</em>(7), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06413-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary indicators of heavy oil production include temperature, pressure, and various other factors, which exhibit rapid trend changes, erratic wave patterns, and irregular long-term behaviors, severely hindering accurate predictions. To effectively capture the long-term nature and complexity of heavy oil parameters, we propose a multistage decomposing transformer network (MDTN). The MDTN consists of two non-autoregressive decoders, an encoding structure with time encoding, and a time series parser. In this paper, we introduce a time series decomposition (TSD) strategy that breaks down complex long-time series into two simpler trend components and residual components. For the long-term analysis, we employ a local sensitive hash attention mechanism to further decompose these two components into multiple subsequences, followed by self-attention calculations for each subsequence. Additionally, to enable the model to fully leverage the temporal information of the sequence, we embed time, value, and position into each input layer of the encoder. To achieve rapid predictions and minimize error accumulation, we have designed a novel non-autoregressive decoder. Finally, the two sequences are combined through a convolution layer. A substantial number of experiments conducted on heavy oil parameter datasets and publicly available datasets demonstrate that the proposed method yields optimal results. For instance, in the complex long-term prediction of boiler temperature, the MAE value of the proposed method reaches 0.715 at the 1008 prediction step, which is nearly 0.1 lower than that of alternative methods.},
  archive      = {J_APIN},
  author       = {Zhang, Xingpeng and Liu, Hongwei and Xiao, Bin and Wang, Min and Wang, Bing},
  doi          = {10.1007/s10489-025-06413-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Multistage decomposition transformer network for predicting complex long time series of heavy oil parameters},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive quantitative trading strategy optimization framework based on meta reinforcement learning and cognitive game theory. <em>APIN</em>, <em>55</em>(7), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06423-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative trading strategy optimization in the complex and dynamic financial markets presents good challenges due to market non-stationarity, bounded rationality of participants, and the lack of adaptability in existing algorithms. To address these challenges, we propose a novel adaptive quantitative trading strategy optimization framework that seamlessly integrates meta reinforcement learning, cognitive game theory, and automated strategy generation. Our framework achieves superior adaptability, robustness, and profitability, with annualized returns of 51.9%, 49.3%, 46.5%, and 53.7% and Sharpe ratios of 2.37, 2.21, 2.08, and 2.45 in the Chinese, US, European, and Japanese stock markets, respectively, outperforming traditional methods and state-of-the-art machine learning algorithms. The maximum drawdowns are limited to -10.2%, -11.4%, -12.1%, and -10.8%, and the Sortino ratios reach 3.54, 3.28, 3.07, and 3.68, demonstrating effective downside risk management. However, challenges remain in terms of computational complexity, the need for more extensive out-of-sample validation, the incorporation of advanced NLP techniques, and the extension to other markets and asset classes. These limitations call for further research efforts. Overall, this research makes notable contributions to quantitative trading, meta reinforcement learning, and cognitive game theory, opening up new avenues for the development of adaptive, robust, and high-performing trading strategies.},
  archive      = {J_APIN},
  author       = {Shen, Zhiheng and Huang, Hanchi},
  doi          = {10.1007/s10489-025-06423-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {An adaptive quantitative trading strategy optimization framework based on meta reinforcement learning and cognitive game theory},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-driven 5G IoT e-nose for whiskey classification. <em>APIN</em>, <em>55</em>(7), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06425-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main contribution is the design, implementation and validation of a complete AI-driven electronic nose architecture to perform the classification of whiskey and acetones. This classification is of paramount important in the distillery production line of whiskey in order to predict the quality of the final product. In this work, we investigate the application of an e-nose (based on arrays of single-walled carbon nanotubes) to the distinction of two different substances, such as whiskey and acetone (as a subproduct of the distillation process), and discrimination of three different types of the same substance, such as three types of whiskies. We investigated different strategies to classify the odor data and provided a suitable approach based on random forest with accuracy of 99% and with inference times under 1.8 seconds. In the case of clearly different substances, as subproducts of the whiskey distillation process, the procedure presented achieves a high accuracy in the classification process, with an accuracy around 96%.},
  archive      = {J_APIN},
  author       = {Segura-Garcia, Jaume and Fayos-Jordan, Rafael and Alselek, Mohammad and Maicas, Sergi and Arevalillo-Herraez, Miguel and Navarro-Camba, Enrique A. and Alcaraz-Calero, Jose M.},
  doi          = {10.1007/s10489-025-06425-1},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {AI-driven 5G IoT e-nose for whiskey classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing robust node classification via information competition: An improved adversarial resilience method for graph attacks. <em>APIN</em>, <em>55</em>(7), 1-11. (<a href='https://doi.org/10.1007/s10489-025-06478-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) demonstrate their effectiveness in facilitating node classification and a range of graph-based tasks. However, recent studies have revealed that GNNs can be vulnerable to various adversarial attacks. Despite various defense strategies, ranging from attack-agnostic defenses to attack-oriented defenses that have been proposed to mitigate the impact of adversarial attacks on graph data, effectively learning attack-agnostic graph representation remains an open challenge. This paper introduces a novel information Competition-based framework for Graph Neural Networks (i.e., iC-GNN, e.g., iC-GCN, iC-GAT, etc.) to enhance the robustness of GNNs against various adversarial attacks in node classifications. Through the use of graph reconstruction and low-rank approximation, our approach learns diversified graph representations to collaboratively perform node classifications. Meanwhile, mutual information constraints are utilized on different graph representations to ensure diversity and competition in graph features. The experimental results indicate that within the proposed framework, iC-GCN outperforms other graph defense frameworks in countering a wide range of targeted and non-targeted adversarial attacks in both evasion and poisoning training scenarios. Additionally, this concept has been extended to encompass other widely utilized GNN models like iC-GAT and iC-SAGE. All iC-GNN models demonstrate effective defense capabilities, demonstrating comparable resilience to adversarial attacks. This underscores the superiority and scalable nature of the iC-GNN framework, providing opportunities for a variety of graph learning applications.},
  archive      = {J_APIN},
  author       = {Huang, Yong and Yang, Yao and Han, Qiao and Guo, Xinling and Zhai, Yiteng and Cheng, Baoping},
  doi          = {10.1007/s10489-025-06478-2},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-11},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing robust node classification via information competition: An improved adversarial resilience method for graph attacks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive study on enhanced QR extraction techniques with deep learning-based verification. <em>APIN</em>, <em>55</em>(7), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06509-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the digital age, Quick Response (QR) codes have become essential in sectors such as digital payments and ticketing, propelled by advancements in Internet of Things (IoT) and deep learning. Despite their growing use, there are significant challenges in the accurate extraction and verification of QR codes, particularly in dynamic environments. Traditional methods struggle with issues like variable lighting, complex backgrounds, and counterfeits, which degrade the performance of QR code extraction and verification processes. This paper introduces a comprehensive approach that refines QR code extraction using enhanced adaptive thresholding techniques and incorporates a deep learning framework specifically tailored for robust QR code verification. Our methodology integrates dynamic window size adjustment, statistical weighting, and post-thresholding refinement to ensure precise QR code extraction under varying conditions. The verification process employs the ShuffleNetV2 network to ensure high performance with significantly low processing times suitable for real-time applications. Additionally, our deep learning model is trained on a comprehensive dataset comprising 28,523 images across 24 distinct QR code pattern classes, including variations in lighting, noise, and backgrounds to simulate real-world conditions. Experimental results demonstrate that our proposed methodology outperforms competing techniques in both processing speed and recognition accuracy, achieving a processing time of 0.08 seconds and a validation accuracy of 99.99% in constrained scenarios. Our approach shows an exceptional ability to distinguish real QR codes from counterfeits and highlights the significance and efficacy of our method in addressing contemporary challenges.},
  archive      = {J_APIN},
  author       = {Alam, Nur and Sagar, A S M Sharifuzzaman and Zhang, Wenqi and Jin, Taicheng and Dosset, Arailym and Dang, L. Minh and Moon, Hyeonjoon},
  doi          = {10.1007/s10489-025-06509-y},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {A comprehensive study on enhanced QR extraction techniques with deep learning-based verification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedFAA: Knowledge filtering for adaptive model aggregation in federated learning. <em>APIN</em>, <em>55</em>(7), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06530-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In federated learning, performing knowledge distillation on unlabeled proxy data is an effective way to aggregate local models into a global model. Most distillation-based methods assume that all knowledge from local models is contributory, and thereby indiscriminately transfer it to the global model. However, this assumption does not hold in data heterogeneity scenarios. Incorporating noisy knowledge during the distillation can negatively impact the performance of the global model. While filtering the knowledge be transferred is an intuitive solution, performing such filtering in federated learning is challenging due to the lack of available proxy-sample labels for knowledge validation. To address this issue, we propose a knowledge filtering approach for adaptive local model aggregation (FedFAA), which filters the knowledge before distillation based on its relevance. Specifically, we design a scoring method that exploits the representation space of a model to measure the relevance between the model knowledge and each proxy sample, without relying on validation labels. With these relevance scores, we further introduce an adaptive teacher model selection scheme that maintains an appropriate distribution of knowledge-providing teacher models across proxy samples, balancing the precision and diversity of the transferred knowledge after filtering. Theoretical analysis and extensive experiments demonstrate the effectiveness of our approach and its superior performance over six state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Lu, Zihao and Wang, Junli and Guang, Mingjian},
  doi          = {10.1007/s10489-025-06530-1},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {FedFAA: Knowledge filtering for adaptive model aggregation in federated learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A keyframe weighted dual-channel attention GCN model for human skeleton motion prediction. <em>APIN</em>, <em>55</em>(7), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06532-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of human skeletal motion sequences is critical for human activity analysis and low-latency motion reconstruction applications. While many studies focus on frame-by-frame prediction model designs, the keyframes in a motion sequence may contain more spatial-temporal information than the other keyframes do. To address the importance of keyframes, this work introduces a heterogeneous keyframe selection and fusion method to discriminate the importance of different motion frames from historical observations for prediction. Specifically, we propose an adaptive keyframe selection algorithm to iteratively select the keyframes and a nonlinear heterogeneous interpolation method to reconstruct the transitional frames. By merging them with the original motion sequence, the semantics of the original motion are preserved, and the importance of the keyframes is highlighted. A graph convolutional network (GCN) is designed for prediction with dual-channel attention to incorporate motion patterns in longer-term historical records to improve motion feature exploration. A comprehensive evaluation of the model is performed on the Human3.6M and AMASS datasets, which shows significant improvement in motion prediction over long-term methods ( $$\ge $$ 320 ms) over the state-of-the-art methods in terms of the 3D mean per joint position error (MPJPE).},
  archive      = {J_APIN},
  author       = {Zhang, Wenwen and Tu, Jianfeng and Li, Siyu and Liu, Lingfeng},
  doi          = {10.1007/s10489-025-06532-z},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {A keyframe weighted dual-channel attention GCN model for human skeleton motion prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Big data fusion with knowledge graph: A comprehensive overview. <em>APIN</em>, <em>55</em>(7), 1-26. (<a href='https://doi.org/10.1007/s10489-025-06549-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with the wide application of intelligent systems in various fields, the combination of data fusion and knowledge graph has become the key to enhance the system’s problem solving capability. However, existing data fusion methods still face challenges when dealing with multi-source heterogeneous data, especially in how to effectively combine knowledge graph. Therefore, this paper systematically reviews existing data fusion methods based on knowledge graph and classifies them into three categories: fusion of raw data, fusion of raw data with knowledge graph, and fusion of knowledge graphs. Each category of methods is described and analyzed in detail by combining a general framework with specific examples. In addition, this paper also discusses the future research direction of data fusion based on knowledge graph, and analyzes the challenges and opportunities it faces. This paper provides a theoretical framework and practical guidance for the problem of multi-source heterogeneous data fusion, and provides methodological support for the development of intelligent systems.},
  archive      = {J_APIN},
  author       = {Liu, Jia and Lan, Ruotian and Du, Yajun and Yuan, Xipeng and Xu, Huan and Li, Tianrui and Huang, Wei and Zhang, Pengfei},
  doi          = {10.1007/s10489-025-06549-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Big data fusion with knowledge graph: A comprehensive overview},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DifNet: Difference-based multi-resolution decomposition for time series anomaly detection. <em>APIN</em>, <em>55</em>(7), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06551-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection is crucial for Internet of Things (IoT) management and system security. Mainstream methods typically treat time series as an indivisible whole to capture insights into normal patterns. However, time series contain deterministic components such as seasonality, periodicity, and trends. Non-decomposition-based methods often average out these components during training, leading to the over-smoothing of normal time series features. This deviates from the core principle of unsupervised time series anomaly detection: to establish a clear boundary between normal and anomalous patterns. We propose DifNet, a comprehensive unsupervised time series anomaly detection method that effectively mitigates feature over-smoothing (FOS). DifNet adopts the concept of time series decomposition and utilizes Fast Fourier Transform (FFT) to analyze the periodic components of time series, guiding the decomposition and fusion process. Additionally, we design a difference-based multi-resolution decomposition network to thoroughly extract complex periodic dependencies within the time series. For multivariate time series data, DifNet follows the channel independence principle and disregards inter-channel dependencies that introduce redundant information in the data. As a more lightweight alternative, we introduce single-channel autoencoder and cross-channel periodicity adjustment. Meanwhile, DifNet integrates contrastive learning at a fine-grained level to prevent FOS and facilitate the extraction of more distinguishable representations. Extensive experimentation conducted on six multivariate and two univariate time series datasets validates the efficacy of DifNet in time series anomaly detection, DifNet achieved an average improvement in the best F1-score of 14.67% across eight datasets.},
  archive      = {J_APIN},
  author       = {Wang, Honglan and Li, Jing and Chen, Yu and Zou, Xuxi and Zeng, Zeng and Wu, Jinlong and Pan, Chenlin and Lu, Yuqi and Gu, Rongbin and He, Xudong and Zhang, Rui},
  doi          = {10.1007/s10489-025-06551-w},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {DifNet: Difference-based multi-resolution decomposition for time series anomaly detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Block-diagonal graph embedding for unsupervised feature selection. <em>APIN</em>, <em>55</em>(7), 1-24. (<a href='https://doi.org/10.1007/s10489-025-06558-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of unsupervised feature selection (UFS) is to remove irrelevant, redundant and noisy features, which could reduce the time consumption and improve the clustering performance of learning machine. Due to the absence of label information, the major research direction of UFS models lies in how to characterize the manifold structure of high-dimensional data and generate the pseudo labels for data samples properly. With the generated label information, a faithful and compact feature subset could be produced that sufficiently preserves the intrinsic structure. In this paper, we propose a novel subspace clustering guided unsupervised feature selection (BDGFS) model. Specifically, the underlying manifold structure is captured by subspace clustering method that could adaptively preserve the cluster labels, meanwhile the salient features are selected to dominate the projected subspace. The BDGFS model can naturally preserve the multi-subspace distribution via subspace clustering and simultaneously learn the feature weight matrix which is sufficient to characterize the underling subspace structure with exact components preserving. We develop an alternative optimization strategy to solve the challenging objective function, and then discuss the convergence of the proposed algorithm. Experimental results on benchmark databases demonstrate that the BDGFS model could outperform the state-of-the-art UFS models. The code of the BDGFS model is released at https://github.com/ty-kj/BDGFS .},
  archive      = {J_APIN},
  author       = {Jiang, Kun and Yang, Zhihai and Sun, Qindong},
  doi          = {10.1007/s10489-025-06558-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {Block-diagonal graph embedding for unsupervised feature selection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PD-type iterative learning consensus control approach for an electromechanical actuator-based multiagent system. <em>APIN</em>, <em>55</em>(7), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06559-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving consensus tracking control of a multiagent system (MAS) is challenging. This article proposes an innovative consensus control scheme of a MAS that is composed of electromechanical actuators. The open-loop derivative-type iterative learning control (ILC) is adopted as the baseline consensus controller. The baseline controller has systematically evolved to a proportional-derivative-type ILC to achieve better consensus tracking control for the said actuator. The proposed ILC procedure is synthesized by including the weighted sum of the tracking error as well as the tracking error-derivative variables. The respective learning gains of the aforementioned tracking error variables are pre-calibrated to ensure faster trajectory tracking with better accuracy. The PD-type ILC law strengthens the system’s disturbance resilience and improves its asymptotic convergence rate. The designed controllers are tested on two different communication topologies via simulations and reliable hardware experiments, in which the virtual leader provides the desired trajectory to four agents. Only the fixed agents interact with the leader to obtain the desired trajectory information in different communication topologies. The fixed agent guarantees accurate trajectory tracking behavior by modifying the control effort according to the deviation between its actual trajectory and the trajectories of the neighboring agents and the virtual leader. The corresponding test results indicate that the proposed PD-type ILC significantly enhances the tracking accuracy and the convergence rate of the system compared to the D-type ILC, validating the effectiveness of the proposed control scheme under different communication topologies.},
  archive      = {J_APIN},
  author       = {Li, Bingqiang and Riaz, Saleem and Saleem, Omer and Zhao, Yiyun and Iqbal, Jamshed},
  doi          = {10.1007/s10489-025-06559-2},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {PD-type iterative learning consensus control approach for an electromechanical actuator-based multiagent system},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning based computer aided diagnosis (CAD) tool supported by explainable artificial intelligence for breast cancer exploration. <em>APIN</em>, <em>55</em>(7), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06561-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer (BC) is a leading cause of death among women, with breast ultrasound (BUS) commonly used for early detection. However, BUS images are often affected by speckle noise, low tissue contrast, and artifacts, which can compromise image analysis tasks like segmentation and classification. Nowadays, Deep Learning (DL)-based Computer-Aided Diagnosis (CAD) systems could significantly enhance clinical diagnosis by leveraging self-learning capabilities to extract a sophisticated hierarchy of features from images. However, DL models often lack transparency in their internal decision-making processes, which is critical for sensitive applications like breast imaging. To address this, Explainable Artificial Intelligence (XAI) has emerged as a key approach to make DL models more transparent and interpretable for clinicians. This paper presents an efficient and fully automated DL-based CAD tool enhanced by XAI techniques for the precise exploration and diagnosis of BC using ultrasound images. The proposed CAD involves four key-steps: preprocessing, segmentation, XAI-based explainability, and feature extraction. In the preprocessing phase, an Autoencoder-based architecture is explored to effectively reduce speckle noise. For segmentation, our approach introduces an optimized architecture inspired by the DeepLabV3 + model. To ensure transparency in the model's predictions, Gradient-weighted Class Activation Mapping (Grad-CAM) is employed to provide interpretable insights into the decisions made by the deep neural network. Lastly, relevant features are extracted using the Gray-Level Co-occurrence Matrix (GLCM) technique. The proposed approach was rigourously evaluated on two publicly available benchmark datasets. For the first dataset (A), the evaluation metrics achieved were as follows: Dice coefficient (0.979), accuracy (0.935), intersection over union (0.955), precision (0.984), F1 score (0.981), and recall (0.980). Similarly, for the second dataset (B), the model showed notable improvements, achieving a Dice coefficient (0.981), accuracy (0.974), intersection over union (0.963), precision (0.986), F1 score (0.985), and recall (0.983).These results highlight the exceptional performance of the optimized DeepLabV3 + model in segmentation tasks, outperforming both U-Net and ResidualUnet architectures.},
  archive      = {J_APIN},
  author       = {Naas, Marwa and Mzoughi, Hiba and Njeh, Ines and Slima, Mohamed Ben},
  doi          = {10.1007/s10489-025-06561-8},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Deep learning based computer aided diagnosis (CAD) tool supported by explainable artificial intelligence for breast cancer exploration},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HLNet: High-level attention mechanism U-net + + for brain tumor segmentation in MRI. <em>APIN</em>, <em>55</em>(7), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06568-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high-level attention mechanism enhances object detection by focusing on important features and details, making it a potential tool for tumor segmentation. However, its effectiveness and efficiency in this context remain uncertain. This study aims to investigate the efficiency, feasibility and effectiveness of integrating a high-level attention mechanism into the U-Net and U-Net +  + model for improving tumor segmentation. Experiments were conducted using U-Net and U-Net +  + models augmented with high-level attention mechanisms to compare their performance. The proposed model incorporated high-level attention mechanisms in the encoder, decoder, and skip connections. Model training and validation were performed using T1, FLAIR, T2, and T1ce MR images from the BraTS2018 and BraTS2019 datasets. To further evaluate the model's effectiveness, testing was conducted on the UPenn-GBM dataset provided by the Center for Biomedical Image Computing and Analysis at the University of Pennsylvania. The segmentation accuracy of the high-level attention U-Net +  + was evaluated using the DICE score, achieving values of 88.68 (ET), 89.71 (TC), and 91.50 (WT) on the BraTS2019 dataset and 90.93 (ET), 92.79 (TC), and 93.77 (WT) on the UPEEN-GBM dataset. The results demonstrate that U-Net +  + integrated with the high-level attention mechanism achieves higher accuracy in brain tumor segmentation compared to baseline models. Experiments conducted on comparable and challenging datasets highlight the superior performance of the proposed approach. Furthermore, the proposed model exhibits promising potential for generalization to other datasets or use cases, making it a viable tool for broader medical imaging applications.},
  archive      = {J_APIN},
  author       = {Yang, Wenyang and Li, Zhiming and Du, Chao and Chow, Steven Kwok Keung},
  doi          = {10.1007/s10489-025-06568-1},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {HLNet: High-level attention mechanism U-net + + for brain tumor segmentation in MRI},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time pickup and delivery scheduling for inter-island logistics using waterborne AGVs. <em>APIN</em>, <em>55</em>(7), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06570-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Archipelagic areas are in urgent need of efficient logistics systems to replace the limited bridges and fixed liners. This paper addresses the dynamic pickup and delivery challenge in inter-island logistics by utilizing waterborne autonomous guided vessels (AGVs). Specifically, the waterborne inter-island logistics problem is precisely expressed as a mixed integer programming (MIP) model. The model considers a variety of practical system constraints that could arise for the waterborne AGVs, e.g., capacity, time windows, berth allocation, and loading constraints. Moreover, in order to solve the possible large-scale scheduling problem dynamically and efficiently, we design an improved variable neighborhood search heuristic method. The approach is featured with four local search strategies and an effective perturbation heuristic to deal with the local minima issue. Extensive comparison experiments are carried out using real-world datasets. The results demonstrate that our algorithm outperforms baseline algorithms in 98% of cases, achieving improvements of over 10% compared to greedy rule-based methods and more than 5% over state-of-the-art heuristic algorithms, such as VNSME. These findings highlight the substantial benefits of the proposed technique, offering significant cost savings when effectively implemented. Comprehensive ablation experiments and parameter sensitivity analyses also demonstrate that the proposed algorithm has superior capabilities in space exploration and exploitation, provided that the step size operator is properly set. The proposed modeling and solution algorithms show great potential in enhancing the efficiency of the inter-island logistics systems.},
  archive      = {J_APIN},
  author       = {Zheng, Huarong and Tian, Jianpeng and Wang, Anqing and Ma, Dongfang},
  doi          = {10.1007/s10489-025-06570-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Real-time pickup and delivery scheduling for inter-island logistics using waterborne AGVs},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-step prediction method of temperature and humidity based on TCN-FECAM-iTransformer. <em>APIN</em>, <em>55</em>(7), 1-28. (<a href='https://doi.org/10.1007/s10489-025-06572-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Greenhouses are a critical component of modern agriculture, facilitating crop growth and development, and accurate predictions of temperature and humidity are essential for mitigating crop diseases and optimizing the growth environment. However, short- and medium-term forecasts of temperature and humidity are challenging because of the complexity of greenhouse microclimates. This paper presents a hybrid model that integrates a frequency-enhanced channel attention mechanism optimized with a temporal convolutional network (TCN-FECAM) and an iTransformer. The model employs a cross-attention mechanism incorporating the advantages of the two models, and a 48-sequence sliding window strategy is used to ensure accurate multistep predictions of temperature and humidity over spans of 3 h to 24 h. The experimental results demonstrate that the TCN-FECAM-iTransformer model outperforms other models across diverse time scales, including GRU, LSTM, Informer, Autoformer, Crossformer, FAM-LSTM, and TPA-LSTM. Specifically, in temperature prediction, the model achieves R2 coefficients of 0.979, 0.973, 0.968, and 0.953 and RMSE values of 0.657, 0.806, 0.923, and 1.126, for 3 h, 6 h, 12 h, and 24 h intervals, respectively. In humidity prediction, the model obtains R2 coefficients of 0.976, 0.961, 0.947, and 0.939 and RMSE values of 1.805, 2.567, 3.132, and 3.451 for 3 h, 6 h, 12 h, and 24 h intervals, respectively. The model therefore exhibits reliable performance in predicting temperature and humidity in greenhouse environments, offering robust support for monitoring and early warnings in crop growth environments.},
  archive      = {J_APIN},
  author       = {Xie, Zongxu and Tao, Zhiqing and Xie, Xianhong and Rao, Yuan and Li, Ke and Li, Wei and Zhu, Jun},
  doi          = {10.1007/s10489-025-06572-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-28},
  shortjournal = {Appl. Intell.},
  title        = {Multi-step prediction method of temperature and humidity based on TCN-FECAM-iTransformer},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tensor completion via leverage sampling and tensor QR decomposition for network latency estimation. <em>APIN</em>, <em>55</em>(7), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06573-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel method for network latency estimation. Network latency estimation is a crucial indicator for evaluating network performance, yet accurate estimation of large-scale network latency requires substantial computation time. Therefore, this paper introduces a method capable of enhancing the speed of network latency estimation. The paper represents the data structure of network nodes as matrices and introduces a time dimension to form a tensor model, thereby transforming the entire network latency estimation problem into a tensor completion problem. The main contributions of this paper include: optimizing leveraged sampling for tensors to improve sampling speed, and on this basis, introducing the Qatar Riyal (QR) decomposition of tensors into the Alternating Direction Method of Multipliers (ADMM) framework to accelerate tensor completion; these two components are combined to form a new model called LNLS-TQR. Numerical experimental results demonstrate that this model significantly improves computation speed while maintaining high accuracy.},
  archive      = {J_APIN},
  author       = {Lei, Jun and Zhao, Jiqian and Wang, Jingqi and Xu, An-Bao},
  doi          = {10.1007/s10489-025-06573-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Tensor completion via leverage sampling and tensor QR decomposition for network latency estimation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal intent recognition based on text-guided cross-modal attention. <em>APIN</em>, <em>55</em>(7), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06583-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In natural language understanding, intent recognition stands out as a crucial task that has drawn significant attention. While previous research focuses on intent recognition using task-specific unimodal data, real-world scenarios often involve human intents expressed through various ways, including speech, tone of voice, facial expressions, and actions. This prompts research into integrating multimodal information to more accurately identify human intent. However, existing intent recognition studies often fuse textual and non-textual modalities without considering their quality gap. The gap in feature quality across different modalities hinders the improvement of the model’s performance. To address this challenge, we propose a multimodal intent recognition model to enhance non-textual modality features. Specifically, we enrich the semantics of non-textual modalities by replacing redundant information through text-guided cross-modal attention. Additionally, we introduce a text-centric adaptive fusion gating mechanism to capitalize on the primary role of text modality in intent recognition. Extensive experiments on two multimodal task datasets show that our proposed model performs better in all metrics than state-of-the-art multimodal models. The results demonstrate that our model efficiently enhances non-textual modality features and fuses multimodal information, showing promising potential for intent recognition.},
  archive      = {J_APIN},
  author       = {Li, Zhengyi and Peng, Junjie and Lin, Xuanchao and Cai, Zesu},
  doi          = {10.1007/s10489-025-06583-2},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Multimodal intent recognition based on text-guided cross-modal attention},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing model learning in reinforcement learning through Q-function-guided trajectory alignment. <em>APIN</em>, <em>55</em>(7), 1-22. (<a href='https://doi.org/10.1007/s10489-024-06083-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based reinforcement learning (MBRL) methods hold great promise for achieving excellent sample efficiency by fitting a dynamics model to previously observed data and leveraging it for RL or planning. However, the resulting trajectories may diverge from actual-world trajectories due to the accumulation of errors in multi-step model sampling, particularly for longer horizons. This undermines the performance of MBRL and significantly affects sample efficiency. Therefore, we present a trajectory alignment capable of aligning simulated trajectories with their real counterparts from any initial random state and with adaptive length, enabling the preparation of paired real-simulated samples to minimize compounding errors. Additionally, we design a Q-function function to estimate Q values for the paired real-simulated samples. The simulated samples whose Q-value difference from the real ones surpasses a given threshold will be discarded, thus preventing the model from over-fitting to erroneous samples. Experimental results demonstrate that both trajectory alignment and Q-function guided sample filtration contribute to improving policy and sample efficiency. Our method surpasses previous state-of-the-art model-based approaches in both sample efficiency and asymptotic performance across a series of challenging control tasks. The code is open source and available at https://github.com/duxin0618/qgtambpo.git .},
  archive      = {J_APIN},
  author       = {Du, Xin and Zhong, Shan and Gong, Shengrong and Si, Yali and Qi, Zhenyu},
  doi          = {10.1007/s10489-024-06083-9},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing model learning in reinforcement learning through Q-function-guided trajectory alignment},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LiDAR-based perception system for logistics in industrial environments. <em>APIN</em>, <em>55</em>(7), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06528-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous vehicles in logistics and industrial environments demand robust and efficient perception systems. This study presents a LiDAR-based perception system designed for such environments, focusing on real-time deterministic obstacle detection and tracking with limited computational power. The proposed multi-stage approach leverages 3D data from LiDAR sensors. First, ground removal is performed to filter out static ground points. Then, a filtering step is applied using precomputed maps of the navigation area to filter out static zones from the LiDAR point clouds. After, object segmentation distinguishes structural elements from potential obstacles, followed by clustering and Principal Component Analysis (PCA) to accurately estimate obstacle pose and volume. An obstacle-tracking method ensures continuous monitoring over time. Extensive experiments in realistic logistics and industrial scenarios have been performed, comparing the proposed approach to state-of-the-art deep-learning-based methods, demonstrating the system’s high performance in both accuracy and efficiency.},
  archive      = {J_APIN},
  author       = {Palos, Martín and Cortés, Irene and Madridano, Ángel and Navas, Francisco and Barbero, Carmen and Milanés, Vicente and García, Fernando},
  doi          = {10.1007/s10489-025-06528-9},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {LiDAR-based perception system for logistics in industrial environments},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Group equivariant learning for few-shot image classification. <em>APIN</em>, <em>55</em>(7), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06546-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning, as an effective approach to solve image classification problems in data-scarce scenarios, has made significant progress in recent years, with numerous methods emerging. These methods typically use convolutional neural networks (CNNs) as feature extractors and classify other data based on the features of a small number of labeled samples. The reason CNNs have become the preferred method for image processing tasks is primarily due to their translational equivariance. However, conventional CNNs lack inherent mechanisms to handle other symmetry transformations (such as rotation and reflection), resulting in reduced classification performance of the model, especially in few-shot scenarios. To address this problem, we leverage the advantages of group convolutions in handling broader symmetric transformations, integrating them into few-shot learning tasks, and accordingly propose a group-equivariant prototypical learning network. This method maps samples into the group space via a group convolution module, enhancing the model’s ability to handle various symmetry transformations present in classification targets within images, thereby improving its feature representation capability. Additionally, we designed a new contrastive loss that can naturally be co-optimized with cross-entropy loss, guiding the model to learn a highly discriminative group feature space. The experimental results on the miniImageNet, CIFAR-FS, and CUB-200 datasets show that the GEPL method significantly improves classification performance, thus verifying the effectiveness of our method.},
  archive      = {J_APIN},
  author       = {Su, Meijuan and Yan, LeiLei and Li, Fanzhang},
  doi          = {10.1007/s10489-025-06546-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Group equivariant learning for few-shot image classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VFE: A large-scale video future event description dataset for evaluating video temporal prediction. <em>APIN</em>, <em>55</em>(7), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06547-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a video, humans can predict subsequent events in the video and generate reasonable descriptions based on the acquired information and prior knowledge. This ability requires in-depth analysis of dynamic visual information in videos and the comprehensive use of extensive world knowledge for logical reasoning and prediction. However, current visual systems have not yet reached a satisfactory level regarding similar temporal prediction capability. To evaluate this new application, we construct a dataset called VFE (Video Future Event Description), a large-scale dataset for subsequent video event prediction. The VFE dataset contains over 84K video clips, and each clip is equipped with a video and description of the premise event and a predicted description of the subsequent events. To evaluate video temporal prediction, we propose a task, video future event prediction, to generate possible future event descriptions for subsequent unseen video clips based on the premise video. In this paper, we also propose a baseline model for evaluating the VFE dataset. The experimental results indicate the challenge of this task, and the ability of the visual system in complex video temporal prediction needs to be further explored. The dataset and code are available at https://github.com/keyancaigou/VFE .},
  archive      = {J_APIN},
  author       = {Lai, Chenghang and Wang, Haibo},
  doi          = {10.1007/s10489-025-06547-6},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {VFE: A large-scale video future event description dataset for evaluating video temporal prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A transfer-based decision-making method based on expert risk attitude and reliability. <em>APIN</em>, <em>55</em>(7), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06548-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attributed to emerging information technologies in the current era, historical data have been gradually accumulated in the process of people making decisions, in which people’s preferences are characterized by the data. These accumulated data are beneficial for generating decision recommendations. A small volume of historical data, unfortunately, may not actually characterize people’s preferences and be difficult to generate convinced decision recommendations. To address decision-making problems in this context, a transfer-based decision-making method is proposed based on the idea of parameter transfer given that experts’ risk attitudes and reliabilities are adopted to characterize their preferences. Characterized by the orness degree in the ordered weighted averaging operator, an expert’s risk attitude is identified by minimizing the average distance between overall assessments and their predictions on the historical dataset. An expert’s decision accuracy and internal consistency are defined on the historical dataset and combined to identify the expert’s reliability. With the source domain selected by experts’ reliabilities, a transfer model is constructed, in which experts’ risk attitudes are transferred between source and target domains. The effectiveness of the proposed method is validated by its application in the auxiliary diagnosis of breast lesions, its comparison with different methods, and its ablation experiment.},
  archive      = {J_APIN},
  author       = {Jia, Xuefei and Fu, Chao and Chang, Wenjun},
  doi          = {10.1007/s10489-025-06548-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {A transfer-based decision-making method based on expert risk attitude and reliability},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NS-FUO: Fourier U-type operator based on nested structure. <em>APIN</em>, <em>55</em>(7), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06552-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For partial differential equations (PDE), neural operators can learn the mapping of input and output functions in infinite dimensional spaces by introducing kernel functions into linear transformations. Fourier neural operator (FNO) is a very representative neural operator, which filters out the high-frequency noise in PDE mainly through low frequency dominated Fourier space truncation, and can solve PDE with high precision and high efficiency. However, for some complex high-dimensional PDE, FNO and other algorithms usually have the problem of incomplete filtering out high-frequency noise, which will affect the solution accuracy. To filter out high-frequency noise more thoroughly and further improve the precision, we propose NS-FUO: Fourier U-type Operator Based on Nested Structure. Firstly, NS-FUO adds MLP to each Fourier layer to extract the nonlinear features of PDE in depth. Then, NS-FUO adds UNet to each Fourier layer to extract the multi-layer condition features of PDE in depth. Finally, NS-FUO adds nested UNet after the last Fourier layer to fuses the original input features of PDE with the filtered output features. The experimental results show that compared with 15 PDE intelligent methods such as FNO, U-FNO, LSM, etc, NS-FUO has the highest accuracy for solving three solid PDEs and four fluid PDEs, and achieves an average accuracy improvement of 11.9% compared with the previous best method LSM.},
  archive      = {J_APIN},
  author       = {Chen, Jingjian and Nie, Jie and Song, Ning and Ye, Min and Wei, Zhiqiang},
  doi          = {10.1007/s10489-025-06552-9},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {NS-FUO: Fourier U-type operator based on nested structure},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MMCA: Multi-stage multi-order context aggregation framework for LDCT denoising. <em>APIN</em>, <em>55</em>(7), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06553-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-dose computed tomography (LDCT) is widely used to reduce patient radiation exposure, but this reduction often comes at the cost of increased noise in the CT images. Although various deep learning-based methods have been developed for LDCT denoising, most struggle to balance local perception and global contextual capture, thus failing to highlight valuable expressions. This paper presents a multi-stage multi-order context aggregation learning framework designed for high-resolution feature map. The framework combines local perception with adaptive context aggregation to improve performance. Each stage employs the macro-architecture of a vision transformer and integrates edge-enhancement features. Initially, the input passes through feature embedding blocks, followed by the stacking of multiple multi-order context aggregation modules to enable efficient feature interaction. The context aggregation modules effectively generate more discriminative representations from features that incorporate edge information. Extensive experiments on two publicly available LDCT denoising datasets demonstrate that our method surpasses state-of-the-art models. Notably, our method strikes a better balance between network efficiency and denoising performance. The code will be made publicly available on https://code.ihep.ac.cn/lijf/MMCA.},
  archive      = {J_APIN},
  author       = {Li, Jianfang and Wang, Li and Wang, Shengxiang and Li, Yakang and Qi, Fazhi},
  doi          = {10.1007/s10489-025-06553-8},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {MMCA: Multi-stage multi-order context aggregation framework for LDCT denoising},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TFP-mixer: A lightweight time and frequency combining model for multivariate long-term time series forecasting. <em>APIN</em>, <em>55</em>(7), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06562-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series are widely present in various fields such as financial investment, energy consumption, electricity usage, and traffic flow. By analyzing time series, we can predict future trends and patterns, which helps in making strategic decisions, optimizing resource allocation, and improving overall efficiency. Recently, most methods prioritize prediction accuracy, often overlooking memory and computational costs, which limit applicability in scenarios requiring rapid response times or high computational resources. Even when focusing solely on prediction accuracy, these methods often overlook important considerations, such as the interactions between time and frequency features, among channels, and within patches. To address these issues, we designed a lightweight time series forecasting model called TFP-Mixer, which integrates both time domain and frequency domain information. In the time domain, TFP-Mixer captures the dynamic changes and dependencies of time series through Time/Frequency interaction, Channel interaction, and Patch interaction. By using Discrete Fourier transform (DFT) to convert time series into frequency domain data, the model extracts and interacts with frequency domain features, enhancing its ability to capture frequency domain characteristics. Extensive experiments on nine real-world time series datasets show that TFP-Mixer achieves a 6.17% and 7.15% improvement over state-of-the-art (SOTA) methods. The code is available at https://github.com/SDUYanDong/TFP-Mixer},
  archive      = {J_APIN},
  author       = {Zhang, Zhaodian and Tian, Guangpo and Guo, Fenghua and Wang, Pengfei},
  doi          = {10.1007/s10489-025-06562-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {TFP-mixer: A lightweight time and frequency combining model for multivariate long-term time series forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consistent coding guided domain adaptation retrieval. <em>APIN</em>, <em>55</em>(7), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06563-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation retrieval (DAR) has become a research hotspot. The current DAR methods have the following problems. 1) They fail to learn a distinguishable retrieval pool during training, which can be better used for retrieval. 2) They ignore the similarity imbalance problem, leading to less attention to similar relationships than dissimilar relationships. 3) There is quantization error caused by classifier, which limits the discriminability of hash codes. To tackle these problems, this paper proposed a consistent coding guided domain adaptation retrieval (CCG) method which simultaneously involves two modules, including consistent hash codes learning and hash function learning. The former adaptively learns distinguishable and domain-consistent hash codes by composing two novel terms: the label-based iterative quantization term and the probability weighted similarity preserving term. The first term uses a classifier to construct the label-based quantization, and introduces an orthogonal rotation matrix to reduce the quantization error. This brings the classification result to the nearest vertex of the Hamming hypercube, thus improving the discriminability of the hash codes. The second term constructs similarity matrices for both intra-domain and inter-domain samples according to their labels, and preserves the similarity relationship between hash codes. In addition, it dynamically and adaptively adjusts the weights of preserving the similar and dissimilar relationship to alleviate the similarity unbalance problem. This further enhances the discriminability and the domain-consistency of the hash codes. Extensive experiments on various datasets demonstrate that the proposed CCG achieves the state-of-the-art performance. The source code is available at https://github.com/SkyHappyHu/CCG .},
  archive      = {J_APIN},
  author       = {Hu, Tianle and Chen, Yonghao and Lv, Weijun and Chen, Yu and Fang, Xiaozhao},
  doi          = {10.1007/s10489-025-06563-6},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Consistent coding guided domain adaptation retrieval},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive robust cost-sensitive online classification algorithm for class-imbalanced datasets. <em>APIN</em>, <em>55</em>(7), 1-25. (<a href='https://doi.org/10.1007/s10489-025-06567-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous development of machine learning technology, classification has become increasingly important in various fields, such as disease detection, user analysis, etc. However, traditional classification algorithms frequently encounter challenges such as class imbalances, noise and outliers, and large-scale dynamic data processing, which limit their performance in practical applications. This study presents an enhanced adaptive robust cost-sensitive online classification algorithm that dynamically adjusts the penalty coefficient according to the distribution characteristics of the data stream and the algorithm’s performance, in combination with an online learning strategy, to improve the model’s robustness in dealing with dynamic data streams, class imbalance, and noise or outliers. A series of numerical experiments and real-world applications have validated that the new algorithm can significantly enhance classification accuracy while maintaining computational efficiency. Notably, the algorithm demonstrates promising application potential in practical problems such as credit card default detection.},
  archive      = {J_APIN},
  author       = {Shan, Xian and You, Jinyu and Li, Xiaoying and Zhang, Zheshuo and Xie, Yu},
  doi          = {10.1007/s10489-025-06567-2},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive robust cost-sensitive online classification algorithm for class-imbalanced datasets},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Key class identification: A comprehensive dataset and a new GNN model. <em>APIN</em>, <em>55</em>(7), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06574-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Program comprehension is a critical task in software maintenance. As the scale of codebases expands, the required human effort increases exponentially. Key Class Identification (KCI) offers an effective solution to this challenge. Despite this, the absence of standardized benchmarks and the lack of robustness in most existing metric-based approaches across different software systems are major obstacles. In this paper, we first construct a comprehensive dataset to objectively evaluate KCI performance. Inspired by ensemble learning, we introduce a voting method to address key class labeling, representing the primary challenge in dataset construction. Additionally, we propose a novel GNN model that leverages graph transformer to capture information from directed class dependency networks for key class identification. Extensive experiments conducted on 170 software systems in our benchmark demonstrate that our approach achieves high accuracy of up to 93.1%, outperforming existing metric-based methods.},
  archive      = {J_APIN},
  author       = {Wang, Shizhou and Chen, Yuhang and Chen, Liangyu},
  doi          = {10.1007/s10489-025-06574-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Key class identification: A comprehensive dataset and a new GNN model},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Orthogonal and spherical quaternion features for weakly supervised learning with label confidence optimization. <em>APIN</em>, <em>55</em>(7), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06575-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised learning (WSL) addresses the challenge of incomplete or noisy labels, but current methods often fail to capture the complexities introduced by weak labels in feature extraction, revealing the limitations of neural networks in modeling the intricate relationships between features and labels. To address these issues, we introduce the Orthogonal and Spherical Quaternion Neural Network (OSQNN), which utilizes quaternion feature embedding with an orthogonal constraint to map real-valued features into quaternion space. This approach improves the understanding of feature-label relationships by overcoming the challenge of embedding real-world data into quaternion spaces. OSQNN maps quaternion features onto a sphere and estimates label reliability through nearest neighbors, maintaining a coherent geometric structure in feature distributions. Furthermore, quaternion convolutions are transformed into parallel grouped real-valued convolutions, enhancing processing efficiency without sacrificing the benefits of quaternion-based computations. Additionally, we propose the Label Confidence Guided Expectation-Maximization (LCGEM) algorithm, integrated into OSQNN, to more effectively capture the complex relationships between weak labels and feature distributions. Experimental results across eight datasets demonstrate the superiority of OSQNN. For instance, in SSL on CIFAR10 (20% labeled data) and CIFAR100, it achieved 91.06% and 69.16% accuracy respectively; in NSL with 40% incorrect labels on CIFAR10 and CIFAR100, the accuracies were 80.84% and 51.98%, showing its high accuracy and robustness. The ablation study highlights the role of the orthogonal constraint and spherical feature mapping in improving performance, while t-SNE visualization confirms the ability of OSQNN to learn discriminative feature representations.},
  archive      = {J_APIN},
  author       = {Zhou, Heng and Zhong, Ping},
  doi          = {10.1007/s10489-025-06575-2},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Orthogonal and spherical quaternion features for weakly supervised learning with label confidence optimization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdaFT: An efficient domain-adaptive fine-tuning framework for sentiment analysis in chinese financial texts. <em>APIN</em>, <em>55</em>(7), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06578-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the prevalence of pre-trained language models (PLMs) within the field of natural language processing, it has become evident that the conventional two-stage approach of ‘pre-training’-then-‘fine-tuning’ consistently yields commendable outcomes. Nevertheless, most publicly accessible PLMs are pre-trained on extensive, general-purpose datasets, thereby failing to address the substantial domain dissimilarity between the source and target data. This discrepancy has significant implications for the adaptability of PLMs to specific domains. To address this issue, our study proposes AdaFT, an efficient domain-adaptive fine-tuning framework that seeks to enhance the traditional fine-tuning process, thus bridging the gap between the source and target domains. This is particularly beneficial for enabling PLMs to better align with the specialized context of the Chinese financial domain. In contrast to the standard two-stage paradigm, AdaFT incorporates two additional stages: ’multi-task further pre-training’ and ’multi-model parameter fusion.’ In the first phase, the PLM undergoes a rapid, multi-task, parallel learning process, which effectively augments its proficiency in Chinese financial domain-related tasks. In the subsequent stage, we introduce an adaptive multi-model parameter fusion (AdaMFusion) strategy to amalgamate the knowledge acquired from the extended pre-training. To efficiently allocate weights for AdaMFusion, we have developed a local search algorithm with a decreasing step length, i.e., Local Search with Decreasing Step size (LSDS). The combination of AdaMFusion and LSDS algorithm strikes a balance between efficiency and performance, making it suitable for most scenarios. We also find that the optimal weighting factor assigned to a model to be fused is positively correlated with the performance improvement of that model on the target task after further pre-training. We demonstrate that further pre-training is generally effective, and further pre-training on domain-relevant corpora is more effective than on task-relevant corpora. Our extensive experiments, utilizing BERT (Bidirectional Encoder Representations from Transformers) as an illustrative example, indicate that Chinese BERT-base trained under the AdaFT framework attains an accuracy rate of 94.95% in the target task, marking a substantial 3.12% enhancement when compared to the conventional fine-tuning approach. Furthermore, our results demonstrate that AdaFT remains effective when applied to BERT-based variants, such as Chinese ALBERT-base.},
  archive      = {J_APIN},
  author       = {Yan, Guofeng and Peng, Kuashuai and Wang, Yongfeng and Tan, Hengliang and Du, Jiao and Wu, Heng},
  doi          = {10.1007/s10489-025-06578-z},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {AdaFT: An efficient domain-adaptive fine-tuning framework for sentiment analysis in chinese financial texts},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing keyphrase extraction from long scientific documents using graph embeddings. <em>APIN</em>, <em>55</em>(7), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06579-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the integration of graph neural network (GNN) representations with pre-trained language models (PLMs) to enhance keyphrase extraction (KPE) from lengthy documents. We demonstrate that incorporating graph embeddings into PLMs yields richer semantic representations, especially for long texts. Our approach constructs a co-occurrence graph of the document, which we then embed using a graph convolutional network (GCN) trained for edge prediction. This process captures non-sequential relationships and long-distance dependencies, both of which are often crucial in lengthy documents. We introduce a novel graph-enhanced sequence tagging architecture that combines PLM-based contextual embeddings with GNN-derived representations. Through evaluations on benchmark datasets, our method outperforms state-of-the-art models, showing notable improvements in F1 scores. Beyond performance on standard benchmarks, this approach also holds promise in domains such as legal, medical, and scientific document processing, where efficient handling of long texts is vital. Our findings underscore the potential for GNNs to complement PLMs, helping address both technical and real-world challenges in KPE for long documents.},
  archive      = {J_APIN},
  author       = {Martínez-Cruz, Roberto and Mahata, Debanjan and López-López, Alvaro J. and Portela, José},
  doi          = {10.1007/s10489-025-06579-y},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing keyphrase extraction from long scientific documents using graph embeddings},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anchor-based incomplete multi-view clustering with graph convolution network. <em>APIN</em>, <em>55</em>(7), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06580-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anchor-based method has proved to be effective in recent incomplete multi-view clustering literature. Although existing methods have achieved significant success in various fields (e.g., digital treatment), they still have several limitations: (1) The construction of anchor graph insufficiently considers the graph structural information inherent in the original data. (2) Most studies are unable to sufficiently explore the correlation between the non-linear structures of representation space and the original space. In this paper, we propose a Anchor-based Incomplete Multi-view Clustering with Graph Convolution Network (AIMCG) method to address the above issues. Specifically, we first adopt graph convolution networks to extract graph information from multi-view data, and employ manifold regularization to constrain the generation of common graph representation. Subsequently, we employ an anchor-based data reconstruction method to generate anchor g raph, combining previous graph information into this process to further enhance the clustering capability. Finally, spectral clustering is applied to the anchor graph to obtain the clustering results. Experiments on 9 benchmark datasets compared with 13 advanced baselines verify the effectiveness of our AIMCG method on incomplete multi-view data.},
  archive      = {J_APIN},
  author       = {Li, Ao and Gao, Tianyu and Wang, Yanbing and Feng, Cong},
  doi          = {10.1007/s10489-025-06580-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Anchor-based incomplete multi-view clustering with graph convolution network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EPDNet: Light-weight small target detection algorithm based on pruning and logical distillation. <em>APIN</em>, <em>55</em>(7), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06582-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drone detection technology plays a crucial role in various fields. However, due to the limited computational resources of edge devices onboard drones, achieving efficient detection using large-parameter algorithms remains challenging. Small target detection in drone-based applications faces several difficulties, including the small size of targets, limited feature information, and vulnerability to environmental interference. Moreover, existing lightweight small target detection methods often compromise detection accuracy while reducing model parameters, failing to meet the dual requirements of accuracy and efficiency in drone scenarios. To address these challenges, this paper proposes EPDNet, a lightweight small target detection algorithm designed for drone applications. First, ConvNextV2 replaces the original backbone network, incorporating a fully convolutional masked autoencoder framework combined with a self-supervised learning strategy to enhance the extraction of essential low-level features. Additionally, the EC2f feature extraction module is introduced to enable interactive modeling of contextual detail features across different target scales, orientations, and shapes. Furthermore, an adaptive channel pruning scheme is designed to reduce redundant parameters and computational complexity, thereby enhancing algorithm efficiency. Finally, the detection performance of the pruned model is further optimized using knowledge distillation. Experimental results on the VisDrone2019 aerial photography dataset demonstrate that EPDNet improves detection precision (P) by 2.6%, increases mean average precision (mAP) by 3.0%, reduces the number of parameters by 29.6%, and decreases computational cost by 17.8%. These results indicate that EPDNet effectively meets the lightweight deployment requirements of drone-based applications.},
  archive      = {J_APIN},
  author       = {Zhu, Gaofeng and Wang, Zhixue and Zhu, Fenghua and Xiong, Gang and Li, Zheng},
  doi          = {10.1007/s10489-025-06582-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {EPDNet: Light-weight small target detection algorithm based on pruning and logical distillation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LiteSpiralGCN: Lightweight 3D hand mesh reconstruction via spiral graph convolution. <em>APIN</em>, <em>55</em>(7), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06585-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hand mesh reconstruction technologies play an important role in computer vision, as they facilitate many applications including virtual/augmented reality, human-computer interaction, etc. However, current methods typically rely on computationally intensive architectures with excessive parameters and storage demands to achieve accuracy. In this paper, we propose a lightweight network via Spiral GCN balancing accuracy and efficiency, named LiteSpiralGCN. Our approach includes an Attention Sampling (AS) module to enhance keypoint feature interactions, a SpiralGCN module for efficient and flexible decoding, and a refinement method that leverages multi-scale and multi-stage information to boost reconstruction accuracy. Experiments conducted on benchmark datasets demonstrate that LiteSpiralGCN effectively balances parameter scale and reconstruction accuracy. Specifically, on the FreiHAND dataset, LiteSpiralGCN achieves a PA-MPJPE of 6.5 mm and a PA-MPVPE of 6.6 mm using only 9.77M parameters. Our code is publicly available at: https://github.com/minqili/LiteSpiralGCN .},
  archive      = {J_APIN},
  author       = {Wang, Yiteng and Li, Minqi and Zhang, Kaibing and He, Xiangjian},
  doi          = {10.1007/s10489-025-06585-0},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {LiteSpiralGCN: Lightweight 3D hand mesh reconstruction via spiral graph convolution},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep metric learning-based side-channel analysis with improved robustness and efficiency. <em>APIN</em>, <em>55</em>(7), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06586-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Side-channel analysis (SCA) is one of the widely studied approaches for assessing vulnerabilities in cryptographic algorithm implementations. Existing deep learning (DL)-based SCA approaches are commonly dataset-specific, and their attack performance heavily depends on optimal hyperparameters and effective neural network architectures. Searching such hyperparameters and architectures could be very time-consuming. In addition, traditional machine learning (ML)-based SCA methods often require manual feature engineering, leading to information loss and limiting attack performance. To address these challenges, we propose a profiled SCA model based on deep metric learning (DML) with template attacks (TA). This novel approach improves dataset generalization, enhances feature extraction, and reduces the reliance on hyperparameters. Specifically, a normalized lifted structured (NLS) loss is designed for the proposed attack model. Then, a label-informed hybrid distance is subtly integrated into the model to enhance the model’s ability for capturing relationships between embeddings and labels, thereby improving the attack performance and robustness. Next, a similarity learning method is designed by evaluating all pairwise distances within a mini-batch, reducing sensitivity to triplet selection and improving training efficiency. Experimental results show that the proposed model significantly outperforms the state-of-the-art DL-based SCA methods. It achieves attack performance improvements of up to 50.0% and an average improvement of 37.9% on public datasets, while being 30.8% faster in network training. Comprehensive evaluations show that the proposed model provides high efficiency, robust performance, and strong generalization across diverse datasets and leakage models.},
  archive      = {J_APIN},
  author       = {Li, Kaibin and Liang, Yihuai and Meng, Hua and Zhou, Zhengchun},
  doi          = {10.1007/s10489-025-06586-z},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Deep metric learning-based side-channel analysis with improved robustness and efficiency},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning nested attentional feature fusion network for high performance visual tracking. <em>APIN</em>, <em>55</em>(7), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06588-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Siamese network-based visual tracking has made significant progress in recent years, with correlation calculations playing a central role in these models. However, the inherently linear and localized nature of correlation often leads to substantial semantic information loss and convergence to local optima, thereby limiting the potential for further performance improvements. To address these challenges, we propose a feature fusion network inspired by the Transformer architecture, incorporating nested attention mechanisms to enhance tracking accuracy and robustness. Unlike standard Transformer-based models, our approach refines correlation accuracy by emphasizing correct matches while attenuating incorrect ones through nested attentional representation learning. This enables more effective feature aggregation and information propagation. Our feature fusion network consists of four interdependent modules: ego-context augmentation, short-term feature augmentation, long-term feature augmentation, and cross-feature augmentation. These modules collaboratively fuse features from target templates and search regions, producing semantically rich feature maps superior to those generated by traditional correlation methods. Built on this framework, our proposed model, AiATransT, achieves state-of-the-art performance on five benchmark datasets, validated by extensive experimental evaluations.},
  archive      = {J_APIN},
  author       = {Gao, Peng and Zhang, Xin-Yue and Yu, Tao},
  doi          = {10.1007/s10489-025-06588-x},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Learning nested attentional feature fusion network for high performance visual tracking},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging subdomain alignment for enhanced anomaly detection in time series. <em>APIN</em>, <em>55</em>(7), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06589-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection focuses on identifying anomalies in continuously collected data at each time step. Developing an effective detection model requires not only accurate anomaly identification but also adaptability to the dynamic changes inherent in time series data. Current research primarily employs deep learning networks with task-specific reconstruction or prediction objectives to learn the underlying patterns of normal data. However, the distribution of complex time series data often shifts subtly over time, leading to evolving normal patterns. These distributional shifts make it difficult for models to establish clear decision boundaries, as they often fail to recognize such changes. To address these challenges, this paper proposes Subdomain Alignment for Enhanced Anomaly Detection in Time Series (SA-EADTS). This method aligns the latent distributions of unknown subdomains using a sensitive distance, enabling anomaly detection on unseen data distributions. Extensive experiments on four real-world datasets demonstrate that SA-EADTS significantly outperforms state-of-the-art baseline methods.},
  archive      = {J_APIN},
  author       = {Chen, Bo and Fang, Min and Li, HaiXiang and Wang, GuiZhi},
  doi          = {10.1007/s10489-025-06589-w},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Leveraging subdomain alignment for enhanced anomaly detection in time series},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MOEA/D with adaptive weight vector adjustment and parameter selection based on Q-learning. <em>APIN</em>, <em>55</em>(6), 1-43. (<a href='https://doi.org/10.1007/s10489-024-05906-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective evolutionary algorithms (MOEAs) are widely utilized for addressing multi-objective optimization problems (MOPs), demonstrating effectiveness in handling low-dimensional and regular Pareto fronts (PFs) MOPs. However, when the number of objectives increases (>3) and the PFs become increasingly intricate, maintaining both the convergence and diversity of solutions presents a significant challenge. To address this, an adaptive weight vector adjustment and parameter selection based on Q-learning (QLMOEA/D-AWA) is proposed. In the algorithm, Q-learning is employed to select both the Tchebycheff value and the number of weight vectors, aiming to balance convergence and diversity. To enhance the convergence, an improved Tchebycheff approach is proposed. To better solve problems in high-dimensional objective spaces, the niche technique is adopted to retain elite individuals. In addition, to address MOPs with irregular PFs, a two-stage weight vector deletion strategy is proposed to remove invalid weight vectors, and a certain number of weight vectors are added based on sparsity rules. An experiment study of objective numbers ranging from 2 to 10 is conducted on DTLZ, WFG, MaF and multi-objective traveling salesman problem (MOTSP). Among 115 benchmark problems, QLMOEA/D-AWA achieves 54 and 49 best results in IGD and HV, respectively.},
  archive      = {J_APIN},
  author       = {Xue, Fei and Chen, Yuezheng and Dong, Tingting and Wang, Peiwen and Fan, Wenyu},
  doi          = {10.1007/s10489-024-05906-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-43},
  shortjournal = {Appl. Intell.},
  title        = {MOEA/D with adaptive weight vector adjustment and parameter selection based on Q-learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel drift detection method using parallel detection and anti-noise techniques. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-024-05988-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the Internet industry, a large amount of streaming data with significant application value will be generated on the Internet. The distribution of stream data is evolving over time compared to traditional data, posing a significant challenge in the learning process from streaming data. In order to adapt the change of data distribution, concept drift detection methods are proposed to pinpoint when the concept drift occurs. Most existing drift detection methods, however, overlook the improvement of the current classifier and the influence of noise data on drift detection. This oversight leads to a decrease in the effectiveness of drift detection. In this paper, we propose a novel adaptation drift detection method to overcome the shortcomings of previous algorithms, such as error detection and lack of anti-noise capability. Meanwhile, stream computing and parallel computing are used to enhance the efficiency of our algorithm. The results of a simulation experiment on 9 synthetic stream data and 6 real-world stream data, all exhibiting concept drift, demonstrate that our method is more effective in handling concept drift compared to other state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Zhang, Qian and Liu, Guanjun},
  doi          = {10.1007/s10489-024-05988-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {A novel drift detection method using parallel detection and anti-noise techniques},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain adaptation for improving automatic airborne pollen classification with expert-verified measurements. <em>APIN</em>, <em>55</em>(6), 1-15. (<a href='https://doi.org/10.1007/s10489-024-06021-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel approach to enhance the accuracy of automatic classification systems for airborne pollen particles by integrating domain adaptation techniques. Our method incorporates expert-verified measurements into the convolutional neural network (CNN) training process to address the discrepancy between laboratory test data and real-world environmental measurements. We systematically fine-tuned CNN models, initially developed on standard reference datasets, with these expert-verified measurements. A comprehensive exploration of hyperparameters was conducted to optimize the CNN models, ensuring their robustness and adaptability across various environmental conditions and pollen types. Empirical results indicate a significant improvement, evidenced by a 22.52% increase in correlation and a 38.05% reduction in standard deviation across 29 cases of different pollen classes over multiple study years. This research highlights the potential of domain adaptation techniques in environmental monitoring, particularly in contexts where the integrity and representativeness of reference datasets are difficult to verify.},
  archive      = {J_APIN},
  author       = {Matavulj, Predrag and Jelic, Slobodan and Severdija, Domagoj and Brdar, Sanja and Radovanovic, Milos and Tesendic, Danijela and Sikoparija, Branko},
  doi          = {10.1007/s10489-024-06021-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Domain adaptation for improving automatic airborne pollen classification with expert-verified measurements},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selections based on uncertainty measurements from dual-quantitative improvement and double-hierarchical fusion. <em>APIN</em>, <em>55</em>(6), 1-35. (<a href='https://doi.org/10.1007/s10489-024-06075-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selections promote classification learning, and rough set theory offers effective mathematical methods; in practice, the performance enhancement of feature selection algorithms formulates a research target and challenge, and the corresponding problem solving usually resorts to improvement constructions of uncertainty measures. By fitting fuzzy rough sets (FFRSs), the relative dependency complement mutual information (FDCIE) motivates a recent algorithm of feature selection, called FNRDCI; however, FDCIE has improvement space of quantification view and fusion hierarchy, so the corresponding feature selection and heuristic algorithm can be advanced. In this paper, the dependency is improved by information localization, while the mutual information is enriched by information fuzzification and decision-class combination, so improved fusion measures and robuster feature selections are established by double-hierarchical fusion on decision classification and class. At first, the correctional dependency is proposed by fuzzy decision localization, and it induces a classification fusion measure (i.e. FCDCIE); based on two types of fuzzy decisions, two types of mutual information (i.e. FRCEmI and FRCFmI) are established by information fuzzification and class combination. Then, two types of dependency and two types of mutual information combinedly generate $$2\times 2=4$$ classification fusion measures (i.e. IFRDCEmI, IFRDCFmI, IFRCDCEmI, IFRCDCFmI) by pursuing class-level priority fusion; these new measures acquire semantics uncertainty, system equations, and granulation monotonicity/nonmonotonicity. Furthermore, $$1+2\times 2=5$$ fusion measures yield 5 novel feature selections with heuristic algorithms. Finally, experimental comparisons demonstrate the effectiveness and efficiency of the proposed novel methods of uncertainty measures and selection algorithms.},
  archive      = {J_APIN},
  author       = {Wang, Qian and Zhang, Xianyong and Lv, Zhiying and Mo, Zhiwen},
  doi          = {10.1007/s10489-024-06075-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-35},
  shortjournal = {Appl. Intell.},
  title        = {Feature selections based on uncertainty measurements from dual-quantitative improvement and double-hierarchical fusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Daily power generation forecasting for a grid-connected solar power plant using transfer learning technique. <em>APIN</em>, <em>55</em>(6), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06090-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is efficiently used for photovoltaic power generation forecasting to handle the intermittent nature of solar energy. However, big data are required for training deep networks which are not available for newly installed plants. Therefore, in this study, a novel strategy is proposed to train a deep learning model using a transfer learning technique to cop up with the unavailability of enough training datasets. A new 400 kWp solar power plant installed in the Himalayan region is considered as a case study to evaluate the proposed model. The proposed approach utilizes solar radiation data to train a deep neural network and then fine-tune the model using the power generation data from the plant. The network architecture is optimized using grey wolf optimizer to find the best suitable model for the data. The evaluation results show that the same model can achieve higher performance in generation forecasting with percentage error improved by 2% and R-value increased by 7.7% after applying transfer learning. Moreover, SHapley Additive exPlanation and Partial Dependence Plots are used to interpret the model behavior and showed that the model is mostly dependent on the previous generation values (up to 4 days) followed by the temperature and solar radiation.},
  archive      = {J_APIN},
  author       = {Tajjour, Salwan and Chandel, Shyam Singh and Malik, Hasmat and Márquez, Fausto Pedro García and Alotaibi, Majed A.},
  doi          = {10.1007/s10489-024-06090-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Daily power generation forecasting for a grid-connected solar power plant using transfer learning technique},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Dirichlet stochastic weights averaging for graph neural networks. <em>APIN</em>, <em>55</em>(6), 1. (<a href='https://doi.org/10.1007/s10489-024-06099-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Park, Minhoi and Chang, Rakwoo and Song, Kyungwoo},
  doi          = {10.1007/s10489-024-06099-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Correction to: Dirichlet stochastic weights averaging for graph neural networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing the imitation game: A trust-based model for distinguishing human and machine participants. <em>APIN</em>, <em>55</em>(6), 1-39. (<a href='https://doi.org/10.1007/s10489-024-06133-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since 1950, the imitation game has captured the interest of researchers investigating human‒machine differences. Designed to evaluate machine cognition through a game-based framework, its complexity demands refinement. The imitation game utilizes this game-based setup, but its inherent intricacy calls for further enhancements. The fundamental question of whether machines are capable of genuine thought has been a key issue in artificial intelligence (AI) studies. Recent developments challenge the ease of differentiation, as AI enables machines to display human-like characteristics. This paper seeks to address the shortcomings of the original Turing test and criticisms of the imitation game by introducing an integrated model. Although machines currently operate based on our instructions, they can learn from errors and produce novel responses through generative AI techniques, even though they do not experience emotions. In this study, a new trust-based model was introduced to improve the imitation game. This model integrated various factors to assess the reliability of participants’ responses, including grammatical accuracy, response time, thinking duration, response speed, creativity, and the use of human-like expressions. The goal was to calculate a trust factor that determines the likelihood of a participant being a human or machine. To evaluate the model’s performance, a comprehensive dataset was developed using a chat generative pretrained transformer (ChatGPT-3.5). Two other large language models (LLMs), the large language model meta AI (Llama 3) and the Claude LLM, were also taken into account. To simulate the experiment with human participants, human-generated text was also included. The simulation results revealed that GPT-3.5 Turbo, Llama 3, and Claude LLM performed differently in terms of grammatical accuracy, human-like phrasing, creativity, and trust factors. GPT-3.5 and Llama 3 had lower error rates but struggled with human-like phrases. Claude resulted in more grammatical errors but better creativity. The human participants consistently showed greater trust and human-like phrase usage. Probability assessments categorized machines with 71–78% accuracy, whereas humans were identified with only a 29–36% chance of being a machine.},
  archive      = {J_APIN},
  author       = {Gupta, Tanisha and Tripathi, Akarsh and Dubey, Ashutosh Kumar and Chahar, Ravita},
  doi          = {10.1007/s10489-024-06133-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-39},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing the imitation game: A trust-based model for distinguishing human and machine participants},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Freeway optimal control based on emission oriented microscopic graph convolutional neural network. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06143-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction and control in the active traffic control system is considered as one of the most critical issues in Intelligent Transportation Systems (ITS). Among the proposed AI-based approaches, Deep Learning (DL) has been largely applied while showing better performances. This research improves macroscopic traffic flow model METANET by establishing a graph convolution neural network (GCN) to explicitly and more precisely incorporate microscopic traffic flow dynamics. The microscopic emission model utilizes the feature extraction function of GCN to reduce the complexity of measuring the environmental profits for the whole traffic network. By introducing the GCN model to facilitate the aggregation of vehicle information, the proposed framework reduces the computational burden and obtains better optimization performance. The designed algorithms are tested on a microscopic simulation platform based on field data. The results demonstrate that the proposed control method produce a more robust and smooth traffic flow environment, which leads to improved traffic efficiency and overall carbon emissions of the road network.},
  archive      = {J_APIN},
  author       = {Fang, Jie and Lu, Mingwen and Fu, Lina and Wang, Juanmeizi and Xu, Mengyun},
  doi          = {10.1007/s10489-024-06143-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Freeway optimal control based on emission oriented microscopic graph convolutional neural network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving vehicle detection accuracy in complex traffic scenes through context attention and multi-scale feature fusion module. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-024-06146-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle detection is a fundamental task for automated driving systems. However, achieving robust performance in complex traffic scenarios remains a formidable challenge. In this paper, we propose a novel vehicle detection model that leverages contextual attention mechanisms and multi-scale feature fusion to effectively tackle the inherent challenges presented by complex scenarios, such as occlusion, truncation, and small-scale vehicle instances. The proposed model introduces a contextual attention module tailored to address vehicle occlusion, augmenting the model’s reasoning ability and overall performance through the integration of global contextual information. Additionally, we introduce a Multi-Scale Feature Fusion Module to mitigate the impact of drastic changes in vehicle scales observed in dynamic traffic scenarios. Through the deployment of a dedicated multi-scale feature fusion module, our model adeptly adapts to significant size variations of vehicles in traffic scene images, thereby enhancing its capability to handle vehicles of varying sizes. Our contributions are validated through comprehensive qualitative and quantitative experiments conducted on both the KITTI dataset and the Cityscapes dataset. The experimental results demonstrate the exceptional robustness and accuracy of our proposed model. These findings provide conclusive evidence of the superior performance and effectiveness of our model in real-world applications.},
  archive      = {J_APIN},
  author       = {Liu, Wenbo and Zhao, Binglin and Zhu, Yuxin and Deng, Tao and Yan, Fei},
  doi          = {10.1007/s10489-024-06146-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Improving vehicle detection accuracy in complex traffic scenes through context attention and multi-scale feature fusion module},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement knowledge graph reasoning based on dual agents and attention mechanism. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06162-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning can model knowledge graph multi-hop reasoning as Markov Decision Processes and improve the accuracy and interpretability of predicting paths between entities. Existing reasoning methods usually ignore the logic of action selection when facing one-to-many or many-to-many relationships, resulting in poor performance in knowledge graph reasoning. Furthermore, the general multi-hop reasoning only achieves effective short-path reasoning and lacks efficiency in long-distance reasoning. To address the above challenges, we propose a reinforcement learning reasoning model based on dual agents and attention mechanism, where two agents are trained at the macro and micro levels, and the macro agent guides the reasoning of the micro agent. The model employs an attention mechanism to enhance the representation of the current state of the agent, to help the policy network in making more appropriate action selections when facing one-to-many or many-to-many relationships, so as to improve the selection efficiency. Simultaneously, we propose a reward function with a penalty mechanism that penalizes the agent for prematurely reaching the correct answer without staying in place, and enhances the reward of the micro agent with the reward of the macro agent. The two agents cooperate with each other to find reasoning paths on the knowledge graph. Finally, we compare the proposed model with six well-known inference method baselines on three benchmark datasets, and the experimental results show that our proposed method achieves very competitive results.},
  archive      = {J_APIN},
  author       = {Yang, Xu-Hua and Wang, Tao and Gan, Ji-Song and Gao, Liang-Yu and Ma, Gang-Feng and Zhou, Yan-Bo},
  doi          = {10.1007/s10489-024-06162-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Reinforcement knowledge graph reasoning based on dual agents and attention mechanism},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Explainable cognitive decline detection in free dialogues with a machine learning approach based on pre-trained large language models. <em>APIN</em>, <em>55</em>(6), 1. (<a href='https://doi.org/10.1007/s10489-024-06169-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {de Arriba-Pérez, Francisco and García-Méndez, Silvia and Otero-Mosquera, Javier and González-Castaño, Francisco J.},
  doi          = {10.1007/s10489-024-06169-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Correction to: Explainable cognitive decline detection in free dialogues with a machine learning approach based on pre-trained large language models},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Applications of pre-trained CNN models and data fusion techniques in Unity3D for connected vehicles. <em>APIN</em>, <em>55</em>(6), 1-29. (<a href='https://doi.org/10.1007/s10489-024-06213-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent Transportation Systems (ITS) aim to enhance road safety and Internet of Things (IoT)-related solutions are crucial in achieving this objective. By leveraging Vehicle-to-Vehicle (V2V) and Vehicle-to-Infrastructure (V2I) technologies, drivers can access valuable information about their surroundings. This research utilized the Unity 3D game engine to simulate various traffic scenarios, exploring a stochastic environment with two data sources: camera and road sign labels. We developed a full-duplex communication system to enable the communication between Python and Unity. This allows the vehicle to capture images in Unity and classify them using Convolutional Neural Network (CNN) models coded in Python. To improve road sign detection accuracy, we applied multi-sensor Data Fusion (DF) techniques to fuse the information received from the sources. We applied DF methods such as the Kalman filter, Dempster-Shafer theory, and Fuzzy Integral Operators to combine the two sources of information. Furthermore, our proposed CNN model incorporates an Ordered Weighted Averaging (OWA) layer to fuse information from three pre-trained CNN models. Our results show that the proposed model integrating the OWA layer achieved an accuracy of 98.81%, outperforming six state-of-the-art models. We compared the Extended Kalman Filter (EKF) and Unscented Kalman Filter (UKF). In our work, EKF exhibited a lower execution time (0.02 seconds), yielding less accurate results. UKF, however, provided a more accurate estimate while being more computationally complex. Furthermore, the Dempster-Shafer model showed approximately 30% better accuracy compared to the Fuzzy Integral Operator. Using this methodology on autonomous vehicles in our virtual environment led to making more accurate decisions, even in a variety of weather conditions and accident scenarios. The findings of this research contribute to the development of more efficient and safer vehicles.},
  archive      = {J_APIN},
  author       = {Norouzi, Mojtaba and Hosseini, Seyed Hossein and Khoshnevisan, Mohammad and Moshiri, Behzad},
  doi          = {10.1007/s10489-024-06213-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-29},
  shortjournal = {Appl. Intell.},
  title        = {Applications of pre-trained CNN models and data fusion techniques in Unity3D for connected vehicles},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computational analysis of virus-host protein-protein interactions using gene ontology and natural language processing. <em>APIN</em>, <em>55</em>(6), 1-22. (<a href='https://doi.org/10.1007/s10489-024-06223-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The role of in-silico computational methods in identifying protein-protein interactions (PPIs) between target and host proteins is crucial for developing effective infection treatments. These methods are essential for quickly determining high-quality and accurate PPIs, predicting protein pairs with the highest likelihood of physical interaction from a large pool, and reducing the need for experimental confirmation or prioritizing pairs for experiments. This study proposes using gene ontology and natural language processing (NLP) approaches to extract and quantify features from protein sequences. In the first step, proteins were represented using gene ontology terms, and a set of features was generated. In the second step, NLP techniques treated gene ontology terms as a word dictionary, creating numerical vectors using the bag of words (BoW), count vector, term frequency-inverse document frequency (TF-IDF), and information content methods. In the third step, different machine learning methods, including Decision Tree, Random Forest, Bagging-RepTree, Bagging-RF, BayesNet, Deep Neural Network (DNN), Logistic Regression, Support Vector Machine (SVM), and VotedPerceptron, were employed to predict protein interactions in the datasets. In the fourth step, the Max-Min Parents and Children (MMPC) feature selection algorithm was applied to improve predictions using fewer features. The performance of the developed method was tested on the SARS-CoV-2 protein interaction dataset. The MMPC algorithm reduced the feature count by over 99%, enhancing protein interaction prediction. After feature selection, the DNN method achieved the highest predictive performance, with an AUC of 0.878 and an F-Measure of 0.793. Sequence-based protein encoding methods AAC, APAAC, CKSAAPP, CTriad, DC, and PAAC were applied to proteins in the SARS-CoV-2 interaction dataset and their performance was compared with GO-NLP. The performance of the relevant methods was measured separately and combined. The highest performance was obtained from the combined dataset with an AUC value of 0.888. This study demonstrates that the proposed gene ontology and NLP approach can successfully predict protein-protein interactions for antiviral drug design with significantly fewer features using the MMPC-DNN model.},
  archive      = {J_APIN},
  author       = {Cihan, Pınar and Ozger, Zeynep Banu and Cakabay, Zeynep},
  doi          = {10.1007/s10489-024-06223-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Computational analysis of virus-host protein-protein interactions using gene ontology and natural language processing},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating cruise user satisfaction through online reviews: A method based on sentiment analysis and large-scale group decision-making. <em>APIN</em>, <em>55</em>(6), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06241-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online reviews of cruise tourism, as user-generated information, contain customers’ evaluations of various aspects of the cruise tourism industry. They influence the development of this industry by affecting potential users’ purchasing decisions. To promote the sustainable development of the cruise tourism industry, it is crucial to understand the factors influencing high user satisfaction and to ensure high levels of user satisfaction. With a focus on the factors influencing the cruise travel experience, this paper proposes a method for determining user requirements (URs) and evaluating user satisfaction with cruise tourism by integrating online review analysis with large-scale group decision-making (LSGDM). First, we establish a sentiment dictionary for the cruise domain based on online reviews, selecting seed sentiment words according to word frequency and expanding them using the Word2vec and semantic orientation using pointwise mutual information algorithms. Second, we use the latent Dirichlet allocation topic model to analyze online reviews and identify the 10 URs that are of actual concern to cruise customers. Then we perform dependency syntax analysis to conduct a fine-grained sentiment analysis of each review to identify the sentiment intensity values toward different cruise URs. Third, we evaluate the final satisfaction and ranking of URs using the LSGDM method, which includes a consensus model with a personalized feedback mechanism based on the minimum adjustment cost. We conclude by providing suggestions for improving the cruise tourism experience.},
  archive      = {J_APIN},
  author       = {Shi, Jing and Chen, Jing and Wu, Jian and Liu, Yujia},
  doi          = {10.1007/s10489-025-06241-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Evaluating cruise user satisfaction through online reviews: A method based on sentiment analysis and large-scale group decision-making},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predictive control approach incorporating incremental learning. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06243-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces Incremental Learning MPC (ILMPC), a novel Model Predictive Control (MPC) approach designed to enhance the adaptability of control systems in dynamic environments with unpredictable disturbances. Traditional MPC methods are often limited by their reliance on static models and fixed optimization schemes, making them less effective in handling disturbances and model inaccuracies. To overcome these limitations, ILMPC integrates incremental learning, enabling continuous refinement of the control model using real-time data. This innovation improves prediction accuracy and control performance, allowing the system to adapt to changing operational conditions and unknown disturbances. Key advances include the development of a sequence prediction model that continuously updates the state-space model through incremental learning, improved disturbance suppression for more stable control, and a reduction in computational complexity by incrementally model parameters. Experimental results show that ILMPC enhances deviation suppression significantly compared to conventional methods and significantly reduces control input volatility, demonstrating its superior performance in real-time disturbance suppression and adaptability.},
  archive      = {J_APIN},
  author       = {Chen, Jian and Pan, Haiwei and Zhang, Kejia and Lan, Haiyan and Xu, Xu and Luo, Wenhui},
  doi          = {10.1007/s10489-025-06243-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Predictive control approach incorporating incremental learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boundary-sensitive adaptive decoupled knowledge distillation for acne grading. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06260-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acne grading is a critical step in the treatment and customization of personalized therapeutic plans. Although the knowledge distillation architecture exhibits outstanding performance on acne grading task, the impact of non-label classes is not considered separately, resulting in low distillation efficiency for non-label classes. Such insufficiency will cause the misclassification of the acne images located on the edge of the decision boundary. To address this issue, a novel method named Adaptive Decoupled Knowledge Distillation (ADKD) which considers the uniqueness of the acne images is proposed. In order to explore the influence of non-label classes and enhance the model’s distillation efficiency on them, ADKD splits the traditional KD loss into two parts: non-label class knowledge distillation (NCKD), and label class knowledge distillation (LCKD). Additionally, it dynamically adjusts the NCKD based on the distance between the sample and each non-label class. This allows the model to allocate different learning intensities to various non-label classes, reducing the overrecognition of classes near the sample and the underrecognition of distant classes. The proposed method enables the model to better learn the fuzzy features between acne images, and more accurately classify the samples located on the decision boundary. To verify the proposed method, extensive experiments were carried out on ACNE04 dataset, ACNEHX dataset, and DermaMnist dataset. The experimental results demonstrate the effectiveness of this method, and its performance surpasses that of current state-of-the-art (SOTA) method.},
  archive      = {J_APIN},
  author       = {Zhou, Xinyang and Liu, Wenjie and Zhang, Lei and Zhang, Xianliang},
  doi          = {10.1007/s10489-025-06260-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Boundary-sensitive adaptive decoupled knowledge distillation for acne grading},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Facial StO2-based personal identification: Dataset construction, feasibility study, and recognition framework. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06267-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometrics have been extensively utilized in the realm of identity recognition. However, each biometric method has its inherent limitations in specific scenarios. For example, identity recognition based on facial images is contactless but can be forged; finger vein recognition is very secure but generally requires contact collection to ensure accurate identification. In some scenarios with high security requirements, there is often a need for contactless acquisition of biometric features that cannot be forged to recognize identity. Therefore, a novel biometric, facial tissue oxygen saturation (StO2) with the advantages of robust anti-spoofing capabilities and non-contact measurement, is proposed for identity recognition. To more comprehensively verify the feasibility of facial StO2 for identity recognition, a Facial StO2 Identity Dataset (FSID148) containing 148 identities is collected and the feasibility of facial StO2 identity recognition is validated by performing verification, close-set identification, and open-set identification tasks. In order to enhance the performance of facial StO2 identity recognition, an attention-guided contrastive learning framework that enables backbones to derive discriminative identity representations from both local and global facial StO2 regions is proposed. The method proposed has achieved accuracies of 96.11%, 94.60%, and 88.51% in the aforementioned tasks, positioning facial StO2 as a promising biometric for a wide array of application scenarios.},
  archive      = {J_APIN},
  author       = {Zhang, Zheyuan and Liu, Xinyu and Jia, Yingjuan and Zhou, Ju and Wang, Hanpu and Wang, Jiaxiu and Chen, Tong},
  doi          = {10.1007/s10489-025-06267-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Facial StO2-based personal identification: Dataset construction, feasibility study, and recognition framework},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mind the naive forecast! a rigorous evaluation of forecasting models for time series with low predictability. <em>APIN</em>, <em>55</em>(6), 1-27. (<a href='https://doi.org/10.1007/s10489-025-06268-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of time series forecasting, numerous machine learning studies have assessed the performance of new methods on highly volatile data from macroeconomics and finance. Unlike in other domains, where models are also compared to simpler statistical or naive baselines, they mostly compare the performance solely relative to other complex models. This approach may lead to limited conclusions and reduce the practical significance of the results, as it overlooks the unpredictability of some highly volatile time series in the datasets used. We apply state-of-the-art methods from time-series econometrics and machine learning, including autoregressive integrated moving average (ARIMA), exponential smoothing (ETS), Bayesian vector autoregressive model (BVAR), long-short term memory neural networks (LSTM), historical consistent neural networks (HCNN), deep vector autoregressive neural networks (DeepVAR), temporal fusion transformers (TFT), and extreme gradient boosting (XGBoost). Our results demonstrate that no method consistently outperforms the naive (no-change) forecast for highly volatile time series from two popular datasets containing exchange rates and stock prices, rendering comparative analysis between complex models less meaningful. In contrast, when applied to more predictable macroeconomic price indices, many of the methods significantly outperform naive forecasts. We find that the performance of machine learning models deteriorates more than that of statistical models for high-volatility time series. This study highlights the critical importance of using appropriate benchmark models, including cost-effective, simple approaches, on datasets that permit meaningful conclusions.},
  archive      = {J_APIN},
  author       = {Beck, Nico and Dovern, Jonas and Vogl, Stefanie},
  doi          = {10.1007/s10489-025-06268-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-27},
  shortjournal = {Appl. Intell.},
  title        = {Mind the naive forecast! a rigorous evaluation of forecasting models for time series with low predictability},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-tailed classification by efficient contrast learning with high quality and high relevance latent features. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06269-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning robust feature representations from long-tail distributed data is essential. Recently, contrastive learning has shown impressive progress in addressing long-tail learning challenges. While contrastive learning aims to optimize the lower bound of mutual information between feature distribution and label distribution, the previous approaches often substantially rely on less accurate and unrealistic assumptions about model distribution and overlook the long-tail nature of the instance space. Consequently, these methods fail to achieve a sufficiently tight lower bound. To address these concerns, we first propose a loss function derived from mini-Batch instance Features and Class Prototypes to construct a Conditional Gaussian mixture distribution (CGM-BF-CP), and prove its generalization ability from the perspective of generalization error upper bound. Then we create high quality and high relevance KNN graph to model relation between features. And propose a corresponding loss function, i.e., Graph based Contrast Learning Loss (GCLL). The feature information can be transferred between classes through this graph, so that the tail class features can be better learned. The experimental results on Cifar10/100-LT and ImageNet-LT show that our proposed model is competitive with the latest state-of-the-art methods. Our code is available at https://github.com/error030/CGM-BP-CP/tree/main .},
  archive      = {J_APIN},
  author       = {Yuan, Hong-li and Liu, Jian-wei},
  doi          = {10.1007/s10489-025-06269-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Long-tailed classification by efficient contrast learning with high quality and high relevance latent features},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision transformer-based generalized zero-shot learning with data criticizing. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06271-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized Zero-Shot Learning (GZSL) aims to enable accurate testing and recognition of unseen classes by utilizing training data from seen classes and leveraging attribute knowledge. However, GZSL faces a challenge wherein the model, trained solely on seen class data, tends to be biased towards recognizing visual features of seen classes, resulting in poorer recognition performance for unseen classes. To address this issue, we propose an approach called Vision Transformer-Based Generalized Zero-Shot Learning with Data Criticizing (ViT-DaCr). In order to obtain improved visual features, we thoroughly examine features extracted by Vision Transformer (ViT) with a new design. Additionally, we recognize that not all training data align with our model during the training process, leading the model to exhibit a bias towards recognizing visual features of seen classes and directly impacting visual feature recognition. Therefore, we propose a data critic mechanism that utilizes Adjusted Boxplot to filter out such data automatically during the training process. Extensive experiments demonstrate the advanced performance of our model on three challenging and popular datasets.},
  archive      = {J_APIN},
  author       = {Zhou, Quan and Liang, Yucuan and Zhang, Zhenqi and Cao, Wenming},
  doi          = {10.1007/s10489-025-06271-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Vision transformer-based generalized zero-shot learning with data criticizing},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Dynamic interactive weighted feature selection using fuzzy interaction information. <em>APIN</em>, <em>55</em>(6), 1. (<a href='https://doi.org/10.1007/s10489-025-06273-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Ma, Xi-Ao and Xu, Hao and Liu, Yi},
  doi          = {10.1007/s10489-025-06273-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Correction to: Dynamic interactive weighted feature selection using fuzzy interaction information},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PTLO: A model-agnostic training strategy based on progressive training and label optimization for fine-grained image classification. <em>APIN</em>, <em>55</em>(6), 1-11. (<a href='https://doi.org/10.1007/s10489-025-06276-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to conventional image recognition, fine-grained classification exhibits increased vulnerability to labeling noise due to the presence of closely related categories, resulting in degraded performance on complex and non-representative samples. While existing approaches mitigate these issues through data cleaning, loss modification, and semi-supervised learning techniques, they often overlook the intrinsic attributes within training samples. Instead of designing any network architectures, this study introduces a model-agnostic progressive training strategy comprising of progressive training and label optimization, where the former is to decrease the affect from the noisy samples by facilitating a graduated learning approach in an easy-to-hard manner, while the latter is to denoise the label noises. Theoretical analysis also demonstrates that the proposed method uncovers valuable cues hidden in the training data, thereby enhancing the robustness of any learning-based models. Experimental evaluations on fine-grained classification benchmarks (e.g., CUB-200-2011, DTD, and Food-101) across various mainstream classification networks demonstrate the effectiveness of our training strategy. Code is available at https://github.com/cb-rep/LPPT .},
  archive      = {J_APIN},
  author       = {Chen, Yiming and Tao, Xiuting and Chen, Bo and Guo, Jian and Li, Shi},
  doi          = {10.1007/s10489-025-06276-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-11},
  shortjournal = {Appl. Intell.},
  title        = {PTLO: A model-agnostic training strategy based on progressive training and label optimization for fine-grained image classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-contextual stress prediction: Simple methodology for comparing features and sample domain adaptation techniques in vital sign analysis. <em>APIN</em>, <em>55</em>(6), 1-26. (<a href='https://doi.org/10.1007/s10489-025-06277-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stress significantly impacts individuals, particularly in professions like nursing and driving, leading to severe health risks and accidents. Accurate stress measurement is critical for effective interventions, yet research is hindered by incomplete datasets and inconsistent methodologies, slowing the development of reliable predictive models. This paper introduces a framework for cross-contextual stress prediction, enabling the generation of general stress prediction models adaptable to specific domain challenges. The methodology leverages two general daily life datasets and three domain-specific datasets, employing steps such as dataset selection, feature extraction, significant feature identification, feature preprocessing, fine-tuning, domain adaptation, and application to specific contexts. Through this framework, key vital signs were identified as significant predictors of stress, including electrocardiography (ECG), heart rate (HR), heart rate variability (HRV) - low frequency (LF), electrodermal activity (EDA), body temperature (TEMP), and skin conductance response (SCR). The experiments conducted include: 1) Utilizing HR and HRV-LF through domain adaptation from general to automobile driving datasets; 2) Applying EDA, HR, and TEMP from general to specific nurse activity datasets; and 3) Adapting ECG, HR, and TEMP from general to automobile driving datasets. Results demonstrate the potential of the proposed framework for cross-contextual stress prediction, with HR and HRV-LF identified as pivotal features. When applied to target datasets specific to stress scenarios, the model achieved a 62% F1 score, demonstrating the effectiveness of the feature-based Correlation Alignment (CORAL) technique combined with Random Forest models in transferring learned knowledge across domains. These findings highlight the robustness of the approach in adapting general stress prediction models to specific contexts, paving the way for real-world applications such as stress monitoring in driving and nursing during high-stress periods like COVID-19.},
  archive      = {J_APIN},
  author       = {Mihirette, Samson and De la Cal, Enrique A. and Tan, Qing and Sedano, Javier},
  doi          = {10.1007/s10489-025-06277-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Cross-contextual stress prediction: Simple methodology for comparing features and sample domain adaptation techniques in vital sign analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised feature learning using locality-preserved auto-encoder with complexity-invariant distance for intelligent fault diagnosis of machinery. <em>APIN</em>, <em>55</em>(6), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06278-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature learning (UFL) has been recognized as a promising feature extractor in machinery fault diagnosis, where the auto-encoder is a very popular UFL framework. For the auto-encoder methods, however, it is still a great challenge to learn discriminative features from complex signals in an unsupervised manner. In this paper, a new UFL method named locality-preserved auto-encoder (LPAE) is proposed by explicitly designing a locality-preserved penalty term. Concretely, the penalty term constrains local geometry of samples in the original space to be well preserved in the reconstruction space, enabling more discriminative features to be learned accordingly. To better formulate this term, the complexity-invariant distance (CID) is employed to measure similarity between two mechanical signals so as to construct a reliable neighbor graph. On a rolling bearing dataset, experimental results verify that the proposed LPAE can learn sufficiently discriminative features from complex vibration signals collected from varying operating conditions, and achieves a remarkable and superior diagnosis performance over the existing advanced UFL methods. Moreover, the effectiveness of CID has been adequately validated by comparing with several other distance measurement methods. The proposed LPAE can be applied to the feature extraction stage of machinery fault diagnosis, which provides a potential solution for engineers to realize unsupervised learning of discriminative features.},
  archive      = {J_APIN},
  author       = {Lu, Zhenghua and Chu, Zhaobi and Zhu, Min and Dong, Xueping},
  doi          = {10.1007/s10489-025-06278-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Unsupervised feature learning using locality-preserved auto-encoder with complexity-invariant distance for intelligent fault diagnosis of machinery},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised symmetric non-negative matrix factorization with graph quality improvement and constraints. <em>APIN</em>, <em>55</em>(6), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06282-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symmetric non-negative matrix factorization (SNMF) decomposes a similarity matrix into the product of an indicator matrix and its transpose, allowing clustering results to be directly extracted from the indicator matrix without additional clustering methods. Furthermore, SNMF has been shown to be effective in clustering nonlinearly separable data. SNMF-based clustering methods significantly depend on the quality of the pairwise similarity matrix, yet their effectiveness is often hindered by the reliance on predefined matrices in most semi-supervised SNMF approaches. Thus, we propose a novel algorithm, named semi-supervised symmetric non-negative matrix factorization with graph quality improvement and constraints ( $$\text {S}^{3}\text {NMFGC}$$ ), addressing this limitation by employing an integrated clustering strategy that dynamically generates and adaptively updates the similarity matrices. This is accomplished by integrating a weighted graph construction based on multiple clustering results, a label propagation algorithm, and pairwise constraint terms into a unified optimization framework that enhances the semi-supervised SNMF model. Subsequently, we adopt an alternating iterative update method to solve the optimization problem and prove its convergence. Rigorous experiments highlight the superiority of our model, which outperforms seven state-of-the-art NMF methods across six datasets.},
  archive      = {J_APIN},
  author       = {Ren, Xiaowan and Yang, Youlong},
  doi          = {10.1007/s10489-025-06282-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Semi-supervised symmetric non-negative matrix factorization with graph quality improvement and constraints},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph denoising neural network for session-based recommendation. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06283-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation (SBR) predicts the next interaction of users based on their clicked items in a session. Previous studies have shown that hypergraphs are superior in capturing complex item transitions which contribute to SBR performance. However, existing hypergraph-based methods fail to model item co-occurrence and sequential patterns simultaneously, limiting the improvement of recommendation performance. Moreover, they are more sensitive to noisy items than conventional graph models due to the item association mechanism. In this paper, we propose a novel hypergraph-based method named Hypergraph Denoising Neural Network (HDNN) for SBR to tackle the abovementioned problems. The proposed method involves two newly-designed modules: a sequential pattern learning module (SPLM) and an adaptive attention selection module (AASM). In particular, SPLM models item sequential patterns to complement the hypergraph-based models which only focus on co-occurrence patterns. Meanwhile, AASM employs learnable attention score thresholds to exclude items with low attention scores, mitigating the impact of noisy items in hypergraphs. Furthermore, the sequential denoising unit (SDU) designed in SPLM is employed to eliminate noise in item sequential patterns, thus realizing the dual denoising purpose. Extensive experiments are conducted on three real-world datasets. The results of the experiments show that our HDNN framework shows better performance than the state-of-the-art models. In particular, all evaluation metrics in Tmall and RetailRocket showed improvements of over 15% and 5%, respectively.},
  archive      = {J_APIN},
  author       = {Ding, Jiawei and Tan, Zhiyi and Lu, Guanming and Wei, Jinsheng},
  doi          = {10.1007/s10489-025-06283-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Hypergraph denoising neural network for session-based recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking probability volume for multi-view stereo: A probability analysis method. <em>APIN</em>, <em>55</em>(6), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06284-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing learning-based multi-view stereo (MVS) models primarily focus on predicting depth maps through a cascaded structure to achieve more robust reconstruction results. However, they often emphasize improving the quality of stereo matching while overlooking the importance of depth hypotheses. In this paper, we propose a novel MVS model from the perspective of probability volume analysis. First, the guiding effect of the probability volume is considered for depth refinement. Ideally, the probability distribution along the depth dimension of the probability volume follows an unimodal pattern. We design an unimodal curve to fit this pattern. Then, a reasonable depth refinement range is adaptively selected for each pixel position based on a predefined probability threshold. Additionally, considering that matching noise may cause the probability volume to appear as a blurred unimodal peak, we design the probability volume split-merge module (PVS-PVM). This module performs a peak search based on conditional constraints, splitting the probability volume into main and sub probability volumes, then computes the two sets of depth hypotheses from them. Finally, the new main and sub probability volumes are computed based on these depth hypotheses and merged to predict the depth. This approach allows for a more comprehensive consideration of the regions with higher probability, improving the robustness of depth hypotheses. Experimental results demonstrate that our method effectively utilizes probability volume information to guide depth map refinement and yields enhanced reconstruction results on the DTU and Tanks & Temples datasets. Our code will be released at https://github.com/zongh5a/ProbMVSNet .},
  archive      = {J_APIN},
  author       = {Yu, Zonghua and Wang, Huaijun and Li, Junhuai and Jin, Haiyan and Cao, Ting and Cheng, Kuanhong},
  doi          = {10.1007/s10489-025-06284-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Rethinking probability volume for multi-view stereo: A probability analysis method},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). You are what your feeds make you: A study of user aggressive behavior on twitter. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06286-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread use of aggressive language on Twitter raises concerns about potential negative influences on user behavior. Despite previous research exploring aggression and negativity on the platform, the relationship between consuming aggressive content and users’ aggressive behavior remains underexplored. This study investigates whether exposure to aggressive content on Twitter can lead users to behave more aggressively. Our methodological approach contains four stages: data collection and annotation, aggressive post detection, user aggression intensity metric, and user profiling. We proposed the English Twitter Aggression dataset (TAG-EN) with substantial inter-annotator agreement (Krippendorff’s alpha=0.78). Subsequently, we benchmark the aggression detection performance on TAG-EN dataset (macro F1=0.92) by fine-tuning a pre-trained RoBERTa-large. We quantified user aggression with a proposed “user aggression intensity” metric based on their overall aggressive activity. Our analysis of 14M posts from 63K users revealed that aggressive Twitter feeds can influence users to behave more aggressively online. Furthermore, the study found that users tend to support and encourage aggressive content on social media, which can contribute to the proliferation of aggressive behavior.},
  archive      = {J_APIN},
  author       = {Mane, Swapnil and Kundu, Suman and Sharma, Rajesh},
  doi          = {10.1007/s10489-025-06286-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {You are what your feeds make you: A study of user aggressive behavior on twitter},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view learning based on product and process metrics for software defect prediction. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06288-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software defect prediction plays a crucial role as a quality assurance technology in software development. The software metrics are associated with the software quality and are vital for prediction models. Most existing defect prediction methods build the prediction model ignoring the complementary information between these two kinds of metrics. In this work, we intend to jointly leverage these two kinds of metrics. For a software instance, we regard the product metrics and the process metrics as its two views. We model the problem of discriminative feature learning from these two kinds of metrics as the problem of multi-view learning. However, it is a challenging task to construct an effective prediction model based on both product and process metrics due to the heterogeneity in data of product and process metrics, and the defect data often has class imbalance characteristic. How to explore the discriminant both inter-view and intra-view effectively has not been well studied. These characteristics make it challenging to construct an effective prediction model. In this paper, we propose a Deep Multi-view Defect Prediction (DMDP) approach, which can predict software defect based on both product and process metrics. We design a neural network with two sub-network branches, which are enforced to share the weights in the last output layer, to map the data from different views to a common space. To guide the training of networks, we design the loss function including the discrepancy loss, discrimination loss and classification loss, which further promotes the distribution consistency across views, makes full use of label information to obtain the discriminative representations, and utilizes the complementarity information for prediction. To alleviate the class imbalance problem, we design a dynamic sampling strategy for dealing with class-imbalanced data. Comprehensive experiments are conducted on 15 projects from three widely used defect datasets. The experimental results demonstrate that multi-view learning based on product and process metrics is helpful for software defect prediction and DMDP outperforms the state-of-the-art baselines.},
  archive      = {J_APIN},
  author       = {Sun, Ying and Wu, Fei and Wu, Di and Jing, Xiao-Yuan and Sun, Yanfei},
  doi          = {10.1007/s10489-025-06288-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Multi-view learning based on product and process metrics for software defect prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A user preference knowledge graph incorporating spatio-temporal transfer features for next POI recommendation. <em>APIN</em>, <em>55</em>(6), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06290-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs can improve the performance of recommendation systems and provide explanations for recommendation results, which have been widely applied in the next Point-of-Interest (POI) recommendation. However, the current knowledge graph method for the next POI recommendation focuses on the static attributes of POIs, and only describes the spatio-temporal characteristics when the user transfers between POIs. To fully tap into user preferences for different POIs, we have done the following innovative work. (1) We construct a user preference knowledge graph with spatio-temporal characteristics, named UPSTKG, which expresses preference information from both individual user and global user perspectives. (2) We use local preference triplets in preference knowledge graphs to construct user preference graphs. And use GCN to obtain user preference vectors to replace common user vectors in the sequence, thereby strengthening the potential connection between users and different POIs. (3) We combine UPSTKG and user preference graph to propose the UPSTKGRec method for the next POI recommendation. To evaluate the effectiveness of UPSTKGRec, it is compared to six highly regarded techniques on three distinct benchmark datasets. Compared with the baseline, the average performance of indicators recell@5 and NDCG@5 has increased by 13.8% and 13.1%.},
  archive      = {J_APIN},
  author       = {Sang, Chun-Yan and Yang, Yang and Zhang, Yi-Bo and Liao, Shi-Gen},
  doi          = {10.1007/s10489-025-06290-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {A user preference knowledge graph incorporating spatio-temporal transfer features for next POI recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive sparsity detection-based evolutionary algorithm for large-scale sparse multi-objective optimization problems. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06291-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale sparse multi-objective optimization problems (LSSMOPs) widely exist in practical applications, which have large-scale decision variables and sparse Pareto optimal solutions. Existing algorithms have some shortcomings in dealing with LSSMOPs: (1) failing to make full use of the knowledge of the sparsity of the Pareto optimal solutions, leading to insufficient sparsity detection; (2) ignoring the connection between binary and real variables, leading to insufficient variables optimization. This paper proposes an adaptive sparsity detection-based evolutionary algorithm (ASD-MOEA) to address these issues, which is a two-stage algorithm. The first stage performs an adaptive sparsity detection strategy, which dynamically adjusts the probability of binary variables flipping and the fitness of decision variables according to the iteration ratio. Then, non-zero variables are mined based on fitness. The second stage performs a variable grouping-based optimization strategy, grouping decision variables according to their sparsity in the set of non-dominated solutions to reduce the search space, then performs genetic operations in the subspace. Finally, we compare ASD-MOEA with six mainstream algorithms. The results show that the proposed algorithm significantly outperforms the existing algorithms in dealing with LSSMOPs, and achieves a balance between sparsity maintenance and variable optimization.},
  archive      = {J_APIN},
  author       = {Qiu, Feiyue and Long, Donghui and Chen, Qi and Hu, Huizhen and Qiu, Qicang},
  doi          = {10.1007/s10489-025-06291-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive sparsity detection-based evolutionary algorithm for large-scale sparse multi-objective optimization problems},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TITD: Enhancing optimized temporal position encoding with time intervals and temporal decay in irregular time series forecasting. <em>APIN</em>, <em>55</em>(6), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06293-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate Time Series (MTS) acquisition processes often exhibit irregularities, making accurate MTS forecasting challenging. Previous researches focused on interpolation approaches to address data completeness in irregular MTS, but these approaches may introduce noise, thereby altering the feature distributions of irregular MTS. Recent researches trend advocate embedding the missing temporal information through position encoding for forecasting irregular MTS. However, these position encodings were typically designed for text sequences and assumed fixed time intervals, which lead to the loss or distortion of temporal information when applied to irregular MTS. Moreover, they struggled to capture the temporal dynamic information in irregular MTS. To address these challenges, we propose a novel approach called TITD (Time Interval and Temporal Decay), which utilizes time interval and temporal decay information to enhance irregular MTS forecasting. TITD optimizes position encoding to effectively capture both local time interval features and long-term temporal decay patterns, breaking the limitations of static and fixed interval position encoding on time dynamic representation. Simultaneously, TITD integrates multi-view input information from irregular MTS to enhance the representation learning of the relationships across different views, thereby achieving superior forecasting performance without interpolation. Extensive experiments on three real-world time series datasets have demonstrated that TITD provides significant improvements over state-of-the-art methods in irregular MTS forecasting.},
  archive      = {J_APIN},
  author       = {Ji, Jinquan and Cao, Yu and Ma, Yukun and Yan, Jianzhuo},
  doi          = {10.1007/s10489-025-06293-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {TITD: Enhancing optimized temporal position encoding with time intervals and temporal decay in irregular time series forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rail-PatchCore: Unsupervised learning-based detection of visual anomalies in the railway-turnout environment. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06294-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity and openness of railway turnout environments pose great challenges to anomaly detection, and supervised methods are highly dependent on labels, making it difficult to address the diverse types of anomalies and the scarcity of samples in turnout environments. To solve these problems, this paper proposes a new method, Rail-PatchCore, which is based on unsupervised learning and effectively reduces the interference of background noise and enhances the ability to capture anomalous features by adding a Dual-Dimensional Channel Attention (DDCA) module and a projection anomaly scoring module to the PatchCore model. The experiments on our railway-turnout anomaly detection dataset(RTAD) and other datasets (RSDDs, MVTec-AD, BTAD, AEBAD-S) show that the detection performance of Rail-PatchCore is better than that of the existing methods, and the image-level and pixel-level AUCROC indices of Rail-PatchCore on the railway turnout anomaly detection dataset reach 72.2% and 95.3%, respectively. This approach provides an efficient and reliable solution for anomaly detection in railway turnout environments.},
  archive      = {J_APIN},
  author       = {Zhang, YuanHao and Yu, Zujun and Zhu, Liqiang and Guo, Baoqing and Wang, Yao},
  doi          = {10.1007/s10489-025-06294-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Rail-PatchCore: Unsupervised learning-based detection of visual anomalies in the railway-turnout environment},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view human point cloud registration method with overlapping regions semantic constraints and feature weighting. <em>APIN</em>, <em>55</em>(6), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06296-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view human point cloud registration is a crucial step in 3D human reconstruction tasks. The symmetric structures and similar geometric features in human point clouds often lead to feature mismatches in point cloud registration. Therefore, we propose a pipeline for game tree registration based on semantic constraints and feature weighting (GTR-SCFW) that enhances the stability and accuracy of feature matching, thereby improving the registration precision of multi-view point clouds. First, we calculate and compare the feature similarity between multi-view point clouds and use a generalized best-first search (BFS) method to construct a multi-layered registration game tree. At each game node, overlapping regions are divided into multiple sub-regions based on semantic information, and global fast registration is used to determine the matching relationships of features within each sub-region. Then, the best matching points in each sub-region are selected based on the confidence of feature pairs, and the weights of all the best point pairs are calculated. Finally, the initial rigid transformation matrix is computed using weighted least squares (WLS), and ICP is employed to achieve fast fine registration. GTR-SCFW effectively avoids incorrect matching relationships caused by geometric feature similarity during the initial transformation estimation, providing a good initial pose for iterative closest point (ICP) fine registration. For point clouds with different initial poses, the registration’s rotational error approaches 0 $$^\circ $$ , while the translational error is as low as 1.203e-4 mm. Comparative experimental results show that this method outperforms existing feature-based registration methods regarding robustness, reliability, and computational efficiency.},
  archive      = {J_APIN},
  author       = {Li, Ming and Li, Guiqin and Li, Xihang and Li, Tiancai},
  doi          = {10.1007/s10489-025-06296-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Multi-view human point cloud registration method with overlapping regions semantic constraints and feature weighting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A complex history browsing text categorization method with improved BERT embedding layer. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06298-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For long texts composed of multiple short fragments, the importance of each fragment to the classification task varies. Some fragments have higher discriminative power and positively contribute to the classification, while others lack discriminative power or even mislead it. Existing methods struggle to converge when handling texts with negative examples. This study analyzes user behavior and assigns interest scores to text fragments based on their classification relevance, allowing the model to focus more on important fragments. Building on bidirectional encoder representations from transformers (BERT), we propose an interest encoding layer model for historical browsing texts. By analyzing user behavior and incorporating an improved term frequency-inverse document frequency (TF-IDF) method, the model adds indicators to fragments with higher discriminative power for user behavior analysis, enabling the model to focus more on these during training. Finally, comparative experiments on the BERT model series validate the advantages of the proposed approach.},
  archive      = {J_APIN},
  author       = {Wang, Yuanhang and Zhou, Yonghua and Qi, Huiyu and Wang, Dingyi and Huang, Annan},
  doi          = {10.1007/s10489-025-06298-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {A complex history browsing text categorization method with improved BERT embedding layer},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An end-to-end audio classification framework with diverse features for obstructive sleep apnea-hypopnea syndrome diagnosis. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06299-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obstructive sleep apnea-hypopnea syndrome (OSAHS) is a prevalent chronic disorder that affects sleep quality and general health. The current diagnostic methods, primarily polysomnography (PSG), are laborious. Furthermore, audio-based methods for diagnosing OSAHS face limited sample sizes and neglect patients’ physiological signs and medical histories. To address these challenges, we introduce a data-driven framework called DFNet, which also considers patients’ medical histories and health indicators. DFNet incorporates an automated audio segmentation- and labeling-based preprocessing procedure to reduce expert annotation costs and subjective errors. We employed random convolutional kernels based on receptive fields for audio feature extraction purposes. These kernels captured both local and global features within the input audio. Additionally, for the first time, we introduced a medical language model that utilizes patients’ medical histories and physiological information as covariates to enhance features. We extensively validated DFNet on an OSAHS dataset obtained from a collaborative university hospital. Our framework classified patients into four categories according to their OSAHS severity: normal, mild, moderate, and severe. DFNet achieved state-of-the-art performance, with a four-class accuracy of 84.12%. DFNet offers a large-scale and cost-effective screening approach for diagnosing OSAHS, reducing the labor requirements of diagnosis. Our code is available at https://github.com/testlbin/DFNet .},
  archive      = {J_APIN},
  author       = {Li, Bin and Qiu, Xihe and Tan, Xiaoyu and Yang, Long and Tao, Jing and Fang, Zhijun and Huang, Jingjing},
  doi          = {10.1007/s10489-025-06299-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {An end-to-end audio classification framework with diverse features for obstructive sleep apnea-hypopnea syndrome diagnosis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple instance learning with hierarchical discrimination and smoothing attention for histopathological diagnosis. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06300-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The microscopic structure of human tissue can be observed by pathological slides, which provides a strong basis for cancer diagnosis. However, the serious lack of experienced pathologists and the complexity of the diagnostic process have facilitated the development of computer-aided pathological image analysis. Pathological slides generally have high resolution, and multiple instance learning (MIL) has been widely used in histopathological whole slide image (WSI) analysis, where each WSI has a large number of unlabelled patches and only a WSI-level label is given. The bag-based MIL methods often learn the decision boundary at the bag level, and thus hard to learn the discriminative features at the instance level. Furthermore, the difficulty of identification varies between positive instances in a bag, and the existing attention-based aggregation methods always assign higher attention scores for the easy-to-identify positive instances, but assign lower attention scores for the difficult-to-identify positive instances and thus cannot learn these difficult instances sufficiently. In this paper, we propose a novel MIL method with hierarchical discrimination learning and a smoothing attention strategy for cancer subtype diagnosis. Particularly, to learn hierarchical discriminative features, the proposed MIL method simultaneously trains a bag classifier and multiple instance classifiers, where the multi-way attention scores of each instance for different categories are used to guide the selection of training samples for the instance classifimer. The smoothing strategy is designed to trade off the attention weights between the easily and hardly identifiable positive instances. We conducted experiments on histopathological diagnosis datasets and achieved state-of-the-art performance. Codes are available at https://github.com/bravePinocchio/HDSA-MIL.},
  archive      = {J_APIN},
  author       = {Zhao, Jing and Zhao, Zhikang and Song, Xueru and Sun, Shiliang},
  doi          = {10.1007/s10489-025-06300-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Multiple instance learning with hierarchical discrimination and smoothing attention for histopathological diagnosis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complex layout generation for large-scale floor plans via deep edge-aware GNNs. <em>APIN</em>, <em>55</em>(6), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06311-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In architectural layout generation, deep learning techniques have advanced the residential generation in multiple scenarios. However, current approaches fail to extract complex graph features from large-scale layouts, neglecting large-scale global context. Additionally, the lack of robust, quantitative evaluation metrics for layouts hampers the objective comparison of different generative approaches. To address these issues, we propose a multi-scale applicable layout generation method based on deep edge-aware GNNs, stressing edge-specific and non-local spatial information. Next, we introduce quantitative metrics to assess layout quality, including room accessibility index and space property proportion, whose purpose is to establish layout standards in the computer-aided design field. Lastly, we create the Public Space Floor Plan Dataset (P-PLAN), a collection of 4,535 annotated layout samples designed to serve as a robust evaluation platform for large-scale layout models. We conducted extensive qualitative and quantitative experiments on the Residential Floor Plan Dataset (R-PLAN) and P-PLAN dataset to demonstrate the effectiveness of the proposed method. Notably, with the proposed evaluation metrics, our method significantly outperforms existing models in accessibility and diversity.},
  archive      = {J_APIN},
  author       = {Lu, Zhengyang and Li, Yifan and Wang, Feng},
  doi          = {10.1007/s10489-025-06311-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Complex layout generation for large-scale floor plans via deep edge-aware GNNs},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-attention fusion and edge-guided fully supervised contrastive learning network for rail surface defect detection. <em>APIN</em>, <em>55</em>(6), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06314-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been significant research focus on efficiently and accurately detecting defects on rail surfaces using computer vision. Utilizing depth information from the rail surface has emerged as an effective approach for detecting visually insignificant types of defects that are unique in nature. However, previous methods have typically overlooked the long-distance dependency between the two modalities when fusing them using conventional convolutional network methods. Additionally, these methods have often relied on traditional cross-entropy loss for edge supervision without considering the intra and inter-pixel relationships associated with edge features. To address these limitations, we propose a novel approach called CECLNet (cross-attention fusion and edge-guided fully supervised contrastive learning network) for rail surface defect detection (RSDD). The proposed CECLNet incorporates a module for inter-modal cross-attention fusion, which effectively explores the complementary information by considering the long-range relationship. Furthermore, we introduce a progressive aggregation-based multiscale feature interactions decoder to promote sufficient information interaction between multiscale features, thus facilitating the generation of final predictions. Finally, we propose a pixel-level fully supervised contrastive learning approach to enhance the efficiency of utilizing edge-assisted information. Extensive experiments conducted on the industrial NEU RGB-D RSDDS-AUG dataset demonstrate the superiority of our proposed CECLNet over 17 state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Yang, Jinxin and Zhou, Wujie},
  doi          = {10.1007/s10489-025-06314-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Cross-attention fusion and edge-guided fully supervised contrastive learning network for rail surface defect detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamically modulated robot compliance via online fuzzy neural networks for individualized ankle rehabilitation. <em>APIN</em>, <em>55</em>(6), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06317-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Admittance control, benefiting from human-robot interaction compliance, is widely used in rehabilitation robot studies. However, using inappropriate parameters for the admittance control model can cause harm like overuse syndrome. Therefore, it is necessary to dynamically adjust these parameters to assist patients under varying recovery periods, enabling active rehabilitation training across a wider range of recovery stages. Integrating multiple intelligent approaches presents a promising solution to this challenge. This paper proposes a variable admittance control strategy that employs a variable operator fuzzy neural network (VAC-VOFNN). The VOFNN facilitates the fuzzification of the inference process, leading to superior non-linear fitting capability. Additionally, the network’s parameters are updated online to match the rehabilitation stages of different subjects. Compared to the admittance control strategy with fixed parameters (ACS-FP) and the variable admittance control strategy with fuzzy neural networks (VAC-FNN), the proposed strategy reduces the root mean square (RMS) of surface electromyography (sEMG) from the medial gastrocnemius by 29.14% and 29.04%, respectively, while also decreasing the average interaction torque by 28.63% and 12.24%, respectively. These results suggest that the proposed strategy leads to reduced effort from subjects and increased training cycles before muscle fatigue during the same rehabilitation activities. This makes it beneficial for ankle rehabilitation of patients in different recovery periods.},
  archive      = {J_APIN},
  author       = {Li, Jianfeng and Zhou, Yu and Zuo, Shiping and Dong, Mingjie},
  doi          = {10.1007/s10489-025-06317-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Dynamically modulated robot compliance via online fuzzy neural networks for individualized ankle rehabilitation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust decision-making for autonomous vehicles via deep reinforcement learning and expert guidance. <em>APIN</em>, <em>55</em>(6), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06319-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate decision-making within highly interactive driving environments is vital for the safety of self-driving vehicles. Despite the significant progress achieved by the existing models for autonomous vehicle decision-making tasks, there remains untapped potential for further exploration in this field. Previous models have focused primarily on specific scenarios or single tasks, with inefficient sample utilization and weak robustness problems, making them challenging to apply in practice. Motivated by this, a robust decision-making method named DRL-EPKG is proposed, which enables the simultaneous determination of vertical and horizontal behaviors of driverless vehicles without being limited to specific driving scenarios. Specifically, the DRL-EPKG integrates human driving knowledge into a framework of soft actor-critic (SAC), where we derive expert policy by a generative model: variational autoencoders (VAE), train agent policy by employing the SAC algorithm and further guide the behaviors of the agent by regulating the Wasserstein distance between the two policies. Moreover, a multidimensional reward function is designed to comprehensively consider safety, driving velocity, energy efficiency, and passenger comfort. Finally, several baseline models are employed for comparative evaluation in three highly dynamic driving scenarios. The findings demonstrate that the proposed model outperforms the baselines regarding the success rate, highlighting the practical applicability and robustness of DRL-EPKG in addressing complex, real-world problems in autonomous driving.},
  archive      = {J_APIN},
  author       = {Li, Feng-Jie and Zhang, Chun-Yang and Chen, C. L. Philip},
  doi          = {10.1007/s10489-025-06319-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Robust decision-making for autonomous vehicles via deep reinforcement learning and expert guidance},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chaotic opposition-based plant propagation algorithm for engineering problem. <em>APIN</em>, <em>55</em>(6), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06320-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Plant Propagation Algorithm (PPA), often exemplified by the Strawberry Algorithm, has demonstrated its effectiveness in solving lower-dimensional optimization problems as a neighborhood search algorithm. While multiple enhancements have been introduced to boost its performance, PPA remains a population-based metaheuristic algorithm. A key element of PPA involves balancing exploration and exploitation, akin to a strawberry plant seeking the best survival strategy. This paper delves into the integration of chaotic numbers and opposition theory in PPA, focusing on how these additions impact its efficiency. The primary research questions revolve around enhancing PPA’s performance and reducing its search space to expedite the algorithm, ultimately leading to faster overall results. Experiments were carried out on three challenging engineering problems: the Pressure Vessel Optimization, the Spring Design Optimization, and the Welded Beam Problem, to fully assess the effectiveness of the improved PPA. The effectiveness of the original PPA, the Chaotic Opposition-Based PPA (COPPA), and several other metaheuristic algorithms were examined in each of these problems. In terms of efficiency and solution quality, the findings consistently demonstrate that COPPA performs better than the traditional PPA and other algorithms. The results indicate that using chaotic-based oppositional processes decreases the search space and enhances performance, resulting in faster and more resource-efficient optimization. The investigation reveals that incorporating chaotic-based oppositional PPA yields improved results while conserving resources and accelerating execution.},
  archive      = {J_APIN},
  author       = {Suny, Alfe and Liza, Maimuna Akter and Fahim, Md. and Reza, Ahmed Wasif and Siddique, Nazmul},
  doi          = {10.1007/s10489-025-06320-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Chaotic opposition-based plant propagation algorithm for engineering problem},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep random walk inspired multi-view graph convolutional networks for semi-supervised classification. <em>APIN</em>, <em>55</em>(6), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06322-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies highlight the growing appeal of multi-view learning due to its enhanced generalization. Semi-supervised classification, using few labeled samples to classify the unlabeled majority, is gaining popularity for its time and cost efficiency, particularly with high-dimensional and large-scale multi-view data. Existing graph-based methods for multi-view semi-supervised classification still have potential for improvement in further enhancing classification accuracy. Since deep random walk has demonstrated promising performance across diverse fields and shows potential for semi-supervised classification. This paper proposes a deep random walk inspired multi-view graph convolutional network model for semi-supervised classification tasks that builds signal propagation between connected vertices of the graph based on transfer probabilities. The learned representation matrices from different views are fused by an aggregator to learn appropriate weights, which are then normalized for label prediction. The proposed method partially reduces overfitting, and comprehensive experiments show it delivers impressive performance compared to other state-of-the-art algorithms, with classification accuracy improving by more than 5% on certain test datasets.},
  archive      = {J_APIN},
  author       = {Chen, Zexi and Chen, Weibin and Yao, Jie and Li, Jinbo and Wang, Shiping},
  doi          = {10.1007/s10489-025-06322-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Deep random walk inspired multi-view graph convolutional networks for semi-supervised classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overview of the application of intelligent optimization algorithms in multi-attribute group decision making. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06324-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent Optimization Algorithms (IOAs) have great potential in solving multi-attribute group decision-making (MAGDM) problems. These problems have gradually become a research hotspot in the field of intelligent decision-making due to their advantages of high decision-making accuracy, versatility, and objective evaluation. This study provides a detailed analysis of the challenges in the MAGDM process and evaluates the feasibility of applying IOAs in this context. Specifically, we study the application of IOAs in the MAGDM process and discuss the advantages and limitations across various application scenarios, including the applications of granulating linguistic information, adjusting decision information, optimizing weights, and aggregating decision information. In addition, the development prospects and challenges of IOAs integration with MAGDM are summarized.},
  archive      = {J_APIN},
  author       = {Kang, Kaiying and Xie, Jialiang and Liu, Xiaohui and Wang, Honghui},
  doi          = {10.1007/s10489-025-06324-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Overview of the application of intelligent optimization algorithms in multi-attribute group decision making},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MVSRF: Point cloud semantic segmentation and optimization method for granular construction objects. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06326-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying shapeless granular materials in complex construction scenarios is critical for achieving automation in engineering equipment such as wheel loaders. The challenges of segmenting point clouds for granular materials involve dealing with sparsity, real-time processing requirements, the lack of distinct shape representation, and the issue of different materials sharing similar shapes. This paper proposes MVSRF, a real-time multi-view based point cloud semantic segmentation method incorporating a single-frame re-segmentation component and a multi-frame semantic filter to enhance accuracy and robustness. First, the segmentation system generates a sparse pixel-depth grid map via semantic projection to encapsulate global points and their behaviors, while employing an edge detector to label boundary points around objects. Second, a zero-shot re-segmentation algorithm involving seed extension, novel one-dimensional DBSCAN, Delaunay triangulation, and semantic reassignment corrects mis-segmented points caused by mapping bias. Finally, a lightweight semantic filter is designed to suppress semantic noise during multiple observations. We have built a multi-sensor platform on a wheel loader and collected experimental data to verify the effectiveness of our method. Two optimization components illustrated exceptional performance on the annotated dataset. The MVSRF method possesses strong robustness against external calibration errors, camera pose estimation errors, and inaccurate image segmentation, providing a practical solution for real-time perception of granular materials.},
  archive      = {J_APIN},
  author       = {Zhang, Lunhui and Liu, Guangjun and Lu, Jiaqi and Wang, Changxin},
  doi          = {10.1007/s10489-025-06326-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {MVSRF: Point cloud semantic segmentation and optimization method for granular construction objects},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A 3D-CNN and multi-loss video prediction architecture. <em>APIN</em>, <em>55</em>(6), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06328-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The achievements of deep learning in the sphere of computer vision have elevated video prediction to a prominent research focus. The prevailing trend in current deep learning endeavors is to pursue advanced optimization of model architectures and enhancement of their performance metrics. The task of video prediction is inherently complex, and most of the algorithm models proposed in the past are also. In this paper, we propose a novel simple video prediction network structure based on three-Dimensional Convolutional Neural Network (3D-CNN) and multi-loss, abbreviated as ML3DVP. Our network model is completely based on 3D-CNN. Compared with Convolutional Long Short-Term Memory (ConvLSTM), Recurrent Neural Network (RNN), Generative Adversarial Network (GAN) and its variants, we start from the most basic network structure to reduce complexity, thereby improving the speed of model prediction. In addition, most models today will encounter quality problems such as insufficient clarity. To solve this problem, we introduced multiple losses for back propagation. Using multiple quality evaluation indicators, Structural Similarity (SSIM) and Peak Signal-to-Noise Ratio (PSNR), as optimization objectives, continuously improves the prediction quality during the training process. The evaluation of model complexity, parameter count, and predictive outcomes across four datasets substantiates that our proposed model has successfully attained the objectives of structural refinement and enhanced performance.},
  archive      = {J_APIN},
  author       = {Qin, Ziru and Dai, Qun},
  doi          = {10.1007/s10489-025-06328-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {A 3D-CNN and multi-loss video prediction architecture},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Concept agent network for zero-base generalized few-shot learning. <em>APIN</em>, <em>55</em>(6), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06331-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized Few-Shot Learning (GFSL) aims to recognize novel classes with limited training samples without forgetting knowledge of auxiliary data (base classes). Most current approaches re-engage the base classes after initial training to balance the predictive bias between the base and novel classes. However, re-using the auxiliary data might not always be possible due to privacy or ethical constraints. Consequently, the zero-base GFSL paradigm emerges, where models trained on the base classes are directly fine-tuned on the novel classes without revisiting the auxiliary data, avoiding the re-balancing of prediction biases. We believe that solving this paradigm relies on a critical yet often overlooked issue: feature overlap between the base and novel classes in the embedding space. To tackle this issue, we propose the Concept Agent Network, a novel framework that interprets visual features as affinity features, thereby effectively diminishing feature overlap by aggregating feature embeddings of the novel classes according to their similarity with the base classes. Additionally, we present the Concept Catena Generator, which creates multiple concepts per base class, improving understanding of the feature distribution of the base classes and clarifying the relationships between the base and novel concepts. To prevent the catastrophic forgetting of the base classes when adapting to the novel ones, we propose an Active Training Regularization strategy, promoting the preservation of base class knowledge. Extensive experimental results on two benchmarks, mini-ImageNet and tiered-ImageNet, have demonstrated the effectiveness of our framework. The potential utility of our framework spans several real-world applications, including autonomous driving, medical image analysis, and real-time surveillance, where the ability to rapidly learn from a few examples without forgetting previously acquired knowledge is critical.},
  archive      = {J_APIN},
  author       = {Wang, Xuan and Ji, Zhong and Liu, Xiyao and Pang, Yanwei and Li, Xuelong},
  doi          = {10.1007/s10489-025-06331-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Concept agent network for zero-base generalized few-shot learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAAR: Dual attention cooperative adaptive pruning rate by data-driven for filter pruning. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06332-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model compression can address the limitations of deep learning in resource-constrained situations by reducing the computational and storage requirements of the model. Structured pruning has emerged as an important compression technique because of its operational flexibility and effectiveness. However, the existing structural pruning methods have two limitations: 1) They use a single measurement to identify the importance of the filters in all the layers, resulting in a loss of spatial information in the shallow layers. 2) The pruning rate is highly dependent on manual interference, which is highly subjective. In this paper, a filter pruning method called dual attention cooperative adaptive pruning rate (DAAR) is proposed. Specifically, a dual attention module that combines spatial attention and channel attention is proposed to measure the effectiveness of the filters. Spatial attention is used in the shallow layers, and channel attention is used in the deep layers. This allows the filter measurements to consider spatial information effectively. An adaptive pruning rate adjustment strategy is also used to eliminate manual subjectivity, achieving precision pruning of each convolutional layer. The experimental results on various datasets and networks demonstrate that the DAAR method achieves improved model performance after pruning. For example, in the CIFAR10 dataset, the precision increases from 93.5% to 93.75% after removing the floating point operations (FLOPs) of 84.1%, outperforming the state-of-the-art pruning methods.},
  archive      = {J_APIN},
  author       = {Lian, Suyun and Zhao, Yang and Pei, Jihong},
  doi          = {10.1007/s10489-025-06332-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {DAAR: Dual attention cooperative adaptive pruning rate by data-driven for filter pruning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ED-END: Robust watermarking technology based on deep coupling of feature extractors. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06333-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning-based watermarking methods have been developed to address the shortcomings of traditional watermarking algorithms. Some methods adopt an end-to-end framework to train the watermarking model, enabling excellent watermark embedding and extraction. However, the visual quality and robustness of these approaches remain insufficient, especially ignoring the adequacy of image feature extraction and the correlation between network modules. We propose a feature extractor and decoder deep coupled watermark network, which can help generate high-robust watermarked images. Specifically, a down-sampling feature extractor is employed to supplement image features post-decoder, the extracted features are synchronously provided to the encoder for watermark embedding. Additionally, skip-connection is introduced to share each layer feature information of the decoder with the encoder, thereby improving the correlation between network modules. Comprehensive experimental results show that the proposed scheme can achieve high robustness against screen-shooting and paper printing processes while maintaining the visual quality of the watermarked image.},
  archive      = {J_APIN},
  author       = {Li, Jun and Fang, Yixiang and Zhao, Yi and Xu, Kangkang and Wang, Junxiang},
  doi          = {10.1007/s10489-025-06333-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {ED-END: Robust watermarking technology based on deep coupling of feature extractors},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Control of traffic network signals based on deep deterministic policy gradients. <em>APIN</em>, <em>55</em>(6), 1-15. (<a href='https://doi.org/10.1007/s10489-024-06208-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The centralized control of traffic signals is a challenging problem due to the high randomness and complexity of traffic flow on urban road networks and the interaction between intersections. Centralized control leads to high spatial dimensionality of joint actions for traffic road network signal control. However, the decisive action output can solve the problem of “dimensional explosion” caused by joint actions. In this paper, we propose a deep deterministic policy gradient-based algorithm for centralized control of urban traffic road network signals. We simplify the traffic signal control to a four-phase green signal ratio, and the deep deterministic policy gradient-based algorithm deterministically outputs the control signal for each intersection based on the information of the whole traffic network, thus avoiding the problem of “dimensional explosion”. In particular, a new normalization function is proposed to generate the green rate of traffic signals and constrain it to a range of maximum and minimum sustained green time by linear transformation, which makes the generated traffic signals more realistic. Our proposed algorithm is shown to be optimal and robust compared to Deep Q-Network(DQN) based and fixed time control for 7-hour SUMO simulation of a single-peak traffic network with three intersections.},
  archive      = {J_APIN},
  author       = {Hu, Huifeng and Lin, Shu and Wang, Ping and Xu, Jungang},
  doi          = {10.1007/s10489-024-06208-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Control of traffic network signals based on deep deterministic policy gradients},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Loop closure detection based on image feature matching and motion trajectory similarity for mobile robot. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-024-05874-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In visual simultaneous localization and mapping (SLAM), loop closure detection plays an irreplaceable role in eliminating cumulative errors, optimizing robot poses, and ensuring map consistency. Most loop closure detection algorithms adopt single feature or feature fusion to detect loop closures, which makes it difficult to ensure accuracy in environments with changing lighting or high-similarity scenes. In this work, image features and motion trajectories are combined to improve the effectiveness of loop closure detection via a staged detection method. First, histogram equalization is used to reduce the algorithm’s sensitivity to lighting. Then, LBP features are used to divide keyframes into multiple sequences, and the sequence where the loop closure candidate frame is located is determined according to the image feature matching results. Then, the most matched keyframe is searched in the sequence as a candidate loop closure. Finally, the true loop closure is confirmed by comparing the motion trajectory similarity to improve the algorithm’s adaptability to high-similarity scenes. The experimental results show that in different application scenarios, the proposed method can achieve good results in terms of precision, recall, area under the curve (AUC), and recall when the precision is 100%.},
  archive      = {J_APIN},
  author       = {Hao, Weilong and Wang, Peng and Ni, Cui and Huangfu, Wenjun and Liu, Zhu and Qi, Kaiyuan},
  doi          = {10.1007/s10489-024-05874-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Loop closure detection based on image feature matching and motion trajectory similarity for mobile robot},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous multi-modal graph network for arterial travel time prediction. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-024-05895-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Travel time prediction has important influence on the overall control of urban Intelligent Transportation Systems (ITS). Urban arterial networks are typically composed of links and intersections, where each link or intersection can be regarded as a spatial node within the network. However, existing researches predominantly focus on modeling spatial nodes in the link modality to predict travel times in urban arterial networks, neglecting the potential correlations among heterogeneous modal nodes. To overcome these limitations, we propose a Heterogeneous Multi-Modal Graph Neural Network (HMGNN) specifically tailored for travel time prediction in arterial networks. Specifically, we innovatively construct spatial correlation graphs that capture the unique traffic characteristics of intersection modal nodes. Furthermore, we design a cross-modal graph generator that captures the latent spatiotemporal features between spatial nodes of distinct modalities, resulting in the generation of heterogeneous modal graphs. Finally, our proposed HMGNN model incorporates tailored network structures for graphs of varying complexities, enabling targeted mining of their inherent information to derive the final prediction results. Extensive experiments conducted using real-world traffic data from Zhangzhou, China, demonstrate that our HMGNN model achieves significant improvements in prediction accuracy.},
  archive      = {J_APIN},
  author       = {Fang, Jie and He, Hangyu and Xu, Mengyun and Wu, Xiongwei},
  doi          = {10.1007/s10489-024-05895-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Heterogeneous multi-modal graph network for arterial travel time prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel consensus reaching approach for large-scale multi-attribute emergency group decision-making under social network clustering based on graph attention mechanism. <em>APIN</em>, <em>55</em>(6), 1-28. (<a href='https://doi.org/10.1007/s10489-024-05992-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergency decision-making problem is common in our daily life. To solve this kind of problem, a group of decision-makers (DMs) are usually invited to make a decision in a limited time. Since multiple attributes are usually considered, it’s called large-scale multi-attribute emergency group decision-making (LS-MA-EGDM). There are two issues in the general research of LS-MA-EGDM. First, clustering and consensus-reaching process (CRP) should consider the influence of DMs’ intrinsic features. Second, consensus adjustment within and among sub-clusters ought to be fast to prevent multi-round iteration. Accordingly, (1) we introduce graph attention mechanism to calculate the attention coefficients between DM pair’s intrinsic features. The multi-head graph attention coefficient based on social network analysis (SNA) is proposed, which is then combined with opinion similarity to construct a social network clustering method. (2) The Einstein product operator is introduced to propagate the attention coefficients and yield DMs’ weights, which is then incorporated in the subsequent adjustment allocation. (3) Identification rules are provided based on four consensus types in the CRP. The one-iteration personalized adjustment strategies corresponding to different consensus types are then proposed. (4) Evidential reasoning (ER) algorithm is finally utilized to aggregate the preferences of clusters after consensus is reaching. The proposed method is further applied to a chemical plant explosion in Texas to illustrate its effectiveness and validity in dealing with emergencies.},
  archive      = {J_APIN},
  author       = {Zhou, Mi and Zhang, Ying and Fan, Xin-Yu and Wu, Ting and Cheng, Ba-Yi and Wu, Jian},
  doi          = {10.1007/s10489-024-05992-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-28},
  shortjournal = {Appl. Intell.},
  title        = {A novel consensus reaching approach for large-scale multi-attribute emergency group decision-making under social network clustering based on graph attention mechanism},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised learning for intelligent disease diagnosis using audio signals: Beyond copd to a spectrum of diseases. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06028-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the widespread prevalence and significant patient base of COPD (Chronic Obstructive Pulmonary Disease), the development of simple and rapid diagnostic methods has emerged as a key research focus. Through pathological studies, the medical community has identified the potential of cough sounds for diagnosing COPD, sparking interest in leveraging deep learning to analyze various disease-related sounds, including those associated with COVID-19 and cardiac conditions, etc. Yet, research specifically targeting COPD remains scarce, primarily due to two challenges: traditional models trained on small medical datasets often fall short of expectations due to stringent data privacy and collection requirements in healthcare; and the scarcity of publicly accessible COPD datasets, particularly those that could obviate the need for medical equipment. Addressing these challenges, our paper introduces a novel dataset of smartphone-recorded cough sounds, termed the CC (COPD-Cough) dataset. It comprises 221 recordings from COPD patients and 632 from healthy individuals, marking the first dataset explicitly curated for COPD cough sound analysis. The dataset, endorsed by clinical professionals and collected independently of medical devices, promises to propel advancements in straightforward COPD diagnostics. Furthermore, we propose a self-supervised learning model enhanced by unique data augmentation techniques and an efficient sound feature extractor, demonstrating superior performance across three distinct disease datasets and achieving state-of-the-art results. Comprehensive ablation studies affirm our model’s efficacy, while sensitivity analyses optimize its applicability to various tasks. For further engagement, the framework’s source code and dataset are available at https://github.com/auto-chao/COPD_Diagnosis and https://zenodo.org/records/10209837 , respectively.},
  archive      = {J_APIN},
  author       = {Sun, Wenchao and Wu, Gang and Ming, Ming and Zhang, Jiameng and Shi, Chun and Qin, Linlin},
  doi          = {10.1007/s10489-024-06028-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Self-supervised learning for intelligent disease diagnosis using audio signals: Beyond copd to a spectrum of diseases},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A BERT-based review helpfulness prediction model utilizing consistency of ratings and texts. <em>APIN</em>, <em>55</em>(6), 1-14. (<a href='https://doi.org/10.1007/s10489-024-06100-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting review helpfulness (RH) to ensure that consumers make effective purchasing decisions is a significant area of study. Many scholars have attempted to develop accurate review helpfulness prediction (RHP) methodologies. However, most previous studies have mainly focused on predictions using product review texts, and few studies have used product satisfaction as indicated by star ratings, particularly the consistency between review texts and star ratings. This study proposes a novel model called BHelP-CoRT (Bidirectional Encoder Representations from Transformers based RHP model utilizing consistency of ratings and texts) to predict RH. The proposed model consists of a review text encoder, star rating encoder, and text-rating interaction. The review text encoder was developed by applying the BERT model to extract contextual semantic features embedded in review texts. The star rating encoder was designed to embed star ratings into feature vectors. The text-rating interaction was constructed by applying an attention mechanism to extract the text-rating interaction and introduce consistency into the RHP tasks. This study conducted extensive experiments to demonstrate the effectiveness of the proposed model from multiple perspectives using real-world online reviews collected from Amazon. The experimental results show that the proposed model outperforms the state-of-the-art models, indicating that it can improve the RHP performance. Specifically, this effectiveness is reflected in the processing of reviews containing inconsistent information. This study supports the marketing efforts of the e-commerce industry by providing an RHP service to address consumer information overload.},
  archive      = {J_APIN},
  author       = {Li, Xinzhe and Li, Qinglong and Ryu, Dongyeop and Kim, Jaekyeong},
  doi          = {10.1007/s10489-024-06100-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {A BERT-based review helpfulness prediction model utilizing consistency of ratings and texts},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SCSNet: A novel transformer-CNN fusion architecture for enhanced segmentation and classification on high-resolution semiconductor micro-scale defects. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-024-06122-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of semiconductor integrated circuit manufacturing, accurately identifying the root causes of defects is critical for enhancing yield rates. Traditionally, this analytical process has been both time-intensive and challenged by inaccuracies, primarily due to the intricate and varied morphology of wafer defects. While convolutional neural networks (CNNs) with encoder-decoder architectures have made significant strides in the segmentation of defects, they inherently struggle to capture distant interactions and achieve high performance in classification tasks. Conversely, recent advancements in transformers have showcased their proficiency in learning global image dependencies. However, transformers often lack the specific graphical priors and the adaptability typically associated with CNNs. Addressing these limitations, we introduce SCSNet, an innovative architecture that merges the strengths of transformers and CNNs. This fusion network is designed to enhance both segmentation and classification of scanning electron microscopy (SEM) images of wafer defects. SCSNet incorporates a conventional encoder-decoder framework, supplemented by shape flow branches and multi-cross-attention (MCF) modules within a skip connection architecture. Rigorous experimentation on a dataset of 4425 high-resolution wafer defects, sourced from our operational wafer fabrication facility, demonstrates SCSNet’s superior performance. Notably, SCSNet surpasses existing advanced CNNs, transformers, and their hybrid counterparts, achieving a classification accuracy of 97.62% and a segmentation Intersection over Union (IoU) of 84.09%. Currently implemented on our local server for engineering use, SCSNet represents a major advancement in semiconductor manufacturing, offering a more precise and efficient tool for wafer defect analysis.},
  archive      = {J_APIN},
  author       = {Luo, Yuening and Mei, Zhouzhouzhou and Qiao, Yibo and Chen, Yining},
  doi          = {10.1007/s10489-024-06122-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {SCSNet: A novel transformer-CNN fusion architecture for enhanced segmentation and classification on high-resolution semiconductor micro-scale defects},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FreqFaceNet: An enhanced transformer architecture with dual-order frequency attention for deepfake detection. <em>APIN</em>, <em>55</em>(6), 1-15. (<a href='https://doi.org/10.1007/s10489-024-06168-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of AI-based image synthesis tools and techniques, Deepfakes have become a serious problem as they pose a massive threat to one’s information security and personal privacy. Several architectures have been proposed to achieve robust Deep Fake detection. However, these methods suffer a drastic drop in performance if the images are visually degraded or have low resolution. To resolve these two issues, a novel FreqFaceNet model has been proposed that employs two novel attentions namely, Wavelet Attention and Fourier Attention, for extracting important frequency-based features from low-resolution images. The extraction of frequency-based features ensures minimal interference of noise due to image compression or low resolution. The proposed model excels on two public benchmark datasets—the DFDC and CelebDF. On the DFDC dataset, FreqFaceNet achieves 98.041% accuracy, an AUC value of 99.748, and a Mathews Correlation Coefficient (MCC) value of 93.857, while on the CelebDF dataset, it obtains an accuracy of 98.325%, an AUC value of 99.81, and an MCC value of 92.819. Qualitative analysis of the proposed model indicates strong classification capabilities. An ablation study has also been conducted to verify the complementary contributions of both Wavelet and Fourier Attention mechanisms.},
  archive      = {J_APIN},
  author       = {Gupta, Varun and Srivastava, Vaibhav and Yadav, Ankit and Vishwakarma, Dinesh Kumar and Kumar, Narendra},
  doi          = {10.1007/s10489-024-06168-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {FreqFaceNet: An enhanced transformer architecture with dual-order frequency attention for deepfake detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VAEneu: A new avenue for VAE application on probabilistic forecasting. <em>APIN</em>, <em>55</em>(6), 1-23. (<a href='https://doi.org/10.1007/s10489-024-06203-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces VAEneu, a novel autoregressive method for multistep ahead univariate probabilistic time series forecasting, designed to address the challenges of generating sharp and well-calibrated probabilistic forecasts without assuming a specific parametric form for the predictive distribution. VAEneu leverages the Conditional VAE framework and optimizes the likelihood of the predictive distribution using the Continuous Ranked Probability Score (CRPS), a strictly proper scoring rule, as the loss function. This approach enables the model to learn flexible, sharp, and well-calibrated predictive distributions without the need for a tractable likelihood function. In a comprehensive empirical study, VAEneu is rigorously benchmarked against 12 baseline models across 12 datasets, demonstrating superior performance in both forecasting accuracy and uncertainty quantification. VAEneu provides a valuable tool for quantifying future uncertainties, and our extensive empirical study lays the foundation for future comparative studies for univariate multistep ahead probabilistic forecasting.},
  archive      = {J_APIN},
  author       = {Koochali, Alireza and Tahaei, Ensiye and Dengel, Andreas and Ahmed, Sheraz},
  doi          = {10.1007/s10489-024-06203-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {VAEneu: A new avenue for VAE application on probabilistic forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: A diverse/converged individual competition algorithm for computationally expensive many-objective optimization. <em>APIN</em>, <em>55</em>(6), 1. (<a href='https://doi.org/10.1007/s10489-024-06225-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Lin, Jie and Zhang, Sheng Xin and Zheng, Shao Yong},
  doi          = {10.1007/s10489-024-06225-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Correction to: A diverse/converged individual competition algorithm for computationally expensive many-objective optimization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IPAttack: Imperceptible adversarial patch to attack object detectors. <em>APIN</em>, <em>55</em>(6), 1-12. (<a href='https://doi.org/10.1007/s10489-025-06246-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread application of deep learning, general object detectors have become increasingly popular in our daily lives. Extensive research, however, has shown that existing detectors are vulnerable to patch-based adversarial attacks, which fool such detectors by crafting adversarial patches. Although existing methods have made significant progress in terms of attack success rate, they still suffer from a highly perceptible problem, making it easy for humans to distinguish these evil examples. To address this issue, in this paper, we propose a novel spatial transform-based end-to-end patch attack method, called IPAttack, to synthesize imperceptible adversarial patches. Our approach estimates a flow field $$\varvec{f}$$ to formulate adversarial examples rather than introduce small $$L_p$$ -norm constrained external perturbations. Besides, to improve the imperceptibility and maintain a high attack performance, we propose the Object Detector Class Activation Map (OD-CAM) for objectors to extract the most interesting region, which will be applied to spatial transform to generate the final adversarial examples. Extensive experiments demonstrate that the proposed IPAttack can generate patch-wised adversarial examples with high imperceptibility while achieving the best attack performance compared to existing methods.},
  archive      = {J_APIN},
  author       = {Wen, Yongming and Si, Peiyuan and Zhou, Wei and Zhao, Zongheng and Yi, Chao and Liu, Renyang},
  doi          = {10.1007/s10489-025-06246-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {IPAttack: Imperceptible adversarial patch to attack object detectors},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FinCaKG-onto: The financial expertise depiction via causality knowledge graph and domain ontology. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06247-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causality stands as an essential relation for elucidating the reasoning behind given contents. However, current causality knowledge graphs fall short in effectively illustrating the inner logic in a specific domain, i.e. finance. To generate such a functional knowledge graph, we propose the multi-faceted approach encompassing causality detection module, entity linking module, and causality alignment module to automatically construct FinCaKG-Onto with the guidance of expert financial ontology - FIBO. In this paper, we outline the resources and methodology employed for FinCaKG-Onto construction, present the schema of FinCaKG-Onto, and share the final knowledge graph FinCaKG-Onto. Through various user scenarios, we demonstrate that FinCaKG-Onto not only captures nuanced domain expertise but also explicitly unveils the causal logic for any anchor terms. To facilitate your convenience of future use, a check table is conducted as well to showcase the quality of FinCaKG-Onto. The related resources are available in the webpage< https://www.ai.iee.e.titech.ac.jp/FinCaKG-Onto/ >.},
  archive      = {J_APIN},
  author       = {Xu, Ziwei and Ichise, Ryutaro},
  doi          = {10.1007/s10489-025-06247-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {FinCaKG-onto: The financial expertise depiction via causality knowledge graph and domain ontology},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-guided classification and regression surrogates co-assisted multi-objective soft subspace clustering algorithm. <em>APIN</em>, <em>55</em>(6), 1-29. (<a href='https://doi.org/10.1007/s10489-025-06266-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficiency of multi-objective soft subspace clustering algorithms (MSSCAs) can be low when applied to large-scale datasets. This inefficiency arises because the multi-objective evolutionary algorithms (MOEAs) utilized in MSSCAs often require a large number of soft subspace clustering objective function evaluations due to their population-based nature. Moreover, relying solely on negative Shannon entropy to constrain feature weights is inadequate for soft subspace clustering algorithms. To address these issues, a knowledge-guided classification and regression surrogates co-assisted multi-objective soft subspace clustering (KCRS-MOSSC) algorithm is presented. First, an inter-cluster feature weight dissimilarity function is designed to further constrain the feature weights. Furthermore, a novel surrogate-based optimization framework called the knowledge-guided classification and regression surrogates co-assisted multi-objective evolutionary framework (KCRS-MOEF) is proposed to efficiently optimize the proposed inter-cluster feature weight dissimilarity function, intra-cluster compactness function, inter-cluster separation function, and negative Shannon entropy function. In KCRS-MOEF, a classification decision tree is utilized as the classification surrogate model to help generate a set of promising offspring, while a radial basis function (RBF) model is employed as the regression surrogate model to assist in the infill criterion by predicting the objective function values of the offspring. Furthermore, to fully leverage the knowledge of the evolutionary process, an infill criterion guided by dynamic process knowledge of elite individuals is designed to enhance the convergence and diversity of the population. Finally, a clustering ensemble strategy based on knee point guidance is proposed to generate a final solution from a set of non-dominated individuals. KCRS-MOEF outperforms state-of-the-art counterparts in terms of convergence, diversity, and time efficiency, as demonstrated in four experiments conducted on the DTLZ benchmark. Furthermore, experiments on various datasets show that the clustering performance and time efficiency of KCRS-MOSSC exceed those of comparison algorithms.},
  archive      = {J_APIN},
  author       = {Zhao, Feng and Li, Lu and Liu, Hanqiang},
  doi          = {10.1007/s10489-025-06266-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-29},
  shortjournal = {Appl. Intell.},
  title        = {Knowledge-guided classification and regression surrogates co-assisted multi-objective soft subspace clustering algorithm},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reusability of bayesian networks case studies: A survey. <em>APIN</em>, <em>55</em>(6), 1-25. (<a href='https://doi.org/10.1007/s10489-025-06289-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian Networks (BNs) are probabilistic graphical models used to represent variables and their conditional dependencies, making them highly valuable in a wide range of fields, such as radiology, agriculture, neuroscience, construction management, medicine, and engineering systems, among many others. Despite their widespread application, the reusability of BNs presented in papers that describe their application to real-world tasks has not been thoroughly examined. In this paper, we perform a structured survey on the reusability of BNs using the PRISMA methodology, analyzing 147 papers from various domains. Our results indicate that only 18% of the papers provide sufficient information to enable the reusability of the described BNs. This creates significant challenges for other researchers attempting to reuse these models, especially since many BNs are developed using expert knowledge elicitation. Additionally, direct requests to authors for reusable BNs yielded positive results in only 12% of cases. These findings underscore the importance of improving reusability and reproducibility practices within the BN research community, a need that is equally relevant across the broader field of Artificial Intelligence.},
  archive      = {J_APIN},
  author       = {Babakov, Nikolay and Sivaprasad, Adarsa and Reiter, Ehud and Bugarín-Diz, Alberto},
  doi          = {10.1007/s10489-025-06289-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {Reusability of bayesian networks case studies: A survey},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NPGCL: Neighbor enhancement and embedding perturbation with graph contrastive learning for recommendation. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06301-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have significantly advanced recommendation systems by modeling user-item interactions through bipartite graphs. However, real-world user-item interaction data are often sparse and noisy. Traditional bipartite graph modeling fails to capture higher-order relationships between users and items, limiting the ability of GNNs to learn high-quality node embeddings. While existing graph contrastive learning methods address data sparsity by partitioning nodes into positive and negative pairs, they also neglect these higher-order relationships, thus limiting the effectiveness of contrastive learning in recommendation systems. Furthermore, due to the inherent limitations of graph convolution, noise can propagate and amplify with increasing layers in deep graph convolutional networks. To address these challenges, Neighbor Enhancement and Embedding Perturbation for Graph Contrastive Learning (NPGCL) is proposed, which introduces two key modules - Relational Neighbor Enhancement Module and Collaborative Neighbor Enhancement Module - to capture higher-order relationships between homogeneous nodes and calculate interaction importance for noise suppression. Moreover, NPGCL employs an Embedding Perturbation Strategy and applies inter-layer contrastive learning to mitigate the noise impact caused by multi-layer graph convolutions. Experimental results demonstrate that NPGCL significantly improves performance across four publicly available datasets, with a notable enhancement in robustness, especially in noisy environments. Specifically, NPGCL achieves performance improvements of 1.77%-3.34% and 3.87%-9.07% on the Gowalla and Amazon-books datasets, respectively. In noisy datasets, NPGCL improves Recall@20 by 4.98% and 10.92%, respectively.},
  archive      = {J_APIN},
  author       = {Wu, Xing and Wang, Haodong and Yao, Junfeng and Qian, Quan and Song, Jun},
  doi          = {10.1007/s10489-025-06301-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {NPGCL: Neighbor enhancement and embedding perturbation with graph contrastive learning for recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Composite gaussian processes flows for learning discontinuous multimodal policies. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06302-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning control policies for real-world robotic tasks often involve challenges such as multimodality, local discontinuities, and the need for computational efficiency. These challenges arise from the complexity of robotic environments, where multiple solutions may coexist. To address these issues, we propose Composite Gaussian Processes Flows (CGP-Flows), a novel semi-parametric model for robotic policy. CGP-Flows integrate Overlapping Mixtures of Gaussian Processes (OMGPs) with the Continuous Normalizing Flows (CNFs), enabling them to model complex policies addressing multimodality and local discontinuities. This hybrid approach retains the computational efficiency of OMGPs while incorporating the flexibility of CNFs. Experiments conducted in both simulated and real-world robotic tasks demonstrate that CGP-flows significantly improve performance in modeling control policies. In a simulation task, we confirmed that CGP-Flows had a higher success rate compared to the baseline method, and the success rate of GCP-Flow was significantly different from the success rate of other baselines in chi-square tests.},
  archive      = {J_APIN},
  author       = {Wang, Shu-yuan and Sasaki, Hikaru and Matsubara, Takamitsu},
  doi          = {10.1007/s10489-025-06302-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Composite gaussian processes flows for learning discontinuous multimodal policies},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and analysis of a variable-parameter noise-tolerant ZNN for solving time-variant nonlinear equations and applications. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06304-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solvers considering time-varying parameters are more suitable for addressing a variety of time-varying problems, whereas traditional fixed-parameter neural networks are somewhat insufficient for efficiently and quickly solving these problems. Many existing zeroing neural networks ensure rapid convergence using the infinite-valued AFs. For solving time-varying nonlinear equations, this paper proposes a finitely-activated variable parameter noise tolerant zeroing neural network (VPNTZNN), applied to trajectory tracking of redundant robotic arms. The designed variable parameters are error-dependent, enabling adaptive adjustment to optimal values as errors fluctuate, thereby ensuring faster convergence of the proposed VPNTZNN. And the constructed variable parameters and activation functions (AFs) do not escalate infinitely over time. Affected by the above variable parameters, the proposed finitely-activated VPNTZNN achieves rapid finite-time convergence with strong noise suppression. Simulation results validate the effectiveness of our method in solving time-variant nonlinear equations and in trajectory tracking of redundant manipulators. Moreover, this approach employs a finite-valued activation function to design a variable-parameter neural network, thereby avoiding the difficulties of practical implementation.},
  archive      = {J_APIN},
  author       = {Zhang, Yu and Wang, Liming and Zhong, Guomin},
  doi          = {10.1007/s10489-025-06304-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Design and analysis of a variable-parameter noise-tolerant ZNN for solving time-variant nonlinear equations and applications},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). E-GCDT: Advanced reinforcement learning with GAN-enhanced data for continuous excavation system. <em>APIN</em>, <em>55</em>(6), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06308-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automation of excavator operations entails the development and implementation of systems that allow excavators to execute tasks autonomously, thereby significantly reducing the need for human intervention. By integrating advanced sensors and artificial intelligence algorithms, these systems aim to increase operational efficiency, safety, and precision in construction and mining. However, previously developed methods have two weaknesses. First, existing automated excavator systems struggle with adapting to diverse and complex environmental conditions and with precision in control mechanisms. Second, operating an excavator involves multiple, repeated decisions that need to be modeled, planned, and executed in real time. However, there is a significant lack of comprehensive datasets that reflect real-world excavation operations to support this process. In this paper, we present an innovative system named E-GCDT. This system integrates the DoppelGANger module, which generates action time series by emulating human-mined trajectories through a generative adversarial mechanism and replays them in a simulation environment, ultimately expanding the dataset to 155 continuous mining trajectories. Furthermore, E-GCDT integrates terrain features into the decision-making process with the contrastive language-image pre-training model (CLIP), in which the decision transformer optimizes trajectory planning for efficient and accurate continuous excavation tasks. E-GCDT uniquely integrates advanced data augmentation and terrain awareness, developing an advanced Markov decision framework (DT) for continuous excavation tasks. The experimental results of a bulldozer verify that the efficiency of E-GCDT surpasses human efficiency. This system sets a new standard for continuous autonomous mining, and this study provides a new perspective on the application of reinforcement learning in industrial environments.},
  archive      = {J_APIN},
  author       = {Zhao, Qianyou and Gao, Le and Wu, Duidi and Lei, Yihao and Wang, Lingyu and Qi, Jin and Hu, Jie},
  doi          = {10.1007/s10489-025-06308-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {E-GCDT: Advanced reinforcement learning with GAN-enhanced data for continuous excavation system},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WLKA-RVS: A retinal vessel segmentation method using weighted large kernel attention. <em>APIN</em>, <em>55</em>(6), 1-12. (<a href='https://doi.org/10.1007/s10489-025-06309-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vessel segmentation is an important task in medical image analysis and has a wide range of applications in the diagnosis and treatment of retinal diseases. However, existing segmentation methods still have some shortcomings in accurately segmenting thin vessels. Based on this observation, we propose a Retinal Vessel Segmentation method based on Weighted Large Kernel Attention (WLKA-RVS), which aims to improve the accuracy of retinal vessel segmentation to better assist physicians in clinical diagnosis and treatment. Our method consists of an encoder and a decoder. In the encoder, a convolution stem first reduces the dimension of the input image. Then, feature extraction is performed by four stages of Swin Transformer modules, each stage with a downsampling layer. In the decoder, there are four different stages of Weighted Large Kernel Attention Block (WLKAB) corresponding to the Swin Transformer modules in the encoder. Then WLKA-RVS applies the Patch Expanding module to achieve upsampling. Finally, a linear layer outputs the final results. We have performed extensive experiments comparing several recent advanced models on three public datasets. WLKA-RVS led by 0.32%, 1.24%, and 0.71% in the mAcc metric, respectively. At the same time, the inference speed of WLKA-RVS met the real-time requirements for medical diagnosis. A series of experiments demonstrated the efficiency, robustness, and applicability of WLKA-RVS.},
  archive      = {J_APIN},
  author       = {Li, Jiayao and Zeng, Min and Wu, Chenxi and Cheng, Qianxiang and Guo, Qiuyan and Li, Song},
  doi          = {10.1007/s10489-025-06309-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {WLKA-RVS: A retinal vessel segmentation method using weighted large kernel attention},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TADST: Reconstruction with spatio-temporal feature fusion for deviation-based time series anomaly detection. <em>APIN</em>, <em>55</em>(6), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06310-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is crucial in time series analysis for identifying abnormal events. To address the limitations of traditional methods in integrating spatiotemporal correlations and modeling normal patterns, we propose a Time Series Anomaly Detection Model Based on Spatio-Temporal Feature Fusion (TADST). First, the Spatio-Temporal Feature Fusion Network (STF) combines temporal convolutional networks and graph attention influence networks to capture temporal dynamic dependencies and attribute correlations respectively, facilitating joint spatiotemporal feature modeling. Then, the Time Series Reconstruction Network (TSR) employs a multi-layer encoder-decoder architecture to learn the normal sample distribution and amplify discrepancies between reconstructed and anomalous data. Finally, the Anomaly Detection Mechanism (ADM) identifies anomalies by fitting the tail distribution of reconstruction deviations. When the anomaly score exceeds a predefined threshold, the mechanism updates the parameters of the Generalized Pareto Distribution, keeping the detection criteria adaptive. Experiments demonstrate that the proposed TADST achieves state-of-the-art results on five publicly available datasets.},
  archive      = {J_APIN},
  author       = {Yang, Bin and Ma, Tinghuai and Rong, Huan and Huang, Xuejian and Wang, Yubo and Zhao, Bowen and Wang, Chaoming},
  doi          = {10.1007/s10489-025-06310-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {TADST: Reconstruction with spatio-temporal feature fusion for deviation-based time series anomaly detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph regularized independent latent low-rank representation for image clustering. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06312-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-rank representation (LRR) has been proved to be effective in exploring low-dimensional subspace structure embedded in the observations. However, existing LRR algorithms often pay no attention to data redundancy, easily leading to performance decay. In addition, the LRR characterizes data global inter-connections, from which some latent similarity features should be further learned and exploited to improve the performance of clustering. Therefore, a novel method termed Graph Regularized Independent Latent Low-Rank Representation (GRI-LLRR) is presented to address the above issues. As we know, Hilbert–Schmidt Independence Criterion (HSIC) measures the independence between two distributions. In the proposed method, it is introduced and developed to another novel graph regularization independent term to remove the uncorrelation between vectors and to preserve the data local geometry. With other constraints, including the sparse, nonnegative and symmetric, the LRR is obtained from the observations. Then, the proposed method further learns the cosine features as latent representation of the LRR for final clustering. Massive experiments have been conducted on eight benchmark data sets. Experimental results show that the proposed GRI-LLRR outperforms some state-of-the-art (SOTA) approaches with improvements of 2.24%, 2.73%, and 2.65% on average for CCA, NMI, and Purity, respectively.},
  archive      = {J_APIN},
  author       = {Li, Bo and Pan, Lin-Feng},
  doi          = {10.1007/s10489-025-06312-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Graph regularized independent latent low-rank representation for image clustering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A code completion approach combining pointer network and transformer-XL network. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06315-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code completion is a crucial aspect of contemporary integrated development environments (IDEs), as it not only streamlines the software development process but also bolsters the quality of software products. By leveraging large-scale codes to learn the probability distribution among code token units, deep learning methods have demonstrated significant improvements in the accuracy of token unit recommendations. However, the efficacy of code completion employing deep learning is often compromised by information loss. To mitigate this issue, we introduce a novel code language model that incorporates both the pointer network and the Transformer-XL architecture to surpass the constraints of current approaches in code completion. Our proposed model accepts as input the original code snippet and its corresponding abstract syntax tree (AST), utilizing the Transformer-XL model as the foundational architecture for capturing long-term dependencies. Additionally, we incorporate a pointer network as an adjunct component to forecast Out-of-Vocabulary (OoV) words. Our approach has been rigorously evaluated on the authentic PY150 and JS150 datasets. The comparative experimental results demonstrate the effectiveness of our model in improving the accuracy of the code completion task at the token unit level.},
  archive      = {J_APIN},
  author       = {Zhang, Xiangping and Liu, Jianxun and Long, Teng and Hu, Haize},
  doi          = {10.1007/s10489-025-06315-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {A code completion approach combining pointer network and transformer-XL network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GenKP: Generative knowledge prompts for enhancing large language models. <em>APIN</em>, <em>55</em>(6), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06318-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have demonstrated extensive capabilities across various natural language processing (NLP) tasks. Knowledge graphs (KGs) harbor vast amounts of facts, furnishing external knowledge for language models. The structured knowledge extracted from KGs must undergo conversion into sentences to align with the input format required by LLMs. Previous research has commonly utilized methods such as triple conversion and template-based conversion. However, sentences converted using existing methods frequently encounter issues such as semantic incoherence, ambiguity, and unnaturalness, which distort the original intent, and deviate the sentences from the facts. Meanwhile, despite the improvement that knowledge-enhanced pre-training and prompt-tuning methods have achieved in small-scale models, they are difficult to implement for LLMs in the absence of computational resources. The advanced comprehension of LLMs facilitates in-context learning (ICL), thereby enhancing their performance without the need for additional training. In this paper, we propose a knowledge prompts generation method, GenKP, which injects knowledge into LLMs by ICL. Compared to inserting triple-conversion or templated-conversion knowledge without selection, GenKP entails generating knowledge samples using LLMs in conjunction with KGs and makes a trade-off of knowledge samples through weighted verification and BM25 ranking, reducing knowledge noise. Experimental results illustrate that incorporating knowledge prompts enhances the performance of LLMs. Furthermore, LLMs augmented with GenKP exhibit superior improvements compared to the methods utilizing triple and template-based knowledge injection.},
  archive      = {J_APIN},
  author       = {Li, Xinbai and Peng, Shaowen and Yada, Shuntaro and Wakamiya, Shoko and Aramaki, Eiji},
  doi          = {10.1007/s10489-025-06318-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {GenKP: Generative knowledge prompts for enhancing large language models},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent forecasting algorithm of power industry expansion based on time series and entropy weight method. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06321-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To accurately predict the electricity consumption trend of individual users and even the entire industry, this paper studies an intelligent prediction algorithm for the power industry based on time series and entropy weight method. Using ARIMA model and X12 model to establish a monthly electricity consumption prediction model, the study obtains the monthly electricity consumption prediction value for the expansion of the power industry. The entropy weight method is employed to calculate the weights of two power industry expansion month electricity consumption forecasting models, thereby achieving intelligent forecasting. The experimental results demonstrate that the maximum error of the proposed method is only 1.78%, and the average time complexity and average space complexity of the proposed algorithm are both below the set threshold.},
  archive      = {J_APIN},
  author       = {Wu, Guoyao and Lan, Zhiqiang and Wu, Xiaofang and Huang, Xiaoying and Mao, Linling},
  doi          = {10.1007/s10489-025-06321-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Intelligent forecasting algorithm of power industry expansion based on time series and entropy weight method},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel data-driven model for explainable hog price forecasting. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06323-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting hog prices is an important and challenging task for pig producers and managers as it plays a crucial role in decision-making processes. Given the significant impact of raw pork supply, public concern, animal diseases, and international markets on hog prices, this study proposes a comprehensive and explainable hybrid model for hog price forecasting by combining principal component analysis (PCA), variational mode decomposition (VMD), weighted average algorithm (WAA) algorithm, and temporal fusion transformers (TFT). To improve the quality of input variables, search engine data reflecting public concern about live pig prices are dimensionally reduced using PCA. This reduction process helps in eliminating unnecessary information and enhancing the input’s relevance. Additionally, VMD is applied to decompose raw pig futures prices, enabling the capture of their underlying trends over time. Subsequently, all the input variables, including the processed search engine data and the decomposed pig futures prices, are fed into the WAA-TFT model. WAA algorithm optimizes the parameters of the TFT model, resulting in accurate predicted values. The interpretable nature of the TFT model provides valuable decision-making insights for practitioners in the agricultural products market. The experimental results show that the proposed model achieves a mean absolute percentage error (MAPE) of only 1.76% on the Chinese hog price prediction dataset, demonstrating the excellent predictive performance of the proposed model.},
  archive      = {J_APIN},
  author       = {Wu, Binrong and Zeng, Huanze and Hu, Huanling and Wang, Lin},
  doi          = {10.1007/s10489-025-06323-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {A novel data-driven model for explainable hog price forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning discriminative features for multi-hop knowledge graph reasoning. <em>APIN</em>, <em>55</em>(6), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06327-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL)-based multi-hop knowledge graph reasoning has achieved remarkable success in real-world applications and can effectively handle knowledge graph completion tasks. This approach involves a policy-based agent navigating the graph environment to extend reasoning paths and identify the target entity. However, most existing multi-hop reasoning models are typically constrained to stepwise inference, which inherently disrupts the global information of multi-hop paths. To overcome this limitation, we introduce discriminative features between valid and invalid paths as global information. Here, we propose a multi-hop path encoder specifically designed to extract these discriminative features. Firstly, a multi-hop path encoding module is employed to derive each path’s hidden features, using cross-attention mechanisms to strengthen the interaction between triple context and path features. Secondly, a discriminative feature extraction module is used to capture the differences between valid and invalid paths. Thirdly, an attention-enhanced gated fusion mechanism is implemented to integrate these discriminative features into the multi-hop inference decoder. We further evaluate our method on five standard datasets. Our method outperforms the baseline models, demonstrating the effectiveness of discriminative features in improving prediction performance, learning speed, and path interpretability.},
  archive      = {J_APIN},
  author       = {Liu, Hao and Li, Dong and Zeng, Bing and Xu, Yang},
  doi          = {10.1007/s10489-025-06327-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Learning discriminative features for multi-hop knowledge graph reasoning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-temporal clustering enhanced multi-graph convolutional network for traffic flow prediction. <em>APIN</em>, <em>55</em>(6), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06329-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamics and uncertainty are the fundamental reasons for the difficulty in accurately predicting traffic flow. In recent years, graph convolutional networks have been widely used in traffic flow prediction because of their excellent dynamic feature mapping ability. However, the existing models usually overlook the correlations among the nodes and the complex impact of external factors on traffic flow, which make it challenging to explore the complex spatial-temporal features. To overcome these shortcomings, we propose a novel Spatial-temporal Clustering enhanced Multi-Graph Convolutional Network (SCM-GCN) for traffic flow prediction. First, a Spatial-Temporal Clustering (STS) module based on the improved adjacency matrix DBSCAN clustering algorithm is constructed, this module divides traffic nodes into multiple highly correlated clusters, each of which consists of multi-graph features and time-varying features. Then, a Multi-Graph Spatial Feature Extraction (MGSFE) module that integrates the graph convolution operation and attention mechanism is designed to extract dynamic spatial features of multi-graph and time-varying features. Next, the Time-Varying Feature Extraction (TVFE) module based on the dilated convolution and gated attention mechanism is constructed. It integrates the output of the MGSFE module to extract dynamic temporal features of time-varying features and output the predicted values. Finally, the comparison and ablation experiments on four datasets show that the proposed model performs better than state-of-the-art models. The key source code and data are available at https://github.com/Bounger2/SCMGCN .},
  archive      = {J_APIN},
  author       = {Bao, Yinxin and Shen, Qinqin and Cao, Yang and Shi, Quan},
  doi          = {10.1007/s10489-025-06329-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Spatial-temporal clustering enhanced multi-graph convolutional network for traffic flow prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic fusion of multi-source heterogeneous data using MOE mechanism for stock prediction. <em>APIN</em>, <em>55</em>(6), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06330-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock prices are influenced by numerous factors, including social media, news, and financial reports, serving as indicators of financial market dynamics. However, harnessing diverse information from different sources and structures to predict price trends remains challenging. In this paper, we propose a dual-stage deep learning model based on the Mixture-of-Expert (MoE) mechanism. In stage one, three distinct expert networks encode information about price movements, financial news, and investor sentiments through multi-source interaction attention. In stage two, a gated network dynamically fuses outputs, capturing temporal relationships in windowed data. Experimental results on the Chinese stock market demonstrate our model outperforms existing ones in forecasting tasks.},
  archive      = {J_APIN},
  author       = {Dong, Yuxin and Wu, Zirui and Hao, Yongtao},
  doi          = {10.1007/s10489-025-06330-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Dynamic fusion of multi-source heterogeneous data using MOE mechanism for stock prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selection based on multi-perspective dynamic neighbourhood entropy measures in a dynamic neighbourhood rough set. <em>APIN</em>, <em>55</em>(6), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06336-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighbourhood rough set (NRS)-based feature selection has been extensively applied in data mining. However, the effectiveness of the NRS model is limited by its reliance on the grid search method to determine the optimal neighbourhood parameter, insensitivity to data distribution under different features, and consideration of uncertainty measures from only one single perspective. To address the aforementioned issues, this study first defines a spatial function that can obtain information about the distribution of samples in space according to the change in the feature subset. On this basis, three perspectives of dynamic neighbourhoods are proposed: pessimistic, neutral, and optimistic. Next, the concept of the dynamic neighbourhood rough set (DNRS) model is developed. The most significant feature of this model is its adaptive ability to dynamically update the neighbourhood radius of samples on the basis of the information of their distribution in space, without the necessity of setting neighbourhood parameters artificially. Then, algebraic and information-theoretic views are introduced to propose multi-perspective dynamic neighbourhood entropy measures, which effectively measure the uncertainty of the data. In addition, a nonmonotonic feature selection algorithm based on mutual information is designed to overcome the limitations of feature selection algorithms that rely on monotonic evaluation functions. This algorithm utilizes multi-perspective dynamic neighbourhood entropy measures from a neutral perspective. Finally, to mitigate the high time complexity in feature selection for high-dimensional datasets, the Fisher score is introduced in an initial dimensionality reduction method. The results of the experiment show that the algorithm effectively eliminates redundant features and improves accuracy.},
  archive      = {J_APIN},
  author       = {Xu, Jiucheng and Ma, Miaoxian and Zhang, Shan and Niu, Wulin},
  doi          = {10.1007/s10489-025-06336-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Feature selection based on multi-perspective dynamic neighbourhood entropy measures in a dynamic neighbourhood rough set},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GANet: Geometry-aware network for RGB-D semantic segmentation. <em>APIN</em>, <em>55</em>(6), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06337-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of RGB-D semantic segmentation has attracted considerable interest in recent times. The challenge is to develop an effective method for combining RGB images, which capture colour variations, with depth images, which provide robust information about object geometry regardless of lighting conditions. Treating both image types equally through the same convolution operator fails to take into account their inherent differences. Thus, in this paper, we propose a novel approach that combines a geometry-aware convolution (GAConv) module and a multiscale fusion module (MFM) with the aim of enhancing the performance of RGB-D image segmentation. The GAConv module effectively captures fine-grained geometric details from depth images, while the MFM module enables efficient integration of multi-scale features, allowing the network to utilise both spatial and semantic information. Extensive experimentation was conducted on the NYUv2 and SUN RGB-D datasets, wherein our model demonstrated consistent superiority over existing state-of-the-art methods in terms of pixel accuracy and mean intersection over union (mIoU).},
  archive      = {J_APIN},
  author       = {Tian, Chunqi and Xu, Weirong and Bai, Lizhi and Yang, Jun and Xu, Yanjun},
  doi          = {10.1007/s10489-025-06337-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {GANet: Geometry-aware network for RGB-D semantic segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature optimization based on multi-order fusion and adaptive recursive elimination for motion classification in doppler radar. <em>APIN</em>, <em>55</em>(6), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06342-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radar-based human motion recognition (HMR) technology has gained substantial importance across diverse domains such as security surveillance, post-disaster search and rescue operations, and the development of smart home environments. The intricate nature of human movements generates radar echo signals with pronounced non-stationary attributes, which encapsulate a wealth of target feature data. However, striking a balance between the precision of motion recognition and the requirement for real-time processing, especially in the context of extracting meaningful features from radar signals, remains a formidable challenge. This research paper introduces a novel approach to tackle this challenge. Firstly,we apply the multi-order fractional Fourier transform (m-FRFT) to radar echo signals, facilitating the extraction of micro-Doppler (m-D) frequency information. Secondly, we have developed an optimized feature selection model named MPG, which stands for m-D parameter screening based on genetic algorithm (GA) and adaptive weight particle swarm optimization (AWPSO). Thirdly, we apply the MPG model to the recursive feature elimination (RFE) algorithm to refine the representation of m-D frequency information, allowing for adaptive parameter adjustment and effective feature dimensionality reduction. The proposed method has been tested using human motion echo data collected from a Doppler radar prototype. The experimental outcomes demonstrate that our approach outperforms traditional feature extraction methods in terms of reducing feature dimensionality, computational efficiency, and classification accuracy.},
  archive      = {J_APIN},
  author       = {Sun, Tong and Ding, Yipeng and Chen, Yuxin and Ping, Lv},
  doi          = {10.1007/s10489-025-06342-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Feature optimization based on multi-order fusion and adaptive recursive elimination for motion classification in doppler radar},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced decision framework for two-player zero-sum markov games with diverse opponent policies. <em>APIN</em>, <em>55</em>(6), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06344-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper takes into account a general two-player zero-sum Markov game scenario in which our agent faces multi-type opponents with multiple policies. To enhance our agent’s return against opponent’s diverse policies, a novel Decision-making Framework based on Opponent Distinguishing and Policy Judgment (DF-ODPJ) is proposed. On the basis of the pre-trained Nash equilibrium strategies, DF-ODPJ can distinguish the opponent’s type by sampling from the interaction trajectory. Then a fast criterion is proposed to judge the opponent’s policy which is proven to minimize the misjudgment probability with optimal threshold calculated. According to the identification results, appropriate policies are generated to enhance the return. The proposed DF-ODPJ is more flexible since it is orthogonal to existing Nash equilibrium algorithms and single-agent reinforcement learning algorithms. The experimental results on grid world, video games, and UAV aerial combat environments illustrate the effectiveness of DF-ODPJ. The code is available at https://github.com/ChenXJ295/DF-ODPJ .},
  archive      = {J_APIN},
  author       = {Zhu, Jin and Wang, Xuan and Geir E., Dullerud},
  doi          = {10.1007/s10489-025-06344-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Enhanced decision framework for two-player zero-sum markov games with diverse opponent policies},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A large scale group decision making with expert guidance via discrete conditional variational autoencoder. <em>APIN</em>, <em>55</em>(6), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06345-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Large Scale Group Decision Making (LSGDM), the differences in decision-makers’ professional backgrounds and attitudes often lead to high-quality decisions being overshadowed by numerous low-quality decisions, thus affecting the accuracy of the final decision. This study proposes a new decision-making method to address this challenge. First, a few experts are invited to make decisions as cluster centers, followed by obtaining decisions from a large number of ordinary decision-makers. The ordinary decisions are then generated and modified using a Discrete Conditional Variational Autoencoder (DCVAE) to enhance decision quality while maintaining consistency with expert decisions. Finally, the normalized prediction selection rate (NPSR) and the Borda Count consensus method are integrated to obtain the final result. Experimental results demonstrate the effectiveness of this method in improving the quality of LSGDM, providing a new solution to the coexistence of high- and low-quality decisions.},
  archive      = {J_APIN},
  author       = {Zhang, Hengshan and He, Adong and Sun, Jiaze and Chen, Yanping},
  doi          = {10.1007/s10489-025-06345-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {A large scale group decision making with expert guidance via discrete conditional variational autoencoder},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-dimensional time-dependent dynamic graph neural network for metro passenger flow prediction. <em>APIN</em>, <em>55</em>(6), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06346-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate metro passenger flow prediction can provide data support for vehicle scheduling and personnel allocation by metro operation departments, ensuring the efficient utilization of related resources. In recent years, Graph Convolutional Networks (GCNs) have demonstrated excellent performance in spatial processing, making them an effective method for extracting spatiotemporal dependencies in metro passenger flow prediction. However, traditional GCN models focus solely on static relationships between stations, overlooking the dynamic changes in station relationships and typically concentrating on short-term temporal dependencies while neglecting longer-term temporal features. To fully consider the spatiotemporal relationships within the metro network, a Multi-Dimensional Temporal Dependency Graph Neural Network (MTDGNN) is proposed for metro passenger flow prediction. Specifically, 1D dilated convolutions are employed to initially extract multi-dimensional temporal dependencies, generating multiple spatiotemporal dependency extraction channels. Two correlation matrices combined with GCN are then proposed to extract spatial relationships between stations within the metro network. The extracted spatiotemporal features are further captured by a Gated Recurrent Unit (GRU) to enhance temporal feature extraction. Subsequently, a multi-head attention mechanism is utilized to integrate the extraction results from multiple channels to obtain the final prediction. Finally, the model is evaluated using metro ridership data from two cities in southwestern and central China. The results indicate that the proposed model exhibits superior predictive performance compared to other methods. The MAE values on the two datasets are 1.5% to 59.3% lower than those of other methods, and the RMSE values are 3.4% to 60.0% lower than those of other methods.},
  archive      = {J_APIN},
  author       = {Li, Ruisen and Zhao, Liqiang and Tang, Jinjin and Tang, Shuixiong and Hao, Zhenxing},
  doi          = {10.1007/s10489-025-06346-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Multi-dimensional time-dependent dynamic graph neural network for metro passenger flow prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An echo state network with adaptive improved pigeon-inspired optimization for time series prediction. <em>APIN</em>, <em>55</em>(6), 1-32. (<a href='https://doi.org/10.1007/s10489-025-06347-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective alternative model to recurrent neural network (RNN), echo state network (ESN) has garnered more attention due to its efficiency in handling time series data. Despite the simple training process and rapid convergence speed of ESN, appropriate parameter settings and a concise network structure are crucial for optimal model performance. Therefore, many optimization algorithms have been proposed to obtain the optimal parameters of ESN. Among these methods, the Pigeon-Inspired Optimization (PIO) has gained attention due to its fast search speed, strong evolution capability, and excellent optimization ability. However, the main drawbacks of PIO are that it may easily get trapped in local optima and achieve lower precision results. To address these issues, this paper proposes a hybrid algorithm combining adaptive improved pigeon-inspired optimization with tabu search (TS-APIO) algorithm. By combining the improved PIO and the tabu search (TS), it not only enhances the global search capability but also strengthens its robustness. Additionally, the adaptive adjustment mechanism can improve the generalization ability. Through theoretical analysis and simulation examples, the TS-APIO algorithm can adaptively select the optimal ESN parameters and structure based on different scenarios. It can effectively enhance the ability to capture the dynamic features and reduce the prediction error.},
  archive      = {J_APIN},
  author       = {Yang, Xu and Wang, Lei and Chen, Qili},
  doi          = {10.1007/s10489-025-06347-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-32},
  shortjournal = {Appl. Intell.},
  title        = {An echo state network with adaptive improved pigeon-inspired optimization for time series prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised heterogeneous graph neural network based on deep and broad neighborhood encoding. <em>APIN</em>, <em>55</em>(6), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06348-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised heterogeneous graph neural networks have shown remarkable effectiveness in addressing the challenge of limited labeled data. However, current contrastive learning methods face limitations in leveraging neighborhood information for each node. Some approaches utilize the local information of the target node, ignoring useful signals from deeper neighborhoods. On the other hand, simply stacking convolutional layers to expand the neighborhood inevitably leads to over-smoothing. To address the problems, we propose HGNN-DB, a Self-supervised Heterogeneous Graph Neural Network Based on Deep and Broad Neighborhood Encoding to tackle the over-smoothing problem within heterogeneous graphs. Specifically, HGNN-DB aims to learn informative node representations by incorporating both deep and broad neighborhoods. We introduce a deep neighborhood encoder with a distance-weighted strategy to capture deep features of target nodes. Additionally, a single-layer graph convolutional network is employed for the broad neighborhood encoder to aggregate broad features of target nodes. Furthermore, we introduce a collaborative contrastive mechanism to learn the complementarity and potential invariance between the two views of neighborhood information. Experimental results on four real-world datasets and seven baselines demonstrate that our model significantly outperforms the current state-of-the-art techniques on multiple downstream tasks. The codes and datasets for this work are available at https://github.com/SSQiana/HGNN-DB.},
  archive      = {J_APIN},
  author       = {Song, Qianyu and Li, Chao and Fu, Jinhu and Zeng, Qingtian and Xie, Nengfu},
  doi          = {10.1007/s10489-025-06348-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Self-supervised heterogeneous graph neural network based on deep and broad neighborhood encoding},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NNBSVR: Neural network-based semantic vector representations of ICD-10 codes. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06349-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatically predicting ICD-10 codes from clinical notes using machine learning models can reduce the burden of manual coding. However, existing methods often overlook the semantic relationships between ICD-10 codes, resulting in inaccurate evaluations when clinically similar codes are considered completely different. Traditional evaluation metrics, which rely on equality-based matching, fail to capture the clinical relevance of predicted codes. This study introduces NNBSVR (Neural Network-Based Semantic Vector Representations), a novel approach for generating semantic-based vector representations of ICD-10 codes. Unlike traditional approaches that rely on exact code matching, NNBSVR incorporates contextual and hierarchical information to enhance both prediction accuracy and evaluation methods. We validate NNBSVR using intrinsic and extrinsic evaluation methods. Intrinsic evaluation assesses the vectors’ ability to reconstruct the ICD-10 hierarchy and identify clinically meaningful clusters. Extrinsic evaluation compares our relevancy-based approach, which includes customized evaluation metrics, to traditional equality-based metrics on an ICD-10 code prediction task using a 9.57 million clinical notes corpus. NNBSVR demonstrates significant improvements over equality-based metrics, achieving a 9.81% gain in micro-F1 score on the training set and a 12.73% gain on the test set. A manual review by medical experts on a sample of 10,000 predictions confirms an accuracy of 92.58%, further validating our approach. This study makes two significant contributions: first, the development of semantic-based vector representations that encapsulate ICD-10 code relationships and context; second, the customization of evaluation metrics to incorporate clinical relevance. By addressing the limitations of traditional equality-based evaluation metrics, NNBSVR enhances the automated assignment of ICD-10 codes in clinical settings, demonstrating superior performance over existing methods.},
  archive      = {J_APIN},
  author       = {Hatoum, Monah Bou and Charr, Jean Claude and Ghaddar, Alia and Guyeux, Christophe and Laiymani, David},
  doi          = {10.1007/s10489-025-06349-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {NNBSVR: Neural network-based semantic vector representations of ICD-10 codes},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning sparse filters-based convolutional networks without offline training for robust visual tracking. <em>APIN</em>, <em>55</em>(6), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06350-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the scarcity of training samples in the visual tracking task, almost all existing Convolutional Neural Networks (CNNs) based deep tracking algorithms rely heavily on large auxiliary datasets to train the tracking model offline. However, such offline training has two inevitable disadvantages: (1) the learned generic features may be less discriminative for tracking specific objects; (2) the training process demands huge computational power provided by high-performance graphics processing units (GPUs), which is not always available in many practical applications. Therefore, learning effective generic features without offline training for robust visual tracking is a necessary and challenging task. This paper tackles this task by proposing the Sparse Filters-based Convolutional Network (SFCN), which is a fully feed-forward convolutional network with a lightweight structure including two convolutional layers. Its convolutional kernels are a set of sparse filters learned and updated online from local patches using sparse dictionary learning. Benefiting from the learned sparse filters, SFCN learns effective generic features by exploiting both the discriminative information between the foreground and background of the target region and the hierarchical layout information among the local patches inside each target candidate region. Furthermore, a dynamic model updating strategy is adopted to alleviate the drift problem. Extensive experiments on five large-scale benchmark datasets show that the proposed method performs favorably against several state-of-the-art tracking algorithms.},
  archive      = {J_APIN},
  author       = {Xu, Qi and Xu, Zhuoming and Chen, Zhe and Chen, Yun and Wang, Huabin and Tao, Liang},
  doi          = {10.1007/s10489-025-06350-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Learning sparse filters-based convolutional networks without offline training for robust visual tracking},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LGCGNet: A local-global context guided network for real-time water surface semantic segmentation. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06351-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned boats will encounter many static and dynamic obstacles during navigation, and only real-time obstacle sensing can ensure safe navigation and long endurance of unmanned boats. In this paper, LGCGNet is proposed to perform real-time water surface semantic segmentation on the images captured by the on-board camera. In order to ensure that the model adapted to obstacles with extremely variable scales, a local-global module is proposed in this paper. The local-global module consisted of residual dense dilated module and context-enhanced separable self-attention. Residual dense dilated module enabled the enhancement of local detail information and context-enhanced separable self-attention enabled model receptive field expansion. In addition, the sub-pixel downsampling module is used to avoid the loss of feature information to improve segmentation accuracy. Experiments on the MaSTr1325 dataset showed that LGCGNet apprpached the segmentation accuracy of state-of-the-art semantic segmentation models with only 689,000 parameters and 9.068G floating point operations per second, with an mIoU of 84.14%. In addition, the processing speed of LGCGNet is 34.86FPS, which meets the frame rate conditions of commercially available photovoltaic equipment. The experiments demonstrated that the LGCGNet proposed in this paper strike a good balance between achieving high accuracy, reducing model size and improving real-time performance.},
  archive      = {J_APIN},
  author       = {Liu, Ting and Luo, Peiqi and Wang, Guofeng and Zhang, Yuxin and Lu, Xiangyi and Dong, Mengyu},
  doi          = {10.1007/s10489-025-06351-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {LGCGNet: A local-global context guided network for real-time water surface semantic segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scnet: Spectral convolutional networks for multivariate time series classification. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06352-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread application of time series data, the study of classification techniques has become an important topic. Although existing multivariate time series classification (MTSC) methods have made progress, they often rely on one-dimensional (1D) time series, which limits their ability to capture complex temporal dynamics and multiscale features. To address these challenges, a Spectral Convolutional Network (SCNet) is introduced in this work. SCNet effectively transforms 1D time series data into the frequency domain using an enhanced Discrete Fourier Transform (enhanced_DFT), revealing periodicity and key frequency components while reshaping the data into a two-dimensional (2D) time series for better representation. Furthermore, it uses a Spectral Energy Prioritization method to optimize frequency domain energy distribution and a multiscale convolutional module to capture features at different scales, improving the model’s ability to analyze short-term and long-term trends. To validate the effectiveness and superiority, we conducted extensive experiments on 10 sub-datasets from the well-known UEA dataset. The results show that our proposed SCNet achieved the highest average accuracy of 74.3%, which is 2.2% higher than the current state-of-the-art models, demonstrating its potential for practical application and efficiency in MTSC task.},
  archive      = {J_APIN},
  author       = {Wu, Xing and Xing, Xinyu and Yao, Junfeng and Qian, Quan and Song, Jun},
  doi          = {10.1007/s10489-025-06352-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Scnet: Spectral convolutional networks for multivariate time series classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Precise spiking neurons for fitting any activation function in ANN-to-SNN conversion. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06354-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) are recognized for their energy efficiency due to spike-based communication. In this regard, the shift towards SNNs is driven by their ability to significantly reduce energy consumption while maintaining the performance of ANNs. Converting Artificial Neural Networks (ANNs) to SNNs is a key research focus, but existing methods often struggle with balancing conversion accuracy and latency, and are typically restricted to ReLU activations. We introduce Precision Spiking (PS) neurons, a novel dynamic spiking neuron model that can precisely fit any activation function by jointly regulating spike timing, reset voltage, and membrane potential threshold. This capability enables exact parameter optimization via iterative methods, achieving low-latency, high-accuracy ANN-to-SNN conversion. Experiments on image classification and natural language processing benchmarks confirm state-of-the-art results, with a maximum conversion loss of 0.55% and up to 0.38% accuracy improvement over the original ANN. To the best of our knowledge, this method offers a significant advancement over existing approaches by achieving high-precision fitting of arbitrary activation functions with low latency and minimal conversion loss, thus considerably expanding the range of feasible ANN-to-SNN conversions.},
  archive      = {J_APIN},
  author       = {Wang, Tianqi and Shen, Qianzi and Li, Xuhang and Zhang, Yanting and Wang, Zijian and Yan, Cairong},
  doi          = {10.1007/s10489-025-06354-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Precise spiking neurons for fitting any activation function in ANN-to-SNN conversion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NoRD: A framework for noise-resilient self-distillation through relative supervision. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06355-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) has become a pivotal technique in deep learning, facilitating model compression and regularization by transferring knowledge from one neural network to another, enhancing its capabilities for downstream tasks such as classification. However, real-world datasets often suffer from noisy label problems, significantly hindering neural network learning in supervised tasks. Recent advancements in KD aim to improve noise-robustness and regularization in deep neural networks through different learning paradigms. Yet, prevalent approaches often exhibit noise-prone behaviors as the student network heavily relies on the teacher’s learning. To address this challenge, we propose a robust knowledge transfer method, NoRD: a Noise-Resilient Self-Distillation framework. This approach leverages relative self-supervision combined with decision matching to minimize noise susceptibility during the knowledge transfer process. Our study evaluates this technique on CIFAR-10, CIFAR-100, and MNIST datasets with synthetic label noise. Results showcase that our method achieves 8-10% higher test accuracy compared to state-of-the-art noise-robust loss functions at noise rates exceeding 50%, surpassing well-known KD methods by 4-5% in top-1 test accuracy. The code is available at https://github.com/philsaurabh/NoRD_Applied-Intelligence .},
  archive      = {J_APIN},
  author       = {Sharma, Saurabh and Lodhi, Shikhar Singh and Srivastava, Vanshika and Chandra, Joydeep},
  doi          = {10.1007/s10489-025-06355-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {NoRD: A framework for noise-resilient self-distillation through relative supervision},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lbgcn: Lightweight bilinear graph convolutional network with attention mechanism for recommendation. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06357-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Graph Convolutional Neural Network (GCN) is a powerful technique for learning and representing graph data, commonly utilized in model-based collaborative filtering recommendation algorithms. However, despite its effectiveness, the issues are data sparsity and interpretability. Most existing GCN-based models simply update the central node’s features by aggregating the features of its neighbors, typically via a weighted sum. Unfortunately, this approach fails to capture the cooperative information hidden in the neighbor interactions. To address this limitation, we propose a recommendation algorithm based on a convolution network of lightweight neighborhood interactive graphs, named the Lightweight Bilinear Graph Convolutional Network (LBGCN). Our approach employs a lightweight graph convolutional neural network as a multi-level feature aggregator, leveraging higher-order connectivity to aggregate neighborhood information into a multi-level feature of the node through the aggregator. Meanwhile, we introduce a local feature aggregator to capture the collaborative filtering signals in the interaction features of neighbors. Finally, we combine the results using an attention mechanism to obtain the embedded representation of final users and items. In addition, we demonstrate the rationality and effectiveness of our proposed model through experiments on three public datasets. The results show that our method could gain 2.52% NDCG improvement at most.},
  archive      = {J_APIN},
  author       = {Su, Yu and Wei, Pingzhu and Zhu, Linbo and Xu, Lixiang and Wang, Xianquan and Tong, He and Han, Ze},
  doi          = {10.1007/s10489-025-06357-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Lbgcn: Lightweight bilinear graph convolutional network with attention mechanism for recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel ensemble bagging-logistic regression algorithm for NoSQL database security. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06358-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present era, the use of the Internet has drastically increased in the sharing of digital information. In this case, the digital information is stored using cloud technology or NoSQL databases. However, there is a significant challenge in protecting and managing the cloud and NoSQL-based data and extracting required information from these sources while maintaining the actual information. The network traffic has also increased significantly, which requires more memory and sufficient systems to manage and monitor the influx of Big Data. Traditional relational databases face issues in managing and securing the cloud-based dynamic data generated from various sources. NoSQL databases have recently been used to store and manage dynamic data effectively. However, there are security and privacy issues with the NoSQL databases, which remain challenging to provide. Consequently, in the present study, we propose a novel algorithm that enhances the security of the NoSQL databases and predicts its success rate. Initially, we implemented the Fernet data masking algorithm to secure the NoSQL database. Then, the secured data is classified and predicted using an innovative proposed method called the Ensemble Bagging Classifier-Logistic Regression (EBC-LR) to validate the accuracy of the secured NoSQL database. The experimental outcomes depict that our proposed algorithm achieves 85 percent accuracy, better than traditional methods in enhancing the security of NoSQL databases. Our proposed algorithm can effectively predict secure standard databases with the highest success rate.},
  archive      = {J_APIN},
  author       = {Kanade, Anuradha and Vibhute, Amol D. and Kanade, Shantanu},
  doi          = {10.1007/s10489-025-06358-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Novel ensemble bagging-logistic regression algorithm for NoSQL database security},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixmamba-fewshot: Mamba and attention mixer-based method with few-shot learning for bearing fault diagnosis. <em>APIN</em>, <em>55</em>(6), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06361-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, artificial intelligence, particularly machine learning and deep learning has ushered in a new era of technological advancements leading to significant progress across various domains. In the field of computer vision, deep learning has made substantial contributions, impacting everything from daily life to production and industry. When machines, rotating devices, and engines operate, bearing failures are inevitable. Our task is to accurately detect or diagnose these failures. However, a key challenge lies in the lack of sufficient data on bearing faults to train a model capable of delivering highly accurate diagnostic results. To address this issue, in this paper, we propose a new approach named MixMamba-Fewshot, leveraging few-shot learning and using a feature extraction module that integrates an attention mechanism called the Priority Attention Mixer and Mamba - a novel theory that has recently gained considerable attention within the research community. Using Mamba for vision-based feature extraction in classification tasks, particularly in few-shot learning is an innovative approach, and it has shown promising results in improving the accuracy of bearing fault diagnosis. When we tested our model on the datasets provided by Case Western Reserve University (CWRU) and the Paderborn University (PU) Bearing Dataset, we compared it with previously published models. Our proposed approach demonstrated a significant improvement in diagnostic accuracy and clearly outperformed existing approaches. Our code will be available at: https://github.com/linhthan216/MixMamba-Fewshot .},
  archive      = {J_APIN},
  author       = {Than, Nhu-Linh and Nguyen, Van Quang and Truong, Gia-Bao and Pham, Van-Truong and Tran, Thi-Thao},
  doi          = {10.1007/s10489-025-06361-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Mixmamba-fewshot: Mamba and attention mixer-based method with few-shot learning for bearing fault diagnosis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HiProIBM: Unsupervised continual learning through hierarchical prototypical cross-level discrimination along with information bottleneck subnetwork masking. <em>APIN</em>, <em>55</em>(6), 1-27. (<a href='https://doi.org/10.1007/s10489-025-06362-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Catastrophic Forgetting (CF) occurs when a machine learning model forgets the experience of previous tasks while learning new tasks due to inadequate retention mechanisms. Unsupervised continual learning (UCL) addresses this by enabling the model to adapt to new tasks using unlabeled data while retaining past knowledge. To mitigate CF in UCL, we use a parameter isolation technique to mask sub-networks dedicated to each task, thus preventing interference with previous tasks. However, relying solely on weight magnitude for constructing these sub-networks can result in the retention of irrelevant weights and the creation of redundant sub-networks. This approach also risks capacity saturation and information suppression for tasks encountered later in the sequence. To overcome this, we use masked sub-networks, inspired by the information bottleneck (IB) concept. It accumulates valuable information into essential weights to construct redundancy-free sub-networks which effectively mitigates CF and enables the new task training. The IB subnetwork masking faces challenges in balancing input compression with meaningful pattern preservation without labels. It risks overcompression and loss of crucial latent structures, which degrades model performance. We address this by learning multiple semantic hierarchies present in the data using unsupervised contrastive learning. However traditional contrastive learning techniques learn meaningful representations by contrasting similar and dissimilar data points. These approaches lack adequate representational power for modeling datasets with multiple semantic hierarchies. The inherent hierarchical semantic structures in datasets are necessary to integrate semantically related clusters into larger, coarser-grained clusters, but existing contrastive learning methods often overlook this and limit semantic understanding. We address this by constructing and updating hierarchical prototypes with cross-level group discrimination to represent semantic structures in the latent space. Our experiments on four standard datasets show performance improvements over SOTA baselines for varying task-sequences from 5 to 100, with nearly-zero forgetting.},
  archive      = {J_APIN},
  author       = {Malviya, Ankit and Kumar Maurya, Chandresh},
  doi          = {10.1007/s10489-025-06362-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-27},
  shortjournal = {Appl. Intell.},
  title        = {HiProIBM: Unsupervised continual learning through hierarchical prototypical cross-level discrimination along with information bottleneck subnetwork masking},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting gas flow rates of wellhead chokes based on a cascade forwards neural network with a historically limited penetrable visibility graph. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06365-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel hybrid model that combines the cascade forward neural network (CFNN) with a historical limited penetrable visibility graph (HLPVG) for accurate prediction of gas flow rates through wellhead chokes in shale gas production. The model addresses the challenges of complex, nonlinear relationships between multiple variables affecting gas flow, including liquid–gas ratio (LGR), upstream pressure, temperature, and choke bean size. Using 11,572 field production samples from shale gas fields in the southern Sichuan Basin, the CFNN-HLPVG model demonstrates superior predictive performance compared to the conventional methods. The HLPVG algorithm transforms time series data into a graph structure, enabling the extraction of rich temporal and topological features, whereas the CFNN captures the complex interactions between variables. The model achieves a mean absolute relative error (MARE) of 0.014, significantly outperforming traditional approaches, including the Gilbert-type correlation, support vector machine, and other neural network architectures. Sobol sensitivity analysis revealed that choke bean size has the greatest impact on gas flow prediction (37.7% first-order sensitivity), followed by upstream pressure (19.3%) and temperature (11.6%), whereas LGR has a minimal influence (0.6%). The model performs particularly well under normal operating conditions but shows decreased accuracy in extreme environments with high temperature and pressure. This research provides a novel approach to gas flow prediction in wellhead chokes, offering valuable insights for optimizing shale gas production operations while highlighting areas for future improvement in handling extreme conditions and multisource data integration.},
  archive      = {J_APIN},
  author       = {Jiang, Youshi and Hu, Jingkai and Chen, Xiyu and Mo, Weiren},
  doi          = {10.1007/s10489-025-06365-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Predicting gas flow rates of wellhead chokes based on a cascade forwards neural network with a historically limited penetrable visibility graph},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised anomalous machine sound detection model based on spectrogram decomposition and parallel sub-network. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06366-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomalous Sound Detection (ASD) has research significance and application prospect industrial automation. Most existing models of ASD have limited ability to effectively utilize machine sound features, leading to reduced stability against sound anomalies and domain shift variations. To address the above issues, we propose a self-supervised ASD model based on spectrogram decomposition and parallel sub-network in this paper. Firstly, we decompose the spectrogram along the time and frequency dimensions to balance feature size and information integrity. This approach emphasizes the temporal and frequency variations in the feature map, facilitating a better understanding of the factors that affect machine sounds under domain shift conditions. Secondly, we design a pair of parallel training sub-networks. The parallel sub-networks employ self-attention mechanisms and shared gradients to effectively capture changes in features across both time and frequency dimensions. This approach improves model stability against anomalies and domain shifts. Finally, the anomaly scores of sub-network branches are fused as anomalous detection results. The performance of the proposed model is validated on DCASE2022 Task2 dataset. The Area under the Receiver Operating Characteristic Curve (AUC) and partial AUC (pAUC) of our model reached 72.89% and 64.83%. The results confirm the effectiveness of the proposed model, achieving better performance.},
  archive      = {J_APIN},
  author       = {Zhang, Tao and Kong, Lingguo and Zhao, Xin and Li, Donglei and Geng, Yanzhang and Ding, Biyun and Wang, Chao},
  doi          = {10.1007/s10489-025-06366-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {A self-supervised anomalous machine sound detection model based on spectrogram decomposition and parallel sub-network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of deep non-smooth symmetric nonnegative matrix factorization on hierarchical clustering. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06367-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep matrix factorization (deep MF) is an increasingly popular unsupervised data-mining technique that operates as a deep decomposition rooted in traditional nonnegative matrix factorization (NMF). Compared with standard NMF, deep MF has shown excellent performance in the extraction of hierarchical information from complex datasets. For cases in which the data matrices corresponding to the dataset are symmetric—such as the adjacency matrix of an undirected graph in network analysis—this paper proposes a deep MF variant called deep non-smooth nonnegative symmetric matrix factorization (DNSSNMF). The aim of this work is to enhance the extraction of complex hierarchical structures in high-dimensional datasets and achieve the clustering of structures inherent in graphical representations by improving the goodness-of-fit of the factor matrix product. Accordingly, we successfully applied DNSSNMF to post-traumatic-stress-disorder (PTSD) datasets and synthetic datasets to extract several hierarchical communities. In particular, we extracted non-disjoint communities in the partial correlation network of psychiatric symptoms in PTSD, revealing correlations between different symptoms and leading to meaningful clinical interpretations. The results of our numerical experiments indicated promising applications of DNSSNMF in fields including network analysis and medicine.},
  archive      = {J_APIN},
  author       = {Li, Shunli and Lu, Linzhang and Liu, Qilong and Chen, Zhen},
  doi          = {10.1007/s10489-025-06367-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Analysis of deep non-smooth symmetric nonnegative matrix factorization on hierarchical clustering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Composed image retrieval: A survey on recent research and development. <em>APIN</em>, <em>55</em>(6), 1-35. (<a href='https://doi.org/10.1007/s10489-025-06372-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, composed image retrieval (CIR) has gained significant attention within the research community due to its excellent research value and extensive real-world applications. CIR allows modifying query images based on user-provided text descriptions, producing search results that better match users’ intent. This paper conducts a comprehensive and up-to-date survey of CIR research and its applications. We summarise recent advancements in CIR methodologies from these perspectives by breaking down a CIR system into four key processes-feature extraction, feature alignment, feature fusion, and image retrieval. We examine feature extraction, emphasizing deep learning techniques for images and text. As deep learning evolves, feature alignment increasingly integrates with other processes, encouraging us to categorize related methods into explicit and implicit approaches. From the perspective of feature fusion, we investigate advancements in image-text feature fusion techniques, categorizing them into 6 broad categories and 17 subcategories. We also summarize different architecture types and training loss functions for image retrieval. Additionally, we review standard benchmark datasets and evaluation metrics in CIR, presenting a comparative analysis of the accuracy of crucial CIR approaches. Finally, we put forward several critical yet underexplored issues in the field.},
  archive      = {J_APIN},
  author       = {Wan, Yongquan and Zou, Guobing and Zhang, Bofeng},
  doi          = {10.1007/s10489-025-06372-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-35},
  shortjournal = {Appl. Intell.},
  title        = {Composed image retrieval: A survey on recent research and development},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anchoring actions using conditional behavior trees and genetic programming. <em>APIN</em>, <em>55</em>(6), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06373-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic Kitting means the creation of parts assortment to be used later. These parts are selected from one or more containers in which there are different types of them randomly distributed. The Anchoring Problem should be considered if we want to provide a general solution to robotic kitting, since users want that it works with different types of parts that are not known ’a priori’. Therefore, we are working on a human supervised approach in which Behavior Trees, robot learning and human-robot interaction are used to anchor percepts and operations to symbols during commissioning or reconfiguration phases. In this paper we explain: (1) the anchoring mechanisms in our system and how behavior trees can be used to represent an anchor, and (2) how Genetic Programming is used to generate Conditional Behavior Trees that anchor symbolic actions to robot operations.},
  archive      = {J_APIN},
  author       = {Escudero-Rodrigo, Diego and Alquezar, René and Aranda, Joan},
  doi          = {10.1007/s10489-025-06373-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Anchoring actions using conditional behavior trees and genetic programming},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADIMPL: A dynamic, real-time and robustness attack detection model for industrial cyber-physical systems based on improved meta pseudo labels. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06374-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the introduction of networking has increased the efficiency of Industrial Cyber-Physical Systems (ICPS), it has also lowered the cost for attackers, significantly increasing security risks. Current research on ICPS attack detection focuses on deep learning methods. However, the dependence on large labeled datasets often hinders these systems from adapting quickly to the dynamic changes and real-time demands of the ICPS environment. To address these issues, we present an attack detection method based on improved meta pseudo label (ADIMPL). ADIMPL innovatively combines two-layer network traffic feature extraction with the compact SqueezeNet deep neural network, achieving high performance with a minimal number of labeled samples. Additionally, the method dynamically adapts to changing attack patterns, significantly increasing detection accuracy while enhancing the robustness and real-time processing capabilities of the detection system. Extensive experiments on real-world industrial CPS datasets (CIC-IDS2017, CIC-IDS2018, and the CIC-Attack Dataset 2023) demonstrate that ADIMPL can effectively, robustly, and in real-time detect network attacks against industrial CPS. Notably, ADIMPL achieves a detection accuracy of 99.13% with an average latency of 0.098 s and maintains a minimum attack detection accuracy of 91.99% even under our proposed GAN+OPSO malicious attacks.},
  archive      = {J_APIN},
  author       = {Zhang, Bohan and Zhang, Pan and Wang, Zhiwen and Lv, Jiaqi and Miao, Wei},
  doi          = {10.1007/s10489-025-06374-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {ADIMPL: A dynamic, real-time and robustness attack detection model for industrial cyber-physical systems based on improved meta pseudo labels},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STGFP: Information enhanced spatio-temporal graph neural network for traffic flow prediction. <em>APIN</em>, <em>55</em>(6), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06377-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction is crucial for the development of intelligent transportation systems aimed at preventing and mitigating traffic issues. We present an information-enhanced spatio-temporal graph neural network model to predict traffic flow, addressing the inefficient utilization of non-Euclidean structured traffic data. Firstly, we employ a multivariate temporal attention mechanism to capture dynamic temporal correlations across different time intervals, while a second-order graph attention network identifies spatial correlations within the network. Secondly, we construct two types of traffic topology graphs that comprehensively describe traffic flow features by integrating non-Euclidean traffic flow data, regional traffic status information, and node features. Finally, a multi-graph convolution neural network is designed to extract long-range spatial features from these traffic topology graphs. The spatio-temporal feature extraction module then combines these long-range spatial features with spatio-temporal features to fuse multiple features and improve prediction accuracy. Experimental results demonstrate that the proposed approach outperforms state-of-the-art baseline methods in predicting traffic flow performance.},
  archive      = {J_APIN},
  author       = {Li, Qi and Wang, Fan and Wang, Chen},
  doi          = {10.1007/s10489-025-06377-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {STGFP: Information enhanced spatio-temporal graph neural network for traffic flow prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-local modeling of enhancer-promoter interactions, a correspondence on “LOCO-EPI: Leave-one-chromosome-out (LOCO) as a benchmarking paradigm for deep learning based prediction of enhancer-promoter interactions”. <em>APIN</em>, <em>55</em>(6), 1-5. (<a href='https://doi.org/10.1007/s10489-025-06378-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recent paper by Tahir et al. (Appl Intell 55:71, 2024) in Applied Intelligence reported a computational model of enhancer promoter interactions without realizing that many of their conclusions were previously published in 2018. In addition to correcting this record, the authors appear to be unaware of an additional body of previous work on enhancer-promoter interactions, which can explain why their computational model performs poorly. We describe how the weak predictive power of their model is consistent with new insights gained from substantial recent progress in the area of detecting and modeling enhancer promoter interactions constrained by DNA looping, extrusion by cohesin, and CTCF.},
  archive      = {J_APIN},
  author       = {Beer, Michael A.},
  doi          = {10.1007/s10489-025-06378-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-5},
  shortjournal = {Appl. Intell.},
  title        = {Non-local modeling of enhancer-promoter interactions, a correspondence on “LOCO-EPI: Leave-one-chromosome-out (LOCO) as a benchmarking paradigm for deep learning based prediction of enhancer-promoter interactions”},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A local generation-mix cascade network for image translation with limited data. <em>APIN</em>, <em>55</em>(6), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06379-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image translation based on deep generative models often overfits with limited data. Current methods overcome this problem through mix-based data augmentation. However, if latent features are mixed without considering semantic correspondences, augmented samples may exhibit visible artifacts and mislead model training. In this paper, we propose a Local Generation-Mix Cascade Network (LogMix), a data augmentation strategy for image translation tasks with limited data. Through cascading a local feature generation module and mixing module, LogMix enables the generation of a reference feature bank, which is mixed with the most similar local representation to form a new intermediate sample. Furthermore, we design a semantic relationship loss based on the mixed distance of latent features ensures consistency in the distribution of features between the generated and source domains. LogMix effectively mitigates the overfitting problem by learning to translate intermediate samples instead of memorizing the training data Experimental results across various tasks demonstrate that, even with limited data, LogMix data augmentation reduces image ambiguity and offers significant advantages in establishing realistic cross-domain mappings.},
  archive      = {J_APIN},
  author       = {Zhang, Yusen and Li, Min and Gou, Yao and Zhang, Xianjie and He, Yujie},
  doi          = {10.1007/s10489-025-06379-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {A local generation-mix cascade network for image translation with limited data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel fuzzy knowledge graph structure for decision making of multimodal big data. <em>APIN</em>, <em>55</em>(6), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06381-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-making in the era of big data is always a challenge. Recently, various methods especially graph sampling have been presented to assist the decision more effectively. As real-world graphs are large, constantly evolving, and distributed in nature, it becomes necessary to sample their structures for many different goals. Therefore, acquiring a comprehensive and in-depth understanding of graph sampling is essential to strengthen this field. In addition, graph sampling techniques often rely on edge or vertex sampling without effective methods for rule or path sampling. In this paper, we propose a novel framework for the rule-based sampling method on fuzzy knowledge graphs. In this framework, fuzzy knowledge graphs are built on integrated databases from multiple sources. We design a purposive random sampling method based on fuzzy rules on graphs to prioritize important rules for output inference. The remaining important rules form the core structure of the fuzzy knowledge graph, known as the Fuzzy Knowledge Graph Structure (FKGS). This structure is considered as a compression mechanism to reduce computational complexity when representing and performing calculations for large-scale data problems. Experimental results based on benchmark datasets on diabetes mellitus show that the sampling method greatly reduces the calculation time while maintaining high accuracy. Moreover, the purposive random sampling method results in significantly higher accuracy than the random sampling method. Besides, the ANOVA method is also conducted to statistically validate the model. The results are significant for decision-making in the context of big data.},
  archive      = {J_APIN},
  author       = {Tan, Nguyen Hong and Long, Cu Kim and Tuan, Tran Manh and Chuan, Pham Minh and Hai, Pham Van and Khanh, Phan Hung and Son, Le Hoang},
  doi          = {10.1007/s10489-025-06381-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {A novel fuzzy knowledge graph structure for decision making of multimodal big data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instructed fine-tuning based on semantic consistency constraint for deep multi-view stereo. <em>APIN</em>, <em>55</em>(6), 1-25. (<a href='https://doi.org/10.1007/s10489-025-06382-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing depth map-based multi-view stereo (MVS) methods typically assume that texture features remain consistent across different viewpoints. However, factors such as lighting changes, occlusions, and weakly textured regions can lead to inconsistent texture features, posing challenges for feature extraction. As a result, relying solely on texture consistency does not always yield high-quality reconstruction results in certain scenarios. In contrast, high-level semantic concepts corresponding to the same objects remain consistent across different viewpoints, which we define as semantic consistency. Since designing and training new MVS networks from scratch is both costly and labor-intensive, we propose fine-tuning existing depth map-based MVS networks during testing phase by incorporating semantic consistency constraints to improve the reconstruction quality in regions with poor results. Considering the robust open-set detection and zero-shot segmentation capabilities of Grounded-SAM, we first use Grounded-SAM to generate semantic segmentation masks for arbitrary objects in multi-view images based on text instructions. These masks are then used to fine-tune pre-trained MVS networks via aligning them from different viewpoints to the reference viewpoint and optimizing the depth maps based on the proposed semantic consistency loss function. Our method is designed as a test-time approach that is adaptable to a wide range of depth map-based MVS networks, requiring only adjustments to a small number of depth-related parameters. Comprehensive experimental evaluation across different MVS networks and large-scale scenarios demonstrates that our method effectively enhances reconstruction quality at a lower computational cost.},
  archive      = {J_APIN},
  author       = {Zhang, Yan and Yan, Hongping and Ding, Kun and Cai, Tingting and Zhou, Yueyue},
  doi          = {10.1007/s10489-025-06382-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {Instructed fine-tuning based on semantic consistency constraint for deep multi-view stereo},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DropMismatch: Removing mismatched UI elements for better pixel to code generation. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06384-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automating the generation of user interface (UI) code from design images has gained significant attention due to its potential to streamline application development. However, the effectiveness of deep learning models in this domain is often hindered by mismatches between UI images and their corresponding layout code, a common issue in image-text datasets. In this paper, we introduce a framework that locates and removes these mismatches, thereby improving the accuracy of UI code generation models. Our approach leverages a convolutional neural network to predict the alignment between UI components and layout code nodes, coupled with a tree-based heuristic algorithm to localize mismatches. Through extensive evaluation, we demonstrate that our method enhances the accuracy of UI code generation by approximately 15%, while significantly reducing the need for costly manual annotations. The proposed framework not only advances the state of automated UI code generation but also lays the foundation for creating high-quality, large-scale UI datasets, essential for future research and development in this field.},
  archive      = {J_APIN},
  author       = {Li, Ming and Lin, Tao},
  doi          = {10.1007/s10489-025-06384-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {DropMismatch: Removing mismatched UI elements for better pixel to code generation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NVS-former: A more efficient medical image segmentation model. <em>APIN</em>, <em>55</em>(6), 1-12. (<a href='https://doi.org/10.1007/s10489-025-06387-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current field of medical image segmentation research, numerous Transformer-based segmentation models have emerged. However, these models often suffer from limitations in multi-scale feature extraction and struggle to capture local detail features and contextual information, thereby constraining their segmentation performance. This paper introduces a novel model for medical image segmentation, called NVS-Former, which comprises both an encoder and a decoder. The key innovation of NVS-Former lies in its redesigned core module during the encoding phase, which not only enhances feature extraction capabilities but also improves the capture of local detail information. Additionally, the decoder structure has been reengineered to further optimize the model’s class prediction abilities. NVS-Former has demonstrated superior performance in tasks involving multi-organ, pulmonary detail, and cell segmentation. In various comparative experiments, it consistently outperformed state-of-the-art methods, highlighting its efficiency and stability in medical image segmentation.},
  archive      = {J_APIN},
  author       = {Huang, Xiangdong and Huang, Junxia and Ibrahim, Noor Farizah},
  doi          = {10.1007/s10489-025-06387-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {NVS-former: A more efficient medical image segmentation model},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A framework for solving bias in graph-based recommender systems with a causal perspective. <em>APIN</em>, <em>55</em>(6), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06388-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems founded on graph neural networks (GNN) have been extensively employed because of their exceptional recommendation efficiency. Nevertheless, numerous recommendation biases also crop up, We have observed that delicate details such as gender and age are frequently implicitly apprehended by recommendation systems, culminating in unfair recommendations, and the associated algorithms of GNN will magnify this bias. To tackle these difficulties, this paper puts forth a method of introducing the notion of causal fairness into the issue of fairness in GNN-based recommendation systems, to accomplish counterfactual fairness of user-sensitive information and thereby attain unbiased recommendations. Specifically, given a GNN-based recommendation system model, which is implemented in our devised fairness framework, chiefly obtaining equitable effects through two facets: (1) attaining user embedding fairness through the counterfactual fairness technique; (2) mitigating the prejudiced impact caused by the GNN algorithm using the proposed central association subgraph method. The amalgamation of these two facets ultimately delivers unbiased recommendations. The effectiveness and sophistication of our proposed method for mitigating partiality problems in GNN recommendation systems from a causal perspective (MGRC) have been proven via experiments on four real-world datasets.},
  archive      = {J_APIN},
  author       = {Yang, Kewu and Li, Guogang and Wang, Linjia and Xie, Jianrong},
  doi          = {10.1007/s10489-025-06388-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {A framework for solving bias in graph-based recommender systems with a causal perspective},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PAG-unet: Multi-task dense scene understanding with pixel-attention-guided unet. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06389-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task dense scene understanding is a fundamental research area in computer vision (CV). By predicting pixels, perceiving, and reasoning about multiple related tasks, it improves both accuracy and data efficiency. However, it faces the challenge that some tasks may require more independent feature representations, and excessive sharing can lead to interference between tasks. To address this issue, we propose a novel Pixel-Attention-Guided Unet (PAG-Unet). PAG-Unet incorporates a Pixel-Attention-Guided Fusion module (PAG Fusion) and a Multi-Task Self-Attention module (MTSA) to enhance task-specific feature extraction and reduce task interference. PAG Fusion leverages the relationship between shallow and deep features by using task-specific deep features to calibrate the distribution of shared shallow features. This suppresses background noise and enhances semantic features, thereby fully extracting task-specific features for different tasks and achieving feature enhancement. MTSA considers both global and local spatial interactions for each task during task interactions, capturing task-specific information and compensating for the loss of crucial details, thus improving prediction accuracy for each task. Our method achieves superior multi-task performance on the New York University Depth v2(NYUD-v2) and PASCAL Visual Object Classes Context(PASCAL-Context) datasets, with most metrics significantly outperforming previous state-of-the-art methods. The code is available at https://github.com/UPLI-123/Pag-Unet .},
  archive      = {J_APIN},
  author       = {Xu, Yi and Li, Changhao},
  doi          = {10.1007/s10489-025-06389-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {PAG-unet: Multi-task dense scene understanding with pixel-attention-guided unet},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting hemodynamic parameters based on arterial blood pressure waveform using self-supervised learning and fine-tuning. <em>APIN</em>, <em>55</em>(6), 1-26. (<a href='https://doi.org/10.1007/s10489-025-06391-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The arterial blood pressure waveform (ABPW) serves as a less invasive technique for evaluating hemodynamic parameters, offering a lower risk compared to the more invasive pulmonary artery catheter (PAC) thermodilution method. Various studies suggest that deep learning models can potentially predict the hemodynamic parameters of ABPW. However, the scarcity of ground truth data restricts the accuracy of these models, preventing them from gaining clinical acceptance. To mitigate this data and domain challenge, this work proposed a self-supervised generative learning model for hemodynamic parameter prediction, called SSHemo (Self-Supervised Hemodynamic model). Specifically, SSHemo suggests first to leverage large amounts of unlabeled ABPW data to learn the representative embedding and then to fine-tune for the downstream task with a small amount of hemodynamic parameters’ ground truth. To verify the effectiveness of SSHemo, we utilize the public available VitalDB data set to train the model, and evaluation was conducted on two public datasets: VitalDB and MIMIC. The experimental results reveal that SSHemo’s regression mean absolute error (MAE) improved significantly from 1.63 L/min to 1.25 L/min when predicting cardiac output (CO). The trending tracking ability for CO changes meets clinical acceptance (radial limit of agreement (LOA) is $$\pm 25.56$$ °, less than $$\pm 30$$ °). In addition, SSHemo demonstrates robust stability in various conditions and cohorts, as evidenced by subgroup analysis, varying systemic vascular resistance (SVR) range analysis, and rapid CO analysis, compared to the most widely used commercial devices, the EV1000. Computational analysis further underscores the value and potential of practical application of the model in various settings.},
  archive      = {J_APIN},
  author       = {Liao, Ke and Elibol, Armagan and Gao, Ziyan and Meng, Lingzhong and Chong, Nak Young},
  doi          = {10.1007/s10489-025-06391-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Predicting hemodynamic parameters based on arterial blood pressure waveform using self-supervised learning and fine-tuning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale contrastive learning via aggregated subgraph for link prediction. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06394-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction seeks to uncover potential or future connections within a network using structural or attribute information. Recently, Graph Neural Network (GNN)-based methods have attracted considerable attention for their effectiveness in link prediction. However, most GNN-based approaches focus solely on single-scale input graphs, which limits their ability to comprehensively capture network structure information. In this paper, multi-scale subgraphs are introduced as input graphs to obtain complementary network structures from different perspectives. Simultaneously, to obtain embedding vectors with better representational capacity, contrastive loss from self-supervised learning is incorporated for link prediction. Specifically, Multi-scale Contrastive learning framework based on Aggregated Subgraph (MCAS) is proposed for predicting missing links. Firstly, we construct enclosing subgraph by extracting neighbors of target nodes. By applying aggregation operation to these subgraphs, different granularities of multi-scale subgraphs are obtained. Secondly, encoders are used to learn information from multiple scales of subgraphs separately. Next, contrastive learning is employed to achieve information balance among the multi-scale subgraphs. Finally, the minimization of the loss allows us to improve the model’s robustness. Empirical evidence indicates that our approach excels state-of-the-art methods on nine datasets, including biological and citation networks. All source code is publicly available at: https://github.com/yabingyao/MCAS4LinkPrediction .},
  archive      = {J_APIN},
  author       = {Yao, Yabing and Guo, Pingxia and Mao, Zhiheng and Ti, Ziyu and He, Yangyang and Nian, Fuzhong and Zhang, Ruisheng and Ma, Ning},
  doi          = {10.1007/s10489-025-06394-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Multi-scale contrastive learning via aggregated subgraph for link prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSFL: A blockchain-based data sharing and federated learning framework. <em>APIN</em>, <em>55</em>(6), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06400-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The massive amount of data generated by the proliferation of Internet of Things (IoT) devices has become one of the key factors driving the advancement of artificial intelligence (AI) technology. However, the lack of storage space and limited computational power of edge devices make it difficult to directly process large data volumes or run complex machine learning algorithms on these devices. At the same time, existing Federated Learning (FL) schemes still face a number of shortcomings, including a single point of failure, vulnerability to poisoning attacks, and a lack of incentives. To address the above issues, we propose DSFL, a blockchain-based framework for fair data sharing and FL. Specifically, we combine digital envelope technology and one-way accumulator with smart contracts to design fair, secure, and trustworthy data sharing protocols that facilitate edge devices to share data proactively, realize the value of data and reduce storage pressure. In addition, we propose blockchain extension schemes suitable for coupling with FL to improve training efficiency. Importantly, the node management mechanism and incentive algorithms are designed to effectively monitor and trace the behavior of nodes, and promote the virtuous cycle of model training and the motivation of participants. Experimental results show that DSFL is able to ensure fair data sharing and efficient model training without the involvement of trusted third parties. In particular, it is able to achieve model accuracy close to that of existing popular schemes even when 40% of the nodes are lazy, providing an excellent defense against malicious nodes.},
  archive      = {J_APIN},
  author       = {Niu, Haiqian and Zhang, Xing and Chu, Zhiguang and Shi, Wei},
  doi          = {10.1007/s10489-025-06400-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {DSFL: A blockchain-based data sharing and federated learning framework},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ROCIP: Robust continuous inertial position tracking for complex actions emerging from the interaction of human actors and environment. <em>APIN</em>, <em>55</em>(6), 1-10. (<a href='https://doi.org/10.1007/s10489-025-06409-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inertial navigation is advancing rapidly due to improvements in sensor technology and tracking algorithms, with consumer-grade inertial measurement units (IMUs) becoming increasingly compact and affordable. Despite progress in pedestrian dead reckoning (PDR), IMU-based positional tracking still faces significant noise and bias issues. While traditional model-based methods and recent machine learning approaches have been employed to reduce signal drift, error accumulation remains a barrier to long-term system performance. Inertial tracking’s self-contained nature offers broad applicability but limits integration with a global reference frame. To solve this problem, a system that could “introspect its error” and “learn from the past” is proposed. It consists of a neural statistical motion model that regresses both poses and uncertainties with DenseNet, which are then fed into Rao-Blackwellised particle filter (RBPF) for calibration with a probabilistic transition map. An inertial tracking dataset with head-mounted IMUs was collected, including walking and running with different speeds while allowing participants to rotate their heads in a self-selected manner. The dataset consisted of 19 volunteers that generated 151 sequences in 4 scenarios with a total time of 929.8 min. It was shown that our proposed method (ROCIP) outperformed the leading methods in the field, with a relative trajectory error (RTE) of 4.94m and absolute trajectory error (ATE) of 4.36m. ROCIP could also solve the problem of error accumulation in dead reckoning and maintain a small and consistent error during long-term tracking.},
  archive      = {J_APIN},
  author       = {Hou, Xinyu and Bergmann, Jeroen},
  doi          = {10.1007/s10489-025-06409-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-10},
  shortjournal = {Appl. Intell.},
  title        = {ROCIP: Robust continuous inertial position tracking for complex actions emerging from the interaction of human actors and environment},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A statistical categorization-based curriculum learning approach for multi-task classification of images. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06270-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification and the detection of features within images remain significant challenges in computer vision. Several approaches, including serial task models and multi-output models, have been explored to address these challenges. This study focuses on multitasking attention mechanisms, which enable simultaneous categorization of data and tasks. By applying a statistical framework, the proposed method enhances the efficiency and accuracy of image classification and feature detection, with a focus on handling multiple tasks concurrently. To enhance the robustness of the model, a data-driven approach based on curriculum learning was proposed. The experiments were conducted using two distinct datasets. The first dataset involves forensic examinations, specifically identifying firearms and their calibers from firing pin marks. The proposed model achieved an accuracy of 95% in brand detection and 98% in caliber detection on this dataset. In the second part of the experiments, the animals with attributes 2 (AwA2) dataset, where state-of-the-art models have previously been applied, was used. The proposed model reduced classification errors by 1 to 10% compared to traditional convolutional neural network (CNN) architectures. The experimental results from both the forensic and public datasets demonstrate that the proposed model effectively handles multitask classification tasks, validating its applicability across diverse domains.},
  archive      = {J_APIN},
  author       = {Veranyurt, Ozan and Sakar, C. Okan},
  doi          = {10.1007/s10489-025-06270-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {A statistical categorization-based curriculum learning approach for multi-task classification of images},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial network embedding with bootstrapped representations for sparse networks. <em>APIN</em>, <em>55</em>(6), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06343-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inherent sparsity of real-world networks presents challenges in learning-rich embeddings and accurately reconstructing networks. To address these challenges, a novel method termed Adversarial Network Embedding with Bootstrapped Representations (ANEBR) is proposed. Firstly, a novel network augmentation method is employed for positive sampling. ANEBR utilizes the Katz Index to extract higher-order latent information and refines it with $$\alpha $$ -entmax. The crucial information is extracted while minimizing noise generation. Secondly, ANEBR circumvents negative sampling by learning bootstrapped representations. Building on bootstrapped representations from the BYOL algorithm, ANEBR incorporates the GAN techniques to align the learned embeddings nonlinearly. Finally, ANEBR attains accurate network reconstruction by imposing a low-rank constraint on the reconstruction error through the nuclear norm. Extensive experiments with statistical and sensitivity analyses demonstrate that ANEBR outperforms state-of-the-art methods in various tasks. Specifically, ANEBR reconstructs the PPI network with a precision of 0.9992, marking a relative improvement of 6.65%. Code is available at https://github.com/wuzelong/ANEBR .},
  archive      = {J_APIN},
  author       = {Wu, Zelong and Wang, Yidan and Lin, Guoliang and Liu, Junlong},
  doi          = {10.1007/s10489-025-06343-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Adversarial network embedding with bootstrapped representations for sparse networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust hierarchical clustering algorithm for automatic identification of clusters. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06376-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aggregation-based hierarchical clustering algorithms are widely used in data analysis due to their robust clustering performance. Although some existing hierarchical clustering methods can identify the number of clusters in a dataset, most are only effective for well-separated clusters and struggle to identify the number of clusters in complex datasets, particularly non-convex noisy datasets. To address these shortcomings, this paper proposes a robust hierarchical clustering algorithm for automatic identification of clusters(RHCAIC), which can identify the optimal number of clusters while providing reliable clustering results. To reduce the impact of noise in clustering, the method first calculates reverse density and designs a dynamic noise discriminator to denoise the dataset. Based on the fact that more similar points have a higher probability of being clustered into the same cluster among multiple results of hierarchical clustering, a robust solution was designed. After constructing a directed graph using the kNN algorithm, the graph merging process is performed by iteratively traversing the directed edges. During this process, the number of clusters is identified, and the clustering results of the denoised dataset are obtained. Finally, by incorporating density information into the noise clustering, the final clustering results are obtained. A series of experiments conducted on 12 synthetic datasets and 8 real datasets demonstrate that, compared to seven other benchmark algorithms, the RHCAIC algorithm not only accurately identifies the number of clusters in the dataset but also produces better clustering results.},
  archive      = {J_APIN},
  author       = {Long, Jianwu and Wang, Qiang and Liu, Luping},
  doi          = {10.1007/s10489-025-06376-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {A robust hierarchical clustering algorithm for automatic identification of clusters},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating potential causes of sepsis with bayesian network structure learning. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06405-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sepsis is a life-threatening and serious global health issue. This study combines knowledge with available hospital data to investigate the potential causes of Sepsis that can be affected by policy decisions. We investigate the underlying causal structure of this problem by combining clinical expertise with score-based, constraint-based, and hybrid structure learning algorithms. A novel approach to model averaging and knowledge-based constraints was implemented to arrive at a consensus structure for causal inference. The structure learning process highlighted the importance of exploring data-driven approaches alongside clinical expertise. This includes discovering unexpected, although reasonable, relationships from a clinical perspective. Hypothetical interventions on Chronic Obstructive Pulmonary Disease, Alcohol dependence, and Diabetes suggest that the presence of any of these risk factors in patients increases the likelihood of Sepsis. This finding, alongside measuring the effect of these risk factors on Sepsis, has potential policy implications. Recognising the importance of prediction in improving health outcomes related to Sepsis, the model is also assessed in its ability to predict Sepsis by evaluating accuracy, sensitivity, and specificity. These three indicators all had results around 70%, and the AUC was 80%, which means the causal structure of the model is reasonably accurate given that the models were trained on data available for commissioning purposes only.},
  archive      = {J_APIN},
  author       = {Petrungaro, Bruno and Kitson, Neville K. and Constantinou, Anthony C.},
  doi          = {10.1007/s10489-025-06405-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Investigating potential causes of sepsis with bayesian network structure learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-channel graph-level anomaly detection method based on multi-graph representation learning. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05852-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-level anomaly detection plays a crucial role in anomaly identification by comparing and classifying the graph-level features of normal and anomalous graphs. Despite advancements, existing methods often suffer from low detection rates and high false-positive rates when dealing with sparse anomalous data. To address this limitation, we propose a dual-channel graph-level anomaly detection model that utilizes two graph isomorphic networks to separately learn from labeled anomalous data and unlabeled normal data. This model enhances the identification of unlabeled anomalies by learning from both types of data through separate channels. Furthermore, to enable the model to be applicable to complex graph types in graph-level anomaly detection applications, we introduce a novel multi-graph representation learning method that can transform multi-graphs into a simplified graph representation. We have rigorously evaluated the proposed model on 6 public datasets, and the experimental results demonstrate the effectiveness of the model, with significant performance improvements over 9 baseline models.},
  archive      = {J_APIN},
  author       = {Jing, Yongjun and Wang, Hao and Chen, Jiale and Chen, Xu},
  doi          = {10.1007/s10489-024-05852-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Dual-channel graph-level anomaly detection method based on multi-graph representation learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D-FaIR: 3D facial imperfection regeneration with defects by fully convolutional mesh autoencoder. <em>APIN</em>, <em>55</em>(6), 1-15. (<a href='https://doi.org/10.1007/s10489-024-05880-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces an effective approach using a fully convolutional mesh autoencoder model to reconstruct 3D facial features in the presence of imperfections. The method accurately simulates facial scars in a virtual environment, adapting to unique situations. This article presents the “Cir3D-FaIR” dataset, which is specifically tailored to address issues related to facial scars. Additionally, we propose a new technique called 3D facial imperfection regeneration (3D-FaIR), which focusses on reconstructing a complete face based on the remaining features of the patient’s face. To further enhance the applicability of this research, the article has developed an advanced outlier detection technique that isolates affected areas and provides appropriate models for wound coverage. The Cir3D-FaIR dataset, consisting of imperfect facial models and open-source package, is available at https://github.com/SIMOGroup/3DFaIR . Our findings demonstrate that the proposed approach can potentially aid in faster and safer patient recovery through convenient methods. We hope that this work inspires the development of new products and innovative solutions for facial scar regeneration.},
  archive      = {J_APIN},
  author       = {Nguyen, Phuong D. and Le, Thinh D. and Nguyen, Duong Q. and Nguyen, Thanh Q. and Chou, Li-Wei and Nguyen-Xuan, H.},
  doi          = {10.1007/s10489-024-05880-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {3D-FaIR: 3D facial imperfection regeneration with defects by fully convolutional mesh autoencoder},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An online self-organizing radial basis function neural network based on gaussian membership. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-024-05989-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radial basis function neural network (RBFNN) is one of the most popular neural networks, and an appropriate selection of its structure and learning algorithms is crucial for its performance. Aiming to alleviate the sensitivity of the RBFNN to its parameters and improve the overall performance of the network, this study proposes a Gaussian Membership-based online self-organizing RBF neural network (GM-OSRBFNN). First, the Gaussian Membership is introduced to enhance network insensitivity to network parameters and used as a similarity metric to indicate the similarity between the sample to a hidden neuron and that between hidden neurons. Second, the similarity metric is used to design the neuron addition and merging rules to achieve a self-organizing network structure, and error constraints are introduced to the neuron addition rule; also, the noisy neuron deletion rule is defined to make the network structure more compact. In addition, an online fixed mini-batch gradient algorithm is used for online learning of network parameters, which can guarantee fast and stable convergence of the network. Finally, the proposed GM-OSRBFNN is tested on common nonlinear system modeling problems to verify its effectiveness. The experimental results show that compared to the existing models, the GM-OSRBFNN can achieve competitive prediction performance with a more compact network structure, faster convergence speed, and, more importantly, better insensitivity to network parameters.},
  archive      = {J_APIN},
  author       = {Jia, Lijie and Li, Wenjing and Qiao, Junfei and Zhang, Xinliang},
  doi          = {10.1007/s10489-024-05989-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {An online self-organizing radial basis function neural network based on gaussian membership},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel recurrent neural network with transformer for anomalous trajectory detection. <em>APIN</em>, <em>55</em>(6), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06069-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomalous trajectory detection within urban road traffic networks is crucial for identifying operational vehicle fraud in intelligent transportation systems. However, most existing approaches are limited to detecting anomalous trajectories solely based on the same original point, neglecting the extraction of spatiotemporal features and contextual information embedded in trajectory data. To address these limitations, a Parallel Recurrent Neural Network with Transformer (PRNNT) model is proposed for anomalous trajectory detection. Specifically, the position embedding and a transformer encoder module are utilized to train trajectory embeddings, allowing the model to learn sequential features and contextual information of trajectories. Moreover, a parallel recurrent neural network is employed to extract hidden trajectory features, capturing the differences between normal and anomalous trajectories. Finally, a linear layer is applied to fuse the spatiotemporal features and output the probability of an anomalous trajectory, enhancing the detection of vehicle trajectory anomalies. Experimental results on Beijing and Porto datasets demonstrate that the proposed PRNNT model significantly outperforms the iBAT (Isolation-Based Anomalous Trajectory), ATDC (Anomalous Trajectory Detection and Classification), ATD-RNN (Anomalous Trajectory Detection using Recurrent Neural Network), XGBoost (Extreme Gradient Boosting), GM-VSAE (Gaussian Mixture Variational Sequence AutoEncoder), and UA-OATD (Deep Unified Attention-based Sequence Modeling for Online Anomalous Trajectory Detection) models, achieving at least a 3.8%, 22.7%, 3.8%, 22.7%, 15%, and 16.7% improvement in F1-score, respectively.},
  archive      = {J_APIN},
  author       = {Xia, Dawen and Li, Yunsong and Ao, Yuce and Wei, Xiaoduo and Chen, Yan and Hu, Yang and Li, Yantao and Li, Huaqing},
  doi          = {10.1007/s10489-024-06069-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Parallel recurrent neural network with transformer for anomalous trajectory detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Implicit regularization of a deep augmented neural network model for human motion prediction. <em>APIN</em>, <em>55</em>(6), 1. (<a href='https://doi.org/10.1007/s10489-024-06148-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Yadav, Gaurav Kumar and Abdel-Nasser, Mohamed and Rashwan, Hatem A. and Puig, Domenec and Nandi, G. C.},
  doi          = {10.1007/s10489-024-06148-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Correction to: Implicit regularization of a deep augmented neural network model for human motion prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-based spatial-temporal synchronous graph convolution networks for traffic flow forecasting. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06341-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow forecasting is crucial for urban traffic control, planning, and detection. Most existing spatial-temporal modeling methods overlook the hidden dynamic correlations between road network nodes and the time series nonstationarity while synchronously capturing complex long- and short-term spatial-temporal dependencies. To this end, this paper proposes an Attention-based Spatial-Temporal Synchronous Graph Convolutional Network (AST-SGCN) to capture complex spatial-temporal correlations over long and short terms. Specifically, we design a self-attention mechanism that utilizes spatial-temporal synchronous computation to efficiently mine dynamic spatial-temporal correlations with changes in traffic and enhance computational efficiency. Then, we construct a residual adaptive adjacency matrix, which includes historical data and node vectors, to stimulate the information transfer of spatial-temporal graph nodes and mine the hidden spatial-temporal dependencies through the graph convolution layer. Next, we establish a Fourier transform layer (FTL) to handle the nonstationary data. Finally, we develop a spatial-temporal hybrid stacking module for capturing complex long-term spatial-temporal correlations, within which two layers of graph convolution and one layer of self-attention are deployed. Extensive experimental results on three real-world traffic flow datasets demonstrate that our AST-SGCN model outperforms the comparable models.},
  archive      = {J_APIN},
  author       = {Wei, Xiaoduo and Xia, Dawen and Li, Yunsong and Ao, Yuce and Chen, Yan and Hu, Yang and Li, Yantao and Li, Huaqing},
  doi          = {10.1007/s10489-025-06341-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Attention-based spatial-temporal synchronous graph convolution networks for traffic flow forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DARTS-EAST: An edge-adaptive selection with topology first differentiable architecture selection method. <em>APIN</em>, <em>55</em>(6), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06353-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DARTS+PT is a well-known differentiable neural architecture search (NAS) method that evaluates the contribution of operations to the performance of the super-network, ultimately deriving the final architecture. However, DARTS+PT introduces randomness into the edge discretization process by selecting edges randomly, which leads to performance instability. Moreover, the method assesses the impact of each candidate operation by iteratively removing them and measuring the resulting drop in super-network performance, leading to a high search cost. To address these issues, this paper identifies the root cause of instability and proposes a novel edge selection criterion to establish an adaptive edge discretization order, improving stability. Additionally, we introduce a topology-first discretization scheme that prioritizes topology selection over operation selection, significantly reducing the search cost. We name this approach DARTS-EAST (Edge-Adaptive Selection with Topology-First Differentiable Architecture Selection). Extensive experiments on widely used benchmarks demonstrate that DARTS-EAST not only achieves competitive performance but also offers significant improvements in both stability and search efficiency.},
  archive      = {J_APIN},
  author       = {Fang, Xuwei and Xie, Weisheng and Li, Hui and Zhou, Wenbin and Hang, Chen and Gao, Xiangxiang},
  doi          = {10.1007/s10489-025-06353-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {DARTS-EAST: An edge-adaptive selection with topology first differentiable architecture selection method},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TANGAN: Solving tangram puzzles using generative adversarial network. <em>APIN</em>, <em>55</em>(6), 1-27. (<a href='https://doi.org/10.1007/s10489-025-06364-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While humans show remarkable proficiency in solving visual puzzles, machines often fall short due to the complex combinatorial nature of such tasks. Consequently, there is a growing interest in developing computational methods for the automatic solution of different puzzles, especially through deep learning approaches. The Tangram, an ancient Chinese puzzle, challenges players to arrange seven polygonal pieces to construct different patterns. Despite its apparent simplicity, solving the Tangram is considered an NP-complete problem, being a challenge even for the most sophisticated algorithms. Moreover, ensuring the generality and adaptability of machine learning models across different Tangram arrangements and complexities is an ongoing research problem. In this paper, we introduce a generative model specifically designed to solve the Tangram. Our model competes favorably with previous methods regarding accuracy while delivering fast inferences. It incorporates a novel loss function that integrates pixel-based information with geometric features, promoting a deeper understanding of the spatial relationships between pieces. Unlike previous approaches, our model takes advantage of the geometric properties of the Tangram to formulate a solving strategy, exploiting its inherent properties only through exposure to training data rather than through direct instruction. Extending the proposed loss function, we present a novel evaluation metric as a better fitting measure for assessing Tangram solutions than previous metrics. We further provide a new dataset containing more samples than others reported in the literature. Our findings highlight the potential of deep learning approaches in geometric problem domains.},
  archive      = {J_APIN},
  author       = {Yamada, Fernanda Miyuki and Batagelo, Harlen Costa and Gois, João Paulo and Takahashi, Hiroki},
  doi          = {10.1007/s10489-025-06364-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-27},
  shortjournal = {Appl. Intell.},
  title        = {TANGAN: Solving tangram puzzles using generative adversarial network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Batch process quality prediction based on denoising autoencoder-spatial temporal convolutional attention mechanism fusion network. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06368-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In batch processes, the accurate prediction of quality variables plays a crucial role in smooth production and quality control. However, various sources of noise in the production environment cause abnormal data fluctuations that deviate from the real value. Coupled with the dynamic nonlinearity of batch processing and the complex spatiotemporal relationship of variables, which greatly increase the difficulty of prediction and pose a severe challenge to prediction performance. Therefore, a denoising autoencoder-Spatial Temporal Convolution Attention Fusion Network (DAE-STCAFN) prediction method is proposed. Firstly, combining DAE and maximum information coefficient (MIC), multi-level data features are extracted to prepare high-quality input data for the quality prediction model. DAE is used to denoise the original data, and relevant variables are selected through MIC. Then, an augmented matrix is constructed to eliminate the autocorrelation of the selected variables in the time series. Secondly, a spatial temporal convolutional attention fusion mechanism is created to extract the spatial temporal fusion features between the input and output variable sequences. Thirdly, to further enhance the learning ability of the model, a batch attention module is constructed to automatically learn the relationship among sample in small batch. Finally, experiments were carried out on the simulation platform of penicillin fermentation and hot tandem rolling process. In the prediction process of penicillin concentration, RMSE and MAE of the proposed method were 0.0099 and 0.0077, respectively. In the prediction of strip thickness, the RMSE and MAE are 0.0008 and 0.0003 respectively. The results show that the proposed method is effective both in simulation experiment and in actual industrial production in terms of prediction accuracy, stability and generalization ability.},
  archive      = {J_APIN},
  author       = {Zhang, Yan and Cao, Jie and Zhao, Xiaoqiang and Hui, Yongyong},
  doi          = {10.1007/s10489-025-06368-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Batch process quality prediction based on denoising autoencoder-spatial temporal convolutional attention mechanism fusion network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-order consensus graph learning for incomplete multi-view clustering. <em>APIN</em>, <em>55</em>(6), 1-25. (<a href='https://doi.org/10.1007/s10489-025-06375-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete Multi-View Clustering (IMVC) aims to partition data with missing samples into distinct groups. However, most IMVC methods rarely consider the high-order neighborhood information of samples, which represents complex underlying interactions, and often neglect the weights of different views. To address these issues, we propose a High-order Consensus Graph Learning (HoCGL) model. Specifically, we integrate a reconstruction term to recover the incomplete multi-view data. High-order proximity matrices are constructed, and the self-representation similarity matrices and multiple high-order proximity matrices are learned mutually, allowing the similarity matrices to incorporate complex high-order information. Finally, the consensus graph representation is derived from the similarity matrices through a self-weighted strategy. An efficient algorithm is designed to solve the proposed model. The excellent clustering performance of the proposed model is validated by comparing it with eight state-of-the-art models across nine datasets.},
  archive      = {J_APIN},
  author       = {Guo, Wei and Che, Hangjun and Leung, Man-Fai},
  doi          = {10.1007/s10489-025-06375-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {High-order consensus graph learning for incomplete multi-view clustering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). StackMFF: End-to-end multi-focus image stack fusion network. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06383-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing end-to-end multi-focus image fusion (MFF) networks demonstrate excellent performance when fusing image pairs. However, when image stacks are processed, the necessity for iterative fusion leads to error accumulation, resulting in various types and degrees of image degradation, which ultimately limits the algorithms’ practical applications. To address this challenge and expand the application scenarios of multi-focus fusion algorithms, we propose a relatively simple yet effective approach: utilizing 3D convolutional neural networks to directly model and fuse entire multi-focus image stacks in an end-to-end manner. To obtain large-scale training data, we developed a refocusing pipeline based on monocular depth estimation technology that can synthesize a multi-focus image stack from any all-in-focus image. Furthermore, we extended the attention mechanisms commonly used in image pair fusion networks from two dimensions to three dimensions and proposed a comprehensive loss function group, effectively enhancing the fusion quality. Extensive experimental results demonstrate that the proposed method achieves state-of-the-art performance in both fusion quality and processing speed while avoiding image degradation issues, establishing a simple yet powerful baseline for the multi-focus image stack fusion task. The codes are available at https://github.com/Xinzhe99/StackMFF .},
  archive      = {J_APIN},
  author       = {Xie, Xinzhe and Qingyan, Jiang and Chen, Dong and Guo, Buyu and Li, Peiliang and Zhou, Sangjun},
  doi          = {10.1007/s10489-025-06383-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {StackMFF: End-to-end multi-focus image stack fusion network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constructive sample partition-based parameter-free sampling for class-overlapped imbalanced data classification. <em>APIN</em>, <em>55</em>(6), 1-29. (<a href='https://doi.org/10.1007/s10489-025-06385-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced data widely exists in real applications ranging from medical diagnosis to economic fraud detection, etc. Data level method is one of the prevalent methods to deal with imbalanced data by re-balancing the distribution between different classes. Recent researches reveal that handling the class-overlapping of imbalanced data when designing data-level approach can effectively improve the performance of imbalanced learning. However, most existing data-level methods rely on specific parameters to obtain desired performance, making them hard to generalize to other scenarios. And the intractable data difficulty factors, i.e., the most frequent class-overlapping problem, makes them confront additional challenges. Designing efficient, flexible method that considers the parameter-free designing and the class-overlapping handling simultaneously remains a challenge. This paper proposes to deal with the class-overlapped imbalanced data with parameter-free adaptive method. To be specific, we first propose a parameter-free constructive sample partition (CSP) method, and then design an adaptive parameter-free CSP-based undersampling method (CSPUS) and an adaptive parameter-free CSP-based hybrid sampling method (CSPHS) to balance the class distribution by handling the class-overlap of the original data. Numerical experiments on 18 representative high-overlap imbalanced datasets from KEEL repository and 23 state-of-the-art comparison methods demonstrate the effectiveness of CSPUS and CSPHS. The source code of our proposed methods is available at https://github.com/ytyancp/CSPS.},
  archive      = {J_APIN},
  author       = {Wang, Weiqing and Yan, Yuanting and Zhou, Peng and Zhao, Shu and Zhang, Yiwen},
  doi          = {10.1007/s10489-025-06385-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-29},
  shortjournal = {Appl. Intell.},
  title        = {Constructive sample partition-based parameter-free sampling for class-overlapped imbalanced data classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of traditional machine learning algorithms for featuring educational exercises. <em>APIN</em>, <em>55</em>(6), 1-25. (<a href='https://doi.org/10.1007/s10489-025-06386-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) algorithms are important in educational environments, and the use of machine learning algorithms to evaluate and improve the quality of education. Previous studies have individually analyzed algorithms to estimate item characteristics, such as grade, number of attempts, and time from student interactions. By contrast, this study integrated all three characteristics to discern the relationships between attempts, time, and performance in educational exercises. We analyzed 15 educational assessments using different machine learning algorithms, specifically 12 for regression and eight for classification, with different hyperparameters. This study used real student interaction data from Zenodo.org, encompassing over 150 interactions per exercise, to predict grades and to improve our understanding of student performance. The results show that, in regression, the Bayesian ridge regression and random forest regression algorithms obtained the best results, and for the classification algorithms, Random Forest and Nearest Neighbors stood out. Most exercises in both scenarios involved more than 150 student interactions. Furthermore, the absence of a pattern in the variables contributes to suboptimal outcomes in some exercises. The information provided makes it more efficient to enhance the design of educational exercises.},
  archive      = {J_APIN},
  author       = {Jiménez-Macías, Alberto and Muñoz-Merino, Pedro J. and Moreno-Marcos, Pedro Manuel and Kloos, Carlos Delgado},
  doi          = {10.1007/s10489-025-06386-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {Evaluation of traditional machine learning algorithms for featuring educational exercises},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of reservoir water levels via an improved attention mechanism based on CNN − LSTM. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06393-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water level prediction is crucial for flood control scheduling and water resource management. The application of various deep learning methods to water level prediction in reservoirs is limited. Accurate water level prediction aids in optimizing reservoir operation strategies, ensuring flood safety downstream and meeting water supply demands. To achieve accurate predictions, a new structure based on a convolutional neural network − long short-term memory (CNN − LSTM) model is proposed, which incorporates a self-attention mechanism and a local attention mechanism in an SL − CNN − LSTM coupled model. Using the Three Gorges Reservoir head area in China as a case study, hydrometeorological data from three points in the reservoir's head area and upstream water level characteristics are used as input variables. Data collected every six hours from 2008 to 2021 were used, with the model trained and tested at an 8:2 ratio. The study revealed that a two-layer CNN configuration performed best in most models. The SL − CNN − LSTM-2 model achieved the best performance across all the metrics, with an R2 of 0.9988, an MAE of 0.2767, an RMSE of 0.3404, and a MAPE of 0.1717, particularly for extreme water level predictions with minimal residuals, validating its strong ability to balance long- and short-term dependencies. Additionally, the model effectively extracts features and captures critical information in time series data, balancing learning capacity and computational efficiency. The research results are highly important for water resource management in large reservoirs, providing reliable technical support for flood control scheduling and water resource optimization.},
  archive      = {J_APIN},
  author       = {Li, Haoran and Zhang, Lili and Yao, Yunsheng and Zhang, Yaowen},
  doi          = {10.1007/s10489-025-06393-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Prediction of reservoir water levels via an improved attention mechanism based on CNN − LSTM},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A personalized consensus-reaching method for large-group decision-making in social networks combining self-confidence and trust relationships. <em>APIN</em>, <em>55</em>(6), 1-24. (<a href='https://doi.org/10.1007/s10489-025-06395-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, large-scale group decision-making (LSGDM) in social network environments considering experts’ psychological behaviors has received increasing attention. Moreover, existing studies have shown that whether it is internal self-confidence or external trust relationships of experts, they play a crucial role in reaching consensus. Therefore, this paper integrates self-confidence and trust relationships, and proposes a personalized consensus-reaching method for LSGDM from the perspective of adjustment willingness. Firstly, we explored the promoting effect of opinion similarity on the efficiency of trust propagation and proposed a method to evaluate unknown trust relationships among experts, integrating the objectivity of trust relationships and the subjectivity of self-confidence to determine the experts’ weights. Secondly, a hierarchical fuzzy clustering algorithm based on the chi-square test is proposed for effective subgroup division, which avoids the impact of setting initial clustering parameters on the clustering results. Afterwards, the adjustment willingness of the subgroups is determined by combining the experts’ self-confidence and the trust relationships between them. In addition to this, a personalized consensus feedback adjustment mechanism that synthesizes the adjustment willingness and trust relationship is constructed to reach consensus, which can better preserve the original information. Finally, the effectiveness of the proposed method is verified through a numerical example. In addition, the advantages of the proposed method are demonstrated by comparing with other methods.},
  archive      = {J_APIN},
  author       = {Liu, Zhengmin and Ding, Ruxue and Wang, Wenxin and Liu, Peide and Gao, Shanshan},
  doi          = {10.1007/s10489-025-06395-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {A personalized consensus-reaching method for large-group decision-making in social networks combining self-confidence and trust relationships},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pursuit-evasion game with online planning using deep reinforcement learning. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06396-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pursuit-evasion with round-up is a problem where multiple pursuers aim to capture a moving target within a specific encirclement to prevent its escape. In this paper, multi-UAV pursuit-evasion algorithms in obstacle environments are investigated and deployed on real-world micro quadcopters. In order to guide pursuers in quickly avoiding obstacles and swiftly approaching the evader, an end-to-end distributed reinforcement learning framework is proposed, and a two-stage reward function is designed. Building upon this, a MADDPG framework based on a trajectory prediction network is constructed to assist pursuers in completing round-up more quickly. Furthermore, unlike most reinforcement learning algorithms, the proposed algorithm is deployed onto a micro quadcopter controller, and a pursuit-evasion game is conducted in a real-world scenario. The results of simulations and physical experiments show that the proposed algorithm can complete round-up more quickly and can be successfully transferred to the real world.},
  archive      = {J_APIN},
  author       = {Chen, Yong and Shi, Yu and Dai, Xunhua and Meng, Qing and Yu, Tao},
  doi          = {10.1007/s10489-025-06396-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Pursuit-evasion game with online planning using deep reinforcement learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The improved mountain gazelle optimizer for spatiotemporal support vector regression: A novel method for railway subgrade settlement prediction integrating multi-source information. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06397-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uneven settlement of railway subgrades not only affects the comfort of train operations but, in extreme cases, may compromise operational safety. As a result, accurately predicting subgrade settlement is crucial for maintaining both safety and operational efficiency. This study introduces an Improved Mountain Gazelle Optimizer for the Spatiotemporal Support Vector Regression (IMGO-STSVR) model, which effectively predicts railway subgrade settlement. Data are collected using Permanent Scatterer Interferometric Synthetic Aperture Radar (PS-InSAR) technology in combination with a multi-source environmental monitoring system. The proposed improvement to the Mountain Gazelle Optimizer (IMGO) enhances the model’s optimization capabilities, while the Support Vector Regression model is improved by the constructed spatiotemporal kernel function (STSVR). Experimental results demonstrate that the IMGO-STSVR model achieves high accuracy and stability across various experimental sites. This method provides valuable insights for predicting subgrade settlement in the railway industry, aiding in the early identification of potential risks, optimizing maintenance strategies, and ensuring the safe and efficient operation of rail transport.},
  archive      = {J_APIN},
  author       = {Chen, Guangwu and Zhao, Shilin and Li, Peng and Wang, Shilin and Zhou, Xin and Potekhin, Vyacheslav},
  doi          = {10.1007/s10489-025-06397-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {The improved mountain gazelle optimizer for spatiotemporal support vector regression: A novel method for railway subgrade settlement prediction integrating multi-source information},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention ensemble mixture: A novel offline reinforcement learning algorithm for autonomous vehicles. <em>APIN</em>, <em>55</em>(6), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06403-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline Reinforcement Learning (RL), which optimizes policies from previously collected datasets, is a promising approach for tackling tasks where direct interaction with the environment is infeasible due to high risk or cost of errors, such as autonomous vehicle (AV) applications. However, offline RL faces a critical challenge: extrapolation errors arising from out-of-distribution (OOD) data. In this paper, we propose Attention Ensemble Mixture (AEM), a novel offline RL algorithm that leverages ensemble learning and an attention mechanism. Ensemble learning enhances the confidence of Q-function predictions, while the attention mechanism evaluates the uncertainty of selected actions. By assigning appropriate attention weights to each Q-head, AEM effectively down-weights OOD actions and up-weights in-distribution actions. We further introduce three key improvements to enhance the robustness and generality of AEM: attention-weighted Bellman backups, KL divergence regularization, and delayed attention updates. Extensive comparative experiments demonstrate that AEM outperforms several state-of-the-art ensemble offline RL algorithms, while ablation studies underscore the significance of the proposed enhancements. In AV tasks, AEM exhibits superior performance compared to other methods, excelling in both offline and online evaluations.},
  archive      = {J_APIN},
  author       = {Han, Xinchen and Afifi, Hossam and Moungla, Hassine and Marot, Michel},
  doi          = {10.1007/s10489-025-06403-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Attention ensemble mixture: A novel offline reinforcement learning algorithm for autonomous vehicles},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning missing instances in intact and projection spaces for incomplete multi-view unsupervised feature selection. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06406-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view unsupervised feature selection has achieved great success in identifying a subset of prominent features from multi-view data to produce compact and meaningful representations. However, most existing methods assume that all data views are complete, which is often not the case in real-world scenarios. Multi-view data is frequently incomplete, with some instances missing in certain views. To address this issue, we propose an incomplete multi-view unsupervised feature selection model based on multiple space learning, termed Learning Missing Instances in Intact and Projection Spaces for Incomplete Multi-view Unsupervised Feature Selection (LIPS). This model integrates intact latent space learning, projection space learning, missing instance imputation, and correlation structure learning into a joint framework. Specifically, LIPS employs intact latent space learning to generate intact representations that capture the full information of multi-view data. Using these representations, LIPS calculates correlations between data through a constrained self-expression strategy, generating a sparse correlation matrix where each row contains few non-zero entries, signifying that each data point can be linearly reconstructed using only a small subset of related neighbors. Subsequently, LIPS projects data into low-dimensional spaces to retain the neighborhood correlations. Finally, it leverages complementary information to impute the missing instances from a cross-view perspective based on intact representations and utilizes neighborhood information to generate neighborhood-smooth imputations for missing instances from view-specific perspectives. Additionally, an effective algorithm is developed to resolve the optimization problem. Extensive experiments conducted on six public datasets of different types, including image datasets (MSRC-v1, Caltech101-7, and CIFAR-10), text datasets (BBCSport and WebKB), and a face dataset (Yale), measured by Acc and NMI, demonstrate that the proposed LIPS outperforms state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Wu, Jian-Sheng and Yu, Hong-Wei and Li, Yanlan and Min, Weidong},
  doi          = {10.1007/s10489-025-06406-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Learning missing instances in intact and projection spaces for incomplete multi-view unsupervised feature selection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-like synthetic sperm video generation from learned behaviors. <em>APIN</em>, <em>55</em>(6), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06407-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-assisted sperm analysis is an open research problem, and a main challenge is how to test its performance. Deep learning techniques have boosted computer vision tasks to human-level accuracy, when sufficiently large labeled datasets were provided. However, when it comes to sperm (either human or not) there is lack of sufficient large datasets for training and testing deep learning systems. In this paper we propose a solution that provides access to countless fully annotated and realistic synthetic video sequences of sperm. Specifically, we introduce a parametric model of a spermatozoon, which is animated along a video sequence using a denoising diffusion probabilistic model. The resulting videos are then rendered with a photo-realistic appearance via a style transfer procedure using a CycleGAN. We validate our synthetic dataset by training a deep object detection model on it, achieving state-of-the-art performance once validated on real data. Additionally, an evaluation of the generated sequences revealed that the behavior of the synthetically generated spermatozoa closely resembles that of real ones.},
  archive      = {J_APIN},
  author       = {Hernández-García, Sergio and Cuesta-Infante, Alfredo and Makris, Dimitrios and S. Montemayor, Antonio},
  doi          = {10.1007/s10489-025-06407-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Real-like synthetic sperm video generation from learned behaviors},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dense image-mask attention-guided transformer network for jaw lesions classification and segmentation in dental cone-beam computed tomography images. <em>APIN</em>, <em>55</em>(6), 1-26. (<a href='https://doi.org/10.1007/s10489-025-06408-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic segmentation and classification of jaw lesions from cone-beam computed tomography (CBCT) images are crucial in computer-assisted diagnosis and treatment planning for oral and maxillofacial (OMF) surgery. However, the evolutionary nature of jaw lesions and their morphological diversity pose significant challenges to both segmentation and classification tasks. Although existing deep learning-based works have achieved promising results on segmentation and classification of other types of lesions, they often consider the two tasks separately, thereby overlooking the strong guidance that lesion masks can provide in determining lesion categories. In this manuscript, we propose a dense image-mask attention-guided transformer network for end-to-end jaw lesions classification and segmentation in 3D CBCT images based on a multi-task learning (MTL) architecture. Specifically, we design multi-dimension attention (MDA) and multi-scale attention (MSA) modules to incorporate dense features from different dimensions and scales, explicitly enhancing the guidance of lesion segmentation for classification decisions. Furthermore, to effectively encode long-term contextual information, we employ a transformer as the classification decoder and design a 3D positional embedding method to preserve the 3D positional information of sequential feature inputs for the transformer. Finally, we design a task merge module that employs a per-lesion inference strategy to assign a category to each lesion instance. A large in-house dataset consisting of 358 CBCT scans with five types of jaw lesions is constructed to evaluate the proposed method. The experimental results show a binary segmentation DICE score of 90%, a mean classification accuracy of 89.23%, and a multi-class segmentation DICE score of 79.06%, surpassing many state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Li, Xiang and Liu, Wei and Tang, Wei and Guo, Jixiang},
  doi          = {10.1007/s10489-025-06408-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Dense image-mask attention-guided transformer network for jaw lesions classification and segmentation in dental cone-beam computed tomography images},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NTFNet: Narrowing-then-fusing network for RGB-TIR semantic segmentation. <em>APIN</em>, <em>55</em>(6), 1-24. (<a href='https://doi.org/10.1007/s10489-025-06411-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the task of understanding scenes in visible (RGB) and thermal-infrared (TIR) images has garnered increasing interest in the field of computer vision. However, most existing methods employ simplistic fusion strategies to merge features from different modalities. These strategies often overlook the differences in shallow-level features between modalities, thereby reducing the discriminability of the fused features and resulting in suboptimal segmentation performance. To address this issue, we present a novel RGB-TIR semantic segmentation framework, named NTFNet. This framework exploits the potential consistency of semantic-level features to rectify shallow-level features and reduce discrepancies between modalities prior to integration. Specifically, auxiliary encoders are employed at each layer to capture semantically consistent information. To obtain rich multi-modal semantic features, we designed a High-Level Feature Fusion Module (HFFM) that enhances feature representation in both channel and spatial dimensions. Subsequently, the Shallow Feature Difference Rectification Module (SFDRM) is introduced to rectify the difference in shallow-level features. To address the loss of detailed information during the rectification process, the SFDRM incorporates a Detail Attention Mechanism (DAM) to preserve the original detail information, thereby further optimizing the final segmentation results. In the end, a Multi-Scale Feature Fusion module (Multi-Scale FFM) is designed to combine the rectified features. Comprehensive experiments on two public RGB-TIR datasets show that our method significantly outperforms other state-of-the-art approaches in terms of performance.},
  archive      = {J_APIN},
  author       = {Liu, Yichen and Ye, Junjie and He, Wangpeng and Qu, Zhiqiang and Xu, Ruoxuan},
  doi          = {10.1007/s10489-025-06411-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {NTFNet: Narrowing-then-fusing network for RGB-TIR semantic segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic graph-based graph attention network for anomaly detection in industrial multivariate time series data. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06412-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For industrial big data, anomaly detection for multivariate time series data is of critical strategic significance. However, the complexity of industrial equipment and production processes, combined with the high dimensionality of production data, makes it challenging for traditional anomaly detection methods to effectively capture the complex interdependencies and dynamic evolutionary relationships among multiple variables. Additionally, issues such as unstable data distributions, variability, and data drift exacerbate the challenges faced by anomaly detection methods in industrial data analysis and decision-making. This study presents a dynamic graph-based graph attention network for anomaly detection in a multivariate time series data (D-GATAD) model, introducing an innovative approach to dynamic graph construction. The proposed method seamlessly integrates node content features with graph topological structure information, enabling adaptive construction of dynamic graphs based on the current sensor network structure. This design allows for precise modeling of the complex temporal dependencies between variables. Furthermore, the method incorporates an optimized prediction-based model design that organically combines embedding vectors with node data, thereby significantly enhancing the interpretability of the analytical results. Experimental evaluations demonstrate that the proposed method outperforms existing state-of-the-art models across multiple public benchmark datasets. Notably, on the highly complex WADI dataset, it achieves a 5.12% improvement in the AUC score, underscoring its robustness and effectiveness in industrial anomaly detection. This research offers an innovative and widely applicable solution for industrial data analysis and anomaly detection, with significant implications for practical deployment.},
  archive      = {J_APIN},
  author       = {Gao, Cong and Ma, Hongye and Pei, Qingqi and Chen, Yanping},
  doi          = {10.1007/s10489-025-06412-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Dynamic graph-based graph attention network for anomaly detection in industrial multivariate time series data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved data-driven model-free adaptive control method for an upper extremity power-assist exoskeleton. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06415-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread application of power-assist exoskeletons in physical labor and daily activities has increased the demand for robust control strategies to address challenges in human-exoskeleton interaction. Factors such as collisions and friction introduce uncertain disturbances, making it difficult to establish an accurate human-exoskeleton interaction model, thereby limiting the applicability of current model-based control methods. To overcome these problems, this study proposes an improved data-driven model-free adaptive control method (IMFAC) for the upper extremity power-assist exoskeleton. The stability and convergence of the closed-loop system are rigorously proven. To optimize the initial conditions of IMFAC, we propose an improved snake optimizer (ISO) algorithm incorporating opposition-based learning. The proposed ISO-IMFAC method is evaluated in two scenarios: a nonlinear Hammerstein model benchmark and a physical exoskeleton platform. Experimental results demonstrate that ISO-IMFAC outperforms other popular data-driven control methods across six metrics: integrated absolute error (4.756), mean integral of time-weighted absolute error (0.457), maximum error (1.167), minimum error (0), mean error (0.032), and error standard deviation (0.169). Additionally, the ISO-IMFAC method effectively drives the exoskeleton without relying on its dynamic model. In two load-bearing experiments conducted with five subjects wearing the exoskeleton, the proposed method reduces average muscle exertion per unit time by over 50% and extended working time by more than 180%. These findings highlight the significant potential of the proposed method to enhance user endurance and reduce physical strain, paving the way for practical applications in diverse real-world scenarios. The code is released at https://github.com/Shurun-Wang/ISO-IMFAC .},
  archive      = {J_APIN},
  author       = {Wang, Shurun and Tang, Hao and Ping, Zhaowu and Tan, Qi and Wang, Bin},
  doi          = {10.1007/s10489-025-06415-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Improved data-driven model-free adaptive control method for an upper extremity power-assist exoskeleton},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated echocardiogram image quality assessment with YOLO and resnet in the left ventricular myocardium of A4C views. <em>APIN</em>, <em>55</em>(6), 1-31. (<a href='https://doi.org/10.1007/s10489-025-06419-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The image quality of echocardiography is an important factor to affect cardiovascular disease diagnosis. Currently, the deep learning (DL) used in cardiac echocardiogram image quality assess model focus more on evaluating the whole dynamic video, but the outputs revealed less local anatomical details in judging the image quality in heart chambers. This study was aimed to achieve the local part image quality assess, specifically for the five locals in the left ventricle of A4C section for myocardium. The object detection model, YOLOv8 (You Only Look Once), were used to crop five local parts in the left ventricle myocardium of A4C section. Then, the ResNet-18 model was used to evaluate the image quality of each cropped part, that output from score 0 to 3, four quality levels. The YOLOv8 model demonstrated exceptional performance metrics with Precision of 98.77%, Recall of 98.84%, mAP50 of 98.95%, and mAP50-90 of 81.33%. Additionally, the model exhibited an average Inference Time of 215ms per frame. Comparatively, the ResNet-18 model achieved Accuracy scores of 79.34%, 82.41%, 77.82%, 82.33%, and 78.13%, which correspond to the assessment of the left ventricular myocardium in all five local A4C views. The aggregate performance of the ResNet-18 model was characterized by average Macro Precision of 66.77%, Recall of 59.89%, and F1 Score of 59.49%. Furthermore, the model displayed average Micro Precision of 67.42%, Recall of 70.00%, and F1 Score of 69.98%. This study determined the effectiveness of YOLOv8 to find the bounding box of local myocardium and ResNet-18 for real-time automatic quality assessment, and had the potential to improve the efficiency of diagnosis for the doctor using echocardiogram.},
  archive      = {J_APIN},
  author       = {Liu, Weiyang and Wang, Qiushuang and Zhang, Peifang and Deng, Yujiao and Zhao, Yawei and Zhang, Yongming and Xu, Hongli and Qiu, Xiaowan and Chen, Xu and Xu, Jiayu and He, Kunlun},
  doi          = {10.1007/s10489-025-06419-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-31},
  shortjournal = {Appl. Intell.},
  title        = {Automated echocardiogram image quality assessment with YOLO and resnet in the left ventricular myocardium of A4C views},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time AI-driven quality control for laboratory automation: A novel computer vision solution for the opentrons OT-2 liquid handling robot. <em>APIN</em>, <em>55</em>(6), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06334-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adoption of robotics and automated solutions in life sciences R&D has accelerated in recent years, driven by the need to process increasing sample volumes, protect laboratory staff from hazardous substances, and manage financial pressures. Various automation systems, each with distinct levels of sample processing, transportation tasks, and data management, are available to meet specific application requirements, with liquid handling robots taking pivotal positions in these systems. However, current liquid handling robots, such as the Opentrons OT-2, lack integrated vision-based quality control, which limits their accuracy and reliability. This study presents an AI-driven computer vision model designed to enhance quality control in laboratory automation. By integrating the YOLOv8 object detection model with the OT-2, our model enables precise detection of pipette tips and liquid volumes, providing real-time feedback on errors, such as missing tips and incorrect liquid levels. Our results demonstrate the model's effectiveness and accessibility, presenting an affordable solution for improving automation in academic and research laboratories. This closed-loop system transforms the OT-2 into a robust tool for automated laboratory tasks, making it an accessible and cost-effective approach for enhancing quality control in laboratory automation and addressing a critical gap in available tools for resource-limited settings.},
  archive      = {J_APIN},
  author       = {Khan, Sana Ullah and Møller, Vilhelm Krarup and Frandsen, Rasmus John Normand and Mansourvar, Marjan},
  doi          = {10.1007/s10489-025-06334-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Real-time AI-driven quality control for laboratory automation: A novel computer vision solution for the opentrons OT-2 liquid handling robot},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anomaly detection in crowd scenes via cross trajectories. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06338-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel finite-time braid entropy (FTBE) theorem to extract feature vectors to detect abnormal events occurring globally and locally in crowds. Detecting abnormal events or behavior in crowd movements is a key research topic regarding community security and management. A trajectory- based method depending on the FTBE theorem and the distribution of motion vectors is presented to determine abnormal events. The FTBE theory determines the complexity of the pattern occurring during the movement of the trajectories describing the behavior. In most studies in the literature, the image is divided into equal regions and the solution is produced by separating every behavior into more than one zone. However, this may result in incorrect results. Our study separated the behavior within a certain time interval into location-independent motion clusters. Each cluster indicated a behavior, which was represented by a feature vector derived from the distribution of FTBE and motion vectors. The learning model and fully connected deep neural network were used to detect which cluster was behaving abnormally in the local area. In addition, abnormal events were determined globally by the step braid entropy score (SBES) value calculated for the current scene. The method was tested using the UMN, UCSD and UCF-Crime databases. The experimental results of the method showed an alternative approach to the detection of abnormal behavior.},
  archive      = {J_APIN},
  author       = {Akpulat, Murat and Ekinci, Murat},
  doi          = {10.1007/s10489-025-06338-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Anomaly detection in crowd scenes via cross trajectories},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convolutional neural networks for advanced adhesive joints application patterns. <em>APIN</em>, <em>55</em>(6), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06340-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adhesive bonding is a widely used joining technique across various industries. Achieving uniform adhesive coverage over the entire surface without the formation of air pockets is crucial for creating strong and durable joints. Simultaneously, it is essential to minimise waste caused by material leakage at the edges. However, generating an optimal adhesive pattern to achieve the desired adhesive distribution after compression remains a challenge, as fluids tend to spread in a circular manner, while industry-relevant target geometries are typically non-circular. This paper investigates the application of Convolutional Neural Networks (CNNs) to optimise adhesive application patterns by utilising a simplified simulation model known as the Partially Filled Gaps Model (PFGM) to generate extensive training data. The CNN is trained to predict fluid distribution outcomes based on initial adhesive application patterns and addresses the inverse problem of determining an optimal application pattern to achieve a desired target distribution after compression. Two training approaches are introduced: a basic inverse model that utilizes a straightforward input–output data exchange, and a more advanced strategy that incorporates a forward model to improve accuracy. The forward model predicts the final distribution, enabling better refinement of the initial application patterns. The results demonstrate that the CNN-based approach is highly effective in generating optimal application patterns for adhesive bonds. Its primary advantage, compared to alternative methods, lies in its ability to achieve precise results within a short computation time. However, a significant drawback is the limited flexibility in accommodating variations in parameters.},
  archive      = {J_APIN},
  author       = {Scholtes, Kiro and Flaig, Florian and Kaufmann, Marvin and Lehne, Frank Guido and Vallée, Till and Fricke, Holger and Müller, Michael},
  doi          = {10.1007/s10489-025-06340-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Convolutional neural networks for advanced adhesive joints application patterns},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiffusionLight: A multi-agent reinforcement learning approach for traffic signal control based on shortcut-diffusion model. <em>APIN</em>, <em>55</em>(6), 1-25. (<a href='https://doi.org/10.1007/s10489-025-06359-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous researches have shown that the Reinforcement Learning(RL) is an effective solution to solve large-scale traffic signal control(TSC) problems. However, facing multi-scenario and emergencies, cooperative control of traffic signals at multi-intersection becomes a challenging multi-agent reinforcement learning(MARL) process. In order to solve real-world problems, this paper proposes a MARL algorithm called DiffusionLight, which combines Shortcut-Diffusion Model(SDM) and Soft Actor-Critic(SAC), and a fast Diffusion model to solve the traffic signal cooperative control problem of multi-scenario and multi-intersection. DiffusionLight has the stable characteristics and powerful expression ability of the SDM as the strategy network to solve the action space, while SAC is used as the value network to better explore the solution space. Experimental results show that DiffusionLight exhibits better stability compared to the baseline algorithm in the face of multi-scenario TSC and burst data anomalies, and as well as excellent performance on multiple public datasets of grid and arterial traffic networks.},
  archive      = {J_APIN},
  author       = {Yu, JiLin and Wang, Zhiwen and Zhang, Ruonan},
  doi          = {10.1007/s10489-025-06359-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {DiffusionLight: A multi-agent reinforcement learning approach for traffic signal control based on shortcut-diffusion model},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TsDa-ASAM: Balancing efficiency and accuracy in coke image particle size segmentation via two-stage distillation-aware adaptive segment anything model. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06427-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coke image segmentation is a crucial step in coke particle size control of the sintering process. However, due to the complexity of model architecture and the dense distribution of coke particles in the images, existing segmentation methods fail to satisfy the efficiency and accuracy requirements for coke image segmentation in industrial scenarios. To address these challenges, this paper proposes a two-stage distillation-aware adaptive segment anything model to balance efficiency and accuracy in coke image particle size segmentation, referred to as TsDa-ASAM. In the first stage, knowledge distillation methods are employed to distill the Segment Anything Model (SAM) into a lightweight model, explicitly focusing on enhancing segmentation efficiency. In the second stage, a domain knowledge injection strategy is formulated, which incorporates domain knowledge into the distillation model to effectively enhance the accuracy. Moreover, an adaptive prompt point selection algorithm is introduced to address the redundancy issue of prompt points in SAM, improving the efficiency of TsDa-ASAM. The effectiveness of TsDa-ASAM is validated through extensive experiments on the publicly available dataset SA-1B and the coke image dataset from industrial sites. After distillation and fine-tuning, the segmentation accuracy of the proposed model improved by 10%, and the segmentation efficiency of TsDa-ASAM was enhanced by 2 to 3 times with the integration of the adaptive prompt point selection algorithm. The experimental results have effectively demonstrated the potential of the proposed model in balancing accuracy and efficiency.},
  archive      = {J_APIN},
  author       = {Wang, Yalin and Peng, Yubin and Tan, Xujie and Pan, Yuqing and Liu, Chenliang},
  doi          = {10.1007/s10489-025-06427-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {TsDa-ASAM: Balancing efficiency and accuracy in coke image particle size segmentation via two-stage distillation-aware adaptive segment anything model},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Entropy guidance hierarchical rich-scale feature network for remote sensing image semantic segmentation of high resolution. <em>APIN</em>, <em>55</em>(6), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06433-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation of high-resolution remote sensing images (HRRSIs) is crucial for a wide range of applications, such as urban planning and disaster management. However, in HRRSIs, existing multiscale feature extraction and fusion methods often fail to achieve the desired accuracy because of the challenges posed by densely distributed small objects and large-scale variations. Therefore, we propose a hierarchical rich-sale feature network with entropy guidance (HRFNet), which introduces an entropy-based weighting and feature mining strategy to enhance feature extraction and fusion. Specifically, image entropy is employed as a quantifiable index to characterize the object distribution within remote sensing images, enabling an adaptive image division strategy. The image entropy is further used as weights during network training to emphasize regions with high entropy, which often correspond to edges and densely populated small objects. Additionally, the proposed feature mining strategy effectively integrates both global and local contextual information across multilayer feature maps. Extensive experiments show that HRFNet achieves mIoU scores of 81.31%, 86.47%, and 51.5% on the Vaihingen, Potsdam, and LoveDA datasets, respectively, outperforming existing methods by 1.0–3.0% mIoU.},
  archive      = {J_APIN},
  author       = {Zhang, Haoxue and Li, Linjuan and Xie, Xinlin and He, Yun and Ren, Jinchang and Xie, Gang},
  doi          = {10.1007/s10489-025-06433-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Entropy guidance hierarchical rich-scale feature network for remote sensing image semantic segmentation of high resolution},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty weighted policy optimization based on bayesian approximation. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06303-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient exploration remains a major challenge in the field of reinforcement learning (RL). Bayesian methods have been widely investigated within the RL paradigm and are used to implement intelligent exploration strategies. However, most of these methods inevitably introduce some complexity within the Bayesian neural networks (BNNs) or are difficult to optimize elegantly. In this work, a novel algorithm called uncertainty weighted policy optimization (UWPO) based on Bayesian approximation, is introduced. UWPO theoretically analyzes the uncertainty of the policy space using the Dirichlet distribution and Monte Carlo (MC) dropout for both discrete and continuous spaces, eliminating the need for an explicit distribution representation in BNNs. The algorithm also proposes an implicit distributional training method for the value function, which is compatible with Bayesian inference. Moreover, an uncertainty-weighted update principle is adopted to adaptively adjust the contribution of each training instance to the objective. Finally, comparing UWPO with other prevailing deep reinforcement learning (DRL) algorithms on the Atari, MuJoCo, and Box2D platforms. The experimental results demonstrate that the algorithm improves the average reward score by nearly 15% while reducing computational costs by 20% compared to current state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Li, Tianyi and Yang, Genke and Chu, Jian},
  doi          = {10.1007/s10489-025-06303-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Uncertainty weighted policy optimization based on bayesian approximation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SFP: Temporal knowledge graph completion based on sequence-focus patterns representation learning. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06306-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extrapolation task in the temporal knowledge graph has received increasing attention from scholars due to its wide range of practical application scenarios. At present, recurrent neural networks are currently widely used in temporal knowledge graph completion techniques. These networks are employed to depict the sequential pattern of entities and relations. However, as the sequence lengthens, some critical early information may become diluted. Prediction errors ensue in the completion task as a result. Furthermore, it is observed that existing temporal knowledge graph completion methods fail to account for the topological structure of relations, which leads to relation representations with essentially little distinction across different timestamps. In order to tackle the previously mentioned concern, our research introduces a Temporal Knowledge Graph Completion Method utilizing Sequence-Focus Patterns Representation Learning (SFP). This method contains two patterns: the Focus pattern and the Sequential pattern. In the SFP model, we developed a novel graph attention network called ConvGAT. This network efficiently distinguishes and extracts complex relation information, thereby enhancing the accuracy of entity representations that are aggregated in the Focus pattern and Sequential pattern. Furthermore we proposed RelGAT, a graph attention network that simulates the topological structure of relations. This enhances the precision of relation representations and facilitates the differentiation between relation embeddings generated at various timestamps in the Focus pattern. Utilizing a time-aware attention mechanism, the Focus pattern extracts vital information at particular timestamps in order to amplify the data that the Sequential pattern dilutes. On five distinct benchmark datasets, SFP significantly outperforms the baseline, according to a comprehensive series of experiments.},
  archive      = {J_APIN},
  author       = {Wang, Jingbin and Ke, XiFan and Zhang, FuYuan and Wu, YuWei and Zhang, SiRui and Guo, Kun},
  doi          = {10.1007/s10489-025-06306-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {SFP: Temporal knowledge graph completion based on sequence-focus patterns representation learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-computing, deep reinforcement learning-based predictive human-robot neuromechanical simulation for wearable robots. <em>APIN</em>, <em>55</em>(6), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06360-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-robot interaction (HRI) is widely used in robotics to assist humans, with wearable robots enhancing mobility for both able-bodied individuals and those with impairments. Traditionally, characterizing human biomechanical responses to these robots requires extensive human testing, which is time-consuming, costly, and potentially risky. Developing computational HRI simulations for wearable robots offers a promising solution. However, modeling the high-fidelity human-exoskeleton interaction in simulations presents significant challenges that remain underexplored. These include creating a high-fidelity autonomous human motion control agent, accounting for the non-passive nature of human responses, and incorporating closed-loop control within the robotic system. In this paper, we propose an AI-computing, deep reinforcement learning-based HRI simulation to predict complex and realistic human biomechanical responses to exoskeleton assistance. The multi-neural network training process develops an end-to-end, autonomous control policy that reduces human muscle effort by utilizing current human kinematic states. This approach processes state information from both the human musculoskeletal and exoskeleton control neural network, generating control policies for robust human walking movement and reducing muscle effort. Numerical experiments demonstrated the framework’s ability to simulate human motion control, showing reductions in hip joint torque (13.04 $$\%$$ ), rectus femoris (RF) muscle activation (7.31 $$\%$$ ), and biceps femoris (BF) muscle activation (12.21 $$\%$$ ) with exoskeleton use. Validation through real-world experiments further confirmed a decrease in RF and BF muscle activations by 22.12 $$\%$$ and 11.45 $$\%$$ , respectively. These results highlight the effectiveness of our proposed AI computing-based simulation method in replicating and optimizing human biomechanics during exoskeleton-assisted movement. This AI computing-based human-exoskeleton predictive simulation may offer a general, high-fidelity platform for studying human biomechanical responses and enabling autonomous control for assistive devices without requiring intensive human testing in the rehabilitation field.},
  archive      = {J_APIN},
  author       = {Wang, Mingyi and Luo, Shuzhen},
  doi          = {10.1007/s10489-025-06360-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {AI-computing, deep reinforcement learning-based predictive human-robot neuromechanical simulation for wearable robots},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance of machine learning methods for cattle identification and recognition from retinal images. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06398-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Animal identification is a critical issue in terms of security, traceability, and animal health, especially in large-scale livestock enterprises. Traditional methods (such as ear tags and branding) both negatively affect animal welfare and may lead to security vulnerabilities. This study aims to develop a biometric system based on retinal vascular patterns for the identification and recognition of cattle. This system aims to provide a safer and animal welfare-friendly alternative by using image processing techniques instead of traditional device-based methods. In the study, preprocessing, segmentation, feature extraction, and performance evaluation steps were applied for the biometric identification and recognition process using retinal images taken from both eyes. Techniques such as green channel extraction, contrast-limited adaptive histogram equalization, morphological operations, noise filtering, and threshold determination were used in the preprocessing stage. Fuzzy C-means, K-means, and Level-set methods were applied for segmentation, and feature extraction was performed using SIFT, SURF, BRISK, FAST, and HARRIS methods. At the end of the study, the highest accuracy rate was obtained as 95.6% for identification and 87.9% for recognition. In addition, the obtained dataset was shared publicly, thus creating a reusable resource that researchers from different disciplines can use. It was concluded that this study made a significant contribution to the field of biometric-based animal identification and recognition and offered a practically usable solution in terms of animal welfare and safety.},
  archive      = {J_APIN},
  author       = {Cihan, Pınar and Saygılı, Ahmet and Akyüzlü, Muhammed and Özmen, Nihat Eren and Ermutlu, Celal Şahin and Aydın, Uğur and Yılmaz, Alican and Aksoy, Özgür},
  doi          = {10.1007/s10489-025-06398-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Performance of machine learning methods for cattle identification and recognition from retinal images},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effect of continuous S-shaped rectified linear function on deep convolutional neural network. <em>APIN</em>, <em>55</em>(6), 1-24. (<a href='https://doi.org/10.1007/s10489-025-06399-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vanishing gradient issue in convolutional neural networks (CNNs) is often addressed by improving activation functions, such as the S-shaped rectified linear activation unit (SReLU). However, SReLU can pose challenges in updating training parameters effectively. To mitigate this, we propose applying the Aggregation Fischer–Burmeister (AFB) function to SReLU, which smooths the secant line slope of the function from both sides. However, direct application of AFB to SReLU can intensify the vanishing gradient issue due to irregular function behavior. To address this concern, we introduce a regulated version of AFB (ReAFB) that ensures proper gradient and mean activation output conditions when applied to SReLU (ReAFBSReLU). We evaluate the performance of CNNs using ReAFBSReLU on three benchmark datasets: MNIST, CIFAR-10 (with and without data augmentation), and CIFAR-100. Specifically, we implement Network in Network (NIN) for MNIST and CIFAR-10, and LeNet for CIFAR-100 dataset. Additionally, we utilize SqueezeNet exclusively to compare the performance of CNNs using the proposed ReAFBSReLU activation function against state-of-the-art activation functions. Our results demonstrate that ReAFBSReLU outperforms other activation functions tested in this study, indicating its efficacy in enhancing training parameter updates and subsequently improving accuracy.},
  archive      = {J_APIN},
  author       = {Ghazvini, Anahita and Abdullah, Siti Norul Huda Sheikh and Ayob, Masri},
  doi          = {10.1007/s10489-025-06399-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {Effect of continuous S-shaped rectified linear function on deep convolutional neural network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Use of artificial intelligence techniques in characterization of vibration signals for application in agri-food engineering. <em>APIN</em>, <em>55</em>(6), 1-24. (<a href='https://doi.org/10.1007/s10489-025-06424-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bottling machinery is a critical component in agri-food industries, where maintaining operational efficiency is key to ensuring productivity and minimizing economic losses. Early detection of faulty conditions in this equipment can significantly improve maintenance procedures and overall system performance. This research focuses on health monitoring of gripping pliers in bottling plants, a crucial task that has traditionally relied on analyzing raw vibration signals or using narrowly defined, application-specific features. However, these methods often face challenges related to limited robustness, high computational costs, and sensitivity to noise. To address these limitations, we propose a novel approach based on generic features extracted through basic signal processing techniques applied to vibration signals. These features are then classified using a random forest algorithm, enabling an effective analysis of health states. The proposed method is evaluated against traditional approaches and demonstrates clear advantages, including higher accuracy in detecting and classifying faulty conditions, greater robustness against random perturbations, and a reduced computational cost. Additionally, the method requires fewer training instances to achieve reliable performance. This study highlights the potential of artificial intelligence and signal processing techniques in predictive maintenance, offering a scalable and efficient solution for fault detection in manufacturing processes, particularly within the agri-food sector.},
  archive      = {J_APIN},
  author       = {Luque, Amalia and Campos Olivares, Daniel and Mazzoleni, Mirko and Ferramosca, Antonio and Previdi, Fabio and Carrasco, Alejandro},
  doi          = {10.1007/s10489-025-06424-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {Use of artificial intelligence techniques in characterization of vibration signals for application in agri-food engineering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparison study of several strategies in multivariate time series clustering based on graph community detection. <em>APIN</em>, <em>55</em>(6), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06444-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series data analysis, especially forecasting, classification, imputation, and anomaly detection, has gained a lot of research attention in recent years due to its prevalence and wide application. Compared to classification, clustering is an unsupervised task and thus more applicable for analyzing massive time series without labels. One latest way is based on the idea of graph community detection: first transforming a time series set into a graph (or a network), in which a node represents a time series instance and an edge denotes that the two connected nodes (thus the represented time series) are more similar to each other; then, running a community detection algorithm on the graph to discover a community structure, that gives out a clustering result. Recently, there are several works based on the graph community detection idea to cluster multivariate time series. However, such works focus only on specific methods in each step, and a performance comparison of combinations of methods in different steps is lacking. This paper outlines the process of graph-based multivariate time clustering as four phases (referred to as framework), namely representation learning, similarity computing, relation network construction, and clustering, lists typical methods in each phase, and makes a comparison study of combinations of each phase methods (called strategies in this paper). Recent time series deep neural network models are introduced to the framework as time series representation learning methods as well. In addition, $$\varvec{\varepsilon } \varvec{k}$$ NN, an improvement of $$\varvec{k}$$ NN by filtering out unnecessary low similarity connections during network construction, is proposed. A great number of experiments are conducted on eight real-world multivariate time series with various properties to verify the performance of different strategy combinations. The results suggest that proper deep neural network is a promising way for learning time series vector representations to compute similarities, and strategies including $$\varvec{\varepsilon } \varvec{k}$$ NN for network construction, average for multi-layer network merging and Louvain for clustering are more effective from a statistical perspective.},
  archive      = {J_APIN},
  author       = {Sun, Hanlin and Jie, Wei and Chen, Yanping and Wang, Zhongmin},
  doi          = {10.1007/s10489-025-06444-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {A comparison study of several strategies in multivariate time series clustering based on graph community detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QuinNet: Quintuple u-shape networks for scale- and shape-variant lesion segmentation. <em>APIN</em>, <em>55</em>(6), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06448-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning approaches have demonstrated remarkable efficacy in medical image segmentation. However, they continue to struggle with challenges such as the loss of global context information, inadequate aggregation of multi-scale context, and insufficient attention to lesion regions characterized by diverse shapes and sizes. To address these challenges, we propose a new medical image segmentation network, which consists of one main U-shape network (MU) and four auxiliary U-shape sub-networks (AU), leading to Quintuple U-shape networks in total, thus abbreviated as QuinNet hereafter. MU devises special attention-based blocks to prioritize important regions in the feature map. It also contains a multi-scale interactive aggregation module to aggregate multi-scale contextual information. To maintain global contextual information, AU encoders extract multi-scale features from the input images, then fuse them into feature maps of the same level in MU, while the decoders of AU refine features for the segmentation task and co-supervise the learning process with MU. Overall, the dual supervision of MU and AU is very beneficial for improving the segmentation performance on lesion regions of diverse shapes and sizes. We validate our method on four benchmark datasets, showing that it achieves significantly better segmentation performance than the competitors. Source codes of QuinNet are available at https://github.com/Truman0o0/QuinNet .},
  archive      = {J_APIN},
  author       = {Fan, Gaojuan and Wang, Jie and Xia, Ruixue and Zhou, Funa and Zhang, Chongsheng},
  doi          = {10.1007/s10489-025-06448-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {QuinNet: Quintuple u-shape networks for scale- and shape-variant lesion segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reinforcement learning malware detection model based on heterogeneous information network path representation. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06417-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the significant increase of Android malware, the APP privacy data leakage incidents occur frequently, which poses a great threat to user property and information security. Specifically, the new malware has the characteristics of high evolution rate and diverse variants, leading to the fact that the current malware detection methods still have three key problems: (1) Difficulty in acquiring Android sample structural features; (2) Weakly in representing malware behavior structure; (3) Poor robustness of the detection model. To address the above limitations, we propose a new malware detection framework MPRLDroid with reinforcement learning. First of all, the MPRLDroid model extracts the Android APP structural features and constructs the heterogeneous information network data based on the semantic call structure between APP, API and permission. Subsequently, the model utilizes reinforcement learning to adaptively generate a meta-path for each sample and combines it with a graph attention network to effectively represent the graph of nodes. Finally, the low-dimensional graph node vector data is brought into the downstream detection task for classification, where the performance change of the classification result is used as a reward function for reinforcement learning. The experimental results demonstrate that the MPRLDroid model, when integrated with reinforcement learning, outperforms the baseline models in terms of performance, and its detection model exhibits greater robustness compared to other models.},
  archive      = {J_APIN},
  author       = {Yang, Kang and Cai, Lizhi and Wu, Jianhua and Liu, Zhenyu and Zhang, Meng},
  doi          = {10.1007/s10489-025-06417-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {A reinforcement learning malware detection model based on heterogeneous information network path representation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSF-SegFormer: A feature fusion algorithm for magnetic leakage image segmentation. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06453-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional segmentation networks have low segmentation accuracy for flux leakage images, often leading to missed or false detections of small defects, which significantly affect the evaluation of defect severity. Based on the SegFormer network, a high-accuracy decoder based on multi-scale feature fusion is proposed, which is more suitable for the segmentation of small defects in flux leakage and replaces the multi-layer perceptron (MLP) decoder of the original network. The new network model is called MSF-SegFormer. MSF-SegFormer introduces a feature fusion network MSF that integrates high-resolution and low-resolution features and introduces feature pyramid fusion, which can merge output features at different levels across different scales. A cascaded attention module is proposed, combining two local attention mechanisms in a cascade and using a residual network to enhance the local feature representation of flux leakage images, improving the accuracy and stability of the task. In the application of flux leakage defect data, compared with benchmark models such as CNN and SegFormer, this model can accurately segment target edges with fewer parameters, maintain high accuracy, reduce false detection probability, and improve the Miou value of the traditional MLP decoder from 88.21% to 90.44%.},
  archive      = {J_APIN},
  author       = {Wang, Zhujun and Ni, Rongtai and Sun, Tianhe and Jiang, Yulong and Liu, Bin},
  doi          = {10.1007/s10489-025-06453-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {MSF-SegFormer: A feature fusion algorithm for magnetic leakage image segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FA3-net: Feature aggregation and augmentation with attention network for sound event localization and detection. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06437-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sound event localization and detection (SELD) aims to identify the category and duration of sound events (SED) while also estimating their respective direction of arrival (DOA). This multi-task problem presents unique challenges, as the features required for SED and DOA tasks are not entirely aligned. Consequently, incomplete feature extraction and suboptimal feature fusion often hinder performance. To address these issues, we propose a feature aggregation and augmentation with attention network (FA3-Net). FA3-Net consists of two main components: the feature aggregation and augmentation with attention (FA3) module and the Conformer module. The FA3 module plays a critical role in fusing and enhancing high-level features, which is specifically designed to efficiently handle the distinct requirements of SED and DOA tasks. It ensures that task-specific features are extracted effectively, while also improving feature discriminability and reducing confusion. The feature aggregation residual block (FAResBlock), a component of the FA3 module, handles task-specific feature aggregation, while the feature augmentation with attention block (FAA block) enhances feature representation across multiple dimensions. The Conformer module is employed to model the temporal sequence, as it excels in capturing both local and global dependencies, making it ideal for comprehensive time sequence analysis. Finally, to overcome data limitations, audio channel swapping (ACS) is employed. Experiments on the STARSS23 dataset, DCASE2021 dataset and L3DAS22 dataset show that FA3-Net significantly outperforms other models in both feature aggregation and augmentation, while also being more efficient and lightweight. The code is available in: https://github.com/wangchuan11111111/FA3-NET},
  archive      = {J_APIN},
  author       = {Wang, Chuan and Huang, Qinghua},
  doi          = {10.1007/s10489-025-06437-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {FA3-net: Feature aggregation and augmentation with attention network for sound event localization and detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved DAB-DETR model for irregular traffic obstacles detection in vision based driving environment perception scenario. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06440-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine vision based irregular traffic obstacles recognition plays a pivotal role in the autonomous driving and Advanced Driver Assistance Systems (ADAS) by providing the necessary environment perception capabilities. Traditional models for recognizing irregular traffic obstacles suffer from challenges with small target detection, poor performance in diverse environmental conditions and computational complexity. This work addresses the critical issue of recognizing irregular traffic obstacles in roadway environments. We present an enhanced target detection model based on the Dynamic Anchor Boxes-recognition Transformer (DAB-DETR). The original model’s structure was limited in expressing relative positional information between features due to the reliance on absolute position encoding. To overcome this limitation, the improved DAB-DETR incorporates relative position encoding within the multi-headed self-attention mechanism of the Transformer encoder. Additionally, we propose a novel Average Precision (AP) loss function that unifies classification and localization losses into a single parameterized formula, addressing performance degradation observed in the original model. Experimental results demonstrate significant improvements in detection accuracy for irregular traffic objects, showcasing the effectiveness of the proposed enhancements. According to the testing results, the improved DAB-DETR model’s detection accuracy is 82.00% with Intersection over Union (IoU) equals to 0.5, which is 3.3% better than the original model and 6.20% and 7.71% better than the conventional models, YOLOv5 and Faster R-CNN, respectively.},
  archive      = {J_APIN},
  author       = {Yang, Junchao and Zhang, Hui and Zhou, Yuting and Guo, Zhiwei and Lin, Feng},
  doi          = {10.1007/s10489-025-06440-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Improved DAB-DETR model for irregular traffic obstacles detection in vision based driving environment perception scenario},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ship pipeline defect detection method based on deep learning and transfer fusion of ultrasonic guided wave signals. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06390-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasonic guided waves (UGW) hold great promise for structural health monitoring (SHM) of pipeline structures. However, the inherent complexity of pipeline defect features within the UGW makes the intuitive and accurate identification of defects based only on UGW signals challenging. In addition, the existing neural network-based UGW signal recognition methods require a large number of defect waveform samples, which limits their applicability. This study proposes a signal recognition method based on deep learning and sample transfer fusion for the identification of UGW signals in ship pipelines, allowing to accurately detect their potential defects. A time–frequency imaging algorithm for ship pipeline UGW signals is first introduced using the continuous wavelet transform (CWT) to capture their time–frequency characteristics. Leveraging transfer learning, UGW signal samples from various operational scenarios onshore oil pipelines are then fused to pre-train the GoogLeNet convolutional neural network (CNN) model. Finally, the pre-trained GoogLeNet model is fine-tuned with ship pipeline UGW signal samples, which allows to accurately detect the underlying defects. The experimental results demonstrate that the proposed method significantly increases the classification accuracy of ship pipeline defects compared with non-transfer learning methods and time-domain imaging. More precisely, the accuracy increases from 63.3% to 97.3%. Furthermore, the obtained results show that the proposed method has high robustness.},
  archive      = {J_APIN},
  author       = {Tang, Ruoli and Li, Yongzhe and Zhang, Shangyu},
  doi          = {10.1007/s10489-025-06390-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Ship pipeline defect detection method based on deep learning and transfer fusion of ultrasonic guided wave signals},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning-based road surveillance system in distributed CCTV environment: Pedestrian fall recognition using spatio-temporal attention networks. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06451-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent CCTV systems are highly effective in monitoring pedestrian and vehicular traffic and identifying anomalies in the roadside environment. In particular, it is necessary to develop an effective recognition system to address the problem of pedestrian falls, which is a major cause of injury in road traffic environments. However, the existing systems have challenges such as communication constraints and performance instability. In this paper, we propose a novel fall recognition system based on Federated Learning (FL) to solve these challenges. The proposed system utilizes a GAT combined with LSTM and attention layers to extract spatio-temporal features, which can more accurately identify pedestrian falls. Each road CCTV works as an independent client to generate local data, and the server aggregates these models to learn a global model. This ensures robust operation in different views and environments, and solves the bottleneck of data communication and security challenges. We validated the feasibility and applicability of the FL-based fall recognition method by implementing the prototype and applying it to the UP-FALL benchmark dataset, which is widely used for fall recognition. Code has been made available at: https://github.com/Kim-Byeong-Hun/Fed-PFR .},
  archive      = {J_APIN},
  author       = {Kim, Byeonghun and Im, Jaegyun and Noh, Byeongjoon},
  doi          = {10.1007/s10489-025-06451-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Federated learning-based road surveillance system in distributed CCTV environment: Pedestrian fall recognition using spatio-temporal attention networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-dimensional requirements for reinforcement recommendation reasoning. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05854-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized recommendation systems not only need to improve the accuracy of recommendations, but also need to focus on the variety and novelty of recommendations to improve user satisfaction. Currently, most of the existing recommendation systems focus on improving the accuracy and diversity of recommendation items, however, they usually do not consider the original user needs, and the potential relationship between diversity and novelty is not deeply explored. In addition to accuracy and diversity, we also consider novelty, and analyze the relationship between diversity and novelty (same place and different place), and propose an explainable recommendation system that integrates multiple (multidimensional) requirements such as accuracy, diversity, and novelty. The model combines semantic relations of knowledge graphs and multi-hop inference so as to analyze and consider the diversity and novelty requirements of users. Meanwhile, a recurrent neural network is used to construct a temporal multi-label classification network to predict users’ multidimensional demands and capture the dependencies between diversity and novelty demands. Finally, a composite reward function, including accuracy reward, diversity reward and novelty reward, is designed to implement a multi-demand, multi-decision recommendation method. Experiments are conducted on three real-world datasets, and the experimental results show that the model can guarantee the accuracy while improving the diversity and novelty of recommended items.},
  archive      = {J_APIN},
  author       = {Li, Yinggang and Tong, Xiangrong and Lv, Zhongming},
  doi          = {10.1007/s10489-024-05854-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Multi-dimensional requirements for reinforcement recommendation reasoning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ISL-net: Dual-stream interaction network with task-optimized modules for more accurate, complete iris segmentation and localization. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-024-05862-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Iris images captured in uncooperative and unconstrained environments pose significant challenges for iris segmentation and localization owing to factors including high occlusions, specular reflections, motion blur, iris rotation, and off-angle images. To address this challenge, this paper proposes ISL-Net, a multitask segmentation network with a task-optimization module based on deep learning for joint iris segmentation and localization. We developed a dual-stream interactive module (DSIM) that combines dual-stream decoders to facilitate information exchange between tasks without interference. To optimize the iris-segmentation and iris-localization performance, we incorporated a balanced attention module (BAM) and a boundary-enhancement module (BEM) in the skip connections of the respective task stream decoders. The BEM recovers missing boundaries in iris localization, while the BAM focuses on uncertain areas in iris segmentation, enhancing the model’s ability to handle these regions. These modules complement each other, improving overall system performance without interference. The proposed model was evaluated on three challenging iris datasets, outperforming most existing models by achieving e1 index scores of 0.34, 0.79, and 0.61% and average normalized Hausdorff distances (HDs) of 0.7221, 1.1914, and 1.0396%. The results indicate that ISL-Net can generate normalized iris images with simple post-processing, making it suitable for direct application in existing iris-recognition systems.},
  archive      = {J_APIN},
  author       = {He, Lei and Yang, Xiaokai and Zheng, Jian and Liu, Zhaobang and Yang, Xiaoguo},
  doi          = {10.1007/s10489-024-05862-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {ISL-net: Dual-stream interaction network with task-optimized modules for more accurate, complete iris segmentation and localization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SDDP: Sensitive data detection method for user-controlled data pricing. <em>APIN</em>, <em>55</em>(6), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06229-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, there is an urgent need for data sharing, in which data pricing is a crucial issue, because a reasonable price can not only enhance the willingness of users to share data but also promote the progress of data sharing. However, current research is mostly approached from the perspective of data sharing platforms, treating all data equally without sufficient evaluation of sensitive data within shared datasets and personalized perception of privacy from the users themselves. To address this problem, we detected sensitive data in each piece of data and then defined the pricing function based on information entropy and the user’s perception of sensitive information. To enhance the accuracy of sensitive data detection, we integrated an attention mechanism into a pre-trained model to comprehensively represent the samples. Subsequently, on the basis of automatically generating label correlation vectors to calculate the correlation matrix, a graph convolutional neural network was employed to mine the correlation between labels. Furthermore, based on the detection results, information entropy and user ratings are reasonably mapped to prices. Pricing based on user ratings is more suitable for pricing personal data rather than government or institutional data. The experimental results on the dataset of Twitter text sent by users have demonstrated that the average precision of our sensitive data detection model has improved by up to 9.26% compared to comparison models, and SDDP can provide reasonable pricing for samples containing sensitive data and fair compensation for users.},
  archive      = {J_APIN},
  author       = {Hu, Yuchuan and Hu, Bitao and Guo, Bing and Dai, Cheng and Shen, Yan},
  doi          = {10.1007/s10489-025-06229-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {SDDP: Sensitive data detection method for user-controlled data pricing},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale dual-stream visual feature extraction and graph reasoning for visual question answering. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06325-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in deep learning algorithms have significantly expanded the capabilities of systems to handle vision-to-language (V2L) tasks. Visual question answering (VQA) presents challenges that require a deep understanding of visual and language content to perform complex reasoning tasks. The existing VQA models often rely on grid-based or region-based visual features, which capture global context and object-specific details, respectively. However, balancing the complementary strengths of each feature type while minimizing fusion noise remains a significant challenge. This study propose a multi-scale dual-stream visual feature extraction method that combines grid and region features to enhance both global and local visual feature representations. Also, a visual graph relational reasoning (VGRR) approach is proposed to further improve reasoning by constructing a graph that models spatial and semantic relationships between visual objects, using Graph Attention Networks (GATs) for relational reasoning. To enhance the interaction between visual and textual modalities, we further propose a cross-modal self-attention fusion strategy, which enables the model to focus selectively on the most relevant parts of both the image and the question. The proposed model is evaluated on the VQA 2.0 and GQA benchmark datasets, demonstrating competitive performance with significant accuracy improvements compared to state-of-the-art methods. Ablation studies confirm the effectiveness of each module in enhancing visual-textual understanding and answer prediction.},
  archive      = {J_APIN},
  author       = {Yusuf, Abdulganiyu Abdu and Feng, Chong and Mao, Xianling and Li, Xinyan and Haruna, Yunusa and Duma, Ramadhani Ally},
  doi          = {10.1007/s10489-025-06325-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Multi-scale dual-stream visual feature extraction and graph reasoning for visual question answering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Locomotion mode prediction in real-life walking with and without ankle–foot exoskeleton assistance. <em>APIN</em>, <em>55</em>(6), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06416-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exoskeletons can assist human locomotion in real-life scenarios, but existing tools for decoding locomotion modes (LMs) focus on recognition rather than prediction, which can lead to delayed assistance. This study proposes a long short-term memory (LSTM) neural network to predict five LMs (level-walking, ramp ascent/descent, stair ascent/descent) with greater lead time compared to state-of-the-art methods. We examined the optimal sequence length (SL) for LSTM-based LM prediction, using data from inertial sensors placed on the lower limbs and the lower back, along with a waist-mounted infrared laser. Ten subjects walked in real-life scenarios, both with and without an ankle–foot exoskeleton. Results show that a 1-s SL provides the most advanced and accurate LM prediction, outperforming SLs of 0.6, 0.8, and 1.2 s. The proposed LSTM model achieved an accuracy of 98 ± 0.31%, predicting LMs 0.66 s in advance (for an average stride time of 1.98 ± 0.83 s). Level-walking presented more misclassifications, and the model primarily relied on inertial data over laser input. Overall, these findings demonstrate the LSTM’s strong predictive capability for both assisted and non-assisted walking and independent of which limb executes the transition, supporting its applicability for exoskeleton-assisted locomotion.},
  archive      = {J_APIN},
  author       = {Carvalho, Simão P. and Figueiredo, Joana and Cerqueira, João J. and Santos, Cristina P.},
  doi          = {10.1007/s10489-025-06416-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Locomotion mode prediction in real-life walking with and without ankle–foot exoskeleton assistance},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A scale-cross non-local network with higher-level semantics guidance for smoke segmentation. <em>APIN</em>, <em>55</em>(6), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06420-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smoke semantic segmentation (SSS) is particularly challenging task due to the various patterns of the target itself, which are caused by the characteristics of smoke, like, non-rigid, translucent, fuzzy, environment-sensitive, and so forth. This paper tailor-makes the Scale-Cross Non-Local Network (SCNN) for Smoke Segmentation, aiming to accurately locate the position of smoke in complex scenes. While non-local enjoys the bonus of the excellent competence in modeling long-range contextual dependencies acquired by self-attention, the constraint on single-scale input and the suitability for low-resolution feature erode its capability in information representation. To address these issues, we bespoke a Scale-Cross Non-Local (SCNL) module to better integrate local features with global dependencies. In practical scenes, diverse non-smoke objects sharing similarity with smoke pose great obstacles to accurate location of smoke. As a solution, we design a Pyramid Irregular Convolution (PIC) module containing rich high-level semantic to further refine the feature representation of segmentation task. By supervising classification task, the high-level semantics obtained can guide the segmentation feature to correct semantic errors at the image level and alleviate the issue of between-class similarity. To assess its generalization ability, we empirically evaluate our SCNN on extensive synthetic and real data. Experimental results demonstrate that SCNN achieves state-of-the-art performance, exhibiting enhanced smoke localization, accuracy in boundary detection, and a significant reduction in the false segmentation rate for smoke-like objects.},
  archive      = {J_APIN},
  author       = {Zhang, Lin and Wu, Jing and Zhao, Yun and Yuan, Feiniu},
  doi          = {10.1007/s10489-025-06420-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {A scale-cross non-local network with higher-level semantics guidance for smoke segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HKGAT: Heterogeneous knowledge graph attention network for explainable recommendation system. <em>APIN</em>, <em>55</em>(6), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06446-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the Heterogeneous Knowledge Graph Attention Network (HKGAT) for recommendation systems. As recommendation technology evolves, systems now emphasize diversity, fairness, and explainability alongside accuracy. Traditional methods encounter issues integrating knowledge graphs and lack explainability. HKGAT addresses these by leveraging heterogeneous knowledge graphs. It consists of a heterogeneous information aggregation layer, an attention-aware heterogeneous relation fusion layer, and a prediction layer. First, recommendation data forms a user-item knowledge graph. Then, the aggregation layer collects relation information, followed by the fusion layer integrating it for higher-order feature representations. The prediction layer combines link prediction and recommendation score prediction. Additionally, paths of top-ten results are analyzed and quantified for explainability to optimize ranking. Experiments on self-constructed and Amazon-book datasets show HKGAT outperforms baselines like HetGCN, with significant improvements in Precision, Recall, F1 score, and NDCG@10, and a notable 1.9% gain in NDCG@10 from explainable ranking optimization.},
  archive      = {J_APIN},
  author       = {Zhang, Yongchuan and Tian, Jiahong and Sun, Jing and Chan, Huirong and Qiu, Agen and Liu, Cailin},
  doi          = {10.1007/s10489-025-06446-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {HKGAT: Heterogeneous knowledge graph attention network for explainable recommendation system},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging CQT-VMD and pre-trained AlexNet architecture for accurate pulmonary disease classification from lung sound signals. <em>APIN</em>, <em>55</em>(6), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06452-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel algorithm for classifying pulmonary diseases using lung sound signals by integrating Variational Mode Decomposition (VMD) and the Constant-Q Transform (CQT) within a pre-trained AlexNet convolutional neural network. Breathing sounds from the ICBHI and KAUHS databases are analyzed, where three key intrinsic mode functions (IMFs) are extracted using VMD and subsequently converted into CQT-based time-frequency representations. These images are then processed by the AlexNet model, achieving an impressive classification accuracy of 93.30%. This approach not only demonstrates the innovative synergy of CQT-VMD for lung sound analysis but also underscores its potential to enhance computerized decision support systems (CDSS) for pulmonary disease diagnosis. The results, showing high accuracy, a sensitivity of 91.21%, and a specificity of 94.9%, highlight the robustness and effectiveness of the proposed method, paving the way for its clinical adoption and the development of lightweight deep-learning algorithms for portable diagnostic tools. Overview of the proposed methodology for pulmonary disease classification using CQT-VMD and pre-trained AlexNet architecture applied to lung sound signals},
  archive      = {J_APIN},
  author       = {Neili, Zakaria and Sundaraj, Kenneth},
  doi          = {10.1007/s10489-025-06452-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Leveraging CQT-VMD and pre-trained AlexNet architecture for accurate pulmonary disease classification from lung sound signals},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OTMKGRL: A universal multimodal knowledge graph representation learning framework using optimal transport and cross-modal relation. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06459-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demand for integrating multimodal information, such as text and images, has grown significantly as it enables richer and more comprehensive knowledge representations. Most existing multimodal knowledge graph representation learning (KGRL) methods focus primarily on fusing multimodal entity information, directly applying multimodal entities and single-modal relations to downstream tasks. However, these methods face challenges related to the heterogeneity of multi-source entity data, which amplifies the differences in feature distributions between entity and relation representations. To address these challenges, we propose a universal multimodal KGRL framework, OTMKGRL, which seamlessly incorporates multimodal information into three types of single-modal KGRL methods. First, OTMKGRL employs Tucker decomposition to project entity text and image data into a shared space, thereby generating multimodal entity representations. It then uses optimal transport to integrate multimodal entity information into the original single-modal entity representations. Second, OTMKGRL introduces a cross-modal relation attention mechanism that fuses effective multimodal entity features into the original single-modal relations, yielding cross-modal relation representations. Extensive experiments across three multimodal datasets demonstrate the effectiveness and versatility of our approach. The OTMKGRL framework significantly enhances the performance of existing single-modal KGRL models in multimodal settings.},
  archive      = {J_APIN},
  author       = {Wang, Tao and Shen, Bo},
  doi          = {10.1007/s10489-025-06459-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {OTMKGRL: A universal multimodal knowledge graph representation learning framework using optimal transport and cross-modal relation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision-based attention deep q-network with prior-based knowledge. <em>APIN</em>, <em>55</em>(6), 1-14. (<a href='https://doi.org/10.1007/s10489-024-05850-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-based reinforcement learning (RL) is a potent algorithm for addressing tasks related to visual behavioural decision-making; nevertheless, it operates as a black-box, directly training models with images as input in the end-to-end fashion. Therefore, to elucidate the underlying mechanisms of the model and the agent’s focus on different features during the decision-making process, a vision-based attention (VA) mechanism is introduced into vision-based RL in this paper. A prior-based mechanism is introduced to address the issue of instability in the attention maps observed by the agent when attention mechanisms are directly integrated into network updates that results in an increase in single-step errors and larger cumulative errors. Thus, a vision-based attention deep Q-network (VADQN) method with a prior-based mechanism is proposed. Specifically, prior attention maps are obtained using a learnable Gaussian filtering and a spectral residual method. Next, the attention maps are fine-tuned using a self-attention (SA) mechanism to enhance their performance. During training, both the attention maps and the parameters of the policy network are concurrently trained to ensure explanations of the regions of interest during online training. Finally, a series of ablation experiments are conducted on Atari games to compare the proposed method with humans, convolutional neural networks, and other approaches. The results demonstrate that the proposed method not only reveals the regions of interest attended to by DRL during the decision-making process but also enhances DRL performance in certain scenarios. This approach provides valuable insights for understanding and improving the performance of DRL in visual decision-making tasks.},
  archive      = {J_APIN},
  author       = {Ma, Jialin and Li, Ce and Hong, Liang and Wei, Kailun and Zhao, Shutian and Jiang, Hangfei and Qu, Yanyun},
  doi          = {10.1007/s10489-024-05850-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Vision-based attention deep q-network with prior-based knowledge},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised text classification method based on three-way decision with evidence theory. <em>APIN</em>, <em>55</em>(6), 1-15. (<a href='https://doi.org/10.1007/s10489-024-06129-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning methods play a crucial role in text classification tasks. However, due to limitation of scarce labeled training data, the uncertainty of pseudo labels is still an unavoidable problem in semi-supervised text classification. To address this issue, this paper introduces three-way decision theory into semi-supervised text classification model, which divides the model output pseudo-labeled samples into different regions and adopts different processing strategies. The accurate and effective pseudo-labeled samples are selected as much as possible to expand the original training set. For the pseudo-labeled outputs by the model, we use evidence theory to fuse the probability outputs of the samples to improve the stability and credibility of pseudo labels. Experimental results demonstrate that the method introduced in this paper effectively enhances the accuracy of semi-supervised text classification while exhibiting high stability.},
  archive      = {J_APIN},
  author       = {Yang, Ziping and Jiang, Chunmao and Huang, Chunmei},
  doi          = {10.1007/s10489-024-06129-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Semi-supervised text classification method based on three-way decision with evidence theory},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse pinball universum nonparallel support vector machine and its safe screening rule. <em>APIN</em>, <em>55</em>(6), 1-33. (<a href='https://doi.org/10.1007/s10489-025-06356-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonparallel support vector machine (NPSVM) is an effective and popular classification technique, which introduces the $$\epsilon $$ -insensitive loss function instead of the quadratic loss function in twin support vector machine (TSVM), making the model have the same sparsity and kernel strategy as support vector machine (SVM). However, NPSVM is sensitive to noise points and does not utilize the prior knowledge embedded in the unlabeled samples. Therefore, to improve its generalization ability and robustness, a sparse pinball Universum nonparallel support vector machine (SPUNPSVM) is first proposed in this paper. On the one hand, the sparse pinball loss is employed to enhance the robustness. On the other hand, it exploits the Universum data, which do not belong to any class, to embed prior knowledge into the model. Numerical experiments have verified its effectiveness. Furthermore, to further speed up SPUNPSVM, we propose a safe screening rule (SSR-SPUNPSVM) based on its sparsity, which achieves acceleration without sacrificing accuracy. Numerical experiments and statistical tests demonstrate the superiority of our SSR-SPUNPSVM.},
  archive      = {J_APIN},
  author       = {Wang, Hongmei and Li, Ping and Zheng, Yuyan and Jiang, Kun and Xu, Yitian},
  doi          = {10.1007/s10489-025-06356-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-33},
  shortjournal = {Appl. Intell.},
  title        = {Sparse pinball universum nonparallel support vector machine and its safe screening rule},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3DGCformer: 3-dimensional graph convolutional transformer for multi-step origin–destination matrix forecasting. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06371-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting Human mobility is of great significance in the simulation and control of infectious diseases like COVID-19. To get a clear picture of potential future outbreaks, it is necessary to forecast multi-step Origin–Destination (OD) matrices for a relatively long period in the future. However, multi-step Origin–Destination Matrix Forecasting (ODMF) is a non-trivial problem. First, previous ODMF models only forecast the OD matrix for the next time-step, and they cannot perform well on long-term multi-step forecasts due to error accumulation. Second, many ODMF methods capture spatial and temporal dependencies with separate modules, which is insufficient to model spatio-temporal correlations in the time-varying OD matrix sequence. To address the challenges in multi-step ODMF, we propose 3-Dimensional Graph Convolutional Transformer (3DGCformer). As an enhancement of the original 3DGCN, we propose a novel Origin–Destination Feature Propagation (ODFP) rule between 3DGCN layers and integrate 2 3DGCNs with different spatio-temporal graphs and corresponding feature propagation rules to model the formation of OD flows in a more comprehensive way. For multi-step forecasts, 3DGCformer uses Transformer to capture long-term global temporal dependency, and adapt its decoder using labeled tokens to avoid error accumulation and improve time efficiency. To avoid information loss as the number of regions increases, we propose a patch embedding approach to convert data from 3DGCNs to the Transformer module. We perform extensive experiments on 4 real-world human mobility datasets, and the results show that our proposed model outperforms the state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Huang, Yiou and Deng, Hao and Zhao, Shengjie},
  doi          = {10.1007/s10489-025-06371-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {3DGCformer: 3-dimensional graph convolutional transformer for multi-step origin–destination matrix forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HRMG-EA: Heterogeneous graph neural network recommendation with multi-level guidance based on enhanced-attributes. <em>APIN</em>, <em>55</em>(6), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06428-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous Graph Neural Networks are an efficient and powerful tool for modeling graph structure data in recommendation systems. However, existing heterogeneous graph neural networks often fail to model the dependencies between user and item attribute preferences, limiting graph structure optimization and consequently reducing the accuracy of recommendations. To overcome these issues, we propose a Heterogeneous graph neural network Recommendation with Multi-level Guidance based on Enhanced-Attributes (HRMG-EA). First, we design an attribute enhanced gated network to model user-item interaction attribute scenarios and obtain enhanced-attributes by capturing complex attribute dependencies. It effectively avoids the expansion of the graph scale in attribute graph scenarios and further covers personalized attribute relationship distribution characteristics of users and items. Then, we propose a novel multi-level graph structure guidance strategy based on enhanced-attributes. It guides graph structure learning from three optimization levels, optimizing from two perspectives: explicit (heterogeneity and homogeneity) and implicit (contrast enhancement). The former can screen higher-quality heterogeneous neighbor nodes in a direct interaction environment, and filter out redundant or erroneous edges under different similar semantic interest paths to improve the quality of the neighborhood environment. The latter aligns representation embeddings of enhanced-attributes and graph structure in a latent space, explores their potential commonalities, and obtains more comprehensive, fine-grained semantic and beneficial structural information. Finally, on two real-world datasets, HRMG-EA significantly outperforms the state-of-the-art baseline algorithms in both recall and normalized discounted cumulative gain. A large number of ablation experiments and analytical verifications also verify its effectiveness.},
  archive      = {J_APIN},
  author       = {Wang, Longtao and Yuan, Guiyuan and Li, Chao and Zhao, Yufei and Duan, Hua and Zeng, Qingtian},
  doi          = {10.1007/s10489-025-06428-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {HRMG-EA: Heterogeneous graph neural network recommendation with multi-level guidance based on enhanced-attributes},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Separable N-soft sets: A tool for multinary descriptions with large-scale parameter sets. <em>APIN</em>, <em>55</em>(6), 1-37. (<a href='https://doi.org/10.1007/s10489-025-06435-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft set theory builds on the idea of a parameterized family of subsets of a universal set, where for each pertinent characteristic, any specific member of the universe either satisfies it or not. The concept of an N-soft set sharpens this model with the aid of multinary parameterized descriptions; that is, N-soft sets categorize the options in terms of multiple classifications of the characteristics. The aim of this research is fourfold. First, this research focuses on daily-life decision-making problems that involve both positive and negative attributes that can be naturally distributed among classes. Each comparable group of attributes produces an N-soft set, and we can represent all these N-soft sets using separable N-soft sets. We show that this structure facilitates decision-making in the presence of large numbers of attributes. Second, to develop tools that provide a mechanism for the selection of an alternative in this new model, we first develop a complement operator for N-soft sets to uniformize the data, and then, we propose strategies for taking advantage of the qualities of the attributes. Aggregation operators are employed to aggregate the data into a resultant N-soft set, a fuzzy N-soft set, or a hesitant N-soft set. Several algorithmic procedures are proposed to define these methods. Third, we define the novel notion of a multihesitant N-soft set. This loosely defined concept is helpful for representing data with multiple and repetitive entries while avoiding information loss. Finally, we provide solutions to several real-life decision-making problems to illustrate the versatility of our approaches. We apply this theory to construct a new method for ranking countries participating in the Olympic Games. Our motivation is that the existing lexicographic procedure is unable to distinguish among gold, silver, and bronze medals won at sports with very different characteristics.},
  archive      = {J_APIN},
  author       = {Khan, Muhammad Jabir and Alcantud, Jose Carlos R. and Akram, Muhammad and Ding, Weiping},
  doi          = {10.1007/s10489-025-06435-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-37},
  shortjournal = {Appl. Intell.},
  title        = {Separable N-soft sets: A tool for multinary descriptions with large-scale parameter sets},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dark-ControlNet: An enhanced dehazing universal plug-in based on the dark channel prior. <em>APIN</em>, <em>55</em>(6), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06439-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing dehazing models have excellent performance in synthetic scenes but still face the challenge of low robustness in real scenes. In this paper, we propose Dark-ControlNet, a generalized and enhanced dehazing plug-in that uses the dark channel prior as a control condition, which can be deployed on existing dehazing models and can be simply fine-tuned to enhance their robustness in real scenes while improving their dehazing performance. We first freeze the backbone network to preserve its encoding and decoding capabilities and input the dark channel prior with high robustness as conditional information to the plug-in network to obtain prior knowledge. Then, we fuse the dark channel prior features into the backbone network in the form of mean-variance alignment via the Haze&Dark(HD) module and guide the backbone network to decode clear images by fine-tuning the plug-in network. The experimental results show that the existing dehazing model enhanced by Dark-ControlNet performs well on synthetic datasets and real datasets.},
  archive      = {J_APIN},
  author       = {Yang, Yu and Yin, Xuesong and Wang, Yigang},
  doi          = {10.1007/s10489-025-06439-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Dark-ControlNet: An enhanced dehazing universal plug-in based on the dark channel prior},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-enhanced and decomposed transformer for multivariate time series anomaly detection. <em>APIN</em>, <em>55</em>(6), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06441-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread adoption of the Internet of Things (IoT), vast amounts of multivariate time series data are generated, which reflect the operational status of systems. Accurate and efficient anomaly detection in these data is crucial for maintaining system stability. However, data from unstable environments often exhibit high volatility, data drift, and complex patterns of anomalies. Unsupervised anomaly detection models are typically designed for stable data and lack generalizability, leading to a high rate of false positives when applied to unstable data. This paper introduces the frequency-enhanced and decomposed transformer for anomaly detection (FDTAD), which is a novel anomaly detection model based on a transformer that is enhanced with frequency and time series decomposition. FDTAD addresses data drift by decomposing time series and leverages both time-domain and frequency-domain information to improve the generalization ability of the model. The model preserves major amplitudes in the frequency domain to extract primary periodic patterns, uses spectral residuals to capture detailed variations, and incorporates a frequency-domain correlation attention mechanism to extract dependencies in frequency-domain data in a sparse representation. Additionally, a spatiotemporal module is designed to extract the temporal correlations in the data and spatial correlations among the data with different attributes. FDTAD combines a data periodic pattern reconstructor and a data detailed pattern reconstructor through an adversarial mechanism to achieve maximum accuracy in reconstructing normal data. Extensive experiments on 10 public datasets demonstrate that FDTAD outperforms state-of-the-art baseline methods, with a 4.1% improvement in the F1 score and a 4.7% improvement in precision.},
  archive      = {J_APIN},
  author       = {Li, Shijiang and Wang, Zhihai and Wang, Xiaokang and Yin, Zihao and Yao, Muyun},
  doi          = {10.1007/s10489-025-06441-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Frequency-enhanced and decomposed transformer for multivariate time series anomaly detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing graph representation learning via type-aware decoupling and node influence allocation. <em>APIN</em>, <em>55</em>(6), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06443-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional graph representation methods can fit the information of graph with low-dimensional vectors, but they cannot interpret their composition, resulting in insufficient security. Graph decoupling, as a method of graph representation, can analyze the latent factors composing the graph representation vectors. However, in current graph decoupling methods, the number of factors is a hyperparameter, and enforce uniform decoupling vector dimensions which leads to information loss or redundancy. To address these issues, we propose a type-aware graph decoupling based on influence called Variational Graph Decoupling Auto-Encoder (VGDAE). It uses node labels as interpretable and objectively existing natural semantics for decoupling and allocates embedding space based on node influence, addressing the issues of manually setting the number of factors in traditional graph decoupling and the mismatch between node information size and embedding space. On the Cora, Citeseer, and fb-CMU datasets, VGDAE shows the impact of different node classes as decoupling targets on classification tasks. Furthermore, we perform visualization of the representations, VGDAE exhibits performance improvements of 2% in classification tasks and 12% in clustering tasks when compared with baseline models.},
  archive      = {J_APIN},
  author       = {Zhu, Guochang and Hu, Jun and Liu, Li and Zhang, Qinghua and Wang, Guoyin},
  doi          = {10.1007/s10489-025-06443-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing graph representation learning via type-aware decoupling and node influence allocation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). REFD: Recurrent encoder and fusion decoder for temporal knowledge graph reasoning. <em>APIN</em>, <em>55</em>(6), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06445-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reasoning over Temporal Knowledge Graphs (TKGs) presents challenges in modeling the dynamic relationships and evolving behaviors of entities and relations over time. Traditional approaches often treat entities and relations separately, which limits their ability to capture their joint temporal evolution and interactions. To overcome these limitations, REFD (Recurrent Encoder and Fusion Decoder) is proposed, a novel framework designed to improve TKG reasoning. The REFD framework consists of two primary components: a recurrent encoder and a fusion decoder. The recurrent encoder incorporates three key modules: (1) the full-domain multi-scale temporal recurrent encoder, which effectively captures temporal dependencies across varying time scales, (2) the entity-relation symbiotic temporal feature deep fusion engine, which integrates temporal features of both entities and relations, and (3) the intelligent temporal feature priority dynamic adjustment mechanism, which adaptively adjusts the importance of different features over time. The fusion decoder, particularly the entity-relation feature Fusion Decoder, combines the temporal features of entities and relations to model their joint evolution, overcoming the limitations of previous methods that model them separately. By jointly capturing the evolving dynamics of entities and relations over time, REFD significantly enhances the accuracy of temporal reasoning tasks. Experimental results show that REFD outperforms existing approaches, offering superior prediction accuracy and better handling of the complexities in TKGs.},
  archive      = {J_APIN},
  author       = {Liu, Qian and Feng, Siling and Huang, MengXing and Bhatti, Uzair Aslam},
  doi          = {10.1007/s10489-025-06445-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {REFD: Recurrent encoder and fusion decoder for temporal knowledge graph reasoning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mastering table tennis with hierarchy: A reinforcement learning approach with progressive self-play training. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06450-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical Reinforcement Learning (HRL) is widely applied in various complex task scenarios. In complex tasks where simple model-free reinforcement learning struggles, hierarchical design allows for more efficient utilization of interactive data, significantly reducing training costs and improving training success rates. This study delves into the use of HRL based on the model-free policy layer to learn complex strategies for a robotic arm playing table tennis. Through processes such as pre-training, self-play training, and self-play training with top-level winning strategies, the robustness of the lower-level hitting strategies has been enhanced. Furthermore, a novel decay reward mechanism has been employed in the training of the higher-level agent to improve the win rate in adversarial matches against other methods. After pre-training and adversarial training, we achieved an average of 52 rally cycles for the forehand strategy and 48 rally cycles for the backhand strategy in testing. The high-level strategy training based on the decay reward mechanism resulted in an advantageous score when competing against other strategies.},
  archive      = {J_APIN},
  author       = {Ma, Hongxu and Fan, Jianyin and Xu, Haoran and Wang, Qiang},
  doi          = {10.1007/s10489-025-06450-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Mastering table tennis with hierarchy: A reinforcement learning approach with progressive self-play training},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new deep learning-based approach for predicting the geothermal heat pump’s thermal power of a real bioclimatic house. <em>APIN</em>, <em>55</em>(6), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06457-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, growing concern about climate change and the need to reduce greenhouse gas emissions have highlighted the role of energy efficiency and sustainability on the global agenda. Energy policies are decisive in establishing regulatory frameworks and incentives to address these challenges, leading to an inclusive and more resilient energy transition. In this context, geothermal energy is an essential source of renewable, low-emission energy, capable of providing heat and electricity sustainably. The present research focuses on a bioclimatic house’s geothermal energy system based on a heating pump and a horizontal heat exchanger. The main aim is to predict the generated thermal power of the heat pump using historical data from several sensors. In particular, two approaches were proposed with both uni-variate and multi-variate scenarios. Several deep learning techniques were applied: LSTM, GRU, 1D-CNN, CNN-LSTM, and CNN-GRU, obtaining satisfactory results over the whole dataset, which comprised one year of data acquisition. Specifically, promising results have been achieved using hybrid methods combining recurrent-based and convolutional neural networks.},
  archive      = {J_APIN},
  author       = {Zayas-Gato, Francisco and Díaz-Longueira, Antonio and Arcano-Bea, Paula and Michelena, Álvaro and Calvo-Rolle, Jose Luis and Jove, Esteban},
  doi          = {10.1007/s10489-025-06457-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {A new deep learning-based approach for predicting the geothermal heat pump’s thermal power of a real bioclimatic house},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An approach to software defect prediction for small-sized datasets. <em>APIN</em>, <em>55</em>(6), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06458-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software defect prediction (SDP) is an active research subject in the software engineering domain. The earlier works on SDP use the same project’s data for prediction in future releases, called within-project defect prediction (WPDP). WPDP may not perform well when the data available for training is small in size. In this work, to address the issue of small-size data, we suggest enhancing the data by borrowing data from other software projects. For better prediction accuracy of learning models, both train and test data must follow the same distribution. However, this may not be true in the case of data being transferred from the other project. Data from different projects may follow different distributions. So, to handle this issue, we have proposed a data preprocessing method, namely data transfer-based WPDP (DT-WPDP). Next, we have shown the use of the deep neural network (DNN) for WPDP and compared it with other classical machine learning (ML) models such as k nearest neighbor, decision tree, logistic regression, and Naive Bayes classifiers. Further, we have performed experimental analysis to assess the effect of the proposed DT-WPDP data preprocessing method with DNN and other ML models. Experimental results show that the proposed approach significantly improves the accuracies of different models. Among different models, the DNN model performed best for all datasets. In the case of very small-sized datasets, which is our main concern in this work, the accuracy of the DNN model is improved by 7% after using the proposed approach.},
  archive      = {J_APIN},
  author       = {Bal, Pravas Ranjan and Shukla, Suyash and Kumar, Sandeep},
  doi          = {10.1007/s10489-025-06458-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {An approach to software defect prediction for small-sized datasets},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TableGPT: A novel table understanding method based on table recognition and large language model collaborative enhancement. <em>APIN</em>, <em>55</em>(5), 1-25. (<a href='https://doi.org/10.1007/s10489-024-05937-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today's information age, table images play a crucial role in storing structured information, making table image recognition technology an essential component in many fields. However, accurately recognizing the structure and text content of various complex table images has remained a challenge. Recently, large language models (LLMs) have demonstrated exceptional capabilities in various natural language processing tasks. Therefore, applying LLMs to the correction tasks of structure and text content after table image recognition presents a novel solution. This paper introduces a new method, TableGPT, which combines table recognition with LLMs and develops a specialized multimodal agent to enhance the effectiveness of table image recognition. Our approach is divided into four stages. In the first stage, TableGPT_agent initially evaluates whether the input is a table image and, upon confirmation, uses algorithms such as the transformer for preliminary recognition. In the second stage, the agent converts the recognition results into HTML format and autonomously assesses whether corrections are needed. If corrections are needed, the data are input into a trained LLM to achieve more accurate table recognition and optimization. In the third stage, the agent evaluates user satisfaction through feedback and applies superresolution algorithms to low-quality images, as this is often the main reason for user dissatisfaction. Finally, the agent inputs both the enhanced and original images into the trained model, integrating the information to obtain the optimal table text representation. Our research shows that trained LLMs can effectively interpret table images, improving the Tree Edit Distance Similarity (TEDS) score by an average of 4% even when based on the best current table recognition methods, across both public and private datasets. They also demonstrate better performance in correcting structural and textual errors. We also explore the impact of image superresolution technology on low-quality table images. Combined with the LLMs, our TEDS score significantly increased by 54%, greatly enhancing the recognition performance. Finally, by leveraging agent technology, our multimodal model improved table recognition performance, with the TEDS score of TableGPT_agent surpassing that of GPT-4 by 34%.},
  archive      = {J_APIN},
  author       = {Ren, Yi and Yu, Chenglong and Li, Weibin and Li, Wei and Zhu, Zixuan and Zhang, TianYi and Qin, ChenHao and Ji, WenBo and Zhang, Jianjun},
  doi          = {10.1007/s10489-024-05937-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {TableGPT: A novel table understanding method based on table recognition and large language model collaborative enhancement},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LSTM-SVM-weibull modeling for decommissioning amount prediction of power batteries based on attention mechanism and ISPBO algorithm. <em>APIN</em>, <em>55</em>(5), 1-29. (<a href='https://doi.org/10.1007/s10489-024-05941-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Taking Shanghai as the research area, fully considering the randomness and timeliness of power battery recycling, a combined prediction model of Long Short-term Memory network—Support Vector Machine—Weibull (LSTM-SVM-Weibull) that integrates attention mechanism and hyperparameters optimized by improved student psychology based optimization (ISPBO) algorithm is proposed to predict the retired amount of power batteries, to further improve the prediction accuracy. In the first stage, the grey relational analysis (GRA) method is used to screen out the strong related influence factors of power battery installed amount. In the second stage, a two-stage predictive model of power battery installed amount based on LSTM network with attention mechanism (Attention-LSTM) and SVM optimized by ISPBO algorithm (ISPBO-SVM) is constructed. Firstly, the attention mechanism is fused in the hidden layer of the LSTM network to accurately predict the various indicators selected by GRA, reduce the impact of indicator value errors on the target value prediction, and highlight the contribution degree of the input sequence at different time prediction points; Then, the Lévy flight strategy is introduced and combined with the Metropolis criterion of the simulated annealing algorithm to accept inferior solutions, the ISPBO algorithm is designed to optimize the hyperparameters of SVM model, so as to predict the target value (power battery installed amount) on the basis of future indicator values by training the ISPBO-SVM target prediction layer. By collecting the historical data of power battery installed amount in Shanghai for simulation experiments, the comparison results show that the designed Attention-LSTM-ISPBO-SVM two-stage power battery installed amount prediction model is significantly better than other comparison models in terms of error and accuracy on different data sets, and it has high accuracy and generalization ability for the prediction of power battery retirement amount. In the third stage, based on the predictive model of power battery installed amount, the Weibull life distribution model is combined to predict the retired amount of power batteries in Shanghai. Through the goodness-of-fit test and evaluating the retirement amount prediction results of different models, it is proved that the predictive model for power battery retired amount based on Weibull life distribution has high stability and practical application value, which effectively reflects the overall change trend of the future power battery retirement amount in Shanghai, and can provide data reference for improving the recovery rate of waste batteries.},
  archive      = {J_APIN},
  author       = {Zhao, Mengna and Chen, Shiping},
  doi          = {10.1007/s10489-024-05941-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-29},
  shortjournal = {Appl. Intell.},
  title        = {LSTM-SVM-weibull modeling for decommissioning amount prediction of power batteries based on attention mechanism and ISPBO algorithm},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy constrained fairness estimation for decision trees. <em>APIN</em>, <em>55</em>(5), 1-27. (<a href='https://doi.org/10.1007/s10489-024-05953-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The protection of sensitive data becomes more vital, as data increases in value and potency. Furthermore, the pressure increases from regulators and society on model developers to make their Artificial Intelligence (AI) models non-discriminatory. To boot, there is a need for interpretable, transparent AI models for high-stakes tasks. In general, measuring the fairness of any AI model requires the sensitive attributes of the individuals in the dataset, thus raising privacy concerns. In this work, the trade-offs between fairness (in terms of Statistical Parity (SP)), privacy (quantified with a budget), and interpretability are further explored in the context of Decision Trees (DTs) as intrinsically interpretable models. We propose a novel method, dubbed Privacy-Aware Fairness Estimation of Rules (PAFER), that can estimate SP in a Differential Privacy (DP)-aware manner for DTs. Our method is the first to assess algorithmic fairness on a rule-level, providing insight into sources of discrimination for policy makers. DP, making use of a third-party legal entity that securely holds this sensitive data, guarantees privacy by adding noise to the sensitive data. We experimentally compare several DP mechanisms. We show that using the Laplacian mechanism, the method is able to estimate SP with low error while guaranteeing the privacy of the individuals in the dataset with high certainty. We further show experimentally and theoretically that the method performs better for those DTs that humans generally find easier to interpret.},
  archive      = {J_APIN},
  author       = {van der Steen, Florian and Vink, Fré and Kaya, Heysem},
  doi          = {10.1007/s10489-024-05953-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-27},
  shortjournal = {Appl. Intell.},
  title        = {Privacy constrained fairness estimation for decision trees},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised motion forecasting with local information interaction in autonomous driving. <em>APIN</em>, <em>55</em>(5), 1-13. (<a href='https://doi.org/10.1007/s10489-024-06030-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion forecasting presents significant challenges critical for ensuring the safety of autonomous driving systems. The accuracy of these forecasts relies heavily on factors such as map topology and the behaviors of vehicles and pedestrians. However, within vast datasets, certain features with unique properties, capable of enhancing representation generalization often remain hidden and overlooked. While self-supervised learning (SSL) has shown promise in uncovering such hidden features through pretext tasks, its application to motion forecasting remains underexplored. In this paper, we propose a novel self-supervised motion forecasting method that exploits the interaction of map topology and actors’ maneuvers within localized focal points to generate more informative and generalizable representations for forecasting task. Since intersections, characterized by intricate structures and frequent motion state changes among actors, serve as pivotal locations where the topology of the intersection map profoundly influences actors’ intentions to change course, we leverage this interplay by calculating map structure-based actors’ attributes, and actors’ maneuver-based map attributes. These attributes yield significant advantages for motion forecasting tasks. Experimentally, our proposed method outperforms the baseline on both the challenging large-scale Argoverse benchmark (Chang et al. 2019) and local test, which demonstrates the effectiveness of the fusion of cross-domain information in a local neighborhood.},
  archive      = {J_APIN},
  author       = {Lei, Xinyu and Liu, Longjun and Li, Haoteng and Zhang, Haonan},
  doi          = {10.1007/s10489-024-06030-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Self-supervised motion forecasting with local information interaction in autonomous driving},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autonomous navigation of UAV in complex environment: A deep reinforcement learning method based on temporal attention. <em>APIN</em>, <em>55</em>(5), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06036-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing demand for Unmanned Aerial Vehicles (UAVs) in both military and civil applications, the ability for UAVs to automatically avoid obstacles and navigate to specific destinations has been receiving growing attention. However, most current methods focus on environments where global information is available or both destination and obstacles are static, which are not suitable for dense, dynamic, complex real-time tasks. Therefore, we propose a novel autonomous navigation method based on Deep Reinforcement Learning (DRL), which is suitable for more complex environments. Based on the Soft Actor-Critic (SAC) algorithm, this method incorporates changes of the state space into network input with a temporal attention mechanism, which allows UAVs to adaptively extract key information from historical environments while maintaining sensitivity to the current environment. We establish a visualized two-dimensional navigation task environment and design different simulation tests to evaluate its the performance and generalization. Results show that compared to baselines, our algorithm can achieve higher average rewards and more stable convergence after training in a static multi-obstacle environment, and can demonstrate better performance in environments featuring multiple obstacles of varying numbers, sizes, and speeds, thereby achieving a balance between task completion efficiency and security.},
  archive      = {J_APIN},
  author       = {Liu, Shuyuan and Zou, Shufan and Chang, Xinghua and Liu, Huayong and Zhang, Laiping and Deng, Xiaogang},
  doi          = {10.1007/s10489-024-06036-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Autonomous navigation of UAV in complex environment: A deep reinforcement learning method based on temporal attention},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SSSA: Low data sentiment analysis using boosting semi-supervised approach and deep feature learning network. <em>APIN</em>, <em>55</em>(5), 1-13. (<a href='https://doi.org/10.1007/s10489-024-06071-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is the process of determining the expressive direction of the user reviews. Recently, sentiment analysis gets more attention. However, low data sentiment analysis receives less attention. The existing works try to augment the samples to consider this issue. In this study, we have utilized a semi-supervised approach to propose a new approach for low-data sentiment analysis. To do so, we have utilized pre-trained XLNet as a feature extractor network to initialize the feature vector for each tweet. Next, these initial representations are fed into the embedding update module to map features into the new space by optimizing the contrastive loss. Then, we utilized a semi-supervised boosting method to assign pseudo labels to unlabeled data. The iteration between the semi-supervised module and the embedding update module is done until convergence is happened. During these iterations, the embedding update module propagates the error-correcting signals to a semi-supervised module. To evaluate the proposed approach, we have applied it to the SemEval2017dataset (task 4), Sentiment 140, and IMDB Movie Reviews. We have designed many different experiment settings to validate the proposed approach’s different modules. On SemEval2017dataset (task 4), we have got 75.9% and 77.1% in AvgRec and $${F}_{1}^{PN}$$ respectively. Also, when only 10% of the training samples as labeled samples are used, we get the 71.8% and 73.6% in AvgRec and $${F}_{1}^{PN}$$ respectively. The results show that our approach significantly improves with respect to the comparable methods. Also, on IMDB Movie Reviews and Sentiment 140, the proposed approach demonstrates improved performance compared to comparable methods.},
  archive      = {J_APIN},
  author       = {Rashidi, Shima and Tanha, Jafar and Sharifi, Arash and Hosseinzadeh, Mehdi},
  doi          = {10.1007/s10489-024-06071-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {SSSA: Low data sentiment analysis using boosting semi-supervised approach and deep feature learning network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skeleton-based human action recognition using LSTM and depthwise separable convolutional neural network. <em>APIN</em>, <em>55</em>(5), 1-21. (<a href='https://doi.org/10.1007/s10489-024-06082-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of computer vision, the task of human action recognition (HAR) represents a challenge, due to the complexity of capturing nuanced human movements from video data. To address this issue, researchers have developed various algorithms. In this study, a novel two-stream architecture is developed that combines LSTM with a depthwise separable convolutional neural network (DSConV) and skeleton information, with the aim of enhancing the accuracy of HAR. The 3D coordinates of each joint in the skeleton are extracted using the Mediapipe library, and the 2D coordinates are obtained using MoveNet. The proposed method comprises two streams, called the temporal LSTM module and the joint-motion module, and was developed to overcome the limitations of prior two-stream RNN models, such as the vanishing gradient problem and the difficulty of effectively extracting temporal-spatial information. A performance evaluation on the benchmark datasets of JHMDB (73.31%), Florence-3D Action (97.67%), SBU Interaction (95.2%), and Penn Action (94.0%) showcases the effectiveness of the proposed model. A comparison with state-of-the-art methods demonstrates the superior performance of the approach on these datasets. This study contributes to advancing the field of HAR, with potential applications in surveillance and robotics.},
  archive      = {J_APIN},
  author       = {Le, Hoangcong and Lu, Cheng-Kai and Hsu, Chen-Chien and Huang, Shao-Kang},
  doi          = {10.1007/s10489-024-06082-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Skeleton-based human action recognition using LSTM and depthwise separable convolutional neural network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CaVIT: An integrated method for image style transfer using parallel CNN and vision transformer. <em>APIN</em>, <em>55</em>(5), 1-15. (<a href='https://doi.org/10.1007/s10489-024-06114-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on image style transfer, aiming to generate images with the desired style while preserving the underlying content structure. Existing models face challenges in accurately representing both content and style features. To address this, an integrated method for image style transfer is proposed, utilizing a parallel CNN and Vision Transformer (CaVIT). It combines a Convolutional Neural Network (CNN) with a Vision Transformer (VIT) to achieve enhanced performance. Our method utilizes VGG-19 with residual blocks to encode style features for enhanced refinement. Additionally, the PA-Trans Encoder Layer is introduced, inspired by the Transformer Encoder Layer, to efficiently encode content features while preserving the complete content structure. The fused features are then decoded into stylized images using a CNN decoder. Qualitative and quantitative evaluations demonstrate that our proposed method outperforms existing models, delivering high-quality results.},
  archive      = {J_APIN},
  author       = {Zhang, ZaiFang and Lu, ShunLu and Guo, Qing and Gao, Nan and Yang, YuXiao},
  doi          = {10.1007/s10489-024-06114-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {CaVIT: An integrated method for image style transfer using parallel CNN and vision transformer},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A meta-heuristic approach to estimate and explain classifier uncertainty. <em>APIN</em>, <em>55</em>(5), 1-20. (<a href='https://doi.org/10.1007/s10489-024-06127-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust is a crucial factor affecting the adoption of machine learning (ML) models. Qualitative studies have revealed that end-users, particularly in the medical domain, need models that can express their uncertainty in decision-making allowing users to know when to ignore the model’s recommendations. However, existing approaches for quantifying decision-making uncertainty are not model-agnostic, or they rely on complex mathematical derivations that are not easily understood by laypersons or end-users, making them less useful for explaining the model’s decision-making process. This work proposes a set of class-independent meta-heuristics that can characterise the complexity of an instance in terms of factors that are mutually relevant to both human and ML decision-making. The measures are integrated into a meta-learning framework that estimates the risk of misclassification. The proposed framework outperformed predicted probabilities and entropy-based methods of identifying instances at risk of being misclassified. Furthermore, the proposed approach resulted in uncertainty estimates that proves more independent of model accuracy and calibration than existing approaches. The proposed measures and framework demonstrate promise for improving model development for more complex instances and provides a new means of model abstention and explanation.},
  archive      = {J_APIN},
  author       = {Houston, Andrew and Cosma, Georgina},
  doi          = {10.1007/s10489-024-06127-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {A meta-heuristic approach to estimate and explain classifier uncertainty},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent gear shifting strategy of mining truck based on deep learning and real-time vehicle condition. <em>APIN</em>, <em>55</em>(5), 1-15. (<a href='https://doi.org/10.1007/s10489-024-06142-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The driving conditions in mining areas are complex, and developing a suitable automatic shifting strategy for mining trucks is crucial. However, the development of automatic shifting strategies faces challenges, as it relies on experience and historical experimental data, which are the highest commercial secrets of manufacturers. In recent years, some shifting strategies based on artificial intelligence technologies have been implemented. However, many people shift gears based on the current state of the vehicle, ignoring the influence of historical data. There is a potential risk of mis-shift when unexpected sensor data is received, and continuously shifting gears in a short period of time can increase the likelihood of transmission damage, affecting the driving experience. To this end, this study proposes a novel gear shifting prediction method based on a multi-parameter Bi-directional Long Short-Term Memory(Bi-LSTM) network operating over continuous time periods. Real-time vehicle state data is collected via the CAN bus and 9 parameters that are positively correlated with gear shifting are selected through R/S analysis. By inputting values of those 9 parameters within continuous time periods into the machine learning model, gear shifting prediction is conducted. The experimental results show that our model predicts gear shifting with 96.85% accuracy while its average time cost is around 3.86 ms, meeting the real-time processing requirement. The model balances prediction accuracy and time consumption, and it overcomes the impact of transient abnormal sensor data. Hence, it has the potential for wide application in predictive models based on data with temporal characteristics.},
  archive      = {J_APIN},
  author       = {Su, Qinghua and Xu, Xiaoyu and Wang, Liyong and Zhang, Dingge and Xie, Min and Zhang, Pengbo},
  doi          = {10.1007/s10489-024-06142-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Intelligent gear shifting strategy of mining truck based on deep learning and real-time vehicle condition},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MPBE: Multi-perspective boundary enhancement network for aspect sentiment triplet extraction. <em>APIN</em>, <em>55</em>(5), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06144-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect Sentiment Triple Extraction (ASTE) is an emerging task in sentiment analysis that aims to extract triplets consisting of aspect terms, opinion terms, and sentiment polarity from review texts. Previous span-based methods often struggle with accurately identifying the boundaries of aspect and opinion terms, especially when multiple word spans appear in a sentence. This limitation arises from their reliance on a single, simplistic approach to constructing contextual features. To address these challenges, we propose Multi-Perspective Boundary Enhancement Network (MPBE). The network captures rich contextual features by adopting a dual-encoder mechanism and constructs multiple channels to further enhance these features. Specifically, we introduce enhanced semantic and syntactic information in two channels, while the third channel transforms the features using discrete fourier transform. In addition, we design a dual-graph cross fusion module to fuse features from different channels for more efficient information interaction and integration. Finally, by statistically analyzing the length distribution of aspect and opinion terms, a candidate length-based decoding strategy is proposed to achieve more accurate decoding. In experiments, the proposed MPBE model achieved excellent results on four benchmark datasets (14Lap, 14Res, 15Res, 16Res), with F1 scores of 62.32%, 73.78%, 65.32%, and 73.36%, respectively, demonstrating the superiority of the method.},
  archive      = {J_APIN},
  author       = {Yang, Kun and Zong, Liansong and Tang, Mingwei and Zheng, Yanxi and Chen, Yujun and Zhao, Mingfeng and Jiang, Zhongyuan},
  doi          = {10.1007/s10489-024-06144-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {MPBE: Multi-perspective boundary enhancement network for aspect sentiment triplet extraction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From spatial to semantic: Attribute-aware fashion similarity learning via iterative positioning and attribute diverging. <em>APIN</em>, <em>55</em>(5), 1-15. (<a href='https://doi.org/10.1007/s10489-024-06173-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fashion image retrieval emphasizes accurately perceiving the fine-grained features to meet users’ precise needs. However, the existing global image-based retrieval methods encounter challenges such as imprecise positioning of attributes, difficulty in distinguishing visually similar but semantically different attribute values, and struggles in the learning of attribute features within specific regions and viewpoints. This paper proposes a two-stage hybrid framework called IPAD (Iterative Positioning and Attribute Diverging) for attribute-aware fashion similarity learning. In the initial stage, we present an iterative positioning strategy to precisely identify local attribute regions through an iterative attention mechanism with adaptive suppression. IPAD leverages the strengths of Convolutional Neural Networks and Vision Transformers. Subsequently, we design an attribute diverging strategy to optimize attribute value aggregation via online clustering using a momentum encoder, thereby enhancing model stability and representation. During inference, we further present a feature reasoning mechanism to refine retrieval results through subgraph similarity matrix generation and re-ranking to enhance accuracy and robustness. Extensive evaluations on three public datasets demonstrate IPAD’s superior performance over state-of-the-art methods in retrieval accuracy, achieving an average improvement in MAP by +4.22%. The source code is available at https://github.com/h8e9r7/IPAD .},
  archive      = {J_APIN},
  author       = {Wan, Yongquan and Zheng, Jianfei and Yan, Cairong and Zou, Guobing},
  doi          = {10.1007/s10489-024-06173-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {From spatial to semantic: Attribute-aware fashion similarity learning via iterative positioning and attribute diverging},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DGT: Depth-guided RGB-D occluded target detection with transformers. <em>APIN</em>, <em>55</em>(5), 1-15. (<a href='https://doi.org/10.1007/s10489-024-06192-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In occluded urban environments, the traditional object detection algorithm relies solely on RGB as input, making it challenging to discern the spatial relationship of occluded objects and consequently affecting the target detection accuracy. Previous studies primarily focused on fusing depth and RGB information at the feature level, resulting in the loss of detailed features from the original data, such as occlusion boundaries. This leads to blurred fusion features and degraded model detection performance. Therefore, this paper proposes a depth-guided RGB-D occluded target detection framework based on transformers (DGT) to effectively extract occlusion boundary information and guide the occlusion discrimination via data-level fusion of depth and RGB information. In particular, a multimodal data-level fusion model is proposed for a two-part task. One is to generate dense depth images with strengthened occlusion edge features by extracting the depth difference of object edges in the point cloud data. The other is to dilute the influence of useless information using RGB-D data-level fusion. A depth-guided occlusion layered detection network with transformers was designed to obtain the cross-module guided feature vector by exchanging the weights of the residual and interaction vectors. Extensive experiments showed that DGT achieves state-of-the-art performance in occluded environments.},
  archive      = {J_APIN},
  author       = {Xu, Kelei and Wang, Chunyan and Zhao, Wanzhong and Liu, Jinqiang},
  doi          = {10.1007/s10489-024-06192-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {DGT: Depth-guided RGB-D occluded target detection with transformers},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Counterfactual regret minimization for the safety verification of autonomous driving. <em>APIN</em>, <em>55</em>(5), 1-13. (<a href='https://doi.org/10.1007/s10489-024-06194-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rare safety-critical events remain a major challenge in autonomous vehicle testing. This paper proposes to use game theory to build a novel testing environment for autonomous vehicles. In this environment, a virtual agent based on counterfactual minimization (CFR) is used to accelerate testing and validate the safety performance of autonomous vehicles. The virtual agent updates the adversarial policies to be enforced by continuously accumulating regret values, thus increasing the probability of security-critical events occurring during the testing process. Finally, recognized metrics such as Time-to-Collision (TTC) and Minimum Safe Distance Factor (MSDF) are introduced to assess the quality of the scenario. Experimental results show that the virtual agent based on counterfactual minimization explicitly generates more safety-critical scenarios and accelerates the evaluation process by multiple orders of magnitude ( $$10^{3}$$ times faster).},
  archive      = {J_APIN},
  author       = {Wang, Yong and Sun, Pengchao and Zhang, Daifeng and Li, Yanqiang},
  doi          = {10.1007/s10489-024-06194-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Counterfactual regret minimization for the safety verification of autonomous driving},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized federated knowledge graph embedding with client-wise relation graph. <em>APIN</em>, <em>55</em>(5), 1-14. (<a href='https://doi.org/10.1007/s10489-024-06211-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Knowledge Graph Embedding (FKGE) has recently garnered considerable interest due to its capacity to extract expressive representations from distributed knowledge graphs, while concurrently safeguarding the privacy of individual clients. Existing FKGE methods typically harness the arithmetic mean of entity embeddings from all clients as the global supplementary knowledge, and learn a replica of global consensus entities embeddings for each client. However, these methods usually neglect the inherent semantic disparities among distinct clients. This oversight not only results in the globally shared complementary knowledge being inundated with too much noise when tailored to a specific client, but also instigates a discrepancy between local and global optimization objectives. Consequently, the quality of the learned embeddings is compromised. To address this, we propose Personalized Federated knowledge graph Embedding with client-wise relation Graph (PFedEG), a novel approach that employs a client-wise relation graph to learn personalized embeddings by discerning the semantic relevance of embeddings from other clients. Specifically, PFedEG learns personalized supplementary knowledge for each client by amalgamating entity embedding from its neighboring clients based on their “affinity” on the client-wise relation graph. Each client then conducts personalized embedding learning based on its local triples and personalized supplementary knowledge. We conduct extensive experiments on four benchmark datasets to evaluate our method against state-of-the-art models and results demonstrate the superiority of our method.},
  archive      = {J_APIN},
  author       = {Zhang, Xiaoxiong and Zeng, Zhiwei and Zhou, Xin and Niyato, Dusit and Shen, ZhiQi},
  doi          = {10.1007/s10489-024-06211-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Personalized federated knowledge graph embedding with client-wise relation graph},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FineDiffusion: Scaling up diffusion models for fine-grained image generation with 10,000 classes. <em>APIN</em>, <em>55</em>(5), 1-16. (<a href='https://doi.org/10.1007/s10489-024-06215-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class-conditional image generation based on diffusion models is renowned for generating high-quality and diverse images. However, most prior efforts focus on generating images for general categories, e.g., 1000 classes in ImageNet-1k. A more challenging task, large-scale fine-grained image generation, remains the boundary to explore. In this work, we present a parameter-efficient strategy, called FineDiffusion, to fine-tune large pre-trained diffusion models scaling to large-scale fine-grained image generation with 10,000 categories. FineDiffusion significantly accelerates training and reduces storage overhead by only fine-tuning tiered class embedder, bias terms, and normalization layers’ parameters. To further improve the image generation quality of fine-grained categories, we propose a novel sampling method for fine-grained image generation, which utilizes superclass-conditioned guidance, specifically tailored for fine-grained categories, to replace the conventional classifier-free guidance sampling. Compared to full fine-tuning, FineDiffusion achieves a remarkable 1.56 $$\times $$ training speed-up and requires storing merely 1.77% of the total model parameters, while achieving state-of-the-art FID of 9.776 on image generation of 10,000 classes. Extensive qualitative and quantitative experiments demonstrate the superiority of our method compared to other parameter-efficient fine-tuning methods. The code and more generated results are available at our project website: https://finediffusion.github.io/ .},
  archive      = {J_APIN},
  author       = {Pan, Ziying and Wang, Kun and Li, Gang and He, Feihong and Lai, Yongxuan},
  doi          = {10.1007/s10489-024-06215-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {FineDiffusion: Scaling up diffusion models for fine-grained image generation with 10,000 classes},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TSHDNet: Temporal-spatial heterogeneity decoupling network for multi-mode traffic flow prediction. <em>APIN</em>, <em>55</em>(5), 1-14. (<a href='https://doi.org/10.1007/s10489-024-06218-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the intricate spatial dependencies and dynamic trends among diverse road segments, the prediction of spatio-temporal traffic flow data presents a formidable challenge. To address this challenge within the complexity of urban multi-mode transportation systems, this paper introduces an innovative solution. Anchored by the TSHDNet framework, the proposed methodology presents a novel spatio-temporal heterogeneous decoupling network that adeptly captures the inherent relationships between traffic patterns and temporal-spatial fluctuations. By seamlessly integrating temporal and nodal embeddings, dynamic graph learning, and multi-scale representation modules, TSHDNet demonstrates remarkable efficacy in unraveling the subtle dynamics of traffic flow. Empirical evaluations and ablation experiments conducted on four real-world datasets affirm the framework’s capability and the effectiveness of the decoupling approach.The source codes are available at: https://github.com/MeiWu2/TSHDNet.git},
  archive      = {J_APIN},
  author       = {Wu, Mei and Weng, Wenchao and Wang, Xinran and Seng, Dewen},
  doi          = {10.1007/s10489-024-06218-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {TSHDNet: Temporal-spatial heterogeneity decoupling network for multi-mode traffic flow prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The relationship among some special concepts from the perspective of formal context restoration. <em>APIN</em>, <em>55</em>(5), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06227-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formal context restoration is a recently developing topic in the field of formal concept analysis (FCA). Its goal is to restore a formal context from some known formal concepts. Each type of formal concept uses its unique perspective to restore formal contexts or concept lattices. This paper investigates the relationship among five types of basic concepts: the object concepts, the attribute concepts, the join-irreducible concepts, the meet-irreducible concepts, and the formal concepts in concept reducts. This paper first studies the elementary relationship among the basic sets of formal concepts and presents these relationship in a Venn diagram. Then the relationship among the basic concept sets are explored from a restoration perspective, specifically including the relationship among basic concepts from the perspectives of formal context restoration and concept lattice restoration. These relationship are then used to study the transformation between the basic concept sets, and are summarised in a formal context and its concept lattice. Finally, a practical case is given to illustrate the relationship among the basic concept sets explored in this paper, including the elementary relationship, and the relationship from the perspectives of formal context restoration and concept lattice restoration.},
  archive      = {J_APIN},
  author       = {Zhao, Siyu and Qi, Jianjun and Wei, Ling and Wan, Qing},
  doi          = {10.1007/s10489-025-06227-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {The relationship among some special concepts from the perspective of formal context restoration},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on small-scale face detection methods in dense scenes. <em>APIN</em>, <em>55</em>(5), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06231-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face detection serves as the core foundation for applications such as face analysis, recognition and reconstruction. In dense scenarios, the target scale difference is significant, and the instance pixels are too small as well as the mutual occlusion is serious leading to inconspicuous feature representation. However, existing detection methods rely on convolutional and pooling layers for feature extraction, with insufficient deep feature extraction and limited inference capability, leading to inaccurate recognition and high leakage rate. Therefore, we propose a small-scale face detection model YOLO-SXS based on the extended Transformer structure, which makes full use of contextual information and feature fusion networks to significantly improve the detection performance for small-scale and occluded faces. Specifically, the fusion of Swin Transformer and Convolutional Neural Networks (CNN) for feature extraction enhances the network’s ability to perceive global features; the Space to Depth (SPD-Conv) mapping is used to improve the network’s feature extraction in low-resolution and small-target detection tasks; furthermore, by adding fine-grained features, YOLO-SXS can significantly improve its performance for small-scale and occluded face detection capability; in addition, by adding a fine-grained feature fusion layer, feature information is retained to the maximum extent, which effectively reduces the loss of target information. The performance evaluation was performed on WIDER FACE, SCUT-HEAD and FDDB datasets, and the experimental results show that our proposed method significantly improves the performance of recognizing small-sized faces and achieves high detection rate and low error rate.},
  archive      = {J_APIN},
  author       = {Cao, Yuan and Zhang, Bei and Wang, Changqing and Wang, Meng},
  doi          = {10.1007/s10489-025-06231-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Research on small-scale face detection methods in dense scenes},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DGMI: A diffusion-based generative adversarial framework for multivariate air quality imputation. <em>APIN</em>, <em>55</em>(5), 1-21. (<a href='https://doi.org/10.1007/s10489-025-06240-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process of monitoring spatiotemporal air quality data, data sample missingness is prevalent, thus rectifying missing values in spatiotemporal data holds paramount significance. In recent years, diffusion probability models have played a prominent role in image, video, and text generation, and have also begun to be applied in the field of spatiotemporal data imputation. However, such models face challenges in extracting fine-grained features for stable model operation and accurate modeling of data probability distributions. To address the aforementioned issues, we propose a Diffusion-based Generative adversarial framework for Multivariate air quality data Imputation, termed DGMI. Recognizing the similar temporal, sensor, and indicator change characteristics inherent in air quality data, our framework is designed to cater to the spatiotemporal characteristics of air quality data by incorporating a multi-cycle temporal feature extraction module and a sensor indicator feature extraction module, facilitating multidimensional refinement and integration of temporal, sensor, and indicator information. Moreover, the initial missing value is encoded with linear interpolation and sine-cosine functions. Following the generation of imputed values by the model, we introduce a discriminator module to discern the consistency between imputed values and observed values to provide feedback for optimizing the model from a data distribution perspective. DGMI outperforms most current data imputation methods under various missing ratios in two real air quality datasets by 4.1% (root mean square error) and 3.0% (mean absolute error), exhibiting efficacy in scenarios characterized by multidimensional spatiotemporal and high missing rates data.},
  archive      = {J_APIN},
  author       = {Cheng, Nuo and Ni, Qingjian},
  doi          = {10.1007/s10489-025-06240-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {DGMI: A diffusion-based generative adversarial framework for multivariate air quality imputation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced interpretation of novel datasets by summarizing clustering results using deep-learning based linguistic models. <em>APIN</em>, <em>55</em>(5), 1-23. (<a href='https://doi.org/10.1007/s10489-025-06250-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s technology-driven era, the proliferation of data is inevitable across various domains. Within engineering, sciences, and business domains, particularly in the context of big data, it can extract actionable insights that can revolutionize the field. Amid data management and analysis, patterns or groups of interconnected data points, commonly referred to as clusters, frequently emerge. These clusters represent distinct subsets containing closely related data points, showcasing unique characteristics compared to other clusters within the same dataset. Spanning across disciplines such as physics, biology, business, and sales, clustering is important in understanding these novel datasets’ essential characteristics, developing complex statistical models, and testing various hypotheses. However, interpreting the characteristics and physical implications of generated clusters by different clustering algorithms is challenging for researchers unfamiliar with these algorithms’ inner workings. This research addresses the intricacies of comprehending data clustering, cluster attributes, and evaluation metrics, especially for individuals lacking proficiency in clustering or related disciplines like statistics. The primary objective of this study is to simplify cluster analysis by furnishing users or analysts from diverse domains with succinct linguistic synopses of clustering results, circumventing the necessity for intricate numerical or mathematical terms. Deep learning techniques based on large language models, such as encoder-decoders (for example, the T5 model) and generative pre-trained transformers (GPTs), are employed to achieve this. This study aims to construct a summarization model capable of ingesting data clusters, producing a condensed overview of the contained insights in a simplified, easily understandable linguistic format. The evaluation process revealed a clear preference among evaluators for the summaries generated by GPT, with T5 summaries following closely behind. GPT and T5 summaries were good at fluency, demonstrating their ability to capture the original content in a human-like manner. In contrast, while providing a structured framework for summarization, the linguistic protoform-based approach is needed to match the quality and coherence of the GPT and T5 summaries.},
  archive      = {J_APIN},
  author       = {K, Natarajan and Verma, Srikar and Kumar, Dheeraj},
  doi          = {10.1007/s10489-025-06250-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Enhanced interpretation of novel datasets by summarizing clustering results using deep-learning based linguistic models},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing suicidal ideation detection through advanced feature selection and stacked deep learning models. <em>APIN</em>, <em>55</em>(5), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06256-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting suicidal ideation on communication platforms such as social media is critical for suicide prevention, as these platforms are frequently used for emotional expression and can reflect significant behavior changes. Many machine learning and deep learning techniques have been employed to address this issue, utilizing embedding methods such as Count Vector, Term Frequency-Inverse Document Frequency, Bidirectional Encoder Representations from Transformers, Multilingual Universal Sentence Encoder etc generate high-dimensional vectors. Directly inputting word embeddings into models can introduce noise and outliers, which may negatively impact predictive accuracy. Therefore, feature selection to optimize the dimensionality of word embedding vectors has emerged as a promising direction for future research. This study proposes a feature selection method called Propose Best Feature Selection, which combines Grey Wolf Optimization, Recursive Feature Elimination, and Stepwise Feature Selection. It uses a Voting Classifier to identify and filter the most significant features, reducing dimensionality. These optimized features are then fed into a stacked ensemble hybrid model, with Bi-Directional Gated Recurrent Unit with Attention and Convolutional Neural Network, acting like base and Extreme Gradient Boostis working like the meta-classifier, achieving an accuracy of 98% in Reddit and 97% in Twitter(X) dataset, outperforming similar methods in the field. This work is focused on textual data, and future efforts may expand to include multimodal analysis, incorporating image-based emotional cues. Scalability challenges for large datasets and real-time applications remain a key limitation.},
  archive      = {J_APIN},
  author       = {Shukla, Shiv Shankar Prasad and Singh, Maheshwari Prasad},
  doi          = {10.1007/s10489-025-06256-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing suicidal ideation detection through advanced feature selection and stacked deep learning models},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A learning artificial visual system and its application to orientation detection. <em>APIN</em>, <em>55</em>(5), 1-20. (<a href='https://doi.org/10.1007/s10489-024-05991-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a learning artificial visual system, the Learning Dendritic Model Artificial Visual System (DModel-AVS), for orientation detection inspired by biological visual mechanisms. The DModel-AVS consists of two layers: local orientation detection neurons layer and global orientation detection neurons layer. The local neurons detect local features of an image, utilizing dendrite model neurons. The global neurons are designed to implement global features of the image by summing the outputs of the local dendritic neurons. The backpropagation-based learning is performed only to the dendritic neurons. The effectiveness of the DModel-AVS is evaluated through several experiments comparing it with various convolutional neural network (CNN)-based orientation detection systems. Results show that the DModel-AVS is a more biologically plausible and effective solution to orientation detection, with higher accuracy, and lower learning costs. The proposed system has practical applications in various fields such as computer vision and robotics.},
  archive      = {J_APIN},
  author       = {Chen, Tianqi and Kobayashi, Yuki and Yan, Chenyang and Qiu, Zhiyu and Hua, Yuxiao and Todo, Yuki and Tang, Zheng},
  doi          = {10.1007/s10489-024-05991-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {A learning artificial visual system and its application to orientation detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STNeRF: Symmetric triplane neural radiance fields for novel view synthesis from single-view vehicle images. <em>APIN</em>, <em>55</em>(5), 1-15. (<a href='https://doi.org/10.1007/s10489-024-06005-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents STNeRF, a method for synthesizing novel views of vehicles from single-view 2D images without the need for 3D ground truth data, such as point clouds, depth maps, CAD models, etc., as prior knowledge. A significant challenge in this task arises from the characteristics of CNNs and the utilization of local features can lead to a flattened representation of the synthesized image when training and validation with images from a single viewpoint. Many current methodologies tend to overlook local features and rely on global features throughout the entire reconstruction process, potentially resulting in the loss of fine-grained details in the synthesized image. To tackle this issue, we introduce Symmetric Triplane Neural Radiance Fields (STNeRF). STNeRF employs a triplane feature extractor with spatially aware convolution to extend 2D image features into 3D. This decouples the appearance component, which includes local features, and the shape component, which consists of global features, and utilizes them to construct a neural radiance field. These neural priors are then employed for rendering novel views. Furthermore, STNeRF leverages the symmetric properties of vehicles to liberate the appearance component from reliance on the original viewpoint and to align it with the symmetry of the target space, thereby enhancing the neural radiance field network’s ability to represent the invisible regions. The qualitative and quantitative evaluations demonstrate that STNeRF outperforms existing solutions in terms of both geometry and appearance reconstruction. More supplementary materials and the implementation code are available for access at the following link: https://github.com/ll594282475/STNeRF .},
  archive      = {J_APIN},
  author       = {Liu, Zhao and Fu, Zhongliang and Li, Gang and Hu, Jie and Yang, Yang},
  doi          = {10.1007/s10489-024-06005-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {STNeRF: Symmetric triplane neural radiance fields for novel view synthesis from single-view vehicle images},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-way reductions of conflict analysis based on relation matrices and integration measures. <em>APIN</em>, <em>55</em>(5), 1-26. (<a href='https://doi.org/10.1007/s10489-024-06020-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conflicts serve as an important focus of uncertainty analysis, and their reductions facilitate the issue identification and conflict solving to become valuable but rare. At present, conflict analysis reductions mainly embrace relation matrices, and they never concern uncertainty measures with highly concentrated information. In this paper, three-way reductions of conflict analysis are transferred from relation matrices to integration measures, and corresponding heuristic reduction algorithms are constructed for information systems. At first, three-way membership degrees and three-way similarity degrees are proposed for conflict analysis, and their measurement boundedness, issue monotonicity, calculation algorithm, and transformation interrelationship are researched. Then, alliance, conflict, and neutrality reductions are proposed based on similarity degrees to acquire heuristic reduction algorithms, and they can be equivalently characterized by both membership degrees and relation matrices. Finally by table examples and data experiments, similarity degrees and relevant measurement properties are validated, and two groups of three-way reduction algorithms related to relation matrices and similarity degrees are comparatively analyzed; as a result, three-way reduction algorithms based on similarity degrees become novel and effective for conflict analysis. This study provides an in-depth insight into three-way reductions of conflict analysis from algebraic measurement.},
  archive      = {J_APIN},
  author       = {Chen, Jiang and Zhang, Xianyong},
  doi          = {10.1007/s10489-024-06020-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Three-way reductions of conflict analysis based on relation matrices and integration measures},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Symmetric perception and ordinal regression for detecting scoliosis natural image. <em>APIN</em>, <em>55</em>(5), 1-15. (<a href='https://doi.org/10.1007/s10489-024-05849-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scoliosis is one of the most common diseases in adolescents. Traditional screening methods for the scoliosis usually use radiographic examination, which requires certified experts with medical instruments and brings the radiation risk. Considering such requirement and inconvenience, we propose to use natural images of the human back for wide-range scoliosis screening, which is a challenging problem. In this paper, we notice that the human back has a certain degree of symmetry, and asymmetrical human backs are usually caused by spinal lesions. Besides, scoliosis severity levels have ordinal relationships. Taking inspiration from this, we propose a dual-path scoliosis detection network with two main modules: symmetric feature matching module (SFMM) and ordinal regression head (ORH). Specifically, we first adopt a backbone to extract features from both the input image and its horizontally flipped image. Then, we feed the two extracted features into the SFMM to capture symmetric relationships. Finally, we use the ORH to transform the ordinal regression problem into a series of binary classification sub-problems. Extensive experiments demonstrate that our approach outperforms state-of-the-art methods as well as human performance, which provides a promising and economic solution to wide-range scoliosis screening. In particular, our method achieves accuracies of 95.11% and 81.46% in estimation of general severity level and fine-grained severity level of the scoliosis, respectively.},
  archive      = {J_APIN},
  author       = {Zhu, Xiaojia and Chen, Rui and Guo, Xiaoqi and Shao, Zhiwen and Dai, Yuhu and Zhang, Ming and Lang, Chuandong},
  doi          = {10.1007/s10489-024-05849-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Symmetric perception and ordinal regression for detecting scoliosis natural image},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph reconstruction and attraction method for community detection. <em>APIN</em>, <em>55</em>(5), 1-17. (<a href='https://doi.org/10.1007/s10489-024-05858-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection as one of the hot issues in complex networks has attracted a large amount of attention in the past several decades. Although many methods perform well on this problem, they become incapable if the networks exhibit more complicated characteristics, e.g. strongly overlapping communities. This paper explores a graph reconstruction and attraction method (GRAM) for community detection. In GRAM, we extract network structure information of a graph by introducing a new passing probability matrix based on Markov Chains by which a new graph is further reconstructed, and modularity optimization is adopted on the reconstructed one instead of the original one for non-overlapping community detection. For identifying overlapping communities, we first initialize a cluster with a vital node as an origin of attraction, then the cluster is extended by graph attraction based on the passing probability. This procedure is repeated for the remaining nodes, and each isolated node if exists is finally classified into its most attractable cluster. Experiments on artificial and real-world datasets have shown the superiority of the proposed method for community detection particularly on the datasets with even more complex, sparse and ambiguous network structures.},
  archive      = {J_APIN},
  author       = {Wu, Xunlian and Teng, Da and Zhang, Han and Hu, Jingqi and Quan, Yining and Miao, Qiguang and Sun, Peng Gang},
  doi          = {10.1007/s10489-024-05858-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Graph reconstruction and attraction method for community detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fooling machine learning models: A novel out-of-distribution attack through generative adversarial networks. <em>APIN</em>, <em>55</em>(5), 1-18. (<a href='https://doi.org/10.1007/s10489-024-05974-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in machine learning (ML) have facilitated the deployment of ML models across various real-world applications. However, these ML models might suffer from various potential security threats. In this paper, we propose a novel out-of-distribution attack: Leveraging pre-trained generative adversarial networks (GANs), an adversary aims to fool an ML model and make the model misclassify a sample from GANs as a pre-specified target class. Our attack is based on the insight that ML models do not know when they do not know, and ML models can unexpectedly recognize a completely different sample (e.g. cartoon face) as a certain class (e.g. airplane) with high confidence. Specifically, we introduce a targeted attack framework through GANs for white-box and black-box scenarios. Our framework casts this problem as an optimization problem and a family of attack methods are developed. Extensive experimental results show that our methods can achieve competitive performance, even compared with several state-of-the-art adversarial example attacks. Furthermore, our methods can evade several widely-used and the latest defenses. We also elaborately analyze various factors that affect the attack performance. Our work will provide a supplementary test to comprehensively evaluate the robustness of ML systems.},
  archive      = {J_APIN},
  author       = {Hu, Hailong and Pang, Jun},
  doi          = {10.1007/s10489-024-05974-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Fooling machine learning models: A novel out-of-distribution attack through generative adversarial networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based neural marked spatio temporal point process model for analyzing football match events. <em>APIN</em>, <em>55</em>(5), 1-17. (<a href='https://doi.org/10.1007/s10489-024-05996-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive modeling plays a crucial role in machine learning, data analysis, and statistics. In sports, predictive modeling methods have emerged to provide insights and evaluate performances based on key performance metrics. However, most existing models tend to focus on predicting only partial aspects of an event, such as the outcome, action type, or location, while neglecting the temporal factors involved. To address this gap, this study introduces the Transformer-Based Neural Marked Spatio-Temporal Point Process (NMSTPP) model, specifically designed for football event data. The NMSTPP model predicts a comprehensive set of future event components, including inter-event time, zone, and action. Additionally, it features a dependent prediction layers architecture to enhance model performance. The Holistic Possession Utilization Score (HPUS) metric is also proposed to evaluate the effectiveness and efficiency of possession periods in football based on the NMSTPP model. With open-source football event data, the NMSTPP model successfully predicted the aforementioned three components of future events, with an improvement of up to 4% overall and 9% for individual components compared to baseline models. The HPUS demonstrated a 0.9 correlation with existing performance metrics, highlighting its utility in performance evaluation. The NMSTPP and HPUS were applied to the Premier League to demonstrate their practical feasibility.},
  archive      = {J_APIN},
  author       = {Yeung, Calvin and Sit, Tony and Fujii, Keisuke},
  doi          = {10.1007/s10489-024-05996-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Transformer-based neural marked spatio temporal point process model for analyzing football match events},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double-level discriminative domain adaptation network for cross-domain fault diagnosis. <em>APIN</em>, <em>55</em>(5), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06016-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately determining the health of critical components contributes to the efficient operation of industrial equipment and systems. Domain adaptation has emerged as a potent tool for cross-domain diagnosis, particularly in real-world scenarios that involve variations in the distributions of the utilized training and test data. However, the current domain adaptation methods are overly concerned with feature alignment while neglecting feature discriminability and the distinguishability of the intrinsic structure within the target domain. This results in the misclassification of target samples according to decision boundaries. In response to this issue, a double-level discriminative domain adaptation network (DL-DDAN) for cross-domain fault diagnosis is proposed. The DL-DDAN aligns domain-level features via adversarial training and designs a class-level discriminative module and a sample-level discriminative module. On the one hand, the class-level discriminative module not only achieves class-level alignment, but also promotes intra-class compactness and inter-class separation by pushing features belonging to the same class closer together and maintaining sufficient separation between the features of different classes. On the other hand, the sample-level discriminative module is applied to the target samples to mine their potential distinguishable information. The experimental results obtained on bearing and gearbox datasets, under various working conditions and measurement points, demonstrated the effectiveness and superiority of the DL-DDAN. The diagnosis framework of DL-DDAN, including Health classifier loss, Domain discriminator loss, Class-level discriminative loss, and Sample-level discriminative loss.},
  archive      = {J_APIN},
  author       = {Li, Yufeng and Xu, Xinghan and Hu, Lei and Sun, Kai and Han, Min},
  doi          = {10.1007/s10489-024-06016-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Double-level discriminative domain adaptation network for cross-domain fault diagnosis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BAM-SORT: Border-guided activated matching for online multi-object tracking. <em>APIN</em>, <em>55</em>(5), 1-22. (<a href='https://doi.org/10.1007/s10489-024-06037-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-object tracking aims at estimating object bounding boxes and identity IDs in videos. Most tracking methods combine a detector and a Kalman filter using the IoU distance as a similarity metric for association matching of the previous trajectories with the current detection box. These methods usually suffer from ID switches and fragmented trajectories in response to congested and frequently occluded scenarios. To solve this problem, in this study, a simple and effective association method is proposed. First, a bottom edge cost matrix is introduced for the utilization of depth information to improve the data association and increase the robustness in the case of occlusion. Second, an asymmetric trajectory classification mechanism is proposed to distinguish the false-postive trajectories, and an activated trajectory matching strategy is introduced to reduce the interference of noise and transient objects in tracking. Finally, the trajectory deletion strategy is improved by introducing the number of trajectory state switches to delete the trajectories caused by spurious high-scoring detection boxes in real time, as a result, the number of fragmented trajectories is also reduced. These innovations achieve excellent performance on various benchmarks, including MOT17, MOT20, and especially DanceTrack where interactions and occlusions are frequent and severe. The code and models are available at https://github.com/djdodsjsjx/BAM-SORT/ .},
  archive      = {J_APIN},
  author       = {Chao, Yuan and Zhu, Huaiyang and Lu, Hengyu},
  doi          = {10.1007/s10489-024-06037-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {BAM-SORT: Border-guided activated matching for online multi-object tracking},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybridization of differential evolution and particle swarm optimization with distributed acceleration constants to solve economic load dispatch problem. <em>APIN</em>, <em>55</em>(5), 1-13. (<a href='https://doi.org/10.1007/s10489-024-06051-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The economic load dispatch problem owns features like multimodality, non-convexity, and hence, the traditional programming models fail to offer a solution to it. We have shown our research interest in PSO to solve the problem due to the umpteen numbers of applications it supports along with their improved swarming intelligence. Our previous paper has been dealt with an improved form of PSO, wherein adaptive acceleration constants were exploited. The adaptive nature comes from the dynamic changing of the acceleration constants with regard to the particle’s position as well as the number of function assessments. In that algorithm, the particles were enabled to search in a systematic distributed environment and the algorithm was known as PSO with Distributed Acceleration Constant (PSODAC). This paper makes an extension of PSODAC through hybridizing it with the notion behind Differential Evolution (DE). The hybridization has been performed in a sequential manner. Hence, it achieves the name as Sequentially Hybridized DE and PSODAC (SH-DEPSODAC), irrespective of the fact that the PSODAC has been employed. A total of three test systems have been utilized to test and examine the superiority of PSODAC for exhibiting higher particle dynamics.},
  archive      = {J_APIN},
  author       = {Yadav, Naresh Kumar},
  doi          = {10.1007/s10489-024-06051-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Hybridization of differential evolution and particle swarm optimization with distributed acceleration constants to solve economic load dispatch problem},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-project defect prediction based on autoencoder with dynamic adversarial adaptation. <em>APIN</em>, <em>55</em>(5), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06087-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-project defect prediction enables a target software project with limited defect data to build a defect prediction model by leveraging abundant data in the source project. However, existing methods of cross-project defect prediction ignore the relative importance of global and local distributions in learning project-invariant feature spaces. This paper proposes a novel approach for cross-project defect prediction called Adan (autoencoder with dynamic adversarial adaptation) to dynamically adjust a project-invariant feature space by aligning global and local distributions simultaneously with adversarial learning. Specifically, the au-encoder was adopted to produce a latent space used as a project-invariant feature space for source and target artifacts. Global and local discriminators were used to adjust the latent space to ensure that representations of source and target artifacts in the project-invariant feature space have approximate global distribution and local distribution, respectively. The prediction model for the target artifacts was then trained using representations of the source artifacts in the project-invariant feature space. Experiments on four open-source projects with 12 pairs of tasks on cross-project defect prediction demonstrated that the proposed Adan approach outperformed state-of-the-art techniques, with an average improvement of 8.42% in terms of AUC.},
  archive      = {J_APIN},
  author       = {Zhang, Wen and Zhao, Jiangpeng and Qin, Guangjie and Wang, Song},
  doi          = {10.1007/s10489-024-06087-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Cross-project defect prediction based on autoencoder with dynamic adversarial adaptation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extended topic classification utilizing LDA and BERTopic: A call center case study on robot agents and human agents. <em>APIN</em>, <em>55</em>(5), 1-22. (<a href='https://doi.org/10.1007/s10489-024-06106-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are two ways to know why customers call the center: from the predetermined calling reason said by the customer to a Robot Agent (RA) before service with a Human Agent (HA) or directly from the customer’s conversation with an HA during the service. Obtaining tags by telling the call reason is easy, but customers can choose the wrong service operation at a non-negligible rate. So, this study used the data from 20,000 Turkish phone conversations with a HA at an inbound call center in the electronic products sector, which are handled for topic extraction with Latent Dirichlet Allocation (LDA) and Bidirectional Encoder Representations from Transformers Topic (BERTopic) topic modeling. First, the customer speeches converted to text received from the system were passed through cleaning and editing typos. Then, the models were created, and the topic extraction process was performed. LDA and BERTopic algorithms were evaluated by comparing the machine learning technology results of the call center with HA and RA. The topics covered were used for classification with Light Gradient Boosting Machine (LGBM) linear Support Vector Machines (SVM), Long Short Term Memory (LSTM), and Logistic Regression (LR). The classification and statistical test results showed that LDA is more successful than the guided BERTopic algorithm. In addition, LDA-based classification was also more successful than RA-based classification. Although LDA-based LSTM and LR algorithms were superior to others, the best performance according to accuracy score belongs to LDA-based LSTM.},
  archive      = {J_APIN},
  author       = {Kazanci, Nevra},
  doi          = {10.1007/s10489-024-06106-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Extended topic classification utilizing LDA and BERTopic: A call center case study on robot agents and human agents},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time optimal trajectory planning of robotic arm based on improved sand cat swarm optimization algorithm. <em>APIN</em>, <em>55</em>(5), 1-54. (<a href='https://doi.org/10.1007/s10489-024-06124-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to address the issue of automatic charging for electric vehicles, a hanging automatic charging system was proposed, with a particular focus on the time-optimal trajectory planning of the robotic arm within the system. Additionally, a multi-strategy improved Sand Cat Swarm Optimization Algorithm (YSCSO) was put forth as a potential solution. The 0805A six-axis manipulator was selected as the research object, and a kinematic model was constructed using the D-H parameter method. The 5-7-5 polynomial interpolation function was proposed and solved to construct the motion trajectory of the robotic arm joint. The cubic chaos-refraction inverse learning, introduced to initialize the population based on the sand cat swarm algorithm SCSO, balances the relationship between the elite pool weighted guided search behavior and the spiral Lévy flight predation behavior through the use of a dynamic nonlinear sensitivity range. Furthermore, the vigilance behavior mechanism of the sand cat was increased to improve the overall optimization performance of the algorithm. The proposed method was applied to 36 benchmark functions of global optimization, and the improvement strategy, convergence behavior, population diversity, exploration, and development of the algorithm were experimentally analyzed. The results demonstrated that the proposed method exhibited superior performance, with 80.86% of the test results significantly different from those of the comparison algorithm. Three constrained mechanical design optimization problems were employed to assess the algorithm’s practicality in engineering applications. Subsequently, the algorithm was applied to the optimal trajectory planning of a robotic arm, resulting in a significant reduction in the optimized joint motion time, a smooth and continuous kinematic curve devoid of abrupt changes, and a 42.72% reduction in motion time. These findings further substantiate the theoretical feasibility and superiority of the algorithm in addressing engineering challenges.},
  archive      = {J_APIN},
  author       = {Lu, Zhenkun and You, Zhichao and Xia, Binghan},
  doi          = {10.1007/s10489-024-06124-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-54},
  shortjournal = {Appl. Intell.},
  title        = {Time optimal trajectory planning of robotic arm based on improved sand cat swarm optimization algorithm},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A temporal-spatial encoder convolutional network model for multitasking prediction. <em>APIN</em>, <em>55</em>(5), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06145-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent neural networks (RNNs), as a specialized neural network architecture for processing time series data, are increasingly vital in predicting the remaining useful life (RUL) and tool wear. However, RNNs have inherent sequence dependency, which makes it difficult to effectively parallelize when processing input data, significantly reducing training efficiency. To address these limitations, this paper proposes a temporal-spatial encoder convolutional network (TSECN) for RUL and tool wear prediction. This model uses the temporal feature extraction (TFE) module is adopted to excavate temporal features parallelly and dynamically weigh the features of different timesteps to improve its feature representation capability. Meanwhile, the spatial feature extraction (SFE) module is employed to excavate both local and global spatial features, which are then fused by a new feature fusion layer to enhance its prediction accuracy. The feature compression module is utilized to reduce the computational complexity and mitigate over-fitting. Finally, the regression prediction module is used to realize an accurate prediction of the target variable. Based on the C-MAPSS and PHM2010 datasets, experiments were conducted to assess the performance of the TSECN model, which shows that the TSECN model surpasses the state-of-the-arts in both the RUL and wear prediction tasks in terms of prediction accuracy.},
  archive      = {J_APIN},
  author       = {Zhao, Chengying and Shi, Huaitao and Huang, Xianzhen and Zhang, Yongchao and He, Fengxia},
  doi          = {10.1007/s10489-024-06145-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {A temporal-spatial encoder convolutional network model for multitasking prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel adaptive predefined-time complete tracking control of nonlinear systems via ELM. <em>APIN</em>, <em>55</em>(5), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06153-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A predefined-time sliding mode adaptive control method (PDTSMAC)for nonlinear system is proposed in the presence of parameters unknown, external disturbances and arbitrary initial values. Firstly, the expected trajectory of the system is extended to the arrival process with characters of predefined-time convergence and the accurate tracking process of completely tracking the desired trajectory, the design principle of extended trajectory is given; Then, an extreme learning machine (ELM) with exponential convergence of external weights is designed to compensate the uncertainties of the system, and a sliding mode adaptive controller with predefined-time convergence is constructed based on a predefined-time convergent sliding mode surface. The stability of the closed-loop system is proved theoretically. The simulation results show that the control strategy can ensure that the construction robot in arbitrary initial state converges to the extended desired trajectory within the predefined-time, and realizes the complete and accurate tracking of the preset desired trajectory, and the trajectory tracking error is less than 0.008.},
  archive      = {J_APIN},
  author       = {Yin, Chun-Wu and Riaz, Saleem},
  doi          = {10.1007/s10489-024-06153-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Novel adaptive predefined-time complete tracking control of nonlinear systems via ELM},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: A framework to evaluate the barriers for adopting the internet of medical things using the extended generalized TODIM method under the hesitant fuzzy environment. <em>APIN</em>, <em>55</em>(5), 1. (<a href='https://doi.org/10.1007/s10489-024-06187-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Alattas, Khalid and Wu, Qun},
  doi          = {10.1007/s10489-024-06187-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Retraction note: A framework to evaluate the barriers for adopting the internet of medical things using the extended generalized TODIM method under the hesitant fuzzy environment},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STViT+: Improving self-supervised multi-camera depth estimation with spatial-temporal context and adversarial geometry regularization. <em>APIN</em>, <em>55</em>(5), 1-20. (<a href='https://doi.org/10.1007/s10489-024-06191-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-camera depth estimation has gained significant attention in autonomous driving due to its importance in perceiving complex environments. However, extending monocular self-supervised methods to multi-camera setups introduces unique challenges that existing techniques often fail to address. In this paper, we propose STViT+, a novel Transformer-based framework for self-supervised multi-camera depth estimation. Our key contributions include: 1) the Spatial-Temporal Transformer (STTrans), which integrates local spatial connectivity and global context to capture enriched spatial-temporal cross-view correlations, resulting in more accurate 3D geometry reconstruction; 2) the Spatial-Temporal Photometric Consistency Correction (STPCC) strategy that mitigates the impact of varying illumination, ensuring brightness consistency across frames during photometric loss calculation; 3) the Adversarial Geometry Regularization (AGR) module, which employs Generative Adversarial Networks to impose spatial constraints by using unpaired depth maps, enhancing performance under adverse conditions such as rain and nighttime driving. Extensive evaluations on large-scale autonomous driving datasets, including Nuscenes and DDAD, confirm that STViT+ sets a new benchmark for multi-camera depth estimation.},
  archive      = {J_APIN},
  author       = {Chen, Zhuo and Zhao, Haimei and Hao, Xiaoshuai and Yuan, Bo and Li, Xiu},
  doi          = {10.1007/s10489-024-06191-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {STViT+: Improving self-supervised multi-camera depth estimation with spatial-temporal context and adversarial geometry regularization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time trajectory prediction of a ping-pong ball using a GRU-TAE. <em>APIN</em>, <em>55</em>(5), 1-21. (<a href='https://doi.org/10.1007/s10489-024-06204-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Table tennis with collaborative robots has been a challenge in robotics for decades, due to its unique challenges, primarily requiring precise real-time ball trajectory predictions to enable responsive, accurate gameplay. Traditional physical models, while widely studied, struggle with factors like spin, limiting accuracy. With advancements in computational power, data-driven approaches as sequence-to-sequence (seq2seq) models as trajectory autoencoders (TAE) offer potential for improved long-term prediction. However, they are not fully optimized for time-series prediction. More advanced seq2seq models with recurrent layers are better suited and improve prediction accuracy, but remain underexplored for trajectory prediction. Additionally, recurrent layers integrated with TAE, as gated-recurrent unit TAE (GRU-TAE), have not been applied for real-world trajectories. This study introduces a novel GRU-TAE model designed for high-accuracy, low-latency trajectory predictions in table tennis. Our approach was evaluated on both real and simulated data, demonstrating that TAE-based architectures outperform traditional recurrent models (e.g., LSTM, GRU, RNN) by 44% in long-term prediction accuracy, achieving an average computation time of 8.2 ms. Additionally, GRU-TAE improves accuracy by 14% over traditional TAE models and by 41% compared to baseline model-based methods in predicting real ball trajectories. These results are important because they enhance robotic arm performance in returning balls to human players, allowing earlier positioning for ball return, and reducing late position adjustments. This work sets the foundation for integrating GRU-TAE with advanced model-based approaches, aiming toward real-world deployment in collaborative table tennis robots.},
  archive      = {J_APIN},
  author       = {Toussaint, Baptiste and Raison, Maxime},
  doi          = {10.1007/s10489-024-06204-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Real-time trajectory prediction of a ping-pong ball using a GRU-TAE},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A masked autoencoder network for spatiotemporal predictive learning. <em>APIN</em>, <em>55</em>(5), 1-12. (<a href='https://doi.org/10.1007/s10489-024-06214-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is about predictive learning, which is generating future frames given previous images. Suffering from the vanishing gradient problem, existing methods based on RNN and CNN can’t capture the long-term dependencies effectively. To overcome the above dilemma, we present MastNet a spatiotemporal framework for long-term predictive learning. In this paper, we design a Transformer-based encoder-decoder with hierarchical structure. As for the transformer block, we adopt the spatiotemporal window based self-attention to reduce computational complexity and the spatiotemporal shifted window partitioning approach. More importantly, we build a spatiotemporal autoencoder by the random clip mask strategy, which leads to better feature mining for temporal dependencies and spatial correlations. Furthermore, we insert an auxiliary prediction head, which can help our model generate higher-quality frames. Experimental results show that the proposed MastNet achieves the best results in accuracy and long-term prediction on two spatiotemporal datasets compared with the state-of-the-art models.},
  archive      = {J_APIN},
  author       = {Sun, Fengzhen and Jin, Weidong},
  doi          = {10.1007/s10489-024-06214-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {A masked autoencoder network for spatiotemporal predictive learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view prototype balance and temporary proxy constraint for exemplar-free class-incremental learning. <em>APIN</em>, <em>55</em>(5), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06233-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exemplar-free class-incremental learning recognizes both old and new classes without saving old class exemplars because of storage limitations and privacy constraints. To address the forgetting of knowledge caused by the absence of old training data, we present a novel method that consists of two modules, multi-view prototype balance and temporary proxy constraints, which are based on feature retention and representation optimization. Specifically, multi-view prototype balance first extends the prototypes to maintain the general state of the class and then balances these prototypes combining knowledge distillation and prototype compensation to ensure the stability and plasticity of the model. To alleviate the feature overlap, the proposed temporary proxy constraint sets the temporary proxies to lightly compress the feature distribution during each mini-batch of training. Extensive experiments on five datasets with different settings demonstrate the superiority of our method against the state-of-the-art exemplar-free class-incremental learning methods.},
  archive      = {J_APIN},
  author       = {Tian, Heng and Zhang, Qian and Wang, Zhe and Zhang, Yu and Xu, Xinlei and Fu, Zhiling},
  doi          = {10.1007/s10489-025-06233-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Multi-view prototype balance and temporary proxy constraint for exemplar-free class-incremental learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive prototype loss based discriminative feature network for few-shot learning. <em>APIN</em>, <em>55</em>(5), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06234-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metric-based few-shot image classification methods generally perform classification by comparing the distances between the query sample features and the prototypes of each class. These methods often focus on constructing prototype representations for each class or learning a metric, while neglecting the significance of the feature space itself. In this paper, we redirect the focus to feature space construction, with the goal of constructing a discriminative feature space for few-shot image classification tasks. To this end, we designed a contrastive prototype loss that incorporates the distribution of query samples with respect to class prototypes in the feature space, emphasizing intra-class compactness and inter-class separability, thereby guiding the model to learn a more discriminative feature space. Based on this loss, we propose a contrastive prototype loss based discriminative feature network (CPL-DFNet) to address few-shot image classification tasks. CPL-DFNet enhances sample utilization by fully leveraging the distance relationships between query samples and class prototypes in the feature space, creating more favorable conditions for few-shot image classification tasks and significantly improving classification performance. We conducted extensive experiments on both general and fine-grained few-shot image classification benchmark datasets to validate the effectiveness of the proposed CPL-DFNet method. The experimental results show that CPL-DFNet can effectively perform few-shot image classification tasks and outperforms many existing methods across various task scenarios, demonstrating significant performance advantages.},
  archive      = {J_APIN},
  author       = {Yan, Leilei and He, Feihong and Zheng, Xiaohan and Zhang, Li and Zhang, Yiqi and He, Jiangzhen and Du, Weidong and Wang, Yansong and Li, Fanzhang},
  doi          = {10.1007/s10489-025-06234-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Contrastive prototype loss based discriminative feature network for few-shot learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sine and cosine based learning rate for gradient descent method. <em>APIN</em>, <em>55</em>(5), 1-28. (<a href='https://doi.org/10.1007/s10489-025-06235-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning networks have been trained using first-order-based methods. These methods often converge more quickly when combined with an adaptive step size, but they tend to settle at suboptimal points, especially when learning occurs in a large output space. When first-order-based methods are used with a constant step size, they oscillate near the zero-gradient region, which leads to slow convergence. However, these issues are exacerbated under nonconvexity, which can significantly diminish the performance of first-order methods. In this work, we propose a novel Boltzmann Probability Weighted Sine with a Cosine distance-based Adaptive Gradient (BSCAGrad) method. The step size in this method is carefully designed to mitigate the issue of slow convergence. Furthermore, it facilitates escape from suboptimal points, enabling the optimization process to progress more efficiently toward local minima. This is achieved by combining a Boltzmann probability-weighted sine function and cosine distance to calculate the step size. The Boltzmann probability-weighted sine function acts when the gradient vanishes and the cooling parameter remains moderate, a condition typically observed near suboptimal points. Moreover, using the sine function on the exponential moving average of the weight parameters leverages geometric information from the data. The cosine distance prevents zero in the step size. Together, these components accelerate convergence, improve stability, and guide the algorithm toward a better optimal solution. A theoretical analysis of the convergence rate under both convexity and nonconvexity is provided to substantiate the findings. The experimental results from language modeling, object detection, machine translation, and image classification tasks on a real-world benchmark dataset, including CIFAR10, CIFAR100, PennTreeBank, PASCALVOC and WMT2014, demonstrate that the proposed step size outperforms traditional baseline methods.},
  archive      = {J_APIN},
  author       = {Verma, Krutika and Maiti, Abyayananda},
  doi          = {10.1007/s10489-025-06235-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-28},
  shortjournal = {Appl. Intell.},
  title        = {Sine and cosine based learning rate for gradient descent method},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive archive exploitation for gaussian estimation of distribution algorithm. <em>APIN</em>, <em>55</em>(5), 1-31. (<a href='https://doi.org/10.1007/s10489-025-06237-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Gaussian Estimation of Distribution Algorithm (GEDA) is a fundamental evolutionary algorithm widely applied to continuous optimization problems but often encounters premature convergence. While external archives have been introduced to mitigate this issue, they frequently misuse historical information, leading to suboptimal results. To address this, we propose an Adaptive Archive Exploitation for GEDA (AAE-GEDA). AAE-GEDA incorporates two key mechanisms: adaptive selection of archive quantities (ASAQ) and angle skewness-landscape (ASL) eigenvalue adaptation. ASAQ selectively utilizes a subset of solutions from the archive to improve the accuracy of covariance estimation, preventing the algorithm from being misled by outdated or irrelevant information. ASL dynamically adjusts the search range, ensuring a balanced trade-off between exploration and exploitation. Experimental results on the IEEE CEC2014 and CEC2017 test suites demonstrate that AAE-GEDA consistently outperforms state-of-the-art evolutionary algorithms.},
  archive      = {J_APIN},
  author       = {Zhao, Dongmin and Tian, Yi and Zeng, Lingshun and Liang, Chunquan},
  doi          = {10.1007/s10489-025-06237-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-31},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive archive exploitation for gaussian estimation of distribution algorithm},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A convex kullback-leibler divergence and critical-descriptor prototypes for semi-supervised few-shot learning. <em>APIN</em>, <em>55</em>(5), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06239-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning has achieved great success in recent years, thanks to its requirement of limited number of labeled data. However, most of the state-of-the-art techniques of few-shot learning employ transfer learning, which still requires massive labeled data to train. To simulate the human learning mechanism, a deep model of few-shot learning is proposed to learn from one, or a few examples. First of all in this paper, we analyze and note that the problem with representative semi-supervised few-shot learning methods is getting stuck in local optimization and prototype bias problems. To address these challenges, we propose a new semi-supervised few-shot learning method with Convex Kullback-Leibler and critical descriptor prototypes, hereafter referred to as CKL. Specifically, CKL optimizes joint probability density via KL divergence, subsequently deriving a strictly convex function to facilitate global optimization in semi-supervised clustering. In addition, by incorporating dictionary learning, the critical descriptor facilitates the extraction of more prototypical features, thereby capturing more distinct feature information and avoiding the problem of prototype bias caused by limited labeled samples. Intensive experiments have been conducted on three popular benchmark datasets, and the experimental results show that this method significantly improves the classification ability of few-shot learning and obtains the most advanced performance. In the future, we will explore additional methods that can be integrated with deep learning to further uncover essential features within samples.},
  archive      = {J_APIN},
  author       = {Liu, Yukun and Shi, Daming},
  doi          = {10.1007/s10489-025-06239-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {A convex kullback-leibler divergence and critical-descriptor prototypes for semi-supervised few-shot learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning portfolio model based on mixture of experts. <em>APIN</em>, <em>55</em>(5), 1-16. (<a href='https://doi.org/10.1007/s10489-025-06242-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of artificial intelligence, the portfolio management problem has received widespread attention. Portfolio models based on deep reinforcement learning enable intelligent investment decision-making. However, most models only consider modeling the temporal information of stocks, neglecting the correlation between stocks and the impact of overall market risk. Moreover, their trading strategies are often singular and fail to adapt to dynamic changes in the trading market. To address these issues, this paper proposes a Deep Reinforcement Learning Portfolio Model based on Mixture of Experts (MoEDRLPM). Firstly, a spatio-temporal adaptive embedding matrix is designed, temporal and spatial self-attention mechanisms are employed to extract the temporal information and correlations of stocks. Secondly, dynamically select the current optimal expert from the mixed expert pool through router. The expert makes decisions and aggregates to derive the portfolio weights. Next, market index data is utilized to model the current market risk and determine investment capital ratios. Finally, deep reinforcement learning is employed to optimize the portfolio strategy. This approach generates diverse trading strategies according to dynamic changes in the market environment. The proposed model is tested on the SSE50 and CSI300 datasets. Results show that the total returns of this model increase by 12% and 8%, respectively, while the Sharpe Ratios improve by 64% and 51%.},
  archive      = {J_APIN},
  author       = {Wei, Ziqiang and Chen, Deng and Zhang, Yanduo and Wen, Dawei and Nie, Xin and Xie, Liang},
  doi          = {10.1007/s10489-025-06242-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Deep reinforcement learning portfolio model based on mixture of experts},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiffGen: A data-driven framework for generating truncated differentials. <em>APIN</em>, <em>55</em>(5), 1-24. (<a href='https://doi.org/10.1007/s10489-025-06248-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential cryptanalysis involves searching for high-probability differential trails. Traditionally, this search requires the use of constraint solvers or dedicated algorithms. Data-driven methods that rely on machine learning are typically limited to constructing statistical distinguishers for specific ciphers. In this paper, we develop a data-driven approach to the differential search problem by introducing DiffGen, a fully data-driven truncated differential search framework. DiffGen employs a metaheuristic algorithm with an active S-box prediction machine learning model as its fitness function to identify potentially valid truncated differentials within a given range of active S-boxes. A second machine learning model then validates the identified truncated differentials. We demonstrate the effectiveness of the DiffGen framework on generalized Feistel ciphers as a case study. Our results show that DiffGen can effectively generate valid truncated differentials, particularly when using particle swarm optimization as a metaheuristic and a differential validation model based on a fully connected artificial neural network. We verified that 84% of the truncated differentials generated by DiffGen in this setting correspond to actual differential trails. Our findings highlight, for the first time, the feasibility of applying a data-driven approach to the differential search problem.},
  archive      = {J_APIN},
  author       = {Idris, Mohamed Fadl and Teh, Je Sen and Yusoff, Mohd Najwadi},
  doi          = {10.1007/s10489-025-06248-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {DiffGen: A data-driven framework for generating truncated differentials},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage graph attention networks and Q-learning based maintenance tasks scheduling. <em>APIN</em>, <em>55</em>(5), 1-20. (<a href='https://doi.org/10.1007/s10489-025-06249-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maintenance tasks scheduling optimization is important and challenging for improving the oil and gas exploitation efficiency. Traditionally, this problem is addressed using exact algorithms, metaheuristic algorithms or solvers. However, due to the large-scale nature of this problem, these trials often fail in practical use. To address this, a compositional message passing neural network (CMPNN) is introduced for graph embedding, and the messages of the whole graph are obtained by aggregating the messages of neighboring nodes, which is used as the input of the subsequent framework. Based on CMPNN, a framework combining two-stage Graph Attention Networks and Q-learning (TSGAT+Q-learning) is proposed in this paper. In the first stage, the agent embedding is completed, i.e., each service technician’s messages are represented by a constructed graph; In the second phase, each maintenance task selects an agent based on probability. In this way, the task assignment scheme is obtained, and finally Q-learning is used for further optimization. In addition, a key contribution is the proposal of a novel exponential reward, designed to speed up model training using REINFORCE in reinforcement learning. To validate the effectiveness of proposed method, scenarios with different scales are provided. In most cases, TSGAT+Q-learning outperforms CPLEX, OR-Tools and other learning-based algorithms. Moreover, the trained networks can also solve the problem with varying numbers of maintenance tasks, which implies that TSGAT+Q-learning has good generalization ability. Finally, the proposed method is also proved to be effective in solving on-site maintenance tasks scheduling problem with multiple constraints. A Two-stage Graph Attention Networks and Q-learning Framework Based Maintenance Tasks Scheduling},
  archive      = {J_APIN},
  author       = {Gao, Xiaoyong and Peng, Diao and Yang, Yixu and Huang, Fuyu and Yuan, Yu and Tan, Chaodong and Li, Feifei},
  doi          = {10.1007/s10489-025-06249-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Two-stage graph attention networks and Q-learning based maintenance tasks scheduling},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive pre-training and instruction tuning for cross-lingual aspect-based sentiment analysis. <em>APIN</em>, <em>55</em>(5), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06251-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Natural Language Processing (NLP), aspect-based sentiment analysis (ABSA) has always been one of the critical research areas. However, due to the lack of sufficient sentiment corpora in most languages, existing research mainly focuses on English texts, resulting in limited studies on multilingual ABSA tasks. In this paper, we propose a new pre-training strategy using contrastive learning to improve the performance of cross-lingual ABSA tasks, and we construct a semantic contrastive loss to align parallel sentence representations with the same semantics in different languages. Secondly, we introduce instruction prompt template tuning, which enables the language model to fully understand the task content and learn to generate the required targets through manually constructed instruction prompt templates. During the generation process, we create a more generic placeholder template-based structured output target to capture the relationship between aspect term and sentiment polarity, facilitating cross-lingual transfer. In addition, we have introduced a copy mechanism to improve task performance further. We conduct detailed experiments and ablation analyzes on eight languages to demonstrate the importance of each of our proposed components.},
  archive      = {J_APIN},
  author       = {Zhao, Wenwen and Yang, Zhisheng and Yu, Song and Zhu, Shiyu and Li, Li},
  doi          = {10.1007/s10489-025-06251-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Contrastive pre-training and instruction tuning for cross-lingual aspect-based sentiment analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Matrix-based incremental local feature selection with dynamic covering granularity. <em>APIN</em>, <em>55</em>(5), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06253-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multigranulation rough set is composed of a set of granularities, providing a theoretical framework for solving problems from a multigranulation perspective. Feature selection aims to find the minimal set of attributes that does not compromise the overall classification capability. It has significant applications in the field of information processing. However, in practical application environments, the granularities in information systems often evolve dynamically over time. To address this scenario, an incremental feature selection algorithm for data with changing granularities in local multigranulation neighborhood covering rough sets is proposed. Firstly, the method of local related family is introduced, relationships between matrix operations of local related sets and those of approximate sets are discussed, and feature selection is studied using matrix methods. Subsequently, two matrix-based incremental feature selection algorithms are proposed for the cases where granularity structures in the data are added or deleted due to feature changes. Experiments on six datasets from UCI are then conducted to evaluate the performance of the proposed algorithms. The experimental results demonstrate that the two proposed incremental feature selection algorithms are highly effective.},
  archive      = {J_APIN},
  author       = {Shi, Qi and Zhang, Yan-Lan},
  doi          = {10.1007/s10489-025-06253-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Matrix-based incremental local feature selection with dynamic covering granularity},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User similarity-based graph convolutional neural network for shilling attack detection. <em>APIN</em>, <em>55</em>(5), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06254-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative recommendation systems have been widely used in various fields, such as movies, music and e-commerce. However, due to the natural openness of its ratings, it is vulnerable to shilling attacks. Shilling attacks greatly affect the accuracy and trustworthiness of recommendation systems, so we urgently need effective methods to counter shilling attacks. Some detection methods have been proposed previously. However, they mostly use manual feature extraction-based methods. These methods require specialized statistical knowledge to summarize user-specific rating patterns in user rating databases, which is very difficult. Thus, we propose a method called User Similarity-based Graph convolutional neural network for Shilling Attack Detection (USGSAD). This method achieves the purpose of detecting shilling attacks without using manual features. First, our method calculates user similarity by jointing both correlation and deviation of user rating behaviors. Second, we build a user relationship graph based on user similarity matrix and use graph embedding method to obtain user low-dimensional embedding vectors. Finally, we design a User Similarity Graph Convolutional Network (USGCN) to assign weights to aggregate user embeddings and predict the attackers in the recommender system. Adequate experiments on Amazon and MovieLens datasets show that our proposed method outperforms the baseline methods in detection performance.},
  archive      = {J_APIN},
  author       = {Zhang, Yan and Hao, Qingbo and Zheng, Wenguang and Xiao, Yingyuan},
  doi          = {10.1007/s10489-025-06254-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {User similarity-based graph convolutional neural network for shilling attack detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep subspace clustering via latent representation learning. <em>APIN</em>, <em>55</em>(5), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06255-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep subspace clustering networks (DSC-Nets), which combine deep autoencoders and self-expressive modules, have garnered widespread attention due to their outstanding performance. Within these networks, the autoencoder captures the latent representations of data by reconstructing the input data, while the self-expressive layer learns an affinity matrix based on these latent representations. This matrix guides spectral clustering, ultimately completing the clustering task. However, the latent representations learned solely through self-reconstruction by the autoencoder lack discriminative power. The quality of these latent representations directly affects the performance of the affinity matrix, which inevitably limits the clustering performance. To address this issue, we propose learning dissimilar relationships between samples using a classification module, and similar relationships using the self-expressive module. We integrate the information from both modules to construct a graph based on learned similarities, which is then embedded into the autoencoder network. Furthermore, we introduce a pseudo-label supervision module to guide the learning of higher-level similarities in the latent representations, thus achieving more discriminative latent features. Additionally, to enhance the quality of the affinity matrix, we employ an entropy norm constraint to improve connectivity within the subspaces. Experimental results on four public datasets demonstrate that our method achieves superior performance compared to other popular subspace clustering approaches.},
  archive      = {J_APIN},
  author       = {Pei, Shenglei and Han, Qinghao and Hao, Zepu and Zhao, Hong},
  doi          = {10.1007/s10489-025-06255-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Deep subspace clustering via latent representation learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-aware recommendation based on hypergraph representation learning and transformer model optimization. <em>APIN</em>, <em>55</em>(5), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06257-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation algorithms based on knowledge graphs (KGs) have been a research focus and hotspot in the field of recommendation systems in recent years. This is mainly because the introduction of a KG can yield auxiliary information about the item of interest and achieve more accurate recommendation effects for users. However, such a model faces two major challenges in predictive tasks. First, these methods find it difficult to capture the interaction information between users and items from a global perspective. Second, in most cases, noisy data, which result from users mistakenly clicking on items they are not interested in, exist in KGs, and these noisy data have a negative impact on the resulting recommendation effect. To address these challenges, this paper proposes a knowledge-aware recommendation approach based on hypergraph representation learning and transformer model optimization (KHRT), which employs a hypergraph that can be used to directly model higher-order relations, thereby enriching the interaction information between users and items. Owing to the lack of global interaction information between users and items in local graphs, a global hypergraph is constructed within the given local graph. Conversely, nonglobal graphs contain redundant information; thus, a nonglobal hypergraph is constructed, enabling the capture of more comprehensive interaction information between users and items. Moreover, the multihead attention mechanism of the transformer model is used to enhance the cooperative relationships between user nodes and item nodes, and more valuable preference information is mined from noisy user interaction data, such as items that users are not interested in. The embeddings of user and item nodes are optimized to alleviate noise interference and achieve improved recommendation performance based on user preferences. Experiments conducted on three real recommendation datasets indicate that the proposed approach outperforms the state-of-the-art traditional recommendation methods and KG-based methods in almost all comparisons.},
  archive      = {J_APIN},
  author       = {Zuo, Yuqi and Zhang, Yunfeng and Zhang, Qiuyue and Zhang, Wenbo},
  doi          = {10.1007/s10489-025-06257-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Knowledge-aware recommendation based on hypergraph representation learning and transformer model optimization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discriminative identification of redundant features for multi-label feature selection. <em>APIN</em>, <em>55</em>(5), 1-17. (<a href='https://doi.org/10.1007/s10489-025-06258-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection is a hotspot in multi-label learning, aiming to tackle the curse of dimensionality. Recently, several embedded models based on sparsity regularization have emerged. Most of them focus on learning an optimal feature selection matrix by means of regression, in which the correlation of instances and labels is concerned. However, the redundancy between features and the discriminative structure of labels have not been involved in. To argue these issues, a novel approach named discriminative identification of redundant features for multi-label feature selection (DIRF) is explored. In the proposed model, a feature affinity graph is constructed to find potentially redundant features with the idea that high similarity between features implies redundancy. Meanwhile, discriminative label correlation is revealed in terms of both label similarity and dissimilarity. Two regularizers are thereby designed to penalize the weights of redundant features. The structural consistency between original labels and predicted labels is therefore maintained. Extensive experiments and analysis show that the proposed DIRF outperforms the state-of-the-art multi-label feature selection methods.},
  archive      = {J_APIN},
  author       = {Jia, Qingwei and Deng, Tingquan and Zhang, Ziang and Wang, Yan and Wang, Changzhong},
  doi          = {10.1007/s10489-025-06258-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Discriminative identification of redundant features for multi-label feature selection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An LSTM approach to predict emergency events using spatial features. <em>APIN</em>, <em>55</em>(5), 1-22. (<a href='https://doi.org/10.1007/s10489-025-06261-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the global population on the rise, the frequency and severity of emergency events like fires and traffic accidents are becoming more frequent and severe. Attending to these emergencies demands valuable and limited resources, such as professionals and vehicles, so it is important to efficiently allocate them to regions that are more likely to require their services. However, the fact that emergencies can be related to spatial and temporal contexts makes resource allocation a highly complex task requiring specialized tools and techniques to exploit these relationships efficiently. This paper proposes an emergency event prediction solution using spatial segmentation and Long Short-Term Memory (LSTM) neural networks to model associations in space and time domains. We used data from real emergency occurrences in Florianópolis, Brazil, collected over five and a half years. Clustering algorithms combined with the silhouette metric were used to segment the time series in four different city regions. A comparison with traditional forecasting techniques and machine learning models showed that the LSTM network is consistent in its predictions and outperforms other approaches. Compared with a state-of-the-art reference employing LSTM, our solution leads to a 17.8% reduction in mean absolute error. Two methodologies for multi-step lookahead prediction are also presented and compared, showing that reusing the output of LSTM to predict future time steps is better than a full model retraining. To assess the generalizability of the model and proposed methodology, we applied the entire pipeline to new data from a different city. Our results demonstrate that models tailored to specific cities significantly outperform those trained on generalized datasets, highlighting the importance of localized training data.},
  archive      = {J_APIN},
  author       = {Vieira Roque, Felipe and Fröhlich, Antônio Augusto and Grellert, Mateus},
  doi          = {10.1007/s10489-025-06261-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {An LSTM approach to predict emergency events using spatial features},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CrowdFPN: Crowd counting via scale-enhanced and location-aware feature pyramid network. <em>APIN</em>, <em>55</em>(5), 1-13. (<a href='https://doi.org/10.1007/s10489-025-06263-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd counting has emerged as a prevalent research direction within computer vision, focusing on estimating the number of pedestrians in images or videos. However, existing methods tend to ignore crowd location information and model efficiency, leading to reduced accuracy due to challenges such as multi-scale variations and intricate background interferences. To address these issues, we propose the scale-enhanced and location-aware feature pyramid network for crowd counting (CrowdFPN). First, it can fine-tune each feature layer to focus more on crowd objects within a specific scale through the Scale Enhancement Module. Then, feature information from different layers is effectively fused using the lightweight Adaptive Bi-directional Feature Pyramid Network. Recognizing the importance of crowd location information for accurate counting, we introduce the Location Awareness Module, which embeds crowd location data into the channel attention mechanism while mitigating the effects of complex background interference. Finally, extensive experiments on four popular crowd counting datasets demonstrate the effectiveness of the proposed model. The code is available at https://github.com/zf990312/CrowdFPN.},
  archive      = {J_APIN},
  author       = {Yu, Ying and Zhu, Feng and Qian, Jin and Fujita, Hamido and Yu, Jiamao and Zeng, Kangli and Chen, Enhong},
  doi          = {10.1007/s10489-025-06263-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {CrowdFPN: Crowd counting via scale-enhanced and location-aware feature pyramid network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic-spatial guided context propagation network for camouflaged object detection. <em>APIN</em>, <em>55</em>(5), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06264-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged object detection (COD) aims to detect objects that blend in with their surroundings and is a challenging task in computer vision. High-level semantic information and low-level spatial information play important roles in localizing camouflaged objects and reinforcing spatial cues. However, current COD methods directly connect high-level features with low-level features, ignoring the importance of the respective features. In this paper, we design a Semantic-spatial guided Context Propagation Network (SCPNet) to efficiently mine semantic and spatial features while enhancing their feature representations. Firstly, we design a twin positioning module (TPM) to explore semantic cues to accurately locate camouflaged objects. Afterward, we introduce a spatial awareness module (SAM) to mine spatial cues in shallow features deeply. Finally, we develop a context propagation module (CPM) to assign semantic and spatial cues to multi-level features and enhance their feature representations. Experimental results show that our SCPNet outperforms state-of-the-art methods on three challenging datasets. Codes will be made available at https://github.com/RJC0608/SCPNet .},
  archive      = {J_APIN},
  author       = {Ren, Junchao and Zhang, Qiao and Kang, Bingbing and Zhong, Yuxi and He, Min and Ge, Yanliang and Bi, Hongbo},
  doi          = {10.1007/s10489-025-06264-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Semantic-spatial guided context propagation network for camouflaged object detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic pruning rate adjustment for dynamic token reduction in vision transformer. <em>APIN</em>, <em>55</em>(5), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06265-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision Transformer (ViT) has demonstrated excellent accuracy in image recognition and has been actively studied in various fields. However, ViT requires a large matrix multiplication called Attention, which is computationally expensive. Since the computational cost of Self-Attention used in ViT increases quadratically with the number of tokens, research to reduce the computational cost by pruning the number of tokens has been active in recent years. To prune tokens, it is necessary to set the pruning rate, and in many studies, the pruning rate is set manually. However, it is difficult to manually determine the optimal pruning rate because the appropriate pruning rate varies from task to task. In this study, we propose a method to solve this problem. The proposed pruning rate adjustment adjusts the pruning rate so that the training loss is converged by Gradient-Aware Scaling (GAS). In addition, we propose Variable Proportional Attention (VPA) for Top-K, a general-purpose token pruning method, to mitigate the performance loss due to pruning. For the CIFAR-10 dataset, several competitive pruning methods improve recognition accuracy over manually setting the pruning rate; eTPS+Adjust on Hybrid ViT-S achieves 99.01% Accuracy with -31.68% FLOPs. Furthermore, Top-K+VPA outperforms token merging when the pruning rate is large for trained ViT-L inference on ImageNet-1k and has superior scalability in the Accuracy-Latency relation. In particular, when Top-K+VPA is applied to ViT-L on a GPU environment with a pruning rate of 6%, it achieves 80.62% Accuracy on the ImageNet-1k dataset with -50.44% FLOPs and -46.8% Latency.},
  archive      = {J_APIN},
  author       = {Ishibashi, Ryuto and Meng, Lin},
  doi          = {10.1007/s10489-025-06265-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Automatic pruning rate adjustment for dynamic token reduction in vision transformer},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting PPI components using a hybrid hierarchical prediction framework with parameter adaptive transfer algorithm. <em>APIN</em>, <em>55</em>(5), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06275-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracy of economic forecasting directly influences the formulation of economic policies and profoundly impacts the stable operation of the economy. As a pivotal indicator of economic activity, predicting the producer price index (PPI) is crucial. Although most existing research is focused on the overall PPI, economic and financial institutions are increasingly interested in its partially disaggregated components. Therefore, this paper proposes a hybrid hierarchical deep network prediction framework called Attention-HRNN-GRU (AHG) with parameter adaptive transfer, which integrates algorithms such as the attention mechanism, the Hierarchical Recurrent Neural Network (HRNN) and the Gated Recurrent Unit (GRU). First, an independent GRU network is designed and trained separately for each PPI level to perform preliminary predictions. The internal parameters of each level’s network are preserved to facilitate interlevel information transfer, forming an initial HRNN framework. An attention mechanism is then introduced to adaptively adjust the parameters of the upper-level prediction model that are used as the prediction parameters for the lower-level model. This process enables effective information transfer across multiple levels, producing high-accuracy prediction outcomes. This method effectively addresses a common issue in traditional hierarchical data prediction, where the direct application of upper-level parameters to lower-level data often overlooks variations between sequences. Experimental results show that the proposed AHG model markedly reduces prediction errors compared with those of the current advanced HRNN model. For example, the root mean square error (RMSE) of the producing materials index improved by 13.11% over that of the advanced model.},
  archive      = {J_APIN},
  author       = {Zhu, Jiaming and Dai, Wan and Wu, Jie and Zhang, Xiang and Chen, Huayou},
  doi          = {10.1007/s10489-025-06275-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Forecasting PPI components using a hybrid hierarchical prediction framework with parameter adaptive transfer algorithm},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The synchronisation control of fractional 4-D quantum game chaotic map with its application in image encryption. <em>APIN</em>, <em>55</em>(5), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06281-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to reflect the nonlinear dynamics of quantum game map more precisely and improve the performance of current cryptosystem, in this paper, we first obtain the fractional four-dimensional quantum game chaotic map according to the fractional calculus. We then proceed to obtain the trajectory, the maximum Lyapunov index, the bifurcation diagram of the aforementioned map, and compare its dynamical behaviours with those of the four-dimensional quantum game chaotic map. Subsequently, we design a synchronisation control system for the proposed fractional system and apply the two systems to the field of information security. Finally, we undertake a comprehensive analysis of the encryption system, examining it from five distinct perspectives. As a result, the key space of proposed algorithm equals to $$6.7 \times 10^{165}$$ and the encrypted image’s information entropy is 7.9997. The NPCR and UACI for the difference attack analysis is $$99.61\%$$ and $$33.44\%$$ respectively accompanied with that the correlation coefficients is near to 0. The result indicates that the proposed algorithm can defense both known plaintext and chosen plaintext attacks which means that it is superior to other algorithms in most of the above aspects.},
  archive      = {J_APIN},
  author       = {Liu, Zeyu and Feng, Binshuai and Yao, Yuxin and Wang, Xujing},
  doi          = {10.1007/s10489-025-06281-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {The synchronisation control of fractional 4-D quantum game chaotic map with its application in image encryption},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel dropout approach for mitigating over-smoothing in graph neural networks. <em>APIN</em>, <em>55</em>(5), 1-14. (<a href='https://doi.org/10.1007/s10489-025-06285-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have emerged as a powerful tool for analyzing structured data represented as graphs. They offer significant contributions across various domains due to their ability to effectively capture and process complex relational information. However, most existing GNNs still suffer from undesirable phenomena such as non-robustness, overfitting, and over-smoothing. These challenges have raised significant interest among researchers. In this context, this work aims to address these issues by proposing a new vision of Dropout named A-DropEdge. First, it applies a message-passing layer to ensure the connection between nodes and avoid dropping in the input. Then, the information propagates through many branches with different random configurations to enhance the aggregation process. Moreover, consistency regularization is adopted to perform self-supervised learning. The experimental results on three graph data sets including Cora, Citeseer, and PubMed show the robustness and performance of the proposed approach in mitigating the over-smoothing problem.},
  archive      = {J_APIN},
  author       = {Hssayni, El houssaine and Boufssasse, Ali and Joudar, Nour-Eddine and Ettaouil, Mohamed},
  doi          = {10.1007/s10489-025-06285-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Novel dropout approach for mitigating over-smoothing in graph neural networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network adaptive terminal sliding mode trajectory tracking control for mechanical leg systems with uncertainty. <em>APIN</em>, <em>55</em>(5), 1-18. (<a href='https://doi.org/10.1007/s10489-025-06228-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an adaptive terminal sliding mode control based on neural block approximation for mechanical leg systems characterized by uncertainty and external disturbances. This control is based on a dynamic model of the mechanical leg and introduces an ideal system trajectory as a constraint. The structure of the paper is as follows. First, the RBF neural network is used to approximate the parameters of the dynamic model in blocks. This process is supplemented with a nonsingular terminal sliding mode surface to accelerate the convergence of tracking errors, and an adaptive law is used to adjust weights online to reconstruct the mechanical leg model. Next, an integral sliding mode control robust component is provided to mitigate external disturbances and correct model inaccuracies. Within this step, the Lyapunov method is used to prove the finite-time stability and uniform boundedness of the control system. Finally, the algorithm is validated and tested using the CAPACE rapid control system on a three-degree-of-freedom mechanical leg platform. The experimental results show that the proposed RBFTSM algorithm performs well in the performance evaluation of the MASE and RMSE values, with high trajectory tracking accuracy, anti-interference ability and strong robustness. Further evidence is presented to demonstrate the effectiveness and practicality of the proposed method.},
  archive      = {J_APIN},
  author       = {Chen, Minbo and Hu, Likun and Liao, Zifeng},
  doi          = {10.1007/s10489-025-06228-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Neural network adaptive terminal sliding mode trajectory tracking control for mechanical leg systems with uncertainty},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A knowledge graph completion model based on weighted fusion description information and transform of the dimension and the scale. <em>APIN</em>, <em>55</em>(5), 1-15. (<a href='https://doi.org/10.1007/s10489-025-06230-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing knowledge graph completion model represents entity and description information by uniform fusion. The convolutional kernel has fewer sliding steps on a triplet matrix composed of entities and relations and does not obtain different-scale characteristics for entities and relations. In this study, a knowledge graph completion model based on weighted fusion description information and the transformation of the dimension and scale, EDMSConvKE, is proposed. First, the entity description information is obtained using the SimCSE model of comparative learning and then combined with the entity according to a certain weight to obtain an entity vector with a stronger expression ability. Second, the head entity, relation, and tail entity vectors are combined into a three-column matrix, and a new matrix is generated using a dimensional transformation strategy to increase the number of sliding steps of the convolution kernel and enhance the information interaction ability of the entity and relation in more dimensions. Third, the multi-scale semantic features of the triples were extracted using convolution kernels of different sizes. Finally, the model in this study was evaluated using a link-prediction experiment, and the model was significantly improved in the Hits@10 and mean rank (MR) indices.},
  archive      = {J_APIN},
  author       = {Yin, Panfei and Zhao, Erping and BianBaDroMa and Ngodrup},
  doi          = {10.1007/s10489-025-06230-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {A knowledge graph completion model based on weighted fusion description information and transform of the dimension and the scale},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A non-parameter oversampling approach for imbalanced data classification based on hybrid natural neighbors. <em>APIN</em>, <em>55</em>(5), 1-27. (<a href='https://doi.org/10.1007/s10489-025-06236-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, researchers have developed numerous interpolation-based oversampling techniques to tackle class imbalance in classification tasks. However, most existing techniques encounter the challenge of k parameter due to the involvement of k nearest neighbor (kNN). Furthermore, they only adopt one sole neighborhood rule, disregarding the positional characteristics of minority samples. This often leads to the generation of synthetic noise or overlapping samples. This paper proposes a non-parameter oversampling framework called the hybrid natural neighbor synthetic minority oversampling technique (HNaNSMOTE). HNaNSMOTE effectively determines an appropriate k value through iterative search and adopts a hybrid neighborhood rule for each minority sample to generate more representative and diverse synthetic samples. Specifically, 1) a hybrid natural neighbor search procedure is conducted on the entire dataset to obtain a data-related k value, which eliminates the need for manually preset parameters. Different natural neighbors are formed for each sample to better identify the positional characteristics of minority samples during the procedure. 2) To improve the quality of the generated samples, the hybrid natural neighbor (HNaN) concept has been proposed. HNaN utilizes kNN and reverse kNN to find neighbors adaptively based on the distribution of minority samples. It is beneficial for mitigating the generation of synthetic noise or overlapping samples since it takes into account the existence of majority samples. Experimental results on 32 benchmark binary datasets with three classifiers demonstrate that HNaNSMOTE outperforms numerous state-of-the-art oversampling techniques for imbalanced classification in terms of Sensitivity and G-mean.},
  archive      = {J_APIN},
  author       = {Lin, Junyue and Liang, Lu},
  doi          = {10.1007/s10489-025-06236-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {5},
  pages        = {1-27},
  shortjournal = {Appl. Intell.},
  title        = {A non-parameter oversampling approach for imbalanced data classification based on hybrid natural neighbors},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selection for label distribution learning using dempster-shafer evidence theory. <em>APIN</em>, <em>55</em>(4), 1-22. (<a href='https://doi.org/10.1007/s10489-024-05879-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the contemporary epoch of massive data, the fuzziness of labels and the high dimensionality of feature space are prevalent characteristics of data. As a mathematical methodology for managing uncertainty, Dempster-Shafer evidence theory has found widespread applications in artificial intelligence, pattern recognition, and decision analysis. However, it has not garnered adequate attention in label distribution learning (LDL). This paper studies feature selection for LDL using Dempster-Shafer evidence theory. First, for a LDL data, distance maps in the feature space and in the label space are given, respectively. Furthermore, a tunable parameter to regulate the proximity level of features or labels is implemented. Then, the $$\alpha $$ -upper and $$\alpha $$ -lower approximations in the LDL data are put forward. Subsequently, to alleviate the influence of uncertainty on classification performance, robust feature evaluation measures for a LDL data, namely, “belief map" and “plausibility map" are defined, and they are based on the approximations. Next, feature selection algorithms utilizing belief and plausibility maps are specially designed. Finally, experimental results and statistical analyses demonstrate that the defined belief and plausibility maps can effectively measure the indeterminacy of LDL data, and the designed feature selection algorithms outperform five existing algorithms regarding classification performance.},
  archive      = {J_APIN},
  author       = {Zhao, Zhengwei and Wang, Rongrong and Pang, Wei and Li, Zhaowen},
  doi          = {10.1007/s10489-024-05879-z},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Feature selection for label distribution learning using dempster-shafer evidence theory},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved distance correlation estimation. <em>APIN</em>, <em>55</em>(4), 1-25. (<a href='https://doi.org/10.1007/s10489-024-05940-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance correlation is a novel class of multivariate dependence measure, taking positive values between 0 and 1, and applicable to random vectors of not necessarily equal arbitrary dimensions. It offers several advantages over the well-known Pearson correlation coefficient, the most important being that distance correlation equals zero if-and-only if- the random vectors are independent. There are two different estimators of the distance correlation available in the literature. The first estimator, proposed by Székely et al. (Ann Stat 35:2769–279 2007), is based on an asymptotically unbiased estimator of the distance covariance, which is a V-statistic. The second builds on an unbiased estimator of the distance covariance proposed in Székely and Rizzo (Stat 42:2382–2412 2014), shown to be a U-statistic by Huo and Székely (Technometrics 58:435–447 2016). This study evaluates their efficiency (mean squared error) and compares computational times for both methods under different dependence structures. Under conditions of independence or near-independence, the V-estimates are biased, while the U-estimator frequently cannot be computed due to negative values. To address this challenge, a convex linear combination of the former estimators is proposed and studied, yielding good results regardless of the level of dependence. Additionally, a medical database is studied and discussed.},
  archive      = {J_APIN},
  author       = {Monroy-Castillo, Blanca E. and Jácome, M. Amalia and Cao, Ricardo},
  doi          = {10.1007/s10489-024-05940-x},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {Improved distance correlation estimation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metaheuristics and strategic behavior of markovian retrial queue under breakdown, vacation and bernoulli feedback. <em>APIN</em>, <em>55</em>(4), 1-28. (<a href='https://doi.org/10.1007/s10489-024-05978-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research article addresses the performance analysis of Markovian retrial queueing system with two types of customers, unreliable server, and Bernoulli feedback. Both regular customers (RC) and prime customers (PC) may either join, or balk from the system based on the trade-off between service profit and delay cost. When the system is busy, the regular customers have to choose whether to join a retrial orbit and make re-attempts or leave the system. Furthermore, due to congestion among regular customers, the server may discontinue the service during breakdown. Due to the unavailability of the service process, customers may experience dissatisfaction. Therefore, our objective is to introduce a Bernoulli feedback service process to enhance service quality, ensuring that customers are successfully served with a certain probability. To analyze the proposed model mathematically, Chapman-Kolmogorov (C-K) inflow-outflow balanced equations have been framed. Then, the probability generating function (PGF) method employed to explicitly derive the queue size distribution, throughput, and other performance metrics. These performance measures provide critical insights into system behavior, which are then incorporated to determine the equilibrium strategies for two types of joining strategies: (i) non-cooperative strategies and (ii) cooperative strategies. Finally, optimization approaches are employed to determine the optimum cost and make tactical decisions regarding the quality of service (QoS) in an integrated manner. The cost optimization is done using metaheuristic optimization techniques such as PSO and GWO. The analytic results established are validated by numerical simulation. The effect of various parameters on the performance indices are examined by cost optimization and sensitivity analysis. The comparison of both algorithms, including average fitness, standard deviation, and convergence analysis, were used and combined with Wilcoxon rank-sum test.},
  archive      = {J_APIN},
  author       = {Dhibar, Sibasish and Jain, Madhu},
  doi          = {10.1007/s10489-024-05978-x},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-28},
  shortjournal = {Appl. Intell.},
  title        = {Metaheuristics and strategic behavior of markovian retrial queue under breakdown, vacation and bernoulli feedback},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image denoising via double-weighted correlated total variation regularization. <em>APIN</em>, <em>55</em>(4), 1-21. (<a href='https://doi.org/10.1007/s10489-024-06024-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image denoising is a widely concerned problem, which has been successfully applied in remote sensing, medicine and other fields. A typical idea of image denoising is to exploit some prior information existing in real-world data, such as low-rank prior and local smoothness prior. Some researchers devote themselves to combining both priors, however, the current methods cannot capture both properties simultaneously and adequately. Motivated by a new regularizer named three-dimensional correlated total variation (3DCTV) for robust principal component analysis problem, in this paper, we propose a new image denoising model via the double-weighted correlated total variation regularization. Specifically, we perform weighting operations on the 3DCTV regularization term and the sparse term separately, which can make fuller use of the low-rank prior, the local smoothness prior and the sparse prior of images. In addition, we add the Frobenius norm term to this model for modeling strong Gaussian noise in some real-world scenarios. Then, we develop an efficient algorithm to solve the resulting optimization problem by using the well-known alternating direction method of multipliers. Finally, we conduct extensive experiments on hyperspectral images, multispectral images and medical images under various noise situations, and the experimental results show that the proposed method outperforms the existing state-of-the-art denoising methods. Especially when the test image is polluted by low-intensity sparse noise, the MPSNR index of our method is about 5 points higher than that of the 3DCTV method.},
  archive      = {J_APIN},
  author       = {Zhang, Zhihao and Zhang, Peng and Liu, Xinling and Hou, Jingyao and Feng, Qingrong and Wang, Jianjun},
  doi          = {10.1007/s10489-024-06024-6},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Image denoising via double-weighted correlated total variation regularization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HSTforU: Anomaly detection in aerial and ground-based videos with hierarchical spatio-temporal transformer for U-net. <em>APIN</em>, <em>55</em>(4), 1-18. (<a href='https://doi.org/10.1007/s10489-024-06042-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is to identify abnormal events against normal ones within surveillance videos mainly collected in ground-based settings. Recently, the demand for processing drone-collected data is rapidly growing with the expanding range of drone applications. However, as most aerial videos collected by flying drones contain dynamic backgrounds and others, it is necessary to deal with their spatio-temporal features in detecting anomalies. This study presents a transformer-based video anomaly detection method whereby we investigate a challenging aerial dataset and three benchmark ground-based datasets. A multi-stage transformer is leveraged as an encoder to generate multi-scale feature maps, which are then conveyed to a hierarchical spatio-temporal transformer, that is linked to a decoder and used to capture spatial and temporal information by utilizing a joint attention mechanism. Extensive evaluations including several ablation studies suggest that this network outperforms the state-of-the-art methods. We expect the proposed transformer for U-net can find diverse applications in the video processing area. Code and pre-trained models are publicly available at https://github.com/vt-le/HSTforU .},
  archive      = {J_APIN},
  author       = {Le, Viet-Tuan and Jin, Hulin and Kim, Yong-Guk},
  doi          = {10.1007/s10489-024-06042-4},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {HSTforU: Anomaly detection in aerial and ground-based videos with hierarchical spatio-temporal transformer for U-net},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent mask image reconstruction for cardiac image segmentation through local–global fusion. <em>APIN</em>, <em>55</em>(4), 1-29. (<a href='https://doi.org/10.1007/s10489-024-06085-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of cardiac structures in magnetic resonance imaging (MRI) is essential for reliable diagnosis and management of cardiovascular disease. Although numerous robust models have been proposed, no single segmentation model consistently outperforms others across all cases, and models that excel on one dataset may not achieve similar accuracy on others or when the same dataset is expanded. This study introduces FCTransNet, an ensemble-based computer-aided diagnosis system that leverages the complementary strengths of Vision Transformer (ViT) models (specifically TransUNet, SwinUNet, and SegFormer) to address these challenges. To achieve this, we propose a novel pixel-level fusion technique, the Intelligent Weighted Summation Technique (IWST), which reconstructs the final segmentation mask by integrating the outputs of the ViT models and accounting for their diversity. First, a dedicated U-Net module isolates the region of interest (ROI) from cine MRI images, which is then processed by each ViT to generate preliminary segmentation masks. The IWST subsequently fuses these masks to produce a refined final segmentation. By using a local window around each pixel, IWST captures specific neighborhood details while incorporating global context to enhance segmentation accuracy. Experimental validation on the ACDC dataset shows that FCTransNet significantly outperforms individual ViTs and other deep learning-based methods, achieving a Dice Score (DSC) of 0.985 and a mean Intersection over Union (IoU) of 0.914 in the end-diastolic phase. In addition, FCTransNet maintains high accuracy in the end-systolic phase with a DSC of 0.989 and an IoU of 0.908. These results underscore FCTransNet’s ability to improve cardiac MRI segmentation accuracy.},
  archive      = {J_APIN},
  author       = {Boukhamla, Assia and Azizi, Nabiha and Belhaouari, Samir Brahim},
  doi          = {10.1007/s10489-024-06085-7},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-29},
  shortjournal = {Appl. Intell.},
  title        = {Intelligent mask image reconstruction for cardiac image segmentation through local–global fusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparative study on ballistic impact detection in helicopter transmission shafts using NARX and LSTM models. <em>APIN</em>, <em>55</em>(4), 1-27. (<a href='https://doi.org/10.1007/s10489-024-06118-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vibration-based techniques are vital for online structural health monitoring (SHM) of rotating machines, enabling fault detection through feature analysis and threshold establishment. Rotating shafts typically exhibit non-linear dynamic behaviour, often due to misalignment or manufacturing imperfections leading to eccentricity. This non-linear behaviour is amplified after ballistic impact, leading to significant asymmetries and increased vibration loads. In this study, we develop an advanced vibration-based method to address the gap in diagnostic tools used to identify ballistic impact damage in helicopter transmission shafts. The proposed scheme employs a non-linear autoregressive model with exogenous inputs (NARX), evaluated against a long short-term memory (LSTM) model, to estimate acceleration signals from a two-sensor cluster. It then uses the estimation error arising from significant variations in signals acquired before and after ballistic impact to assess the structural integrity of the operating structure. The efficiency of the models is validated using experimental data obtained during ballistics testing. The results show that the proposed method effectively detects various types of impact damage, offering a promising tool for ballistic impact diagnosis in helicopter transmission shafts.},
  archive      = {J_APIN},
  author       = {Panagiotopoulou, Vasiliki and Brancato, Lorenzo and Petriconi, Emanuele and Baldi, Andrea and Mariani, Ugo and Giglio, Marco and Sbarufatti, Claudio},
  doi          = {10.1007/s10489-024-06118-1},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-27},
  shortjournal = {Appl. Intell.},
  title        = {Comparative study on ballistic impact detection in helicopter transmission shafts using NARX and LSTM models},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Granular-ball-matrix-based incremental semi-supervised feature selection approach to high-dimensional variation using neighbourhood discernibility degree for ordered partially labelled dataset. <em>APIN</em>, <em>55</em>(4), 1-26. (<a href='https://doi.org/10.1007/s10489-024-06134-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In numerous real-world applications, data tends to be ordered and partially labelled, predominantly due to the constraints of labeling costs. The current methodologies for managing such data are inadequate, especially when confronted with the challenge of high-dimensional datasets, which often require reprocessing from the start, resulting in significant inefficiencies. To tackle this, we introduce an incremental semi-supervised feature selection algorithm that is grounded in neighborhood discernibility, and incorporates pseudolabel granular balls and matrix updating techniques. This novel approach evaluates the significance of features for both labelled and unlabelled data independently, using the power of neighborhood distinguishability to identify the most optimal subset of features. In a bid to enhance computational efficiency, especially with large datasets, we adopt a pseudolabel granular balls technique, which effectively segments the dataset into more manageable samples prior to feature selection. For high-dimensional data, we employ matrices to store neighborhood information, with distance functions and matrix structures that are tailored for both low and high-dimensional contexts. Furthermore, we present an innovative matrix updating method designed to accommodate fluctuations in the number of features. Our experimental results conducted across 12 datasets-including 4 with over 2000 features-demonstrate that our algorithm not only outperforms existing methods in handling large samples and high-dimensional datasets but also achieves an average time reduction of over six fold compared to similar semi-supervised algorithms. Moreover, we observe an average improvement in accuracy of 1.4%, 0.6%, and 0.2% per dataset for SVM, KNN, and Random Forest classifiers, respectively, when compared to the best-performing algorithm among the compared algorithms.},
  archive      = {J_APIN},
  author       = {Xu, Weihua and Li, Jinlong},
  doi          = {10.1007/s10489-024-06134-1},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Granular-ball-matrix-based incremental semi-supervised feature selection approach to high-dimensional variation using neighbourhood discernibility degree for ordered partially labelled dataset},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical loop closure detection with weighted local patch features and global descriptors. <em>APIN</em>, <em>55</em>(4), 1-14. (<a href='https://doi.org/10.1007/s10489-024-06135-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maintaining high-precision localization and ensuring map consistency are crucial objectives for mobile robots. However, loop closure detection remains a challenging aspect of their operation because of viewpoint and appearance changes. To address this issue, this paper proposes WP-VLAD, a novel hierarchical loop closure detection method that tightly couples global features and weighted local patch-level features (WPs). WP-VLAD employs MobileNetV3 as the backbone network for feature extraction, and integrates a trainable vector of local aggregated descriptors (VLAD) for compact global and local feature representation. A hierarchical navigable small world method is used to retrieve loop candidate frames based on the global features, whereas a multiscale feature fusion weighted map prediction module assigns weights to the local patches during mutual nearest neighbour matching. The proposed weight allocation strategy emphasizes salient regions, reducing interference from dynamic objects. The experimental results on benchmark datasets demonstrate that WP-VLAD significantly improves matching performance while maintaining efficient computation, exhibiting strong generalizability and robustness across various complex environments.},
  archive      = {J_APIN},
  author       = {Ren, Mingrong and Zhang, Xiurui and Liu, Bin and Zhu, Yuehui},
  doi          = {10.1007/s10489-024-06135-0},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Hierarchical loop closure detection with weighted local patch features and global descriptors},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Batch-mode active ordinal classification based on expected model output change and leadership tree. <em>APIN</em>, <em>55</em>(4), 1-22. (<a href='https://doi.org/10.1007/s10489-024-06152-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While numerous batch-mode active learning (BMAL) methods have been developed for nominal classification, the absence of a BMAL method tailored for ordinal classification is conspicuous. This paper focuses on proposing an effective BMAL method for ordinal classification and argues that a BMAL method should guarantee that the selected instances in each iteration are highly informative, diverse from labeled instances, and diverse from each other. We first introduce an expected model output change criterion based on the kernel extreme learning machine-based ordinal classification model and demonstrate that the criterion is a composite containing both informativeness assessment and diversity assessment. Selecting instances with high scores of this criterion can ensure that the selected are highly informative and diverse from labeled instances. To ensure that the selected instances are diverse from each other, we propose a leadership tree-based batch instance selection approach, drawing inspiration from density peak clustering algorithm. Thus, our BMAL method can select a batch of peak-scoring points from different high-scoring regions in each iteration. The effectiveness of the proposed method is empirically examined through comparisons with several state-of-the-art BMAL methods.},
  archive      = {J_APIN},
  author       = {He, Deniu and Taimoor, Naveed},
  doi          = {10.1007/s10489-024-06152-z},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Batch-mode active ordinal classification based on expected model output change and leadership tree},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing real-time and day-ahead load forecasting accuracy with deep learning and weighed ensemble approach. <em>APIN</em>, <em>55</em>(4), 1-23. (<a href='https://doi.org/10.1007/s10489-024-06155-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Economic dispatching of power system includes real-time dispatching and day-ahead dispatching. In this process, accurate real-time and day-ahead load forecasting is crucial. However, integrating real-time forecasting and day-ahead forecasting into one system, and ensuring that both have good performance, is a challenging problem. To solve the above problem, we propose a load forecasting system based on deep learning and weighted ensemble. The system is composed of the high precision prediction module and the intelligent weighted ensemble module. In the high precision prediction module, we use variational mode decomposition (VMD) to decompose the data into multiple components of different frequencies, and build a selection pool that includes statistical models and deep learning to select the best prediction model for each component through customed metrics. In the intelligent weighted ensemble module, we improve the Grey Wolf optimization algorithm with tent chaos mapping and flight strategy. The improved Grey Wolf optimization algorithm (ILGWO) is used to determine the weight of each component, then the weight is multiplied by the component prediction result, and the final prediction result is obtained by adding. To verify the superiority of the proposed forecasting system, we conducted experiments using four sets of load data from New South Wales, Australia. Through six groups of experiments and three groups of discussion, the accuracy, stability and applicability of the load forecasting system are verified. Compared with the traditional method, the prediction accuracy (MAPE) of the proposed load forecasting system is improved by about 55%. In addition, we further validated the generality of the system with four sets of load data from Queensland, Australia. The results show that the proposed load forecasting system is significantly superior to other models and provides more reliable load forecasting for power system management and scheduling.},
  archive      = {J_APIN},
  author       = {Li, Zeyu and Tian, Zhirui},
  doi          = {10.1007/s10489-024-06155-w},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing real-time and day-ahead load forecasting accuracy with deep learning and weighed ensemble approach},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic point-line SLAM based on lightweight object detection. <em>APIN</em>, <em>55</em>(4), 1-16. (<a href='https://doi.org/10.1007/s10489-024-06164-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous Localization and Mapping (SLAM) is currently a prominent research topic in robotics, playing a crucial role in the domains of localization and navigation within unfamiliar environments. Traditional SLAM algorithms typically assume static surroundings, yet dynamic elements in real-world environments significantly impact both localization accuracy and robustness, thereby limiting algorithm applicability. To address the challenge of degraded localization accuracy caused by dynamic objects in indoor settings, we propose a dynamic point-line SLAM algorithm based on ORB-SLAM2. To address the issue of insufficient feature points caused by the removal of dynamic points in ORB-SLAM2, we augment the point features with additional line features to introduce more constraints. Additionally, we propose a novel lightweight object detection algorithm called YOLOv5s-Lightweight(YOLOv5sL) based on YOLOv5s. Experimental results on the VOC dataset demonstrate that our model achieves better real-time performance while maintaining high accuracy compared to the original YOLOv5s. Furthermore, leveraging the RGB-D model of ORB-SLAM2, we present an adaptive epipolar constraint-based dynamic feature filtering algorithm. This algorithm effectively removes dynamic points and lines by utilizing prior information from object detection networks and incorporating depth information through a new tracking thread. As a result, it efficiently filters out dynamic feature points and significantly reduces the influence of dynamic objects. Finally, we validate the effectiveness of our improved algorithm using dynamic sequences from the TUM RGB-D dataset, showing notable reductions in Absolute Trajectory Error (ATE) and Relative Pose Error (RPE), thus confirming its efficacy.},
  archive      = {J_APIN},
  author       = {Zhong, Jiaqi and Qian, Huaming},
  doi          = {10.1007/s10489-024-06164-9},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Dynamic point-line SLAM based on lightweight object detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting the value of football players: Machine learning techniques and sensitivity analysis based on FIFA and real-world statistical datasets. <em>APIN</em>, <em>55</em>(4), 1-26. (<a href='https://doi.org/10.1007/s10489-024-06189-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study focuses on applying machine learning methodologies to football player data for predicting player market values in the dynamic football market. Player datasets are rich, encompassing performance metrics, physiological attributes, and contextual variables. Machine learning models, including both traditional and advanced methods, effectively extract insights from complex data to estimate player market values. Addressing challenges like overfitting and computational complexity involves applying regularization, feature engineering, and interpretability tools to manage high-dimensional data and improve predictive accuracy. In this study sensitivity of selected models (Support Vector Regression (SVR), Random Forest Regression (RFR), Extreme Gradient Boosting (XGB), and Categorical Boosting (CAT)) models to extracted data from FIFA 19 and Real-world Statistical Datasets evaluated by Shapley Additive Explanations (SHAP) and the 20 most relevant features selected in the ranking of SHAP for each regression model. Then, models optimized with two meta-heuristic algorithms demonstrated their performance in predicting the market values of players. Dempster-Shafer Theory (DST) was utilized to develop an ensemble of models to overcome overfitting problems, and Fourier amplitude sensitivity testing (FAST) gave insight for future data extractions. The analysis of market values for players revealed significant model performance variations. XGSC hybrid model demonstrated exceptional precision with a minimal error of 1.7 million dollars (10% of average measured value), followed by RSCX_SC with misestimations of 2 million dollars (13.3% of average measured value). Extracted results suggested that models, especially ensemble form, offer reliable accuracy for club managers and stakeholders, aiding in strategic player selection based on previous performance. This approach proves particularly beneficial for optimizing player salaries, especially when considering a prominent team with market values above average.},
  archive      = {J_APIN},
  author       = {Shen, Qijie},
  doi          = {10.1007/s10489-024-06189-0},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Predicting the value of football players: Machine learning techniques and sensitivity analysis based on FIFA and real-world statistical datasets},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DT4PEIS: Detection transformers for parasitic egg instance segmentation. <em>APIN</em>, <em>55</em>(4), 1-15. (<a href='https://doi.org/10.1007/s10489-024-06199-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parasitic infections pose a significant health risk in many regions worldwide, requiring rapid and reliable diagnostic methods to identify and treat affected individuals. Recent advancements in deep learning have significantly improved the accuracy and efficiency of microscopic image analysis workflows, enabling its application in various domains such as medical diagnostics and microbiology. This work presents DT4PEIS, a novel two-stage architecture for the instance segmentation of parasite eggs in microscopic images. The first stage is a DEtection TRansformer (DETR) based architecture, which predicts the bounding boxes and class labels of the detected eggs. Then, the predicted bounding boxes are used as prompts to guide the segmentation process in the second stage, which is based on the Segment Anything Model (SAM) architecture. We evaluate the performance of the proposed method on the Chula-ParasiteEgg-11 dataset. Our results show that the proposed method outperforms the other architectures in terms of segmentation mean Average Precision (mAP), providing a more detailed and accurate representation of the detected eggs.},
  archive      = {J_APIN},
  author       = {Ruiz-Santaquiteria, Jesus and Pedraza, Anibal and Deniz, Oscar and Bueno, Gloria},
  doi          = {10.1007/s10489-024-06199-y},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {DT4PEIS: Detection transformers for parasitic egg instance segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fault diagnosis method based on interpretable machine learning model and decision visualization for HVs. <em>APIN</em>, <em>55</em>(4), 1-18. (<a href='https://doi.org/10.1007/s10489-024-06219-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-speed and highly dynamic hypersonic vehicles demand exceptional safety and reliability during flight. Accurate detection and localization of faults in actuators and reaction control systems are pivotal for controlling and predicting operational states. However, this process encounters challenges such as multiple fault modes, limited data availability, and suboptimal diagnostic accuracy. Our focus is on common fault types in reaction control systems and actuators. We have designed a residual module and an attention module to construct an interpretable fault diagnosis model that extracts deep features from fault residual sequences and state parameter sequences. This model allows for the simultaneous and precise identification of fault type, location, and occurrence time. Furthermore, we visualize the diagnosis process through the use of attention weights and class activation mapping, thereby enhancing the interpretability of the fault diagnosis and bolstering the reliability of the results. Our findings reveal that both the residual module and attention module enhance diagnostic accuracy. In the diagnosis network, shallow attention primarily facilitates feature fusion, whereas deep attention primarily serves to filter features and improve detection capabilities. Without increasing computational complexity, the interpretable fault diagnosis model achieved an accuracy of 96.65%, and the fault time localization error was reduced by 86.15%. The proposed method simplifies model training and elevates fault detection accuracy, offering a reliable approach for isolating and identifying actuator faults.},
  archive      = {J_APIN},
  author       = {Zhou, Dengji and Huang, Dawen and Tie, Ming and Zhang, Xing and Hao, Jiarui and Wu, Yadong and Shen, Yaoxin and Wang, Yulin},
  doi          = {10.1007/s10489-024-06219-x},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {A fault diagnosis method based on interpretable machine learning model and decision visualization for HVs},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CG-MCFNet: Cross-layer guidance-based multi-scale correlation fusion network for 3D face recognition. <em>APIN</em>, <em>55</em>(4), 1-22. (<a href='https://doi.org/10.1007/s10489-024-06221-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D face recognition (FR) has been a popular field in recent years, which benefits from the advancement of 3D sensors and the application demands of video surveillance scenes. Existing 3D FR methods could show excellent performance when faces are complete. However, incomplete 3D faces, especially large poses and occluded, may prevent the model to learn effective and strong discriminative facial information adequately, resulting in unsatisfactory recognition results. To address this issue, we propose a cross-layer guidance-based multi-scale correlation fusion network (CG-MCFNet) for 3D FR. Firstly, we design a shallow feature enhancement extraction (SFE) module to obtain more effective facial detail information, and a deep feature enhancement extraction (DFE) module to learn more information with strong discrimination. Secondly, a novel multi-scale feature correlation fusion (MCF) module is proposed for fusing features from different layers, aiming to reduce the interference of redundant features and enhance the acquisition of discriminative features. Finally, the above three modules are integrated to form a new multi-scale local feature extraction (MLFE) module for capturing the face local information of rich and more strong discriminative. In addition, we introduce a global and local feature similarity weighted joint inference strategy, to further improve recognition accuracy. Extensive experiments on six challenging datasets, including three low-quality datasets (Lock3DFace, KinectFaceDB, and IIIT-D, where Lock3DFace is a video dataset), two high-quality datasets (UMB-DB, Bosphorus), and a cross-quality dataset synthesized by Bosphorus, prove that our CG-MCFNet achieves the best performance for incomplete 3D FR, which demonstrates the strong generalization ability of our model.},
  archive      = {J_APIN},
  author       = {Zhao, Panzi and Ming, Yue and Yu, Hui and Hu, Yuting and Zhou, Jiangwan and Liu, Yuanan},
  doi          = {10.1007/s10489-024-06221-3},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {CG-MCFNet: Cross-layer guidance-based multi-scale correlation fusion network for 3D face recognition},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A data-centric framework for combating domain shift in underwater object detection with image enhancement. <em>APIN</em>, <em>55</em>(4), 1-26. (<a href='https://doi.org/10.1007/s10489-024-06224-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater object detection has numerous applications in protecting, exploring, and exploiting aquatic environments. However, underwater environments pose a unique set of challenges for object detection including variable turbidity, colour casts, and light conditions. These phenomena represent a domain shift and need to be accounted for during design and evaluation of underwater object detection models. Although methods for underwater object detection have been extensively studied, most proposed approaches do not address challenges of domain shift inherent to aquatic environments. In this work we propose a data-centric framework for combating domain shift in underwater object detection with image enhancement. We show that there is a significant gap in accuracy of popular object detectors when tested for their ability to generalize to new aquatic domains. We used our framework to compare 14 image processing and enhancement methods in their efficacy to improve underwater domain generalization using three diverse real-world aquatic datasets and two widely used object detection algorithms. Using an independent test set, our approach superseded the mean average precision performance of existing model-centric approaches by 1.7–8.0 percentage points. In summary, the proposed framework demonstrated a significant contribution of image enhancement to underwater domain generalization.},
  archive      = {J_APIN},
  author       = {Folkman, Lukas and Pitt, Kylie A. and Stantic, Bela},
  doi          = {10.1007/s10489-024-06224-0},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {A data-centric framework for combating domain shift in underwater object detection with image enhancement},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RamIR: Reasoning and action prompting with mamba for all-in-one image restoration. <em>APIN</em>, <em>55</em>(4), 1-16. (<a href='https://doi.org/10.1007/s10489-024-06226-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {All-in-one image restoration aims to recover various degraded images using a unified model. To adaptively reconstruct high-quality images, recent prevalent CNN and Transformer based models incorporate learnable prompts to dynamically acquire degradation-specific knowledge for different degraded images, achieving state-of-the-art restoration performance. However, existing methods exhibit limitations, including high computational burden and inadequate modeling of long-range dependencies. To address these issues, we propose a reasoning and action prompt-driven Mamba-based image restoration model, namely RamIR. Specifically, RamIR employs the Mamba block for long-range dependencies modeling with linear computational complexity relative to the feature map size. Inspired by Chain-of-Thought (CoT) prompting, we integrate Reasoning and Action (ReAct) prompts within the Mamba block. Hence, we utilize the capability of pretrained vision language (PVL) models to generate textual reasoning prompts describing the type and severity of degradations. Simultaneously, another output from PVL acts as action prompt representing the clean image caption. These prompts, employed in a CoT manner, enhance the network’s sensitivity to degradation and elicit targeted recovery actions tailored to different reasoning prompts. Additionally, we explore the seamless interaction between Mamba blocks and prompts, introducing a novel prompt-driven module (PDM) to facilitate prompt utilization. Extensive experimental results demonstrate the superior performance of RamIR, highlighting its advantages in terms of input scaling efficiency over existing benchmark models for all-in-one image restoration.},
  archive      = {J_APIN},
  author       = {Tang, Aiqiang and Wu, Yan and Zhang, Yuwei},
  doi          = {10.1007/s10489-024-06226-y},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {RamIR: Reasoning and action prompting with mamba for all-in-one image restoration},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Utility-based agent model for intermodal behaviors: A case study for urban toll in lille. <em>APIN</em>, <em>55</em>(4), 1-23. (<a href='https://doi.org/10.1007/s10489-024-05869-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reduce the congestion and pollution in urban cities, the political authorities encourage the modal shift from private cars in favor of sustainable trip behaviors such as intermodality (through combinations of private cars and public transport). Coercive decisions such as urban tolls are also an increasingly investigated solution. To avoid the cost of toll taxes, agents thus select intermodal transportation modes (private cars and public transport) by parking their vehicles in park-and-ride (PR) facilities at the entrance to the area toll. This paper proposes a methodology for an agent-based model (ABM), particularly a model called utility-based agent, to reproduce intermodal trip behaviors in a city and to assess the impact of an urban toll. In this context, we focus on multinomial logit models, coupled with the agent-and-activity simulation tool MATSim, is used to determine the modal choice for each agent. Based on open data (for European Metropolis of Lille, MEL), the simulation shows that $$\varvec{20}$$ € ( $$\varvec{21.75}$$ $) of toll tax is sufficient to reduce by $$\varvec{20}\%$$ the use of private vehicles.},
  archive      = {J_APIN},
  author       = {Diallo, Azise Oumar and Lozenguez, Guillaume and Doniec, Arnaud and Mandiau, René},
  doi          = {10.1007/s10489-024-05869-1},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Utility-based agent model for intermodal behaviors: A case study for urban toll in lille},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-calibration algorithm for soil moisture sensors using deep learning. <em>APIN</em>, <em>55</em>(4), 1-19. (<a href='https://doi.org/10.1007/s10489-024-05921-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current era of smart agriculture, accurately measuring soil moisture has become crucial for optimising irrigation systems, significantly improving water use efficiency and crop yields. However, existing soil moisture sensor technologies often suffer from accuracy issues, leading to inefficient irrigation practices. The calibration of these sensors is limited by conventional methods that rely on extensive ground reference data, making the process both costly and impractical. This study introduces an innovative self-calibration method for soil moisture sensors using deep learning. The proposed method focuses on a novel strategy requiring only two characteristic points for calibration: saturation and field capacity. Deep learning algorithms enable effective and accurate in-situ self-calibration of sensors. This method was tested using a large dataset of simulated erroneous sensor readings generated with simulation software. The results demonstrate that the method significantly improves soil moisture measurement accuracy, with 84.83% of sensors showing improvement, offering a more agile and cost-effective implementation compared to traditional approaches. This advance represents a significant step towards more efficient and sustainable agriculture, offering farmers a valuable tool for optimal water and crop management, while highlighting the potential of deep learning in solving complex engineering challenges.},
  archive      = {J_APIN},
  author       = {Aranda Britez, Diego Alberto and Tapia, Alejandro and Millán Gata, Pablo},
  doi          = {10.1007/s10489-024-05921-0},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {A self-calibration algorithm for soil moisture sensors using deep learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparative study of handling imbalanced data using generative adversarial networks for machine learning based software fault prediction. <em>APIN</em>, <em>55</em>(4), 1-34. (<a href='https://doi.org/10.1007/s10489-024-05930-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software fault prediction (SFP) is the process of identifying potentially defect-prone modules before the testing stage of a software development process. By identifying faults early in the development process, software engineers can spend their efforts on those components most likely to contain defects, thereby improving the overall quality and reliability of the software. However, data imbalance and feature redundancy are challenging issues in SFP that can negatively impact the performance of fault prediction models. Imbalanced software fault datasets, in which the number of normal modules (majority class) is significantly higher than that of faulty modules (minority class), may lead to many false negative results. In this work, we study and perform an empirical assessment of the variants of Generative Adversarial Networks (GANs), an emerging synthetic data generation method, for resolving the data imbalance issue in common software fault prediction datasets. Five GANs variations - CopulaGAN, VanillaGAN, CTGAN, TGAN and WGANGP are utilized to generate synthetic faulty samples to balance the proportion of the majority and minority classes in datasets. Thereafter, we present an extensive evaluation of the performance of different prediction models which involve combining Recursive Feature Elimination (RFE) for feature selection with GANs oversampling methods, along with pairs of Autoencoders for feature extraction with GANs models. Throughout the experiments with five fault datasets extracted from the PROMISE repository, we evaluate six different machine learning approaches using precision, recall, F1-score, Area Under Curve (AUC) and Matthews Correlation Coefficient (MCC) as performance evaluation metrics. The experimental results demonstrate that the combination of CTGAN with RFE and a pair of CTGAN with Autoencoders outperform other baselines for all datasets, followed by WGANGP and VanillaGAN. According to the comparative analysis, GANs-based oversampling methods exhibited significant improvement in dealing with data imbalance for software fault prediction.},
  archive      = {J_APIN},
  author       = {Thi Minh Phuong, Ha and Vu Thu Nguyet, Pham and Huu Nhat Minh, Nguyen and Thi My Hanh, Le and Thanh Binh, Nguyen},
  doi          = {10.1007/s10489-024-05930-z},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-34},
  shortjournal = {Appl. Intell.},
  title        = {A comparative study of handling imbalanced data using generative adversarial networks for machine learning based software fault prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-correction algorithm for transparent object shadow detection. <em>APIN</em>, <em>55</em>(4), 1-14. (<a href='https://doi.org/10.1007/s10489-024-06001-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shadow detection for transparent objects is a challenging task. The difficulty arises from the fact that transparent objects and shadow regions are prone to occlusion, and the boundaries of transparent objects become more blurred due to optical effects, ultimately leading to incomplete shadow detection results. In this paper, a novel semisupervised shadow detection algorithm based on self-correction is proposed to address these problems. We construct a shadow detection module based on a hybrid attention mechanism CBAM and integrate the short-term memory capability of LSTM networks, assisting the model in accurately localizing shadow areas based on prior experience. To address the issue of easily overlooked shadow areas, we aim to minimize the difference between the predicted shadow mask and the real shadow mask as our optimization objective. We train the shadow self-correction module using binary cross-entropy loss to enhance the model’s ability to detect shadow areas that are prone to be overlooked. Furthermore, a pretrained boundary detector is utilized to obtain the boundary information between the predicted and real shadow masks. The shadow detection model is then optimized under the constraint of boundary consistency, enabling the model to more accurately identify the boundaries of shadow regions and enhancing the shadow detection performance. The experimental results indicate that, compared to existing shadow detection algorithms, the proposed algorithm performs well in terms of both transparent and nontransparent object shadow detection.},
  archive      = {J_APIN},
  author       = {Li, Jiaqi and Wen, Shuhuan and Chen, Rongting and Lu, Di and Hu, Jianyi and Zhang, Hong},
  doi          = {10.1007/s10489-024-06001-z},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {A self-correction algorithm for transparent object shadow detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced causal effects estimation based on offline reinforcement learning. <em>APIN</em>, <em>55</em>(4), 1-28. (<a href='https://doi.org/10.1007/s10489-024-06009-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal effects estimation is essential for analyzing the causal effects of treatment (intervention) on outcome, but traditional methods often rely on the strong assumption of no unobserved confounding factors. We propose ECEE-RL (Enhanced Causal Effects Estimation based on Reinforcement Learning), a novel architecture that leverages offline reinforcement learning to relax this assumption. ECEE-RL innovatively models causal effects estimation as a stateless Markov Decision Process, allowing for adaptive policy optimization through action-reward combinations. By framing estimation as "actions" and sensitivity analysis results as "rewards", ECEE-RL minimizes sensitivity to confounders, including unobserved ones. Theoretical analysis confirms the convergence and robustness of ECEE-RL. Experiments on the two simulated datasets demonstrate significant improvements, with CATE MSE reductions ranging from 5.45% to 66.55% and sensitivity significance reductions of up to 98.29% compared to baseline methods. These results corroborate our theoretical findings on ECEE-RL's improved accuracy and robustness. Application to real-world pilot-aircraft interaction data reveals significant causal effects of control behaviors on bioelectrical signals and emotions, demonstrating ECEE-RL's practical utility. While computationally intensive, ECEE-RL offers a promising approach for causal effects estimation, particularly in scenarios where unobserved confounding may be present, representing an important step towards more reliable causal inference in complex real-world settings.},
  archive      = {J_APIN},
  author       = {Xia, Huan and Jiang, Chaozhe and Zhang, Chenyang},
  doi          = {10.1007/s10489-024-06009-5},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-28},
  shortjournal = {Appl. Intell.},
  title        = {Enhanced causal effects estimation based on offline reinforcement learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel embedded cross framework for high-resolution salient object detection. <em>APIN</em>, <em>55</em>(4), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06073-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object detection (SOD) is a fundamental research topic in computer vision and has attracted significant interest from various fields, it has revealed two issues while driving the rapid development of salient detection. (1) The salient regions in high-resolution images exhibit significant differences in location, structure, and edge details, which makes them difficult to recognize and depict. (2) The traditional salient detection architecture is insensitive to detecting targets in high-resolution feature spaces, which leads to incomplete saliency predictions. To address these limitations, this paper proposes a novel embedded cross framework with a dual-path transformer (ECF-DT) for high-resolution SOD. The framework consists of a dual-path transformer and a unit fusion module for partitioning the salient targets. Specifically, we first design a cross network as a baseline model for salient object detection. Then, the dual-path transformer is embedded into the cross network with the objective of integrating fine-grained visual contextual information and target details while suppressing the disparity of the feature space. To generate more robust feature representations, we also introduce a unit fusion module, which highlights the positive information in the feature channels and encourages saliency prediction. Extensive experiments are conducted on nine benchmark databases, and the performance of the ECF-DT is compared with that of other existing state-of-the-art methods. The results indicate that our method outperforms its competitors and accurately detects the targets in high-resolution images with large objects, cluttered backgrounds, and complex scenes. It achieves MAEs of 0.017, 0.026, and 0.031 on three high-resolution public databases. Moreover, it reaches S-measure rates of 0.909, 0.876, 0.936, 0.854, 0.929, and 0.826 on six low-resolution public databases.},
  archive      = {J_APIN},
  author       = {Wang, Baoyu and Yang, Mao and Cao, Pingping and Liu, Yan},
  doi          = {10.1007/s10489-024-06073-x},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {A novel embedded cross framework for high-resolution salient object detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DeepSCNN: A simplicial convolutional neural network for deep learning. <em>APIN</em>, <em>55</em>(4), 1-21. (<a href='https://doi.org/10.1007/s10489-024-06121-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional neural networks (GCNs) are deep learning methods for processing graph-structured data. Usually, GCNs mainly consider pairwise connections and ignore higher-order interactions between nodes. Recently, simplices have been shown to encode not only pairwise relations between nodes but also encode higher-order interactions between nodes. Researchers have been concerned with how to design simplicial-based convolutional neural networks. The existing simplicial neural networks can achieve good performance in tasks such as missing value imputation, graph classification, and node classification. However, due to issues of gradient vanishing, over-smoothing, and over-fitting, they are typically limited to very shallow models. Therefore, we innovatively propose a simplicial convolutional neural network for deep learning (DeepSCNN). Firstly, simplicial edge sampling technology (SES) is introduced to prevent over-fitting caused by deepening network layers. Subsequently, initial residual connection technology is added to simplicial convolutional layers. Finally, to verify the validity of the DeepSCNN, we conduct missing data imputation and node classification experiments on citation networks. Additionally, we compare the experimental performance of the DeepSCNN with that of simplicial neural networks (SNN) and simplicial convolutional networks (SCNN). The results show that our proposed DeepSCNN method outperforms SNN and SCNN.},
  archive      = {J_APIN},
  author       = {Tang, Chunyang and Ye, Zhonglin and Zhao, Haixing and Bai, Libing and Lin, Jingjing},
  doi          = {10.1007/s10489-024-06121-6},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {DeepSCNN: A simplicial convolutional neural network for deep learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing few-shot learning using targeted mixup. <em>APIN</em>, <em>55</em>(4), 1-14. (<a href='https://doi.org/10.1007/s10489-024-06157-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Irrespective of the attention that long-tailed classification has received over recent years, expectedly, the performance of the tail classes suffers more than the remaining classes. We address this problem by means of a novel data augmentation technique called Targeted Mixup. This is about mixing class samples based on the model’s performance regarding each class. Instances of classes that are difficult to distinguish are randomly chosen and linearly interpolated to produce a new sample such that the model can pay attention to those two classes. The expectation is that the model can learn the distinguishing features to improve classification of instances belonging to their respective classes. To prove the efficiency of our proposed methods empirically, we performed experiments using CIFAR-100-LT, Places-LT, and Speech Commands-LT datasets. From the results of the experiments, there was an improvement on the few-shot classes without sacrificing too much of the model performance on the many-shot and medium-shot classes. In fact, there was an increase in the overall accuracy as well.},
  archive      = {J_APIN},
  author       = {Darkwah Jnr., Yaw and Kang, Dae-Ki},
  doi          = {10.1007/s10489-024-06157-8},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing few-shot learning using targeted mixup},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DDet3D: Embracing 3D object detector with diffusion. <em>APIN</em>, <em>55</em>(4), 1-16. (<a href='https://doi.org/10.1007/s10489-024-06045-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing approaches rely on heuristic or learnable object proposals (which are required to be optimised during training) for 3D object detection. In our approach, we replace the hand-crafted or learnable object proposals with randomly generated object proposals by formulating a new paradigm to employ a diffusion model to detect 3D objects from a set of randomly generated and supervised learning-based object proposals in an autonomous driving application. We propose DDet3D, a diffusion-based 3D object detection framework that formulates 3D object detection as a generative task over the 3D bounding box coordinates in 3D space. To our knowledge, this work is the first to formulate the 3D object detection with denoising diffusion model and to establish that 3D randomly generated and supervised learning-based proposals (different from empirical anchors or learnt queries) are also potential object candidates for 3D object detection. During training, the 3D random noisy boxes are employed from the 3D ground truth boxes by progressively adding Gaussian noise, and the DDet3D network is trained to reverse the diffusion process. During the inference stage, the DDet3D network is able to iteratively refine the 3D randomly generated and supervised learning-based noisy boxes to predict 3D bounding boxes conditioned on the LiDAR Bird’s Eye View (BEV) features. The advantage of DDet3D is that it allows to decouple training and inference stages, thus enabling the use of a larger number of proposal boxes or sampling steps during inference to improve accuracy. We conduct extensive experiments and analysis on the nuScenes and KITTI datasets. DDet3D achieves competitive performance compared to well-designed 3D object detectors. Our work serves as a strong baseline to explore and employ more efficient diffusion models for 3D perception tasks.},
  archive      = {J_APIN},
  author       = {Erabati, Gopi Krishna and Araujo, Helder},
  doi          = {10.1007/s10489-024-06045-1},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {DDet3D: Embracing 3D object detector with diffusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-stage cyberbullying detection based on multi-view features and decision fusion strategy. <em>APIN</em>, <em>55</em>(4), 1-21. (<a href='https://doi.org/10.1007/s10489-024-06049-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyberbullying has emerged as a pressing concern across various social platforms due to the escalating usage of online networks. Cyberbullying may lead victims to depression, self-harm, and even suicide. In this research, a two-stage cyberbullying detection framework based on multi-view features and decision fusion strategies is proposed. The first stage is to discover cyberbullying texts in social media, and the second stage delves into categorizing the specific forms of bullying present in the identified texts. In the two-stage detection process, features are constructed from multiple views, including Content view, Profanity view, and User view, to portray the bullying behavior. Furthermore, a decision fusion strategy is designed, incorporating both single-view features and multi-view features to enhance detection effectiveness. Finally, the research explains the complex mechanism of multi-view features in two-stage cyberbullying detection by calculating their SHAP values. The experimental results demonstrate the effectiveness of the multi-view feature and decision fusion strategy in cyberbullying detection. Notably, this framework yields impressive results, boasting an F1-score of 89.66% and an AUC of 95.98% in Stage I, while achieving an F1-score of 74.25% and an Accuracy of 79.01% in Stage II. The interpretability analysis of features affirms the pivotal role played by multi-view features, with the Content view features emerging as especially significant in the pursuit of effective cyberbullying detection.},
  archive      = {J_APIN},
  author       = {Li, Tingting and Zeng, Ziming and Sun, Shouqiang},
  doi          = {10.1007/s10489-024-06049-x},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {A two-stage cyberbullying detection based on multi-view features and decision fusion strategy},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new multivariate decomposition-ensemble approach with denoised neighborhood rough set for stock price forecasting over time-series information system. <em>APIN</em>, <em>55</em>(4), 1-21. (<a href='https://doi.org/10.1007/s10489-024-06070-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uncertainty of the stock market is the foundation for investors to obtain returns. Driven by interests, stock price forecasting has become a research hotspot. However, as the high latitude, highly volatile, and noisy, forecasting the stock prices has become a highly challenging task. The existing stock price forecasting methods only study low latitude data, which is unable to reflect the cumulative effect of multiple factors on stock price. To effectively address the high latitude, high volatility, and noise of stock price, a time-series information system (TSIS) forecasting approach for stock price is proposed. Aiming at dynamically depicting the real-world decision-making scenarios from a finer granularity, the TSIS is constructed based on the information systems. Then, a denoised neighborhood rough set (DNRS) model based on the TSIS is proposed by local density factor to achieve the purpose of feature selection, which can weaken the impact of noise on sample data. Subsequently, the multivariate empirical mode decomposition (MEMD) and multivariate kernel extreme learning machine (MKELM) are employed to decompose and forecast. Finally, the proposed TSIS forecasting approach is applied to stock price. Experimental results show that the TSIS forecasting approach for stock price has excellent performance and can be provided in the quantitative trading of stock market.},
  archive      = {J_APIN},
  author       = {Bai, Juncheng and Sun, Bingzhen and Guo, Yuqi and Chu, Xiaoli},
  doi          = {10.1007/s10489-024-06070-0},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {A new multivariate decomposition-ensemble approach with denoised neighborhood rough set for stock price forecasting over time-series information system},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Crowd evacuation path planning and simulation method based on deep reinforcement learning and repulsive force field. <em>APIN</em>, <em>55</em>(4), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06074-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning is essential for simulating crowd evacuation. However, existing path planning methods encounter challenges, including unbalanced exit utilization, ineffective obstacle avoidance, and low evacuation efficiency. To address these issues, this paper presents a path planning method based on Deep Reinforcement Learning (DRL) and a Repulsive Force Field (RFF) for crowd evacuation simulation. First, a dynamic exit scoring mechanism is proposed and integrated into the DRL training process to balance exit utilization during evacuation. Additionally, we address the sparse reward issue in DRL by extracting key points from actual evacuation trajectories as short-term goals. Finally, we enhance the movement strategy output by constructing an RFF to improve obstacle avoidance in complex environments. Experimental results demonstrate that the proposed method effectively avoids obstacles and efficiently completes evacuation tasks.},
  archive      = {J_APIN},
  author       = {Wang, Hongyue and Liu, Hong and Li, Wenhao},
  doi          = {10.1007/s10489-024-06074-w},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Crowd evacuation path planning and simulation method based on deep reinforcement learning and repulsive force field},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of switching-input LSTM network for vessel trajectory prediction. <em>APIN</em>, <em>55</em>(4), 1-22. (<a href='https://doi.org/10.1007/s10489-024-06079-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rapid economic development of modern society, the demand for cargo in the shipping industry has experienced unprecedented growth in recent years. The introduction of a large number of ships, especially large, new, and intelligent ships, has made shipping networks more complex. Controlling transportation risks has become more challenging than ever before. Ship trajectory prediction based on automatic identification system (AIS) data can effectively help identify abnormal ship behaviors and reduce maritime risks such as collisions, grounding, and contacts. In recent years, with the rapid development of deep learning theories, recurrent neural network models (long short-term memory and gated recurrent unit) have been widely used in ship trajectory prediction due to their powerful ability to capture hidden information in time-series data. However, these models struggle with tasks involving high complexity of trajectory features. To address this issue, this paper introduces a switching-input mechanism based on LSTM, constructing a ship trajectory prediction model based on the SI-LSTM model. The switching-input mechanism enables the model to adjust its processing of important information according to dynamic changes in input data, effectively capturing local features of complex trajectories. The experimental section, which includes eight cases of complex trajectories, demonstrates the competitive generalization ability and prediction accuracy of SI-LSTM.},
  archive      = {J_APIN},
  author       = {Wang, Weihong and Yi, Zuo and Zhao, Licheng and Jia, Peng and Kuang, Haibo},
  doi          = {10.1007/s10489-024-06079-5},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Application of switching-input LSTM network for vessel trajectory prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A chaotic variant of the golden jackal optimizer and its application for medical image segmentation. <em>APIN</em>, <em>55</em>(4), 1-32. (<a href='https://doi.org/10.1007/s10489-024-06084-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The initial segmentation phase is crucial in image processing to simplify the image representation and extract some desired features. Different methods and techniques have been proposed for image multi-level thresholding, but they are still stuck in local optima and need improvement. Recently, a metaheuristic optimization algorithm called Golden Jackal Optimizer (GJO) has been proposed as an alternative solution. The GJO has been adopted as a good solution for many optimization problems. However, the GJO attempted to solve the convergence problem to a local minimum during execution, often leading to unsatisfactory results. Most variants of GJO are based on chaotic systems due to their easy implementation and remarkable capacity to avoid being trapped in local optima. This paper proposes a Polynomial Chebychev Symmetric Chaotic-based GJO (PCSCGJO) algorithm by combining a recently developed chaotic generating function to achieve better segmentation results. This variant improves the GJO by introducing the chaotic generating function of the Chebyshev polynomials as an update process while searching for the optimal solution. Simulation results prove the effectiveness of the PCSCGJO method and its ability to deal with different medical color images. The quality of the segmented images obtained by the proposed method was compared to well-known metaheuristic algorithms using performance metrics such as PSNR, SSIM, FSIM, and MSE. Consequently, the metrics values show that the suggested technique outperforms the other methods regarding quality and accuracy.},
  archive      = {J_APIN},
  author       = {Hamza, Amir and Grimes, Morad and Boukabou, Abdelkarim and Lekouaghet, Badis and Oliva, Diego and Dib, Samira and Himeur, Yacine},
  doi          = {10.1007/s10489-024-06084-8},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-32},
  shortjournal = {Appl. Intell.},
  title        = {A chaotic variant of the golden jackal optimizer and its application for medical image segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level adaptive feature representation based on task augmentation for cross-domain few-shot learning. <em>APIN</em>, <em>55</em>(4), 1-12. (<a href='https://doi.org/10.1007/s10489-024-06110-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-Domain Few-Shot Learning (CDFSL) is one of the most cutting-edge fields in machine learning. It not only addresses the traditional few-shot problem but also allows for different distributions between base classes and novel classes. However, most current CDFSL models only focus on the generalization performance of high-level features during training and testing, which hinders their ability to generalize well to domains with significant gaps. To overcome this problem, we propose a CDFSL method based on Task Augmentation and Multi-Level Adaptive features representation(TA-MLA). At the feature representation level, we introduce a meta-learning strategy for multi-level features and adaptive features. The former come from different layers of network. They jointly participate in image prediction to fully explore transferable features suitable for cross-domain scenarios. The latter is based on a feature adaptation module of feed-forward attention, aiming to learn domain-adaptive features to improve the generalization of the model. At the training task level, we employ a plug-and-play Task Augmentation(TA) module to generate challenging tasks with adaptive inductive biases, thereby expanding the distribution of the source domain and further bridging domain gaps. Extensive experiments conducted on multiple datasets. The results demonstrate that our method based on meta-learning can effectively improves few-shot classification performance, especially in cases with significant domain shift.},
  archive      = {J_APIN},
  author       = {Yue, Ling and Feng, Lin and Shuai, Qiuping and Li, Zihao and Xu, Lingxiao},
  doi          = {10.1007/s10489-024-06110-9},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {Multi-level adaptive feature representation based on task augmentation for cross-domain few-shot learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive spiking neuron with population coding for a residual spiking neural network. <em>APIN</em>, <em>55</em>(4), 1-24. (<a href='https://doi.org/10.1007/s10489-024-06128-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) have attracted significant research attention due to their inherent sparsity and event-driven processing capabilities. Recent studies indicate that the incorporation of convolutional and residual structures into SNNs can substantially enhance performance. However, these converted spiking residual structures are associated with increased complexity and stacked parameterized spiking neurons. To address this challenge, this paper proposes a meticulously refined two-layer decision structure for residual-based SNNs, consisting solely of fully connected and spiking neuron layers. Specifically, the spiking neuron layers incorporate an innovative dynamic leaky integrate-and-fire (DLIF) neuron model with a nonlinear self-feedback mechanism, characterized by dynamic threshold adjustment and a self-regulating firing rate. Furthermore, diverging from traditional direct encoding, which focuses solely on individual neuronal frequency, we introduce a novel mixed coding mechanism that combines direct encoding with multineuronal population decoding. The proposed architecture improves the adaptability and responsiveness of spiking neurons in various computational contexts. Experimental results demonstrate the superior efficacy of our approach. Although it uses a highly simplified structure with only 6 timesteps, our proposal achieves enhanced performance in the experimental trials compared to multiple state-of-the-art methods. Specifically, it achieves accuracy improvements of 0.01-1.99% on three static datasets and of 0.14-7.50% on three N-datasets. The DLIF model excels in information processing, showing double mutual information compared to other neurons. In the sequential MNIST dataset, it balances biological realism and practicality, enhancing memory and the dynamic range. Our proposed method not only offers improved computational efficacy and simplified network structure but also enhances the biological plausibility of SNN models and can be easily adapted to other deep SNNs.},
  archive      = {J_APIN},
  author       = {Dan, Yongping and Sun, Changhao and Li, Hengyi and Meng, Lin},
  doi          = {10.1007/s10489-024-06128-z},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive spiking neuron with population coding for a residual spiking neural network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient PSO-based evolutionary model for closed high-utility itemset mining. <em>APIN</em>, <em>55</em>(4), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06151-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-utility itemset mining (HUIM) is a widely adopted data mining technique for discovering valuable patterns in transactional databases. Although HUIM can provide useful knowledge in various types of data, it can be challenging to interpret the results when many patterns are found. To alleviate this, closed high-utility itemset mining (CHUIM) has been suggested, which provides users with a more concise and meaningful set of solutions. However, CHUIM is a computationally demanding task, and current approaches can require prolonged runtimes. This paper aims to solve this problem and proposes a meta-heuristic model based on particle swarm optimization (PSO) to discover CHUIs, called CHUI-PSO. Moreover, the algorithm incorporates several new strategies to reduce the computational cost associated with similar existing techniques. First, we introduce Extended TWU pruning (ETP), which aims to decrease the number of possible candidates to improve the discovery of solutions in large search spaces. Second, we propose two new utility upper bounds, used to estimate itemset utilities and bypass expensive candidate evaluations. Finally, to increase population diversity and prevent redundant computations, we suggest a structure called ExploredSet to maintain and utilize the evaluated candidates. Extensive experimental results show that CHUI-PSO outperforms the current state-of-the-art algorithms regarding execution time, accuracy, and convergence.},
  archive      = {J_APIN},
  author       = {Carstensen, Simen and Lin, Jerry Chun-Wei},
  doi          = {10.1007/s10489-024-06151-0},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {An efficient PSO-based evolutionary model for closed high-utility itemset mining},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). F2RAIL: Panoptic segmentation integrating fpn and transFormer towards RAILway. <em>APIN</em>, <em>55</em>(4), 1-21. (<a href='https://doi.org/10.1007/s10489-024-06158-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Panoptic segmentation method enables precise identification and localization of various elements in railway scenes by assigning unique masks to each object in the image, thereby providing crucial data support for autonomous perception tasks in railway environments. However, existing segmentation methods fail to effectively leverage the prominent boundary and linear features of objects such as railway tracks and guardrails, resulting in unsatisfactory segmentation performance in railway scenes. Moreover, the inherent structural limitations of generic segmentation methods lead to weak feature extraction capabilities. Accordingly, this paper proposes the F2RAIL panoptic segmentation network, which achieves a unified approach to multi-scale detection and high-precision recognition through an innovative fusion of Feature Pyramid Networks (FPN) and transformer networks. By introducing an edge feature enhancement module, we address the insufficient utilization of linear features in railway scenes by segmentation models; By introducing a multi-dimensional enhancement module, we resolve the issues of weakened or even lost deep feature information in segmentation models. Based on the aforementioned structural innovations and methodological improvements, F2RAIL achieved a panoptic quality(PQ) of 43.74% on our custom railway dataset, representing a 2.2% improvement over existing state-of-the-art(SOTA) methods. Additionally, it demonstrated comparable performance to SOTA methods on public benchmark datasets.},
  archive      = {J_APIN},
  author       = {Dingyuan, Bai and Baoqing, Guo and Tao, Ruan and Xingfang, Zhou and Tao, Sun and Yu, Wang and Tao, Liu},
  doi          = {10.1007/s10489-024-06158-7},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {F2RAIL: Panoptic segmentation integrating fpn and transFormer towards RAILway},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EMD empowered neural network for predicting spatio-temporal non-stationary channel in UAV communications. <em>APIN</em>, <em>55</em>(4), 1-28. (<a href='https://doi.org/10.1007/s10489-024-06165-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel prediction method for spatio-temporal non-stationary channels between unmanned aerial vehicles (UAVs) and ground control vehicles, essential for the fast and accurate acquisition of channel state information (CSI) to support UAV applications in ultra-reliable and low-latency communication (URLLC). Specifically, an empirical mode decomposition (EMD)-empowered spatio-temporal attention neural network is proposed, referred to as EMD-STANN. The STANN sub-module within EMD-STANN is designed to capture the spatial correlation and temporal dependence of CSI. Furthermore, the EMD component is employed to handle the non-stationary and nonlinear dynamic characteristics of the UAV-to-ground control vehicle (U2V) channel, thereby enhancing the feature extraction and refinement capabilities of the STANN and improving the accuracy of CSI prediction. Additionally, we conducted a validation of the proposed EMD-STANN model across multiple datasets. The results indicated that EMD-STANN is capable of effectively adapting to diverse channel conditions and accurately predicting channel states. Compared to existing methods, EMD-STANN exhibited superior predictive performance, as indicated by its reduced root mean square error (RMSE) and mean absolute error (MAE) metrics. Specifically, EMD-STANN achieved a reduction of 24.66% in RMSE and 25.46% in MAE compared to the reference method under our simulation conditions. This improvement in prediction accuracy provides a solid foundation for the implementation of URLLC applications.},
  archive      = {J_APIN},
  author       = {Zhang, Qiuyun and Guo, Qiumei and Jiang, Hong and Yin, Xinfan and Mushtaq, Muhammad Umer and Luo, Ying and Wu, Chun},
  doi          = {10.1007/s10489-024-06165-8},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-28},
  shortjournal = {Appl. Intell.},
  title        = {EMD empowered neural network for predicting spatio-temporal non-stationary channel in UAV communications},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effectiveness of encoder-decoder deep learning approach for colorectal polyp segmentation in colonoscopy images. <em>APIN</em>, <em>55</em>(4), 1-24. (<a href='https://doi.org/10.1007/s10489-024-06167-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal cancer is considered one of the deadliest diseases, contributing to an alarming increase in annual deaths worldwide, with colorectal polyps recognized as precursors to this malignancy. Early and accurate detection of these polyps is crucial for reducing the mortality rate of colorectal cancer. However, the manual detection of polyps is a time-consuming process and requires the expertise of trained medical professionals. Moreover, it often misses polyps due to their varied size, color, and texture. Computer-aided diagnosis systems offer potential improvements, but they often struggle with precision in complex visual environments. This study presents an enhanced deep learning approach using encoder-decoder architecture for colorectal polyp segmentation to capture and utilize complex feature representations. Our approach introduces an enhanced dual attention mechanism, combining spatial and channel-wise attention to focus precisely on critical features. Channel-wise attention, implemented via an optimized Squeeze-and-Excitation (S&E) block, allows the network to capture comprehensive contextual information and interrelationships among different channels, ensuring a more refined feature selection process. The experimental results showed that the proposed model achieved a mean Intersection over Union (IoU) of 0.9054 and 0.9277, a dice coefficient of 0.9006 and 0.9128, a precision of 0.8985 and 0.9517, a recall of 0.9190 and 0.9094, and an accuracy of 0.9806 and 0.9907 on the Kvasir-SEG and CVC-ClinicDB datasets, respectively. Moreover, the proposed model outperforms the existing state-of-the-art resulting in improved patient outcomes with the potential to enhance the early detection of colorectal polyps.},
  archive      = {J_APIN},
  author       = {Hamza, Ameer and Bilal, Muhammad and Ramzan, Muhammad and Malik, Nadia},
  doi          = {10.1007/s10489-024-06167-6},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {Effectiveness of encoder-decoder deep learning approach for colorectal polyp segmentation in colonoscopy images},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-way conflict analysis based on multi-scale situation tables. <em>APIN</em>, <em>55</em>(4), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06188-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the existing three-way conflict analysis models, ratings have only one scale. However, when evaluating an issue in real life, agents can also use multi-scale ratings, which can provide a more comprehensive description and better analysis. Therefore, it is necessary to study three-way conflict analysis based on a multi-scale situation table. In this paper, we consider the construction of three-way conflict analysis models on multi-scale situation tables (MS-STs). Firstly, we introduce the concept of MS-STs, in which the attitudes of agents towards issues are represented by multi-scale ratings. Secondly, we construct two types of three-way conflict analysis models on MS-STs using two different methods. One approach is to directly construct a three-way conflict analysis model on original MS-STs, called Type-1 three-way conflict analysis model. In this approach, we measure the conflict distances between agents on a subset of issues by using the proposed weighted distance function. We then trisect all pairs of agents. The other method involves converting an original MS-ST into a single-scale situation table through optimal scale selection. This results in a single-scale situation table induced by the optimal scale combination. Based on this, we construct a corresponding Type-2 three-way conflict analysis model. We provide several examples to illustrate the construction process of these two models. Additionally, we provide the calculation methods for weights and thresholds. Finally, we compare the proposed models in this paper with existing models to verify their applicability and effectiveness.},
  archive      = {J_APIN},
  author       = {Lu, Chuan-Yuan and Yang, Hai-Long and Guo, Zhi-Lian},
  doi          = {10.1007/s10489-024-06188-1},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Three-way conflict analysis based on multi-scale situation tables},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visible and thermal image fusion network with diffusion models for high-level visual tasks. <em>APIN</em>, <em>55</em>(4), 1-26. (<a href='https://doi.org/10.1007/s10489-024-06210-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fusion technology enhances the performance of applications such as security, autonomous driving, military surveillance, medical imaging, and environmental monitoring by combining complementary information. The fusion of visible and thermal (RGB-T) images is critical for improving human observation and visual tasks. However, the training of most semantics-driven fusion algorithms combines segmentation and fusion tasks, thereby increasing the computational cost and underutilizing semantic information. Designing a cleaner fusion architecture to mine rich deep semantic features is the key to addressing this issue. A two-stage RGB-T image fusion network with diffusion models is proposed in this paper. In the first stage, the diffusion model is employed to extract multiscale features. This provided rich semantic features and texture edges for the fusion network. In the next stage, semantic feature enhancement module (SFEM) and detail feature enhancement module (DFEM) are proposed to improve the network’s ability to describe small details. An adaptive global-local attention mechanism (AGAM) is used to enhance the weights of key features related to visual tasks. Specifically, we benchmarked the proposed algorithm by creating a new tri-modal sensor driving scene dataset (TSDS), which includes 15234 sets of labeled images (visible, thermal, and polarization degree images). The semantic segmentation model trained on our fusion images achieved 78.41% accuracy, and the object detection model achieved 87.21% MAP. The experimental results indicate that our algorithm outperforms the state-of-the-art image fusion algorithms.},
  archive      = {J_APIN},
  author       = {Meng, Jin and Zou, Jiahui and Xiang, Zhuoheng and Wang, Cui and Wang, Shifeng and Li, Yan and Kim, Jonghyuk},
  doi          = {10.1007/s10489-024-06210-6},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Visible and thermal image fusion network with diffusion models for high-level visual tasks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cyclic deformable medical image registration with prompt: Deep fusion of diffeomorphic and transformer methods. <em>APIN</em>, <em>55</em>(4), 1-19. (<a href='https://doi.org/10.1007/s10489-025-06232-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image registration is a fundamental task in medical image analysis. Recently, competitive methods, such as deep learning-based registration and deformable registration, which have demonstrated promising results, have been proposed. However, meeting the demands for high precision in clinical applications is still a challenge. Here, we propose a cyclic optimization registration framework that deeply fuses diffeomorphic and deep learning methods through a single forward-two path structure. A neural network estimates the initial deformation field, which directly generates registered images to enhance feature extraction capabilities. Additionally, dynamic diffeomorphism is introduced for the initial deformation field to generate the final deformation field, ensuring the invertibility of the transformation. We incorporate the Dense Spatial Correspondence Prompt module for cyclically learning the final deformation field, enabling the network to estimate smoother and more accurate spatial transformations. Experiments conducted on a publicly available 3D dataset demonstrate exceptional registration accuracy with a DSC of 0.621 and an SSIM of 0.913, while preserving desirable diffeomorphic properties with almost zero non-positive Jacobians.},
  archive      = {J_APIN},
  author       = {Li, Longhao and Li, Li and Zhang, Yunfeng and Bao, Fangxun and Yao, Xunxiang and Zhang, Caiming},
  doi          = {10.1007/s10489-025-06232-8},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {4},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Cyclic deformable medical image registration with prompt: Deep fusion of diffeomorphic and transformer methods},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stabilizing and improving federated learning with highly non-iid data and client dropout. <em>APIN</em>, <em>55</em>(3), 1-18. (<a href='https://doi.org/10.1007/s10489-024-05956-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The label distribution skew has been shown to be a significant obstacle that limits the model performance in federated learning (FL). This challenge could be more serious when the participating clients are in unstable network circumstances and drop out frequently. Previous works have demonstrated that the classifier head is particularly sensitive to the label skew. Therefore, maintaining a balanced classifier head is of significant importance for building a good and unbiased global model. To this end, we propose a simple yet effective framework by introducing a calibrated softmax function with smoothed prior for computing the cross-entropy loss, and a prototype-based feature augmentation scheme to re-balance the local training, which provide a new perspective on tackling the label distribution skew in FL and are lightweight for edge devices and can facilitate the global model aggregation. With extensive experiments on two benchmark classification tasks of Fashion-MNIST and CIFAR-10, our numerical results demonstrate that our proposed method can consistently outperform the baselines, 2 8% of accuracy over FedAvg in the presence of severe label skew and client dropout.},
  archive      = {J_APIN},
  author       = {Xu, Jian and Yang, Meilin and Ding, Wenbo and Huang, Shao-Lun},
  doi          = {10.1007/s10489-024-05956-3},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Stabilizing and improving federated learning with highly non-iid data and client dropout},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A domain-aware model with multi-perspective contrastive learning for natural language understanding. <em>APIN</em>, <em>55</em>(3), 1-18. (<a href='https://doi.org/10.1007/s10489-024-06154-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intent detection and slot filling are core tasks in natural language understanding (NLU) for task-oriented dialogue systems. However, current models face challenges with numerous intent categories, slot types, and domain classifications, alongside a shortage of well-annotated datasets, particularly in Chinese. Therefore, we propose a domain-aware model with multi-perspective, multi-positive contrastive learning. First, we adopt a self-supervised contrastive learning with multiple perspectives and multiple positive instances, which is capable of spacing the vectors of positive and negative instances from the domain, intent, and slot perspectives, and fusing more positive instance information to increase the classification effectiveness of the model. Our proposed domain-aware model defines domain-level units at the decoding layer, allowing the model to predict intent and slot information based on domain features, which greatly reduces the search space for intent and slot. In addition, we design a dual-stage attention mechanism for capturing implicitly shared information between intents and slots. We propose a data augmentation method that adds noise to the embedding layer, applies fine-grained augmentation techniques, and filters biased samples based on a similarity threshold. Our model is applied to real task-oriented dialogue systems and compared with other NLU models. Experimental results demonstrate that our proposed model outperforms other models in terms of NLU performance.},
  archive      = {J_APIN},
  author       = {Wang, Di and Ni, Qingjian},
  doi          = {10.1007/s10489-024-06154-x},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {A domain-aware model with multi-perspective contrastive learning for natural language understanding},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An attribute reduction algorithm using relative decision mutual information in fuzzy neighborhood decision system. <em>APIN</em>, <em>55</em>(3), 1-26. (<a href='https://doi.org/10.1007/s10489-024-06171-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fuzzy neighborhood rough set integrates the strengths of fuzzy rough set and neighborhood rough set, serving as a pivotal extension of the rough set theory in attribute reduction. However, this model’s widespread application is hindered by its sensitivity to data distribution and limited efficacy in assessing classification uncertainty for datasets with substantial density variations. To mitigate these challenges, this paper introduces an attribute reduction algorithm based on fuzzy neighborhood relative decision mutual information. Firstly, the classification uncertainty of samples is initially defined in terms of relative distance. Simultaneously, the similarity relationship of fuzzy neighborhoods is reformulated, thereby reducing the risk of sample misclassification through integration with variable-precision fuzzy neighborhood rough approximation. Secondly, the notion of representative sample is introduced, leading to a redefinition of fuzzy membership. Thirdly, fuzzy neighborhood relative mutual information from the information view is constructed and combined with fuzzy neighborhood relative dependency from the algebraic view to propose fuzzy neighborhood relative decision mutual information. Finally, an attribute reduction algorithm is devised based on fuzzy neighborhood relative decision mutual information. This algorithm evaluates the significance of attributes by integrating both informational and algebraic perspectives. Comparative tests on 12 public datasets are conducted to assess existing attribute approximation algorithms. The experimental results show that the proposed algorithm achieved an average classification accuracy of 91.28 $$\%$$ with the KNN classifier and 89.86 $$\%$$ with the CART classifier. In both classifiers, the algorithm produced an average reduced subset size of 8.54. While significantly reducing feature redundancy, the algorithm consistently maintains a high level of classification accuracy.},
  archive      = {J_APIN},
  author       = {Xu, Jiucheng and Zhang, Shan and Ma, Miaoxian and Niu, Wulin and Duan, Jianghao},
  doi          = {10.1007/s10489-024-06171-w},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {An attribute reduction algorithm using relative decision mutual information in fuzzy neighborhood decision system},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning state-action correspondence across reinforcement learning control tasks via partially paired trajectories. <em>APIN</em>, <em>55</em>(3), 1-18. (<a href='https://doi.org/10.1007/s10489-024-06190-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many reinforcement learning (RL) tasks, the state-action space may be subject to changes over time (e.g., increased number of observable features, changes of representation of actions). Given these changes, the previously learnt policy will likely fail due to the mismatch of input and output features, and another policy must be trained from scratch, which is inefficient in terms of sample complexity. Recent works in transfer learning have succeeded in making RL algorithms more efficient by incorporating knowledge from previous tasks, thus partially alleviating this problem. However, such methods typically must provide an explicit state-action correspondence of one task into the other. An autonomous agent may not have access to such high-level information, but should be able to analyze its experience to identify similarities between tasks. In this paper, we propose a novel method for automatically learning a correspondence of states and actions from one task to another through an agent’s experience. In contrast to previous approaches, our method is based on two key insights: i) only the first state of the trajectories of the two tasks is paired, while the rest are unpaired and randomly collected, and ii) the transition model of the source task is used to predict the dynamics of the target task, thus aligning the unpaired states and actions. Additionally, this paper intentionally decouples the learning of the state-action corresponce from the transfer technique used, making it easy to combine with any transfer method. Our experiments demonstrate that our approach significantly accelerates transfer learning across a diverse set of problems, varying in state/action representation, physics parameters, and morphology, when compared to state-of-the-art algorithms that rely on cycle-consistency.},
  archive      = {J_APIN},
  author       = {García, Javier and Rañó, Iñaki and Burés, J. Miguel and Fdez-Vidal, Xosé R. and Iglesias, Roberto},
  doi          = {10.1007/s10489-024-06190-7},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Learning state-action correspondence across reinforcement learning control tasks via partially paired trajectories},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient knowledge distillation using a shift window target-aware transformer. <em>APIN</em>, <em>55</em>(3), 1-13. (<a href='https://doi.org/10.1007/s10489-024-06207-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Target-aware Transformer (TaT) knowledge distillation effectively extracts information from intermediate layers but faces high computational costs for large feature maps. While the non-overlapping Patch-group distillation in TaT reduces complexity, it loses boundary information, affecting accuracy. We propose an improved Shifted Windows Target-aware Transformer (Swin TaT) knowledge distillation method, utilizing a hierarchical shift window strategy to preserve boundary information and balance computational efficiency. Our multi-scale approach optimizes Patch-group distillation with dynamic adjustment, ensuring effective local and global feature transfer. This flexible and efficient design enhances distillation performance, addressing previous limitations. The proposed Swin TaT method demonstrates exceptional performance across various architectures, with ResNet18 as the student network. It achieves 73.03% Top-1 accuracy on ImageNet1K, surpassing the SOTA by 1.06% while reducing parameters to approximately 46% less, and improves mIoU by 2.13% on COCOStuff10k.},
  archive      = {J_APIN},
  author       = {Feng, Jing and Ong, Wen Eng},
  doi          = {10.1007/s10489-024-06207-1},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Efficient knowledge distillation using a shift window target-aware transformer},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A physically-constrained ensemble learning rate of penetration prediction model based on multi-source data fusion. <em>APIN</em>, <em>55</em>(3), 1-24. (<a href='https://doi.org/10.1007/s10489-024-05922-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rate of penetration (ROP) is a key indicator of drilling efficiency in oil and gas extraction. Accurate ROP prediction is crucial for optimizing drilling design and reducing costs. However, current ROP prediction models rarely consider the impact of geological parameters on ROP. Additionally, data-driven models often lack the constraints of physical laws governing the relationships between parameters, leading to poor interpretability of the results. To address these issues, this paper proposes a Correlation-Constrained Ensemble (CCE) model for ROP prediction that integrates both geological and engineering data. The CCE model first uses the Gradient Boosting Decision Tree (GBDT) algorithm to combine four models: Artificial Neural Network (ANN), Regression Tree (RT), Random Forest (RF), and Support Vector Regression (SVR). The model then applies correlation constraints to optimize predictions that do not meet the constraint conditions. By incorporating geological data and applying physical constraints, the mean absolute percentage error (MAPE) of the predictions on the test dataset was reduced from 13.67% to 8.87%. Finally, error evaluation methods more suitable for engineering applications were defined, namely error satisfaction and regional accuracy. Using these methods, the impact of different formations and lithologies on prediction results was analyzed. It was found that the prediction errors are larger at lithological transition interfaces and in formations with high clay content. For the regions with larger prediction errors identified in this study, corresponding solutions for engineering applications have been provided.},
  archive      = {J_APIN},
  author       = {Fan, Yongdong and Jin, Yan and Pang, Huiwen and Lu, Yunhu},
  doi          = {10.1007/s10489-024-05922-z},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {A physically-constrained ensemble learning rate of penetration prediction model based on multi-source data fusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized emotion analysis based on fuzzy multi-modal transformer model. <em>APIN</em>, <em>55</em>(3), 1-28. (<a href='https://doi.org/10.1007/s10489-024-05954-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing and detecting human intensions and emotions are important means to improve the communication between users and machines in the areas of human-computer interaction (HCI) and human-robot interaction (HRI). Despite significant progress in utilizing state-of-the-art (SOTA) Transformer-based models, various obstacles persist in managing complicated input interdependencies and extracting intricate contextual semantics. Moreover, it lacks practical applicability and struggles to accurately capture and effectively manage the inherent complexity and unpredictability of human emotions. In recognition of the identified research gaps, we introduce a robust and innovative fuzzy multi-modal Transformer (FMMT) model. Our novel fuzzy Transformer model uniquely heightens the comprehension of emotional contexts by concurrently analyzing audio, visual, and text data through three distinct branches. By incorporating fuzzy mathematic theory and introducing a unique temporal embedding technique to trace the evolution of emotional states, it effectively handles the inherent uncertainty in human emotions, thereby filling a significant void in emotional AI. Building upon the FMMT model, we further explored the emotion expression approach. Furthermore, performance comparison analysis with SOTA baseline methods and detailed ablation study were performed. The results show that the proposed FMMT performs better than the baseline methods. Finally, we conducted detailed experimental verification and empirical analyses of the practicality of the designed method by verifying uncertainty emotion and analyzing emotional state transitions combined with personalized factor. Overall, our research makes a significant contribution to emotion analysis through the implementation of a novel fuzzy Transformer model. This model enhances emotion perception and advances the methods for analyzing emotional expression, thus setting an edge over prior studies.},
  archive      = {J_APIN},
  author       = {Liu, JianBang and Ang, Mei Choo and Chaw, Jun Kit and Ng, Kok Weng and Kor, Ah-Lian},
  doi          = {10.1007/s10489-024-05954-5},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-28},
  shortjournal = {Appl. Intell.},
  title        = {Personalized emotion analysis based on fuzzy multi-modal transformer model},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The impact of traffic accidents on traffic capacity in weaving area of highway under the intelligent connected vehicle environment. <em>APIN</em>, <em>55</em>(3), 1-20. (<a href='https://doi.org/10.1007/s10489-024-06097-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Connected automated vehicles (CAV) will become an important part of future traffic flows. In the highway weaving area, the road conditions are complex and the possibility of traffic accidents is relatively high. In this paper, a cellular automaton model of heterogeneous traffic flow weaving area of multi-lane expressway under accident conditions is proposed, in which three common accident types of rear-end accidents, lateral collisions and collisions with fixed obstacles are considered, and the influence of accidents on traffic flow in intelligent networked environment is simulated and analyzed. The following conclusions are obtained: (1) Collision with fixed obstacle accidents have the least impact on traffic flow in the weaving area, followed by rear-end collisions, and lastly, lateral collision type. (2) CAVs effectively alleviate the traffic congestion under accident conditions and improve the traffic capacity of the weaving area. At the same time, in order to give full play to the characteristics of CAVs, a longer weaving area is needed to improve the traffic capacity of the weaving area. (3) As the length of the weaving area increases, the traffic capacity of the weaving areas generally tends to increase. However, the traffic accidents occurring on the ramp greatly weaken the weaving characteristics of the vehicles in the weaving area, reducing the impact of the length of the weaving area on the traffic flow. Moreover, under the same type of traffic accident, the traffic capacity of traffic accidents occurring on the ramp is significantly higher than that of other lanes.(4) The traffic accidents occurring at the end of the weaving area have a greater negative impact on the traffic flow, especially the type of lateral collision accidents, which greatly diminish the traffic capacity of the weaving area, but the traffic accidents occurring on the ramp do not have such obvious negative effect.},
  archive      = {J_APIN},
  author       = {Ma, Wei and Qian, Yongsheng and Zeng, Junwei and Lei, Shufan and Wei, Xuting and Zhang, Futao},
  doi          = {10.1007/s10489-024-06097-3},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {The impact of traffic accidents on traffic capacity in weaving area of highway under the intelligent connected vehicle environment},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enterprise risk assessment model based on graph attention networks. <em>APIN</em>, <em>55</em>(3), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06103-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enterprise risk assessment not only provides a crucial reference for enterprises’ strategic and business decisions, but also forms a fundamental basis for the financing decisions of banks and other financial institutions. Furthermore, as a critical node within the industrial chain, the enterprise’s risk may directly affect the stability of the entire industrial chain, highlighting the significance of researching enterprise risk assessment. Existing enterprise risk assessment methods need to be revised to account for the risk transmission between enterprises across different types of relationships. Consequently, it leads to the need for more utilization of industrial chain structure and interaction information between enterprises. To address this problem, an enterprise risk assessment model, which is based on attention mechanism and graph network, is proposed. Firstly, weights of associated enterprises under a particular relationship are focused on. Then, weights of different relationships are introduced. After that, feature aggregation is conducted. Finally, features are put into the classification network to determine the risk category of the target enterprise, and enterprise risk assessment is accomplished. Experiments using dataset in integrated circuit industrial chain are conducted to verify this method, and the result shows that the method can effectively assess enterprise risk.},
  archive      = {J_APIN},
  author       = {Bi, Kejun and Liu, Chuanjie and Guo, Bing},
  doi          = {10.1007/s10489-024-06103-8},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Enterprise risk assessment model based on graph attention networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DuAGNet: An unrestricted multimodal speech recognition framework using dual adaptive gating fusion. <em>APIN</em>, <em>55</em>(3), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06119-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech recognition is a major communication channel for human-machine interaction with outstanding breakthroughs. However, the practicality of single-modal speech recognition is not satisfactory in high-noise or silent communication applications. Integrating multiple modalities can effectively address this problem, but existing fusion methods tend to pay excessive attention to the alignment of semantic features and the construction of fused features between modalities, omitting the preservation of single-modal characteristics. In this work, audio signals, visual clues of lip region images, and facial electromyography signals are used for unrestricted speech recognition, which can effectively resist the noise interference brought by single modalities. To preserve the unique feature expression of each speech modality and improve the global perception of the coupling correlations among them, a Dual Adaptive Gating fusion framework is proposed (dubbed DuAGNet), utilizing modality-specific and feature-specific adaptive gating networks. A multimodal speech dataset is constructed from forty subjects to validate the effectiveness of the proposed DuAGNet, covering three modalities of speech data and 100 classes of Chinese phrases. Both the highest recognition accuracy of 98.79% and lowest standard deviation of 0.83 are obtained with clean test data, and a maximum increase of accuracy over 80% is achieved, compared to audio speech recognition systems when introduced severe audio noise.},
  archive      = {J_APIN},
  author       = {Wu, Jinghan and Zhang, Yakun and Zhang, Meishan and Zheng, Changyan and Zhang, Xingyu and Xie, Liang and An, Xingwei and Yin, Erwei},
  doi          = {10.1007/s10489-024-06119-0},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {DuAGNet: An unrestricted multimodal speech recognition framework using dual adaptive gating fusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ULDC: Uncertainty-based learning for deep clustering. <em>APIN</em>, <em>55</em>(3), 1-16. (<a href='https://doi.org/10.1007/s10489-024-06125-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep clustering has gained prominence due to its impressive capability to handle high-dimensional real-world data. However, in the absence of ground-truth labels, existing clustering methods struggle to discern false positives that resemble the target cluster and false negatives that visually differ but maintain semantic consistency. The unreliable projections caused by visual ambiguity disrupt representation learning, leading to sub-optimal clustering outcomes. To address this challenge, we propose a novel method called uncertainty-based learning for deep clustering (ULDC), which aims to discover more optimal cluster structures within data from an uncertainty perspective. Specifically, we utilize the Dirichlet distribution to quantify the uncertainty of feature projections in the latent space, providing a probabilistic framework for modeling uncertainty during the clustering process. We then develop uncertainty-based learning to mitigate the interference caused by false positives and negatives in the clustering tasks. Additionally, a semantic calibration module is introduced to achieve a global alignment of cross-instance semantics, facilitating the learning of clustering-favorite representations. Extensive experiments on five widely-used benchmarks demonstrate the effectiveness of ULDC. The source code is available from https://github.com/YL616/ULDC .},
  archive      = {J_APIN},
  author       = {Chang, Luyao and Niu, Xinzheng and Li, Zhenghua and Zhang, Zhiheng and Li, Shenshen and Fournier-Viger, Philippe},
  doi          = {10.1007/s10489-024-06125-2},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {ULDC: Uncertainty-based learning for deep clustering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A tree-based framework to mine top-K closed sequential patterns. <em>APIN</em>, <em>55</em>(3), 1-29. (<a href='https://doi.org/10.1007/s10489-024-06137-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Top-K closed sequential pattern (CSP) mining addresses the challenge of reducing the number of mined patterns and the dependency on the support threshold parameter. This study tackles top-K CSP mining from three angles: top-K generic CSPs, group CSPs, and redundancy-aware CSPs. We propose the novel SP-Tree-based KCloTreeMiner to mine these variations and introduce the PaMHep data structure for efficient candidate pattern maintenance. Two pruning strategies—namely, pattern absorption and SP-Tree-based temporary node projection—are also presented to reduce search space. This study offers a thorough theoretical analysis and establishes bounds for the top-K framework, covering everything from solution design to completeness and optimization. Evaluations on six real-life datasets show up to a 23% average runtime improvement for KCloTreeMiner over the benchmark algorithm TKCS. We also propose two greedy algorithms $$Max_{WC}$$ and $$Max_{WOC}$$ for pattern summarization and introduce Subset Distance for measuring distances between sequential patterns, improving K-medoid clustering results over average silhouette-width for the reported clusters.},
  archive      = {J_APIN},
  author       = {Ahmed Rizvee, Redwan and Farhan Ahmed, Chowdhury and Leung, Carson K.},
  doi          = {10.1007/s10489-024-06137-y},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-29},
  shortjournal = {Appl. Intell.},
  title        = {A tree-based framework to mine top-K closed sequential patterns},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DIPE: A diagnosis-assisted inquiry point extractor towards medical dialogues. <em>APIN</em>, <em>55</em>(3), 1-13. (<a href='https://doi.org/10.1007/s10489-024-06138-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic knowledge extraction from medical dialogues has emerged as an increasingly significant problem in modern medical care. However, diagnosis characteristics of medical texts and imbalanced distribution of item categories within inquiry points are ignored in traditional methods used for medical information extraction, resulting in unsatisfactory performance. In this paper, we propose a Diagnosis-assisted Inquiry Point Extractor (DIPE), where a novel hierarchical attention mechanism, named WSWC (Word-Sentence-Window-Context), is devised to simulate diagnosis-oriented inference and further effectively captures semantic correlation in utterances. Additionally, we construct an imbalance-aware loss function to mitigate the imbalanced distribution of entity categories within inquiry points by assigning weights based on the disparity in sample counts for each category. Experimental results on two public datasets demonstrate that DIPE is an effective solution for inquiry point extraction in medical dialogues.},
  archive      = {J_APIN},
  author       = {Li, Qi and Huang, Faliang and Ge, Lin and Zhao, Jie},
  doi          = {10.1007/s10489-024-06138-x},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {DIPE: A diagnosis-assisted inquiry point extractor towards medical dialogues},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid vision transformer and residual neural network model for fall detection using UWB radars. <em>APIN</em>, <em>55</em>(3), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06156-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting falls presents a significant challenge for researchers, given the risk of serious injuries like femoral neck fractures, brain hemorrhages, or burns, which result in significant pain and, in some cases, worsen over time, leading to end-of-life complications or even fatalities. One approach to addressing this challenge involves promptly alerting caregivers, such as nurses, upon detecting a fall. In our work, we present a technique to detect falls within a 40-square-meter apartment by collecting data from three ultra-wideband radars. The presented technique combines a vision transformer and a residual neural network for fall identification, a binary classification task distinguishing between fall and non-fall events. To train and test the presented technique, we use data reflecting various fall types simulated by 10 participants across three locations in the apartment. We evaluated the performance of the presented technique in comparison with some base models by using the leave-one-subject-out strategy to demonstrate the generalization of experiment results in practical scenarios with new subjects. We also report our results by applying cross-validation to select a validation set, which highlights the effectiveness of the presented technique during the training phase and demonstrates the confidence of the obtained results in the testing phase. Consistently, the results illustrate the superior performance of the presented technique compared to the based models. Encouragingly, our results indicate nearly 99% accuracy in fall detection, demonstrating promising potential for real-world application.},
  archive      = {J_APIN},
  author       = {Abudalfa, Shadi and Bouchard, Kevin},
  doi          = {10.1007/s10489-024-06156-9},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {A hybrid vision transformer and residual neural network model for fall detection using UWB radars},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault diagnosis using deep neural networks for industrial alarm sequence clustering. <em>APIN</em>, <em>55</em>(3), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06161-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant progress has been made in the field of industrial alarm management systems (AMS) in terms of diagnostic and prognostic accuracy. However, persistent challenges, such as poorly configured alarm setups and floods, contribute to an increased number of false alarms, consequently reducing the efficiency of the monitoring system. In addition, more sophisticated models and interactive visualization tools are needed to support supervisors and maintenance operators. This paper proposes a novel approach based on deep learning that combines autoencoder and self-organizing maps to extract valuable features and a clustering algorithm to identify related alarm groups. This bi-level methodology is applied to real manufacturing system datasets, demonstrating its effectiveness in identifying false alarms, reducing alarm sequence interpretation time, enhancing understanding of alarm interrelationships, and providing a basis for causal analysis and root cause identification. The approach also compares favorably with the classical methods in the literature, laying the foundation for improved industrial safety management. The system also offers maintenance recommendations to decision makers, further validating alarm sequences.},
  archive      = {J_APIN},
  author       = {Benatia, Mohamed Amin and Chabane, Ahmed Nait and Sahnoun, M’hammed and Bettayeb, Belgacem},
  doi          = {10.1007/s10489-024-06161-y},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Fault diagnosis using deep neural networks for industrial alarm sequence clustering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient convolutional dual-attention transformer for automatic modulation recognition. <em>APIN</em>, <em>55</em>(3), 1-16. (<a href='https://doi.org/10.1007/s10489-024-06202-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic modulation recognition (AMR) involves identifying the modulation of electromagnetic signals in a noncollaborative manner. Deep learning-based methods have become a focused research topic in the AMR field. Such models are frequently trained using standardized data, relying on many computational and storage resources. However, in real-world applications, the finite resources of edge devices limit the deployment of large-scale models. In addition, traditional networks cannot handle real-world signals of varying lengths and local missing data. Thus, we propose a network structure based on a convolutional Transformer with a dual-attention mechanism. This proposed structure effectively utilizes the inductive bias of the lightweight convolution and the global property of the Transformer model, thereby fusing local features with global features to get high recognition accuracy. Moreover, the model can adapt to the length of the input signals while maintaining strong robustness against incomplete signals. Experimental results on the open-source datasets RML2016.10a, RML2016.10b, and RML2018.01a demonstrate that the proposed network structure can achieve 95.05%, 94.79%, and 98.14% accuracy, respectively, with enhancement training and maintain greater than 90% accuracy when the signals are incomplete. In addition, the proposed network structure has fewer parameters and lower computational cost than benchmark methods.},
  archive      = {J_APIN},
  author       = {Yi, Zengrui and Meng, Hua and Gao, Lu and He, Zhonghang and Yang, Meng},
  doi          = {10.1007/s10489-024-06202-6},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Efficient convolutional dual-attention transformer for automatic modulation recognition},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse low-redundancy multi-label feature selection with adaptive dynamic dual graph constraints. <em>APIN</em>, <em>55</em>(3), 1-18. (<a href='https://doi.org/10.1007/s10489-024-06205-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the introduction of manifold learning, graph-based multi-label feature selection has received much attention and achieved state-of-the-art performance. However, improving the graph quality is still a problem that needs to be solved urgently. In addition, existing methods only focus on correlation learning and ignore the feature redundancy problem. To solve these problems, we design an adaptive dynamic graph learning method (ADG), which obtains high-quality dynamic similarity graphs by constraining the Laplacian rank of similarity graphs. Moreover, high-quality dynamic redundancy graphs can also be obtained using ADG, which can better solve the feature redundancy problem. Then, using the $$L_{2,1}$$ norm as a sparsity constraint, we propose sparse low-redundant multi-label feature selection (SLADG) with adaptive dynamic dual-graph constraints, and design an efficient scheme to optimize SLADG. Finally, experimental results on eleven publicly available data demonstrate that ADG can obtain high-quality dynamic graphs, and relative to existing state-of-the-art methods, SLADG improves overall performance by an average of at least 3.0427% across the seven evaluated metrics.},
  archive      = {J_APIN},
  author       = {Wu, Yanhong and Bai, Jianxia},
  doi          = {10.1007/s10489-024-06205-3},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Sparse low-redundancy multi-label feature selection with adaptive dynamic dual graph constraints},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSDCNet: Multi-stage and deep residual complementary multi-focus image fusion network based on multi-scale feature learning. <em>APIN</em>, <em>55</em>(3), 1-22. (<a href='https://doi.org/10.1007/s10489-024-05983-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing the boundary blurring problem in focus and out-of-focus regions is a key area of research in multifocus image fusion. Effective utilization of multi-scale modules is essential for enhancing performance. Therefore, this paper proposes a multi-stage feature extraction and deep residual complementary multifocus image fusion network. In the feature extraction stage, the V-shaped connection module captures the main objects and contours of the image. The feature thinning extraction module uses extended convolution to learn image details and refine textures at multiple scales. The advanced feature texture enhancement module targets boundary blurring regions, enhancing texture details and improving fusion quality. Asymmetric convolution reduces the network’s computational burden, improving feature learning efficiency. The fusion strategy uses a compound loss function to ensure image quality and prevent color distortion. The image reconstruction module uses residual connections with different-sized convolution kernels to maintain feature consistency and improve image quality. The network utilizes a dual-path Pseudo-Siamese structure, which handles image focus and defocus regions separately. Experimental results demonstrate the algorithm’s effectiveness. On the Lytro dataset, it achieves AG and EI metric values of 6.9 and 72.5, respectively, outperforming other methods. Fusion metrics SD = 61.80, SF = 19.63, and VIF = 0.94 surpass existing algorithms, effectively resolving the boundary blurring problem and providing better visual perception and broader applicability.},
  archive      = {J_APIN},
  author       = {Hu, Gang and Jiang, Jinlin and Sheng, Guanglei and Wei, Guo},
  doi          = {10.1007/s10489-024-05983-0},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {MSDCNet: Multi-stage and deep residual complementary multi-focus image fusion network based on multi-scale feature learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic-simulation-based multi-attribute group decision-making method under uncertain environment and the application. <em>APIN</em>, <em>55</em>(3), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06096-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For multi-attribute group decision-making with interval uncertainties, this paper proposes a stochastic-simulation-based multi-attribute group decision-making model that considers the relative superiority or inferiority between any two alternatives for a comprehensive evaluation. First, a novel attribute weights method is proposed by reducing the decision uncertainty based on the stochastic simulation method, where the uncertainty is determined by the superiority or inferiority of pairwise comparisons of alternatives on the associated attribute. Based on this, the attribute weights are calculated using a programming model that aims to minimise the uncertainty between the alternatives and the ideal state. The uncertain attribute values provided by each expert are aggregated into individual possibility rankings. Subsequently, a novel information aggregation method that considers group consensus is introduced, in which the consensus level among all experts is measured based on individual possibility rankings. The consensus measurement of individual possibility rankings allows to identify high- and low-consensus decision-making information within expert judgements. This process facilitates recognition of the consensus quality of each expert’s decision-making information. The final possibility-ranking is then aggregated based on the consensus quality of the various possibility decision-making information. Finally, this study uses a numerical example of the evaluation of a company's performance to demonstrate the effectiveness and application of the proposed method.},
  archive      = {J_APIN},
  author       = {Yi, Pingtao and Wang, Shiye and Li, Weiwei},
  doi          = {10.1007/s10489-024-06096-4},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Stochastic-simulation-based multi-attribute group decision-making method under uncertain environment and the application},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of circRNA-drug sensitivity using random auto-encoders and multi-layer heterogeneous graph transformers. <em>APIN</em>, <em>55</em>(3), 1-18. (<a href='https://doi.org/10.1007/s10489-024-05859-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A growing evidence has demonstrated that the expression of circRNAs have significant impact on cell sensitivity to drugs, thereby affecting drug efficacy. Several computational methods have been developed to identify potential circRNA-drug sensitivity associations based on graph auto-encoder and multi-modal information of circRNA and drugs. However, multi-modal information may still lead to a local embedding representation space. And the graph auto-encoder is easy to neglect the global information of the whole graph. Thus, the predictive performance of existing methods is still not satisfactory and needs improvement. In this study, we introduce a model named MHGTCDA for forecasting potential circRNA-drug sensitivity associations using adaptive random auto-encoders (RAEs) and multi-layer Heterogeneous Graph Transformers (MHGT). Firstly, random auto-encoders are used to encode the circRNAs and drugs, respectively. Secondly, MHGT framework is used to obtain context representation of the nodes, which directly utilizes the edge information of the bipartite graph composed of circRNA-drug pairs, thereby reducing information loss. Then, the concatenated embedding matrices of circRNAs and drugs from MHGT are decoded through inner product to obtain the predicted circRNA-drug sensitivity associations. Extensive cross-validation experiments demonstrate that MHGTCDA outperforms nine other state-of-the-art methods. Case studies further illustrate the excellent predictive ability of the proposed method. These results highlight the potential of MHGTCDA as a valuable method for predicting circRNA-drug sensitivity associations, offering significant benefits to drug development.},
  archive      = {J_APIN},
  author       = {Liu, Yinbo and Ren, Xinxin and Li, Jun and Chen, Xiao and Zhu, Xiaolei},
  doi          = {10.1007/s10489-024-05859-3},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Prediction of circRNA-drug sensitivity using random auto-encoders and multi-layer heterogeneous graph transformers},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A malware visualization method based on transition probability matrix suitable for imbalanced family classification. <em>APIN</em>, <em>55</em>(3), 1-23. (<a href='https://doi.org/10.1007/s10489-024-05911-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information technology brings us not only marvelous convenience and productivity, but also potential insecure factor, which may pose threats to our properties, data or even reputation. Malicious software is exactly an accomplice of such attacks. Fundamentally, the key step to deal with malicious software is to accurately identify and classify it. Although traditional static and dynamic analysis approaches could accomplish this task to some extent, they have intrinsic defects in terms of variant feature exaction, vulnerability to code obfuscation and encryption, or excessive resource consumption. Recently, CNN-based malware classification methods, which employ CNN models to classify visualized malware images, provide a promising way to accomplish malware classification tasks. However, most mainstream CNN models require inputs with a fixed size, while various sizes of original malware samples frequently lead to various sizes of malware visualization images. Simply resizing these images causes losses of malware features, resulting in drops of classification accuracy. In this paper, we propose a malware visualization method based on transition probabilities of malware operation codes to generate proper images with a uniform size as inputs for CNN models. As a result, the conventional resizing operations could be avoided. The proposed method is compatible with most mainstream CNN models. Moreover, the proposed method could address problems concerning insufficient or imbalanced datasets, which may challenge the classification abilities of CNN models. Experimental results demonstrate the excellent compatibility and classification performance of the proposed method in terms of accuracy, precision, recall and F1-score. For reproducible research, the source codes and training models of the proposed method are available at https://github.com/xchuxiao23/mal_cls .},
  archive      = {J_APIN},
  author       = {Wu, Wei and Peng, Haipeng and Xu, Chuxiao and Liu, Yuhong and Li, Lixiang},
  doi          = {10.1007/s10489-024-05911-2},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {A malware visualization method based on transition probability matrix suitable for imbalanced family classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DFW-PVNet: Data field weighting based pixel-wise voting network for effective 6D pose estimation. <em>APIN</em>, <em>55</em>(3), 1-14. (<a href='https://doi.org/10.1007/s10489-024-05942-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the benefit of reduced memory and computational overhead, the sparse-based 6 degrees-of-freedom (6D) pose estimation method leverages the creation of sparse two-dimensional (2D) to three-dimensional (3D) correspondences to estimate the pose of objects in an RGB image. However, this method often leads to accuracy degradation. In this paper, we propose a data field weighting based pixel-wise voting network (DFW-PVNet), aiming at improving the accuracy of the 6D pose estimation while keeping excellent memory and computational overheads. The proposed DFW-PVNet first assigns potential weights to pixels at different positions by utilizing data field theory and then selects the pixels with higher potential weights to participate in the voting and locating of 2D keypoints. By building accurate sparse 2D-3D correspondences between the located 2D keypoints and the corresponding predefined 3D keypoints, the 6D pose of the object can be calculated through a perspective-n-point (PnP) solver. Experiments are conducted based on the LINEMOD and the Occlusion LINEMOD datasets, and the results show that the accuracy of the proposed method surpasses the state-of-the-art sparse-based methods and is comparable to dense-based methods but with significantly lower memory and computational overheads.},
  archive      = {J_APIN},
  author       = {Lu, Yinning and Pei, Songwei},
  doi          = {10.1007/s10489-024-05942-9},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {DFW-PVNet: Data field weighting based pixel-wise voting network for effective 6D pose estimation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Video authentication detection using deep learning: A systematic literature review. <em>APIN</em>, <em>55</em>(3), 1-30. (<a href='https://doi.org/10.1007/s10489-024-05997-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in deep learning have notably influenced research across various data types, with a significant focus on video authentication. This area has emerged as a crucial aspect of ensuring the integrity and trustworthiness of video content amidst growing concerns over manipulation and falsification. It is emerging as a field ripe for exploration. This paper presents a systematic literature review (SLR) on using deep learning techniques for video authentication, addressing the urgent need for robust methods to verify video integrity amidst increasing manipulation threats. Reviewing literature from the past five years, this SLR reviews 99 research articles from the last five years and highlights the significant progress made through deep learning techniques (Convolution Neural Network (CNN), Recurrent Neural Network (RNN), Deep Neural Network (DNN), and Generative Adversarial Networks (GANs)). It aims to investigate applications, techniques, datasets, and challenges in video authentication, providing a comprehensive guide for researchers. This study encompasses a broad range of research articles, identifying key advancements and trends in combating video manipulation and focusing on maintaining digital media trustworthiness.},
  archive      = {J_APIN},
  author       = {Alrawahneh, Ayat Abd-Muti and Abdullah, Sharifah Nurul Asyikin Syed and Abdullah, Siti Norul Huda Sheikh and Kamarudin, Nazhatul Hafizah and Taylor, Sarah Khadijah},
  doi          = {10.1007/s10489-024-05997-8},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-30},
  shortjournal = {Appl. Intell.},
  title        = {Video authentication detection using deep learning: A systematic literature review},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tracking-removed neural network with graph information for classification of incomplete data. <em>APIN</em>, <em>55</em>(3), 1-20. (<a href='https://doi.org/10.1007/s10489-024-06031-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the real world, the presence of missing values brings a challenge to the classification, and missing value imputation is often inseparably involved in classification for incomplete data. In this paper, we propose a tracking-removed neural network with graph information for solving the classification problem of incomplete data. Specifically, we redesign the hidden layer neuron structure of the autoencoder to improve the network’s ability to mine associations among attributes. Graph information, which is used to analyze the similarity among samples, is introduced into the above tracking-removed neural network to further improve the network’s imputation performance for missing values. On the basis of appropriate imputation, the output layer neurons of the proposed network are reorganized to achieve the mapping of incomplete data to classification. Moreover, we present a learning algorithm that regards the missing values as variables and co-trains them with the network parameters for the designed model. The proposed strategy enables all the existing attribute information in incomplete datasets to participate in network training, which promotes the network to match the classification and regression structure of incomplete data, thereby improving the classification performance of the model for incomplete data. The experiments on 6 public datasets verify the effectiveness of the proposed method.},
  archive      = {J_APIN},
  author       = {Lai, Xiaochen and Zhang, Zheng and Chen, Hui and Zhang, Liyong and Li, Zhuohan and Lu, Wei},
  doi          = {10.1007/s10489-024-06031-7},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Tracking-removed neural network with graph information for classification of incomplete data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mapless autonomous navigation for UGV in cluttered off-road environment with the guidance of wayshowers using deep reinforcement learning. <em>APIN</em>, <em>55</em>(3), 1-25. (<a href='https://doi.org/10.1007/s10489-024-06054-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Navigating unmanned ground vehicle (UGV) through off-road environments is critical for various tasks like exploration and rescue. Unlike scenarios allowing offline global planning based on prior knowledge, online navigation becomes essential due to the dynamic nature of these tasks. Although deep reinforcement learning (DRL) offers promise for mapless autonomous navigation due to its end-to-end advantages, existing approaches often rely solely on goal positions. This neglects the complex distribution of obstacles along the path, leading to inefficient interactions with the environment during training. To address this challenge, a deep reinforcement learning framework is proposed for autonomous navigation guided by wayshowers. Initially, a new metric is developed based on multilevel analysis to generate elevation maps, aiding in the identification of optimal wayshowers. Upon integrating wayshower information with other inputs, a multi-head attention (MHA) module is incorporated into DRL network, which includes a length attention mechanism to enhance focus on recent historical observation sequences to promote model convergence. Furthermore, the reward function is reshaped to offer dense reward signals, thereby resolving the sparse reward problem inherent in goal-driven methods. To validate the proposed approach, experiments are conducted on several off-road maps in both the Carla and Gazebo simulators. The results demonstrate the superiority of our method not only in simple environments but also in more challenging scenarios.},
  archive      = {J_APIN},
  author       = {Li, Zhijian and Li, Xu and Hu, Jinchao and Liu, Xixiang},
  doi          = {10.1007/s10489-024-06054-0},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {Mapless autonomous navigation for UGV in cluttered off-road environment with the guidance of wayshowers using deep reinforcement learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge graph relation prediction based on graph transformation. <em>APIN</em>, <em>55</em>(3), 1-18. (<a href='https://doi.org/10.1007/s10489-024-06080-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph relation prediction aims to predict the missing relation between entities. Many existing graph neural network (GNN)-based relation prediction models suffer from over-parameterization, and some models cannot effectively learn the correlation between relations for the relation prediction task. In order to solve the above problems, we propose a knowledge graph relation prediction model based on graph transformation. We use two kinds of graph transformation and a parallel fusion model to learn the semantic information, which effectively reduces the number of parameters and reduces the loss of semantic information compared to the Levi graph. Then, we utilize the self-attention mechanism to learn the correlation between relations, and combine it with the DistMult scoring function to complete the relation prediction task. Experiments on four real-world datasets WN18RR, CoDEx-S, Kinship, and FB15K-237 show that our model achieved a better balance between the number of parameters and prediction performance compared to existing GNN-based models on most datasets.},
  archive      = {J_APIN},
  author       = {Liu, Linlan and Huang, Weide and Shu, Jian and Zhao, Hongjian},
  doi          = {10.1007/s10489-024-06080-y},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Knowledge graph relation prediction based on graph transformation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complex product network change prediction method based on GANs with small sample data. <em>APIN</em>, <em>55</em>(3), 1-13. (<a href='https://doi.org/10.1007/s10489-024-06108-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex product network change prediction can significantly reduce product redesign time. The accuracy of change predictions often depends on the richness of the historical sample data of this product. Aiming at the problems of less change data and low prediction accuracy in product design change prediction, this paper proposes an improved generative adversarial network using multiple discriminators based on real historical data and generated data called sdrgGAN to improve the data generation. Generated data and real historical data both are applied in the product intensity prediction. The proposed sdrgGAN has improved the multi-feature fusion ability based on feature similarity. The discriminator part is composed of several discriminators. This design improves the discriminant ability of the discriminator and is helpful in generating more realistic data. In the experiment, real historical change data of a TV set is applied. Convolutional Neural Network (CNN) and Long Short Memory Model (LSTM) are used for the prediction of a product change intensity. The experimental results demonstrate the effectiveness of the designed GANs in dealing with small sample problems.},
  archive      = {J_APIN},
  author       = {Wang, Hongmei and Liu, Shuo and Zhang, Song and Wang, Faguang and Li, Shiyin},
  doi          = {10.1007/s10489-024-06108-3},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Complex product network change prediction method based on GANs with small sample data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FAHC: Frequency adaptive hypergraph constraint for collaborative filtering. <em>APIN</em>, <em>55</em>(3), 1-15. (<a href='https://doi.org/10.1007/s10489-024-06111-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) exhibit superior recommendation performance with their powerful capability of representing complex relationships. However, existing methods encounter two key challenges: (1) The high-frequency signals on graphs are momentous, but the graph convolutional networks cannot adaptively capture the different combinations of various frequency features (i.e., high-frequency and low-frequency signals) simultaneously. (2) GNNs can only integrate the adjacency node features (i.e., pairwise relation), but non-adjacent nodes are also correlated in the user-item interaction graph (i.e., the high-order interaction). To address these challenges, this study explores Frequency Adaptive Hypergraph Constraint for Collaborative Filtering (FAHC). Specifically, FAHC mainly consists of frequency adaptive graph convolutional networks and hypergraph convolutional networks. The frequency adaptive convolutional network can automatically and effectively capture the different combinations of various frequency signals on the graph. Then, we combine the frequency adaptive graph convolutional network with the hypergraph convolutional network to learn the local and global node features. Furthermore, we propose a novel constraint loss, which can help achieve better recommendation performance. The experiments indicate that FAHC improves the other baselines implemented on three published datasets, with the maximum improvement being over 90%. All source codes can be accessed at https://github.com/tangyu-ty/FAHC.},
  archive      = {J_APIN},
  author       = {Tang, Yu and Peng, Lilan and Wu, Zhendong and Hu, Jie and Zhang, Pengfei and Lu, Hongchun},
  doi          = {10.1007/s10489-024-06111-8},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {FAHC: Frequency adaptive hypergraph constraint for collaborative filtering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complex product quality prediction method based on an improved light gradient boosting machine. <em>APIN</em>, <em>55</em>(3), 1-20. (<a href='https://doi.org/10.1007/s10489-024-06112-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality prediction, as a means of identifying potential quality issues in products, plays a crucial role in increasing the level of quality control within enterprises. The data from the process of manufacturing complex products exhibit characteristics of high dimensionality, strong correlation, and imbalance, which pose certain challenges to achieving accurate quality prediction for complex products, especially in intervals with sparse sample distributions. To improve the accuracy of quality prediction for complex products, this paper proposes a complex product quality prediction model based on cost-sensitive learning and gradient boosting decision trees (GBDTs). Initially, eXtreme gradient boosting (XGBoost) is employed to select the optimal feature subset from the original high-dimensional data. A mapping relationship between the manufacturing process data and quality characteristic values is subsequently established on the basis of a light gradient boosting machine (lightGBM) model. On this basis, cost-sensitive learning is introduced, and a new loss function named DenseMSE is designed for the lightGBM model, establishing a quality prediction model based on DenseMSE–lightGBM. The experimental results demonstrate that the proposed quality prediction model has improved the prediction accuracy in intervals with sparse samples. Moreover, the accuracy of the quality prediction model based on DenseMSE–lightGBM surpasses that of other mainstream prediction models, providing meaningful guidance for achieving more accurate quality prediction for complex products.},
  archive      = {J_APIN},
  author       = {Zheng, Haiyang and Gao, Xinqin and Yang, Mingshun and Yang, Xueqi and Li, Yan and Ding, Yongming},
  doi          = {10.1007/s10489-024-06112-7},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Complex product quality prediction method based on an improved light gradient boosting machine},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automation of observational gait assessment through an optical 3D motion system and transformers. <em>APIN</em>, <em>55</em>(3), 1-21. (<a href='https://doi.org/10.1007/s10489-024-06163-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessment of human gait is a useful diagnostic tool for identifying musculoskeletal abnormalities and disorders. Most clinicians use qualitative approaches based on visual observations to analyze gait, leading to repetitive exercises that require subjective evaluation. This study proposes a system to automate and objectify traditional observational gait tests using a transformer encoder network that analyzes data captured with a 3D optical motion system. This preliminary study focused on the Tinetti test, or Performance-Oriented Mobility Assessment for gait evaluation (POMA-G), using data collected with an OptiTrack camera system. An optical motion capture system consisting of eight OptiTrack Prime 13-W cameras, sampled at 60 Hz and synchronized with the Clinical 3D Motion Analysis (3DMA) software was used. Anthropometric measurements of the participants were recorded and their gait movements were captured while simulating various pathologies evaluated in the POMA-G test. The algorithms were designed and implemented in an artificial neural network model based on transformer process information to monitor and classify the gait components. On average, the machine learning models achieved an accuracy of 97.56% ± 4.79%, F1 score of 96.39% ± 7.95%, and area under the receiver operating characteristic curve (AUC-ROC) value of 99.29% ± 1.81%, demonstrating a high capability to identify and classify the gait components evaluated using the POMA-G scale. Automating the observational evaluation of gait using a 3D optical motion system and machine learning methods offers a quantitative and objective approach to gait analysis. This system not only promises to facilitate more accurate diagnoses and effectively monitor gait-related disorders, but also highlights the potential of motion capture technology and machine learning for clinical gait assessment. This study establishes a foundation for future research aimed at improving the accuracy and applicability of automatic gait assessment tools.},
  archive      = {J_APIN},
  author       = {Carneros-Prado, David and González-Velázquez, Sergio and Dobrescu, Cosmin C. and González, Iván and Fontecha, Jesús and Hervás, Ramón},
  doi          = {10.1007/s10489-024-06163-w},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Automation of observational gait assessment through an optical 3D motion system and transformers},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attribute selection for incomplete decision systems by maximizing correlation and independence with mutual granularity. <em>APIN</em>, <em>55</em>(3), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06170-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough set theory has been widely used in attribute selection. However, there are few researchers who have explored the relationship between attributes from the perspective of knowledge granularity. Additionally, existing attribute selection methods are mostly tailored for complete decision systems and are not applicable to incomplete ones. In light of the aforementioned challenge, this paper primarily focuses on addressing the issue of attribute selection for incomplete decision systems by utilizing the correlation among attributes formed through knowledge granularity. Firstly, the concept of mutual granularity is defined by introducing discernment granularity and conditional discernment granularity into incomplete decision systems. Secondly, an attribute selection algorithm based on mutual granularity is presented for incomplete decision systems. Thirdly, a novel method for enhancing mutual granularity is proposed, which takes into account both the independence and correlation among candidate and selected attributes, with the aim of quantifying the uncertainty inherent in incomplete decision systems. Fourthly, an attribute selection algorithm based on enhanced mutual granularity is proposed. Finally, experimental results show that the proposed attribute selection method can effectively select the more relevant attributes with lower redundancy, thereby demonstrating strong classification capabilities when applied to incomplete decision systems.},
  archive      = {J_APIN},
  author       = {Zhang, Chucai and Zhang, Yongkang and Dai, Jianhua},
  doi          = {10.1007/s10489-024-06170-x},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Attribute selection for incomplete decision systems by maximizing correlation and independence with mutual granularity},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced hybrid adaptive physics-informed neural network for forward and inverse PDE problems. <em>APIN</em>, <em>55</em>(3), 1-20. (<a href='https://doi.org/10.1007/s10489-024-06195-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed neural networks (PINNs) have emerged as a powerful tool for solving partial differential equations (PDEs) in various scientific and engineering applications. PINNs integrate the PDEs into the loss functions of neural networks through automatic differentiation, which comprises a weighted combination of the PDE residuals, boundary and initial constraints, and observed data. However, the accuracy and efficiency of PINNs need substantial improvement to meet the requirements across a wider range of challenging problems. In this paper, we propose a hybrid adaptive (HA) sampling method and a feature embedding layer for PINN. The spatiotemporal points for PINN training (called residual points) are resampled during iteration procedure via the proposed HA method. The HA method ensures randomness in the selection of points while also prioritizing those with large PDE residuals, thereby ensuring efficient training by focusing the network’s learning on areas where the model’s predictions are less accurate. Moreover, the vanilla PINN architecture is further enhanced by a feature embedding layer, which transforms the raw input into a higher-dimensional space, enabling the network to better capture complex relationships underlying in PDEs and improve its fitting ability. The numerical experiments on a variety of forward and inverse PDE problems have shown that the proposed methods significantly improve the accuracy and efficiency of PINN with reduced reliance on the number of sampling points. The L2 relative error of vanilla PINN can be reduced by approximately 1 $$\sim $$ 2 orders of magnitude and the proposed methods outperform state-of-the-art baselines.},
  archive      = {J_APIN},
  author       = {Luo, Kuang and Liao, Shaolin and Guan, Zhong and Liu, Baiquan},
  doi          = {10.1007/s10489-024-06195-2},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {An enhanced hybrid adaptive physics-informed neural network for forward and inverse PDE problems},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention mechanism fusion neural network for typhoon path prediction. <em>APIN</em>, <em>55</em>(3), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06196-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timely and accurately predicting typhoon movement paths is essential to prevent typhoon disasters and reduce property losses. However, the existing typhoon path prediction models have weak spatiotemporal correlation feature extraction capabilities and insufficient consideration of the importance of different dimensional features, resulting in low prediction accuracy. In this paper, we propose an attention mechanism-based fusion neural network prediction model for typhoon paths to address this issue. This model first uses a Temporal Convolutional Network (TCN) with residual units (R-TCN) to extract time-dependent features from typhoon trajectory data. Then, we propose a fusion self-attention-based ResNeXt-50 model (AT-ResNeXt-50) to obtain position attention between atmospheric data image channels, thus having better spatiotemporal feature extraction capabilities. Finally, we use attention aggregation to automatically weigh and fuse the two data features, achieving high-precision typhoon path prediction based on multidimensional feature data. The experimental results show that our model has higher accuracy and is significantly superior to the several existing data-driven typhoon path prediction methods.},
  archive      = {J_APIN},
  author       = {Qiao, Baiyou and Wang, Yu and Yao, Laigang and Han, Donghong and Wu, Gang},
  doi          = {10.1007/s10489-024-06196-1},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Attention mechanism fusion neural network for typhoon path prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSTSPYN: A dynamic spatial-temporal similarity pyramid network for traffic flow prediction. <em>APIN</em>, <em>55</em>(3), 1-23. (<a href='https://doi.org/10.1007/s10489-024-06198-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction plays a crucial role in intelligent transportation systems as it enables effective control and management of urban traffic. However, existing methods that based on Graph Convolutional Networks (GCNs) primarily utilize local neighborhood information for message passing, resulting in limited perception of global structures. Additionally, it is also a challenge to extract spatial-temporal similarity features due to the constraints of graph structures. To address these issues, we propose a novel traffic flow prediction model based on Dynamic Spatial-Temporal Similarity Pyramid Network (DSTSPYN). Our model employs a spatial-temporal pyramid architecture, which dynamically adjusts the weights of central, edge, and global spatial-temporal features using an enhanced attention mechanism. Furthermore, it captures dynamic temporal dependencies at different scales through pyramid gated convolution. Meanwhile, the spatial similarity features of different time steps can be extracted through the spatial-temporal global similarity (STGS) module. We evaluate our model on four public transportation datasets and demonstrate that the DSTSPYN model outperforms several baseline methods in terms of prediction accuracy. It effectively captures the dynamic spatial-temporal correlations of the road network and edge node features, making it well-suited for long-term traffic flow prediction.},
  archive      = {J_APIN},
  author       = {Wang, Xing and Chen, Feifei and Jin, Biao and Lin, Mingwei and Zou, Fumin and Zeng, Ruihao},
  doi          = {10.1007/s10489-024-06198-z},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {DSTSPYN: A dynamic spatial-temporal similarity pyramid network for traffic flow prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NP-FedKGC: A neighbor prediction-enhanced federated knowledge graph completion model. <em>APIN</em>, <em>55</em>(3), 1-16. (<a href='https://doi.org/10.1007/s10489-024-06201-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) are often incomplete, omitting many existing facts. To address this issue, researchers have proposed many knowledge graph completion (KGC) models to fill in the missing triples. A full KG often consists of interconnected local KGs from multiple organizations, forming a cross-domain KG. Federated learning enables the effective utilization of the entire cross-domain KG for training a federated KGC model, rather than relying solely on a local KG from a single client. However, the existing methods often neglect the latent information among local KGs. Therefore, we propose a neighbor prediction-enhanced federated knowledge graph completion (NP-FedKGC) model to improve KGC by mining latent information. Specifically, we first obtain embeddings of entities and relations from multiple clients’ local KGs. Second, we employ the obtained embeddings as labels to train a respective neighbor prediction model for each client. Subsequently, the neighbor prediction model is applied to enhance each client’s local KG. Third, the enhanced local KGs of all clients are used to train the final federated KGC model. Comprehensive experimental results show that the proposed NP-FedKGC model outperforms three baseline models, FedE, FedR, and FedM, at MRR and Hits@1/3/10.},
  archive      = {J_APIN},
  author       = {Liu, Songsong and Li, Wenxin and Song, Xiao and Gong, Kaiqi},
  doi          = {10.1007/s10489-024-06201-7},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {NP-FedKGC: A neighbor prediction-enhanced federated knowledge graph completion model},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced stacking models for machine fault diagnosis with ensemble trees and SVM. <em>APIN</em>, <em>55</em>(3), 1-12. (<a href='https://doi.org/10.1007/s10489-024-06206-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis plays an integral role in machine health monitoring. However, in practical applications, there are obvious differences in class distribution within the data, leading to poor performance of the algorithm in identifying a few classes. Meanwhile, overfitting and computational resource requirements have become a challenge. Recently, the stacking model has been promoted in the field of fault diagnosis, but its performance evaluation of stacking models in many literature is not comprehensive enough. In this paper, an Advanced Ensemble Trees model (AET) is proposed. The SMOTE (Synthetic Minority Oversampling Technique) resampling technique is used to optimise the dataset balance. Then, the advantages of Support Vector Machines (SVM) and multi-tree models are combined to form a robust base model using hyper-parameter tuning. Simple Logistic Regression (LR) is used as a meta-model to construct the new stacking model. Through extensive experimental validation, it is found that the AET model is close to 99% in several key performance metrics and outperforms existing machine learning methods and relatively short model training time.},
  archive      = {J_APIN},
  author       = {Liao, Yuhua and Li, Ming and Sun, Qingshuai and Li, Pude},
  doi          = {10.1007/s10489-024-06206-2},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {Advanced stacking models for machine fault diagnosis with ensemble trees and SVM},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parameters security strategy formulated by hyperchaos in federal learning. <em>APIN</em>, <em>55</em>(3), 1-12. (<a href='https://doi.org/10.1007/s10489-024-06209-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a machine learning framework that effectively provides multiple organizations with data usage and model training while meeting the requirements of privacy protection, data security and government regulations. However, the leakage of parameters frequently occurred in the process of their exchange. Existing parametric encryption algorithms, such as differential privacy and homomorphic encryption, can significantly elevate privacy protection levels but always bring negative effect to the convergence performance of the final model or huge time consuming for practical application. Therefore, this paper propose a new encryption and decryption algorithm based on the hyperchaotic system, called bit and parameter correlation permutation (BCP), which helps to protect the parameters through the upload and download process, and such algorithm is compatible with any hyperchaotic map. With this method, we could guarantee the security without any sacrifices of model accuracy in a shorter period of time. Finally, the proposed algorithm achieves a time complexity of O( $$N^2$$ ) and offers a 0.69 reduction in loss for FL when compared with the differential privacy, while both ensure high security. Additionally, BCP can yield a difference of $$10^{50}$$ orders of magnitude, even with inputs differing by only $$10^{-11}$$ .},
  archive      = {J_APIN},
  author       = {Yang, Zhen and Yang, Tiancheng and Li, Shouliang and Li, Huale},
  doi          = {10.1007/s10489-024-06209-z},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {Parameters security strategy formulated by hyperchaos in federal learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BHRAM: A knowledge graph embedding model based on bidirectional and heterogeneous relational attention mechanism. <em>APIN</em>, <em>55</em>(3), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06212-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding (KGE) is a method designed to predict missing relations between entities in a knowledge graph (KG), which has garnered much attention in recent years due to the incompleteness of KGs. However, existing KGE models have limitations in dealing with heterogeneous KGs and relation direction prediction. To address this issue, a novel KGE model called BHRAM is proposed. It is based on a bidirectional and heterogeneous relational attention mechanism. Specifically, BHRAM comprises three primary components, namely entity aggregation, relation aggregation and triplet prediction. The entity aggregation module divides the adjacency matrix into original and reverse relation adjacency matrices, using graph convolution to aggregate node features and subsequently form entity embedding representations. The relation aggregation module leverages bidirectional relations for feature extraction, learns the weight information of diverse paths independently and generates embedding representations of relation paths through an aggregation function. Finally, the triplet prediction module utilizes a score function for probabilistic predictions. To validate the superiority of BHRAM, comprehensive experiments were conducted on four well-known datasets, including baseline comparisons, relation classification tasks and ablation study. The results demonstrate that BHRAM significantly outperforms the other baselines on the FB15k-237, Kinship and UMLS datasets, while achieving similar or better performance than the baselines on the WN18RR dataset. These findings indicate that BHRAM can serve as a robust and effective model for addressing the heterogeneity in KGs.},
  archive      = {J_APIN},
  author       = {Zhang, Chaoqun and Li, Wanqiu and Mo, Yuanbin and Tang, Weidong and Li, Haoran and Zeng, Zhilin},
  doi          = {10.1007/s10489-024-06212-4},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {BHRAM: A knowledge graph embedding model based on bidirectional and heterogeneous relational attention mechanism},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incremental classification of remote sensing images using feature pyramid and class hierarchy enhanced by label relationship graphs. <em>APIN</em>, <em>55</em>(3), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06216-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incremental learning is a machine learning strategy that enables the integration of new data to address emerging tasks without retraining the model from scratch. This approach retains previously acquired knowledge and conserves resources, yet it faces the challenge of catastrophic forgetting. Hierarchical classification (HC) improves accuracy and efficiency by assigning labels with hierarchical relationships to objects. In this work, we propose CHFL, an incremental learning method for remote sensing images. CHFL leverages hierarchical relationships through a label relationship graph and class hierarchy information to encode knowledge effectively. It integrates a Feature Pyramid Network (FPN) to process multi-scale features, capturing discriminative region information, and a Learning Without Forgetting (LWF) strategy to efficiently learn new classes while preserving performance on previous ones. Additionally, a Hierarchy and Exclusion (HEX) graph is introduced to constrain label predictions, enhancing consistency and improving classification accuracy. Experimental results on the high-resolution remote sensing dataset HRSC show that CHFL achieves an accuracy of 93.82% on new class classifications while maintaining competitive performance on previous classes. Compared with existing methods, CHFL demonstrates superior classification performance, effectively mitigating catastrophic forgetting and addressing scale variations in remote sensing imagery.},
  archive      = {J_APIN},
  author       = {Chu, Yang and Qian, Yuntao},
  doi          = {10.1007/s10489-024-06216-0},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Incremental classification of remote sensing images using feature pyramid and class hierarchy enhanced by label relationship graphs},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion-based remote sensing image fusion for classification. <em>APIN</em>, <em>55</em>(3), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06217-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of remote sensing image fusion is to merge remote sensing images from multiple data sources to generate high-quality images with elevated spatial and spectral resolution. The resulting images of superior quality can enhance the geometric precision of remote sensing images, augment the quantity and detail of feature information, augment classification accuracy, and facilitate dynamic monitoring across many applications. In fields such as agriculture, forestry, urban planning, and environmental monitoring, high-quality images can enhance the precision and resolution of interpretation and facilitate the extraction of target information. A typical example of remote sensing image fusion is the fusion of low-resolution hyperspectral image (HSI) and light detection and ranging (LiDAR) data. The majority of the various remote sensing image fusion methodologies that have been put forth thus far conduct fusion studies regarding the specific data characteristics of HSI and LiDAR, with only a limited focus on the correlation between the two regarding their spatial distribution. To address this issue, this paper proposes an image fusion classification network based on the denoising diffusion probabilistic model (DDPM). DDPM can be trained to learn the data distribution of an image and generate a new image with the same distribution by inverse diffusion, it is frequently employed in the field of image generation research, yet its application to image fusion research remains unexplored. Therefore, we use DDPM to extract the spatial feature distribution of correlations derived from HSI-LiDAR data pairs, fuse them with hyperspectral features from HSI, and then train them jointly. Experimental results demonstrate that intermediate activation at a specific time step in the inverse diffusion process can effectively extract feature information from HSI and LiDAR, resulting in a significant improvement in classification accuracy after fusion with hyperspectral features of HSI. Furthermore, even when replacing the inputs with multispectral images (MSI) and synthetic aperture radar (SAR) data, the model still maintains considerable performance.},
  archive      = {J_APIN},
  author       = {Jiang, Yuling and Liu, Shujun and Wang, Huajun},
  doi          = {10.1007/s10489-024-06217-z},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Diffusion-based remote sensing image fusion for classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning in real-time strategy games: A systematic literature review. <em>APIN</em>, <em>55</em>(3), 1-16. (<a href='https://doi.org/10.1007/s10489-024-06220-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning is a field of Machine Learning in which agents learn from interacting with the environment. These agents can deal with more complex problems when their decision-making process is combined with deep learning. While deep reinforcement learning can be used in many real-world applications, games often provide a good source of simulation environments for testing such algorithms. Among all game categories, real-time strategy games usually pose a difficult challenge since they have large state and action spaces, partial observation maps, sparse reward, and Multi-Agent problems, where the events occur continuously simultaneously. Thus, this paper provides a systematic literature review of deep reinforcement learning related to real-time strategy games. The main goals of this review are presented as follows: (a) identify the games used in recent works; (b) summarize the architectures and techniques used; (c) identify the simulation environments adopted and (d) understand whether the works focus on micromanagement or macromanagement tasks when dealing with real-time strategy games. The results show that some architectures have achieved better performance overall when handling both micro and macromanagement tasks, and that techniques for reducing the training time and the state space may improve the agents learning. This paper may help to guide future research on developing strategies to build agents for complex scenarios such as those faced in real-time strategy games. Visual summary of the Systematic Literature Review methodology and results. It presents the objective of the review, the research questions, the protocol parameters and criteria, and the results},
  archive      = {J_APIN},
  author       = {Barros e Sá, Gabriel Caldas and Madeira, Charles Andrye Galvão},
  doi          = {10.1007/s10489-024-06220-4},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Deep reinforcement learning in real-time strategy games: A systematic literature review},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring refined boundaries and accurate pseudo-labels for semi-supervised medical image segmentation. <em>APIN</em>, <em>55</em>(3), 1-20. (<a href='https://doi.org/10.1007/s10489-024-06222-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the tedious and expensive nature of annotating data for medical image segmentation tasks, semi-supervised learning (SSL) methods utilizing a small amount of labeled data have gained widespread attention. However, most existing methods overlook the importance of boundary regions in multi-class tasks and are sensitive to incorrect pseudo-label. In this paper, a novel Dual-Cycled Boundary Refine Network (DCBR-Net) is presented, consisting of two simple yet slightly different segmentation networks and a Boundary Residual Refine (BRR) module. First, a new boundary refine method for the semi-supervised medical image segmentation field is designed, that is a BRR module with a residual architecture. This module is capable of enhancing the representation of boundaries while ensuring the quality of inner regions. Besides, a dual-cycled pseudo-label scheme is designed to train the unlabeled data. Through providing diverse outputs and achieving double supervision for the result, the issue of ineffective guidance caused by model consistency after multiple iterations is alleviated. Furthermore, a novel dynamic loss function is developed based on the prediction disagreement between different models, which can suppress the influence of incorrect pseudo-labels. Extensive experiments conducted on four public medical datasets demonstrate that our network can achieve competitive results, especially with higher reliability in boundary regions. On the ACDC, LA, and Fundus datasets, with only a 20% labeled ratio, our network achieves DSC scores of 90.53%, 90.40%, and 89.19%, respectively, which are comparable to fully supervised performance.},
  archive      = {J_APIN},
  author       = {Ma, Xiaochen and Li, Yanfeng and Sun, Jia and Chen, Houjin and Ren, Yihan and Chen, Ziwei},
  doi          = {10.1007/s10489-024-06222-2},
  journal      = {Applied Intelligence},
  month        = {2},
  number       = {3},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Exploring refined boundaries and accurate pseudo-labels for semi-supervised medical image segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monitoring african geopolitics: A multilingual sentiment and public attention framework. <em>APIN</em>, <em>55</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10489-024-05905-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a framework for assessing geopolitical news based on local sentiment and public attention. Our approach uses data from social media and local online press in Kenya, Nigeria, Senegal, and South Africa, considering both local languages and colonial languages (French and English). We focus on four main topics: Foreign Relations, Institutional Stability, Conflicts, and Nature and Pandemics, using specific keywords to retrieve relevant data. We construct a Pre-trained Multilingual BERT Model, fine-tuned for tasks like text classification and sentiment analysis, emphasizing African low-resource languages. Our experiments compare different embedding approaches, showing better performance with our domain-specific model, ToumBERT, compared to the multilingual BERT-base model. The proposed Geopolitical Risk measurement methodology employs three indices: Novelty, Severity and Reach while Novelty is related to the newness of a geopolitical controversial topic, the Severity, to the roughness of comments in front of this controversy and the Reach to its media coverage. Low scores in these indices signal potential political issues in specific topics, regions and dates. To facilitate monitoring the progression of the constructed metrics, we have implemented a dashboard that visualizes their temporal evolution. This dashboard supports multiple filters (dates, topics, countries, etc.) and allows direct access to the original documents as the primary information source.},
  archive      = {J_APIN},
  author       = {Abdou Mohamed, Naira and Benelallam, Imade and Rahmani, Youcef},
  doi          = {10.1007/s10489-024-05905-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Monitoring african geopolitics: A multilingual sentiment and public attention framework},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data augmented large language models for medical record generation. <em>APIN</em>, <em>55</em>(2), 1-22. (<a href='https://doi.org/10.1007/s10489-024-05934-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Writing various medical records takes significant daily workload for physicians. Generative AI technique has the advantage in tasks of data-to-text generation and text summarization, and brings opportunities to reduce workload for physicians to work on medical records. However, current general Large Language Models (LLMs) cannot satisfy the strict requirements to correctness of generative texts in specific tasks of medical record generation. In addition, due to the constraints to protect patient privacy, physicians cannot upload patient data to public cloud services for LLM cloud service. We develop optimized LLMs for medical record generation, which can be deployed in hospitals and integrated with the Electronic Medical Record (EMR) applications for physicians to reduce workload of writing medical records. We propose an approach for constructing data augmented LLM on medical record generation. As for each specific task, we extract annotated data with high quality from the EMR application in a hospital. Based on such data and customized instruct, we construct certain optimized models for specific tasks, including medical Data-to-Text generation (from structural medical data to history of present illness) and medical text summarization (from a series of progress notes to discharge summary). Furthermore, we propose Faithfulness score, a evaluation metrics, based on semantic similarity between the generative texts by LLMs and reference texts by physicians. Extensive experiments are conducted with high-quality task-specific medical data, and tested with our optimized models and two other models, including a general state-of-the-art (SOTA) model and a medical model, thereby evaluating the correctness of the generated medical records by Faithfulness score, separately on the two specific tasks.The experimental results demonstrate that our optimized models has improved the Faithfulness score of the generated medical records, respectively by 19.72% and 19.33% rather than the existing SOTA models, on medical Data-to-Text generation and medical text summarization.Our work has been validated and applied in the hospital we cooperate with, and save approximately 0.5-1 hour of working time per day for a physician, so that he or she can spend more time in taking care of his or her patients.This method can be generalized to any hospital, using its native medical data, to achieve a specialized model available for medical record generation tasks.The code is available at https://github.com/LotusPhilip/data-augmented-model},
  archive      = {J_APIN},
  author       = {Zhang, Xuanyi and Zhao, Genghong and Ren, Yi and Wang, Weiguang and Cai, Wei and Zhao, Yan and Zhang, Xia and Liu, Jiren},
  doi          = {10.1007/s10489-024-05934-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Data augmented large language models for medical record generation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SFE-SLAM: An effective LiDAR SLAM based on step-by-step feature extraction. <em>APIN</em>, <em>55</em>(2), 1-15. (<a href='https://doi.org/10.1007/s10489-024-05963-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LiDAR Simultaneous Localization and Mapping (SLAM) plays a crucial role in intelligent robotics, finding extensive applications in autonomous driving and exploration. The traditional feature-based LiDAR SLAM holds a prominent position due to its robustness and accuracy. However, these methods still exhibit limitations in point cloud preprocessing and feature extraction. In this paper, we introduce an effective LiDAR SLAM method to address these issues. Specifically, we propose a novel Concentric Cluster Model (CCM) for clustering point clouds, aiming to preserve stable point clouds and eliminate the unstable ones. Additionally, we propose a Step-by-step Feature Extraction (SFE), which significantly enhances the effect of traditional feature extraction methods. We test the proposed SLAM method on several sequences of the KITTI odometry, M2DGR, and M2DGR-plus datasets. Experimental results show that our method achieves superior accuracy compared to several state-of-the-art LiDAR SLAM methods, while maintaining real-time performance.},
  archive      = {J_APIN},
  author       = {Ren, Yang and Zeng, Hui and Liang, Yiyou},
  doi          = {10.1007/s10489-024-05963-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {SFE-SLAM: An effective LiDAR SLAM based on step-by-step feature extraction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DCFA-iTimeNet: Dynamic cross-fusion attention network for interpretable time series prediction. <em>APIN</em>, <em>55</em>(2), 1-15. (<a href='https://doi.org/10.1007/s10489-024-05973-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although time series prediction research among engineering and technology has made breakthrough progress in performance, challenges remain in modeling complex dynamic interactions between variables and interpretability. To address these two problems, a novel two-stage strategy framework called DCFA-iTimeNet is introduced. In the first stage, this paper innovatively proposes a dynamic cross-fusion attention mechanism (DCFA) . This module facilitates the model to exchange information between different patches of the time series, thereby capturing the complex interactions between variables across time. In the second stage, we exploit a decomposition-based linear explainable Bidirectional Gated Recurrent Unit (DeLEBiGRU), which consists mainly of standard BiGRU and tensorized BiGRU. It is proposed to analyze each variable’s historical long-term, instantaneous, and future impacts. Such design is crucial for understanding how each variable impacts the overall prediction over time. Extensive experimental results demonstrate that the proposed model can effectively model and interpret complex dynamic relationships of multivariate time series and understand the model’s decision-making process. Moreover, the performance outperforms the state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Yuan, Jianjun and Wu, Fujun and Zhao, Luoming and Pan, Dongbo and Yu, Xinyue},
  doi          = {10.1007/s10489-024-05973-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {DCFA-iTimeNet: Dynamic cross-fusion attention network for interpretable time series prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Searching a lightweight network architecture for thermal infrared pedestrian tracking. <em>APIN</em>, <em>55</em>(2), 1-14. (<a href='https://doi.org/10.1007/s10489-024-05984-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manually-designed network architectures for thermal infrared pedestrian tracking (TIR-PT) require substantial effort from human experts. AlexNet and ResNet are widely used as backbone networks in TIR-PT applications. However, these architectures were originally designed for image classification and object detection tasks, which are less complex than the challenges presented by TIR-PT. This paper makes an early attempt to search an optimal network architecture for TIR-PT automatically, employing single-bottom and dual-bottom cells as basic search units and incorporating eight operation candidates within the search space. To expedite the search process, a random channel selection strategy is employed prior to assessing operation candidates. Classification, batch hard triplet, and center loss are jointly used to retrain the searched architecture. The outcome is a high-performance network architecture that is both parameter- and computation-efficient. Extensive experiments proved the effectiveness of the automated method.},
  archive      = {J_APIN},
  author       = {Tang, Wen-Jia and Liu, Xiao and Gao, Peng and Wang, Fei and Yuan, Ru-Yue},
  doi          = {10.1007/s10489-024-05984-z},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Searching a lightweight network architecture for thermal infrared pedestrian tracking},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variational graph neural network with diffusion prior for link prediction. <em>APIN</em>, <em>55</em>(2), 1-14. (<a href='https://doi.org/10.1007/s10489-024-06063-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Graph neural networks(GNNs) has achieved tremendous success in a variety of fields. Many approaches have been proposed to address data with graph structure. However, many of these are deterministic methods, therefore, they are unable to capture the uncertainty, which is inherent in the nature of graph data. Various VAE(Variational auto-encoder)-based approaches have been proposed to tackle such problems. Unfortunately, due to the simple a posterior and a prior assumption problems of such methods, they are not well suited to handle uncertainty in graph data. For example, VGAE(Variational graph auto-encoder) assumes that the posterior and prior distributions are simple Gaussian distributions, which can lead to overfitting problems when incompatible with the true distributions. Many methods propose to solve the posterior distribution problem, but most ignore the effect of the prior distribution. Therefore, in this paper, we proposed a novel method to solve the Gaussian prior problem. Specifically, in order to enhance the representation power of the prior distribution, we use the diffusion model to model the prior distribution. We incorporate the diffusion model into VGAE. In the forward diffusion process, noise is gradually added to the latent variables, and then the samples are recovered by the backward diffusion process. To realize the backward diffusion process, we propose a new denoising model which predicts noise by stacking GCN(Graph Convolution Network) and MLP(Multi-layers Perceptron). We perform experiments on different datasets and the experimental results demonstrate that our method obtains state-of-the-art results.},
  archive      = {J_APIN},
  author       = {Su, Hailong and Li, Zhipeng and Yuan, Chang-An and Vladimir, F. Filaretov and Huang, De-Shuang},
  doi          = {10.1007/s10489-024-06063-z},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Variational graph neural network with diffusion prior for link prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A distributionally robust risk-aware approach to chance constrained sustainable development model under unknown distribution. <em>APIN</em>, <em>55</em>(2), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05884-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel distributionally robust risk-aware approach that aims to tackle the increasingly complex sustainable development model by taking into account job creation and economic growth. To alleviate the inherent conservatism in existing robust sustainable development model, we develop a distributionally robust chance constrained sustainable development model. This innovative approach, incorporating adjustable value-at-risk measures, offers a formal theoretical guarantee for sustainable economic development. However, its practical implementation presents considerable difficulty due to the non-convex nature of the optimization problem associated with the sustainable development model. Moreover, acquiring accurate probability distribution functions for uncertainties in the sustainable development model poses a challenge due to the limited availability of historical data. To address these challenges, we propose a distributionally robust risk-aware reformulated method that approximates the chance constrained sustainable development model as a semidefinite programming problem, taking into account the mean and variance of uncertainties. This operational strategy provides decision-makers with a robust market-optimal solution. A comparative analysis reveals that our proposed method outperforms alternative approaches by achieving a 5% higher GDP within the sustainable development model, underscoring its strong potential as a reliable and secure decision-making tool for the next generation of sustainable development.},
  archive      = {J_APIN},
  author       = {Wang, Xindi and Xu, Zeshui and Li, Bo},
  doi          = {10.1007/s10489-024-05884-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {A distributionally robust risk-aware approach to chance constrained sustainable development model under unknown distribution},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Manifold and patch-based unsupervised deep metric learning for fine-grained image retrieval. <em>APIN</em>, <em>55</em>(2), 1-18. (<a href='https://doi.org/10.1007/s10489-024-05926-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately and swiftly retrieving from fine-grained images is a critical and challenging task. As the key technology for fine-grained image retrieval, deep metric learning aims to learn a mapping space, where samples exhibit two properties: positive concentration and negative separation, facilitating the measurement of similarities between samples. Unsupervised deep metric learning, which obviates the need for labels during training, has garnered widespread attention compared to its supervised counterparts due to its convenience. Current methods in unsupervised deep metric learning face issues such as imbalance in sample construction, difficulty in sample differentiation, and neglect of intrinsic image features. To address these challenges, we propose Manifold and Patch-based Unsupervised Deep Metric Learning (MPUDML) for Fine-Grained Image Retrieval. Specifically, we adopt a manifold similarity-based balanced sampling strategy for constructing more balanced mini-batch samples. Moreover, we leverage soft supervision information obtained from the manifold and cosine similarities between unlabeled images for sample differentiation, effectively reducing the impact of noisy samples. Additionally, we utilize the rich feature information between internal image patches through image patch-level clustering and localization tasks to guide the acquisition of a more comprehensive feature embedding representation, thereby enhancing retrieval performance. Our method, MPUDML, was evaluated against various state-of-the-art unsupervised deep metric learning approaches in fine-grained image retrieval and clustering tasks. Experimental findings indicate that our MPUDML method exceeds other advanced methods in recall (R@K) and Normalized Mutual Information (NMI).},
  archive      = {J_APIN},
  author       = {Yuan, Shi-hao and Feng, Yong and Qiu, A-Gen and Duan, Guo-fan and Zhou, Ming-liang and Qiang, Bao-hua and Wang, Yong-heng},
  doi          = {10.1007/s10489-024-05926-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Manifold and patch-based unsupervised deep metric learning for fine-grained image retrieval},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reversible data hiding in encrypted images based on lasso regression predictor and dynamic secret sharing. <em>APIN</em>, <em>55</em>(2), 1-21. (<a href='https://doi.org/10.1007/s10489-024-05929-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reversible data hiding in encrypted images (RDH-EI) integrates encryption with information hiding, enabling the embedding of additional data while ensuring full recovery of the original image, widely used in multimedia data protection and forensics. However, with the increasingly serious problem of data islands, the existing RDH-EI schemes for end-to-end communication scenarios can no longer meet the application requirements for multi-party data sharing. For solving this problem, this paper proposes an RDH-EI method based on Lasso regression predictor and dynamic secret sharing. First, Lasso regression predictor is proposed, which avoids the problem of over-fitting by regularizing the loss function. Then, to reserve more embeddable room, we map the prediction error and use arithmetic coding for compression. Next, the original image and auxiliary information are shared through dynamic secret sharing algorithm, and they can be transmitted to the corresponding data hiders respectively. According to the reserved room, each data hider allows for the discrete implantation of the secret bits into the corresponding encrypted image. The receiver can successfully extract the secret bits and recreate the cover image without distortion by gathering a specific percentage of marked images. Experimental results demonstrate that the suggested Lasso regression predictor has a greater prediction accuracy, outperforming contemporary methods for embedding rate. Additionally, it has great security and strong key sensitivity.},
  archive      = {J_APIN},
  author       = {Ren, Yu and Qin, Jiaohua and Xiang, Xuyu and Tan, Yun},
  doi          = {10.1007/s10489-024-05929-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Reversible data hiding in encrypted images based on lasso regression predictor and dynamic secret sharing},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Dirichlet stochastic weights averaging for graph neural networks. <em>APIN</em>, <em>55</em>(2), 1. (<a href='https://doi.org/10.1007/s10489-024-06086-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Park, Minhoi and Chang, Rakwoo and Song, Kyungwoo},
  doi          = {10.1007/s10489-024-06086-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Correction to: Dirichlet stochastic weights averaging for graph neural networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine grained sentiment analysis on microblogs based on graph convolution and self attention graph pooling. <em>APIN</em>, <em>55</em>(2), 1-16. (<a href='https://doi.org/10.1007/s10489-024-06102-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microblog is one of the most popular social media platforms in China. Fine grained sentiment analysis of Chinese microblog comments has attracted much attention. Graph Convolutional Neural Network (GCN) has been broadly used in sentiment analysis but still suffers from emotion misclassification due to the complexity and diversity of Chinese microblogs’ syntax structures. To address the issue, we propose a graph pooling method based on self-attention mechanism, namely, AGMPool. The AGMPool pooling method uses graph convolution to calculate its attention score for each graph node and then to filter out nodes with excessive useless information in the graph topology according to these scores, which effectively improves the performance of fine-grained sentiment analysis through GCN. In addition, for better understanding of diverse syntax structures of Chinese microblogs, we propose a microblog fine grained sentiment analysis model, namely, LMG-AGMPool, which combines GCN with the AGMPool pooling method and extracts emotional features based on the syntax structures of text and the importance of words in text. The experimental results indicate that the LMG-AGMPool model has better performance than the traditional methods and the deep learning methods in fine grained sentiment analysis.},
  archive      = {J_APIN},
  author       = {Li, Yuanyuan and Zhou, Baolong and Niu, Yijie and Zhao, Yuetong},
  doi          = {10.1007/s10489-024-06102-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Fine grained sentiment analysis on microblogs based on graph convolution and self attention graph pooling},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An fMRI-based auditory decoding framework combined with convolutional neural network for predicting the semantics of real-life sounds from brain activity. <em>APIN</em>, <em>55</em>(2), 1-12. (<a href='https://doi.org/10.1007/s10489-024-05873-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic decoding, understood as predicting the semantic information carried by stimuli presented to subjects based on neural signals, is an active area of research. Previous studies have mainly focused on the visual perception process, with relatively little attention paid to complex auditory decoding. Moreover, simple linear models do not achieve optimal performance for the mapping between brain signals and natural sounds. Therefore, a robust approach that combines a pretrained audio tagging model and a nonlinear multilayer perceptron model was proposed to transfer information from non-invasive measured brain activity to deep learning features, thereby generating sound semantics. The results achieved on previously unseen subjects, training without data from the target subjects, and ultimately predicting natural-sound semantics from the fMRI data of unseen subjects. In the study with 30 subjects, the framework in research achieves 23.21% Top-1 and 51.88% Top-5 accuracy scores, which significantly exceed the baseline scores and the scores of other classical algorithms. The approach advances the decoding of auditory neural excitation with the help of deep neural networks, and the proposed model successfully completes a challenging cross-subject decoding task.},
  archive      = {J_APIN},
  author       = {Zhao, Mingqian and Liu, Baolin},
  doi          = {10.1007/s10489-024-05873-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {An fMRI-based auditory decoding framework combined with convolutional neural network for predicting the semantics of real-life sounds from brain activity},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-based assessment of diabetes risk. <em>APIN</em>, <em>55</em>(2), 1-13. (<a href='https://doi.org/10.1007/s10489-024-05912-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, diabetes is one of the most dangerous diseases in modern society. Prevention is an extremely important aspect in the field of medicine, and the field of artificial intelligence and the healthcare industry are penetrating and integrating with each other, and combining machine models for prediction and diagnosis of diabetes is a big trend. In order to validate the advantages and potential of XGBoost model in the field of diabetes prediction, this study identified 10 key features by processing a medical examination dataset containing 556,495 sample size. Among them, glycated hemoglobin has high clinical value as a predictor. By constructing six machine models (XGBoost, Decision Tree, Logistic Regression, Random Forest, CatBoost, and LightGBM) and comparing their performances, we finally obtained that: the performance of XGBoost is relatively the best, with accuracy of 97.5%, recall of 97%, F1 score of 96.9%, and ROC-AUC score of 0.971.},
  archive      = {J_APIN},
  author       = {Sun, Qi and Cheng, Xin and Han, Kuo and Sun, Yichao and Ren, He and Li, Ping},
  doi          = {10.1007/s10489-024-05912-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Machine learning-based assessment of diabetes risk},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing explainability in medical image classification and analyzing osteonecrosis X-ray images using shadow learner system. <em>APIN</em>, <em>55</em>(2), 1-40. (<a href='https://doi.org/10.1007/s10489-024-05916-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous applications have explored medical image classification using deep learning models. With the emergence of Explainable AI (XAI), researchers have begun to recognize its potential in validating the authenticity and correctness of results produced by black-box deep learning models. On the other hand, current diagnostic approaches for osteonecrosis face significant challenges, including difficulty in early detection, subjectivity in image interpretation, and reliance on surgical interventions without a comprehensive diagnostic foundation. This paper presents a novel Medical Computer-Aid-Diagnosis System—the Shadow Learning System framework—which integrates a convolutional neural network (CNN) with an Explainable AI method. This system not only performs conventional computer-aiding-diagnosis functions but also uniquely exploits misclassified data samples to provide additional medically relevant information from the machine learning model’s perspective, assisting doctors in their diagnostic process. The implementation of XAI techniques in our proposed system goes beyond merely validating CNN model results; it also enables the extraction of valuable information from medical images through an unconventional machine learning perspective. Our paper aims to enhance and extend the general structure and detailed design of the Shadow Learner System, making it more advantageous not only for human users but also for the deep learning model itself. A case study on femoral head osteonecrosis was conducted using our proposed system, which demonstrated improved accuracy and reliability in its prediction results. Experimental results interpreted using XAI methods are visualized to prove the confidence of our proposed model that generates reasonable results, confirming the effectiveness of the proposed model.},
  archive      = {J_APIN},
  author       = {Wu, Yaoyang and Fong, Simon and Liu, Liansheng},
  doi          = {10.1007/s10489-024-05916-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-40},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing explainability in medical image classification and analyzing osteonecrosis X-ray images using shadow learner system},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RKHS reconstruction based on manifold learning for high-dimensional data. <em>APIN</em>, <em>55</em>(2), 1-24. (<a href='https://doi.org/10.1007/s10489-024-05923-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel trick has achieved remarkable success in various machine learning tasks, especially those with high-dimensional non-linear data. In addition, these data usually tend to have compact representation that cluster in a low-dimensional subspace. In order to offer a general and comprehensive framework for high-dimensional non-linear data, in this paper, we generalizes multiple kernel learning and subspace learning in a reconstructed reproducing kernel Hilbert space (RKHS) endowed with manifold leaning. First, we construct reconstructed kernels by fusing manifold learning and some base kernel functions, and then learn the optimal kernel by linearly combining the reconstructed kernels. The proposed MKL method can introduce different prior knowledge such as neighborhood information and classification information, to solve different tasks of high-dimensional data. Furthermore, we propose a subspace learning based on RKHS reconstruction, named MVSL for short, of which the objective function is designed with variance maximization criterion, and use an iterative algorithm to solve it. We also incorporates data discriminant information to the learning process of the modified kernel by kernel alignment criterion and a regularization term, to learning the optimal kernel matrix for RKHS reconstruction, and propose another subspace learning method, named Discriminative MVSL. Experimental results on toy and real-world datasets demonstrate that the proposed MKL and subspace learning methods are able to learn the local manifold and the global statistics information of data based on RKHS reconstruction, and thus they achieve a satisfactory performance on classification and dimension reduction tasks.},
  archive      = {J_APIN},
  author       = {Niu, Guo and Zhu, Nannan and Ma, Zhengming and Wang, Xin and Liu, Xi and Zhou, Yan and Zhou, Yuexia},
  doi          = {10.1007/s10489-024-05923-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {RKHS reconstruction based on manifold learning for high-dimensional data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection and pose measurement of underground drill pipes based on GA-PointNet++. <em>APIN</em>, <em>55</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10489-024-05925-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drilling for gas extraction, a common method in coal mine gas control, involves tedious loading and uploading of drill pipes. This study aims to design a method for detecting and measuring pose drill pipes using point cloud data. We present an experimental platform for acquiring drill pipe point cloud data under various lights. Additionally, we propose a GA-PointNet + + model, enhanced with an adversarial generation network. The pose of the drill pipe was calculated from the segmented pipe and pin point clouds. Results indicate that the intersection-over-union (IoU) values for pipe and pin, based on GA-PointNet + + , are 0.824 and 0.472, respectively. Evaluating the model's performance in recognizing the pin using the ROC curve yielded an AUC of 0.87. The combination of GA-Pointnet + + and RGB-D camera was used to pose drill pipes, achieving an average accuracy of 82.5% under different lighting conditions. Under lighting conditions of 25–35 lx with an added diffuser film and 10–15 lx, the accuracy reaches 90%, with average distance errors of 1.4 cm and 2.5 cm, and average angle errors of 3.5° and 3.7°, respectively. This has significant implications for the use of LED lights in underground environments. Therefore, the proposed drill pipe pose measurement method is of great significance for the intelligentization of coal mine drilling operations.},
  archive      = {J_APIN},
  author       = {Luo, Jiangnan and Cai, Jinyu and Li, Jianping and Zhang, Deyi and Gao, Jiuhua and Li, Yuze and Lei, Liu and Hao, Mengda},
  doi          = {10.1007/s10489-024-05925-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Detection and pose measurement of underground drill pipes based on GA-PointNet++},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network-based adaptive reinforcement learning for optimized backstepping tracking control of nonlinear systems with input delay. <em>APIN</em>, <em>55</em>(2), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05932-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of adaptive optimized tracking control design is addressed for a class of nonlinear systems in strict-feedback form. The system under consideration contains input delay and has unmeasurable and restricted states within predefined compact sets. First, neural networks (NNs) are employed to approximate the unknown nonlinear dynamics, and an adaptive neural network (NN) state observer is constructed to compensate for the absence of state information. Additionally, by utilizing an auxiliary system compensation method alongside the backstepping technique, the impact of input delay is eliminated, and the generation of intermediate variables is prevented. Second, tan-type barrier optimal cost functions are established for each subsystem within the backstepping method to prevent the state variables from exceeding preselected sets. Moreover, by establishing both actor and critic NNs to execute a reinforcement learning algorithm, the optimal controller and optimal performance index function are evaluated, while relaxing the persistence of excitation condition. According to the Lyapunov stability theorem, it is demonstrated that all signals in the closed-loop system are semi-globally uniformly ultimately bounded (SGUUB), and the output signal accurately tracks a reference trajectory with the desired precision. Finally, a practical simulation example is provided to verify the effectiveness of the proposed control strategy, demonstrating its potential for real-world implementation.},
  archive      = {J_APIN},
  author       = {Zhu, Boyan and Karimi, Hamid Reza and Zhang, Liang and Zhao, Xudong},
  doi          = {10.1007/s10489-024-05932-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Neural network-based adaptive reinforcement learning for optimized backstepping tracking control of nonlinear systems with input delay},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent dual actor-critic framework for reinforcement learning navigation. <em>APIN</em>, <em>55</em>(2), 1-20. (<a href='https://doi.org/10.1007/s10489-024-05933-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent navigation task remains a fundamental challenge in robotics and autopilots. Reinforcement learning approaches to navigation often struggle to address the value overestimation in dynamic environments, multi-agent interactions, and diverse objectives. In this study, we propose a novel Multi-Agent Dual Actor-Critic (MADAC) framework for reinforcement learning navigation tasks. Our framework consists of dual-Actor and dual-Critic pairs. The dual-Actor component is developed to bolster the diversity of exploration by agents and avoid potential overestimation caused by a single policy, while the dual-Critic is employed to effectively regulate the fluctuation of value function estimates, mitigating inaccuracies in state value estimation and alleviating the issue of overestimation. By incorporating dual Actor-Critic pairs, our framework facilitates effective coordination and learning among multiple agents, leading to improved navigation performance and adaptability in complex environments. We validated the performance of the MADAC framework through extensive experiments in simulated navigation environments. Our results demonstrate that the MADAC framework outperforms SOTA methods in terms of navigation success rate, convergence speed, and robustness to dynamic environments, and scalability to increasing numbers of agents. The MADAC framework offers a promising approach for tackling real-world navigation challenges in dynamic and collaborative environments, with implications for robotics, autonomous systems, and interactive entertainment.},
  archive      = {J_APIN},
  author       = {Xiong, Fengguang and Zhang, Yaodan and Kuang, Xinhe and He, Ligang and Han, Xie},
  doi          = {10.1007/s10489-024-05933-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Multi-agent dual actor-critic framework for reinforcement learning navigation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MultiGranDTI: An explainable multi-granularity representation framework for drug-target interaction prediction. <em>APIN</em>, <em>55</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10489-024-05936-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug-target interaction (DTI) prediction is a tough task with critical applications in drug repurposing and design scenarios, as it significantly reduces resource consumption and accelerates the drug discovery process. With the proliferation of experimentally measured pharmaceutical data and increasingly complex drug-target interactions, deep DTI approaches are becoming increasingly competitive due to their ability to utilize large-scale data in an end-to-end manner. It is fascinating to consider how to consolidate drug-target pair representations at different granularities to enhance deep DTI models with limited performance. The employed models typically involve solely single granular information and thus lead to a significant lack of features. Motivated by this concern, this study proposes an explainable multi-granularity representation framework for DTI prediction (MultiGranDTI). First, a hierarchical network with constraint is devised to enable the natural conversion of drug representations with different granularities, effectively integrating atomic and substructural information. Second, the 1st-order and 2nd-order sequence information of the target protein is modeled and then encoded together with the spatial information. Subsequently, several convolution layers further extract various levels of protein features. Finally, the drug and protein features are concatenated and fed into regular dense layers for interaction prediction. Comprehensive experiments reveal that MultiGranDTI achieves competitive performance in two types of tasks on four benchmark datasets. Additionally, a visualization case shows that our method is capable of efficiently identifying particular functional groups and substructures in molecules and providing a plausible explanation for the predicted results. A novel MultiGranDTI model to boost DTI prediction by comprehensively mining the multi-granularity information of compounds and proteins},
  archive      = {J_APIN},
  author       = {Gong, Xu and Liu, Qun and He, Jing and Guo, Yike and Wang, Guoyin},
  doi          = {10.1007/s10489-024-05936-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {MultiGranDTI: An explainable multi-granularity representation framework for drug-target interaction prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards adaptive information propagation and aggregation in hypergraph model for node classification. <em>APIN</em>, <em>55</em>(2), 1-15. (<a href='https://doi.org/10.1007/s10489-024-05939-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, hypergraph models have gained widespread attention in the hypergraph node classification task due to their ability to capture high-order node relationships. Nevertheless, most previous models are unaware of the potential pairwise node relationships in hypergraph data and fail to sufficiently mine such relationships during the information propagation process, leading to suboptimal performance. Moreover, the over-smoothing problem causes the loss of distinctive features of nodes during the information aggregation process and limits the ability of previous models to extract and leverage valuable information from high-hop neighbors, resulting in restricted expressivity and performance. To tackle these problems, we propose a novel adaptive hypergraph neural network (AdaHGNN), that can adaptively mine potential pairwise node relationships and efficiently extract and adaptively aggregate information from high-hop neighbors for accurate hypergraph node classification. Specifically, we propose a new dual-view information propagation mechanism (IPM) that consists of graph-view IPM and hypergraph-view IPM to adaptively capture high-order node relationships and mine potential pairwise relationships, and fuse them through gate mechanism. We then simplify the conventional hypergraph convolution into a decoupled hypergraph convolution to efficiently extract information from high-hop neighbors. Finally, we customize a new adaptive aggregation method to adaptively aggregate valuable information from high-hop neighbors for classification. Extensive experiments conducted on four citation datasets demonstrate the superiority of the proposed model in accuracy and efficiency, and confirm its applicability.},
  archive      = {J_APIN},
  author       = {Jin, Yilun and Yin, Wei and Wang, Yiwei and Chen, Yong and Xiao, Bo},
  doi          = {10.1007/s10489-024-05939-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Towards adaptive information propagation and aggregation in hypergraph model for node classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bias reduction via cooperative bargaining in synthetic graph dataset generation. <em>APIN</em>, <em>55</em>(2), 1-10. (<a href='https://doi.org/10.1007/s10489-024-05947-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In general, to draw robust conclusions from a dataset, all the analyzed population must be represented on said dataset. Having a dataset that does not fulfill this condition normally leads to selection bias. This problem can affect any dataset, including graph datasets, which have become popular with the emergence of Graph Neural Networks (GNNs) and their many applications. Although synthetic graphs can be used to augment available real graph datasets to overcome selection bias, the generation of unbiased synthetic datasets is complex with current tools. In this work, we propose a method to find a synthetic graph dataset that has a well-distributed representation of graphs within a given metric space. The resulting dataset can then be used, among others, to study the accuracy of different GNN models or to benchmark the speedups obtained by different graph processing acceleration frameworks.},
  archive      = {J_APIN},
  author       = {Wassington, Axel and Abadal, Sergi},
  doi          = {10.1007/s10489-024-05947-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-10},
  shortjournal = {Appl. Intell.},
  title        = {Bias reduction via cooperative bargaining in synthetic graph dataset generation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reinforced final belief divergence for mass functions and its application in target recognition. <em>APIN</em>, <em>55</em>(2), 1-25. (<a href='https://doi.org/10.1007/s10489-024-05955-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an extension of Bayesian probability theory, the Dempster-Shafer (D-S) evidence theory uses mass function instead of traditional probability distribution. This theory is famous for multi-sensor data fusion and can well represent uncertainty. However, if there are conflicting mass functions, the D-S evidence theory will fail. The existing methods for handling conflicting mass functions do not fully consider the interaction between focal elements. Therefore, to solve the conflict problem, this paper defines the similarity factor and quantity factor of the focal element and then considers the impact of their interaction. After that, we propose a novel reinforced final belief divergence (RFBD) measure to solve the conflicting problem in mass functions from the perspective of divergence measurement. We use several numerical examples to verify the superiority of RFBD in handling conflicting evidence under uncertain conditions. Finally, we combine belief entropy and ambiguity measure to propose the RFBD-based multi-sensor data fusion approach, then achieve target recognition in UCI datasets. The experimental results show that our RFBD is better than the advanced divergence methods currently available.},
  archive      = {J_APIN},
  author       = {Zhang, Fuxiao and Chen, Zichong and Cai, Rui},
  doi          = {10.1007/s10489-024-05955-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {A reinforced final belief divergence for mass functions and its application in target recognition},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-optimization scheme for in-situ training of memristor neural network based on contrastive learning. <em>APIN</em>, <em>55</em>(2), 1-17. (<a href='https://doi.org/10.1007/s10489-024-05957-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memristor and its crossbar structure have been widely studied and proven to be naturally suitable for implementing vector-matrix multiplier (VMM) operation in neural networks, making it one of the ideal underlying hardware when deploying models on edge smart devices. However, the problem of receiving much useless information is common and the non-ideal characteristics will also affect the system training accuracy and efficiency. Considering these problems, We combine the contrastive learning (CL) into in-situ training process on the memristor crossbar, improving the model feature extraction capability and robustness. Meanwhile, to make the contrastive learning integrate with the crossbar better, we proposed a multi-optimization scheme on the network loss function, model deployment method, and gradient calculation process. We also proposed some compensation strategies to address the key non-ideal characteristics we analyzed and fitted. The test results show that under the scheme proposed, the model for deployment has a high accuracy value at the beginning, reaching 83.18% in only 2 epochs, and can quickly achieve an accuracy of 3.99% increase compared to the average accuracy of the existing algorithms with the energy consumption reduced by about 8 times.},
  archive      = {J_APIN},
  author       = {Xiong, Feier and Zhou, Yue and Hu, Xiaofang and Duan, Shukai},
  doi          = {10.1007/s10489-024-05957-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Multi-optimization scheme for in-situ training of memristor neural network based on contrastive learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learner’s cognitive state recognition based on multimodal physiological signal fusion. <em>APIN</em>, <em>55</em>(2), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05958-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is crucial to evaluate learning outcomes by identifying the cognitive state of the learner during the learning process. Studies utilizing Electroencephalography (EEG) and other peripheral physiological signals, combined with deep learning models, have demonstrated improved performance in cognitive state recognition. These studies have primarily focused on unimodal data, which are vulnerable to various types of noise, making it difficult to fully capture and represent cognitive states. Leveraging the complementarity between multimodal physiological signals can mitigate the impact of anomalies in unimodal data, thereby improving the accuracy and stability of cognitive state recognition. Therefore, this study proposes a multimodal physiological signal feature representation fusion model based on multi-level attention (PSFMMA). The model aims to integrate multimodal physiological signals to identify learners’ cognitive states with greater stability and accuracy. PSFMMA first extracts the temporal features of physiological signals by multiplexing the embedding layer. Subsequently, it generates signal representation vectors by further extracting semantic features through a signal feature mapping layer and enhancing important features with designed attention modules. Finally, the model employs an attention mechanism based on different signal representation vectors to fuse multimodal information for identifying learners’ cognitive states. This study designs various learning activities and collects electroencephalography (EEG), electrodermal activity (EDA), and photoplethysmography (PPG) data from 22 participants engaging in these activities to create the Based on Learning Activities Collection (BLAC) dataset. The proposed model was evaluated on the BLAC dataset, achieving an identification accuracy of 96.32 ± 0.32%. The results demonstrate that the model can effectively recognize learners’ cognitive states. Furthermore, the model’s performance was validated on the publicly available emotion classification dataset DEAP, attaining an accuracy of 99.15 ± 0.12%. The source code is available at https://github.com/chengshudaxuesheng/PSFMMA .},
  archive      = {J_APIN},
  author       = {Li, Yingting and Li, Yue and He, Xiuling and Fang, Jing and Zhou, ChongYang and Liu, Chenxu},
  doi          = {10.1007/s10489-024-05958-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Learner’s cognitive state recognition based on multimodal physiological signal fusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised batch active learning based on mutual information. <em>APIN</em>, <em>55</em>(2), 1-18. (<a href='https://doi.org/10.1007/s10489-024-05962-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active learning reduces the annotation cost of machine learning by selecting and querying informative unlabeled samples. Semi-supervised active learning methods can considerably utilize the regional information of unlabeled samples, and thus, more effectively select valuable samples. Existing semi-supervised batch active learning algorithms frequently exhibit poor robustness due to their high computational complexity, making handling large-scale datasets a difficult task. However, existing active learning algorithms based on high-performance semi-supervised learners adopt a single-sample selection mode, under which the model requires multiple rounds of iterative processes, significantly reducing the overall efficiency of the algorithm and affecting its practicality. To address these issues, we propose a new semi-supervised batch active learning algorithm called approximate error reduction based on mutual information (MIAER). First, we use hierarchical anchor graph regularization (HAGR) as the semi-supervised learner. HAGR exhibits good robustness and only involves a small-scale reduced Laplacian matrix in its optimization process, enabling rapid processing of large-scale datasets. Second, we propose a batch sampling strategy based on mutual information and error reduction in the sample selection stage. This strategy, which is based on hierarchical anchor graphs, first measures the uncertainty of samples by using approximate error reduction, considerably reducing computational overhead. Then, it uses mutual information to measure the diversity of samples in category space while removing redundant batch samples, preserving samples with high uncertainty as much as possible. Comparative experiments with several advanced active learning methods on a large number of datasets fully demonstrate the effectiveness and stability of MIAER.},
  archive      = {J_APIN},
  author       = {Ji, Xia and Wang, LingZhu and Fang, XiaoHao},
  doi          = {10.1007/s10489-024-05962-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Semi-supervised batch active learning based on mutual information},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LocalDGP: Local degree-balanced graph partitioning for lightweight GNNs. <em>APIN</em>, <em>55</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10489-024-05964-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have been widely employed in various fields including knowledge graphs and social networks. When dealing with large-scale graphs, traditional full-batch training methods suffer from excessive GPU memory consumption. To solve this problem, subgraph sampling methods divide the graph into multiple subgraphs and then train the GNN on each subgraph sequentially, which can reduce GPU memory consumption. However, the existing graph partitioning algorithms (e.g., METIS) require global graph information before partitioning, and consume a significant amount of memory to store this information, which is detrimental for large-scale graph partitioning. Moreover, the GNN parameters in the subgraph sampling methods are shared among all the subgraphs. The structural differences between the subgraphs and the global graph (e.g., differences in node degree distributions) will produce a gradient bias on the subgraphs, resulting in a degradation of GNN accuracy. Therefore, a local degree-balanced graph partitioning algorithm named LocalDGP is proposed in this paper. First, in LocalDGP, only the local graph information is acquired during the partitioning process, which can reduce memory consumption. Second, the nodes are balancedly partitioned into subgraphs based on degree to ensure that the subgraph structure is consistent with the global graph. Extensive experimental results on four graph datasets demonstrate that LocalDGP can improve the accuracy of the GNNs while reducing memory consumption. The code is publicly available at https://github.com/li143yf/LocalDGP .},
  archive      = {J_APIN},
  author       = {Ji, Shengwei and Li, Shengjie and Liu, Fei and Xu, Qiang},
  doi          = {10.1007/s10489-024-05964-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {LocalDGP: Local degree-balanced graph partitioning for lightweight GNNs},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An original model for multi-target learning of logical rules for knowledge graph reasoning. <em>APIN</em>, <em>55</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10489-024-05966-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale knowledge graphs are crucial for structuring human knowledge; however, they often remain incomplete. This paper tackles the challenge of completing missing factual triples in knowledge graphs using through rule reasoning. Current rule learning methods tend to allocate a significant portion of triples to constructing the graph during training, while neglecting multi-target reasoning scenarios. Furthermore, these methods typically depend on qualitative assessments of mined rules, lacking a quantitative method to evaluate rule quality. We propose a model that optimizes training data usage and supports multi-target reasoning. To overcome limitations in evaluating model performance and rule quality, we propose two novel metrics. Experimental results show that our model outperforms baseline methods on five benchmark datasets, validating the effectiveness of these metrics.},
  archive      = {J_APIN},
  author       = {Li, Haotian and Wang, Bailing and Wang, Kai and Zhang, Rui and Wei, Yuliang},
  doi          = {10.1007/s10489-024-05966-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {An original model for multi-target learning of logical rules for knowledge graph reasoning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autoregressive multimodal transformer for zero-shot sales forecasting of fashion products with exogenous data. <em>APIN</em>, <em>55</em>(2), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05972-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting future sales volumes of fashion industry products is challenging due to rapid market changes and limited historical sales data for recent products. As traditional forecasting methods and machine learning models often fail to address this problem, we propose a novel autoregressive multimodal transformer architecture to anticipate the sales volume of brand-new apparel items by capturing trends among interrelated attributes. In this paper, we utilize authentic data from a fashion company that includes a limited amount of historical time-series sales data and several influencing factors like product image, textual descriptions, and temporal attributes. To mitigate the data inadequacies, we investigate the impact of integrating exogenous knowledge from an e-tailer site filtered with fashion apparel products. Also, we found that employing the zero-shot forecasting approach further aids in forecasting with minimal time-series sales data. Our approach achieves the values of 1.546 and 16.42 in terms of MAE and WAPE, respectively, by leveraging exogenous data compared to existing benchmark models. This study demonstrates the potential of our autoregressive multimodal transformer to predict sales volumes with more precision, and it highlights the importance of incorporating the zero-shot forecasting approach in the dynamic fashion industry.},
  archive      = {J_APIN},
  author       = {Rajendran, Muralidharan and Hong, Bonghee},
  doi          = {10.1007/s10489-024-05972-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Autoregressive multimodal transformer for zero-shot sales forecasting of fashion products with exogenous data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge graph embeddings based on 2d convolution and self-attention mechanisms for link prediction. <em>APIN</em>, <em>55</em>(2), 1-18. (<a href='https://doi.org/10.1007/s10489-024-05977-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction refers to using existing facts in the knowledge graph to predict missing facts. This process can enhance the integrity of the knowledge graph and facilitate various downstream applications. However, existing link prediction models usually extract features only in a global or local scope, resulting in feature extraction being limited to a single scope. Additionally, to achieve optimal results, many models require increasing embedding dimensions and parameter numbers, which can lead to scalability issues when applied to large knowledge graphs. To address these issues, we propose a model that fuses the self-attention mechanism with 2D convolution for the link prediction task. The model utilizes a self-attention mechanism with numerous heads to capture feature interactions between entities and relations in the global scope. Furthermore, we innovatively introduce 2D convolution to capture feature interactions in the local scope. Results using FB15k-237 and WN18RR as standard link prediction benchmarks show that our fusion model has good comparable performance with current state-of-the-art models. In particular, compared to the ConvE model (which uses only 2D convolution), our proposed model achieves 13.7% and 14.7% improvement in MRR metrics, and compared to the SAttLE model (which uses only the self-attention mechanism) achieves 2.5% and 0.5% improvement in MRR metrics. Furthermore, due to the low-dimensional embedding of entities and relations, our proposed model has low complexity, good scalability, and thus can accomplish link prediction tasks on larger knowledge graphs in the real world.},
  archive      = {J_APIN},
  author       = {Zan, Shijie and Ji, Weidong and Zhou, Guohui},
  doi          = {10.1007/s10489-024-05977-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Knowledge graph embeddings based on 2d convolution and self-attention mechanisms for link prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Communication-efficient federated learning based on compressed sensing and ternary quantization. <em>APIN</em>, <em>55</em>(2), 1-13. (<a href='https://doi.org/10.1007/s10489-024-05979-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing work on Federated Learning (FL) transmits full-precision weights, which contain a significant amount of redundant information, leading to a substantial communication burden. This issue is particularly pronounced with the growing prevalence of smart mobile and Internet of Things (IoT) devices, where data sharing generates a large communication cost. To address this issue, we propose a communication-efficient Federated Learning algorithm, FedCSTQ, based on compressed sensing (CS) and ternary quantization.FedCSTQ introduces a heuristic sparsification method that enhances information selection, thereby mitigating the accuracy degradation typically associated with CS. Additionally, the algorithm incorporates ternary quantization to process residuals after sparsity, further reducing the impact of accuracy degradation due to sparsity while guaranteeing a small amount of communication overhead. Experiments conducted on the publicly available datasets reveal that FedCSTQ outperforms the standard FL (FedAvg), SignSGD with a majority vote, FL using dithering(CEP-FL), and FL based on Compressed Sensing (CS-FL). Ablation studies further demonstrate the effectiveness of our method.},
  archive      = {J_APIN},
  author       = {Zheng, Jiali and Tang, Jing},
  doi          = {10.1007/s10489-024-05979-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Communication-efficient federated learning based on compressed sensing and ternary quantization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive robust control without initial stabilizing for constrained-states nonlinear multiplayer mixed zero-sum game systems with matched input disturbances. <em>APIN</em>, <em>55</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10489-024-05980-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, for the multiplayer mixed zero-sum game (MZSG) problem of the constrained-states nonlinear systems with matched input disturbances, an adaptive robust control method without initial stabilizing is presented on account of barrier function (BF) transformation. Firstly, the original system with state constraints is converted to a transformed system without state constraints by barrier function transformation. Secondly, to overcome the influence of matched input disturbances, considering the nominal system related to the transformation system, the cost function corresponding to each player is appropriately selected, and the robust regulation scheme with matched input disturbances is converted to the optimal regulation scheme. In addition, a novel weight tuning law is designed for the critic neural network (NN) by combining the experience replay (ER) mechanism and the index function. Then, the corresponding cost function of each player is approximated by the critic NN without requiring initial stabilizing control. Utilizing the Lyapunov stability theory, under the influence of state constraints and matched input disturbances, the critic NN weights and states within the multiplayer system are ensured to be uniformly ultimately bounded (UUB). Ultimately, the validity of the proposed method is verified by two simulation examples.},
  archive      = {J_APIN},
  author       = {Qiao, Xiaopeng and Qin, Chunbin and Wang, Jinguang and Zhang, Zhongwei and Shang, Ziyang},
  doi          = {10.1007/s10489-024-05980-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive robust control without initial stabilizing for constrained-states nonlinear multiplayer mixed zero-sum game systems with matched input disturbances},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NeuroMoCo: A neuromorphic momentum contrast learning method for spiking neural networks. <em>APIN</em>, <em>55</em>(2), 1-13. (<a href='https://doi.org/10.1007/s10489-024-05982-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, brain-inspired spiking neural networks (SNNs) have attracted great research attention owing to their inherent bio-interpretability, event-triggered properties and powerful perception of spatiotemporal information, which is beneficial to handling event-based neuromorphic datasets. In contrast to conventional static image datasets, event-based neuromorphic datasets present heightened complexity in feature extraction due to their distinctive time series and sparsity characteristics, which influences their classification accuracy. To overcome this challenge, a novel approach termed Neuromorphic Momentum Contrast Learning (NeuroMoCo) for SNNs is introduced in this paper by extending the benefits of self-supervised pre-training to SNNs to effectively stimulate their potential. This is the first time that self-supervised learning (SSL) based on momentum contrastive learning is realized in SNNs. In addition, we devise a novel loss function named MixInfoNCE tailored to their temporal characteristics to further increase the classification accuracy of neuromorphic datasets, which is verified through rigorous ablation experiments. Finally, experiments on DVS-CIFAR10, DVS128Gesture and N-Caltech101 have shown that NeuroMoCo of this paper establishes new state-of-the-art (SOTA) benchmarks: 83.6% (Spikformer-2-256), 98.62% (Spikformer-2-256), and 84.4% (SEW-ResNet-18), respectively.},
  archive      = {J_APIN},
  author       = {Ma, Yuqi and Wang, Huamin and Shen, Hangchi and Chen, Xuemei and Duan, Shukai and Wen, Shiping},
  doi          = {10.1007/s10489-024-05982-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {NeuroMoCo: A neuromorphic momentum contrast learning method for spiking neural networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SANet: Similarity aggregation and semantic fusion for few-shot semantic segmentation. <em>APIN</em>, <em>55</em>(2), 1-12. (<a href='https://doi.org/10.1007/s10489-024-05986-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot semantic segmentation (FSS) methods based on meta-learning strategies have shown promise in extracting instance knowledge from support set to infer pixel-wise labels in query set. However, a key challenge in FSS is addressing spatial inconsistency between query image and support image due to intra-class difference and inter-class similarity. Moreover, existing FSS methods often rely on multiple decoding methods for differentiated pixel-wise matching, leading to semantic inconsistency. To tackle these issues, we propose a similarity aggregation network (SANet), which effectively explores visual correspondence between support and query features while aligning semantic dimensions. Specifically, SANet introduces a mask attention module (MAM) to capture spatial relations between non-local attention features from support features and query features. Additionally, a similarity aggregation module (SAM) is proposed, which utilizes the multi-head attention mechanism and combines prior mask to calculate the aggregation similarity between each query pixel and all supporting pixels, thereby focusing the network on foreground areas. Finally, a feature fusion module (FFM) is used to adaptively fuse features at multiple scales and channels for accurate prediction. Extensive experiments on PASCAL-5i and COCO-20i demonstrate the efficiency and competitiveness of SANet.},
  archive      = {J_APIN},
  author       = {Ye, Minrui and Zhang, Tao},
  doi          = {10.1007/s10489-024-05986-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {SANet: Similarity aggregation and semantic fusion for few-shot semantic segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global and local information-aware relational graph convolutional network for temporal knowledge graph completion. <em>APIN</em>, <em>55</em>(2), 1-15. (<a href='https://doi.org/10.1007/s10489-024-05987-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal knowledge graph completion (TKGC) focuses on inferring missing facts from temporal knowledge graphs (TKGs) and has been widely studied. While previous models based on graph neural networks (GNNs) have shown noteworthy outcomes, they tend to focus on designing complex modules to learn contextual representations. These complex solutions require a large number of parameters and heavy memory consumption. Additionally, existing TKGC approaches focus on exploiting static feature representation for entities and relationships, which fail to effectively capture the semantic information of contexts. In this paper, we propose a global and local information-aware relational graph convolutional neural network (GLARGCN) model to address these issues. First, we design a sampler, which captures significant neighbors by combining global historical event frequencies with local temporal relative displacements and requires no additional learnable parameters. We then employ a time-aware encoder to model timestamps, relations, and entities uniformly. We perform a graph convolution operation to learn a global graph representation. Finally, our method predicts missing entities using a scoring function. We evaluate the model on four benchmark datasets and one specific dataset with unseen timestamps. The experimental results demonstrate that our proposed GLARGCN model not only outperforms contemporary models but also shows robust performance in scenarios with unseen timestamps.},
  archive      = {J_APIN},
  author       = {Wang, Shuo and Chen, Shuxu and Zhong, Zhaoqian},
  doi          = {10.1007/s10489-024-05987-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Global and local information-aware relational graph convolutional network for temporal knowledge graph completion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QEFS: A novel plant disease prediction approach using quantum-inspired evolutionary feature selection. <em>APIN</em>, <em>55</em>(2), 1-23. (<a href='https://doi.org/10.1007/s10489-024-05990-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plant disease prediction is crucial for global food security, prompting the development of novel detection techniques. Initially, Convolution Neural Networks (CNNs) were extensively employed in this domain for their image recognition and object detection capabilities. Recently, with the evolution of Quantum Computing (QC), Quantum Convolutional Neural Networks (QCNNs) have demonstrated improved classification and prediction performance in classical problems, such as medical image analysis and drug discovery. QCNNs excel in classification by leveraging effective features generated through their layers. Features extracted from QCNNs utilize quantum parallelism to explore various feature combinations simultaneously, enhancing the network’s ability to capture intricate patterns and relationships in classical image datasets. However, the high-dimensional nature of these quantum-derived features necessitates effective Feature Selection (FS) to address the curse of dimensionality, improve model interpretability, and ensure computational efficiency in downstream tasks. The study presents Quantum-Inspired Evolutionary Feature Selection (QEFS), a unique method combining effective quantum feature extraction along with the FS approach employing an evolutionary algorithm to tackle this challenge. A hybrid evolutionary optimizer is formulated by integrating key attributes from fundamental optimizing algorithms, combining the strengths of basic optimizers to yield an enhanced hybrid algorithm. In this methodology, features are initially extracted using a QCNN model. Subsequently, these features undergo an FS process using the hybrid FS approach to determine the optimal feature count. The selected features are then fed into five Machine Learning (ML) classifiers for classification. To validate the effectiveness of this approach, the study leverages two distinct plant datasets—normal plants and medicinal plants. The primary objective of the research is binary as well as multi-class classification, specifically differentiating between healthy and diseased plant images. This methodological innovation aims to overcome current limitations in QCNN applications through effective FS using the evolutionary optimization technique.},
  archive      = {J_APIN},
  author       = {Anand, Khushi and Jain, Bhawna and Mittal, Himanshu and Yadav, Vijay Kumar},
  doi          = {10.1007/s10489-024-05990-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {QEFS: A novel plant disease prediction approach using quantum-inspired evolutionary feature selection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel multimodal contrast learning framework using zero-shot prediction for abnormal behavior recognition. <em>APIN</em>, <em>55</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10489-024-05994-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human abnormal behavior detection is important to ensure public safety and prevent unwanted incidents. Currently, recognition systems for human abnormal behavior adopt neural network models and perform standard 1-of-N majority voting procedures. However, recognizing human abnormal behaviors can be challenging due to lengthy and numerous video datasets and the limitations of existing methods that rely on predefined categories and scenarios. This study proposed a novel method named Visual Text Contrastive Learning (VTCL) for identifying abnormal human behavior in campus settings. The proposed model emphasizes semantic information from automatically labeled properties text and videos of abnormal behaviors, moving beyond simple numerical representations. The proposed method integrates the cross and multi-frame methods within the visual branch to improve spatial and temporal performance. In the textual branch, the proposed prompting technique captures the contextual backdrop of abnormal behaviors to enrich supervision with behavioral semantic information. Then, the model learns the visual-text features to enhance the learning process through contrastive learning techniques. In addition, this work also presented a new study to explore zero-shot campus abnormal behavior recognition (CABR). It lays the foundation for unlocking the implementation of highly available and robust CABR for multiple and even new scenarios. The proposed VTCL model demonstrated a Top-1 accuracy of 86.92% and a Top-5 accuracy of 98.14% on the CABR50 dataset, including fifty abnormal behaviors on campus, with competitive computational complexity. Furthermore, the zero-shot performance of the proposed model showed competitive outcomes when evaluated on additional datasets, including CABRZ6 and UCF-101.},
  archive      = {J_APIN},
  author       = {Liu, Hai Chuan and Mohd Khairuddin, Anis Salwa and Chuah, Joon Huang and Zhao, Xian Min and Wang, Xiao Dan and Fang, Li Ming and Kong, Si Bo},
  doi          = {10.1007/s10489-024-05994-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Novel multimodal contrast learning framework using zero-shot prediction for abnormal behavior recognition},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quality prediction of multi-stage batch process based on integrated ConvBiGRU with attention mechanism. <em>APIN</em>, <em>55</em>(2), 1-22. (<a href='https://doi.org/10.1007/s10489-024-06002-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is important for quality prediction and monitoring to ensure the safe operation of the process. When constructing a prediction model, it is crucial to choose appropriate input variables to influence the online prediction performance and quality monitoring. Data-driven techniques have been widely used for prediction and monitoring of quality variables, but there are some difficulties in the application of batch processes, three-dimensional characteristics of data, different initial conditions, and multi-stage characteristics within batches. Therefore, we propose a quality prediction model of multi-stage batch process based on integrated ConvBiGRU with attention mechanism (MI-ConvBiGRU-AM). Firstly, Firstly, the original 3D data are expanded into 2D time slices by the batch-variable expansion method. Secondly, the 2D time slices are clustered to complete stage identification using the improved affine propagation clustering method based on the design of the Markov chain similarity matrix. At each stage, we select product quality-related modeling variables using the Maximum Relevance Minimum Redundancy (mRMR). Then, the selected variables are used to train a convolutional bi-directional gated recurrent unit with an attention mechanism (ConvBiGRU-AM). Finally, ConvBiGRU-AM model for each stage is integrated together a whole prediction model for the entire process to accomplish quality prediction, and the prediction residuals are utilized for quality monitoring. The validity of the proposed method was verified by Industrial-scale fed-batch fermentation (IFBF) process and the Hot strip mill (HSM) process. For the IFBF process, the model achieved an FDR of 99.73%, FAR of 0.54%, MAE of 0.0043, RMSE of 0.0396, MAPE of 0.0121, and R2 of 0.9971. For the HSM process, the results were an FDR of 99.95%, FAR of 0.25%, MAE of 0.0053, RMSE of 0.0111, MAPE of 0.1539, and R2 of 0.9990. These results demonstrate that the proposed method significantly improves prediction accuracy and achieves better quality monitoring compared to existing methods, highlighting its effectiveness for industrial applications.},
  archive      = {J_APIN},
  author       = {Liu, Kai and Zhao, Xiaoqiang and Mou, Miao and Hui, Yongyong},
  doi          = {10.1007/s10489-024-06002-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Quality prediction of multi-stage batch process based on integrated ConvBiGRU with attention mechanism},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An anchor-free instance segmentation method for cells based on mask contour. <em>APIN</em>, <em>55</em>(2), 1-15. (<a href='https://doi.org/10.1007/s10489-024-06004-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection and segmentation of cells can be of great significance to the further quantitative analysis of biomedical research in the field of biomedical engineering. Especially, it is a serious challenging task for some microscope imaging devices with limited resources owing to a large number of learning parameters and computational burden when using the detect-then-segment two-stage strategy. In this work, an anchor-free instance segmentation method is proposed for cells based on mask contour. Specifically, an anchor-free network framework is firstly designed for instance segmentation by replacing the standard convolution in the contour generation branch with a deformable convolution. Then, these key contour points are linked to generate coarse contours of cells by using a Graham algorithm. Thirdly, the obtained coarse contours are used for regressing and approaching the ground truths in polar coordinates under the supervision of the Mask loss function. Finally, a series of comparison experiments are conducted to verify the effectiveness of the proposed methods on various datasets. The results show that the proposed method can obtain a better trade-off between recognition performance and computing efficiency, and it can surpass the existing one-stage SOTA methods in the Dice coefficient while maintaining higher computational efficiency on different datasets. Even with a two-stage instance segmentation method like Mask R-CNN, the proposed method can only obtain slightly lower Dice coefficients but with much higher FPS.},
  archive      = {J_APIN},
  author       = {Chen, Qi and Zhang, Huihuang and Zhou, Qianwei and Guan, Qiu and Hu, Haigen},
  doi          = {10.1007/s10489-024-06004-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {An anchor-free instance segmentation method for cells based on mask contour},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Niche-based memetic algorithm with adaptive parameters for optimizing order delivery strategies in O2O platforms. <em>APIN</em>, <em>55</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06006-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing prevalence of Online-to-Offline (O2O) commerce, online food ordering platforms are handling tens of millions of daily food orders. For O2O platforms, an efficient food delivery strategy is crucial as it directly impacts customer satisfaction and, subsequently, the platform’s competitiveness. To address the O2O food delivery problem’s (OFDP) unique features, including multi-depot with capacity, pickup-delivery, and time-window constraints, we have developed a heuristic algorithm called the Niche-based Memetic Algorithm with Adaptive Parameters (NMAAP). The NMAAP incorporates niche differentiation to increase population diversity and adaptive adjustment of crossover and mutation rates to balance exploration and exploitation, ultimately overcoming the issue of being trapped in local optima. To evaluate the effectiveness of the NMAAP, we conducted static and dynamic experiments using real order data obtained from Ele.me. The results of the experiments were promising and indicated that the NMAAP outperformed the baseline methods, resulting in reduced average and maximum waiting times for customers, in both static and dynamic settings. These findings emphasize the ability of the NMAAP to improve overall performance and enhance customer satisfaction in the O2O food delivery industry.},
  archive      = {J_APIN},
  author       = {Kong, Xiangyu and Zou, Guangyu and Qi, Heng and Tang, Jiafu and Hou, Yaqing},
  doi          = {10.1007/s10489-024-06006-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Niche-based memetic algorithm with adaptive parameters for optimizing order delivery strategies in O2O platforms},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SparseGraphX: Exponentially regularized optimal sparse graph for enhanced label propagation. <em>APIN</em>, <em>55</em>(2), 1-20. (<a href='https://doi.org/10.1007/s10489-024-06007-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based semi-supervised learning’s inherent ability to exploit the underlying structure of data distribution for supplementing label propagation has gained momentum over recent years. However, its effectiveness highly relies on the graph's structure quality and deteriorates when dealing with high dimensional, noisy, unevenly distributed data thus, necessitating adaptivity with sparsity in graph construction. To achieve this, an Exponentially Regularized Optimal Sparse Graph (EROSG) is introduced that inculcates these characteristics by exploring local connectivity ensuring efficient label propagation with reduced complexity. Accordingly, EROSG constructs the affinity matrix using a novel distance metric to widen the sample-wise interclass deviation and strengthen the local connectivity. The resulting affinity matrix is then optimized by Lagrangian multipliers with non-negative and SoftMax constraints to yield the adaptive sparse graph facilitating label propagation. Extensive analysis of EROSG on diverse datasets demonstrates consistent and superior accuracy of over 93% with a minimum availability of 5–10% of labeled data which is lacking in its competitors. Also, EROSG’s parameter-free nature lessens realization complexity emphasizing the need of the hour.},
  archive      = {J_APIN},
  author       = {M, Kanimozhi and MS, Sudhakar},
  doi          = {10.1007/s10489-024-06007-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {SparseGraphX: Exponentially regularized optimal sparse graph for enhanced label propagation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Talking-head video generation with long short-term contextual semantics. <em>APIN</em>, <em>55</em>(2), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06010-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-shot talking-head video generation involves a face-appearance source image and a series of motions extracted from driving frames to produce a coherent video. Most existing methods merely use the source image to generate videos over long time intervals, which leads to detail loss and distorted images due to the semantics mismatch. Short-term semantics extracted from previous generated frames with temporal consistency can complement the mismatches of long-term semantics. In this paper, we propose a talking-head generation method utilizing long short-term contextual semantics. First, the cross-entropy of real frame and generated frame with long short-term Semantics is mathematically modeled. Then, a novel semi-autoregressive GAN is proposed to efficiently avoid semantics mismatch by utilizing complementary long-term and autoregressively extracted short-term semantics. Moreover, a short-term semantics enhancement module is proposed aiming for suppressing the noise in the autoregressive pipeline and reinforcing fusion of the long short-term semantics. Extensive experiments have been performed and the experimental results demonstrate that our method can generate detailed and refined frames and outperforms the other methods, particularly with large motion changes.},
  archive      = {J_APIN},
  author       = {Jing, Zhao and Bie, Hongxia and Wang, Jiali and Bie, Zhisong and Li, Jinxin and Ren, Jianwei and Zhi, Yichen},
  doi          = {10.1007/s10489-024-06010-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Talking-head video generation with long short-term contextual semantics},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can neural networks estimate parameters in epidemiology models using real observed data?. <em>APIN</em>, <em>55</em>(2), 1-16. (<a href='https://doi.org/10.1007/s10489-024-06012-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary objective of this study is to address the challenges associated with estimating parameters in mathematical epidemiology models, which are crucial for understanding the dynamics of infectious diseases within a population. The scope of this research includes the development and application of a two-phase neural network for parameter estimation, specifically within the context of epidemic compartmental models. This study presents a novel approach by integrating an extreme learning machine with a heuristic population-based optimization method within a two-phase neural network framework. The networks are driven by a heuristic population-based optimization method, enhancing the accuracy and efficiency of parameter estimation in mathematical epidemiology models. The effectiveness of the method is validated using actual COVID-19 data provided by the Turkish Ministry of Health. The data includes cases categorized as Susceptible, Exposed, Infected, Removed, and Deceased, which are crucial components of epidemic compartmental models. The obtained results highlight the capability of the proposed method to provide insights into the spread of infectious diseases by offering reliable estimates of model parameters. This, in turn, supports better understanding and forecasting of disease dynamics. The methodology provides a significant contribution to the field by offering a new, efficient technique for parameter estimation in epidemiological models.},
  archive      = {J_APIN},
  author       = {Ahmad, Muhammad Jalil and Günel, Korhan},
  doi          = {10.1007/s10489-024-06012-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Can neural networks estimate parameters in epidemiology models using real observed data?},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic detection of obstructive sleep apnea through nonlinear dynamics of single-lead ECG signals. <em>APIN</em>, <em>55</em>(2), 1-29. (<a href='https://doi.org/10.1007/s10489-024-06013-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obstructive Sleep Apnea (OSA) is a sleep disorder where the brain and body receive insufficient oxygen during sleep. Traditional diagnosis involves Polysomnography (PSG), which is time-consuming, tedious, subjective, and costly in clinical settings. To address these drawbacks, computer-assisted diagnosis techniques have emerged, utilizing a single physiological signal. This study aims to introduce an innovative method for automatically detecting OSA based on the dynamics of the ECG system. The approach combines tunable quality factor (Q-factor) wavelet transform (TQWT), variational mode decomposition (VMD), and three-dimensional (3D) phase space for feature extraction, capturing clinically relevant information from OSA ECG recordings. Neural networks are employed to model and identify ECG system dynamics via deterministic learning theory, classifying normal and OSA ECG signals based on differences in dynamics using a bank of dynamical estimators. An assessment is conducted utilizing a 10-fold cross-validation methodology on a PhysioNet apnea-ECG dataset, which comprises 70 nocturnal recordings derived from an equal number of subjects. The empirical outcomes demonstrate that the introduced approach, which amalgamates a classifier based on neural network principles and the recommended attributes, attains superior accuracy (98.27 $$\%$$ ), sensitivity (97.68 $$\%$$ ), and specificity (98.63 $$\%$$ ) in contrast to conventional PSG. The results corroborate the suggested technique as a viable substitute for automatic OSA detection in a clinical setting.},
  archive      = {J_APIN},
  author       = {Chen, Liangjie and Liu, Fenglin and Wang, Ying and Wang, Qinghui and Yuan, Chengzhi and Zeng, Wei},
  doi          = {10.1007/s10489-024-06013-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-29},
  shortjournal = {Appl. Intell.},
  title        = {Automatic detection of obstructive sleep apnea through nonlinear dynamics of single-lead ECG signals},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multivariate time series classification based on spatial-temporal attention dynamic graph neural network. <em>APIN</em>, <em>55</em>(2), 1-18. (<a href='https://doi.org/10.1007/s10489-024-06014-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series classification (MVTSC) has significant potential for Internet of Things applications. Recently, deep learning (DL) and graph neural network (GNN) methods have been applied to MVTSC tasks. Unfortunately, DL-based methods ignore explicit inter-series correlation modeling. Most existing GNN-based methods treat MVTS data as a static graph spanning the entire temporal trajectory, which inadequately captures changes in inter-series local correlations. To address this problem, we propose the spatial-temporal attention dynamic GNN (STADGNN), which explicitly models dynamic inter-series correlations by constructing the MVTS data into a dynamic graph structure at a finer granularity. It combines discrete Fourier transform (DFT) and discrete wavelet transform (DWT), which extract the global and local features of MVTS data in an end-to-end framework. In dynamic graph learning, spatial-temporal attention mechanisms are employed to simultaneously capture changes in inter-series local correlations and intra-series temporal dependencies without relying on predefined priors. Experimental results on 25 UEA datasets indicate that the STADGNN outperforms existing DL-based and GNN-based baseline models in MVTSC tasks.},
  archive      = {J_APIN},
  author       = {Qian, Lipeng and Zuo, Qiong and Liu, Haiguang and Zhu, Hong},
  doi          = {10.1007/s10489-024-06014-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Multivariate time series classification based on spatial-temporal attention dynamic graph neural network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-path decoder architecture for semantic segmentation of wheat ears. <em>APIN</em>, <em>55</em>(2), 1-13. (<a href='https://doi.org/10.1007/s10489-024-06023-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a dual-path decoder segmentation network (DPDS) is presented, which innovatively introduces a dual-path structure into a semantic segmentation network incorporating atrous spatial pyramid pooling (ASPP). A novel loss function, boundary focal loss (BFLoss), is designed specifically for wheat ears segmentation scenarios, which adaptively adjusts weights for different pixel points through the binarization of boundary information, focusing the training on the edges of wheat ears. It is suggested to apply the DPDS network in conjunction with BFLoss to the semantic segmentation of wheat ears. The experimental results demonstrated that BFLoss possesses advantages over commonly used binary cross entropy loss (BCELoss) and focal loss in semantic segmentation. Additionally, the dual-path decoder architecture was proved to reach higher precision than activating only one of the pathways. In comparative experiments with established semantic segmentation networks, the DPDS model achieved the best performance on several evaluation metrics, and attained a balance between precision and recall. Notably, the combination of DPDS and BFLoss achieved a 91.86% F1 score on the wheat ears semantic segmentation test dataset. Therefore, the DPDS model can be effectively applied to semantic segmentation scenarios of crops like wheat, and also provides new insights for the improvement of existing networks. Code is available at https://github.com/awesome-pythoner/dual-path-decoder-segment .},
  archive      = {J_APIN},
  author       = {Wang, Lihui and Chen, Yu},
  doi          = {10.1007/s10489-024-06023-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Dual-path decoder architecture for semantic segmentation of wheat ears},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A swin-transformer-based network with inductive bias ability for medical image segmentation. <em>APIN</em>, <em>55</em>(2), 1-18. (<a href='https://doi.org/10.1007/s10489-024-06029-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately segmenting organs, or diseased regions of varying sizes, is a challenge in medical image segmentation tasks with limited datasets. Although Transformer-based methods have self-attention mechanisms, excellent global modelling abilities and can effectively focus on crucial areas in medical images, they still face the intractable issues of computational complexity and excessive reliance on data. The Swin-Transformer has partly addressed the problem of computational complexity, however the method still requires large amounts of training data due to its lack of inductive bias capabilities. When applied to medical image segmentation tasks with small datasets, this leads to suboptimal performances. In contrast, the CNN-based methods can compensate for this limitation. To address this issue further, this paper proposes Swin-IBNet, which combines the Swin-Transformer with a CNN in a novel manner to imbue it with inductive bias capabilities, reducing its reliance on data. During the encoding process of Swin-IBNet, two novel and crucial modules, the feature fusion block (FFB) and the multiscale feature aggregation block (MSFA), are designed. The FFB is responsible for propagating the inductive bias capability to the Swin-Transformer encoder. Different from the previous use of multiscale features, MSFA efficiently leverages multiscale information from different layers through self-learning. This paper not only attempts to analyse the interpretability of the proposed Swin-IBNet but also performs more verifications on the public Synapse, ISIC 2018 and ACDC datasets. The experimental results show that Swin-IBNet is superior to the baseline method, Swin-Unet, and several state-of-the-art methods. Especially on the Synapse dataset, the DSC of Swin-IBNet surpasses that of Swin-Unet by 3.45%.},
  archive      = {J_APIN},
  author       = {Gao, Yan and Xu, Huan and Liu, Quanle and Bie, Mei and Che, Xiangjiu},
  doi          = {10.1007/s10489-024-06029-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {A swin-transformer-based network with inductive bias ability for medical image segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedIBD: A federated learning framework in asynchronous mode for imbalanced data. <em>APIN</em>, <em>55</em>(2), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06032-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of edge computing and Internet of Things (IoT), the computing power of edge devices continues to increase, and the data obtained is more specific and private. Methods based on Federated Learning (FL) can help utilize the data that exists widely on edge devices in a privacy-preserving way and train a shareable global model collaboratively. However, the imbalanced data from edge devices pose a huge challenge to FL, as data features extracted from uneven, biased, and incomplete samples complicate the model aggregation process required to achieve well-performing models. To support FL on imbalanced data, a new asynchronous FL framework, named FedIBD: Federated learning framework in Asynchronous mode for Imbalanced Data, is proposed. FedIBD not only considers the temporal inconsistency in asynchronous learning but also measures the informative differences in imbalanced data to support FL in asynchronous and heterogeneous environments. Compared with the existing synchronous and asynchronous FL methods, FedIBD can achieve significantly better performance in terms of accuracy, communication time and cost on imbalanced data.},
  archive      = {J_APIN},
  author       = {Hou, Yingwei and Li, Haoyuan and Guo, Zihan and Wu, Weigang and Liu, Rui and You, Linlin},
  doi          = {10.1007/s10489-024-06032-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {FedIBD: A federated learning framework in asynchronous mode for imbalanced data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KnowGNN: A knowledge-aware and structure-sensitive model-level explainer for graph neural networks. <em>APIN</em>, <em>55</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06034-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-level Graph Neural Network (GNN) explanation methods have become essential for understanding the decision-making processes of GNN models on a global scale. Many existing model-level GNN explanation methods often fail to incorporate prior knowledge of the original dataset into the initial explanation state, potentially leading to suboptimal explanation results that diverge from the real distribution of the original data. Moreover, these explainers often treat the nodes and edges within the explanation as independent elements, ignoring the structural relationships between them. This is particularly problematic in graph-based explanation tasks that are highly sensitive to structural information, which may unconsciously make the explanations miss key patterns important for the GNNs’ prediction. In this paper, we introduce KnowGNN, a knowledge-aware and structure-sensitive model-level GNN explanation framework, to explain GNN models in a global view. KnowGNN starts with a seed graph that incorporates prior knowledge of the dataset, ensuring that the final explanations accurately reflect the real data distribution. Furthermore, we construct a structure-sensitive edge mask learning method to refine the explanation process, enhancing the explanations’ ability to capture key features. Finally, we employ a simulated annealing (SA)-based strategy to control the explanation errors efficiently and thus find better explanations. We conduct extensive experiments on four public benchmark datasets. The results show that our method outperforms state-of-the-art explanation approaches by focusing explanations more closely on the actual characteristics of the data.},
  archive      = {J_APIN},
  author       = {Ma, Yinglong and Liu, Xiaofeng and Guo, Chenqi and Jin, Beihong and Liu, Huili},
  doi          = {10.1007/s10489-024-06034-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {KnowGNN: A knowledge-aware and structure-sensitive model-level explainer for graph neural networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Echo lite voice fusion network: Advancing underwater acoustic voiceprint recognition with lightweight neural architectures. <em>APIN</em>, <em>55</em>(2), 1-10. (<a href='https://doi.org/10.1007/s10489-024-06035-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater acoustic voiceprint recognition, serving as a key technology in the field of biometric identification, presents a wide range of application prospects, especially in areas such as marine resource development, underwater communication, and underwater safety monitoring. Conventional acoustic voiceprint recognition methods exhibit limitations in underwater environments, prompting the need for a lightweight neural network approach to optimally address underwater acoustic voiceprint recognition tasks. This paper introduces a novel lightweight voicing recognition model, the Echo Lite Voice Fusion Network (ELVFN), which incorporates depthwise separable convolution and self-attention mechanism, and significantly improves voicing recognition performance by optimizing acoustic feature extraction technology and hierarchical feature fusion strategy. Concurrently, the computational complexity and parameter quantity of the model are substantially reduced. Comparative analyses with existing acoustic voiceprint recognition models corroborate the superior performance of our model across multiple underwater acoustic datasets. Experimental results demonstrate that ELVFN outperforms in various evaluation metrics, notably in terms of processing efficiency and recognition accuracy. Finally, we discuss the application potential and future development directions of the model, providing an efficient solution for underwater acoustic voiceprint recognition in resource-constrained environments.},
  archive      = {J_APIN},
  author       = {Wu, Jiaqi and Guan, Donghai and Yuan, Weiwei},
  doi          = {10.1007/s10489-024-06035-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-10},
  shortjournal = {Appl. Intell.},
  title        = {Echo lite voice fusion network: Advancing underwater acoustic voiceprint recognition with lightweight neural architectures},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multifactorial modality fusion network for multimodal recommendation. <em>APIN</em>, <em>55</em>(2), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06038-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal recommendation systems aim to deliver precise and personalized recommendations by integrating diverse modalities such as text, images, and audio. Despite their potential, these systems often struggle with effective modality fusion strategies and comprehensive modeling of user preferences. To address these issues, we propose the Multifactorial Modality Fusion Network (MMFN). MMFN overcomes the limitations of previous models by following pivotal architectures. First, this novel approach employs three Graph Neural Networks (GNN) to extract foundational interactions and semantic information across modalities meticulously. Second, a Gated Multi-factor Semantic Sensor operates through a series of stacked gating units, guided by interaction embeddings, to extract features from modal embeddings deeply. Third, a User Preference-Oriented Modality Aligner, leveraging contrastive learning to synchronize user preferences with item features, thus enhancing the expressiveness of embeddings and the overall quality of recommendations. We demonstrate the marked superiority of MMFN in both performance and efficiency compared to traditional collaborative filtering methods and contemporary deep multimodal recommendation systems. Through comprehensive evaluations on the baby, sports, and clothing datasets, MMFN achieves significant gains in Recall@20 metrics, with improvements of 2.49%, 8.79%, and 24.51% over the following best baseline models. Additionally, MMFN also leads in training efficiency, outperforming most competing models. MMFN paves the way for future multimodal recommendation systems, leveraging the full spectrum of deep learning technologies.},
  archive      = {J_APIN},
  author       = {Chen, Yanke and sun, Tianhao and Ma, Yunhao and Zou, Huhai},
  doi          = {10.1007/s10489-024-06038-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Multifactorial modality fusion network for multimodal recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-focus image fusion network with local-global joint attention module. <em>APIN</em>, <em>55</em>(2), 1-22. (<a href='https://doi.org/10.1007/s10489-024-06039-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-focus image fusion can obtain high-quality images by overcoming the limited depth of field of optical lenses. Benefiting from deep learning, we design a local-global joint attention module and propose a novel multi-focus image fusion network. The module essentially is an attention module. Local and global features are extracted respectively through point-wise convolution and spatial pyramid pooling. A joint attention map is produced by reducing the dimension and fusing these two features. The proposed network is mainly composed of a feature fusion module and two weight-shared dense feature extraction modules, each connected to six consecutive attention modules. Such design has two benefits: adequate extraction of initial features and capturing of local and global features. Subjective visual evaluation demonstrates that the proposed network can preserve the authenticity of fusion results. And it also reduces the appearance of artifacts and detail losses between the focus and defocus regions. Objective metric evaluation shows that the proposed network outperforms most of the existing models, such as SwinFusion, GACN, and UFA-FUSE, in Lytro, MFI-WHU, and MFFW datasets. Ablation experiments demonstrate that the design of attention and the overall framework of the network is reasonable. Overall, the proposed model can finish the multi-focus image fusion task with high quality.},
  archive      = {J_APIN},
  author       = {Zou, Xinheng and Yang, You and Zhai, Hao and Jiang, Weiping and Pan, Xin},
  doi          = {10.1007/s10489-024-06039-z},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {A multi-focus image fusion network with local-global joint attention module},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection of H.266/VVC video transcoding based on refined block partition and filtering modes statistics in coding domain. <em>APIN</em>, <em>55</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06040-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video transcoding has posed significant challenges to the authenticity and integrity of digital videos, which makes the detection of transcoded videos one of the most important video forensics techniques. However, the detection of transcoded H.266/Versatile Video Coding (H.266/VVC) videos is rarely reported in the literature. To tackle this issue, we first analyze the generation of VVC transcoding traces. It is found that the variation of the block partition and filtering modes in video frames can be used as the clue to expose VVC transcoding. Then a series of refined coding technologies in VVC, such as Multi-type Tree (QTMT) partition and new in-loop filtering, are analyzed to facilitate feature selection. On this basis, the proportions of Coding Units (CUs) with different sizes in intra-coded frames, filtering modes in Deblocking Filtering (DBF), positive and negative offsets in Sample Adaptive Offset Filtering (SAOF), and blocks with different categories in Adaptive Loop Filtering (ALF) are used for feature construction. These feature sets are further concatenated into a 61-dimensional feature vector for supervised learning and video classification. Extensive experiments are conducted to evaluate the performance. The results demonstrate the effectiveness and robustness of our method in transcoding detection.},
  archive      = {J_APIN},
  author       = {Xu, Qiang and Wang, Hao and Xu, Dongmei and Yuan, Jianye and Yan, Hong},
  doi          = {10.1007/s10489-024-06040-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Detection of H.266/VVC video transcoding based on refined block partition and filtering modes statistics in coding domain},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight diagnosis method for gear fault based on multi-path convolutional neural networks with attention mechanism. <em>APIN</em>, <em>55</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06094-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fault diagnosis of gear is indeed a crucial aspect of maintaining rotating machinery, as it helps in ensuring the safe and efficient operation of industrial equipment. Deep learning models have gained significant attention for gear fault diagnosis due to their ability to automatically extract features from raw data, but they also come with their own set of challenges. One major limitation of existing methods is the insufficient consideration given to the impact of environmental noise at industrial field on the diagnostic effectiveness of the models. Additionally, there is a contradiction between the week computational resources of current embedded platforms for industrial field device applications and the large number of parameters and computations required for deep learning models. This may hinder the deployment of complex models in industrial field devices. To address these issues, a novel approach to multi-path convolutional neural network with dual branch attention (AMPCNN) has been proposed. This approach aims to enhance the recognition of different fault types and maintain high accuracy in noisy environments by extracting multi-scale features of the original vibration signal using multi-path convolution and dual branch attention mechanisms. Furthermore, a multi-knowledge distillation (MKD) method has been introduced to construct lightweight multi-sensor gear fault diagnosis models. This approach facilitates the transfer of multiple knowledge from a complex teacher network to a simpler student network, resulting in a lightweight model that exhibits excellent robustness in various noise environments. The experimental results show that the lightweight model achieves high accuracy while requiring significantly fewer floating-point operations and parameter quantities compared to the original teacher network.},
  archive      = {J_APIN},
  author       = {Chen, Tianming and Wang, Manyi and Jiang, Yilin and Yao, Jiachen and Li, Ming},
  doi          = {10.1007/s10489-024-06094-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {A lightweight diagnosis method for gear fault based on multi-path convolutional neural networks with attention mechanism},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-lingual prompting method with semantic-based answer space clustering. <em>APIN</em>, <em>55</em>(2), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06101-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prompt learning has achieved remarkable performance in various natural language understanding scenarios as it intuitively bridges the gap between pre-training and fine-tuning. However, directly applying monolingual prompting methods to cross-lingual tasks leads to discrepancies between source-language training and target-language inference, namely language bias in cross-lingual transfer. To address this gap, we propose a novel model called Cross-lingual Semantic Clustering Prompt (X-SCP). Specifically, in the prompt engineering stage, we design a language-agnostic prompt template and introduce a progressive code-switching approach to enhance the alignment between source and target languages. In the answer engineering stage, we construct a unified multilingual answer space through semantic consistency-guided clustering. The model trains a cluster-based verbalizer by learning a pre-clustered multilingual answer space. In this way, X-SCP alleviates language bias in both prompt engineering and answer engineering. Experimental results show that our model outperforms the strong baselines under zero-shot cross-lingual settings on both the XGLUE-NC and MLDoc document classification datasets.},
  archive      = {J_APIN},
  author       = {Ahmat, Ahtamjan and Yang, Yating and Ma, Bo and Dong, Rui and Ma, Rong and Wang, Lei},
  doi          = {10.1007/s10489-024-06101-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Cross-lingual prompting method with semantic-based answer space clustering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GRUDMU-DSCNN: An edge computing method for fault diagnosis with missing data. <em>APIN</em>, <em>55</em>(2), 1-23. (<a href='https://doi.org/10.1007/s10489-024-06104-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional deep learning methods for rolling bearing fault diagnosis require a lot of computational time and resources. At the same time, the accuracy of fault diagnosis is affected by missing data collected due to the instability of sensors or data acquisition systems. In this paper, we propose a fault diagnosis method based on Gated Recurrent Unit with Decays and Maskless Update—Depthwise Separable Convolution Neural Network (GRUDMU-DSCNN). First, we use the trainable attenuation mechanism in GRUDMU for effective imputation of missingness and change the position of mask vectors to deal with missing data and solve the problem of missing data affecting the accuracy of fault diagnosis. In addition, we combine GRUDMU with DSCNN and deploy the model to edge devices. This improves the effectiveness of real-time fault diagnosis in edge computing scenarios. Furthermore, to verify whether the proposed method is effective in improving the accuracy of fault diagnosis in two missing patterns, namely Interval Missing and Missing Completely At Random (MCAR), we used a customized experimental equipment dataset and open experiments. The NVIDIA Jetson Xavier NX suite served as the edge computing platform to verify the effectiveness and superiority of the proposed model. The results indicate an average improvement in classification accuracy of 8.07% and 9.65% on both datasets when compared to existing methods.},
  archive      = {J_APIN},
  author       = {Yu, Ziyang and Wang, Yanzhi and Zong, Xiaofeng and Wu, Jinhong and Zhou, Qi},
  doi          = {10.1007/s10489-024-06104-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {GRUDMU-DSCNN: An edge computing method for fault diagnosis with missing data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved convolution neural network integrating attention based deep sparse auto encoder for network intrusion detection. <em>APIN</em>, <em>55</em>(2), 1-17. (<a href='https://doi.org/10.1007/s10489-024-05872-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network intrusion detection (NID) is seen as a pivotal technology in the network security which can detect malicious threats occurring in the network and lend stabilized services for expanding the network environments. However, Network-based Intrusion Detection Systems (NIDSs) are not sensitive to infrequent intrusions features and tend to have high misjudgment rate on imbalanced datasets, which lead to obvious defects for detecting minority classes of intrusion. Therefore, a novel neoteric NID methodology predicated upon an optimized convolutional neural network (CNN) integrating Attention based Deep Sparse Auto Encoder (ADSAE) (ADSAE-CNN) is put forward. The data expanding method based on the ADSAE model integrates attention mechanisms with deep stacked autoencoders to expand intrusion records of minority classes in data preprocessing, so as to balance the data distribution of intrusion detection datasets, improve the sensitivity of the detection model to the intrusion of few categories, and enhance the monitoring of the intrusion by the system. Meanwhile, the ADSAE can encode and transform the intrusion data to ameliorate the feature extraction capability of convolutional layers of the proposed ADSAE-CNN for detecting and classifying different intrusions classes. Finally, the ADSAE-CNN methodology is devoted to the network intrusion detection of two experiments on UNSW-NB15 and CSE-CIC-IDS2018 datasets and achieves the total precision of detection 89.1% on UNSW-NB15 and 94.20% on CSE-CIC-IDS2018, which can lead to considerably elevate the detection rate of minority intrusions and means significant effectiveness on multi-class network intrusion detections.},
  archive      = {J_APIN},
  author       = {Geng, Zhiqiang and Li, Xueming and Ma, Bo and Han, Yongming},
  doi          = {10.1007/s10489-024-05872-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Improved convolution neural network integrating attention based deep sparse auto encoder for network intrusion detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensemble deep neural network method for solving free boundary american style stochastic volatility models. <em>APIN</em>, <em>55</em>(2), 1-37. (<a href='https://doi.org/10.1007/s10489-024-05897-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an ensemble deep learning method for solving free boundary American-style stochastic volatility models. Our solution framework for such free boundary problems—where the early exercise boundary surface is a function of time and volatility—is developed so as to obtain the value function and Greeks simultaneously. To this end, we first use the Landau transformation to fix the free boundary, and we normalize the value function and the time domain. We then develop a novel ensemble auxiliary operator (EANO) involving a suite of configurations based on an ensemble neural network output (EDNN). The early exercise boundary surface, value function, delta sensitivity, vega, gamma, vomma and vanna are predicted from the EDNN, EANO, and the derivatives of the EANO after training. The performance of our neural network configuration is validated by comparison with existing methods and examples. Results show that our ensemble learning method achieves good predictive potential with a small dataset and training time. In particular, it performs well when the correlation factor $$\rho $$ is high, a situation which has been shown in the literature to give rise to computational error and numerical instability arising from the mixed derivative term.},
  archive      = {J_APIN},
  author       = {Nwankwo, Chinonso and Ware, Tony and Dai, Weizhong},
  doi          = {10.1007/s10489-024-05897-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-37},
  shortjournal = {Appl. Intell.},
  title        = {Ensemble deep neural network method for solving free boundary american style stochastic volatility models},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HyperLips: Hyper control lips with high resolution decoder for talking face generation. <em>APIN</em>, <em>55</em>(2), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05914-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Talking face generation has a wide range of potential applications in the field of virtual digital humans. However, rendering high-fidelity facial video while ensuring lip synchronization remains challenging for existing audio-driven talking face generation approaches. To tackle this problem, we present HyperLips, a two-stage framework comprising a hypernetwork for lip control and a high-resolution decoder for generating high-fidelity faces. In the first stage, we develop a base face generation network that utilizes the hypernetwork to regulate the encoding latent code of the visual face information based on audio. The process begins using FaceEncoder to extract features from the face frame, resulting in a latent code. Next, HyperConv modifies the latent code to synchronize the lip movement with the audio, with its weighting parameters updated by HyperNet using the audio features as input. Finally, the FaceDecoder decodes the modified and synchronized latent code into visual face content. In the second stage, higher-quality face videos are obtained through a high-resolution decoder. To enhance face generation quality, we trained a high-resolution decoder, HRDecoder, using face images and detected sketches generated from the first stage as input. The experimental results on benchmarks LRS2 show that the performance of HyperLips is obviously beyond the state-of-the-art methods, e.g., the PSNR, SSIM (higher is better) are improved from 33.281, 0.894 to 34.914, 0.914, respectively; LPIPS, FID, LMD (lower is better) are reduced from 0.051, 5.199, 1.471 to 0.032, 3.690, 1.186, respectively. Our method outperforms state-of-the-art with more realistic, high-fidelity, and lip-synchronized talking faces, as demonstrated by extensive quantitative and qualitative experiments. Please refer our project page as below: https://semchan.github.io/HyperLips_Project/},
  archive      = {J_APIN},
  author       = {Chen, Yaosen and Yao, Yu and Li, Zhiqiang and Wang, Wei and Zhang, Yanru and Yang, Han and Wen, Xuming},
  doi          = {10.1007/s10489-024-05914-z},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {HyperLips: Hyper control lips with high resolution decoder for talking face generation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HFL-GAN: Scalable hierarchical federated learning GAN for high quantity heterogeneous clients. <em>APIN</em>, <em>55</em>(2), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05924-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel approach for training generative adversarial networks using federated machine learning. Generative adversarial networks have gained plenty of attention in the research community especially with their abilities to produce high quality synthetic data for a variety of use-cases. Yet, when combined with federated learning, those models suffer from degradation in both training time and quality of results. To address this challenge, this paper introduces a novel approach that uses hierarchical learning techniques to enable the efficient training of federated GAN models. The proposed approach introduces an innovative mechanism that dynamically clusters participant clients to edge servers as well as a novel multi-generator GAN architecture that utilizes non-identical model aggregation stages. The proposed approach has been evaluated on a number of benchmark datasets to measure its performance on higher numbers of participating clients. The results show that HFL-GAN outperforms other comparative state-of-the-art approaches in the training of GAN models in complex non-IID federated learning settings.},
  archive      = {J_APIN},
  author       = {Petch, Lewis and Moustafa, Ahmed and Ma, Xinhui and Yasser, Mohammad},
  doi          = {10.1007/s10489-024-05924-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {HFL-GAN: Scalable hierarchical federated learning GAN for high quantity heterogeneous clients},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised perturbation based self-supervised federated adversarial training. <em>APIN</em>, <em>55</em>(2), 1-12. (<a href='https://doi.org/10.1007/s10489-024-05938-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similar to traditional machine learning, federated learning is susceptible to adversarial attacks. Existing defense methods against federated attacks often rely on extensive labeling during the local training process to enhance model robustness. However, labeling typically requires significant resources. To address the challenges posed by expensive labeling and the robustness issues in federated learning, we propose the Unsupervised Perturbation based Self-Supervised Federated Adversarial Training (UPFAT) framework. Within local clients, we introduce an innovative unsupervised adversarial sample generation method, which adapts the classical self-supervised framework BYOL (Bootstrap Your Own Latent). This method maximizes the distances between embeddings of various transformations of the same input, generating unsupervised adversarial samples aimed at confusing the model. For model communication, we present the Robustness-Enhanced Moving Average (REMA) module, which adaptively utilizes global model updates based on the local model’s robustness.Extensive experiments demonstrate that UPFAT outperforms existing methods by $$\varvec{3\sim 4\%}$$ .},
  archive      = {J_APIN},
  author       = {Zhang, Yuyue and Ye, Hanchen and Zhao, Xiaoli},
  doi          = {10.1007/s10489-024-05938-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {Unsupervised perturbation based self-supervised federated adversarial training},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collision avoidance time-varying group formation tracking control for multi-agent systems. <em>APIN</em>, <em>55</em>(2), 1-13. (<a href='https://doi.org/10.1007/s10489-024-05959-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study considers the time-varying group formation (TVGF) tracking control problem for general linear multi-agent systems (MASs) with collision avoidance, where the MAS is divided into multiple subgroups, enabling followers to form prescribed formations and track trajectories provided by their respective leaders without collisions. Firstly, a distributed TVGF tracking control protocol is introduced using only relative information among neighboring agents. Then, feasibility conditions under which MASs can successfully realize the TVGF tracking without collisions are put forward. Utilizing Lyapunov stability theory, the convergence of the TVGF tracking error systems is confirmed, ensuring the collision-free achievement of the desired formation. Finally, some simulation examples are provided to validate the effectiveness of the theoretical results.},
  archive      = {J_APIN},
  author       = {Li, Weihao and Zhou, Shiyu and Shi, Mengji and Yue, Jiangfeng and Lin, Boxian and Qin, Kaiyu},
  doi          = {10.1007/s10489-024-05959-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Collision avoidance time-varying group formation tracking control for multi-agent systems},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale feature map fusion encoding for underwater object segmentation. <em>APIN</em>, <em>55</em>(2), 1-17. (<a href='https://doi.org/10.1007/s10489-024-05971-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater object segmentation presents significant challenges due to the degradation of image quality and the complexity of underwater environments. In recent years, deep learning has provided an effective approach for object segmentation. However, DeepLabV3+, as a classical model for general scenes, shows limitations in achieving accurate and real-time segmentation in complex underwater conditions. To address this issue, we propose a DeepLab-FusionNet, an extended version of DeepLabV3+, specifically designed for underwater object segmentation. The model utilizes a multi-resolution parallel branch structure to extract multi-scale information and employs an improved inverted residual structure as the basic feature extraction module in the encoding network. Structural reparameterization technique is introduced to optimize inference speed and memory access costs during the inference stage. Additionally, a module for linking deep and shallow level information is constructed to reduce the loss of detail and spatial information during downsampling and convolution. Evaluation on the SUIM dataset shows a 3.3% increase in mean Intersection over Union (mIoU) and a speed improvement of 34 frames per second (FPS) compared to the baseline model DeepLabV3+. Further comparisons with other classic lightweight models and Transformer-based models on the UIIS and TrashCan datasets demonstrate that our model achieves good accuracy and balanced computational efficiency in challenging underwater environments. Although there is room for improvement due to overfitting and fixed convolution kernel limitations, future integration with Transformer methods is planned. Our model offers an effective solution for real-time target segmentation for underwater robots, with broad applications in human exploration and development of marine resources. Our codes are available at: https://github.com/sunmer1rain/deeplabv_fusionnet},
  archive      = {J_APIN},
  author       = {Liu, Chengxiang and Yao, Haoxin and Qiu, Wenhui and Cui, Hongyuan and Fang, Yubin and Xu, Anqi},
  doi          = {10.1007/s10489-024-05971-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Multi-scale feature map fusion encoding for underwater object segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constructing explainable health indicators for aircraft engines by developing an interpretable neural network with discretized weights. <em>APIN</em>, <em>55</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10489-024-05981-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remaining useful life predictions depend on the quality of health indicators (HIs) generated from condition monitoring sensors, evaluated by predefined prognostic metrics such as monotonicity, prognosability, and trendability. Constructing these HIs requires effective models capable of automatically selecting and fusing features from pertinent measurements, given the inherent noise in sensory data. While deep learning approaches have the potential to automatically extract features without the need for significant specialist knowledge, these features lack a clear (physical) interpretation. Furthermore, the evaluation metrics for HIs are nondifferentiable, limiting the application of supervised networks. This research aims to develop an intrinsically interpretable ANN, targeting qualified HIs with significantly lower complexity. A semi-supervised paradigm is employed, simulating labels inspired by the physics of progressive damage. This approach implicitly incorporates nondifferentiable criteria into the learning process. The architecture comprises additive and newly modified multiplicative layers that combine features to better represent the system’s characteristics. The developed multiplicative neurons are not restricted to pairwise actions, and they can also handle both division and multiplication. To extract a compact HI equation, making the model mathematically interpretable, the number of parameters is further reduced by discretizing the weights via a ternary set. This weight discretization simplifies the extracted equation while gently controlling the number of weights that should be overlooked. The developed methodology is specifically tailored to construct interpretable HIs for commercial turbofan engines, showcasing that the generated HIs are of high quality and interpretable.},
  archive      = {J_APIN},
  author       = {Moradi, Morteza and Komninos, Panagiotis and Zarouchas, Dimitrios},
  doi          = {10.1007/s10489-024-05981-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Constructing explainable health indicators for aircraft engines by developing an interpretable neural network with discretized weights},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Document-level relation extraction via commonsense knowledge enhanced graph representation learning. <em>APIN</em>, <em>55</em>(2), 1-13. (<a href='https://doi.org/10.1007/s10489-024-05985-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level relation extraction (DocRE) aims to reason about complex relational facts among entities by reading, inferring, and aggregating among entities over multiple sentences in a document. Existing studies construct document-level graphs to enrich interactions between entities. However, these methods pay more attention to the entity nodes and their connections, regardless of the rich knowledge entailed in the original corpus.In this paper, we propose a commonsense knowledge enhanced document-level graph representation, called CGDRE, which delves into the semantic knowledge of the original corpus and improves the ability of DocRE. Firstly, we use coreference contrastive learning to capture potential commonsense knowledge. Secondly, we construct a heterogeneous graph to enhance the graph structure information according to the original document and commonsense knowledge. Lastly, CGDRE infers relations on the aggregated graph and uses focal loss to train the model. Remarkably, it is amazing that CGDRE can effectively alleviate the long-tailed distribution problem in DocRE. Experiments on the public datasets DocRED, DialogRE, and MPDD show that CGDRE can significantly outperform other baselines, achieving a significant performance improvement. Extensive analyses demonstrate that the performance of our CGDRE is contributed by the capture of commonsense knowledge enhanced graph relation representation.},
  archive      = {J_APIN},
  author       = {Dai, Qizhu and Li, Rongzhen and Xue, Zhongxuan and Li, Xue and Zhong, Jiang},
  doi          = {10.1007/s10489-024-05985-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Document-level relation extraction via commonsense knowledge enhanced graph representation learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel hybrid neural network approach incorporating convolution and LSTM with a self-attention mechanism for web attack detection. <em>APIN</em>, <em>55</em>(2), 1-17. (<a href='https://doi.org/10.1007/s10489-024-05998-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As web attacks have recently increased in number and sophistication, traditional machine learning methods have struggled to defend against well-designed attacks. Therefore, deep learning methods have been widely used in web attack detection, leveraging their ability to discern intricate features within the original payload for precise identification of web application threats. In this study, we propose a novel hybrid neural network model for web attack detection, named hybrid convolutional long short-term memory (HCLSTM). Specifically, the HCLSTM model utilizes two branches to extract features from Hypertext Transfer Protocol (HTTP) request packet: a Deep Feedforward Neural Network (DFNN) branch for extracting word features from Uniform Resource Locator (URL), and a Convolutional Neural Network (CNN) branch for capturing combinatorial and local relationships within payloads. Then, the extracted features from both branches are concatenated and subsequently fed into a Bidirectional Long Short-Term Memory (Bi-LSTM) network integrated with a self-attention mechanism, designed to capture intricate link relationships between URL and payloads. The final classification layer produces the detection results. To evaluate the proposed model, we conducted experiments on CSIC 2010 HTTP dataset. The experimental results reveal that HCLSTM can accurately detect web attacks with a high accuracy of 99.46% and a low false positive rate of 0.02%.},
  archive      = {J_APIN},
  author       = {Luo, Kangqiang and Chen, Yindong},
  doi          = {10.1007/s10489-024-05998-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {A novel hybrid neural network approach incorporating convolution and LSTM with a self-attention mechanism for web attack detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel spatial complex fuzzy inference system for detection of changes in remote sensing images. <em>APIN</em>, <em>55</em>(2), 1-26. (<a href='https://doi.org/10.1007/s10489-024-06000-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance the efficacy of change detection in remote sensing images, we propose a novel Spatial Complex Fuzzy Inference System (Spatial CFIS). This system incorporates fuzzy clustering to generate complex fuzzy rules and employs a triangular spatial complex fuzzy rule base to predict changes in subsequent images compared to their original versions. The weight set of the rule base is optimized using the ADAM algorithm to boost the overall performance of Spatial CFIS. Our proposed model is evaluated using datasets from the weather image data warehouse of the USA Navy and the PRISMA mission funded by the Italian Space Agency (ASI). We compare the performance of Spatial CFIS against other relevant algorithms, including PFC-PFR, SeriesNet, and Deep Slow Feature Analysis (DSFA). The evaluation metrics include RMSE (Root Mean Squared Error), R2 (R Squared), and Analysis of Variance (ANOVA). The experimental results demonstrate that Spatial CFIS outperforms other models by up to 40% in terms of accuracy. In summary, this paper presents an innovative approach to handling remote sensing images by applying a spatial-oriented fuzzy inference system, offering improved accuracy in change detection.},
  archive      = {J_APIN},
  author       = {Thang, Nguyen Truong and Giang, Le Truong and Son, Le Hoang and Giang, Nguyen Long and Taniar, David and Thien, Nguyen Van and Tuan, Tran Manh},
  doi          = {10.1007/s10489-024-06000-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {A novel spatial complex fuzzy inference system for detection of changes in remote sensing images},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SegWCD: A new segmentation-based weak supervision neural network for building change detection. <em>APIN</em>, <em>55</em>(2), 1-14. (<a href='https://doi.org/10.1007/s10489-024-06003-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual annotation of changes in high-resolution remote sensing images is labor-intensive and limits advancements in change detection. We introduce the Segmentation-based Weakly Supervised Change Detection (segWCD) framework to mitigate this challenge. Our method leverages a semantic segmentation model to generate pseudo-labels, offering weak supervision for detecting changes. The Creator module further refines these labels, enhancing the model’s detection accuracy. Additionally, we address the issue of label noise by variably weighting the pseudo-labels based on their confidence, thus optimizing the training process. Experimental results show that segWCD achieves a Recall of 0.921, an F1 score of 0.627, and an MIOU of 0.708, performing comparably to fully supervised methods. This approach marks a significant step forward in weakly supervised learning, demonstrating the potential of refined pseudo-labeling techniques.},
  archive      = {J_APIN},
  author       = {Wu, Yunyang and Zhang, Xiaobo and Zhao, Xiaole and Sun, Yimin and Li, Tianrui},
  doi          = {10.1007/s10489-024-06003-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {SegWCD: A new segmentation-based weak supervision neural network for building change detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WRGAT-PTBERT: Weighted relational graph attention network over post-trained BERT for aspect based sentiment analysis. <em>APIN</em>, <em>55</em>(2), 1-11. (<a href='https://doi.org/10.1007/s10489-024-06011-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) focused on forecasting the sentiment orientation of a given aspect target within the input. Existing methods employ neural networks and attention mechanisms to encode input and discern aspect-context relationships. Bidirectional Encoder Representation from Transformer(BERT) has become the standard contextual encoding method in the textual domain. Researchers have ventured into utilizing graph attention networks(GAT) to incorporate syntactic information into the task, yielding cutting-edge results. However, current approaches overlook the potential advantages of considering word dependency relations. This work proposes a hybrid model combining contextual information obtained from a post-trained BERT with syntactic information from a relational GAT (RGAT) for the ABSA task. Our approach leverages dependency relation information effectively to improve ABSA performance in terms of accuracy and F1-score, as demonstrated through experiments on SemEval-14 Restaurant and Laptop, MAMS, and ACL-14 Twitter datasets.},
  archive      = {J_APIN},
  author       = {Verma, Sharad and Kumar, Ashish and Sharan, Aditi},
  doi          = {10.1007/s10489-024-06011-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-11},
  shortjournal = {Appl. Intell.},
  title        = {WRGAT-PTBERT: Weighted relational graph attention network over post-trained BERT for aspect based sentiment analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BiNext-cervix: A novel hybrid model combining BiFormer and ConvNext for pap smear classification. <em>APIN</em>, <em>55</em>(2), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06025-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cervical cancer is the fourth most prevalent cancer among women worldwide and a major contributor to cancer-related mortality in females. Manually classifying cytopathology screening slides remains one of the most important and commonly used methods for diagnosing cervical cancer. However, this method requires the participation of medical experts and is highly labor intensive. Consequently, in regions with limited medical resources, prompt cervical cancer diagnosis is challenging. To address this issue, the BiNext-Cervix model, a new deep learning framework, has been proposed to rapidly and accurately diagnose cervical cancer via Pap smear images. BiNext-Cervix employs Tokenlearner in the initial stage to facilitate interaction between two pixels within the image, enabling the subsequent network to better understand the image features. Additionally, the BiNext-Cervix integrates the recently introduced ConvNext and BiFormer models, allowing for deep exploration of image information from both local and global perspectives. A fully connected layer is used to fuse the extracted features and perform the classification. The experimental results demonstrate that combining ConvNext and BiFormer achieves higher accuracy than using either model individually. Furthermore, the proposed BiNext-Cervix outperforms other commonly used deep learning models, showing superior performance.},
  archive      = {J_APIN},
  author       = {Dong, Minhui and Wang, Yu and Zang, Zeyu and Todo, Yuki},
  doi          = {10.1007/s10489-024-06025-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {BiNext-cervix: A novel hybrid model combining BiFormer and ConvNext for pap smear classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic interactive weighted feature selection using fuzzy interaction information. <em>APIN</em>, <em>55</em>(2), 1-26. (<a href='https://doi.org/10.1007/s10489-024-06026-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional information theory-based feature selection methods are designed for discrete features, which require additional discretization steps when working with continuous features. In contrast, fuzzy information theory-based feature selection methods can handle continuous features directly. However, most existing fuzzy information theory-based feature selection methods do not consider the dynamic interaction between candidate features and the already selected ones. To address this issue, we propose a dynamic weighted feature selection method based on fuzzy interaction information that can handle continuous features. First, we use fuzzy information theory metrics to characterize the concepts of feature relevance, redundancy, and interaction. Second, we define a fuzzy interaction weight factor that can quantify the redundancy and interaction between features by using fuzzy interaction information. Third, we design a novel feature selection algorithm called fuzzy dynamic interactive weighted feature selection (FDIWFS) by combining the fuzzy interaction weight factor with a sequential forward search strategy. To evaluate the effectiveness of FDIWFS, we compare it with eight state-of-the-art feature selection methods on fifteen publicly available datasets. The results of comparative experiments demonstrate that FDIWFS outperforms the other methods in terms of classification performance.},
  archive      = {J_APIN},
  author       = {Ma, Xi-Ao and Xu, Hao and Liu, Yi},
  doi          = {10.1007/s10489-024-06026-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Dynamic interactive weighted feature selection using fuzzy interaction information},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatio-temporal attention-based hybrid deep network for time series prediction of industrial process. <em>APIN</em>, <em>55</em>(2), 1-16. (<a href='https://doi.org/10.1007/s10489-024-06033-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial time series involves a large amount of production process information, which effectively reflects the production status of the industrial process. To better understand characteristics and patterns of changes in production conditions, it is crucial to analyze and predict industrial time series data. Given the involvement of numerous parameters and complex physical-chemical reactions in industrial processes, attaining precise predictive performance utilizing a single model remains a formidable challenge. In this paper, we propose a novel hybrid deep learning prediction method based on spatio-temporal attention and temporal convolution network. The proposed method aims to handle the multivariate coupling characteristics and dynamic nonlinear features in industrial time series through different model structures for accurate prediction. In this method, historical data are first segmented into multiple consecutive inputs along the temporal dimension, which are then used as inputs to the subsequent attention mechanism module. To realize the mapping from points to series in the temporal dimension, the segmented input is processed using both the adaptive attention mechanism and one-dimensional convolution. Then the spatio-temporal coupling features are further explored through the spatio-temporal attention model. In addition, to extract dynamic nonlinear features from historical data, a parallel temporal convolutional network with temporal pattern attention is utilized. In order to evaluate the prediction performance of the proposed model, we use two different real-world industrial time series datasets for comprehensive evaluation. The experimental results demonstrate the effectiveness and accuracy of the proposed method. Code is available at https://github.com/TensorPulse/MACnet .},
  archive      = {J_APIN},
  author       = {Lu, Dong and Zhou, Xiaofeng and Li, Shuai},
  doi          = {10.1007/s10489-024-06033-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Spatio-temporal attention-based hybrid deep network for time series prediction of industrial process},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prompt-guided and degradation prior supervised transformer for adverse weather image restoration. <em>APIN</em>, <em>55</em>(2), 1-14. (<a href='https://doi.org/10.1007/s10489-024-06050-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The restoration of images affected by adverse weather conditions is hindered by two main challenges. The first is the restoration of fine details in severely degraded regions. The second is the interference between different types of degradation data during the model training process, which consequently reduces the restoration performance of the model on individual tasks. In this work, we propose a Transformer-based All-in-one image restoration model, called PDFormer, to alleviate the aforementioned issues. Initially, we designed an effective transformer network to capture the global contextual information in the image and utilize this information to restore the locally severely degraded regions better. Additionally, to alleviate the interference between different types of degraded data, we introduced two specialized modules: the Prompt-Guided Feature Refinement Module (RGRM) and the Degradation Mask Supervised Attention Module (MSAM). The former employs a set of learnable prompt parameters to generate prompt information, which interacts with the degraded feature through cross-attention, enhancing the discriminative ability of different degraded features in the latent space. The latter, under the supervision of the degraded mask prior, assists the model in differentiating between different degradation types and locating the regions and sizes of the degradations. The designs above permit greater flexibility in handling specific degradation scenarios, enabling the adaptive removal of different degradation artifacts to restore fine details in images. Performance evaluation on both synthetic and real data has demonstrated that our method surpasses existing approaches, achieving state-of-the-art (SOTA) performance.},
  archive      = {J_APIN},
  author       = {Liu, Weihan and Shao, Mingwen and Meng, Lingzhuang and Qiao, Yuanjian and Bao, Zhiyuan},
  doi          = {10.1007/s10489-024-06050-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Prompt-guided and degradation prior supervised transformer for adverse weather image restoration},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proformer: A scalable graph transformer with linear complexity. <em>APIN</em>, <em>55</em>(2), 1-15. (<a href='https://doi.org/10.1007/s10489-024-06065-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since existing GNN methods use a fixed input graph structure for messages passing, they cannot solve the problems of heterogeneity, over-squashing, long-range dependencies, and graph incompleteness. The all-pair message passing scheme is an effective means to address the above issues. However, owing to the quadratic complexity problem of self-attention used in the all-pair message passing scheme, it is not possible to simultaneously guarantee the scalability and accuracy of the algorithm on large-scale graph datasets. In this paper, we propose Proformer, which uses multilayer dilation convolution to project the key and value in self-attention and uses a focused function to further enhance the model representation and reduce the computational complexity of the all-pair message passing scheme from quadratic to linear. The experimental results show that Proformer performs very well in tasks such as nodes, images, and text. Additionally, when scaled to large-scale graph datasets, it is able to effectively reduce the inference time and GPU memory utilization while guaranteeing the algorithm's accuracy. On OGB-Proteins, it not only improves the ROC-AUC by 3.2% but also conserves 27.8% of the GPU memory.},
  archive      = {J_APIN},
  author       = {Liu, Zhu and Wang, Peng and Ni, Cui and Zhang, Qingling},
  doi          = {10.1007/s10489-024-06065-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Proformer: A scalable graph transformer with linear complexity},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement-learning-based decentralized event-triggered control of partially unknown nonlinear interconnected systems with state constraints. <em>APIN</em>, <em>55</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06072-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many applications with great potential, safety is critical as it needs to meet strict safety specifications within physical constraints. This paper studies the decentralized event-triggered control problem of a class of partially unknown nonlinear interconnected systems with state constraints under the reinforcement learning approach. First, by introducing a control barrier function into the performance function of each auxiliary subsystem with state constraints, the system state can be operated within a user-defined safe set. And then, the original control problem can be translated equivalently into finding or searching optimal event-triggered control policies that combine to form the desired decentralized controller, resulting in significant savings in communication resources. Compared with the traditional actor-critic network structure approach, the proposed identifier-critic network structure can loosen the constraints on the system dynamics and eliminate the errors arising from approximating the actor network. Updating the weight vectors in the critic network by gradient descent and concurrent learning techniques removes the need for the traditional persistence of excitation conditions. Furthermore, it is rigorously proved that all the signals of the interconnected nonlinear system are bound according to the Lyapunov stability theory. Last, the effectiveness of the proposed control scheme is verified by simulation examples.},
  archive      = {J_APIN},
  author       = {Qin, Chunbin and Wu, Yinliang and Zhu, Tianzeng and Jiang, Kaijun and Zhang, Dehua},
  doi          = {10.1007/s10489-024-06072-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Reinforcement-learning-based decentralized event-triggered control of partially unknown nonlinear interconnected systems with state constraints},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-constraint distributed terminal distribution path planning for fresh agricultural products. <em>APIN</em>, <em>55</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06076-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common combinatorial optimization issue in actual engineering is the vehicle routing problem (VRP). Examples of these problems include logistics distribution, solid waste recycling planning, and underwater routing planning. The optimization algorithms are important for the solution quality of the proposed VRP. As the scale of the vehicle routing problem increases, the problem becomes more difficult. It is hard for the traditional algorithm to obtain the optimal solution to the problem in an acceptable computing time. In this paper, an adaptive large neighborhood water wave optimization (ALNSWWO) algorithm is designed to solve multi-depot capacitated vehicle routing problems with time windows (MDCVRPTW). Aimed at addressing the main problems of the original algorithm, an improvement strategy is designed. In the breaking operation, variable neighborhood search (VNS) and large neighborhood search (LNS) local search strategies are added. In the refinement operation, the learning operator based on the genetic algorithm and the adaptive large neighborhood search (ALNS) search mechanism is added. The above mechanism solves the problems that the original algorithm is prone to falling into local optima. The experimental results demonstrate that the distribution path scheme of fresh agricultural products (FAP) can be optimized through the ALNSWWO. The proposed ALNSWWO can reduce the distribution distance, time, cost, carbon emissions, and improve customer satisfaction.},
  archive      = {J_APIN},
  author       = {Liu, Huan and Zhang, Jizhe and Dai, Yongqiang and Qin, Lijing and Zhi, Yongkun},
  doi          = {10.1007/s10489-024-06076-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Multi-constraint distributed terminal distribution path planning for fresh agricultural products},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NQF-RNN: Probabilistic forecasting via neural quantile function-based recurrent neural networks. <em>APIN</em>, <em>55</em>(2), 1-31. (<a href='https://doi.org/10.1007/s10489-024-06077-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic forecasting offers insights beyond point estimates, supporting more informed decision-making. This paper introduces the Neural Quantile Function with Recurrent Neural Networks (NQF-RNN), a model for multistep-ahead probabilistic time series forecasting. NQF-RNN combines neural quantile functions with recurrent neural networks, enabling applicability across diverse time series datasets. The model uses a monotonically increasing neural quantile function and is trained with a continuous ranked probability score (CRPS)-based loss function. NQF-RNN’s performance is evaluated on synthetic datasets generated from multiple distributions and six real-world time series datasets with both periodicity and irregularities. NQF-RNN demonstrates competitive performance on synthetic data and outperforms benchmarks on real-world data, achieving lower average forecast errors across most metrics. Notably, NQF-RNN surpasses benchmarks in CRPS, a key probabilistic metric, and tail-weighted CRPS, which assesses tail event forecasting with a narrow prediction interval. The model outperforms other deep learning models by 5% to 41% in CRPS, with improvements of 5% to 53% in left tail-weighted CRPS and 6% to 34% in right tail-weighted CRPS. Against its baseline model, DeepAR, NQF-RNN achieves a 41% improvement in CRPS, indicating its effectiveness in generating reliable prediction intervals. These results highlight NQF-RNN’s robustness in managing complex and irregular patterns in real-world forecasting scenarios.},
  archive      = {J_APIN},
  author       = {Song, Jungyoon and Chang, Woojin and Song, Jae Wook},
  doi          = {10.1007/s10489-024-06077-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-31},
  shortjournal = {Appl. Intell.},
  title        = {NQF-RNN: Probabilistic forecasting via neural quantile function-based recurrent neural networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double fuzzy relaxation local information C-means clustering. <em>APIN</em>, <em>55</em>(2), 1-25. (<a href='https://doi.org/10.1007/s10489-024-06078-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy c-means clustering (FCM) has gained widespread application because of its ability to capture uncertain information in data effectively. However, attributed to the prior assumption of identical distribution, traditional FCM is sensitive to noise and cluster size. Modified methods incorporating local spatial information can enhance the robustness to noise. However, they tend to balance cluster sizes, resulting in poor performance when dealing with imbalanced data. Modified methods learning the statistical characteristics of data are feasible to handle imbalanced data. However, they are often sensitive to noise due to the ignorance of local information. Aiming at the lack of method that can simultaneously alleviate the sensitivity to noise and cluster size, a double fuzzy relaxation local information c-means clustering algorithm (DFRLICM) is proposed in this paper. Firstly, sample relaxation is introduced to explore potential clustering results and enhance inter-class separability. Secondly, to cooperate with the relaxation, we design fuzzy weights to record the imbalance situation of data clusters, enhancing the capability of algorithm in dealing with imbalanced data. Thirdly, we introduce fuzzy factor to account for the preservation of local structures in data and improve the robustness of algorithm. Finally, we integrate the three elements into a unified model framework to achieve the combination optimization of robustness to noise and insensitivity to cluster size simultaneously. Extensive experiments are conducted and the results demonstrate that the proposed algorithm indeed achieves a balance between robustness to noise and insensitivity to cluster size.},
  archive      = {J_APIN},
  author       = {Gao, Yunlong and Zheng, Xingshen and Wu, Qinting and Zhang, Jiahao and Cao, Chao and Pan, Jinyan},
  doi          = {10.1007/s10489-024-06078-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {Double fuzzy relaxation local information C-means clustering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PUA-net: End-to-end information hiding network based on structural re-parameterization. <em>APIN</em>, <em>55</em>(2), 1-15. (<a href='https://doi.org/10.1007/s10489-024-06081-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image hiding aims to secretly embed secret information into a cover image and then recover the hidden data with minimal or no loss at the receiving end. Many works on steganography and deep learning have proved the huge prospects of deep learning in the field of image information hiding. However, current deep learning-based steganography research exposes significant limits, among which key issues such as how to improve embedding capacity, imperceptibility, and robustness remain crucial for image-hiding tasks. This article introduces PUA-Net, a new end-to-end neural network model for image steganography. PUA-Net consists of three main components: 1) the CbDw attention module, 2) the attention gate module, and 3) the partial combination convolution module. Each of these components utilizes structural reparameterization operations. In addition, we propose a residual image minimization loss function and use a combination of loss functions based on this loss function. This model can seamlessly embed bit stream information of different capacities into images to generate stego images that are imperceptible to the human eye. Experimental results confirm the effectiveness of our model, achieving an RS-BPP of 5.98 when decoding the extracted secret information and recovering the cover image. When only the extracted secret information is output, the model achieves a maximum RS-BPP of 6.94. Finally, experimental results show that our PUA-Net model outperforms deep learning-based steganography approaches on COCO, ImageNet, and BOSSbase datasets, including GAN-based methods such as Stegastamp and SteganoGAN.},
  archive      = {J_APIN},
  author       = {Lin, Feng and Xue, Ru and Dong, Shi and Ding, Fuhao and Han, Yixin},
  doi          = {10.1007/s10489-024-06081-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {PUA-net: End-to-end information hiding network based on structural re-parameterization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DTGA: An in-situ training scheme for memristor neural networks with high performance. <em>APIN</em>, <em>55</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06091-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memristor Neural Networks (MNNs) stand out for their low power consumption and accelerated matrix operations, making them a promising hardware solution for neural network implementations. The efficacy of MNNs is significantly influenced by the careful selection of memristor update thresholds and the in-situ update scheme during hardware deployment. This paper addresses these critical aspects through the introduction of a novel scheme that integrates Dynamic Threshold (DT) and Gradient Accumulation (GA) with Threshold Properties. In this paper, realistic memristor characteristics, including pulse-to-pulse (P2P) and device-to-device (D2D) behaviors, were simulated by introducing random noise to the Vteam memristor model. A dynamic threshold scheme is proposed to enhance in-situ training accuracy, leveraging the inherent characteristics of memristors. Furthermore, the accumulation of gradients during back propagation is employed to finely regulate memristor updates, contributing to an improved in-situ training accuracy. Experimental results demonstrate a significant enhancement in test accuracy using the DTGA scheme on the MNIST dataset (82.98% to 96.15%) and the Fashion-MNIST dataset (75.58% to 82.53%). Robustness analysis reveals the DTGA scheme’s ability to tolerate a random noise factor of 0.03 for the MNIST dataset and 0.02 for the Fashion-MNIST dataset, showcasing its reliability under varied conditions. Notably, in the Fashion-MNIST dataset, the DTGA scheme yields a 7% performance improvement accompanied by a corresponding 7% reduction in training time. This study affirms the efficiency and accuracy of the DTGA scheme, which proves adaptable beyond multilayer perceptron neural networks (MLP), offering a compelling solution for the hardware implementation of diverse neuromorphic systems.},
  archive      = {J_APIN},
  author       = {Shen, Siyuan and Guo, Mingjian and Wang, Lidan and Duan, Shukai},
  doi          = {10.1007/s10489-024-06091-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {DTGA: An in-situ training scheme for memristor neural networks with high performance},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge interaction graph guided prompting for event causality identification. <em>APIN</em>, <em>55</em>(2), 1-14. (<a href='https://doi.org/10.1007/s10489-024-06095-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event causality identification (ECI) aims to identify causality between event pairs in a text, and is commonly approached as a supervised classification task using pre-trained language models (PLMs). However, limitations in implicit causality identification and insufficient event-knowledge interaction pose significant challenges to ECI. To address these issues, we propose a novel Knowledge Interaction Graph guided Prompt Tuning (KIGP), which leverages prompt tuning and knowledge interaction to fully exploit the potential of PLMs for ECI by integrating external knowledge. Specifically, to accurately capture implicit causality, we design the guidance mechanism and construct event-knowledge interaction graphs that enable external knowledge to enhance event representations through deep interaction between events and knowledge. Experimental results on two benchmark datasets demonstrate that our model outperforms existing approaches significantly.},
  archive      = {J_APIN},
  author       = {Hu, Ruijuan and Li, Jian and Liu, Haiyan and Qi, Guilin and Zhang, Yuxin},
  doi          = {10.1007/s10489-024-06095-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Knowledge interaction graph guided prompting for event causality identification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSDformer: An autocorrelation transformer with multiscale decomposition for long-term multivariate time series forecasting. <em>APIN</em>, <em>55</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06105-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The improvement of performance and efficiency in long-term time series forecasting is significant for practical applications. However, while enhancing overall performance, existing time series forecasting methods often exhibit unsatisfactory capabilities in the restoration of details and prediction efficiency. To address these issues, an autocorrelation Transformer with multiscale decomposition (MSDformer) is proposed for long-term multivariate time series forecasting. Specifically, a multiscale decomposition (MSDecomp) module is designed, which identifies the temporal repeating patterns in time series with different scales to retain more historical details while extracting trend components. An Encoder layer is proposed based on the MSDecomp module and Auto-Correlation mechanism, which discovers the similarity of subsequences in a periodic manner and effectively captures the seasonal components to improve the degree of restoration of prediction details while extracting the residual trend components. Finally, unlike the traditional Transformer structure, the decoder structure is replaced by the proposed Autoregressive module to simplify the output mode of the decoder and enhance linear information. Compared to other advanced and representative models on six real-world datasets, the experimental results demonstrate that the MSDformer has a relative performance improvement of an average of 8.1%. MSDformer also has lower memory usage and temporal consumption, making it more advantageous for long-term time series forecasting.},
  archive      = {J_APIN},
  author       = {Su, Guangyao and Guan, Yepeng},
  doi          = {10.1007/s10489-024-06105-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {MSDformer: An autocorrelation transformer with multiscale decomposition for long-term multivariate time series forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparative performance of machine learning-selected portfolios from dynamic CSI300 constituents: Forward vs. backward adjusted stock prices. <em>APIN</em>, <em>55</em>(2), 1-18. (<a href='https://doi.org/10.1007/s10489-024-06107-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing studies utilize backward-adjusted stock prices from data platforms to develop and backtest investment strategies using machine learning models. However, these prices are not point-in-time data and may introduce look-ahead bias, raising concerns about the reliability of model performance. To examine the impact of different price adjustment methods, we compare the predictive performance of various machine learning models and the backtesting results of portfolios constructed using these models with both forward-adjusted and backward-adjusted stock prices. Our study, conducted from 2012 to 2022, evaluates the real-world viability of investment strategies on the dynamic constituents of the CSI300 index. The empirical results reveal that while certain measures of machine learning models’ predictive performance may not be significantly affected by the stock price adjustment method, the backtesting performance under backward-adjusted stock prices is overestimated compared to that under forward-adjusted stock prices. This research provides evidence for the impact of historical stock price adjustments in developing machine learning models and presents a comprehensive framework for applying these techniques to the management of index constituent portfolios, thereby bridging the gap between predictive modeling and practical investment strategies.},
  archive      = {J_APIN},
  author       = {Zhou, Ligang and Chen, Xiaoguo and Tang, Xiaolei},
  doi          = {10.1007/s10489-024-06107-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Comparative performance of machine learning-selected portfolios from dynamic CSI300 constituents: Forward vs. backward adjusted stock prices},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving multi-class classification: Scaled extensions of harmonic mean-based adaptive k-nearest neighbors. <em>APIN</em>, <em>55</em>(2), 1-25. (<a href='https://doi.org/10.1007/s10489-024-06109-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel extension of the harmonic mean-based adaptive k-nearest neighbors (HMAKNN) algorithm, called scaled HMAKNN (SHMAKNN), which builds on HMAKNN’s strengths to achieve improved multi-class classification accuracy. HMAKNN uses a modified voting mechanism based on the harmonic mean and adaptive k-value selection to address issues like the sensitivity to k-value selection and the limitations of majority voting. SHMAKNN further improves the decision process by adjusting the components of the harmonic mean, focusing on voting values and the average distances of each class label. Additionally, SHMAKNN applies a re-scaling process to adjust the distances of the nearest neighbors within a specific range, enhancing the consistency of distances at different scales. These improvements help align the elements of the harmonic mean more effectively, leading to a balanced and less biased classification process. The study utilized 26 benchmark datasets, carefully curated to ensure accuracy and consistency, selected from diverse domains to evaluate the proposed method on real-world problems. These datasets were chosen to represent challenges like noise, imbalance, and sparsity, ensuring robustness in handling common data complexities. Additionally, small to medium-sized datasets were used to reduce computational burden and allow for efficient evaluation. The evaluation results show that the proposed SHMAKNN models outperform existing methods in both accuracy and F1-score for datasets with four or more classes. Specifically, SHMAKNN achieved the highest average accuracy and F1-score (86.36% and 86.16%) compared to HMAKNN (86.10% and 85.74%) and traditional k-nearest neighbors (84.87% and 84.69%). The performance improvements were validated using Friedman’s test at a significance level of 0.05, confirming their statistical significance of the results. Consequently, the findings indicate that the proposed algorithm exhibits remarkable performance, thereby confirming its reliability and validity in the context of real-world applications, particularly those involving multiple classes.},
  archive      = {J_APIN},
  author       = {Açıkkar, Mustafa and Tokgöz, Selçuk},
  doi          = {10.1007/s10489-024-06109-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {Improving multi-class classification: Scaled extensions of harmonic mean-based adaptive k-nearest neighbors},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UEFN: Efficient uncertainty estimation fusion network for reliable multimodal sentiment analysis. <em>APIN</em>, <em>55</em>(2), 1-20. (<a href='https://doi.org/10.1007/s10489-024-06113-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid evolution of the digital era has greatly transformed social media, resulting in more diverse emotional expressions and increasingly complex public discourse. Consequently, identifying relationships within multimodal data has become increasingly challenging. Most current multimodal sentiment analysis (MSA) methods concentrate on merging data from diverse modalities into an integrated feature representation to enhance recognition performance by leveraging the complementary nature of multimodal data. However, these approaches often overlook prediction reliability. To address this, we propose the uncertainty estimation fusion network (UEFN), a reliable MSA method based on uncertainty estimation. UEFN combines the Dirichlet distribution and Dempster-Shafer evidence theory (DSET) to predict the probability distribution and uncertainty of text, speech, and image modalities, fusing the predictions at the decision level. Specifically, the method first represents the contextual features of text, speech, and image modalities separately. It then employs a fully connected neural network to transform features from different modalities into evidence forms. Subsequently, it parameterizes the evidence of different modalities via the Dirichlet distribution and estimates the probability distribution and uncertainty for each modality. Finally, we use DSET to fuse the predictions, obtaining the sentiment analysis results and uncertainty estimation, referred to as the multimodal decision fusion layer (MDFL). Additionally, on the basis of the modality uncertainty generated by subjective logic theory, we calculate feature weights, apply them to the corresponding features, concatenate the weighted features, and feed them into a feedforward neural network for sentiment classification, forming the adaptive weight fusion layer (AWFL). Both MDFL and AWFL are then used for multitask training. Experimental comparisons demonstrate that the UEFN not only achieves excellent performance but also provides uncertainty estimation along with the predictions, enhancing the reliability and interpretability of the results.},
  archive      = {J_APIN},
  author       = {Wang, Shuai and Ratnavelu, K. and Bin Shibghatullah, Abdul Samad},
  doi          = {10.1007/s10489-024-06113-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {UEFN: Efficient uncertainty estimation fusion network for reliable multimodal sentiment analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two novel deep multi-view support vector machines for multiclass classification. <em>APIN</em>, <em>55</em>(2), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06126-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view classification methods have better generalization performance compared to the single-view classification methods due to the consistency information from multiple views. In recent years, the combination of support vector machine (SVM) and multi-view learning has been widely studied. To improve the robustness of multi-view classification methods, emphasis has shifted to the integration of multi-view classification approaches with fully-connected and convolutional neural networks. A classical deep two-view classification method named deep SVM-2K is a combination of support vector machine with two stage kernel canonical correlation analysis (SVM-2K) and deep learning. However, limitations of deep SVM-2K are that it can not cope with multi-view classification and multiclass classification problems. To address these issues, we propose two novel deep multi-view models named deep multi-view support vector machine (DMVSVM) for multiclass classification. DMVSVM uses the learned features by auto-encoder (AE) or deep neural network (DNN) to train the SVM classifier for each view. The two models then impose some constraints to make the output of the multi-view SVM classifiers as consistent as possible, which used to exploring intrinsic relations. Experiments performed on different real-word datasets show the effectiveness of our proposed approaches.},
  archive      = {J_APIN},
  author       = {Li, Yanfeng and Xie, Xijiong},
  doi          = {10.1007/s10489-024-06126-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Two novel deep multi-view support vector machines for multiclass classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: A new humanitarian relief logistic network for multi-objective optimization under stochastic programming. <em>APIN</em>, <em>55</em>(2), 1. (<a href='https://doi.org/10.1007/s10489-024-06174-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Ghasemi, Peiman and Goodarzian, Fariba and Abraham, Ajith},
  doi          = {10.1007/s10489-024-06174-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Retraction note: A new humanitarian relief logistic network for multi-objective optimization under stochastic programming},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: A cluster-based stratified hybrid decision support model under uncertainty: Sustainable healthcare landfill location selection. <em>APIN</em>, <em>55</em>(2), 1. (<a href='https://doi.org/10.1007/s10489-024-06175-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Tirkolaee, Erfan Babaee and Torkayesh, Ali Ebadi},
  doi          = {10.1007/s10489-024-06175-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Retraction note: A cluster-based stratified hybrid decision support model under uncertainty: Sustainable healthcare landfill location selection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: Online education satisfaction assessment based on cloud model and fuzzy TOPSIS. <em>APIN</em>, <em>55</em>(2), 1. (<a href='https://doi.org/10.1007/s10489-024-06176-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Xu, Xiuqin and Xie, Jialiang and Wang, Honghui and Lin, Mingwei},
  doi          = {10.1007/s10489-024-06176-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Retraction note: Online education satisfaction assessment based on cloud model and fuzzy TOPSIS},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: A DES-based group decision model for group decision making with large-scale alternatives. <em>APIN</em>, <em>55</em>(2), 1. (<a href='https://doi.org/10.1007/s10489-024-06177-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Xu, Che and Liu, Weiyong and Chen, Yushu},
  doi          = {10.1007/s10489-024-06177-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Retraction note: A DES-based group decision model for group decision making with large-scale alternatives},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: Three-way selection random forest algorithm based on decision boundary entropy. <em>APIN</em>, <em>55</em>(2), 1. (<a href='https://doi.org/10.1007/s10489-024-06178-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Zhang, Chunying and Ren, Jing and Liu, Fengchun and Li, Xiaoqi and Liu, Shouyue},
  doi          = {10.1007/s10489-024-06178-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Retraction note: Three-way selection random forest algorithm based on decision boundary entropy},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: Interval-valued dual hesitant fuzzy linguistic group recommendation method by considering the double relevance. <em>APIN</em>, <em>55</em>(2), 1. (<a href='https://doi.org/10.1007/s10489-024-06179-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Jiang, Wenchao and Yuan, Xumei and Zang, Yuqi},
  doi          = {10.1007/s10489-024-06179-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Retraction note: Interval-valued dual hesitant fuzzy linguistic group recommendation method by considering the double relevance},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: Cloud vendor selection for the healthcare industry using a big data-driven decision model with probabilistic linguistic information. <em>APIN</em>, <em>55</em>(2), 1. (<a href='https://doi.org/10.1007/s10489-024-06180-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Krishankumar, R. and Sivagami, R. and Saha, Abhijit and Rani, Pratibha and Arun, Karthik and Ravichandran, K. S.},
  doi          = {10.1007/s10489-024-06180-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Retraction note: Cloud vendor selection for the healthcare industry using a big data-driven decision model with probabilistic linguistic information},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: Query-oriented topical influential users detection for top-k trending topics in twitter. <em>APIN</em>, <em>55</em>(2), 1. (<a href='https://doi.org/10.1007/s10489-024-06181-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Gomasta, Sarmistha Sarna and Dhali, Aditi and Anwar, Md Musfique and Sarker, Iqbal H.},
  doi          = {10.1007/s10489-024-06181-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Retraction note: Query-oriented topical influential users detection for top-k trending topics in twitter},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: Feature selection techniques in the context of big data: Taxonomy and analysis. <em>APIN</em>, <em>55</em>(2), 1. (<a href='https://doi.org/10.1007/s10489-024-06182-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Mohammed Abdulwahab, Hudhaifa and Ajitha, S. and Ahmed Naji Saif, Mufeed},
  doi          = {10.1007/s10489-024-06182-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Retraction note: Feature selection techniques in the context of big data: Taxonomy and analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: A survey of group decision making methods in healthcare industry 4.0: Bibliometrics, applications, and directions. <em>APIN</em>, <em>55</em>(2), 1. (<a href='https://doi.org/10.1007/s10489-024-06183-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Lu, Keyu and Liao, Huchang},
  doi          = {10.1007/s10489-024-06183-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Retraction note: A survey of group decision making methods in healthcare industry 4.0: Bibliometrics, applications, and directions},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: An optimal deep learning-based LSTM for stock price prediction using twitter sentiment analysis. <em>APIN</em>, <em>55</em>(2), 1. (<a href='https://doi.org/10.1007/s10489-024-06184-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Swathi, T. and Kasiviswanath, N. and Rao, A. Ananda},
  doi          = {10.1007/s10489-024-06184-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Retraction note: An optimal deep learning-based LSTM for stock price prediction using twitter sentiment analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: Incremental deep forest for multi-label data streams learning. <em>APIN</em>, <em>55</em>(2), 1. (<a href='https://doi.org/10.1007/s10489-024-06185-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Liang, Shunpan and Pan, Weiwei and You, Dianlong and Liu, Ze and Yin, Ling},
  doi          = {10.1007/s10489-024-06185-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Retraction note: Incremental deep forest for multi-label data streams learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: Location algorithm of transfer stations based on density peak and outlier detection. <em>APIN</em>, <em>55</em>(2), 1. (<a href='https://doi.org/10.1007/s10489-024-06186-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Shao-Hong, Yan and Jia-Yang, Niu and Tai-Long, Chen and Qiu-Tong, Liu and Cen, Yang and Jia-Qing, Cheng and Zhi-Zhen, Fu and Jie, Li},
  doi          = {10.1007/s10489-024-06186-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Retraction note: Location algorithm of transfer stations based on density peak and outlier detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAPTSTA-AnoECG: A PatchTST-based ECG anomaly detection method with subtractive attention and data augmentation. <em>APIN</em>, <em>55</em>(2), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05881-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An electrocardiogram (ECG) is a crucial noninvasive medical diagnostic method that enables real-time monitoring of the electrical activity of the heart. ECGs hold a significant position in the rapid diagnosis and routine monitoring of cardiac diseases due to their user-friendly operation, prompt detection, broad range of diagnosable problems, and cost-effectiveness. However, thorough comprehension of ECG readings requires a high level of medical expertise due to the complex variations in ECG patterns, substantial interindividual differences, and numerous interfering factors. Consequently, current ECG machines and ECG Holters typically provide simplistic indications of ECG anomalies. Nonetheless, current ECG anomaly detection (EAD) algorithms lack precision; therefore, these medical devices cannot accurately report the specific types of diseases reflected in ECG results. In response to these challenges, this paper proposes enhancing the accuracy of electrocardiogram detection by improving algorithms. Therefore, we propose SAPTSTA-AnoECG, a PatchTST-based ECG anomaly detection method with subtractive attention and data augmentation. This method introduces a subtractive attention mechanism to make the Transformer architecture more suitable for time series data. We also use data augmentation to increase the robustness of the model. In addition, a patch-based approach is employed to reduce the algorithm’s computational complexity of the model. Furthermore, we introduce a new publicly available ECG dataset named HCE in this paper and conduct comparative experiments using this dataset along with the PTB-XL and CPSC 2018 datasets. The experimental results demonstrate the effectiveness of this method.},
  archive      = {J_APIN},
  author       = {Li, Yifan and Wang, Mengjue and Guan, Mingxiang and Lu, Chen and Li, Zhiyong and Chen, Tieming},
  doi          = {10.1007/s10489-024-05881-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {SAPTSTA-AnoECG: A PatchTST-based ECG anomaly detection method with subtractive attention and data augmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Technical analysis-based unsupervised intraday trading djia index stocks: Is it profitable in long term?. <em>APIN</em>, <em>55</em>(2), 1-12. (<a href='https://doi.org/10.1007/s10489-024-05903-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paradigm shift from conventional stock market trading rings to computer-driven algorithmic trading has given rise to a new era characterized by specialized trading systems and indicators meticulously engineered to decode price charts and enhance the prospects of profitable trading. Nevertheless, despite these notable advancements, the majority of traders continue to grapple with losses rather than realizing gains, echoing the historical pursuit of the elusive philosopher’s stone by alchemists of yore. In response to this challenge, our research delves into the realm of artificial neural networks (ANNs) to cultivate more sophisticated trading methodologies. Our empirical investigations suggest that trading strategies relying on price chart analysis generally achieve a moderate level of accuracy. However, it is imperative to acknowledge that the intricate patterns that materialize over time, coupled with return metrics, persistently elude precise prediction within the framework of unsupervised automated trading. These findings underscore the critical importance of embracing a progressive approach to trading that synergizes human expertise with cutting-edge technological capabilities.},
  archive      = {J_APIN},
  author       = {Rahim, Mussadiq Abdul and Mushafiq, Muhammad and Khan, Sultan Daud and Ullah, Rafi and Khan, Salabat and Ishaque, Muhammad},
  doi          = {10.1007/s10489-024-05903-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {Technical analysis-based unsupervised intraday trading djia index stocks: Is it profitable in long term?},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LMTformer: Facial depression recognition with lightweight multi-scale transformer from videos. <em>APIN</em>, <em>55</em>(2), 1-23. (<a href='https://doi.org/10.1007/s10489-024-05908-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression will become the most common mental disorder worldwide by 2030. A number of models based on deep learning are proposed to help the clinicians to assess the severity of depression. However, two issues remain unresolved: (1) few studies have not considered to encode multi-scale facial behaviors. (2) the current studies have the high computational complexity to hinder the proposed architecture in clinical application. To mitigate the above issues, an end-to-end, lightweight, multi-scale transformer based architecture, termed LMTformer, for sequential video-based depression analysis (SVDA), is proposed. In LMTformer, which consists of the three models: coarse-grained feature extraction (CFE) block, light multi-scale transformer (LMST), final Beck Depression Inventory–II (BDI–II) predictor (FBP). In CFE, coarse-grained features are extracted for LMST. In LMST, a multi-scale transformer is proposed to model the potential local and global features at the different receptive field. In addition, multi-scale global feature aggregation (MSGFA) is also proposed to model the global features. For FBP, two fully connected layers are used. Our novel architecture LMTformer is evaluated on the AVEC2013/AVEC2014 depression databases, and the former dataset with a root mean square error (RMSE) of 7.75 and a mean absolute error (MAE) of 6.12 for AVEC2013, and a RMSE of 7.97 and a MAE of 6.05 for AVEC2014. On the LMVD dataset, we obtain the best performances with F1-score of 82.74%. Additionally, the model represents the excellent computational complexity while only need 0.95M parameters and 1.1G floating-point operations per second (FLOPs). Code will be available at: https://github.com/helang818/LMTformer/.},
  archive      = {J_APIN},
  author       = {He, Lang and Zhao, Junnan and Zhang, Jie and Jiang, Jiewei and Qi, Senqing and Wang, Zhongmin and Wu, Di},
  doi          = {10.1007/s10489-024-05908-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {LMTformer: Facial depression recognition with lightweight multi-scale transformer from videos},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Iterative local search for preserving data privacy. <em>APIN</em>, <em>55</em>(2), 1-14. (<a href='https://doi.org/10.1007/s10489-024-05909-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {k-Anonymization is a popular approach for sharing datasets while preserving the privacy of personal and sensitive information. It ensures that each individual is indistinguishable from at least k-1 others in the anonymized dataset through data suppression or generalization, which inevitably leads to some information loss. The goal is to achieve k-anonymization with minimal information loss. This paper presents an efficient local search framework designed to address this challenge using arbitrary information loss metrics. The framework leverages anytime capabilities, allowing it to balance computation time and solution quality, thereby progressively improving the quality of the anonymized data. Our empirical evaluation shows that the proposed local search framework significantly reduces information loss compared to current state-of-the-art solutions, providing performance improvements of up to 54% and 43% w.r.t. the k-members and l-greedy heuristic solutions, the leading algorithms for large datasets. Additionally, our solution approach outperforms the Hun-garian-based solution, the best solution approach for small-size instances, by up to 4.7% on these instances.},
  archive      = {J_APIN},
  author       = {Arbelaez, Alejandro and Climent, Laura},
  doi          = {10.1007/s10489-024-05909-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Iterative local search for preserving data privacy},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimized path planning approach for automatic parking using hybrid a* bidirectional search. <em>APIN</em>, <em>55</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10489-024-05915-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning in automatic parking is a significant challenge due to constrained parking spaces and numerous obstacles. To enhance both the safety and efficiency of the planned path, this paper proposes a bidirectional hybrid A* algorithm for narrow spaces with a high density of obstacles. A vehicle obstacle avoidance method that incorporates rectangular expansion through numerical analysis is proposed to achieve collision-free navigation. Meanwhile, a safety cost is integrated into the hybrid A* search algorithm to maintain a sufficient safety distance between the planned path and obstacles. Additionally, to enhance the efficiency of path planning, a bidirectional search method is combined with the hybrid A* algorithm, with the addition of a bidirectional cohesive item cost. Finally, simulation experiments are conducted to generate parking paths for both vertical and parallel parking scenarios. The simulation results indicate that the proposed algorithm obtains a sufficient safety distance, reduced search time, and fewer expanded nodes. Meanwhile, the stability and adaptability of the proposed method are analyzed. The comparison with other algorithms suggests that the proposed algorithm provides a larger safety distance and shorter search time.},
  archive      = {J_APIN},
  author       = {Jin, Wenrui and Li, Jiaxue and Lv, Xiaoxiao and Zhang, Tao},
  doi          = {10.1007/s10489-024-05915-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {An optimized path planning approach for automatic parking using hybrid a* bidirectional search},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient strategies for spatial data clustering using topological relations. <em>APIN</em>, <em>55</em>(2), 1-26. (<a href='https://doi.org/10.1007/s10489-024-05927-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using topology in data analysis is a promising new field, and recently, it has attracted numerous researchers and played a vital role in both research and application. This study explores the burgeoning field of topology-based data analysis, mainly focusing on its application in clustering algorithms within data mining. Our research addresses the critical challenges of reducing execution time and enhancing clustering quality, which includes decreasing the dependency on input parameters - a notable limitation in current methods. We propose five innovative strategies to optimize clustering algorithms that utilize topological relationships by combining solutions of expanding points fewer times, merging clusters, and using a jump to increase the radius value according to the nearest neighbor distance array index. These strategies aim to refine clustering performance by improving algorithmic efficiency and the quality of clustering outcomes. This approach elevates the standard of cluster analysis and contributes significantly to the evolving landscape of data mining and analysis.},
  archive      = {J_APIN},
  author       = {Nguyen, Trang T. D. and Nguyen, Loan T. T. and Bui, Quang-Thinh and Duy, Le Nhat and Pedrycz, Witold and Vo, Bay},
  doi          = {10.1007/s10489-024-05927-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Efficient strategies for spatial data clustering using topological relations},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CSRP: Modeling class spatial relation with prototype network for novel class discovery. <em>APIN</em>, <em>55</em>(2), 1-18. (<a href='https://doi.org/10.1007/s10489-024-05946-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Novel Class Discovery(NCD) is a learning paradigm within the open-world task, in which machine learning models leverage prior knowledge to guide unknown samples into semantic clusters in an unsupervised environment. Recent research notes that maintaining class relations can assist classifiers in better recognizing unknown classes. Inspired by this study, we propose Class-Spatial-Relation modeling with a Prototype network (CSRP). A prototype network is a machine learning model used to classify tasks. It performs by learning prototypes for each class and makes classification decisions based on the similarity between a given sample and these prototypes. It conducts complex class boundaries better than linear classification models, providing higher flexibility and accuracy for classification tasks. Specifically, the proposed prototype network enables spatial modeling based on the distance between samples and each prototype, which can better obtain class relation information to improve the model’s interpretability and robustness. In addition, we simultaneously perform knowledge distillation on known and unknown classes to balance the model’s classification performance for each class. To evaluate the effectiveness and generality of our method, we perform extensive experiments on the CIFAR-100 dataset and fine-grained datasets: Stanford Cars, CUB-200-2011, and FGVC-Aircraft, respectively. Our method results are comparable to existing state-of-the-art performance in the standard dataset CIFAF100, while outstanding performance on three fine-grained datasets surpassed the baseline by 3%-9%. In addition, our method creates more compact clusters in the latent space than in linear classification. The success demonstrates the effectiveness of our approach.},
  archive      = {J_APIN},
  author       = {Jin, Wei and Li, Nannan and Dong, Jiuqing and Guo, Huiwen and Wang, Wenmin and You, Chuanchuan},
  doi          = {10.1007/s10489-024-05946-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {CSRP: Modeling class spatial relation with prototype network for novel class discovery},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual transfer learning method based on 3D-CNN and vision transformer for emotion recognition. <em>APIN</em>, <em>55</em>(2), 1-25. (<a href='https://doi.org/10.1007/s10489-024-05976-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of medical science, emotion recognition based on electroencephalogram (EEG) has been widely used in emotion computing. Despite the prevalence of deep learning in EEG signals analysis, standard convolutional and recurrent neural networks fall short in effectively processing EEG data due to their inherent limitations in capturing global dependencies and addressing the non-linear and unstable characteristics of EEG signals. We propose a dual transfer learning method based on 3D Convolutional Neural Networks (3D-CNN) with a Vision Transformer (ViT) to enhance emotion recognition. This paper aims to utilize 3D-CNN effectively to capture the spatial characteristics of EEG signals and reduce data covariance, extracting shallow features. Additionally, ViT is incorporated to improve the model’s ability to capture long-range dependencies, facilitating deep feature extraction. The methodology involves a two-stage process: initially, the front end of a pre-trained 3D-CNN is employed as a shallow feature extractor to mitigate EEG data covariance and transformer biases, focusing on low-level feature detection. The subsequent stage utilizes ViT as a deep feature extractor, adept at modeling the global aspects of EEG signals and employing attention mechanisms for precise classification. We also present an innovative algorithm for data mapping in transfer learning, ensuring consistent feature representation across both spatio-temporal dimensions. This approach significantly improves global feature processing and long-range dependency detection, with the integration of color channels augmenting the model’s sensitivity to signal variations. In a 10-fold cross-validation experiment on the DEAP, experimental results demonstrate that the proposed method achieves classification accuracies of 92.44 $$\%$$ and 92.85 $$\%$$ for the valence and arousal dimensions, and the accuracies of four-class classification across valence and arousal are HVHA: 88.01 $$\%$$ , HVLA: 88.27 $$\%$$ , LVHA: 90.89 $$\%$$ , LVLA: 78.84 $$\%$$ . Similarly, it achieves an accuracy of 98.69 $$\%$$ on the SEED. Overall, this methodology not only holds substantial potential in advancing emotion recognition tasks but also contributes to the broader field of affective computing.},
  archive      = {J_APIN},
  author       = {Guo, Zhifen and Wang, Jiao and Zhang, Bin and Ku, Yating and Ma, Fengbin},
  doi          = {10.1007/s10489-024-05976-z},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {A dual transfer learning method based on 3D-CNN and vision transformer for emotion recognition},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An active object detection model with multi-step prediction based on deep q-learning network and innovative training algorithm. <em>APIN</em>, <em>55</em>(2), 1-21. (<a href='https://doi.org/10.1007/s10489-024-05993-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active Object Detection (AOD) gathers additional information by deliberately adjusting the agent’s viewpoint, ensuring precise detection results in complex environments. Viewpoint planning(VP) is one of the focal points of attention in AOD. Until now, the predominant approach in implementing AOD algorithms has involved the use of deep q-learning networks(DQNs), with a single discrete action as the output. Nevertheless, these methods exhibit shortcomings in both implementation efficiency and success rate. To address these challenges, an AOD algorithm is proposed in this paper, allowing for multistep prediction and employing a novel training strategy. In more detail, the AOD network using a shared decision-making approach is first constructed, simultaneously outputting the action category and range. Moreover, a novel training method based on the Prioritized Experience Replay(PER) is introduced in this article, enhancing the operational success rate of the AOD algorithm. Finally, the reward function is optimized for the designed framework, thereby promoting the convergence of network training. Several comparable methods are tested on a public dataset(Active Vision Dataset), and the results clearly illustrate the superiority of the approach presented in this article.},
  archive      = {J_APIN},
  author       = {Wang, Jianyu and Zhu, Feng and Wang, Qun and Cui, Yunge and Sun, Haibo and Zhao, Pengfei},
  doi          = {10.1007/s10489-024-05993-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {An active object detection model with multi-step prediction based on deep q-learning network and innovative training algorithm},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GFENet: Group-wise feature-enhanced network for steering angle prediction by fusing events and images. <em>APIN</em>, <em>55</em>(2), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06019-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing end-to-end networks for steering angle prediction usually use images generated by standard cameras as input. However, standard cameras are susceptible to poor lighting conditions and motion blur, which is not conducive to training an accurate and robust end-to-end network. In contrast, biological vision-inspired event cameras overcome the aforementioned shortcomings with their unique working principle and offer significant advantages such as high temporal resolution, high dynamic range and low power consumption. Nevertheless, event cameras generate a lot of noise and are unable to provide texture information on static region. Therefore, these two types of cameras are complementary to each other to some extent. To explore the benefits of fusing information from these two types of cameras in autonomous driving tasks, we propose GFENet, an attention-based two-stream encoder-decoder architecture for steering angle prediction by combining events and images. Firstly, asynchronous and sparse events are converted into synchronous and dense event frames. Then, event frames and corresponding image frames are fed into two symmetric encoders to extract features. Next, We introduce a Group-Wise Feature-Enhanced (GEF) module that can refine features and suppress noise to guide the fusion of two modalities features at different levels. Finally, The final fused features are passed through a simple decoder to predict the steering angle. Experiments results on the DDD20 and EventScape datasets shows that our GFEFNet outperforms the state-of-the-art image-event fusion method.},
  archive      = {J_APIN},
  author       = {Chen, Duo-Wen and Guo, Chi and Hu, Jian-Lang},
  doi          = {10.1007/s10489-024-06019-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {GFENet: Group-wise feature-enhanced network for steering angle prediction by fusing events and images},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSDM: Multi-space diffusion with dynamic loss weight. <em>APIN</em>, <em>55</em>(2), 1-21. (<a href='https://doi.org/10.1007/s10489-024-06043-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have achieved remarkable results in image generation. However, due to the slow convergence speed, room for enhancement remains in existing loss weight strategies. In one aspect, the predefined loss weight strategy based on signal-to-noise ratio (SNR) transforms the diffusion process into a multi-objective optimization problem. However, it takes a long time to reach the Pareto optimal. In contrast, the unconstrained optimization weight strategy can achieve lower objective values, but the loss weights of each task change unstably, resulting in low training efficiency. In addition, the imbalance of lossy compression and semantic information in latent space diffusion also leads to missing image details. To solve these problems, a new loss weight strategy combining the advantages of predefined and learnable loss weights is proposed, effectively balancing the gradient conflict of multi-objective optimization. A high-dimensional multi-space diffusion method called Multi-Space Diffusion is also introduced, and a loss function that considers both structural information and robustness is designed to achieve a good balance between lossy compression and fidelity. The experimental results indicate that the proposed model and strategy significantly enhance the convergence speed, being 3.7 times faster than the Const strategy, and achieve an advanced FID = 3.35 score on the ImageNet512.},
  archive      = {J_APIN},
  author       = {Liu, Zhou and Ye, Zheng and Liu, Jing and Qin, Jun and He, Ben and Gurrin, Cathal},
  doi          = {10.1007/s10489-024-06043-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {MSDM: Multi-space diffusion with dynamic loss weight},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-light image enhancement via an attention-guided deep retinex decomposition model. <em>APIN</em>, <em>55</em>(2), 1-13. (<a href='https://doi.org/10.1007/s10489-024-06044-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images acquired from optical imaging devices in a low-light or back-lit environment usually lead to a poor visual experience. The poor visibility and the attendant contrast or color distortion may degrade the performance of subsequent vision processing. To enhance the visibility of low-light image and mitigate the degradation of vision systems, an attention-guided deep Retinex decomposition model, dubbed Ag-Retinex-Net, is proposed. Inspired by the Retinex theory, the Ag-Retinex-Net first decomposes the input low-light image into two layers under an elaborate multi-term regularization, and then recomposes the refined two layers to obtain the final enhanced images via attention-guided generative adversarial learning. The multi-term constraints in the decomposition module can help better regularize and extract the decomposed illumination and reflectance. And the attention-guided generative adversarial learning in the recomposition module is utilized to help remove the degradation. The experimental results show that the proposed Ag-Retinex-Net outperforms other Retinex-based methods in terms of both visual quality and several objective evaluation metrics.},
  archive      = {J_APIN},
  author       = {Luo, Yu and Lv, Guoliang and Ling, Jie and Hu, Xiaomin},
  doi          = {10.1007/s10489-024-06044-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Low-light image enhancement via an attention-guided deep retinex decomposition model},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient enhanced feature framework for grading of renal cell carcinoma using histopathological images. <em>APIN</em>, <em>55</em>(2), 1-22. (<a href='https://doi.org/10.1007/s10489-024-06047-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Renal cell carcinoma (RCC) represents the primary type of kidney cancer, responsible for approximately 85% of kidney cancer-related fatalities. Precise grading of this cancer is pivotal for tailoring effective treatments. Detecting RCC early, before metastasis, significantly improves survival rates. While Artificial intelligence-based classification methods have emerged for RCC, advancements in accuracy, processing efficiency, and memory utilization remain imperative. This study introduces the Efficient Enhanced Feature Framework (EFF-Net), a deep neural network architecture designed for RCC grading using histopathological image analysis. EFF-Net amalgamates potent feature extraction from convolutional layers with efficient Separable convolutional layers, aiming to accelerate model inference, reduce trainable parameters, mitigate overfitting, and elevate RCC grading precision. Evaluation across three distinct datasets showcases the EFF-Net's outstanding performance: achieving 91.90% accuracy, a precision of 91.4%, a recall of 91.8%, and a harmonic mean of precision and recall (F1 score) of 91.9% on the Kasturba Medical College (KMC) dataset. Additionally, on the Lung and Colon Dataset, EFF-Net achieved 99.8% accuracy, a precision of 99.7%, a recall of 99.9%, and a 98.7% F1 score. Similarly, the Acute Lymphoblastic Leukaemia dataset demonstrated remarkable performance: 99.8% accuracy, a precision of 99%, a recall of 99%, and a 99.7% F1 score. EFF-Net's superior accuracy surpasses existing state-of-the-art approaches while exhibiting reduced trainable parameters and computational requirements.},
  archive      = {J_APIN},
  author       = {Maqsood, Faiqa and Wang, Zhenfei and Ali, Muhammad Mumtaz and Qiu, Baozhi and Mahmood, Tahir and Sarwar, Raheem},
  doi          = {10.1007/s10489-024-06047-z},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {An efficient enhanced feature framework for grading of renal cell carcinoma using histopathological images},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Precipitation nowcasting with generative diffusion models. <em>APIN</em>, <em>55</em>(2), 1-21. (<a href='https://doi.org/10.1007/s10489-024-06048-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years traditional numerical methods for accurate weather prediction have been increasingly challenged by deep learning methods. Numerous historical datasets used for short and medium-range weather forecasts are typically organized into a regular spatial grid structure. This arrangement closely resembles images: each weather variable can be visualized as a map or, when considering the temporal axis, as a video. Several classes of generative models, comprising Generative Adversarial Networks, Variational Autoencoders, or the recent Denoising Diffusion Models have largely proved their applicability to the next-frame prediction problem, and is thus natural to test their performance on the weather prediction benchmarks. Diffusion models are particularly appealing in this context, due to the intrinsically probabilistic nature of weather forecasting: what we are really interested to model is the probability distribution of weather indicators, whose expected value is the most likely prediction. In our study, we focus on a specific subset of the ERA-5 dataset, which includes hourly data pertaining to Central Europe from the years 2016 to 2021. Within this context, we examine the efficacy of diffusion models in handling the task of precipitation nowcasting, with a lead time of 1 to 3 hours. Our work is conducted in comparison to the performance of well-established U-Net models, as documented in the existing literature. An additional comparative analysis has been done with the forecasting capabilities of the CERRA system, part of the Copernicus Climate Change Service. The novelty of our approach, Generative Ensemble Diffusion (GED), lies in its innovative use of a diffusion model to generate a diverse set of possible weather scenarios. These scenarios are then amalgamated into a single prediction in a post-processing phase. This approach mimics the usual weather forecasting technique consisting in running an ensemble of numerical simulations under slightly different initial conditions by exploiting instead the intrinsic stochasticity of the generative model. In comparison to recent deep learning models addressing the same problem, our approach results in approximately a 25% reduction in the mean squared error. Reverse diffusion is a core concept in our GED approach, is particularly relevant to weather forecasting. In the context of diffusion models, reverse diffusion refers to the process of iteratively refining a noisy initial prediction into a coherent and realistic forecast. By leveraging reverse diffusion, our model effectively simulates the complex temporal dynamics of weather systems, mirroring the inherent uncertainty and variability in weather patterns.},
  archive      = {J_APIN},
  author       = {Asperti, Andrea and Merizzi, Fabio and Paparella, Alberto and Pedrazzi, Giorgio and Angelinelli, Matteo and Colamonaco, Stefano},
  doi          = {10.1007/s10489-024-06048-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Precipitation nowcasting with generative diffusion models},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interactive multi-task ESG classification method for chinese financial texts. <em>APIN</em>, <em>55</em>(2), 1-18. (<a href='https://doi.org/10.1007/s10489-024-06068-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In view of the problems existing in the ESG classification task of Chinese financial texts, such as feature loss caused by excessively long texts, this paper proposes an interactive multi-task model AmultiESG for ESG classification of Chinese financial texts. The model divides Chinese financial text ESG classification and financial sentiment dictionary expansion into primary and secondary tasks. First, BiLSTM model is used to learn the original representation of the text. Then, in the secondary task, the attention mechanism and full connection layers are combined with the domain dictionary to realize the extraction of emotional words. In the main task, in order to prevent feature loss due to the excessively long texts, we process the text again and divide it into blocks according to the period. Meanwhile, we learned new feature representation of the text by combining text label representation, text block representation, BiLSTM output features and domain dictionary features. And we introduce an interactive information transfer mechanism to iteratively improve the predicted results of the two tasks and strengthen the association between them. It has been experimentally demonstrated that the proposed method shows superior performance compared to other baselines for the ESG classification task of Chinese financial text, especially for long-text classification tasks.},
  archive      = {J_APIN},
  author       = {Zhang, Han and Zhang, Yazhou and Wang, Xinyu and Zhang, Lei and Ji, Lixia},
  doi          = {10.1007/s10489-024-06068-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {An interactive multi-task ESG classification method for chinese financial texts},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robot path tracking method based on manual guidance and path reinforcement learning. <em>APIN</em>, <em>55</em>(2), 1-20. (<a href='https://doi.org/10.1007/s10489-024-06098-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlling the movement of an industrial robot along specific edges of a workpiece in a complex environment, where multiple paths intersect, is crucial for tasks such as welding and gluing. Traditional robot teaching methods restrict robots to fixed task environments using pre-programmed motion planning schemes. Although vision-guided robotic path-tracking systems can automatically extract paths, the presence of multiple intersections complicates autonomous path determination and tracking using conventional vision-based algorithms. To address this challenge, this study proposed a robot path-tracking approach that integrates manual guidance with path reinforcement learning. This strategy leverages both visual- and human-guided information to learn complex manipulation skills that require precise positional constraints and continuous motion, such as welding or gluing, in environments with intersecting paths. A user-friendly robot path teaching framework was designed, allowing operators to select key positions on the robot manipulator’s motion path (2D guide pixel points) from color images using a mouse to generate guide images. However, these interactively selected 2D guide pixel points may introduce biases relative to the ideal robot path (i.e., the edge of the workpiece that needs to be tracked). To mitigate this, a path reinforcement learning technique was proposed that uses the edge image of the workpiece along with manual guidance to determine the necessary actions (2D pixel tracking path points) for tracking specific edges in complex environments. This process is constrained by guide images and an invalid action mask matrix. An invalid action mask matrix, calculated from the guide points, prevents the exploration of suboptimal trajectories during path reinforcement learning. The robot’s 6- degrees of freedom (DOF) path was then derived from the 2D pixel-tracking path points and depth images. Finally, the accuracy of 2D pixel path tracking was tested in a virtual environment, yielding an average error of 0.363 pixels and a standard deviation of 0.594 pixels. The effectiveness of the proposed path-tracking approach in scenarios with multiple intersecting paths was verified in a physical environment.},
  archive      = {J_APIN},
  author       = {Pan, Yong and Chen, Chengjun and Li, Dongnian and Zhao, Zhengxu},
  doi          = {10.1007/s10489-024-06098-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {A robot path tracking method based on manual guidance and path reinforcement learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual semantic navigation with real robots. <em>APIN</em>, <em>55</em>(2), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06115-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Semantic Navigation (VSN) is the ability of a robot to learn visual semantic information for navigating in unseen environments. These VSN models are typically tested in those virtual environments where they are trained, mainly using reinforcement learning based approaches. Therefore, we do not yet have an in-depth analysis of how these models would behave in the real world. In this work, we propose a new solution to integrate VSN models into real robots, so that we have true embodied agents. We also release a novel ROS-based framework for VSN, ROS4VSN, so that any VSN-model can be easily deployed in any ROS-compatible robot and tested in a real setting. Our experiments with two different robots, where we have embedded two state-of-the-art VSN agents, confirm that there is a noticeable performance difference of these VSN solutions when tested in real-world and simulation environments. We hope that this research will endeavor to provide a foundation for addressing this consequential issue, with the ultimate aim of advancing the performance and efficiency of embodied agents within authentic real-world scenarios. Code to reproduce all our experiments can be found at https://github.com/gramuah/ros4vsn .},
  archive      = {J_APIN},
  author       = {Gutiérrez-Álvarez, Carlos and Ríos-Navarro, Pablo and Flor-Rodríguez-Rabadán, Rafael and Acevedo-Rodríguez, Francisco Javier and López-Sastre, Roberto Javier},
  doi          = {10.1007/s10489-024-06115-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Visual semantic navigation with real robots},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-based multi-label feature selection with dynamic graph constraints and latent representation learning. <em>APIN</em>, <em>55</em>(2), 1-22. (<a href='https://doi.org/10.1007/s10489-024-06116-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, multi-label feature selection with joint manifold learning and linear mapping has received much attention. However, the low-quality graph matrix used by existing methods leads to model limitations. Traditional linear mapping cannot learn the coupling relationship between different outputs. In addition, existing approaches ignore latent supervisory information in label correlation. To this end, we obtain a dynamic graph matrix with Laplace rank constraints by the $$L_{1}$$ norm with a conventional graph matrix. We also mine more reliable supervised information from label correlations by introducing latent representation learning. Moreover, we integrate all the above terms into a linear mapping learning framework based on improved matrix decomposition, and design a simple and effective scheme based on alternating iterations to optimize this framework. Numerous experimental results validate the competitive advantage of the proposed method over existing state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Bai, Jianxia and Wu, Yanhong},
  doi          = {10.1007/s10489-024-06116-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Graph-based multi-label feature selection with dynamic graph constraints and latent representation learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-adaptation feature correspondences identification algorithm in terms of IMU-aided information fusion for VINS. <em>APIN</em>, <em>55</em>(2), 1-12. (<a href='https://doi.org/10.1007/s10489-024-06120-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature correspondences identification between consecutive frames is a critical prerequisite in the monocular Visual-Inertial Navigation System (VINS). In this paper, we propose a novel self-adaptation feature point correspondences identification algorithm in terms of IMU-aided information fusion at the level of feature tracking for nonlinear optimization framework-based VINS. This method starts with an IMU pre-integration predictor to predict the pose of each new coming frame. In weak texture scenes and motion blur situations, in order to increase the number of feature correspondences and improve the track lengths of feature points, we introduce a novel predicting-matching based feature point tracking strategy to build new matches. On the other hand, the predicted pose is incorporated into the outliers rejection step to deal with mismatch caused by dynamic objects. Finally, the proposed self-adaptation feature correspondences identification algorithm is implemented based on VINS-Fusion and validated through public datasets. The experimental results show that it effectively improves the accuracy and tracking length of feature matching, and demonstrates better performance in terms of camera pose estimation as compared to state-of-the-art approaches.},
  archive      = {J_APIN},
  author       = {Yu, Zhelin},
  doi          = {10.1007/s10489-024-06120-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {A self-adaptation feature correspondences identification algorithm in terms of IMU-aided information fusion for VINS},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HFedCWA: Heterogeneous federated learning algorithm based on contribution-weighted aggregation. <em>APIN</em>, <em>55</em>(2), 1-16. (<a href='https://doi.org/10.1007/s10489-024-06123-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of heterogeneous federated learning (HFL) is to address the issues of data heterogeneity, computational resource disparity, and model generalizability and security in federated learning (FL). To facilitate the collaborative training of data and enhance the predictive performance of models, a heterogeneous federated learning algorithm based on contribution-weighted aggregation (HFedCWA) is proposed in this paper. First, weights are assigned on the basis of the distribution differences and quantities of heterogeneous device data, and a contribution-based weighted aggregation method is introduced to dynamically adjust weights and balance data heterogeneity. Second, personalized strategies based on regularization are formulated for heterogeneous devices with different weights, enabling each device to participate in the overall task in an optimal manner. Differential privacy methods are concurrently utilized in FL training to further enhance the security of the system. Finally, experiments are conducted under various data heterogeneity scenarios using the MNIST and CIFAR10 datasets, and the results demonstrate that the HFedCWA can effectively improve the model’s generalizability ability and adaptability to heterogeneous data, thereby enhancing the overall efficiency and performance of the HFL system.},
  archive      = {J_APIN},
  author       = {Du, Jiawei and Wang, Huaijun and Li, Junhuai and Wang, Kan and Fei, Rong},
  doi          = {10.1007/s10489-024-06123-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {HFedCWA: Heterogeneous federated learning algorithm based on contribution-weighted aggregation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring emotional stability: From conventional approaches to machine learning insights. <em>APIN</em>, <em>55</em>(2), 1-15. (<a href='https://doi.org/10.1007/s10489-024-06130-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In contemporary psychological assessments, diverse traits are often evaluated using extensive questionnaires. This study focuses on the trait of emotional stability, and acknowledges the inherent limitations and issues associated with prolonged survey instruments. To address these challenges, we propose a Machine Learning (ML) approach to directly predict emotional stability, offering a more efficient alternative to bulky questionnaires. The study carefully selected variables with previously established relationships to emotional stability, utilizing a dataset of 2203 individuals who responded to a series of psychometric questionnaires. The proposed method yields promising results, achieving an R2 score of approximately 0.71 on the test set, indicating robust predictive performance. These models highlighted the significance of variables such as emotional stress and self-esteem, emphasizing their substantial role in predicting emotional stability. It is noteworthy that even with a reduced set of variables, the models remained statistically equivalent. The results provide valuable insights for predicting stability with smaller sets of variables and contribute knowledge that complements the understanding of emotional stability.},
  archive      = {J_APIN},
  author       = {Madroñal, Marcos Romero and Ramírez, Eduar S. and Ruiz, Luis Gonzaga Baca and Serrano-Fernández, María José and Pérez-Moreiras, Elena and Pegalajar Jiménez, María del Carmen},
  doi          = {10.1007/s10489-024-06130-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Exploring emotional stability: From conventional approaches to machine learning insights},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Entity alignment in noisy knowledge graph. <em>APIN</em>, <em>55</em>(2), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06131-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity alignment is an important task in Knowledge Graph(KG), which aims to find identical entities in two different KGs. Existing methods include two steps, graph representation and alignment inference. The representation is learned based on the semantics and structure of KG. In applications, however, incorrect triples (which are also called structure noise) inevitably exist in KGs due to low-quality corpora and low-performance construction algorithms. The structure noise in KGs affects the representation of KGs and the alignment inference. To this end, we propose an entity alignment method in noisy knowledge graphs for the first time. Firstly, a noise-aware module is designed to recognize the noisy triples and exclude them from KG representation. Secondly, we design a more strict semi-supervised algorithm that combines local similarity and global alignment cost together to obtain high-quality pseudo-alignments in noisy environments. The experimental results demonstrate the effectiveness of our method in noisy KGs and the good compatibility with other baselines.},
  archive      = {J_APIN},
  author       = {Zhang, Yuhong and Zhu, Xiaolong and Hu, Xuegang},
  doi          = {10.1007/s10489-024-06131-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Entity alignment in noisy knowledge graph},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nash equilibria decision tree for binary classification. <em>APIN</em>, <em>55</em>(2), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06132-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision trees rank among the most popular and efficient classification methods. They are used to represent rules for recursively partitioning the data space into regions from which reliable predictions regarding classes can be made. These regions are usually delimited by axis-parallel or oblique hyperplanes. Axis-parallel hyperplanes are intuitively appealing and have been widely studied. However, there is still room for exploring different approaches. In this paper, a splitting rule that constructs axis-parallel hyperplanes by computing the Nash equilibrium of a game played at the node level is used to induct a Nash Equilibrium Decision Tree for binary classification. Numerical experiments are used to illustrate the behavior of the proposed method.},
  archive      = {J_APIN},
  author       = {Suciu, Mihai-Alexandru and Lung, Rodica Ioana},
  doi          = {10.1007/s10489-024-06132-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {A nash equilibria decision tree for binary classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective dynamical evaluation and optimization mechanism for accurate motion primitives learning. <em>APIN</em>, <em>55</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10489-024-06147-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory planning is an important stage in robot operation. Many imitation learning methods have been researched for learning operation skills from demonstrated trajectories. However, it is still a challenge to use the learned skill models to generate motion trajectories suitable for various changing conditions. In this paper, a closed-loop dynamical evaluation and optimization mechanism is proposed for imitation learning model to generate the optimal trajectories that can adapt to multiple conditions. This mechanism works by integrating the following parts: (1) imitation learning based on an improved dynamic motion primitive; (2) constructing the trajectory similarity evaluation function; (3) presenting an enhanced whale optimization algorithm(EWOA) by introducing the piecewise decay rate and inertia weight for avoiding getting stuck in local optima. The EWOA iteratively optimizes the key parameter of the skill learning model based on the cost function of the trajectory similarity evaluation for generating the trajectory with the highest similarity to the teaching trajectory. The effectiveness of the EWOA is validated using 10 functions by comparing with the other two methods. And the feasibility of the dynamical optimization mechanism is proved under different motion primitives and various generation conditions.},
  archive      = {J_APIN},
  author       = {Liu, Chunfang and Li, Changfeng and Li, Xiaoli and Zuo, Guoyu and Yu, Pan},
  doi          = {10.1007/s10489-024-06147-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {An effective dynamical evaluation and optimization mechanism for accurate motion primitives learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Text-dominant multimodal perception network for sentiment analysis based on cross-modal semantic enhancements. <em>APIN</em>, <em>55</em>(2), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06150-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis (MSA) aims to discern the emotional information expressed by users in the multimodal data they upload on various social media platforms. In most previous studies, these modalities (audio A, visual V, and text T) were typically treated equally, overlooking the lower representation quality inherent in audio and visual modalities. This oversight often results in inaccurate interaction information when audio or visual modalities are used as the primary input, thereby negatively impacting the model’s sentiment predictions. In this paper, we propose a text-dominant multimodal perception network with cross-modal transformer-based semantic enhancement. The network comprises primarily a text-dominant multimodal perception (TDMP) module and a cross-modal transformer-based semantic enhancement (TSE) module. TDMP leverages the text modality to dominate intermodal interactions, extracting high correlation and differentiation features from each modality, thereby obtaining more accurate representations for each modality. The TSE module uses a transformer architecture to convert the audio and visual modality features into text features. By applying KL divergence constraints, it ensures that the translated modality representations capture as much emotional information as possible while maintaining high similarity to the original text modality representations. This enhances the original text modality semantics while mitigating the negative impact of the input. Extensive experiments on the CMU-MOSI and CMU-MOSEI datasets demonstrate the effectiveness of our proposed model. The overview of Text-dominant Multimodal Perception Network},
  archive      = {J_APIN},
  author       = {Li, Zuhe and Liu, Panbo and Pan, Yushan and Yu, Jun and Liu, Weihua and Chen, Haoran and Luo, Yiming and Wang, Hao},
  doi          = {10.1007/s10489-024-06150-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Text-dominant multimodal perception network for sentiment analysis based on cross-modal semantic enhancements},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SPECN: Sequential patterns enhanced capsule network for sequential recommendation. <em>APIN</em>, <em>55</em>(2), 1-11. (<a href='https://doi.org/10.1007/s10489-024-06159-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential patterns and the order of items in sequences are particularly important for sequential recommendation (SR), which decide what item will interact with the user. However, there are still some problems for the existing methods: (1) They treat all the features of each item equally, we believe that those features the user pays more attention to of each item play a key role to predict next item. (2) Many methods not only ignore sequential patterns and the order of sequences, but also cannot highlight more important features, they only focus on whether the features exist. To address these issues, we propose the Sequential Patterns Enhanced Capsule Network (SPECN). SPECN leverages a self-attention mechanism, using user information as a guide to highlight the most relevant features for each item, then concatenates these features with the original item features in the sequence.SPECN applies horizontal and vertical capsule networks which package neurons into vectors to extract sequential patterns features and the order of sequences. The horizontal capsule network enhances sequential pattern features by learning both the original and user-focused features of individual or adjacent items, containing original features and those features that the user pays more attention to of single item or adjacent items’ features (features of the previous item that the users pay more attention to and features of the current item) to enhance the sequential patterns features. The vertical capsule network captures finer-grained feature representations for each item, improving the recommendation quality. We conduct several experiments on three real-world datasets to demonstrate the superiority of SPECN, outperforming existing methods in terms of accuracy and robustness.},
  archive      = {J_APIN},
  author       = {Shunpan, Liang and Zhizhong, Zheng and Guozheng, Zhang and Qianjin, Kong},
  doi          = {10.1007/s10489-024-06159-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-11},
  shortjournal = {Appl. Intell.},
  title        = {SPECN: Sequential patterns enhanced capsule network for sequential recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hierarchical set-enumeration tree enabling high occupancy item set mining and the use of an adaptive occupancy threshold. <em>APIN</em>, <em>55</em>(2), 1-21. (<a href='https://doi.org/10.1007/s10489-024-06166-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The highly efficient HEP algorithm is a useful tool for mining High Occupancy (HO) item sets. Occupancy is an important measure that describes the interestingness of frequent item sets. The current study examines the efficiency problems in mining HO item sets and proposes an improved HEP algorithm, named advanced HEP (A–HEP), based on set theory rules which eliminate a large number of redundant iterations. The study also proposes a novel adaptive-and-modified HEP (NAM–HEP) algorithm that uses HO Set-Enumeration (SE) trees to store HO item sets. The study proposes definitions for adaptive thresholds such as support threshold and occupancy threshold based on the attributes of the transaction database for efficient pruning of the HO-SE tree. Two pseudo-code blocks are presented in addition to a detailed description of the A–HEP and NAM–HEP algorithms and their advantages. Using the A–HEP and NAM–HEP algorithms, HO item sets are investigated from the practical transaction databases named mushroom and retail. The results indicate that the proposed A–HEP and NAM–HEP algorithms enhance mining performance and runtime benchmarks.},
  archive      = {J_APIN},
  author       = {Tran, Thanh-Nam and Truong Hoang, Vinh and Truong, Thanh-Cong and Voznak, Miroslav},
  doi          = {10.1007/s10489-024-06166-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {A hierarchical set-enumeration tree enabling high occupancy item set mining and the use of an adaptive occupancy threshold},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An asynchronous federated learning-assisted data sharing method for medical blockchain. <em>APIN</em>, <em>55</em>(2), 1-21. (<a href='https://doi.org/10.1007/s10489-024-06172-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, medical blockchain data sharing methods that rely on federated learning face challenges, including node disconnection, vulnerability to poisoning attacks, and insufficient consideration of conflicts of interest among participants. To address these issues, we propose a novel method for data sharing in medical blockchain systems based on asynchronous federated learning. First, we develop an aggregation algorithm designed specifically for asynchronous federated learning to tackle the problem of node disconnection. Next, we introduce a Proof of Reputation (PoR) consensus algorithm and establish a consensus committee to mitigate the risk of poisoning attacks. Furthermore, we integrate a tripartite evolutionary game model to examine conflicts of interest among publishing nodes, committee nodes, and participating nodes. This framework enables all parties involved to make strategic decisions that promote sustainable data-sharing practices. Finally, we conduct a security analysis to validate the theoretical effectiveness of the proposed method. Experimental evaluations using real medical datasets demonstrate that our method outperforms existing approaches.},
  archive      = {J_APIN},
  author       = {Gan, Chenquan and Xiao, Xinghai and Zhang, Yiye and Zhu, Qingyi and Bi, Jichao and Jain, Deepak Kumar and Saini, Akanksha},
  doi          = {10.1007/s10489-024-06172-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {An asynchronous federated learning-assisted data sharing method for medical blockchain},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging meta-data of code for adapting prompt tuning for code summarization. <em>APIN</em>, <em>55</em>(2), 1-15. (<a href='https://doi.org/10.1007/s10489-024-06197-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prompt tuning alleviates the gap between pre-training and fine-tuning and achieves promising results in various natural language processing (NLP) tasks. However, it is nontrivial for adapting prompt tuning in intelligent code tasks since code-specific knowledge such as abstract syntax tree is usually hierarchy-structured and therefore is hard to be converted into plain text. Recent works (e.g., PT4Code) introduce simple task prompts along with a programming language indicator into prompt template, achieving improvement over non-prompting state-of-the-art code models (e.g., CodeT5). Inspired by this, we propose a novel code-specific prompt paradigm, meta-data prompt, which introduces semi-structured code’s meta-data (attribute-value pairs) into prompt template and facilitates the adaption of prompt tuning techniques into code tasks. Specifically, we find the usage of diverse meta-data attributes and their combinations and employ the OpenPrompt to implement a meta-data prompt based code model, PRIME (PRompt tunIng with MEta-data), via utilizing CodeT5 as the backbone model. We experiment PRIME with the source code summarization task on the publicly available CodeSearchNet benchmark. Results show that 1) using good meta-data can lead to an improvement on the model performance; 2) the proposed meta-data prompt can be combined with traditional task prompt for further improvement; 3) our best-performing model can consistently outperform CodeT5 by an absolute score of 0.73 and PT4Code by an absolute score of 0.48 regarding the averaged BLEU metric across six programming languages.},
  archive      = {J_APIN},
  author       = {Jiang, Zhihua and Wang, Di and Rao, Dongning},
  doi          = {10.1007/s10489-024-06197-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Leveraging meta-data of code for adapting prompt tuning for code summarization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards more accurate object detection via encoding reinforcement and multi-channel enhancement. <em>APIN</em>, <em>55</em>(2), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06200-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing object detection networks typically apply small kernel convolution that can extract sufficient features for recognizing targets but have poor long-range dependency capability and smaller receptive fields. This paper proposes an object detection network with structure featuring large kernel convolutions and multiple channels. Firstly, the encoding reinforcement module using large kernel convolutions is designed to enlarge the receptive field and improve global feature extraction. Then, the channel enhancement module is constructed to enhance structural information learning. In addition, the encoding reinforcement and channel enhancement are designed in a lightweight way. Finally, the WIOU loss function is introduced to enhance the model’s robustness in poor-quality datasets. In the experiments, the proposed model can achieve optimal performance with similar parameters or computational complexity to existing CNN-based lightweight models.},
  archive      = {J_APIN},
  author       = {Wang, Weina and Li, Shuangyong and Jumahong, Huxidan},
  doi          = {10.1007/s10489-024-06200-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Towards more accurate object detection via encoding reinforcement and multi-channel enhancement},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Short-term traffic flow prediction based on spatial–temporal attention time gated convolutional network with particle swarm optimization. <em>APIN</em>, <em>55</em>(2), 1-15. (<a href='https://doi.org/10.1007/s10489-024-06117-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the surge in vehicle ownership has led to a corresponding increase in the complexity of traffic data. Consequently, accurate traffic flow prediction has become crucial for effective traffic management. While the advancements in intelligent transportation system (ITS) and internet of things (IoT) technology have facilitated traffic flow prediction, many existing methods overlook the influence of the training process on model accuracy. Traditional approaches often fail to account for this critical aspect. Hence, a new approach to traffic flow prediction is introduced in this paper: a spatial–temporal attention time-gated convolutional network based on particle swarm optimization (PSO-STATG). This method uses the particle swarm algorithm to dynamically optimize the learning rate and epoch parameters throughout the training process. Firstly, spatial–temporal correlations are extracted through spatial map convolution and time-gated convolution, facilitated by an attention mechanism. Subsequently, the learning rate and epoch parameters are dynamically adjusted during the training phase via the particle swarm optimization algorithm. Finally, experiments are conducted with real-world datasets, and the results are compared with those from several existing methods. The experimental results indicate that the accuracy and stability of our proposed model in predicting traffic flow are superior.},
  archive      = {J_APIN},
  author       = {Li, Zhongxing and Li, Zenan and Pan, Chaofeng and Wang, Jian},
  doi          = {10.1007/s10489-024-06117-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Short-term traffic flow prediction based on spatial–temporal attention time gated convolutional network with particle swarm optimization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Calibrating TabTransformer for financial misstatement detection. <em>APIN</em>, <em>55</em>(1), 1-15. (<a href='https://doi.org/10.1007/s10489-024-05861-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we deal with the task of identifying the probability of misstatements in the annual financial reports of public companies. In particular, we improve the state-of-the-art for financial misstatement detection by training a TabTransformer model with a gated multi-layer perceptron, which encodes and exploits relationships between financial features. We further calibrate a sample-dependent focal loss function to deal with the severe class imbalance in the data and to focus on positive examples that are hard to distinguish. We evaluate the proposed methodology in a realistic setting that preserves the essential characteristics of the task: (a) the imbalanced distribution of classes in the data, (b) the chronological order of data, and (c) the systematic noise in the labels, due to the delay in manually identifying misstatements. The proposed method achieves state-of-the-art results in this setting, compared to recent approaches in the literature. As an additional contribution, we release the dataset to facilitate further research in the field.},
  archive      = {J_APIN},
  author       = {Zavitsanos, Elias and Kelesis, Dimitrios and Paliouras, Georgios},
  doi          = {10.1007/s10489-024-05861-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Calibrating TabTransformer for financial misstatement detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A prototype evolution network for relation extraction. <em>APIN</em>, <em>55</em>(1), 1-14. (<a href='https://doi.org/10.1007/s10489-024-05864-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prototypical networks transform relation instances and relation types into the same semantic space, where a relation instance is assigned a type based on the nearest prototype. Traditional prototypical network methods generate relation prototypes by averaging the sentence representations from a predefined support set, which suffers from two key limitations. One limitation is sensitive to the outliers in the support set that can skew the relation prototypes. Another limitation is the lack of the necessary representational capacity to capture the full complexity of the relation extraction task. To address these limitations, we propose the Prototype Evolution Network (PEN) for relation extraction. First, we assign a type cue for each relation instance to mine the semantics of the relation type. Based on the type cues and relation instances, we then present a prototype refiner comprising a multichannel convolutional neural network and a scaling module to learn and refine the relation prototypes. Finally, we introduce historical prototypes during each episode into the current prototype learning process to enable continuous prototype evolution. We evaluate the PEN on the ACE 2005, SemEval 2010, and CoNLL2004 datasets, and the results demonstrate impressive improvements, with the PEN outperforming existing state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Wang, Kai and Chen, Yanping and Huang, Ruizhang and Qin, Yongbin},
  doi          = {10.1007/s10489-024-05864-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {A prototype evolution network for relation extraction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Channel enhanced cross-modality relation network for visible-infrared person re-identification. <em>APIN</em>, <em>55</em>(1), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06057-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible-infrared person re-identification (VI Re-ID) is designed to perform pedestrian retrieval on non-overlapping visible-infrared cameras, and it is widely employed in intelligent surveillance. For the VI Re-ID task, one of the main challenges is the huge modality discrepancy between the visible and infrared images. Therefore, mining more shared features in the cross-modality task turns into an important issue. To address this problem, this paper proposes a novel framework for feature learning and feature embedding in VI Re-ID, namely Channel Enhanced Cross-modality Relation Network (CECR-Net). More specifically, the network contains three key modules. In the first module, to shorten the distance between the original modalities, a channel selection operation is applied to the visible images, the robustness against color variations is improved by randomly generating three-channel R/G/B images. The module also exploits the low- and mid-level information of the visible and auxiliary modal images through a feature parameter-sharing strategy. Considering that the body sequences of pedestrians are not easy to change with modality, CECR-Net designs two modules based on relation network for VI Re-ID, namely the intra-relation learning and the cross-relation learning modules. These two modules help to capture the structural relationship between body parts, which is a modality-invariant information, disrupting the isolation between local features. Extensive experiments on the two public benchmarks indicate that CECR-Net is superior compared to the state-of-the-art methods. In particular, for the SYSU-MM01 dataset, the Rank1 and mAP reach 76.83% and 71.56% in the "All Search" mode, respectively.},
  archive      = {J_APIN},
  author       = {Song, Wanru and Wang, Xinyi and Wu, Weimin and Zhang, Yuan and Liu, Feng},
  doi          = {10.1007/s10489-024-06057-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Channel enhanced cross-modality relation network for visible-infrared person re-identification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HG-search: Multi-stage search for heterogeneous graph neural networks. <em>APIN</em>, <em>55</em>(1), 1-18. (<a href='https://doi.org/10.1007/s10489-024-06058-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, heterogeneous graphs, a complex graph structure that can express multiple types of nodes and edges, have been widely used for modeling various real-world scenarios. As a powerful analysis tool, heterogeneous graph neural networks (HGNNs) can effectively mine the information and knowledge in heterogeneous graphs. However, designing an excellent HGNN architecture requires a lot of domain knowledge and is a time-consuming and laborious task. Inspired by neural architecture search (NAS), some works on homogeneous graph NAS have emerged. However, there are few works on heterogeneous graph NAS. In addition, the hyperparameters related to the HGNN architecture are also important factors affecting its performance in downstream tasks. Manually tuning hyperparameters is also a tedious and inefficient process. To solve the above problems, we propose a novel search (HG-Search for short) algorithm specifically for HGNNs, which achieves fully automatic architecture design and hyperparameter tuning. Specifically, we first design a search space for HG-Search, composed of two parts: HGNN architecture search space and hyperparameter search space. Furthermore, we propose a multi-stage search (MS-Search for short) module and combine it with the policy gradient search (PG-Search for short). Experiments on real-world datasets show that this method can design HGNN architectures comparable to those manually designed by humans and achieve automatic hyperparameter tuning, significantly improving the performance in downstream tasks. The code and related datasets can be found at https://github.com/dawn-creator/HG-Search .},
  archive      = {J_APIN},
  author       = {Sun, Hongmin and Kan, Ao and Liu, Jianhao and Du, Wei},
  doi          = {10.1007/s10489-024-06058-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {HG-search: Multi-stage search for heterogeneous graph neural networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic-aware matrix factorization hashing with intra- and inter-modality fusion for image-text retrieval. <em>APIN</em>, <em>55</em>(1), 1-18. (<a href='https://doi.org/10.1007/s10489-024-06060-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal retrieval aims to retrieve related items in one modality using a query from another modality. As the foundational and key challenge of it, image-text retrieval has garnered significant research interest from scholars. In recent years, hashing techniques have gained widespread interest for large-scale dataset retrieval due to their minimal storage requirements and rapid query processing capabilities. However, existing hashing approaches either learn unified representations for both modalities or specific representations within each modality. The former approach lacks modality-specific information, while the latter does not consider the relationships between image-text pairs across various modalities. Therefore, we propose an innovative supervised hashing method that leverages intra-modality and inter-modality matrix factorization. This method integrates semantic labels into the hash code learning process, aiming to understand both inter-modality and intra-modality relationships within a unified framework for diverse data types. The objective is to preserve inter-modal complementarity and intra-modal consistency in multimodal data. Our approach involves: (1) mapping data from various modalities into a shared latent semantic space through inter-modality matrix factorization to derive unified hash codes, and (2) mapping data from each modality into modality-specific latent semantic spaces via intra-modality matrix factorization to obtain modality-specific hash codes. These are subsequently merged to construct the final hash codes. Experimental results demonstrate that our approach surpasses several state-of-the-art cross-modal image-text retrieval hashing methods. Additionally, ablation studies further validate the effectiveness of each component within our model.},
  archive      = {J_APIN},
  author       = {Shi, Dongxue and Liu, Zheng and Gao, Shanshan and Li, Ang},
  doi          = {10.1007/s10489-024-06060-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Semantic-aware matrix factorization hashing with intra- and inter-modality fusion for image-text retrieval},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards user-specific multimodal recommendation via cross-modal attention-enhanced graph convolution network. <em>APIN</em>, <em>55</em>(1), 1-13. (<a href='https://doi.org/10.1007/s10489-024-06061-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Recommendation (MR) exploits multimodal features of items (e.g., visual or textual features) to provide personalized recommendations for users. Recently, scholars have integrated Graph Convolutional Networks (GCN) into MR to model complicated multimodal relationships, but still with two significant challenges: (1) Most MR methods fail to consider the correlations between different modalities, which significantly affects the modal alignment, resulting in poor performance on MR tasks. (2) Most MR methods leverage multimodal features to enhance item representation learning. However, the connection between multimodal features and user representations remains largely unexplored. To this end, we propose a novel yet effective Cross-modal Attention-enhanced graph convolution network for user-specific Multimodal Recommendation, named CAMR. Specifically, we design a cross-modal attention mechanism to mine the cross-modal correlations. In addition, we devise a modality-aware user feature learning method that uses rich item information to learn user feature representations. Experimental results on four real-world datasets demonstrate the superiority of CAMR compared with several state-of-the-art methods. The codes of this work are available at https://github.com/ZZY-GraphMiningLab/CAMR},
  archive      = {J_APIN},
  author       = {Wang, Ruidong and Li, Chao and Zhao, Zhongying},
  doi          = {10.1007/s10489-024-06061-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Towards user-specific multimodal recommendation via cross-modal attention-enhanced graph convolution network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust self-training algorithm based on relative node graph. <em>APIN</em>, <em>55</em>(1), 1-20. (<a href='https://doi.org/10.1007/s10489-024-06062-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-training algorithm is a well-known framework of semi-supervised learning. How to select high-confidence samples is the key step for self-training algorithm. If high-confidence examples with incorrect labels are employed to train the classifier, the error will get worse during iterations. To improve the quality of high-confidence samples, a novel data editing technique termed Relative Node Graph Editing (RNGE) is put forward. Say concretely, mass estimation is used to calculate the density and peak of each sample to build a prototype tree to reveal the underlying spatial structure of the data. Then, we define the Relative Node Graph (RNG) for each sample. Finally, the mislabeled samples in the candidate high-confidence sample set are identified by hypothesis test based on RNG. Combined above, we propose a Robust Self-training Algorithm based on Relative Node Graph (STRNG), which uses RNGE to identify mislabeled samples and edit them. The experimental results show that the proposed algorithm can improve the performance of the self-training algorithm.},
  archive      = {J_APIN},
  author       = {Wang, Jikui and Duan, Huiyu and Zhang, Cuihong and Nie, Feiping},
  doi          = {10.1007/s10489-024-06062-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {A robust self-training algorithm based on relative node graph},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Highway spillage detection using an improved STPM anomaly detection network from a surveillance perspective. <em>APIN</em>, <em>55</em>(1), 1-22. (<a href='https://doi.org/10.1007/s10489-024-06066-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spillages may cause traffic congestion and incidents and seriously affect the efficiency of traffic operation. Due to the changeable shape and scale of a spill on a highway, the location of the spill is random, so the current background extraction and object detection methods cannot achieve good detection results for the spill. This paper proposes a highway spill detection method using an improved STPM anomaly detection network. The method is based on the STPM network and achieves detection through FFDNet image filtering, calculation of the global correlation features of the student and teacher networks, contour positioning of spillages in the feature map, and automatic collection of positive samples to train and update the model, achieving high-precision identification and positioning of the spillages. The experimental results of the custom-built top-view road surface spillage dataset and the MVTec anomaly detection dataset show that the method proposed in this paper can obtain an AOC-ROC value of 0.978 and a PRO score of 0.965 and can distinguish between spillages and reflective cones, avoiding the problem of false detection when spills are similar in appearance. Therefore, the proposed method has value in the research and engineering application of spill detection in special highway scenes.},
  archive      = {J_APIN},
  author       = {Liang, Haoxiang and Song, Huansheng and Zhang, Shaoyang and Bu, Yongfeng},
  doi          = {10.1007/s10489-024-06066-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Highway spillage detection using an improved STPM anomaly detection network from a surveillance perspective},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised anomaly detection and imputation in noisy time series data for enhancing load forecasting. <em>APIN</em>, <em>55</em>(1), 1-23. (<a href='https://doi.org/10.1007/s10489-024-05856-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient energy management relies heavily on accurate load forecasting, particularly in the face of increasing energy demands and the imperative for sustainable operations. However, the presence of anomalies in historical data poses a significant challenge to the effectiveness of forecasting models, potentially leading to suboptimal resource allocation and decision-making. This paper presents an innovative unsupervised feature bank based framework for anomaly detection in time series data affected by anomalies. Leveraging an RNN-based recurrent denoising autoencoder, identified anomalies are replaced with plausible patterns. We evaluate the effectiveness of our methodology through a comprehensive study, comparing the performance of different forecasting models before and after the anomaly detection and imputation processes. Our results demonstrate the versatility and effectiveness of our approach across various energy applications for smart grids and smart buildings, highlighting its potential for widespread adoption in energy management systems.},
  archive      = {J_APIN},
  author       = {Dissem, Maher and Amayri, Manar},
  doi          = {10.1007/s10489-024-05856-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Unsupervised anomaly detection and imputation in noisy time series data for enhancing load forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GILNet: Grouping interaction learning network for lightweight salient object detection. <em>APIN</em>, <em>55</em>(1), 1-22. (<a href='https://doi.org/10.1007/s10489-024-05860-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, salient object detection (SOD) has achieved significant progress with the rapid development of convolutional neural networks (CNNs). However, the enhancement of SOD accuracy often comes at the cost of increased network size and computational complexity, hindering the application of existing SOD methods to lightweight devices, particularly robot devices. To address this issue, we propose a lightweight grouping interaction learning network (GILNet) for efficient and effective multi-level feature learning and shared feature aggregation. Specifically, our novel grouping interaction learning module (GIL) enables efficient feature extraction, and based on this module, we construct a lightweight backbone network to extract multi-scale features. Furthermore, we introduce a shared feature aggregation (SFA) module to aggregate these features in a shared manner, and a progressive guidance prediction (PGP) module to gradually refine the saliency predictions. Extensive experiments on five popular benchmarks demonstrate that GILNet yields comparable accuracy with state-of-the-art methods. More importantly, GILNet operates at a GPU speed of 345 frames/s with only 1.21M parameters, representing a significant reduction in computational cost and model size. These results highlight the significance of our method in achieving a better trade-off between accuracy and efficiency.},
  archive      = {J_APIN},
  author       = {Wei, Yiru and Zhu, Zhiliang and Yu, Hai and Zhang, Wei},
  doi          = {10.1007/s10489-024-05860-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {GILNet: Grouping interaction learning network for lightweight salient object detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DTR4Rec: Direct transition relationship for sequential recommendation. <em>APIN</em>, <em>55</em>(1), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05875-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation aims at mining user interests through modeling sequential behaviors. Most existing sequential recommendation methods overlook the direct transition relationship among items, and only encode a user sequence as a whole, capturing the intention behind the sequence and predicting the next item with which the user might interact. However, in real-world scenarios, a small subset of items within a sequence may directly impact future interactions due to the direct transition relationship among items. To solve the above problem, in this paper, we propose a novel framework called Direct Transition Relationship for Recommendation (DTR4Rec). Specifically, we first construct a long-term direct transition matrix and a short-term co-occurrence matrix among items based on their occurrence patterns in the interaction data. The long-term direct transition matrix is constructed by counting the frequency of transitions from one item to another within a relatively long window. The short-term co-occurrence matrix is built by counting the frequency of co-occurrences of two items within a short window. We further utilize a learnable fusion approach to blend traditional sequence transition patterns with the direct transition relationship among items for predicting the next item. This integration is accomplished through a learnable fusion matrix. Additionally, in order to mitigate the data sparsity problem and enhance the generalization of the model, we propose a new paradigm for computing item similarity, which considers both collaborative filtering similarity and sequential similarity among items, then such similarity is utilized to substitute part of items in the sequence, thereby creating augmented data. We conduct extensive experiments on three real-world datasets, demonstrating that DTR4Rec outperforms state-of-the-art baselines for sequential recommendation.},
  archive      = {J_APIN},
  author       = {He, Ming and Zhang, Han and Zhang, Zihao and Liu, Chang},
  doi          = {10.1007/s10489-024-05875-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {DTR4Rec: Direct transition relationship for sequential recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detrended partial cross-correlation analysis-random matrix theory for denoising network construction. <em>APIN</em>, <em>55</em>(1), 1-21. (<a href='https://doi.org/10.1007/s10489-024-05975-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A denoised complex network framework employing a detrended partial cross-correlation analysis-based coefficient for achieving the intrinsic scale-dependent correlations between each pair of variables is developed to explore the interrelatedness of multiple nonstationary variables in the real-world. In doing this, we start with introducing the detrended partial cross-correlation coefficient into random matrix theory, and executing a denoising process through correlation matrix reconfiguration, which is followed by utilizing the denoised correlation matrix to construct a planar maximally filtered graph network. It allows us assess the interactions among complex objects more accurately. The effectiveness of our proposed method is validated through the numerical experiments simulating the eigenvalue distribution, and the results show that our method accurately locates the maximum eigenvalue at a specific scale, but existing methods fail to achieve. As a practical application, we also apply the proposed denoising network framework to investigate the co-movement behavior of PM $$_{2.5}$$ air pollution of North China and the linkage of commodity futures prices in China. The results show that the denoising process significantly enhances the information content of the network, revealing several interesting insights regarding network properties.},
  archive      = {J_APIN},
  author       = {Wang, Fang and Zhang, Zehui and Wang, Min and Ling, Guang},
  doi          = {10.1007/s10489-024-05975-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Detrended partial cross-correlation analysis-random matrix theory for denoising network construction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PVT-MA: Pyramid vision transformers with multi-attention fusion mechanism for polyp segmentation. <em>APIN</em>, <em>55</em>(1), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06041-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early diagnosis and prevention of colorectal cancer rely on colonoscopic polyp examination.Accurate automated polyp segmentation technology can assist clinicians in precisely identifying polyp regions, thereby conserving medical resources. Although deep learning-based image processing methods have shown immense potential in the field of automatic polyp segmentation, current automatic segmentation methods for colorectal polyps are still limited by factors such as the complex and variable intestinal environment and issues related to detection equipment like glare and motion blur. These limitations result in an inability to accurately distinguish polyps from surrounding mucosal tissue and effectively identify tiny polyps. To address these challenges, we designed a multi-attention-based model, PVT-MA. Specifically, we developed the Cascading Attention Fusion (CAF) Module to accurately identify and locate polyps, reducing false positives caused by environmental factors and glare. Additionally, we introduced the Series Channels Coordinate Attention (SCC) Module to maximize the capture of polyp edge information. Furthermore, we incorporated the Receptive Field Block (RFB) Module to enhance polyp features and filter image noise.We conducted quantitative and qualitative evaluations using six metrics across four challenging datasets. Our PVT-MA model achieved top performance on three datasets and ranked second on one. The model has only 26.39M parameters, a computational cost of 10.33 GFlops, and delivers inference at a high speed of 47.6 frames per second (FPS).},
  archive      = {J_APIN},
  author       = {Shang, Xiao and Wu, Siqi and Liu, Yuhao and Zhao, Zhenfeng and Wang, Shenwen},
  doi          = {10.1007/s10489-024-06041-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {PVT-MA: Pyramid vision transformers with multi-attention fusion mechanism for polyp segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning for automation usage prediction: Identifying critical factors in driver decision-making. <em>APIN</em>, <em>55</em>(1), 1-21. (<a href='https://doi.org/10.1007/s10489-024-06052-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inappropriate automation usage is a common cause of incidents in semi-autonomous vehicles. Predicting and understanding the factors influencing this usage is crucial for safety. This study aims to evaluate machine learning models in predicting automation usage from behavioral data; and analyze how workload, environment, performance, and risk influence automation usage for different conditions. An existing dataset from a driving simulator study with 16 participants across four automation conditions (Speed High, Speed Low, Full High, and Full Low) was used. Five machine learning models were trained, using different splitting techniques, to predict automation usage. The input to these models were features related to workload, environment, performance, and risk, pre-processed and optimized to reduce computational time. The best-performing model was used to analyze the impact of each factor on automation usage. Random Forest models consistently demonstrated the highest prediction power, with accuracy exceeding 79% for all conditions, providing a robust foundation for enhancing vehicle safety and optimizing human-automation collaboration. Additionally, factors influencing automation usage ranked: Workload>Environment>Performance>Risk., contrasting with literature on pre-drive intentions to use automation. This study offers insights into real-time prediction of automation usage in semi-autonomous vehicles and quantifies the importance of key factors across different automation conditions. The findings reveal variations in prediction accuracy and factor importance across conditions, providing valuable implications for adaptive automated driving system design. Additionally, the hierarchy of factors influencing automation usage reveals a contrast between real-time decisions and pre-drive intentions, emphasizing the need for adaptive systems in dynamic driving conditions.},
  archive      = {J_APIN},
  author       = {Bustamante Orellana, Carlos and Rodriguez Rodriguez, Lucero and Huang, Lixiao and Cooke, Nancy and Kang, Yun},
  doi          = {10.1007/s10489-024-06052-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Machine learning for automation usage prediction: Identifying critical factors in driver decision-making},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ZPDSN: Spatio-temporal meteorological forecasting with topological data analysis. <em>APIN</em>, <em>55</em>(1), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06053-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meteorological forecasting is of paramount importance for safeguarding human life, mitigating natural disasters, and promoting economic development. However, achieving precise forecasts poses significant challenges owing to the complexities associated with feature representation in observed meteorological data and the dynamic spatio-temporal dependencies therein. Graph Neural Networks (GNNs) have gained prominence in addressing spatio-temporal forecasting challenges, owing to their ability to model non-Euclidean data structures and capture spatio-temporal dependencies. However, existing GNN-based methods lead to obscure of spatio-temporal patterns between nodes due to the over-smoothing problem. Worse still, important high-order structural information is lost during GNN propagation. Topological Data Analysis (TDA), a synthesis of mathematical analysis and machine learning methodologies that can mine the higher-order features present in the data itself, offers a novel perspective for addressing cross-domain spatio-temporal meteorological forecasting tasks. To leverage above problems more effectively and empower GNN with time-aware ability, a new spatio-temporal meteorological forecasting model with topological data analysis is proposed, called Zigzag Persistence with subgraph Decomposition and Supra-graph construction Network (ZPDSN), which can dynamically simulate meteorological data across the spatio-temporal domain. The adjacency matrix for the final spatial dimension is derived by treating the topological features captured via zigzag persistence as a high-order representation of the data, and by introducing subgraph decomposition and supra-graph construction mechanisms to better capture spatial-temporal correlations. ZPDSN outperforms other GNN-based models on four meteorological datasets, namely, temperature, cloud cover, humidity and surface wind component.},
  archive      = {J_APIN},
  author       = {Ma, Tinghuai and Su, Yuming and Abdel Wahab, Mohamed Magdy and Khalil, Alaa Abd ELraouf},
  doi          = {10.1007/s10489-024-06053-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {ZPDSN: Spatio-temporal meteorological forecasting with topological data analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ST-NAMN: A spatial-temporal nonlinear auto-regressive multichannel neural network for traffic prediction. <em>APIN</em>, <em>55</em>(1), 1-22. (<a href='https://doi.org/10.1007/s10489-024-06055-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient traffic information prediction is significantly important for the management of intelligent transportation systems. The traffic status (e.g., speed or flow) on one road segment is spatially affected by both its nearby neighbors and distant locations. The impending traffic status can be temporally influenced not only by its recent status but also by the randomness of its historical status change. The current state-of-the-art methods have effectively captured the spatio-temporal dependencies of road networks. However, most existing methods overlook the impact of time delay when capturing dynamic time dependencies. In addition, aggregating roads with similar traffic patterns from a wide range of spatial associations still poses challenges. In this paper, a spatial-temporal nonlinear auto-regressive multi-channel neural network (ST-NAMN) model is proposed to reveal the sophisticated nonlinear dynamic interconnections between temporal and spatial dependencies in road traffic data. Considering the temporal periodicity and spatial pattern similarity inherently in road traffic data, a divided period latent similarity correlation matrix (DLSC) first is utilized to calculate the similarity of traffic patterns from historical observation data. Then, we introduce an output feedback to the multi-layer perceptron (MLP) through a delay unit, which enables the output-layer to feedback its result data to the input layer in real-time, and further participate in the next iterative training to boost the learning capacity. Furthermore, an Enhanced-Bayesian Regularization weight updating method (EBR) is designed to better contemplate the influence of the continuous and delayed observation points compared to existing optimizers during the learning procedure. Experimental tests have been carried out on four real-world datasets and the results demonstrated that the proposed ST-NAMN method outperforms other state-of-the-art models.},
  archive      = {J_APIN},
  author       = {Zuo, Jiankai and Zhang, Yaying},
  doi          = {10.1007/s10489-024-06055-z},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {ST-NAMN: A spatial-temporal nonlinear auto-regressive multichannel neural network for traffic prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-relational neighbors constructed graph neural network for heterophily graph learning. <em>APIN</em>, <em>55</em>(1), 1-18. (<a href='https://doi.org/10.1007/s10489-024-06056-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have shown great power in exploring graph representation. However, most current GNNs are based on the homophily assumption and they have two primary weaknesses when applied to heterophily graphs: difficult to capture long-range dependence and unable to distinguish spatial relationships of neighbors. In an attempt to address these issues, we propose a multi-relational neighbors constructed graph neural network (MRN-GNN). Our core components, neighbor reconstruction and the bi-level attention aggregation mechanism, provide an effective way to enhance the ability to express heterophily graphs. Specifically, for neighbor reconstruction, we establish connections between node pairs with highly similar features, making it possible to capture long-range dependences. Meanwhile, we construct multi-relational neighbors for each node to distinguish different spatial structure of neighbors. Based on the reconstructed graph, a bi-level aggregation scheme is proposed to enable hierarchical aggregation, facilitating better feature transmission among multi-relational nodes. During this process, an attention mechanism is built to dynamically assign weights to each neighbor under different relations, further strengthening the representation capability. In this work, we focus on the node classification task on heterophily graphs. We conduct comprehensive experiments on seven datasets, including both heterophily and homophily datasets. Compared with representative methods, our MRN-GNN demonstrates significant superiority on heterophily graphs, while also achieving competitive results on homophily graphs.},
  archive      = {J_APIN},
  author       = {Xu, Huan and Gao, Yan and Liu, Quanle and Bie, Mei and Che, Xiangjiu},
  doi          = {10.1007/s10489-024-06056-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {A multi-relational neighbors constructed graph neural network for heterophily graph learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive knowledge graph for multi-label image classification. <em>APIN</em>, <em>55</em>(1), 1-17. (<a href='https://doi.org/10.1007/s10489-024-05845-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-label image classification tasks, recent studies often exploit Graph Convolutional Networks(GCNs) to construct category label dependencies. However, existing GCN-based methods have two major drawbacks. First, the co-occurrence relationships contained in the GCN adjacency matrix constructed only from the dataset label statistics are not comprehensive enough, and a fixed adjacency matrix may reduce the generalization of the model. Second, GCN may suffer from over-smoothing during node updates. To solve these problems, we propose a Multi-Label classification model based on Adaptive Knowledge Graph (ML-AKG). ML-AKG consists of the following parts: (1) We adopt an adaptive adjacency matrix constructed based on the knowledge graph to obtain better category label dependencies. (2) To alleviate the over-smoothing and gradient vanishing problems of the GCN model, we add a residual connection structure between the input and output of the GCN layer. (3) A pre-trained multimodal model is introduced to replace the traditional CNN as the image encoder. We conducted extensive experiments on public multi-label image classification benchmarks, and the experimental results verified the effectiveness of our method. Our model achieves 80.1%, 94.1% and 94.6% mAPs on the MS-COCO, VOC 2007 and VOC 2012, respectively.},
  archive      = {J_APIN},
  author       = {Lin, Zhihong and Tang, Xue-song and Hao, Kuangrong and Zhao, Mingbo and Li, Yubing},
  doi          = {10.1007/s10489-024-05845-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive knowledge graph for multi-label image classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-in-graph discriminative feature enhancement network for fine-grained visual classification. <em>APIN</em>, <em>55</em>(1), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05846-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained visual classification (FGVC) seeks to identify sub-classes within the same meta-class. Prior efforts mainly mine the features of discriminative parts to enhance classification performance. However, we argue that most of these works ignore the spatial details inside each part and the spatial correlations between parts when extracting local features and fusing global features, inhibiting the further improvement of feature quality, especially for the irregular discriminative parts. To alleviate this issue, we rethink the feature generation route from pixels to parts and to objects, and propose a novel graph-in-graph discriminative feature enhancement network (G $$^{2}$$ DFE-Net). Specifically, the G $$^{2}$$ DFE-Net consists of two nested graph convolutional networks, where an internal graph is first developed based on the spatial attention strategy to highlight details of the irregular discriminative regions. Then, a KNN-based external graph is introduced to capture the spatial context correlation among independent discriminative parts. With the collaboration of internal and external graph, G $$^{2}$$ DFE-Net boosts the class separability and compactness of global feature representation, thereby benefiting the accurate FGVC. We conduct thorough experiments on five benchmark datasets, and both quantitative and qualitative results confirm the superior accuracy of our G $$^{2}$$ DFE-Net compared to previous state-of-the-art algorithms. The code is available at https://github.com/WangYuPeng1/G2DFE-Net.},
  archive      = {J_APIN},
  author       = {Wang, Yupeng and Xu, Can and Wang, Yongli and Wang, Xiaoli and Ding, Weiping},
  doi          = {10.1007/s10489-024-05846-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Graph-in-graph discriminative feature enhancement network for fine-grained visual classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiview diffusion-based affinity graph learning with good neighbourhoods for salient object detection. <em>APIN</em>, <em>55</em>(1), 1-20. (<a href='https://doi.org/10.1007/s10489-024-05847-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object detection is a challenging task in computer vision and has been used to extract valuable information from many real scenarios. The graph-based detection approach has attracted extensive attention because of its high efficiency and stability. Nevertheless, most existing approaches utilize multiview features to construct graph models, resulting in poor performance in extreme scenes. In graph-based models, the graph structure and neighbourhoods play essential roles in salient object detection performance. In this paper, we propose a novel saliency detection approach via multiview diffusion-based affinity learning with good neighbourhoods. The proposed model includes three components: 1) multiview diffusion-based affinity learning to produce a local/global affinity matrix, 2) subspace clustering to choose good neighbourhoods, and 3) an unsupervised graph-based diffusion model to guide saliency detection. The uniqueness of our affinity graph model lies in exploring multiview handcrafted features to identify different underlying salient objects in extreme scenes. Extensive experiments on several standard databases validate the superior performance of the proposed model over other state-of-the-art methods. The experimental results demonstrate that our graph model with multiview handcrafted features is competitive with the outstanding graph models with multiview deep features.},
  archive      = {J_APIN},
  author       = {Wang, Fan and Wang, Mingxian and Peng, Guohua},
  doi          = {10.1007/s10489-024-05847-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Multiview diffusion-based affinity graph learning with good neighbourhoods for salient object detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-aware tensor factorization for temporal recommendation. <em>APIN</em>, <em>55</em>(1), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05851-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, temporal recommendation, which recommends items to users with considering temporal information has attracted widespread attention. How to capture and combine the time-varying user behavior distributions and the time-varying user behavior transition patterns is challenging. To address these challenges, we propose a Time-Aware Tensor Factorization for Temporal Recommendation (TATF4TRec). First, the personalized Markov transition tensors are applied to represent the users’ temporal behaviors. Then a tensor factorization method is proposed to capture the time-varying patterns of these tensors. Furthermore, the model linearly combines the time-varying patterns of user behavior and predicts the recommended results at a given time. Extensive experiments on five datasets demonstrate that TATF4TRec outperforms the state-of-the-art baselines significantly.},
  archive      = {J_APIN},
  author       = {Feng, Yali and Wen, Wen and Hao, Zhifeng and Cai, Ruichu},
  doi          = {10.1007/s10489-024-05851-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Time-aware tensor factorization for temporal recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ISFNN: An enhanced neural network for parametric modeling of passive devices with input skip-connections. <em>APIN</em>, <em>55</em>(1), 1-19. (<a href='https://doi.org/10.1007/s10489-024-05853-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-performance passive devices play a critical role in the radio frequency front-end of wireless systems. Accurately characterizing the electromagnetic (EM) responses of these devices poses a formidable challenge, particularly in high-frequency design. Commercial numerical methods often demand substantial computational resources and necessitate complete recalculation for any structural modifications. This paper proposes an input skip-connections feedforward neural network (ISFNN) for the parametric modeling of passive devices. The ISFNN architecture incorporates multiple skip connections within the layer blocks, which periodically integrate the input design variables into the intermediate hidden layers. This design facilitates feature combination and enhances the extraction capability of design variables. The intermediate layers contain both the original input features and the learned feature information from preceding layers, enabling the model to effectively and robustly capture the nonlinear relationships between the design variables and EM responses. Additionally, a systematic algorithm is proposed to develop and train the ISFNN model. The ISFNN offers a unified solution for both single-physics EM analysis and EM-centric multi-physics (MP) analysis. Compared to other ANN-based models, the ISFNN achieves smaller testing errors with fewer training samples for single-physics EM modeling. Furthermore, in certain applications, conducting MP analysis is more aligned with the actual operating conditions of high-performance microwave components. The nongeometrical parameters are incorporated into the input design features. The ISFNN accurately predicts EM responses using only MP training data, without requiring additional single-physics EM data, transfer functions, or multiple mapping modules. Validation examples demonstrate the better modeling accuracy and efficiency of the ISFNN. Within the design space, the trained ISFNN can generate new MP data in just 0.02 seconds per calculation, significantly reducing time costs while maintaining high modeling precision.},
  archive      = {J_APIN},
  author       = {Ren, Yimin and Deng, Xiaojiao and Zheng, Xiaoping},
  doi          = {10.1007/s10489-024-05853-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {ISFNN: An enhanced neural network for parametric modeling of passive devices with input skip-connections},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FAGCL: Frequency-based augmentation graph contrastive learning for recommendation. <em>APIN</em>, <em>55</em>(1), 1-17. (<a href='https://doi.org/10.1007/s10489-024-05857-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive Learning (CL) has recently achieved remarkable performance in recommendation systems, especially in Graph Collaborative Filtering (GCF), due to its effective handling of data sparsity issues by comparing positive and negative sample pairs. In CL-based GCF models, those sample pairs can be created by various data augmentation methods, which can be typically divided into two main aspects: graph-based and feature-based. However, those methods are either slow to train or ignore graph structure during data augmentation. To solve those issues, in this paper, we propose a frequency-based augmentation graph contrastive learning model named FAGCL, which takes graph structure into account without a slow training process. To be specific, FAGCL consists of three key steps. First, we propose a frequency-based data augmentation method to reconstruct the user-item interaction graph and get sample pairs for contrastive learning, which is fast to operate and can filter out some high-frequency graph signals that may lower model’s accuracy. Second, to improve efficiency, we propose an optimized GNNs forward propagation process for CL-based GCF models based on the first step. Third, to avoid extra forward/backward propagation processes, we adopt the one-encoder framework, which combines recommendation and contrastive learning tasks in the same pipeline instead of separating them. Extensive experiments on three benchmark datasets demonstrate that the proposed model FAGCL has the fastest speed of data augmentation and training, and outperforms other CL-based GCF models in accuracy in most cases.},
  archive      = {J_APIN},
  author       = {Xu, Jingyu and Yang, Bo and Li, Zimu and Liu, Wei and Qiao, Hao},
  doi          = {10.1007/s10489-024-05857-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {FAGCL: Frequency-based augmentation graph contrastive learning for recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CrossGFA: Wind power prediction with a multi-scale cross-graph network via a frequency-enhanced channel attention mechanism. <em>APIN</em>, <em>55</em>(1), 1-14. (<a href='https://doi.org/10.1007/s10489-024-05863-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind power generation data exhibits non-periodic and non-stationary characteristics coupled with significant noise levels, posing challenges for conventional forecasting models. Existing time series prediction techniques struggle to handle the instability, high sampling frequencies, and inherent noise present in wind power data. To address these issues, we propose a novel Multiscale Cross Interaction Graph Neural Network with a Frequency-Enhanced Channel Attention Mechanism (CrossGFA). The CrossGFA effectively captures wind power trends across multiple scales via cross-scale GNN modules while reducing noise. Simultaneously, the cross-variable GNN component leverages both homogeneity and heterogeneity among variables, enhancing the detection of potential associations between different wind power characteristics. Furthermore, the frequency-enhanced channel attention mechanism complements the GNN framework by mitigating frequency domain noise. Extensive evaluations on four real-world wind power station datasets demonstrate that CrossGFA outperforms state-of-the-art time series forecasting methods, validating its effectiveness in handling the complexities of wind power data.},
  archive      = {J_APIN},
  author       = {Zhang, Haoyu and Wang, Daoli and Jiang, Xuchu},
  doi          = {10.1007/s10489-024-05863-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {CrossGFA: Wind power prediction with a multi-scale cross-graph network via a frequency-enhanced channel attention mechanism},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An aspect-opinion joint extraction model for target-oriented opinion words extraction on global space. <em>APIN</em>, <em>55</em>(1), 1-21. (<a href='https://doi.org/10.1007/s10489-024-05865-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In aspect-based sentiment analysis, target-oriented opinion words extraction (TOWE) aims to extract opinion words based on aspect terms. Most current methods used in TOWE tasks only focus on explicit aspects and tend to overlook the implicit aspects, leading to a bias in the sample selection process and incomplete modeling of the TOWE tasks. Therefore, it is essential to consider both explicit and implicit aspects simultaneously in the modeling process of TOWE tasks. This paper proposes an aspect-opinion joint extraction (AOJE) model composed of an aspect term extraction unit (ATEU) and a target-oriented opinion words extraction unit (TOWEU). ATEU first is responsible for extracting aspect terms and converting them into prompt templates. TOWEU uses these templates to obtain opinion words for specific targets. This model is trained and evaluated on global space, including explicit and implicit aspects. This approach effectively addresses the issue of sample selection bias. The proposed AOJE method performs better than existing methods by an average of 4.06% on the Macro-F1 score on the SemEval 14-16 datasets. In particular, the AOJE model shows significant improvements compared to the IOG (Inward-Outward LSTM+Global context) model, with Macro-F1 scores increasing by 9.00%, 8.48%, 7.41%, and 9.21% on the Laptop 14, Restaurant 14, Restaurant 15, and Restaurant 16 datasets, respectively. These experimental results indicate that the AOJE model trained on global space significantly enhances the performance of TOWE and improves generalization capabilities.},
  archive      = {J_APIN},
  author       = {Huang, Jiaming and Li, Xianyong and Du, Yajun and Fan, Yongquan and Huang, Dong and Chen, Xiaoliang},
  doi          = {10.1007/s10489-024-05865-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {An aspect-opinion joint extraction model for target-oriented opinion words extraction on global space},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ETTrack: Enhanced temporal motion predictor for multi-object tracking. <em>APIN</em>, <em>55</em>(1), 1-17. (<a href='https://doi.org/10.1007/s10489-024-05866-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many Multi-Object Tracking (MOT) approaches exploit motion information to associate all the detected objects across frames. However, traditional tracking-by-detection (TBD) methods, relying on the Kalman Filter, often work well in linear motion scenarios but struggle to accurately predict the locations of objects undergoing complex and non-linear movements. To overcome these limitations, we propose ETTrack, a novel motion prediction method with an enhanced temporal motion predictor. Specifically, the motion predictor integrates a transformer model and a Temporal Convolutional Network (TCN) to capture both long-term and short-term motion patterns, and it predicts the future motion of individual objects based on the historical motion information. Additionally, we propose a novel Momentum Correction Loss function that provides additional information regarding the motion direction of objects during training. This allows the motion predictor to rapidly adapt to sudden motion variations and more accurately predict future motion. Our experimental results demonstrate that ETTrack achieves a competitive performance compared with state-of-the-art trackers on DanceTrack and SportsMOT, scoring 56.4 $$\%$$ and 74.4 $$\%$$ in HOTA metrics, respectively. Our work provides a robust solution for MOT in complex dynamic environments, which enhances the non-linear motion prediction capabilities of tracking algorithms.},
  archive      = {J_APIN},
  author       = {Han, Xudong and Oishi, Nobuyuki and Tian, Yueying and Ucurum, Elif and Young, Rupert and Chatwin, Chris and Birch, Philip},
  doi          = {10.1007/s10489-024-05866-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {ETTrack: Enhanced temporal motion predictor for multi-object tracking},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Windows deep transformer Q-networks: An extended variance reduction architecture for partially observable reinforcement learning. <em>APIN</em>, <em>55</em>(1), 1-19. (<a href='https://doi.org/10.1007/s10489-024-05867-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial Observability Markov Desicion Process (POMDP) is always worth studying in reinforcement learning (RL) due to its universality in the real world. Compared with Markov Decision Processes (MDP), agents in POMDP cannot fully receive information from the environment, which is an obstacle to traditional RL algorithms. One solution is to establishes a sequence-to-sequence model. As the core of deep Q-networks, Transformer has achieved certain outperformed results in dealing with partial observability problems. Nevertheless, deep Q-network has the issue of over-estimation of Q-value, which leads to unstable input data quality in Transformer. With the accumulation of deviation fast, model performance may decline drastically, resulting in severe errors that are fatal to policy learning. In this paper, we note that the previous Q-value overestimation mitigation model is not suitable for Deep Transformer Q-Networks (DTQN) framework, for DTQN is a sequence-to-sequence model, not merely a value optimization model in traditional RL. Therefore, we propose Windows DTQN, based on the reduction of Q-value variance via the synergistic effect of shallow and deep windows. In particular, Windows DTQN ensembles the historical Q-networks through the shallow windows, and estimates the uncertainty of the Q-networks through the deep windows for weight allocation. Our experiments conducted on gridverse environments demonstrate that our model achieves better results than the current mainstream DQN algorithms in POMDP. Compared to DTQN, Windows DTQN increases the average success rate by 5.1% and the average return by 1.11.},
  archive      = {J_APIN},
  author       = {Wang, Zijian and Wang, Bin and Dou, Hongbo and Liu, Zhongyuan},
  doi          = {10.1007/s10489-024-05867-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Windows deep transformer Q-networks: An extended variance reduction architecture for partially observable reinforcement learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent fault diagnosis of automobile main reducer based onstacked convolutional auto-encoder and parallel attention-based convolutional blocks. <em>APIN</em>, <em>55</em>(1), 1-20. (<a href='https://doi.org/10.1007/s10489-024-05868-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis is an important subfield of prognostic and health management (PHM). Intelligent fault diagnosis based on deep learning is the most popular data-driven method of the present. However, current researches are prone to ignoring the strong noisy backgroundin real working conditions and cannot achieve excellent performance in actual application. As we all know, noise reduction and feature extraction are two vital aspects in mechanicalfault diagnosis. In this article, an intelligent diagnostic model based onimproved stacked convolutional auto-encoder (ISCAE) and parallel attention-based convolutional blocks (PACB) is proposed. ISCAE-based module is constructed to reduce the noise of raw signals and then PACB-based module can synchronouslyextract local spatial feature and global feature automatically.To equalize the role of above-mentioned two modules which are serial in the proposed model, two modules are trained and optimized synchronously to simultaneously adjust the neural network weights. The capability and effectiveness of the model are evaluated using a dataset collected from real operating environment of main reducer. The comparative analysisresults show that the ISCAE-PACB-based model can reach the accuracy of 98.95% and is superior to existing models.},
  archive      = {J_APIN},
  author       = {Ye, Qing and Liu, Changhua},
  doi          = {10.1007/s10489-024-05868-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Intelligent fault diagnosis of automobile main reducer based onstacked convolutional auto-encoder and parallel attention-based convolutional blocks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Community detection in multiplex networks by deep structure-preserving non-negative matrix factorization. <em>APIN</em>, <em>55</em>(1), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05870-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiplex networks convey more valuable information than single-layer networks; thus, performing the community detection task involving these networks has become a subject of extensive research on the exploration of latent community structures. The non-negative matrix factorization (NMF) algorithm has proven successful in community detection scenarios by offering good interpretations of community structures. However, directly obtaining consensus community assignments using the traditional NMF algorithm poses a challenge due to the presence of complex structures spanning across different layers in the multiplex network. In this paper, we propose a novel algorithm called Deep Structure-Preserving Non-negative Matrix Factorization (DSP-NMF) to perform community detection in multiplex networks. Specifically, DSP-NMF constructs a deep autoencoder-like NMF model to generate meaningful network embeddings that are represented by multiple basis matrices and reconstructed by corresponding transposed basis matrices. By integrating the similarity relationships of nodes into the proposed DSP-NMF algorithm, the corresponding Laplacian matrices in each network layer are regularized to preserve the community structure during the learning process. Simultaneously, a consensus network embedding can be learned to obtain the final community partition. In this manner, the proposed DSP-NMF algorithm not only uncovers robust community structures in multiplex networks but also maintains the coherence between layers without losing complementary features. The experimental results obtained on five multiplex network datasets show that our proposed DSP-NMF algorithm outperforms other competitive methods in community detection tasks involving multiplex networks.},
  archive      = {J_APIN},
  author       = {Zhou, Qinli and Zhu, Wenjie and Chen, Hao and Peng, Bo},
  doi          = {10.1007/s10489-024-05870-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Community detection in multiplex networks by deep structure-preserving non-negative matrix factorization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-target opinion words extraction. <em>APIN</em>, <em>55</em>(1), 1-17. (<a href='https://doi.org/10.1007/s10489-024-05871-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Target-oriented Opinion Words Extraction (TOWE) emerges as a novel subtask of Aspect-Based Sentiment Analysis (ABSA), exerting profound impacts on numerous downstream tasks and real-world applications. Current research on target-oriented opinion words extraction focuses solely on extracting opinions for a single target. However, when handling multiple “target-opinion” pairs within a single data instance, inefficiency and time-consuming issues arise. Therefore, we propose an alternative solution to target-oriented opinion words extraction, termed Multi-Target Opinion Words Extraction (MTOWE). To achieve multi-target opinion words extraction, we conduct a statistical analysis and reconstruction of popular datasets(14lap, 14res, 15res, and 16res) in the target-oriented opinion words extraction task, denoted as M-14lap, M-14res, M-15res, and M-16res, respectively. We propose a Graph-based Collaborative Understanding Network for MTOWE. Experimental results demonstrate that the graph-based collaborative understanding network significantly outperforms the baseline models on the four datasets of the multi-target opinion words extraction task, achieving F1 scores of 74.04, 82.30, 74.92, and 83.49, respectively. More importantly, when processing the same batch of information, the inference time of MTOWE is significantly reduced. On the four datasets, the average inference time of MTOWE is only 70% of that of TOWE, while the F1 scores of MTOWE are only slightly lower than those of TOWE.},
  archive      = {J_APIN},
  author       = {Zhao, Zixue and Li, Shuaibo and Li, Zhengpeng and Li, Kejin and Wu, Jiansheng},
  doi          = {10.1007/s10489-024-05871-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Multi-target opinion words extraction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust unsupervised feature selection based on matrix factorization with adaptive loss via bi-stochastic graph regularization. <em>APIN</em>, <em>55</em>(1), 1-22. (<a href='https://doi.org/10.1007/s10489-024-05876-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature selection (UFS) has gained increasing attention and research interest in various domains, such as machine learning and data mining. Recently, numerous matrix factorization-based methods have been widely adopted for UFS. However, the following issues still exist. First, most methods based on matrix factorization use the squared Frobenius-norm to measure the loss term, making them sensitive to outliers. Although using $$ \varvec{l}_{\varvec{2,1}} $$ -norm-based loss improves the robustness, it is sensitive to small loss. Second, most existing matrix factorization-based methods utilize a fixed graph to preserve the local structure of data, making them fail to capture the intrinsic local structure accurately. To address the above drawbacks, we present a novel robust UFS model named matrix factorization with adaptive loss via bi-stochastic graph regularization (MFALBS). Specifically, MFALBS decomposes the projected data points into two orthogonal matrices to facilitate discriminative feature selection. Meanwhile, MFALBS utilizes an adaptive loss function for measuring the loss term in order to enhance model robustness. Moreover, MFALBS adopts an adaptive learning strategy for optimal bi-stochastic graph learning in order to improve local structure preservation ability. Finally, an optimization algorithm is proposed to solve the proposed model. Experimental results on real-world datasets show the effectiveness and superiority of MFALBS.},
  archive      = {J_APIN},
  author       = {Song, Xiangfa},
  doi          = {10.1007/s10489-024-05876-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Robust unsupervised feature selection based on matrix factorization with adaptive loss via bi-stochastic graph regularization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MVC-HGAT: Multi-view contrastive hypergraph attention network for session-based recommendation. <em>APIN</em>, <em>55</em>(1), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05877-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation (SBR) mainly analyzes user’s interaction sequences and recommends a list of items for the next potential interaction. The existing models of SBR mostly obtain different item features through dual-channel graph neural networks, but there are often many different views of high-order relationships hidden in the real session sequence. Especially, the sparsity of the interaction sequence affects the performance of the SBR model. To make the recommendation results more comprehensive and accurate, we propose a multi-view contrastive hypergraph attention network (MVC-HGAT) for session-based recommendation, which models the session sequence as multi-view hypergraphs from three different views: the context relationship of the interaction sequence, the click unit and the hidden similarity attribute of items. The multi-view feature information of items is captured by hypergraph attention network (HGAT) and fused by sum-pooling. Additionally, multi-view contrastive learning is employed to alleviate data sparsity in the hypergraph. To prevent fitting, label smoothing is introduced in the loss function. Extensive experiment results on selected real datasets, including Diginetica, Yoochoose and Retailrocket, demonstrate that our proposed MVC-HGAT has improved recommendation performance to some extent, and is better than the baselines for two metrics Prec@20 and MRR@20.},
  archive      = {J_APIN},
  author       = {Yang, Fan and Peng, Dunlu},
  doi          = {10.1007/s10489-024-05877-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {MVC-HGAT: Multi-view contrastive hypergraph attention network for session-based recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GraphSense: A self-aware dynamic graph learning networks for graph data over internet. <em>APIN</em>, <em>55</em>(1), 1-19. (<a href='https://doi.org/10.1007/s10489-024-05882-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic graph data learning is an important data analysis technique. In the age of big data, the volume of data produced daily is immense, the data types are varied, the value density is low, and the data continues to accumulate over time. These characteristics make data processing more challenging. In particular, unstructured data, unlike structured data, does not have a fixed format, and its volume is large and variable, which presents a significant challenge to traditional data processing techniques. Nowadays, researchers have been employing graph neural network models to analyze unstructured data. However, real-world graph structures are dynamic and time-varying, and the static graph neural network cannot effectively learn graph node embeddings and network structures. To address the challenges mentioned above, we propose a self-aware dynamic graph network structure learning model, called GraphSense. The algorithm consists of two modules: self-sensing neighborhood aggregation algorithm and dynamic graph structure learning algorithm based on RNN. GraphSense can make each node discover more valuable neighbors through the self-aware neighborhood aggregation algorithm in each epoch. The algorithm employs gated recurrent unit to dynamically aggregate the information of node neighbors to learn the high-order information. Next, in order to capture the temporal properties of graph structures, we employ dynamic graph structure learning algorithm based on RNN to replicate the time evolution process of dynamic graphs. Finally, we evaluate the performance of GraphSense on four publicly available datasets by two specific tasks(edge and node classification). The experimental results show that the proposed GraphSense model outperforms the baseline model by 2.0% to 25.0% on the Elliptic dataset, 2.5% to 27.0% on the Bitcoin-alpha dataset, 3.0% to 31.0% on the Bitcoin-otc dataset, and 0.9% to 26.0% on the Reddit dataset in terms of F1 scores. The results suggest that our model is effective in learning from dynamic graph data.},
  archive      = {J_APIN},
  author       = {Li, Zhi-Yuan and Zhou, Ying-Yi and He, En-Han},
  doi          = {10.1007/s10489-024-05882-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {GraphSense: A self-aware dynamic graph learning networks for graph data over internet},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Remaining useful-life prediction of lithium battery based on neural-network ensemble via conditional variational autoencoder. <em>APIN</em>, <em>55</em>(1), 1-15. (<a href='https://doi.org/10.1007/s10489-024-05885-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning using deep neural networks has become prevalent in predicting the Remaining Useful Life (RUL) of Lithium Batteries (LiBs). However, owing to the predominant linearity of ensemble learning, capturing nonlinear relationships among base learners remains a persistent challenge. This study presents an RUL-prediction method for LiBs based on a neural-network ensemble via a Conditional Variational Autoencoder (CVAE). The proposed method serves as a nonlinear ensemble learning method and promises enhanced prediction performance while maintaining ease of implementation. The methodology entails several key steps. First, data smoothing is conducted via local weighted linear regression. Subsequently, a preliminary linear-ensemble phase is executed through an attention mechanism, which filters out extraneous information in the features and bolsters the importance of valid features. Subsequently, a nonlinear ensemble is accomplished by utilizing the CVAE, with truth labels serving as conditions. Finally, the efficacy of the proposed method is substantiated through experimentation, demonstrating its superior performance compared to the candidate methods.},
  archive      = {J_APIN},
  author       = {Zhang, Hengshan and Guo, Kaijie and Chen, Yanping and Sun, Jiaze},
  doi          = {10.1007/s10489-024-05885-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Remaining useful-life prediction of lithium battery based on neural-network ensemble via conditional variational autoencoder},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal clustering for accurate short-term load forecasting using bayesian multiple linear regression. <em>APIN</em>, <em>55</em>(1), 1-24. (<a href='https://doi.org/10.1007/s10489-024-05887-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective short-term load forecasting (STLF) is essential for optimizing electricity grid operations. This study focuses on refining STLF for day-ahead predictions using Bayesian multiple linear regression (BMLR). This study’s originality lies in its innovative use of BMLR combined with data clustering techniques to improve prediction accuracy, a method not previously explored in existing literature. We address the critical issue of input data clustering, highlighting its impact on prediction accuracy. Four clustering methods based on temporality were examined, with clustering by weekday and hour proving most effective for BMLR-based STLF. Predictors included historical load, temperature, season, weekday, and hour, selected using the Akaike information criterion (AIC). Linear regression assumptions were verified, and solutions were proposed for deviations, notably addressing heteroscedasticity. Autocorrelation in residuals was addressed to improve forecasting efficiency. Time-cross validation and performance metrics demonstrated model effectiveness. Second-degree polynomial terms are included for better fitting. Clustering by weekday and hour is optimal for BMLR-based STLF, aiding accurate load forecasts. The main objectives of this research are to determine the optimal clustering method for BMLR in STLF and to provide practical insights into the application of Bayesian techniques in load forecasting. This research significantly contributes to the field of STLF by providing practical insights into data clustering and model refinement, offering valuable perspectives for enhanced energy management and grid stability.},
  archive      = {J_APIN},
  author       = {Urošević, Vladimir and M. Savić, Andrej},
  doi          = {10.1007/s10489-024-05887-z},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {Temporal clustering for accurate short-term load forecasting using bayesian multiple linear regression},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparison based analysis of window approach for concept drift detection and adaptation. <em>APIN</em>, <em>55</em>(1), 1-17. (<a href='https://doi.org/10.1007/s10489-024-05890-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the non-stationary data stream distribution, concept drift occurs due to change in patterns with respect to time. It is necessary to identify drift in the data stream during the early stage. One way to explore the change in patterns is windowing, where two windows compare to find the difference in data distribution. In the two-window-based methods, the concept drift may occur much before the incoming window. The current window will wait to compare with a new incoming window’s data distribution for drift detection. It may lead to delay in detection, increasing misclassification error, and decreasing classification accuracy. The paper proposes DD-SCC-I and DD-KRC-I, incrementally adaptive single-window-based drift detection methods, to overcome the above issue. These methods localize the concept change by finding the correlation between attribute vectors. The proposed work deals with multi-dimensional data, binary-class classification, and multi-class classification problems. An improved two-window-based concept drift detection methods, DD-SCC-II and DD-KRC-II, are built to find drift using the same correlation. Further, the comparison is made among proposed methods in terms of the number of drift detected and drift detection times to demonstrate the behavior of methods. These proposed methods compare with state-of-the-art methods using real-time and synthetic data sets. The evaluation result shows DD-SCC-I and DD-KRC-I detect early drift with an increase in average rank of 4.18 and 4.56, respectively.},
  archive      = {J_APIN},
  author       = {Agrahari, Supriya and Singh, Anil Kumar},
  doi          = {10.1007/s10489-024-05890-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Comparison based analysis of window approach for concept drift detection and adaptation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cross-granularity feature fusion method for fine-grained image recognition. <em>APIN</em>, <em>55</em>(1), 1-19. (<a href='https://doi.org/10.1007/s10489-024-05891-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained image recognition is characterized by high interclass object similarities and large intraclass object variations. Many existing works focus on locating more discriminative parts, but it is difficult to extract multigranular features synchronously and fuse them to make joint decisions about various granular parts. To address these issues, this work proposes a novel cross-granularity feature fusion method. First, a multi-granularity feature generator is used to obtain various granularity features simultaneously for mid-level feature maps via its subgenerators. The subgenerators divide the feature maps into blocks to ensure the relative integrity of the local features, and randomly shuffle the divided blocks to increase the variance of the local regions. Then, a cross-granularity feature fusion strategy achieves the joint decision-making of multiple granularity features in fine-grained images. Therefore, the proposed method can extract various granularity features and promote the synergistic interaction of richer granularity features. The effectiveness of the method is verified through comprehensive experiments on three widely-used fine-grained object recognition benchmark datasets and a chip inner structure dataset. The experimental results show that the proposed method significantly outperforms the baseline and exhibits a comparable performance to that of the SOTA method. Source codes are available at https://github.com/ShanWuJ/CGFF},
  archive      = {J_APIN},
  author       = {Wu, Shan and Hu, Jun and Sun, Chen and Zhong, Fujin and Zhang, Qinghua and Wang, Guoyin},
  doi          = {10.1007/s10489-024-05891-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {A cross-granularity feature fusion method for fine-grained image recognition},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dirichlet and liouville-based normality scores for deep anomaly detection using transformations: Applications to images and beyond images. <em>APIN</em>, <em>55</em>(1), 1-20. (<a href='https://doi.org/10.1007/s10489-024-05892-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of anomaly detection in data by learning a normality score function through the use of data transformations. Applying transformations to a dataset is essential for enhancing its representation and revealing underlying patterns. First, we propose geometric transformations for image data. The core idea of our approach is to train a multi-class deep classifier to distinguish between various geometric transformations. At test time, we construct the normality score function by approximating the softmax output predictions vector using generalized forms of Dirichlet distributions, including the generalized Dirichlet (GD), scaled Dirichlet (SD), shifted scaled Dirichlet (SSD), and Beta-Liouville (BL) distributions. These generalized forms of the Dirichlet distribution are more robust in real-world applications compared to the standard Dirichlet distribution. They offer a more flexible covariance structure, making them suitable for approximating both symmetric and asymmetric distributions. For parameter estimation, we use the maximum likelihood method based on the transformed forms of the original data. In the second step, we extend our approach to non-image data by selecting appropriate transformations. This transformation procedure involves building several neural networks, training them on the original data to obtain its transformed form, and then passing the transformed data through an auto-encoder. Experiments conducted on both image and non-image data demonstrate the effectiveness of our proposed strategy. The results show that our anomaly detection models, based on generalized Dirichlet distributions, outperform baseline techniques and achieve high Area Under the Receiver Operating Characteristic (AUROC) scores.},
  archive      = {J_APIN},
  author       = {Sghaier, Oussama and Amayri, Manar and Bouguila, Nizar},
  doi          = {10.1007/s10489-024-05892-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Dirichlet and liouville-based normality scores for deep anomaly detection using transformations: Applications to images and beyond images},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-granularity representation learning for sketch-based dynamic face image retrieval. <em>APIN</em>, <em>55</em>(1), 1-11. (<a href='https://doi.org/10.1007/s10489-024-05893-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In some specific scenarios, a face sketch can be used to identify a person. However, drawing a face sketch often requires excellent skills and is time-consuming, which seriously hinders its widespread in the actual scenarios. The new framework of sketch less face image retrieval (SLFIR) (Dai et al. 2023) explores to provide some form of interaction between humans and machines during the drawing process to break the above barriers. Considering SLFIR framework, there is big gap between the partial sketch with few strokes and any one whole face photo, resulting in poor performance at the early stage. In this study, we proposed a multi-granularity (MG) representation learning (MGRL) to address the SLFIR problem, in which we learn the representation for the different granularity regions for the partial sketch and its target image. Specifically, (1) a classical triplet network was first adopted to learn the joint embedding space shared between the complete sketch and its target face photo; (2) Then, we divided the partial sketch in the sketch drawing episode into MG regions; Another learnable branch in the triplet network was designed to optimize the representation of the multi-granularity regions; Finally, by combining all the MG regions of the sketches and photos, the final distance was determined. In the experiments, our method outperformed state-of-the-art baseline methods in terms of early retrieval performance on two publicly accessible datasets. Codes are available at https://github.com/ddw2AIGROUP2CQUPT/MGRL},
  archive      = {J_APIN},
  author       = {Wang, Liang and Dai, Dawei and Fu, Shiyu},
  doi          = {10.1007/s10489-024-05893-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Appl. Intell.},
  title        = {Multi-granularity representation learning for sketch-based dynamic face image retrieval},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cross-database micro-expression recognition framework based on meta-learning. <em>APIN</em>, <em>55</em>(1), 1-19. (<a href='https://doi.org/10.1007/s10489-024-05896-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro-expressions are facial expressions that are revealed unconsciously when suppressing true emotions and are widely used in multiple tasks, such as deception detection. However, at present, the amount of available micro-expression data is small, and there are large differences between different databases, so it is still difficult to accurately perform cross-database micro-expression recognition, which hinders real applications of recognition. To address this issue, this article first presents a meta-learning framework suitable for cross-database micro-expression recognition named Meta-CDMERF, which is trained by combining multiple micro-expression databases. Then, a residual feature-wise linear (RFL) module is proposed to generate more feature distributions and adaptively choose representative features during multi micro-expression database training, thereby reducing the feature distance between samples of the same type in different databases. Next, a new loss function is designed, which combines the cross-entropy loss function with an interclass loss function. Specifically, the inter-class loss is based on the mean value of similar features from the support set and aims to increase the distance between samples of different categories, thereby capturing subtle changes in micro-expression images. Finally, the unweighted average recall (UAR) and unweighted F1 score (UF1) values of the proposed method on the CASME II database are 62.64% and 60.00%, respectively, reaching state-of-the-art performance.},
  archive      = {J_APIN},
  author       = {Wang, Hanpu and Zhou, Ju and Liu, Xinyu and Jia, Yingjuan and Chen, Tong},
  doi          = {10.1007/s10489-024-05896-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {A cross-database micro-expression recognition framework based on meta-learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast tensor robust principal component analysis with estimated multi-rank and riemannian optimization. <em>APIN</em>, <em>55</em>(1), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05899-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the fact that tensor robust principal component analysis (TRPCA) and its variants do not utilize the actual rank value, which limits the recovery performance, and their computational costs are always monumental for large-scale tensor recovery, a fast TRPCA is proposed to recover the low-rank tensor and sparse tensor by estimating the multi-rank vector and adopting Riemannian optimization strategy in this paper. Specifically, a fast multi-rank estimation of low-rank tensor is proposed by modifying the Gershgorin disk theorem-based matrix rank estimation. An innovative TRPCA with Estimated Multi-Rank (TRPCA-EMR) is proposed to eliminate hyperparameter tuning by imposing strict multi-rank equality constraints. Additionally, Riemannian optimization is employed to project each frontal slice of the tensor in Fourier domain onto a low multi-rank manifold in efficiently coping with tensor Singular Value Decomposition (t-SVD) and reduce computational complexity. Experimental results on synthetic and real-world tensor datasets demonstrate TRPCA-EMR’s superior efficiency and effectiveness compared to existing methods, confirming its potential for practical applications and reassuring its reliability.},
  archive      = {J_APIN},
  author       = {Zhu, Qile and Wu, Shiqian and Fang, Shun and Wu, Qi and Xie, Shoulie and Agaian, Sos},
  doi          = {10.1007/s10489-024-05899-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Fast tensor robust principal component analysis with estimated multi-rank and riemannian optimization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ChatGPT vs state-of-the-art models: A benchmarking study in keyphrase generation task. <em>APIN</em>, <em>55</em>(1), 1-25. (<a href='https://doi.org/10.1007/s10489-024-05901-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based language models, including ChatGPT, have demonstrated exceptional performance in various natural language generation tasks. However, there has been limited research evaluating ChatGPT’s keyphrase generation ability, which involves identifying informative phrases that accurately reflect a document’s content. This study seeks to address this gap by comparing ChatGPT’s keyphrase generation performance with state-of-the-art models, while also testing its potential as a solution for two significant challenges in the field: domain adaptation and keyphrase generation from long documents. We conducted experiments on eight publicly available datasets spanning scientific, news, and biomedical domains, analyzing performance across both short and long documents. Our results show that ChatGPT outperforms current state-of-the-art models in all tested datasets and environments, generating high-quality keyphrases that adapt well to diverse domains and document lengths.},
  archive      = {J_APIN},
  author       = {Martínez-Cruz, Roberto and López-López, Alvaro J. and Portela, José},
  doi          = {10.1007/s10489-024-05901-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {ChatGPT vs state-of-the-art models: A benchmarking study in keyphrase generation task},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical kernelized movement primitives for learning human-robot collaborative trajectories in referred object handover. <em>APIN</em>, <em>55</em>(1), 1-15. (<a href='https://doi.org/10.1007/s10489-024-05902-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While research in Learning-by-Demonstration (LbD) methods has made significant progress, learning human-robot collaborative trajectories has been a challenging task. In this paper, a hierarchical kernelized movement primitives (KMPs) model is proposed for learning human-robot handover trajectories. The model learns the non-linear correlations between human hand positions and robotic end-effector positions within a baseline subregion and generalizes them to other subregions. Therefore, the proposed hierarchical KMPs achieve one-shot cross-subregion trajectory skill transfer, which is the major advantage over the classic KMPs. The benefit of such an improvement is the generalization capability of the robot’s reactive trajectory in the whole workspace while avoiding collecting a large number of trajectory samples. In addition, we also present a trajectory scaling and modulation method to ensure the adaptation and generalization of joint trajectory scales. This enables the adaptation of the robot’s movement toward trajectory scales. Experiments of human-robot handover in a robot-assistive assembly scenario demonstrate the performance gains over the classic KMPs in trajectory prediction accuracy. In addition, the results also validate that the proposed method is capable of one-shot transfer across subregions and adaptation to the trajectory scale variance.},
  archive      = {J_APIN},
  author       = {Qian, Kun and Yue, Zhaokun and Bai, Jishen},
  doi          = {10.1007/s10489-024-05902-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Hierarchical kernelized movement primitives for learning human-robot collaborative trajectories in referred object handover},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Entity-relation aggregation mechanism graph neural network for knowledge graph embedding. <em>APIN</em>, <em>55</em>(1), 1-14. (<a href='https://doi.org/10.1007/s10489-024-05907-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) are inherently suited for modeling graph-structured data and have been extensively utilized in Knowledge Graph Embedding (KGE). Current GNN-based KGE models primarily focus on message aggregation among entities, often neglecting the aggregation of messages related to relations. Additionally, the interaction information between entities and relations, as well as their distinctions, is overlooked during the updating of relations. To address these issues, we propose the Entity-Relation Aggregation Mechanism Graph Neural Network (ERAGNN), where relations are also considered as nodes in the graph for message aggregation. The ERAGNN layer comprises an entity aggregation sublayer and a relation aggregation sublayer. The entity aggregation sublayer employs an entity-relation composition operation to aggregate messages across entity nodes, while the relation aggregation sublayer utilizes an entity-entity composition operation. Furthermore, shared-weight matrices are implemented to enhance interactions between entities and relations. Lastly, an attention mechanism is incorporated to differentiate neighboring messages during the update of relation embeddings. Experimental results demonstrate that ERAGNN achieves state-of-the-art link prediction performance on three benchmark datasets: FB15k-237, WN18RR, and WN18.},
  archive      = {J_APIN},
  author       = {Xu, Guoshun and Rao, Guozheng and Zhang, Li and Cong, Qing},
  doi          = {10.1007/s10489-024-05907-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Entity-relation aggregation mechanism graph neural network for knowledge graph embedding},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A spatial interpolation based on neighbor cluster adaptive model with spatial color block clustering algorithm. <em>APIN</em>, <em>55</em>(1), 1-22. (<a href='https://doi.org/10.1007/s10489-024-05913-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate soil nutrient data are crucial for precise fertilizer recommendations in intelligent agriculture. However, the process of soil testing, which includes collecting samples, determining available nutrients and interpreting results, is expensive. To address this challenge, spatial interpolation methods are commonly used to predict soil fertility. Yet, existing techniques like IDW (Inverse Distance Weighting) and OK (Ordinary Kriging) face limitations, making it difficult to achieve highly accurate estimates. Therefore, this paper introduces NCAMS (Neighbor Cluster Adaptive Model with Spatial Color Block), a novel interpolation approach that automatically identifies nearby points crucial for estimating soil nutrient values at a given location. In our approach, we not only consider spatial correlation but also incorporate the soil variables of sampled points. Delaunay triangulation and hash functions further divide data points into distinct clusters, with our model automatically selecting specific clusters. Moreover, our interpolation method integrates IDW and OK without requiring extensive training on real-world data. Extensive experiments on four real-world datasets, conducted through cross-validation, demonstrate the superior performance of our approach compared to eight state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Zhu, Liang and Chen, Feng and Song, Xin},
  doi          = {10.1007/s10489-024-05913-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {A spatial interpolation based on neighbor cluster adaptive model with spatial color block clustering algorithm},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ISWP: Novel high-fidelity adversarial examples generated by incorporating invisible and secure watermark perturbations. <em>APIN</em>, <em>55</em>(1), 1-18. (<a href='https://doi.org/10.1007/s10489-024-05917-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Invisible watermarking is widely used for tracking and holding accountable unauthorized usage of copyrighted content, but it does not prevent attackers from obtaining illegal access to digital assets. Consequently, user privacy and security are significantly compromised. Recent investigations have revealed that adversarial attacks are capable of misleading state-of-the-art deep learning models by inducing incorrect classifications. The generated adversarial examples can dramatically mitigate malicious access to protected content. To integrate invisible watermarking with adversarial attacks in a unified task, we explore the potential of creating meaningful perturbations in adversarial examples that combine adversarial attacks with secure watermark perturbations. A novel method called ISWP (invisible and secure watermark perturbations) for embedding meaningful perturbations into input images is proposed in this paper to accomplish both adversarial attacks and copyright protection. ISWP employs the discrete wavelet transform (DWT) and basin hopping (BH) in its adversarial attack process, resulting in the creation of imperceptible adversarial watermark perturbations. Furthermore, encryption technologies are incorporated into the adversarial attack process to safeguard against unauthorized malicious access. The experimental results show that the generated adversarial examples exhibit benign visual performance while achieving remarkable attack capacity and robustness on different DNN models, and the embedded watermarks are extracted as powerful tools for copyright certification, which demonstrates their effectiveness as a protection mechanism for private content.},
  archive      = {J_APIN},
  author       = {Liang, Jinchao and Liu, Yang and Gao, Lu and Zhang, Ze and Liu, Xiaolong},
  doi          = {10.1007/s10489-024-05917-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {ISWP: Novel high-fidelity adversarial examples generated by incorporating invisible and secure watermark perturbations},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel discrete initial-boosted tabu learning neuron: Dynamical analysis, DSP implementation, and batch medical image encryption. <em>APIN</em>, <em>55</em>(1), 1-18. (<a href='https://doi.org/10.1007/s10489-024-05918-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new discrete initial-boosted Tabu learning single neuron (DITLSN) is constructed using a new activation function to combine the Tabu learning neuron model in this paper. The complex and abundant dynamical behavior of the DITLSN is analyzed using bifurcation diagrams (BD) and Lyapunov exponential spectra(LEs), such as period, chaos, hyper-chaos, and attractor coexistence. In particular, the coexistence of initial-boosted hyperchaotic attractors found in numerical simulations of the DITLSN suggests that different initial states produce multiple highly complex attractors whose positions can change. The existence of attractor coexistence phenomenon makes chaotic parameters more difficult to be attacked by existing parameter identification algorithms, while its own high sensitivity to the initial state is more suitable for application scenarios such as secure communication. The results of the circuit implementation in the DSP platform are also in excellent agreement with the software simulation results. Finally, a batch medical image encryption scheme (BEIES) suitable for large-scale medical image encryption is designed. The performance analysis demonstrates that the designed scheme excels in the aspects of key performance, anti-statistical attack, anti-differential attack, robustness, etc., and most importantly, it has very high encryption and decryption efficiency, which is suitable for the application scenario of large-scale medical image batch processing.},
  archive      = {J_APIN},
  author       = {Zhang, Zheyi and Cao, Yinghong and Zhou, Nanrun and Xu, Xianying and Mou, Jun},
  doi          = {10.1007/s10489-024-05918-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Novel discrete initial-boosted tabu learning neuron: Dynamical analysis, DSP implementation, and batch medical image encryption},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One image for one strategy: Human grasping with deep reinforcement based on small-sample representative data. <em>APIN</em>, <em>55</em>(1), 1-14. (<a href='https://doi.org/10.1007/s10489-024-05919-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the first step in grasping operations, vision-guided grasping actions play a crucial role in enabling intelligent robots to perform complex interactive tasks. In order to solve the difficulties in data set preparation and consumption of computing resources before and during training network, we introduce a method of training human grasping strategies based on small sample representative data sets, and learn a human grasping strategy through only one depth image. Our key idea is to use the entire human grasping area instead of multiple grasping gestures so that we can greatly reduce the preparation of dataset. Then the grasping strategy is trained through the q-learning framework, the agent is allowed to continuously explore the environment so that it can overcome lack of data annotation and prediction in early stage of the visual network, then successfully map the human strategy into visual prediction. Considering the widespread clutter environment in real tasks, we introduce push actions and adopt a staged reward function to make it conducive to the grasping. Finally we learned the human grasping strategy and applied it successfully, and stably executed it on objects that not seen before, improved the convergence speed and grasping effect while reducing the consumption of computing resources. We conducted experiments on a Doosan robotic arm equipped with an Intel Realsense camera and a two-finger gripper, and achieved human strategy grasping with a high success rate in cluttered scenes.},
  archive      = {J_APIN},
  author       = {Wang, Fei and Shi, Manyi and Chen, Chao and Zhu, Jinbiao and Liu, Yue and Chu, Hao},
  doi          = {10.1007/s10489-024-05919-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {One image for one strategy: Human grasping with deep reinforcement based on small-sample representative data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep neural network-based feature selection with local false discovery rate estimation. <em>APIN</em>, <em>55</em>(1), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05944-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection, aiming at identifying the most significant subset of features from the original data, plays a prominent role in high-dimensional data processing. To a certain extent, feature selection can mitigate the issue of poor interpretability of deep neural networks (DNNs). Despite recent advancements in DNN-based feature selection, most methods overlook the error control of selected features and lack reproducibility. In this paper, we propose a new method called DeepTD to perform error-controlled feature selection for DNNs, in which artificial decoy features are constructed and subjected to competition with the original features according to the feature importance scores computed from the trained network, enabling p-value-free local false discovery rate (FDR) estimation of selected features. The merits of DeepTD include: a new DNN-derived measure of feature importance combining the weights and gradients of the network; the first algorithm that estimates the local FDR based on DNN-derived scores; confidence assessment of individual selected features; better robustness to small numbers of important features and low FDR thresholds than competition-based FDR control methods, e.g., the knockoff filter. On multiple synthetic datasets, DeepTD accurately estimated the local FDR and empirically controlled the FDR with 10 $$\%$$ higher power on average than knockoff filter. At lower FDR thresholds, the power of our method has even reached two to three times that of other state-of-the-art methods. DeepTD was also applied to real datasets and selected 31 $$\%$$ -49 $$\%$$ more features than alternatives, demonstrating its validity and utility.},
  archive      = {J_APIN},
  author       = {Cao, Zixuan and Sun, Xiaoya and Fu, Yan},
  doi          = {10.1007/s10489-024-05944-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Deep neural network-based feature selection with local false discovery rate estimation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale GraphSAGE with class center balancing loss for rolling bearing fault diagnosis under extremely class imbalance. <em>APIN</em>, <em>55</em>(1), 1-18. (<a href='https://doi.org/10.1007/s10489-024-05960-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The imbalance between normal and fault data in the condition monitoring of rotating machinery often leads to models needing more focus on the information from the majority class. To this end, this work proposed a rolling bearing fault diagnosis method based on class center balancing loss (CCBL) and multi-scale GraphSAGE (MSGraphSAGE) to handle extreme class imbalance. First, a node-level pathgraph using frequency-domain signals enhances the model’s learning and generalization capabilities by associating signal features. Next, a multi-scale feature extractor is designed, employing DropEdge-based MSGraphSAGE in the first layer to improve the model’s feature extraction performance. Finally, a CCBL function is developed to reweight the class weights, reducing the weight loss assigned to the majority class to balance the class weights. Six imbalanced cases were designed on two bearing datasets, and the experimental results demonstrate the advantages of this method in highly imbalanced fault diagnosis tasks, validating the effectiveness and superiority of the proposed GNN model and class center balancing loss.},
  archive      = {J_APIN},
  author       = {Zhou, Jianyu and Zhang, Xiangfeng and Jiang, Hong},
  doi          = {10.1007/s10489-024-05960-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Multi-scale GraphSAGE with class center balancing loss for rolling bearing fault diagnosis under extremely class imbalance},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensemble microbial classification based on space partitioning and data augmentation. <em>APIN</em>, <em>55</em>(1), 1-29. (<a href='https://doi.org/10.1007/s10489-024-05961-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disease diagnosis tasks using microbial data are often hindered by extreme class imbalance issues, which are further manifested as inter-class and intra-class imbalances. The former can be handled by general methods such as the SMOTE, while the latter has not been well studied. In this paper, we propose an ensemble classification algorithm based on space partitioning and data augmentation (ECSD) to address both types of imbalances. First, the data are mapped into a low-dimensional space through KPCA, LMNN, and RENN. These techniques address the data sparsity and noise in the original dataset. Second, we design a Kannoy technique to increase the distance between data points in different subspaces. In this way, the data distribution is more uniform, thus alleviating the intra-class imbalance problem. Third, a WGAN trained on the whole dataset is used to augment the data in each subspace. Different data augmentation and filtering strategies are employed to alleviate inter-class imbalance issues. Finally, base classifiers trained on each subspace are ensembled using a distance-weighted technique. The ensembler aims to provide stable predictions. Our algorithm is compared with four algorithms for handling class imbalance and three algorithms that address microbial-based diagnosis on 17 datasets. The results show that our algorithm outperforms its counterparts in terms of multiple metrics, especially when the dataset imbalance ratio is high.},
  archive      = {J_APIN},
  author       = {Wen, Liu-Ying and Chen, Zhu and Min, Fan},
  doi          = {10.1007/s10489-024-05961-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Appl. Intell.},
  title        = {Ensemble microbial classification based on space partitioning and data augmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning for dynamic strategy interchange in financial markets. <em>APIN</em>, <em>55</em>(1), 1-19. (<a href='https://doi.org/10.1007/s10489-024-05965-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial markets present a complex and dynamic environment, making them an ideal testing ground for artificial intelligence (AI) and machine learning techniques. The integration of quantitative strategies with AI methods, particularly deep reinforcement learning (DRL), has shown promise in enhancing trading performance. Traditional quantitative strategies often rely on backtesting with historical data to validate their effectiveness. However, the inherent volatility and unpredictability of financial markets make it challenging for a single strategy to consistently outperform across different market conditions. In this paper, we introduce Financial Strategy Reinforcement Learning (FSRL), a novel framework leveraging DRL to dynamically select and execute the most appropriate quantitative strategy from a diverse set based on real-time market conditions. This approach departs from conventional methods that depend on a fixed strategy, instead modeling the strategy selection process as a Markov Decision Process (MDP). Within this framework, the DRL agent learns to adaptively switch between strategies, optimizing performance by responding to evolving market scenarios. Our experiments, conducted on two real-world market datasets, demonstrate that FSRL’s dynamic strategy-switching capability not only captures the strengths of individual strategies but also offers a robust and adaptive trading solution. While dynamic strategy selection may not always surpass the best-performing single strategy in every individual metric, it consistently outperforms the weakest strategy and provides a more resilient approach to managing the complexities of financial markets. These findings underscore the potential of DRL in transforming quantitative trading from a multi-factor approach to a multi-strategy paradigm, offering enhanced adaptability and robustness in the face of market volatility.},
  archive      = {J_APIN},
  author       = {Zhong, Xingyu and Wei, Jinhui and Li, Siyuan and Xu, Qingzhen},
  doi          = {10.1007/s10489-024-05965-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Deep reinforcement learning for dynamic strategy interchange in financial markets},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-criteria decision support system to evaluate the effectiveness of training courses on citizens’ employability. <em>APIN</em>, <em>55</em>(1), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05967-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines the impact of lifelong learning on the professional lives of employed and unemployed individuals. Lifelong learning is a crucial factor in securing employment or enhancing one’s existing career prospects. To achieve this objective, this study proposes the implementation of a multi-criteria decision support system for the evaluation of training courses in accordance with their capacity to enhance the employability of the students. The methodology is delineated in four stages. Firstly, a ‘working life curve’ was defined to provide a quantitative description of an individual’s working life. Secondly, an analysis based on K-medoids clustering defined a control group for each individual for comparison. Thirdly, the performance of a course according to each of the four predefined criteria was calculated using a t-test to determine the mean performance value of those who took the course. Ultimately, the unweighted TOPSIS method was used to evaluate the efficacy of the various training courses in relation to the four criteria. This approach effectively addresses the challenge of using extensive datasets within a system while facilitating the application of a multi-criteria unweighted TOPSIS method. The results of the multi-criteria TOPSIS method indicated that training courses related to the professional fields of administration and management, hostel and tourism and community and sociocultural services have positive impact on employability and improving the working conditions of citizens. However, courses that demonstrate the greatest effectiveness in ranking are the least demanded by citizens. The results will help policymakers evaluate the effectiveness of each training course offered by the regional government.},
  archive      = {J_APIN},
  author       = {Bas, María C. and Bolós, Vicente J. and Prieto, Álvaro E. and Rodríguez-Echeverría, Roberto and Sánchez-Figueroa, Fernando},
  doi          = {10.1007/s10489-024-05967-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {A multi-criteria decision support system to evaluate the effectiveness of training courses on citizens’ employability},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliability-aware label distribution learning with attention-rectified for facial expression recognition. <em>APIN</em>, <em>55</em>(1), 1-13. (<a href='https://doi.org/10.1007/s10489-024-05999-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition poses a significant challenge in computer vision with numerous applications. However, existing FER methods need more generalization ability and better robustness when dealing with complex datasets with noisy labels. We propose a label distribution learning model, RA-ARNet, with novel reliability-aware (RA) and attention-rectified (AR) modules to handle noisy labels. Specifically, the RA module evaluates the reliability of the image’ neighboring instances in the valence-arousal space and constructs corresponding label distribution based on the evaluation as auxiliary supervision information to enhance the model’s robustness and generalization on various FER datasets with noisy labels. The AR module can gradually improve the model’s ability to extract attention features of facial landmarks by introducing consistency detection of attention feature maps of images and landmarks in training, thereby improving the model’s FER accuracy. The competitive experimental results on public datasets validate the effectiveness of the proposed method and compare it with the current state-of-the-art methods. The experimental results indicate that the classification performance of RA-ARNet reaches 91.36% on RAF-DB and 61.47% on AffectNet (8 cls) and shows potential to deal with images with occlusion.},
  archive      = {J_APIN},
  author       = {Peng, Liyuan and Liu, Yanbing and Wei, Yuyun and Cui, Jia and Qi, Meng},
  doi          = {10.1007/s10489-024-05999-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Reliability-aware label distribution learning with attention-rectified for facial expression recognition},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-domain feature alignment and hierarchical cross feature enhancement network for under-sampled magnetic image reconstruction. <em>APIN</em>, <em>55</em>(1), 1-20. (<a href='https://doi.org/10.1007/s10489-024-06008-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance imaging (MRI) is widely used in clinical diagnosis due to its high resolution and non-invasive scanning capabilities. However, long scanning times limit its development. To reduce acquisition time and obtain high-quality reconstructed images, a novel multi-domain MRI reconstruction network that fully utilizes the image domain, k-space, and wavelet domain is proposed. This network includes a parallel convolutional neural network (CNN) with k-space and wavelet domain branches, as well as a U-shaped image domain network. Following the parallel dual-domain CNN, a dual-domain feature alignment module aligns features from the k-space and wavelet domains into a unified representation space, mitigating artifact impacts. This design enhances the model’s understanding of multi-domain signals and improves generalization. Additionally, in the image domain, a hierarchical cross-feature enhancement module, based on Nested UNet, incorporates two cross-attention modules into different hierarchical skip connections of the Nested U-Net to reduce information propagation loss and enhance feature representation. Deep supervision within the image domain network further boosts the network’s performance and robustness. Extensive experiments on two public MRI datasets, FastMRI and CC359, as well as the private clinical dataset, validate the proposed method. Compared to several state-of-the-art deep learning methods, our approach demonstrates good reconstruction performance in both numerical assessments and visual effects.},
  archive      = {J_APIN},
  author       = {Liu, Qiaohong and Han, Xiaoxiang and Chen, Yang},
  doi          = {10.1007/s10489-024-06008-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {A multi-domain feature alignment and hierarchical cross feature enhancement network for under-sampled magnetic image reconstruction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid feature selection and aggregation strategy-based stacking ensemble technique for network intrusion detection. <em>APIN</em>, <em>55</em>(1), 1-24. (<a href='https://doi.org/10.1007/s10489-024-06015-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion Detection System (IDS) plays an important role in the cybersecurity for preventing the platform from network attacks. To improve the overall performance of IDS, researchers have introduced machine learning methods to classify network behaviors. As the Internet develops and cyberspace expands, the network environment becomes increasingly diverse and complex. As a result, the traditional and single machine learning methods limit the development of intrusion detection systems, and it is difficult to resist the exponential growth of network attacks. To solve this problem, we propose a novel intrusion detection method based on the hybrid feature selection and stacking ensemble techniques to improve the performance of the intrusion detection system. We first apply the hybrid feature selection technique based on the filtering and embedding methods to reduce the feature dimensions. The filtering method uses the information gain rate, while the embedding method uses the feature importance from the random forest model and determines the best feature subset through the hybrid strategy. On the basis of this, a random forest binary classifier is constructed for each category before a multi-classifier is constructed by the aggregation strategy-based stacking ensemble mechanism to determine the specific type of network behavior. The experimental results show that, on the UNSW-NB15 dataset, the proposed method achieved an accuracy of 80.83% with only 9 selected best features (45 in total), which is an improvement of 5.37% compared to the baseline method. On the CICIDS2017 dataset, the accuracy of proposed model reached 99.97% with 27 features selected (75 in total), outperforming the baseline methods. The detection and recognition performance of our proposed method is better than that of traditional machine learning methods and other well-known ensemble methods in terms of accuracy, F1-Score, Cohen’s Kappa score, and false alarm rate. This indicates that our proposed model could be a useful tool in intrusion detection.},
  archive      = {J_APIN},
  author       = {Huang, Yongqing and Chen, Guoqing and Gou, Jin and Fan, Zongwen and Liao, Yongxin},
  doi          = {10.1007/s10489-024-06015-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {A hybrid feature selection and aggregation strategy-based stacking ensemble technique for network intrusion detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expanding a machine learning class towards its application to the stock market forecast. <em>APIN</em>, <em>55</em>(1), 1-20. (<a href='https://doi.org/10.1007/s10489-024-06018-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a new and efficient algorithm to perform a short-term market trend forecast, based on the Artificial Organic Networks (AON) metaheuristic machine learning framework. Regarding this goal, we present the concept of Artificial Halocarbon Compounds (AHC) or AHC-algorithm as a bio-inspired supervised machine learning algorithm based on the AON framework. Through our research, we contrast the forecast acquired with the proposed AHC model, to previously reported outcomes using the Artificial Hydrocarbon Networks (AHN) in similar tasks. The AHN algorithm is the first formally defined topology based on the AON, making the AHN algorithm a vital benchmark to contemplate. After comparing the AHC-algorithm to the original AHN-algorithm, we found out that due to the high computational complexity of the latter, the new topology is more convenient when modeling more complex systems; being this characteristic the main contribution of the AHC-algorithm, allowing it to be a more adaptable, dynamic, and reconfigurable topology. Likewise, we compared the results of the AHC-algorithm against the outcomes derived from an ARIMA model; we also made a cross-reference contrast against results concerning the prediction of other stock market indices using former state-of-the-art machine learning methods. The proficiency of the AHC-algorithm is assessed by doing a forecast of the IPC Mexico index obtaining good results, achieving a computed R-square of 0.9919, and an $$8\times 10^{-4}$$ mean relative error for the forecast.},
  archive      = {J_APIN},
  author       = {González-Núñez, Enrique and Trejo, Luis A. and Kampouridis, Michael},
  doi          = {10.1007/s10489-024-06018-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Expanding a machine learning class towards its application to the stock market forecast},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EDIR: An expert method for describing image regions based on knowledge distillation and triple fusion. <em>APIN</em>, <em>55</em>(1), 1-16. (<a href='https://doi.org/10.1007/s10489-024-06027-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained visual features generally require higher image input resolutions, which in turn necessitate a larger parameter count for general visual models to effectively analyze these features. However, the substantial computational demands of larger models present significant challenges to research in this domain. To address these challenges, our research integrates descriptions of fine-grained visual information from images. We propose an innovative Expert method for Describing Image Regions (EDIR) based on knowledge distillation and triple fusion techniques. Our method comprises a Knowledge-Distilled Expert Network (KDEN) and a Triple Information Set Fusion Network (TIFN) that combine global and regional image descriptions in a controlled prompting manner. Unlike existing studies, our approach not only extracts global and regional image features independently but also relates their spatial information. Our EDIR method reduces visual model parameters by 6.7 times compared to CogVLM, improves ImageNet-1K zero-shot detection accuracy by 0.68%, increases the CIDEr score on NoCaps by 1.9 points, and achieves an average improvement of 1.39% in hallucination accuracy. It also increases the average inference frame rate to 32.92 FPS, representing a 5.82-fold improvement over the baseline.},
  archive      = {J_APIN},
  author       = {Ren, Kai and Hu, Chuanping and Xi, Hao and Li, Yongqiang and Fan, Jinhao and Liu, Lihua},
  doi          = {10.1007/s10489-024-06027-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {EDIR: An expert method for describing image regions based on knowledge distillation and triple fusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated edge learning for medical image augmentation. <em>APIN</em>, <em>55</em>(1), 1-17. (<a href='https://doi.org/10.1007/s10489-024-06046-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the medical sector, diagnostic technology-related progress is often hindered by data isolation and stringent privacy laws, posing obstacles for institutions that lack extensive disease data. This scarcity impedes the development of precise diagnostic models and reliable auxiliary tools. To address these challenges, we introduce the horizontal federated data augmentation model for medical assistance (HFDAM-MA), a novel approach designed to address the complexities of data scarcity. Our model addresses the limitations of traditional generative adversarial networks (GANs), which often rely on the independent and identically distributed (IID) assumption during training (a condition that is rarely satisfied in real-world medical data scenarios) and face computational challenges in healthcare settings. The HFDAM-MA leverages federated learning (FL) principles to enable non-IID collaborative training across multiple medical institutions. This approach alleviates the data collection pressure at individual sites and ensures the privacy of sensitive medical information. A central node orchestrates the distribution of a unified GAN model to local sites, where it operates in conjunction with two convolutional neural networks (CNNs) to generate synthetic medical images and corresponding labels. Extensive experimental results underscore the effectiveness of our model. As participation increases, we observe a substantial improvement in the diagnostic accuracy of the global model. Moreover, the performance of the local models is bolstered, and the diversity of the generated data is expanded, offering a robust solution to the challenges of data privacy, imbalanced data, and insufficient labeling that are prevalent in the medical sector.},
  archive      = {J_APIN},
  author       = {Li, Shuai and Hu, Liang and Sun, Chengyu and Hu, Juncheng and Li, Hongtu},
  doi          = {10.1007/s10489-024-06046-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Federated edge learning for medical image augmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An attention-BiLSTM network identification method for time-delay feedback nonlinear system. <em>APIN</em>, <em>55</em>(1), 1-15. (<a href='https://doi.org/10.1007/s10489-024-06067-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the identification problem of feedback nonlinear system with time delay (FNTD). A data-driven identification method for the FNTD system based on bidirectional long short-term memory (BiLSTM) networks is proposed. First, considering the long input and output data sequence and the existence of bidirectional features, the BiLSTM network is chosen for identification. In addition, in order to mine the complex nonlinear mapping relationship between input and output, the attention mechanism is introduced into the BiLSTM algorithm to highlight the influence of key factors. The Gaussian kernel function selects the optimal complexity model to enhance the extrapolation performance, and further improves the identification accuracy. Then, the attention-BiLSTM algorithm is proposed. In the simulation, a numerical example and two application examples are implemented. The results show that the attention-BiLSTM method can effectively identify the FNTD system, and is superior to LSTM and BiLSTM in terms of identification accuracy and speed. The proposed attention-BiLSTM method has the highest identification accuracy, and the RMSE is $$5.57\%$$ and $$1.05\%$$ lower than the LSTM and BiLSTM models, respectively. The $$R^2$$ value reaches 0.9997, which is $$16.17\%$$ and $$0.77\%$$ higher than LSTM and BiLSTM, respectively.},
  archive      = {J_APIN},
  author       = {Yan, Jun and Li, Junhong and Bai, Guixiang and Li, Yanan},
  doi          = {10.1007/s10489-024-06067-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {An attention-BiLSTM network identification method for time-delay feedback nonlinear system},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial domain adaptation with CLIP for few-shot image classification. <em>APIN</em>, <em>55</em>(1), 1-12. (<a href='https://doi.org/10.1007/s10489-024-06088-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning focuses on training efficient models with limited amounts of training data. Its mainstream approaches have evolved from single-modal to multi-modal methods. The Contrastive Vision-Language Pre-training model, known as CLIP, achieves image classification by aligning the embedding spaces of images and text. To better achieve knowledge transfer between image domain and text domain, we propose a fine-tuning framework for vision-language models with CLIP. It introduces a novel adversarial domain adaptation approach, which trains a text and image symmetrical classifier to identify the differences between two domains. To more effectively align text and image into the same space, we adapt two types of confusion loss to construct the aligned semantic space by fine-tuning multi-modal features extractor. Experiments on 11 public datasets show that our proposed method has superior performance compared with state of art CLIP-driven learning methods.},
  archive      = {J_APIN},
  author       = {Sun, Tongfeng and Yang, Hongjian and Li, Zhongnian and Xu, Xinzheng and Wang, Xiurui},
  doi          = {10.1007/s10489-024-06088-4},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {Adversarial domain adaptation with CLIP for few-shot image classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-language few-shot intent recognition via prompt-based tuning. <em>APIN</em>, <em>55</em>(1), 1-16. (<a href='https://doi.org/10.1007/s10489-024-06089-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-language intent recognition is a fundamental task in cross-language understanding. Recently, this task has been addressed by pretrained cross-language language models. Existing approaches typically augment pretrained language models with additional data, such as annotated parallel corpora. However, these additional data are scarce in practice, especially for low-resource languages. Inspired by the recent effective results of prompt learning, this paper proposes a new framework for enhancing cross-language few-shot intent recognition methods based on prompt tuning (CIRP). The proposed method converts the cross-language intent recognition task into a masked language modelling problem by designing prompt templates. To make the proposed model more generalizable, and avoid templates and label words dependent on a specific language, the method encodes the prompt templates into language-independent embedding representations via the multilingual pretrained language models, and initializes the label words into soft label words by averaging the [mask] vector values from different utterances of the same label, which reduces the distance between label word embeddings and encoder outputs of the [mask] to increase the accuracy of cross-language intent recognition. The experimental results on the few-shot cross-language MultiATIS++, MIvD benchmark dataset show that, compared with the four baseline models, the CIRP performs remarkably well in terms of intent recognition accuracy. Notably, when the sample sizes are set to 1 and 8 shots, the cross-language intent recognition accuracy metrics improve by an average of 11.75% compared with those of the baseline models.},
  archive      = {J_APIN},
  author       = {Cao, Pei and Li, Yu and Li, Xinlu},
  doi          = {10.1007/s10489-024-06089-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Cross-language few-shot intent recognition via prompt-based tuning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A framework of granular-ball generation for classification via granularity tuning. <em>APIN</em>, <em>55</em>(1), 1-23. (<a href='https://doi.org/10.1007/s10489-024-05904-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Granular-ball Computing (GbC), the radius of a granular-ball is usually defined as the maximum or average distance from all enclosed objects to the center. However, both methods face challenges in building a high-quality family of granular-balls for enhanced classification performance. The former often results in overlaps between heterogeneous granular-balls, and the latter may fail to cover all objects. This paper presents an effective way to define the radius with adaptive granularity tuning and explores the subsequent application of the constructed granular-balls in classifications. Specifically, we introduce the concept of generalized granular-ball, where the center and radius are calculated with weight factors. The general granular-balls are further enhanced through two steps. The first step removes their overlaps through the concepts of heterogeneous neighborhood and de-overlapping parameter, reducing the granular-balls to be tangent or separate to each other. The second step further refines the radii of the tangent granular-balls by referencing the best granular-ball. Algorithms are developed to generate the granular-balls with dynamic radius adjustments and to build the subsequent classifier. Finally, experimental results on nine UCI datasets demonstrate the effectiveness and efficiency of our approach.},
  archive      = {J_APIN},
  author       = {Pan, Jialong and Lang, Guangming and Xiao, Qimei and Yang, Tian},
  doi          = {10.1007/s10489-024-05904-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {A framework of granular-ball generation for classification via granularity tuning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LOCO-EPI: Leave-one-chromosome-out (LOCO) as a benchmarking paradigm for deep learning based prediction of enhancer-promoter interactions. <em>APIN</em>, <em>55</em>(1), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05848-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mammalian and vertebrate genomes, the promoter regions of the gene and their distal enhancers may be located millions of base-pairs from each other, while a promoter may not interact with the closest enhancer. Since base-pair proximity is not a good indicator of these interactions, there is a significant body of work to develop methods for understanding Enhancer-Promoter Interactions (EPI) from genetic and epigenomic marks. Over the last decade, several machine learning and deep learning methods have reported increasingly higher accuracies for predicting EPI. Typically, these approaches perform analysis by randomly splitting the dataset of Enhancer-Promoter (EP) pairs into training and testing subsets followed by model training. However, the aforementioned random splitting inadvertently causes information leakage by assigning EP pairs from the same genomic region to both testing and training sets. As a result, it has been pointed out in the literature that the performance of EPI prediction algorithms is overestimated because of genomic region overlap among the training and testing parts of the data. Building on that, in this paper we propose to use a more thorough training and testing paradigm i.e., Leave-one-chromosome-out (LOCO) cross-validation for EPI prediction. LOCO has been used in other bioinformatics contexts and ensures that there is no genomic overlap between training and testing sets enabling more fair estimation of performance. We demonstrate that a deep learning algorithm which gives higher accuracies when trained and tested on random-splitting setting, drops drastically in performance under LOCO setting, showing overestimation of performance in previous literature. We also propose a novel hybrid multi-branch neural network architecture for EPI prediction. In particular, our architecture has one branch consisting of a deep neural network, while the other branch extracts traditional k-mer features derived from the nucleotide sequence. The two branches are later merged and the neural network is trained jointly to force the network to learn feature representations which are already not covered by k-mer features. We show that the hybrid architecture performs significantly better in a realistic and fair LOCO testing paradigm, demonstrating it can learn more general aspects of EP interactions instead of overfitting to genomic regions. Through this paper we are also releasing the LOCO splitting-based EPI dataset to encourage other research groups to benchmark their EPI algorithms using a consistent LOCO paradigm. Research data is available in this public repository: https://github.com/malikmtahir/EPI},
  archive      = {J_APIN},
  author       = {Tahir, Muhammad and Khan, Shehroz S. and Davie, James and Yamanaka, Soichiro and Ashraf, Ahmed},
  doi          = {10.1007/s10489-024-05848-6},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {LOCO-EPI: Leave-one-chromosome-out (LOCO) as a benchmarking paradigm for deep learning based prediction of enhancer-promoter interactions},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Re-induction based mining for high utility item-sets. <em>APIN</em>, <em>55</em>(1), 1-17. (<a href='https://doi.org/10.1007/s10489-024-05855-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The High Utility Itemset mining (HUIM) is an important research area in the field of data mining and knowledge discovery. HUIM aims to discover the high utility patterns from a given database, based on a utility threshold value, where the utility is a user-defined objective function. The existing HUIM algorithms fail to consider the actual behaviour of the occurrence of patterns in database. They consider all the patterns having the same utility value to be of equal importance. However, this may not always be the case, since some patterns may occur in localized clusters in the database while others can have a more uniform sequence of occurrence. The Frequent Itemset Mining (FIM) approaches also fail to address this problem since they are based on a support framework that considers only the frequency of occurrence of an itemset in the database. To address this research gap, this study introduces a novel concept of maintaining a count value of the itemsets, called re-induction count, in order to keep track of the relative occurrence of items in the database. A novel algorithm, named Ri-Miner, is proposed to mine itemsets based on both a minimum utility threshold and their re-induction count. The experimental results show that Ri-Miner outperforms existing methods by achieving a 15% improvement in execution time and a 10% reduction in memory usage. The proposed method can be useful in various applications that require capturing the underlying occurrence behaviour of the patterns the database, like market-basket analysis, healthcare, web stream analytics, etc.},
  archive      = {J_APIN},
  author       = {Mathur, Pushp S. and Chand, Satish},
  doi          = {10.1007/s10489-024-05855-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Re-induction based mining for high utility item-sets},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised attribute reduction algorithm framework based on spectral clustering and attribute significance function. <em>APIN</em>, <em>55</em>(1), 1-26. (<a href='https://doi.org/10.1007/s10489-024-05878-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction is a significant challenge in fields like data mining and pattern recognition. Various models have been introduced to enhance the performance of attribute reduction algorithms, such as the fuzzy rough sets model. However, the common greedy-based reduction algorithm frameworks shared by these models often struggle to efficiently remove redundant attributes. Manual intervention is often employed by researchers to extract the optimal attribute subset, such as setting hyperparameters to control the algorithm’s progression. Unfortunately, these methods lack practical relevance. To address these challenges, this study presents an unsupervised attribute reduction algorithm framework that employs spectral clustering and an attribute significance function. Initially, we introduce an attribute similarity function and a spectral clustering algorithm to capture the data’s main partition structures. We then propose a method for automatically selecting the optimal clustering result, aiming to generate preliminary reduction outcomes. Additionally, we developed a novel unsupervised attribute reduction framework by integrating it with the traditional approach. Furthermore, a specific unsupervised attribute reduction algorithm has been obtained by embedding an unsupervised attribute significance function. Comparative experiments were conducted with six state-of-the-art algorithms across 27 datasets, and the results show that our proposed algorithm demonstrates superior efficiency and effectiveness in attribute selection.},
  archive      = {J_APIN},
  author       = {Wen, Haotong and Liang, Meishe and Zhao, Shixin and Mi, Jusheng and Jin, Chenxia},
  doi          = {10.1007/s10489-024-05878-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Unsupervised attribute reduction algorithm framework based on spectral clustering and attribute significance function},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MIGCL: Fake news detection with multimodal interaction and graph contrastive learning networks. <em>APIN</em>, <em>55</em>(1), 1-23. (<a href='https://doi.org/10.1007/s10489-024-05883-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rapid growth of news containing multimedia elements, such as images in social networks, cross-modal learning is crucial for accurate fake news detection. Most previous approaches focus on embedding images and sentences independently into a shared embedding space by developing complex neural networks to coarsely fuse multimodal information. However, these approaches rarely seek fine-grained connections between images and sentences prior to performing multimodal fusion and lack the ability to understand complex intra- and intermodal relationships. In addition, previous studies have primarily concentrated on intra- and intermodal relationships within each sample, but interclass sample dynamics have been neglected. To address these issues, we propose a multimodal interaction and graph contrastive learning network (MIGCL) for fake news detection. The multimodal interaction network consists of cross-modal alignment and filtering mechanisms that take into account both locally fine-grained and comprehensive cross-modal interactions while also adaptively suppressing irrelevant cross-modal interactions. Moreover, we develop a hierarchical graph contrastive learning framework that employs fully and self-supervised contrastive learning methods to investigate the intricate connections of intra- and intermodal representations. More precisely, unimodal graphs are constructed at the intramodal level to explore the authenticity information contained in the intra- and interclass samples of a particular modality. At the intermodal level, multimodal graphs are constructed to capture the correlations between intra- and interclass cross-modal samples. Furthermore, we enhance the robustness of the model feature representation by applying perturbations to the graph structure. The proposed MIGCL achieves superior performance on three benchmark datasets, indicating the efficacy of our approach.},
  archive      = {J_APIN},
  author       = {Cui, Wei and Shang, Mingsheng},
  doi          = {10.1007/s10489-024-05883-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {MIGCL: Fake news detection with multimodal interaction and graph contrastive learning networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal market information fusion for stock price trend prediction in the pharmaceutical sector. <em>APIN</em>, <em>55</em>(1), 1-27. (<a href='https://doi.org/10.1007/s10489-024-05894-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the evolution of China's market economy, the securities market is increasingly anchoring a pivotal role in the nation's economic landscape. Consequently, stock trend forecasting has garnered heightened attention among scholars and practitioners. This research pioneers the use of multimodal information to predict stock market fluctuations. Based on our experimental results, LSTM + Transformer performs better in handling multimodal data for stock movement prediction tasks regarding accuracy, F1-score, precision, and recall. Additionally, we employed the Granger causality test and Impulse response test to investigate the causal relationships between sentiment and stock trends, as well as the interplay between COVID-related indicators and stock trajectories. We identified discernible causal links between sentiments, COVID indicators, and stock trends for select pharmaceutical stocks. Our findings can provide valuable guidance for investors and market regulators, especially within the pharmaceutical industry. Understanding investor sentiment and the impact of the pandemic on severity can assist in effective stock commentary management and improve investment strategies.},
  archive      = {J_APIN},
  author       = {Wang, Hongren and Xie, Zerong and Chiu, Dickson K. W. and Ho, Kevin K. W.},
  doi          = {10.1007/s10489-024-05894-0},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Appl. Intell.},
  title        = {Multimodal market information fusion for stock price trend prediction in the pharmaceutical sector},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSA-CNN: An fpga-integrated deformable systolic array for convolutional neural network acceleration. <em>APIN</em>, <em>55</em>(1), 1-18. (<a href='https://doi.org/10.1007/s10489-024-05898-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Field-Programmable Gate Arrays (FPGAs) are increasingly being explored for accelerating Convolutional Neural Networks (CNNs) due to their efficient energy consumption and robust performance. For low-power edge deployment, FPGA-based CNN accelerators typically adopt spatial unrolling architectures. These designs not only achieve high computational efficiency but also feature reduced latency between data transfer and storage access, with low power consumption. Nonetheless, these accelerators may not perform as well with convolutional layers that have large input sizes but few channels. The complexity involved in managing spatial unrolling can hinder their large-scale implementation in integrated circuits. To meet these challenges, this paper presents a new computing architecture called the Deformation Systolic Array (DSA). It starts by designing configurable processing elements (PEs). The architecture uses a designed feature pumping (F-P) method as its dataflow to minimize delays. Additionally, a data broadcasting approach is employed across PEs using a systolic array, enhancing data reuse. The scalable design allows adaptation to varying resource capacities and computational requirements. Furthermore, a scheduling policy has been developed that enables PEs to follow different parallel processing modes depending on the number of channels, size, and type of the convolutional layer. The evaluation experiments demonstrate that, compared to the NVIDIA RTX 3090 GPU and the SIYUAN370 ASIC, DSA-CNN achieves that speedups of 2.10 $$\times $$ and 1.89 $$\times $$ , respectively, when deploying the lightweight object detection network SSD-MobileNetV1-300 on the VU13P.},
  archive      = {J_APIN},
  author       = {Wan, Yi and Chen, Junfan and Yang, Xiong and Zhang, Hailong and Huang, Chao and Xie, Xianzhong},
  doi          = {10.1007/s10489-024-05898-w},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {DSA-CNN: An fpga-integrated deformable systolic array for convolutional neural network acceleration},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LGCE-net: A local and global contextual encoding network for effective and efficient medical image segmentation. <em>APIN</em>, <em>55</em>(1), 1-20. (<a href='https://doi.org/10.1007/s10489-024-05900-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation in clinical applications is important and challenging. Learning contextual features including local and global information is pivotal in effective medical image segmentation. Existing methods based on convolutional neural networks (CNNs) are usually constrained by limited receptive fields, resulting in inaccurate segmentation when dealing with local similarities and large-scale variations in complex medical images. In this paper, we focus on combining convolution and attention mechanisms for effective and efficient medical image segmentation, and propose a local and global contextual encoding network (LGCE-Net), which contains an encoder, a feature extraction module and a decoder. In the encoder, multi-scale feature maps are obtained through convolution and pooling operations. For feature extraction, the Dense Atrous Convolution Attention (DACA) block is introduced, which leverages atrous convolutions with different atrous rates and space-related attention to capture local information. Additionally, the Spatial Grid Attention (SGA) block, which combines grid attention and spatial attention to extract global contextual information, is presented to enhance the feature representations. Finally, sub-pixel convolution is used to restore semantic features extracted from the encoder and the feature extraction module. We conducted experiments on three public datasets and our approach outperforms CNN-based, attention-based and state-of-the-art CNN-Attention combined models. Moreover, our model runs at 200 Frames-Per-Second (FPS) when only 9.22M parameters are used. Our code will be released once the manuscript is accepted for publication.},
  archive      = {J_APIN},
  author       = {Zhu, Yating and Peng, Meifang and Wang, Xiaoyan and Huang, Xiaojie and Xia, Ming and Shen, Xiaoting and Jiang, Weiwei},
  doi          = {10.1007/s10489-024-05900-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {LGCE-net: A local and global contextual encoding network for effective and efficient medical image segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CRViT: Vision transformer advanced by causality and inductive bias for image recognition. <em>APIN</em>, <em>55</em>(1), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05910-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision Transformer (ViT) has shown powerful potential in various vision tasks by exploiting Transformer’s self-attention mechanism and global perception capability. However, to train a large number of network parameters, ViT requires a huge amount of data and number of computational resources, thus performing poorly on small and medium-sized datasets. Compared to ViT, convolutional networks maintain high accuracy despite the small amount of data due to the consideration of the inductive bias (IB). Besides, causal relationships can explore the underlying correlation of data structures, making the deep learning networks more intelligent. In this work, we propose a Causal Relationship Vision Transformer (CRViT), which refines ViT by fusing causal relationships and IB. We propose a random fourier features module that makes feature vectors independent of each other and uses convolution to learn correct correlation between feature vectors and extract causal features to introduce causal relationships in our network. The structure of convolutional downsampling significantly reduces the number of parameters of our model while introducing IB. Experimental validations underscore the data efficiency of CRViT, achieving a Top-1 accuracy of 80.6% on the ImageNet-1k dataset. This surpasses the ViT benchmark by 2.7% while concurrently reducing parameters by 92%. This enhanced performance is also consistent across smaller datasets, including T-ImageNet, CIFAR, and SVHN. We create the counterfactual dataset Colorful MNIST and experimentally demonstrate that causality is truly joined.},
  archive      = {J_APIN},
  author       = {Lu, Faming and Jia, Kunhao and Zhang, Xue and Sun, Lin},
  doi          = {10.1007/s10489-024-05910-3},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {CRViT: Vision transformer advanced by causality and inductive bias for image recognition},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep graph regularized nonnegative tucker decomposition for image data analysis. <em>APIN</em>, <em>55</em>(1), 1-20. (<a href='https://doi.org/10.1007/s10489-024-05920-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonnegative Tucker decomposition (NTD) is widely recognized as an effective tool for image analysis. However, the single-layer structure of the original NTD model is insufficient for capturing multiple directional representations and local manifold structural information from the raw image data. To overcome these limitations, we extend the single-layer framework to a deep graph regularized nonnegative Tucker decomposition (DGNTD) structure by harmoniously unifying deep learning and graph regularization terms in NTD. DGNTD constructs a hierarchical deep structure and decomposes image data into several layers that describe the interconnections of different layers throughout the deep structure. Furthermore, DGNTD with graph learning utilizes a graph structure to express the relationships between samples, which allows for the depiction of the inner geometrical relationships between samples while preserving computational feasibility. In addition, tests on three image datasets, including COIL20, ORL, and PIE, are used to assess the effectiveness of the proposed method.},
  archive      = {J_APIN},
  author       = {Liao, Qingshui and Bakar, Sakhinah Abu and Liu, Qilong and Razak, Fatimah Abdul},
  doi          = {10.1007/s10489-024-05920-1},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Deep graph regularized nonnegative tucker decomposition for image data analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective optimization of the mixed-flow intelligent production line for automotive MEMS pressure sensors. <em>APIN</em>, <em>55</em>(1), 1-14. (<a href='https://doi.org/10.1007/s10489-024-05928-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent manufacturing can provide powerful support for the digital transformation of manufacturing industry. Micro-electro-mechanical system (MEMS) sensors have been widely used in the automotive industry because of their small size, low cost, and high reliability. Aiming at the problems of low flexibility, poor adaptability, and high manufacturing cost in the mixed-flow intelligent production line of multi-variety automotive MEMS pressure sensors in this study, a multi-objective optimization model is established with takt time and balance rate as optimization objectives. The non-dominated sorting genetic algorithm-II (NSGA-II) is used to obtain the multi-objective optimization of the mixed-flow intelligent production line with the elite strategy, crowding degree, and crowded comparison operator. The accuracy of the NSGA-II is validated by comparing it with that of the ant colony optimization (ACO) algorithm, simulated annealing (SA) algorithm, and particle swarm optimization (PSO) algorithm. The NSGA-II achieves higher optimization accuracies for takt time and balance rate compared to ACO, SA, and PSO algorithms. Specifically, the NSGA-II achieves optimization accuracies of 2.73%, 2.44%, and 8.99% for the takt time, slightly surpassing those of the ACO, SA, and PSO algorithms respectively. Similarly, for the balance rate, the NSGA-II achieves optimization accuracies of 2.17%, 1.89%, and 2.48%, slightly higher than those of the ACO, SA, and PSO algorithms respectively. The takt time is optimized by NSGA-II to less than 10 s/piece, while the balance rate is optimized to over 90%. The multi-objective optimization of the mixed-flow intelligent production line for automotive MEMS pressure sensors is practical and instructive for improving production line efficiency.},
  archive      = {J_APIN},
  author       = {Zhang, Quanyong and Li, Hui and Shen, Shengnan and Cao, Wan and Jiang, Jing and Tang, Wen and Hu, Yuanshun},
  doi          = {10.1007/s10489-024-05928-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Multi-objective optimization of the mixed-flow intelligent production line for automotive MEMS pressure sensors},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain adaptive segmentation method for mechanical assembly based on iterative loops. <em>APIN</em>, <em>55</em>(1), 1-15. (<a href='https://doi.org/10.1007/s10489-024-05931-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the assembly process of mechanical products, employing deep learning techniques for the semantic segmentation of assembly images enables real-time monitoring of irregularities, including incorrect or missing assemblies. However, most of the current monitoring methods based on deep learning adopt supervised learning. This requires a large number of labels according to different assembly specifications, which is time-consuming and laborious. To address this issue, this study designed a two-stage adaptive segmentation framework based on iterative loops for synthesis-physical assembly images, i.e., ILDA-Net (iterative loops domain adaptation network), which does not require any labeling of physical assemblies. In the adversarial learning stage, a trainable line-guided filter module and a line discriminator module are introduced for maintaining line features. The two modules are iteratively trained in a loop to continuously optimize the segmentation model. In the self-training stage, the edge segmentation quality is guaranteed by optimizing the segmentation model through utilizing unreliable pseudo-labels. Finally, this study constructed a set of semantic segmentation datasets for domain adaptation of synthetic-physical assembly images and conducted experiments on these datasets. Based on these experiments, the Dice coefficient can reach up to 89.33%, which demonstrating that the proposed method can be utilized for the physical assembly image segmentation.},
  archive      = {J_APIN},
  author       = {Wang, Jinlei and Chen, Chengjun and Dai, Chenggang},
  doi          = {10.1007/s10489-024-05931-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Domain adaptive segmentation method for mechanical assembly based on iterative loops},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LCLD: A lightweight vanishing point detector with contrast-learning-based intermediate supervision module. <em>APIN</em>, <em>55</em>(1), 1-13. (<a href='https://doi.org/10.1007/s10489-024-05949-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vanishing point detection is crucial in 3D vision, enabling the extraction of 3D information from 2D images. However, many vanishing point detectors involve a trade-off between model complexity and detection accuracy. To address this problem, we propose a lightweight vanishing point detector with intermediate supervision and a classifier for channel aggregation (CIAP). The proposed approach has the following novelties. Firstly, the intermediate supervision module leverages contrast learning, which learns by bringing similar samples closer and pushing dissimilar ones apart, with an extremely positive and negative sample selection strategy. Secondly, the fully connected layers are replaced with purely convolutional layers that aggregate multi-channel information, reducing the model parameters from $$\varvec{22M}$$ to $$\varvec{4.6M}$$ without compromising accuracy. Extensive validation on synthetic and real-world datasets shows the strong performance of our approach, with a $$\varvec{5.4\%}$$ improvement in angle accuracy $$\varvec{0.2^{\circ }}$$ over the state-of-the-art method VaPiD on the synthetic dataset. The reduced parameter count supports energy-efficient systems, contributing to the development of sustainable and scalable 3D vision solutions.},
  archive      = {J_APIN},
  author       = {Yang, Lianping and Huang, Wencong and Zhao, Xin and Zhu, Hegui},
  doi          = {10.1007/s10489-024-05949-2},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {LCLD: A lightweight vanishing point detector with contrast-learning-based intermediate supervision module},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid imputation-based optimal evidential classification for missing data. <em>APIN</em>, <em>55</em>(1), 1-18. (<a href='https://doi.org/10.1007/s10489-024-05950-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifying incomplete data remains a challenging task, as missing values can provide uncertain and imprecise information that reduces classification performance. To address this issue, we proposed a hybrid imputation-based optimal evidential classification (HOEC) method for missing data under the Dempster-Shafer theory framework. The proposed HOEC method can capture uncertainty and imprecision during imputation and classification procedures. Specifically, a hybrid imputation strategy was developed to estimate the missing values in the training and test sets by combining single and multiple imputations. Thus, we obtained accurate estimations and captured their uncertainties. An optimal evidential partition rule was then designed to adaptively submit an incomplete sample to a singleton class or meta-class under the Dempster-Shafer theory framework. Therefore, we can capture the imprecision caused by missing values and reduce classification errors. Experiments on several incomplete datasets demonstrated the effectiveness of the HOEC method compared with related methods.},
  archive      = {J_APIN},
  author       = {Zhang, Zhen and Tian, Hong-peng},
  doi          = {10.1007/s10489-024-05950-9},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Hybrid imputation-based optimal evidential classification for missing data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Requirement-service mapping technology in the industrial application field based on large language models. <em>APIN</em>, <em>55</em>(1), 1-14. (<a href='https://doi.org/10.1007/s10489-024-05969-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article introduces a method of requirements-service mapping based on large-scale language models, utilizing the significant semantic understanding capability of large language models. It leverages multiple rounds of natural language question-answering to interact with users, achieve the transformation of users’ vague requirements into structured information, and eventually map to specific application services. Through combining large language models with traditional vector searching techniques, the micro-adjustment of large language models is realized for extracting and structuring requirements’ information without retraining or inputting massive data to build context. It presents classification of requirements and definition of service attributes to constrain and regulate content of user requirements, providing rules for large language models to express non-structured raw requirements into clear structured information. Upon obtaining the structured information, word embedding is further used to vectorize service information and requirements. The service mapping process is completed through vector matching algorithms, realizing the ultimate transformation from requirements to services. Finally, through industrial application service template, case studies have been conducted to analyze the accuracy of mapping under different requirement rules, thus ultimately demonstrating the effectiveness of the requirement-mapping method proposed in this article.},
  archive      = {J_APIN},
  author       = {Ruixiang, Liu and Qiujun, Deng and Xianhui, Liu and Chenglin, Zhu and Weidong, Zhao},
  doi          = {10.1007/s10489-024-05969-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Requirement-service mapping technology in the industrial application field based on large language models},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-based behavioral cloning for algorithmic trading. <em>APIN</em>, <em>55</em>(1), 1-21. (<a href='https://doi.org/10.1007/s10489-024-06064-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trading robots, meticulously crafted programs, are designed to execute trades automatically. However, stock trading presents a unique challenge. Unlike finite game tasks, stock markets operate perpetually, making it arduous for traders to design appropriate reward functions for training Reinforcement Learning models. For stock trading tasks that can easily determine the optimal decision trajectory from historical data, previous studies showed that Behavioral Cloning has much better learning efficiency than Reinforcement Learning. In this study, we propose a novel Behavior Cloning algorithm that leverages Long Short-Term Memory (LSTM) networks and self-attention mechanism as core components. Our approach effectively captures temporal dependencies and interrelations among elements at various positions, aiming to enhance learning efficiency. Additionally, a strategic approach known as the positive transaction expert strategy was devised to guide the model training process. In our comparative analysis, we evaluated the proposed algorithm against supervised learning, reinforcement learning, and traditional time series trading algorithms. The empirical results indicate that the Attention-Based Behavioral Cloning algorithm exhibits an 83.33% likelihood of achieving the highest return. The learning structure of Attention-Based Behavioral Cloning},
  archive      = {J_APIN},
  author       = {Sun, Qizhou and Xie, Yufan and Si, Yain-Whar},
  doi          = {10.1007/s10489-024-06064-y},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Attention-based behavioral cloning for algorithmic trading},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SDROF: Outlier detection algorithm based on relative skewness density ratio outlier factor. <em>APIN</em>, <em>55</em>(1), 1-21. (<a href='https://doi.org/10.1007/s10489-024-06092-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection is a crucial research problem in data mining, aiming to identify data objects that significantly deviate from the distribution of other data. To solve the issues of low-density patterns and low local density problems in nearest neighbor-based outlier detection methods, this paper proposes an outlier detection algorithm based on the relative skewness density ratio outlier factor. An adaptive determination of the number of neighbors (k value) and neighborhood is achieved using the natural neighbor search algorithm, effectively addressing parameter setting challenges. It introduces the concept of relative skewness to quantify how much data objects deviate from their neighbors, along with a local density ratio to capture variations in local density. This leads to a new outlier measure called the Relative Skewness Density Ratio Outlier Factor, which uses the ratio of relative skewness to local density as the outlier factor. The outlier degree of each data object is further assessed by evaluating the deviation of this factor from its neighbors. Experimental validation of the proposed algorithm is conducted on both artificial and real-world datasets, with comparisons against recent novel outlier detection algorithms, demonstrating the effectiveness of the proposed algorithm.},
  archive      = {J_APIN},
  author       = {Zhang, Zhongping and Wang, Kuo and Dong, Jinyu and Li, Sen},
  doi          = {10.1007/s10489-024-06092-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {SDROF: Outlier detection algorithm based on relative skewness density ratio outlier factor},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted mean of vectors algorithm with neighborhood information interaction and vertical and horizontal crossover mechanism for feature selection. <em>APIN</em>, <em>55</em>(1), 1-44. (<a href='https://doi.org/10.1007/s10489-024-05889-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Weighted Mean of Vectors Algorithm (INFO) is an enhanced weighted average method that optimizes vector positions using three strategies: updating rule, vector combination, and local search. This algorithm exhibits notable optimization capabilities and high convergence accuracy. However, it is not without limitations; specifically, it tends to become trapped in local optima when addressing multi-peaked functions, suffers from a lack of population diversity, and is prone to premature convergence. To address these issues, this paper presents an improved version of the algorithm, WCINFO, which integrates a weighted voting (WV) strategy and a horizontal and vertical crossover (CC) strategy. The WV strategy facilitates early-stage information exchange among search agents and neighboring individuals, while the CC strategy effectively prevents the algorithm from becoming trapped in local optima. This study evaluates WCINFO’s performance using the IEEE CEC 2017 test set, comparing it against the original INFO algorithm, seven mainstream meta-heuristic algorithms (MAs), and eleven enhanced MAs. The Wilcoxon signed-rank test is employed to assess WCINFO’s performance. The results indicate that WCINFO surpasses the other algorithms in convergence accuracy, speed, and robustness. Furthermore, to ascertain WCINFO’s efficacy in feature selection (FS), its binary variant, BWCINFO, is compared against eight other binary classifiers across 16 publicly available datasets. WCINFO achieved the lowest classification error rates compared to other algorithms and selected the fewest features across all 16 datasets. Additionally, it attained 100% accuracy on six of these datasets, with the size of the feature subsets being less than 35.2% of the original number of features.},
  archive      = {J_APIN},
  author       = {Wang, Zhilin and Chen, Yi and Cai, Zhennao and Heidari, Ali Asghar and Liu, Lei and Chen, Huiling},
  doi          = {10.1007/s10489-024-05889-x},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-44},
  shortjournal = {Appl. Intell.},
  title        = {Weighted mean of vectors algorithm with neighborhood information interaction and vertical and horizontal crossover mechanism for feature selection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based reinforcement learning for optical cavity temperature control system. <em>APIN</em>, <em>55</em>(1), 1-21. (<a href='https://doi.org/10.1007/s10489-024-05943-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracy of laser gas detection technology is influenced by the temperature of the optical cavity. Traditional control methods suffer from inadequacies in fully considering the coupling effects between features and the time delay in heat transfer. To address these issues, a method combining Transformer and reinforcement learning (RL) has been proposed. By using Transformer, this method generates enhanced features that are then used by the RL algorithm for iterative learning, aiming to optimize the control strategy. Additionally, a dual attention mechanism is introduced to enhance the model’s comprehension of the complex dynamics within the optical cavity. This study represents the first application of Transformer in the field of temperature control, paving the way for the utilization of advanced machine-learning techniques in optical cavity temperature regulation. Experimental results confirm the proposed method’s efficiency and long-term effectiveness in ensuring precise temperature control, demonstrating its potential in managing the complex cross-coupling effects within temperature control systems.},
  archive      = {J_APIN},
  author       = {Zhang, Hongli and Lu, Yufan and Wang, Chi and Dou, Wei and Liu, Shulin and Huang, Cheng and Peng, Jian and Cheng, Weiheng},
  doi          = {10.1007/s10489-024-05943-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Transformer-based reinforcement learning for optical cavity temperature control system},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multilingual natural scene text detection via global feature fusion. <em>APIN</em>, <em>55</em>(1), 1-16. (<a href='https://doi.org/10.1007/s10489-024-05951-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural scene text detection is a significant challenge in computer vision, with tremendous potential applications in multilingual, diverse, and complex text scenarios. A multilingual text detection model based on the Cascade Mask R-CNN is proposed to address the challenges of low accuracy and high difficulty in detecting multilingual text in natural scenes. In response to the challenges posed by multilingual text images with multiple character sets and various font styles, the SFM Swin Transformer feature extraction network is introduced to increase the robustness of character and font detection across different languages. To address the considerable variation in text scales and complex arrangements in natural scene text images, the AS-HRFPN feature fusion network is constructed by incorporating an adaptive spatial feature fusion module and a spatial pyramid pooling module. The feature fusion network improvements enhance the model’s ability to detect text sizes and orientations. Furthermore, to address the complexity of high background diversity and variations in font letter morphology across different languages in multilingual natural scene text images, existing methods often need better detection performance because of the need for global information caused by limited local receptive fields. To mitigate this, a global semantic segmentation branch is introduced to extract and preserve global features to guide text detection. This study collected and constructed a real-world, multilingual, natural scene text image dataset, and comprehensive experiments and analyses were conducted. The experimental results demonstrate that the proposed algorithm achieves an F-measure of 85.02%, which is 4.71% higher than that of the baseline model. Extensive cross-dataset validations on the MSRA-TD500, ICDAR2017MLT, and ICDAR2015 datasets were also conducted to verify the generality of our approach.},
  archive      = {J_APIN},
  author       = {Guo, Hai and Wang, Tao and Yun, Jian and Zhao, Jingying},
  doi          = {10.1007/s10489-024-05951-8},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Multilingual natural scene text detection via global feature fusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NkEL: Nearest k-labelsets ensemble for multi-label learning. <em>APIN</em>, <em>55</em>(1), 1-21. (<a href='https://doi.org/10.1007/s10489-024-05968-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label learning (MLL) can be viewed as an extension of multi-class learning (MCL) that supports nonexclusive labels. Random k-labelset ensemble (RAkEL) is a popular algorithm that transforms MLL into a series of MCL tasks to exploit label correlations. However, its effectiveness is impacted by the randomness of labelset construction. In this paper, we propose an MLL algorithm with nearest k-labelsets ensemble (NkEL) possessing three techniques. First, we select a labelset with a size of k for each label using the nearest-neighbor technique. Thus, NkEL considers high-order label correlations and has strong adaptability. Second, for each MCL problem, we build a neural network to provide numerical rather than categorical predictions. Therefore, the output values represent the confidence levels of different classes. Third, we propose an intra-labelset ensemble strategy for each label. This approach alleviates the limitations imposed by low class separability with the support of the total probability theorem. Experiments are conducted on datasets derived from various domains to compare the proposed method with fourteen popular algorithms. The results obtained in terms of six ranking-based and two classification-based measures demonstrate the feasibility and effectiveness of NkEL. The source code is available at github.com/fansmale/nkel.},
  archive      = {J_APIN},
  author       = {Zhong, Xi-Yan and Zhang, Yu-Li and Wang, Dan-Dong and Min, Fan},
  doi          = {10.1007/s10489-024-05968-z},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {NkEL: Nearest k-labelsets ensemble for multi-label learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-temporal synchronous graphsage for traffic prediction. <em>APIN</em>, <em>55</em>(1), 1-17. (<a href='https://doi.org/10.1007/s10489-024-05970-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of intelligent transportation systems (ITSs) relies heavily on accurate traffic prediction, which hinges on effectively capturing spatial-temporal features. Current methodologies often address spatial and temporal dependencies separately, which limits their ability to synchronize modeling efforts. Moreover, existing graph convolutional network (GCN) approaches primarily support transductive learning and fall short in inductive tasks. To address these challenges, this paper introduces a novel spatial-temporal synchronous GraphSAGE (STS-GraphSAGE) model for traffic prediction. By integrating spatial and temporal correlations into a unified graph structure, STS-GraphSAGE achieves synchronous learning of these dependencies. Specifically, we introduce the Spearman correlation coefficient to compensate for the spatial adjacency matrix, facilitating the construction of an inclusive spatial graph. Coupled with a causal temporal graph, this forms a spatial-temporal synchronous graph that is capable of capturing intricate dependencies across both dimensions. Furthermore, our model employs multiple STS-GraphSAGE layers equipped with attention mechanisms to inductively aggregate spatial-temporal features from neighboring nodes. Extensive experiments on real-world datasets validate the effectiveness of STS-GraphSAGE, which significantly outperforms state-of-the-art baselines in traffic prediction tasks.},
  archive      = {J_APIN},
  author       = {Yu, Xian and Bao, Yinxin and Shi, Quan},
  doi          = {10.1007/s10489-024-05970-5},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Spatial-temporal synchronous graphsage for traffic prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ImageShield: A responsibility-to-person blind watermarking mechanism for image datasets protection. <em>APIN</em>, <em>55</em>(1), 1-24. (<a href='https://doi.org/10.1007/s10489-024-06093-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-quality diverse image datasets, particularly those featuring faces and medical records, are essential for deep learning applications in computer vision. Protecting the copyright and privacy of such datasets remains a challenge, as existing blind watermarking methods fall short of effectively monitoring and restricting unauthorized access. To address this issue, we propose ImageShield, a responsibility-to-person blind watermarking mechanism for image datasets protection. It introduces a hybrid approach, combining traditional transform domain watermarking with an enhanced generative adversarial network (GAN), achieving an optimal balance between watermark imperceptibility and robustness. In the extraction phase, an optimized network architecture integrates the enhanced GAN with a specially designed attack layer, improving the efficiency of watermark feature retrieval, and reducing computational overhead. The method ensures high fidelity in extracting watermark features, even under potential distortions or attacks, by leveraging the robust structure of the GAN and attack layer. Experimental results on the Helen datasets and custom datasets demonstrate ImageShield’s superiority in terms of imperceptibility (PSNR: 37.2963 dB, SSIM: 0.9906), robustness, watermark embedding capacity, and execution efficiency. These contributions offer a novel solution to enhance the security and traceability of protected image datasets.},
  archive      = {J_APIN},
  author       = {Tang, Zongwei and Yu, Junyang and Chai, Xiuli and Ma, Tianfeng and Gan, Zhihua and Wang, Binjie},
  doi          = {10.1007/s10489-024-06093-7},
  journal      = {Applied Intelligence},
  month        = {1},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {ImageShield: A responsibility-to-person blind watermarking mechanism for image datasets protection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
