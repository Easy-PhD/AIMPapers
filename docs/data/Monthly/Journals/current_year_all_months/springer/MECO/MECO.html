<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MECO</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="meco">MECO - 47</h2>
<ul>
<li><details>
<summary>
(2025). Hierarchical prompt fusion and image denoising for multimodal aspect-based sentiment analysis. <em>MECO</em>, <em>17</em>(4), 1--12. (<a href='https://doi.org/10.1007/s12293-025-00475-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Aspect-Based Sentiment Analysis (MABSA) is a fine-grained task that aims to analyze users’ sentiment polarity towards target aspects through different and rich modal contents. In conjunction with this topic, many methods have been proposed to link modalities to form interactive judgments of emotional tendencies. However, the currently proposed methods have some disadvantages: (1) Since some image modalities are unrelated to text modalities, information irrelevant to the aspect will be introduced; (2) Different modalities are difficult to complement each other during the fusion process, resulting in poor fusion performance, and the fusion process may also introduce additional noise. To address these issues, we propose a novel MABSA network model that combines a simple noise filtering approach with an innovative fast learning method for effective classification. Specifically, for the visual modality, we introduce an image content filtering (ICF) layer to filter out information that is not relevant to the aspect and text modalities. In addition, in the fusion stage, we proposed an excellent bidirectional interactive prompt fusion (BIPF) layer, which integrates prompt learning into the query and fusion stages, realizes the fusion of different modalities and contextual semantic information, and makes modal fusion more comprehensive. The outcomes of our experiments indicate that the model we developed attains leading-edge performance levels when tested on two MABSA datasets. Furthermore, a large number of experiments have shown that the model we put forward exhibits remarkable performance and robustness.},
  archive      = {J_MECO},
  author       = {Fuxian, Zhu and Xiaoli, Xu},
  doi          = {10.1007/s12293-025-00475-1},
  journal      = {Memetic Computing},
  month        = {12},
  number       = {4},
  pages        = {1--12},
  shortjournal = {Memet. Comput.},
  title        = {Hierarchical prompt fusion and image denoising for multimodal aspect-based sentiment analysis},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A parallel cooperative coevolutionary multi-verse algorithm for large-scale multi-objective UAV path planning problems. <em>MECO</em>, <em>17</em>(4), 1--32. (<a href='https://doi.org/10.1007/s12293-025-00473-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning of Unmanned Aerial Vehicles (UAVs) in complex environments with high dimensionality attempts to search for waypoint sequences always of increased size. Such a challenging task can be considered as a multi-objective Large-Scale Global Optimization (LSGO) problem where efficient solving requires more sophisticated algorithms. In this paper, a novel Parallel Cooperative Coevolutionary Multi-Objective Multi-Verse Optimization (PCCMOMVO) algorithm is developed and successfully applied. In this Cooperative Coevolutionary (CC) framework, a MOMVO algorithm is considered to design an improved subcomponent optimizer based on an allocated multi-core CPU architecture and a Message Passing Interface (MPI). The MOMVO population is divided into sub-populations, called species, where each of them is responsible for optimizing a subcomponent of the LSGO problem according to the “divide-and-conquer” concept of CC framework. To form a complete candidate solution of the whole LSGO path planning problem, each species shares a number of representative solutions selected from the Pareto non-dominated ones found so far. The selection process is based on the Pareto ranks achieved by the use of a Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS). A parallelization mechanism based on a simple yet efficient master–slave model and allocated MPI is implemented to provide acceleration in computation runtime. Demonstrative results and ANOVA tests are presented over planning scenarios with increased complexity to demonstrate the superiority and effectiveness of the PCCMOMVO algorithm. Extensive evaluations and comparisons are carried out in terms of collision-avoidance capabilities, path shortness and efficiency against the curse of dimensionality and computational time consumption.},
  archive      = {J_MECO},
  author       = {Jarray, Raja and Bouallègue, Soufiene},
  doi          = {10.1007/s12293-025-00473-3},
  journal      = {Memetic Computing},
  month        = {12},
  number       = {4},
  pages        = {1--32},
  shortjournal = {Memet. Comput.},
  title        = {A parallel cooperative coevolutionary multi-verse algorithm for large-scale multi-objective UAV path planning problems},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive binary particle swarm optimization algorithm with filtration and local search for feature selection in text classification. <em>MECO</em>, <em>17</em>(4), 1--21. (<a href='https://doi.org/10.1007/s12293-025-00481-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary Particle Swarm Optimization (BPSO) has demonstrated effectiveness in discrete data feature selection; however, its performance diminishes in high-dimensional feature spaces. To address this limitation, we present a novel memetic algorithm called Filtration and Local Search-based Binary Particle Swarm Optimization (FLS-BPSO), designed to enhance efficiency and facilitate rapid feature selection in text classification. The algorithm initiates by constructing an initial feature subset using mutual information as a filter-based method. To mitigate unnecessary computation and reduce time complexity, particles showing no improvement after a specific iteration count are filtered out during the process. Achieving a balance between exploration and exploitation, an inertia weight is dynamically updated, accounting for swarm size. Additionally, to maintain diversity and prevent convergence to local optima, a local search technique is applied to the best remaining particles, considering three feature groups: strong, weak, and confusing features. Experimental evaluations on five diverse datasets compare the performance of FLS-BPSO with standard BPSO, the Simulated Annealing (SA) algorithm, and the Genetic Algorithm (GA). Results demonstrate the superiority of FLS-BPSO in terms of classification performance, expressed in terms of micro-F1 score, high feature space reduction rate, and low computational cost when using three classification techniques (NB, SVM, and LSTM), exhibiting enhanced classification accuracy and robustness across multiple datasets varying between binary and multi-class.},
  archive      = {J_MECO},
  author       = {Farek, Lazhar and Benaidja, Amira},
  doi          = {10.1007/s12293-025-00481-3},
  journal      = {Memetic Computing},
  month        = {12},
  number       = {4},
  pages        = {1--21},
  shortjournal = {Memet. Comput.},
  title        = {An adaptive binary particle swarm optimization algorithm with filtration and local search for feature selection in text classification},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Facial emotion recognition based on ResNet18 with multi-dimensional attention mechanisms. <em>MECO</em>, <em>17</em>(4), 1--17. (<a href='https://doi.org/10.1007/s12293-025-00476-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion, as a fundamental characteristic of humans, is the most important non-verbal way of expressing inner feelings and intentions, playing a crucial role in communication. Although various deep learning frameworks have been applied to the field of emotion recognition, facial images contain rich emotional features in the eyebrows, mouth corners, eyes, as well as changes in skin tone, light-shadow contrast, and muscle tension distribution. How to effectively characterize these emotional features from multiple dimensions remains a significant challenge in facial emotion recognition. This study proposes an enhanced ResNet18 architecture incorporating three specialized attention mechanisms: (1) channel-wise attention for feature refinement, (2) spatial attention for regional emphasis, and (3) multi-scale attention for hierarchical feature fusion. This synergistic design enables comprehensive integration of features across global contexts, local details, and varying granularities, significantly improving facial emotion recognition accuracy. Our model was evaluated on the DEAP dataset for classification experiments based on arousal and valence. The binary classification accuracy for valence and arousal reached 99.21% and 99.20%, respectively, while the accuracy for four-class emotion recognition was 97.45%. Experimental results demonstrate that our proposed method can effectively extract multi-dimensional features from facial expressions and improve the accuracy and robustness of emotion recognition. Our approach provides innovative feature extraction techniques and a theoretical foundation for emotion recognition based on facial images, offering significant reference value for enhancing recognition accuracy.},
  archive      = {J_MECO},
  author       = {Xi, Yang and Wu, Chenxue and Meng, Tianyu and Li, Cunzhen},
  doi          = {10.1007/s12293-025-00476-0},
  journal      = {Memetic Computing},
  month        = {12},
  number       = {4},
  pages        = {1--17},
  shortjournal = {Memet. Comput.},
  title        = {Facial emotion recognition based on ResNet18 with multi-dimensional attention mechanisms},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An ensemble event extraction method on news. <em>MECO</em>, <em>17</em>(4), 1--14. (<a href='https://doi.org/10.1007/s12293-025-00479-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Navigating through the complexities of news to extract pivotal events demands innovative methodologies to ensure accurate and reliable outcomes. This paper introduces a novel ensemble approach for event extraction, synergizing multiple models to enhance accuracy and reliability amidst the strategic and operational intricacies of news. A key metric, the Confidence Score (CS), quantifies the reliability and credibility of extracted events, serving as a robust indicator of a model’s assurance in its predictions and providing a mechanism to navigate through ambiguities in the data. The paper offers a holistic representation and estimation of the confidence of individual model outputs. A comprehensive CS evaluation method is introduced, integrating consistency and prior confidence of multi-model output, and is augmented by an iterative update algorithm, enhancing CS evaluation accuracy by comparing consistency of pairwise outputs of identical arguments and updating the CS in a weighted manner based on prior scores. Experiments conducted on a dataset compiled from online news underscore the notable improvement of our method in comparison to both singular model and prevalent ensemble strategies, demonstrating its efficacy and potential applicability in practice.},
  archive      = {J_MECO},
  author       = {Liu, Lihua and Chen, Haiwen and Ge, Ningchao and Xiao, Kaiming and Wu, Jibing and Li, Xuan and Huang, Hongbin},
  doi          = {10.1007/s12293-025-00479-x},
  journal      = {Memetic Computing},
  month        = {12},
  number       = {4},
  pages        = {1--14},
  shortjournal = {Memet. Comput.},
  title        = {An ensemble event extraction method on news},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An estimation of distribution algorithm-based hyper-heuristic for the blocking flowshop group scheduling problem. <em>MECO</em>, <em>17</em>(3), 1--28. (<a href='https://doi.org/10.1007/s12293-025-00454-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its practical relevance in many industrial applications, the blocking flowshop group scheduling problem (BFGSP) has gained more and more attentions in recent years. This paper presents a novel estimation of distribution algorithm-based hyper-heuristic (EDA-HH) to minimize the makespan criterion of the BFGSP. In EDA-HH, two constructive heuristics are devised based on the problem’s properties to generate high-quality initial individuals (i.e., BFGSP’s solutions). Meanwhile, an improved estimation distribution algorithm (EDA) and eleven efficient heuristics are designed in its higher and lower levels, respectively. The improved EDA is utilized not only to reasonably accumulate the valuable information of high-level permutations constructed by low-level heuristics, but also to dynamically generate excellent permutations to determine the suitable execution order of these heuristics. Moreover, to further enhance the search efficiency, two speedup scanning methods according to the problem’s properties are devised to evaluate each individual. Extensive simulations and comparisons on 560 benchmark instances demonstrate that the proposed EDA-HH can achieve better solution than nine state-of-the-art algorithms.},
  archive      = {J_MECO},
  author       = {Zhang, Sen and Qian, Bin and Hu, Rong and Zhang, Zi-qi and Shang, Qingxia and Li, Zuocheng and Wang, Ling},
  doi          = {10.1007/s12293-025-00454-6},
  journal      = {Memetic Computing},
  month        = {9},
  number       = {3},
  pages        = {1--28},
  shortjournal = {Memet. Comput.},
  title        = {An estimation of distribution algorithm-based hyper-heuristic for the blocking flowshop group scheduling problem},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A clustering-based weighted optimization algorithm for large-scale multi-objective optimization problems. <em>MECO</em>, <em>17</em>(3), 1--32. (<a href='https://doi.org/10.1007/s12293-025-00459-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A weighted optimization framework based on problem transformation is an effective method for solving large-scale multi-objective optimization problems (LSMOPs). The problem transformation approach searches an area that is close to the reference solutions by using transformation functions to ensure rapid population convergence. Clustering-based methods can help identify critical regions or representative sets of solutions in the solution space, and can be used to select reference solutions. Accordingly, a clustering-based weighted optimization algorithm is proposed in this paper to solve LSMOPs. First, a combination of hierarchical clustering and partitional clustering is used to select reference solutions from the current population. The clustering selection method makes the selected solutions more diverse, and the reference solutions are used to guide the search direction for performing weighted optimization. Second, a power value transformation method is designed during the problem transformation stage. The transformation can alter the method for mapping the decision variables and effectively reduce the original decision space. Finally, an adaptive method for allocating the number of fitness evaluations is proposed to reasonably distribute computing resources throughout the evolutionary process. The proposed algorithm is tested on two benchmark large-scale multi-objective optimization test problem suites, and seven competitive multi-objective optimization algorithms are compared with it. The experimental results show that the proposed algorithm has advantages over the state-of-the-art algorithms in terms of search performance and convergence speed.},
  archive      = {J_MECO},
  author       = {Wang, Hao and Zhu, Shuwei and Fang, Wei},
  doi          = {10.1007/s12293-025-00459-1},
  journal      = {Memetic Computing},
  month        = {9},
  number       = {3},
  pages        = {1--32},
  shortjournal = {Memet. Comput.},
  title        = {A clustering-based weighted optimization algorithm for large-scale multi-objective optimization problems},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-adaptive competitive swarm optimizer: A memetic approach for global optimization and human-powered aircraft design. <em>MECO</em>, <em>17</em>(3), 1--37. (<a href='https://doi.org/10.1007/s12293-025-00465-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a memetic approach of Competitive Swarm Optimizer (CSO) named Self-Adaptive Competitive Swarm Optimizer (SACSO). We focus on two key parameters of CSO: scaling factor and population size and introduce a parameter sorting scheme and a linear population reduction strategy to enhance the performance of SACSO. Specifically, the parameter sorting scheme assigns smaller scaling factors to better-performing particle individuals to encourage exploitative searchability, while larger scaling factors are allocated to poor-performing particle individuals to promote exploration in unknown search areas. The linear population reduction strategy adapts to different optimization phases, emphasizing exploration in the early phase and enhancing exploitation in the later phase. To investigate the performance of SACSO, we conducted comprehensive numerical experiments on CEC2017, CEC2022, and seven classic engineering problems. The experimental results and statistical analysis demonstrate the competitiveness of SACSO against six state-of-the-art optimizers and four advanced CSO variants. Ablation studies further validate the contribution of the two introduced strategies. Finally, we applied SACSO to real-world Human-Powered Aircraft (HPA) design problems, and the results highlight the potential of SACSO for solving various real-world optimization challenges. The source code of SACSO is available at https://github.com/RuiZhong961230/SACSO .},
  archive      = {J_MECO},
  author       = {Zhong, Rui and Wang, Zhongmin and Al-Shourbaji, Ibrahim and Houssein, Essam H. and Kachare, Pramod H. and Jabbari, Abdoh and Kirner, Raimund and Yu, Jun},
  doi          = {10.1007/s12293-025-00465-3},
  journal      = {Memetic Computing},
  month        = {9},
  number       = {3},
  pages        = {1--37},
  shortjournal = {Memet. Comput.},
  title        = {Self-adaptive competitive swarm optimizer: A memetic approach for global optimization and human-powered aircraft design},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recent advancement of metaheuristic optimization algorithms-based learning for breast cancer diagnosis: A review. <em>MECO</em>, <em>17</em>(3), 1--22. (<a href='https://doi.org/10.1007/s12293-025-00467-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is the most prevalent cancer among women globally and ranks as a primary cause of cancer-related mortality, surpassed only by lung cancer. The condition arises from the atypical growth of cells in the breast ducts, which, if unrecognized, may result in serious health consequences. Conventional diagnostic techniques, including as mammography, ultrasound, and histology, have greatly aided in detection but frequently face limitations related to accuracy, reliability, and scalability. The advent of artificial intelligence (AI) and metaheuristic optimization algorithms has created novel prospects to transform breast cancer diagnosis. These methods, derived from biological, evolutionary, and swarm intelligence mechanisms, provide effective solutions for intricate optimization challenges, such as feature selection, image classification, and dimensionality reduction. This paper examines current developments in metaheuristic optimization algorithms and their application to breast cancer diagnosis, emphasizing three principal methodologies. The initial component is the Twin Convolutional Neural Network (TwinCNN) combined with the Binary Ebola Optimization Search Algorithm (BEOSA), a multimodal strategy that tackles the difficulties of categorizing breast cancer images obtained from several modalities. This approach attained cutting-edge classification accuracies of 97.7% for histology and 91.3% for mammography datasets. The second method involves Particle Swarm Optimization (PSO) integrated with Spatially Constrained Adaptively Regularized Kernel-Based Fuzzy C-Means (ScARKFCM) clustering, achieving a notable accuracy of 92.6% on the MIAS dataset, highlighting its efficacy in breast cancer image segmentation and classification. The enhanced Ant Colony Optimization method integrated with Residual Network-101 CNN illustrates the synergy between optimization and deep learning techniques},
  archive      = {J_MECO},
  author       = {Awotwe, Samuel and Dufera, Amanuel Tafese and Yi, Wenhui},
  doi          = {10.1007/s12293-025-00467-1},
  journal      = {Memetic Computing},
  month        = {9},
  number       = {3},
  pages        = {1--22},
  shortjournal = {Memet. Comput.},
  title        = {Recent advancement of metaheuristic optimization algorithms-based learning for breast cancer diagnosis: A review},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual evolutionary algorithm based on dyna-Q for distributed heterogeneous hybrid flow shop problems with L-R trapezoidal fuzzy numbers. <em>MECO</em>, <em>17</em>(3), 1--26. (<a href='https://doi.org/10.1007/s12293-025-00468-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of manufacturing, distributed manufacturing models have been applied to hybrid flow shop scheduling problems (HFSP). The variability among different factories renders traditional scheduling methods based on single-factory models no longer applicable. Furthermore, real-world production processes are inevitably influenced by changes in factors such as equipment conditions, worker skills, and production environments, leading to uncertainties in the processing times of machine operations. To address this problem, a dual evolutionary algorithm based on Dyna-Q is proposed. Trapezoidal fuzzy numbers are used to represent uncertain processing times, aiming to solve the heterogeneous hybrid flow shop scheduling problem (HHFSP) with the objectives of minimizing the makespan and total energy consumption (TEC). First, three efficient initialization methods are proposed to generate high-quality initial populations. Second, two evolutionary algorithms with different search directions are designed to enhance population diversity and convergence, respectively. Furthermore, a Dyna-Q-based selector is introduced to adaptively choose the optimal solver under the current state, achieving a balance between exploration and exploitation. Finally, extensive experiments are conducted to validate the effectiveness and efficiency of the proposed algorithm.},
  archive      = {J_MECO},
  author       = {Xia, Liangcai and Chen, Shijun and Zhou, Weigang and Wang, Qian and Xu, Jiying},
  doi          = {10.1007/s12293-025-00468-0},
  journal      = {Memetic Computing},
  month        = {9},
  number       = {3},
  pages        = {1--26},
  shortjournal = {Memet. Comput.},
  title        = {Dual evolutionary algorithm based on dyna-Q for distributed heterogeneous hybrid flow shop problems with L-R trapezoidal fuzzy numbers},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Measures of exploration and exploitation rates in MAs: Classification, comparison, and convergence analysis. <em>MECO</em>, <em>17</em>(3), 1--42. (<a href='https://doi.org/10.1007/s12293-025-00469-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploration and exploitation are fundamental components of metaheuristic algorithms (henceforth MAs), essential for optimizing performance and achieving superior results. Exploration involves visiting diverse regions within the search space, while exploitation focuses on refining solutions near previously visited areas. Balancing these components is critical, necessitating accurate measurement and control during the optimization process. This paper presents a comprehensive review and empirical evaluation of strategies for quantifying and analyzing exploration-exploitation dynamics in MAs. We investigate eight well-established algorithms, using 12 benchmark functions from the CEC 2022 suite to assess the validity of various measurement techniques. Multiple statistical and visual tools, including 3D trajectory maps, heat maps, and attraction basins, are employed to examine these dynamics. We also analyze Pearson and Spearman correlation coefficients and exploration ratios for each algorithm across the selected indicators. The results reveal that the Attraction Basin and Diversity-based methods most accurately capture the true exploration-exploitation behaviour. In parallel, the TLBO and OOBO algorithms consistently demonstrate superior performance across various test functions and dimensions, owing to their well-regulated balance. These findings are reinforced by a detailed statistical analysis, including Friedman tests. To the best of our knowledge, this study is the first to offer such a comprehensive investigation, contributing to the field of optimization by guiding future research and aiding in the development of more robust and efficient MAs.},
  archive      = {J_MECO},
  author       = {Ferhat, Aridj and Zitouni, Farouq and Lakbichi, Rihab and Limane, Abdelhadi and Harous, Saad},
  doi          = {10.1007/s12293-025-00469-z},
  journal      = {Memetic Computing},
  month        = {9},
  number       = {3},
  pages        = {1--42},
  shortjournal = {Memet. Comput.},
  title        = {Measures of exploration and exploitation rates in MAs: Classification, comparison, and convergence analysis},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-start algorithm with iterated decremental local search for minimum capacitated dominating set problem in large graphs. <em>MECO</em>, <em>17</em>(3), 1--35. (<a href='https://doi.org/10.1007/s12293-025-00470-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Minimum Capacitated Dominating Set (CAPMDS) problem involves finding a dominating set with the minimum cardinality, subject to the constraint that each vertex in the dominating set cannot dominate more vertices than its associated capacity allows. CAPMDS is a crucial variant of the dominating set problem and finds applications in various domains, including wireless sensor networks and information retrieval. While researchers have devoted significant attention to CAPMDS, existing approaches often struggle to scale up and can be time-consuming. In this study, we aim to enhance the scalability and efficiency of solving the CAPMDS problem. We introduce a novel multi-start algorithm with an iterated decremental local search (MSIDLS) that incorporates several innovative concepts. Firstly, we develop an adaptive initialization process with varying degrees of greediness to generate an initial solution. Subsequently, an iterated decremental local search is executed to improve the initial solution, consistently reducing the solution’s cardinality. Notably, we introduce a dynamic vertex weighting score function with a forgetting mechanism to assess the suitability of inserting or removing a vertex from the dominating set. Furthermore, we present a new reallocation strategy based on the constraint path within the iterated decremental local search, intensifying the quality of the solution. To validate our approach, we conduct experiments on large graphs with both uniform and variable capacity. The computational results demonstrate that MSIDLS outperforms state-of-the-art algorithms, consistently achieving superior best and average objective values. Our experiments on large graphs also verify the effectiveness of the reallocation strategy and the score function with forgetting.},
  archive      = {J_MECO},
  author       = {Hu, Shuli and Zhou, Shuang and Ling, Dian and Li, Jiaqi and Li, Ruizhi and Zhou, Yupeng and Yin, Minghao},
  doi          = {10.1007/s12293-025-00470-6},
  journal      = {Memetic Computing},
  month        = {9},
  number       = {3},
  pages        = {1--35},
  shortjournal = {Memet. Comput.},
  title        = {A multi-start algorithm with iterated decremental local search for minimum capacitated dominating set problem in large graphs},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A flattened-tree genetic programming approach with multi-scale feature extraction for image classification. <em>MECO</em>, <em>17</em>(3), 1--19. (<a href='https://doi.org/10.1007/s12293-025-00472-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic programming (GP) approaches have shown considerable potential in image classification. However, the inherent complexity of deep and wide tree structures in existing GP methods often leads to issues such as overfitting and redundancy. Additionally, most of the traditional GP approaches focus on feature extraction from either the original image or its local regions, overlooking the multi-scale image information that could improve classification performance. To this end, a flattened-tree GP approach with multi-scale feature extraction for image classification is proposed. Specifically, we propose a flattened-tree GP program structure incorporating specialized functions and terminal sets. This structure allows for an efficient combination of features while minimizing redundancy and enhancing feature learning quality. By avoiding the complexity that may be associated with deep and wide tree structures, the proposed approach reduces overfitting and improves model performance. Then, a novel region resampling layer that enables multi-scale feature extraction is suggested in the proposed GP program structure. This layer allows GP to capture global and local features on different scales, enhancing the model’s ability to learn more discriminative feature representations. By integrating multi-scale information, the model could better adapt to varying patterns within images. Finally, we validate the proposed approach on eight diverse datasets compared with the state-of-the-arts. The experimental results show the superiority of our proposed approach in image classification, achieving higher accuracy and better generalization. Visual analysis of optimal GP individuals further highlights the interpretability and effectiveness of learned characteristics with our proposed approach.},
  archive      = {J_MECO},
  author       = {Qiu, Jianfeng and Ding, Mingshuai and Li, Kaixuan and Zhang, Lei and Wang, Chao and Xie, Juan and Cheng, Fan},
  doi          = {10.1007/s12293-025-00472-4},
  journal      = {Memetic Computing},
  month        = {9},
  number       = {3},
  pages        = {1--19},
  shortjournal = {Memet. Comput.},
  title        = {A flattened-tree genetic programming approach with multi-scale feature extraction for image classification},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel ensemble learning-based model for APT attack detection. <em>MECO</em>, <em>17</em>(3), 1--19. (<a href='https://doi.org/10.1007/s12293-025-00474-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the effectiveness of APT attack detection models is one of the most critical and essential tasks today. Following this trend, this paper proposes a new model called ACDF-mLSTM to address two primary challenges currently faced by research in this field: (i) data imbalance and (ii) information aggregation and feature extraction. Specifically, to solve the data imbalance problem, the paper proposes a novel data generation method named ACDF. This method leverages advanced and sophisticated techniques to focus on identifying crucial points in sequential data and analyzing context by considering preceding and succeeding data points. Subsequently, a Diffusion Model is applied to generate synthetic APT attack data, built upon the principle of gradual diffusion. With this approach, the ACDF model can generate more meaningful and realistic data. Next, to address the task of information aggregation and feature extraction, the paper proposes a new deep learning model named mLSTM, based on the optimization of Long Short-Term Memory (LSTM). Thus, the mLSTM model performs two main tasks: (i) extracting information from network flows within traffic and (ii) aggregating and highlighting important information before it enters the classification model. In the experimental section, the paper evaluates the ACDF-mLSTM model for the first time across various scenarios and datasets to demonstrate its effectiveness and adaptability. The evaluation results show that the ACDF-mLSTM model outperformed most other methods by an average of 2 to 12% across all metrics and on all experimental datasets.},
  archive      = {J_MECO},
  author       = {Duc, Vu Thanh and Do Xuan, Cho and Long, Vu Thanh},
  doi          = {10.1007/s12293-025-00474-2},
  journal      = {Memetic Computing},
  month        = {9},
  number       = {3},
  pages        = {1--19},
  shortjournal = {Memet. Comput.},
  title        = {A novel ensemble learning-based model for APT attack detection},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-task multi-objective evolutionary algorithm for constrained multi-objective optimization problems. <em>MECO</em>, <em>17</em>(3), 1--29. (<a href='https://doi.org/10.1007/s12293-025-00471-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective evolutionary algorithms often struggle to simultaneously achieve both objective optimization and constraint satisfaction, particularly when dealing with multi-objective optimization problems that involve complex constraints. To address these issues, this paper proposes a multi-task multi-objective evolutionary algorithm (MTMOEA) to solve constrained multi-objective optimization problems. The algorithm includes three optimization tasks: one original task and two auxiliary tasks. Among the auxiliary tasks, one is the unconstrained optimization task with all constraints removed, and the other is the optimization task with partial constraints applied. For the unconstrained task, an optimization stopping strategy is adopted to determine whether to halt further optimization, thereby avoiding unnecessary computational resource usage. For the partially constrained task, a classification-based dynamic constraint updating strategy is employed to ensure that the task focuses on constraints that have a greater impact on problem-solving. Based on the characteristics of the three tasks, a knowledge transfer strategy, which includes two different knowledge transfer methods, is proposed. The proposed MTMOEA is evaluated against ten state-of-the-art constrained multi-objective evolutionary algorithms on three benchmark sets: LIRCMOP, DOC, and DASCMOP. Experimental results validate the effectiveness of the proposed algorithm.},
  archive      = {J_MECO},
  author       = {Liu, Tianyu and Wu, Yu and Xu, He},
  doi          = {10.1007/s12293-025-00471-5},
  journal      = {Memetic Computing},
  month        = {9},
  number       = {3},
  pages        = {1--29},
  shortjournal = {Memet. Comput.},
  title        = {A multi-task multi-objective evolutionary algorithm for constrained multi-objective optimization problems},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tri-objective hybrid genetic programming for transparent and effective entity matching via optimized similarity measure combination. <em>MECO</em>, <em>17</em>(3), 1--18. (<a href='https://doi.org/10.1007/s12293-025-00477-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity matching plays a critical role in data integration, decision-making, and interoperability across diverse datasets. Its effectiveness heavily depends on the design and integration of Similarity Measures (SMs), which quantify relationships between entities. However, no single SM consistently performs well across heterogeneous scenarios, necessitating an optimized combination for robust alignment. While Genetic Programming (GP) has been increasingly adopted for automating SM combination, it often generates complex and opaque feature sets, limiting interpretability and user trust. To address these challenges, this paper proposes a Tri-Objective Hybrid Genetic Programming (TOHGP) framework that optimizes SM combinations while ensuring matching accuracy, interpretability, and efficiency. Unlike traditional Single-Objective Evolutionary Algorithms (SOEAs) that optimize a single metric, TOHGP leverages a tri-objective evaluation strategy to effectively manage competing objectives. Additionally, an adaptive constant refinement mechanism dynamically adjusts constants in Pareto-optimal solutions, improving search performance without unnecessary computational overhead. Experimental experiments on OAE’s Conference datasets demonstrate that TOHGP consistently outperforms state-of-the-art methods, achieving higher-quality alignments with improved interpretability and reliability.},
  archive      = {J_MECO},
  author       = {Gao, Fan and Luo, Bing and Yang, Ya-Juan},
  doi          = {10.1007/s12293-025-00477-z},
  journal      = {Memetic Computing},
  month        = {9},
  number       = {3},
  pages        = {1--18},
  shortjournal = {Memet. Comput.},
  title        = {Tri-objective hybrid genetic programming for transparent and effective entity matching via optimized similarity measure combination},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensemble of simple optimizers. <em>MECO</em>, <em>17</em>(3), 1--24. (<a href='https://doi.org/10.1007/s12293-025-00478-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a set of simple metaheuristic approaches are integrated into an ensemble optimization algorithm, called the Ensemble of Simple Optimizers (EnSO). The simple optimizers share information through a stochastic elite guidance mechanism. The proposed approach is compared with its components and other state-of-the-art metaheuristics on 49 optimization problems. The results show that the ensemble strategy improves the performance of the optimization algorithm, converting the simple and weak optimizers into a stronger one. In addition, this ensemble of simple optimizers compete well with the other more complex and advance optimization methods. In general, the results show that EnSO is a viable and efficient optimization method.},
  archive      = {J_MECO},
  author       = {Omran, Mahamed G. H. and Salman, Ayed and Clerc, Maurice},
  doi          = {10.1007/s12293-025-00478-y},
  journal      = {Memetic Computing},
  month        = {9},
  number       = {3},
  pages        = {1--24},
  shortjournal = {Memet. Comput.},
  title        = {Ensemble of simple optimizers},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reordering-enhanced grad-CAM for unveiling hidden patterns in multi-source financial data. <em>MECO</em>, <em>17</em>(2), 1--16. (<a href='https://doi.org/10.1007/s12293-025-00443-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) excel in feature extraction and pattern recognition in areas like image classification and speech processing. However, their application in the financial sector has been limited due to the complexity, high dimensionality, and temporal nature of financial data, as well as the need for model interpretability. This study, based on CNN technology, proposes a Reordering-Enhanced Grad-CAM algorithm to improve model interpretability and reliability, offering transparent and dependable tools for financial decision-making. The innovation of this study lies in two key aspects: firstly, it replaces the traditional manual variable selection approach with automatic feature extraction and fusion using CNNs, demonstrating the effectiveness of deep learning in handling large-scale financial data. Secondly, we propose a novel reordering-based iterative algorithm that adapts Grad-CAM, originally designed for image classification, to multi-source financial time series data, treating sliding window data segments as pseudo-images to improve interpretability and identify critical features. Using data from Shanghai and Shenzhen A-shares (1990–2020), the Reordering-Enhanced Grad-CAM technique generated heatmaps that identified key predictive indicators, leading to improved model performance. Robustness analysis demonstrated that over 70% of important variables were consistently identified, with some models reaching up to 100%, confirming the reliability and stability of our method in financial distress prediction.},
  archive      = {J_MECO},
  author       = {Zhang, Zhigang and Liu, Kehui and Lei, Junli},
  doi          = {10.1007/s12293-025-00443-9},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--16},
  shortjournal = {Memet. Comput.},
  title        = {Reordering-enhanced grad-CAM for unveiling hidden patterns in multi-source financial data},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AIM: An accurate and explainable model for ATAC to GEX translation and pathway analysis. <em>MECO</em>, <em>17</em>(2), 1--21. (<a href='https://doi.org/10.1007/s12293-025-00442-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of multimodal technologies has enabled the simultaneous measurement of various cellular modalities, such as chromatin accessibility (ATAC), gene expression (GEX), and surface protein abundance in single cells. However, the lack of multimodal datasets requires the development of robust algorithms that can translate data between different modalities. In this study, we present AIM, a framework for accurate and interpretive multimodal translation, specifically designed for the conversion of ATAC data into GEX profiles. AIM introduces a novel two-tier modeling architecture. The upper tier captures the global relationships between ATAC and GEX, generating an initial estimate of gene expression. The lower tier performs a finer-grained analysis by modeling inter-chromosomal interactions to refine the generated GEX representation. This modular structure enhances both the accuracy and adaptability of AIM. Additionally, an integrated attention mechanism provides interpretability by highlighting critical chromatin regions influencing specific gene expressions. Our experimental results demonstrate that AIM achieves state-of-the-art performance, with a per-chromosome RMSE of 0.2206, outperforming existing approaches (0.2232). Furthermore, the attention maps generated by AIM offer a pathway analysis capability, uncovering biologically significant gene-gene interactions such as ARHGAP24-ARAP2 and SYK-PAX5. These findings validate AIM’s effectiveness not only as a data translation tool but also as a platform for deriving mechanistic insights into gene regulatory dynamics.},
  archive      = {J_MECO},
  author       = {Nguyen, Quang H. and Tran, Hoang V. and Nguyen, Huu Tien and Le, Phuong T. M. and Nguyen, Phi Le and Nguyen, Binh P.},
  doi          = {10.1007/s12293-025-00442-w},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--21},
  shortjournal = {Memet. Comput.},
  title        = {AIM: An accurate and explainable model for ATAC to GEX translation and pathway analysis},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bagging-based ensemble classifiers using multi-objective genetic programming. <em>MECO</em>, <em>17</em>(2), 1--17. (<a href='https://doi.org/10.1007/s12293-025-00444-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective evolutionary computation algorithm, genetic programming (GP) can be designed as effective classifiers due to its flexible representation method. However, the classification performance of GP classifiers can be degraded due to imbalanced data and weak generalization ability. Precision-recall curve (PRC) has been proven to be an effective evaluation metric for dealing with imbalanced data. However, PRC may result in classifiers with the same PRC value being completely different classifiers. Moreover, controlling the complexity of GP individuals can improve their generalization ability. Therefore, in this paper, multi-objective GP (MOGP) is used to optimize three objectives including recall, precision and model complexity to reduce the impact of imbalanced data and improve the generalization of GP individuals. MOGP-based ensemble classifier construction methods can improve the generalization ability of classification models. However, this strategy needs to address the issues of how to improve the diversity of GP solutions and select optimal solutions from Pareto fronts. Therefore, in this paper, a bagging-based ensemble classifier construction method is proposed to improve the generalization of GP classifiers, which uses non-repeated sampling to generate multiple training subsets and runs MOGP multiple times on these training subsets to construct ensembles. Experiments on ten datasets show that our MOGP-based classifier construction method can achieve better classification performance than single-objective GP classifier construction methods, and our bagging-based ensemble classifier construction methods can further improve the classification performance compared to only using MOGP. Comparisons with six state-of-the-art GP classifier construction methods and six traditional machine learning algorithms show that our proposed approach can achieve significantly better classification performance in most cases.},
  archive      = {J_MECO},
  author       = {Zheng, Yang and Zhang, Fan and Gao, Xiaoying and Ma, Jianbin},
  doi          = {10.1007/s12293-025-00444-8},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--17},
  shortjournal = {Memet. Comput.},
  title        = {Bagging-based ensemble classifiers using multi-objective genetic programming},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multifactorial memetic algorithm with adaptive auxiliary tasks for service migration optimization in mobile edge computing. <em>MECO</em>, <em>17</em>(2), 1--23. (<a href='https://doi.org/10.1007/s12293-025-00448-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high-speed mobile networks, mobile edge computing is tasked with service migration optimization, i.e., assigning mobile users to the right servers to minimize the response time. Service migration optimization is a complex problem posing significant challenges to conventional optimization methods. To tackle this problem, we develop a multifactorial memetic algorithm with adaptive auxiliary tasks or MFMA-AAT for short. MFMA-AAT solves the target service migration optimization problem and an adaptively selected auxiliary task simultaneously, where the auxiliary task is a simplified version of the target problem to guide the search towards promising regions faster via knowledge transfer. Multiple auxiliary tasks are pre-constructed based on the distribution of the mobile users and the one with the best improvement at each generation is selected for knowledge transfer. A community detection-based memetic operator is also introduced to accelerate the local convergence of the proposed algorithm. Experimental results on test problems demonstrate that MFMA-AAT is more efficient than traditional service migration approaches and other state-of-the-art multifactorial evolutionary algorithms.},
  archive      = {J_MECO},
  author       = {Li, Guo and Liu, Zhaobo and Liu, Ling and Zhu, Zexuan},
  doi          = {10.1007/s12293-025-00448-4},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--23},
  shortjournal = {Memet. Comput.},
  title        = {Multifactorial memetic algorithm with adaptive auxiliary tasks for service migration optimization in mobile edge computing},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving multi-objective energy-efficient flexible job shop problems by a dual-level NSGA-II algorithm. <em>MECO</em>, <em>17</em>(2), 1--29. (<a href='https://doi.org/10.1007/s12293-025-00449-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incorporating energy consumption into optimization has attracted increasing attention in both academia and industry. Nevertheless, the integration of green, flexible, and dynamic manufacturing in literature remains underexplored. To this end, we focus on a dynamic flexible job shop scheduling problem (dFJSP) relevant to aerospace structural components. The following challenging issues are considered, such as processing route flexibility, limited machine and tool resources, transportation time, setup time, new job arrivals, machine breakdowns, and various machine processing speeds. To address this complex problem, a dual-level multi-objective algorithm based on the nondominated sorting genetic algorithm II (hereafter called DLNSGAII) is developed. The first level incorporates a dynamic diffusion-based strategy (D-DBS), which aims to balance exploration and exploitation effectively. This is achieved by quickly identifying high-quality solutions and discarding inferior ones while also ensuring ample computational resources allocated for exploration to avoid convergence on local optima. At the second level, a static convergence-based search strategy (S-CBS) is conducted to allocate resources according to the potential of solutions to achieve faster convergence. Additionally, to tackle the disruptions, two sets of rescheduling mechanisms have been designed: one includes five strategies for integrating new job arrivals, and another encompasses two strategies for responding to machine breakdowns. Furthermore, to enhance the search capabilities toward different objectives, two critical-path-based neighborhood structures have been incorporated. Utilizing hypervolume (HV) and inverted generational distance (IGD) as evaluation metrics, a comparative analysis of algorithmic performance was conducted. Among the 35 experiments, DLNSGAII exhibited superiority in 88.57% and 63% of the total experiments based on the HV and IGD metrics, respectively, emphasizing its advantages in terms of convergence and generalizability.},
  archive      = {J_MECO},
  author       = {Li, Junqing and Zhang, Weimeng and Li, Jiake},
  doi          = {10.1007/s12293-025-00449-3},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--29},
  shortjournal = {Memet. Comput.},
  title        = {Solving multi-objective energy-efficient flexible job shop problems by a dual-level NSGA-II algorithm},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage memetic algorithm for green flexible job shop scheduling problem considering machine deterioration and maintenance. <em>MECO</em>, <em>17</em>(2), 1--33. (<a href='https://doi.org/10.1007/s12293-025-00450-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The green flexible job shop scheduling problem (GFJSP) has received widespread attention in the context of Industry 5.0. However, the often-overlooked machine deterioration and maintenance during production result in a gap between scheduling plans and their practical applications. This study develops a model for green flexible job shop scheduling that considers machine deterioration and maintenance (GFJSP-DM) and proposes an enhanced two-stage memetic algorithm (ETMA) for its resolution. In the exploration stage, a heuristic hybrid initialization strategy is employed to generate diverse, high-quality individuals; in addition, a potential solution selection strategy aids the model-driven variable neighborhood local search to conduct a more detailed and effective exploration of the objective space. During the optimization stage, the algorithm presents a right-shift energy-saving strategy, designed based on inverse decoding, to evaluate four scenarios of delayed processing, further reducing the total energy consumption of the scheduling plans. Finally, extensive experimental results on test instances demonstrate that ETMA can effectively solve the GFJSP-DM problem.},
  archive      = {J_MECO},
  author       = {Zhu, Guoqiang and Liu, Jianfeng and Gong, Wenyin},
  doi          = {10.1007/s12293-025-00450-w},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--33},
  shortjournal = {Memet. Comput.},
  title        = {Two-stage memetic algorithm for green flexible job shop scheduling problem considering machine deterioration and maintenance},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-objective influence maximization with consideration of node burden. <em>MECO</em>, <em>17</em>(2), 1--16. (<a href='https://doi.org/10.1007/s12293-025-00452-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximization of influence seeks to identify a set of nodes with the greatest influence within a network. While influence has been the primary focus, the burden of nodes defined as their capacity to serve influenced nodes, such as the storage capacity in device-to-device networks has been overlooked in the literature. In this paper, we introduce a novel bi-objective influence maximization problem, termed Influence Maximization with Burden, which aims to simultaneously maximize the influence of seed nodes and minimize the variance in the burden of these nodes. We provide both intuitive and empirical evidence to support the feasibility and necessity of this problem. We provide both intuitive and empirical evidence to support the feasibility and necessity of this problem. Furthermore, we develop two algorithms to solve the proposed problem. The first is a fast, suboptimal algorithm utilizing the reverse reachable sampling method. The second is a memetic algorithm featuring a novel meme operator designed to identify promising nodes. Experimental results on both synthetic and real-world networks demonstrate that our proposed algorithms outperform existing methods in terms of effectiveness and efficiency. Our code is available on GitHub: https://github.com/fmyzckj.},
  archive      = {J_MECO},
  author       = {Feng, Mingyang and Zhao, Qi and He, Shan and Shi, Yuhui},
  doi          = {10.1007/s12293-025-00452-8},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--16},
  shortjournal = {Memet. Comput.},
  title        = {Bi-objective influence maximization with consideration of node burden},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A receding horizon control-based holistic ant colony system approach for multi-runway aircraft arrival sequencing and scheduling. <em>MECO</em>, <em>17</em>(2), 1--18. (<a href='https://doi.org/10.1007/s12293-025-00447-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aircraft arrival sequencing and scheduling (ASS) is a significant research problem that aims to relieve aircraft congestion in airports. Due to the increasing demand for air transportation and the limitation of runway capacity, effective and efficient scheduling approaches for handling the ASS problem are in great need for most modern airports. Ant colony system (ACS) in evolutionary computation is now commonly used to tackle the ASS problem due to its promising performance. However, most existing ACS-based algorithms are designed to tackle single-runway ASS problems or to tackle multi-runway ASS problems in a separative fashion (e.g., first considering the landing sequence and then considering the runway assignment, which will easily result in local optima). This paper the first time proposes a novel holistic ACS (HACS)-based scheduling approach for effectively solving the multi-runway ASS problem by scheduling the sequencing and the runways simultaneously. The proposed approach follows the local memetic feature of ASS that very late arrived aircraft are not likely to be scheduled to land very early, so as to divide the ASS problem into a set of subproblems using a receding horizon control technique and then to optimize each subproblem through the HACS algorithm. The advantage of HACS is that it can figure out the runway assignment of the aircraft in each receding horizon window as well as their landing sequence simultaneously in one stage, which is a global view to obtain the global optimal solution rather than the separative ACS algorithm that is easily trapped to local optima. Instances with different scales and different congestion modes are adopted to comprehensively evaluate the performance of the HACS approach. The experimental results show the superiority of HACS, especially in the large-scale, congested mode, and in scheduling environments with more runways.},
  archive      = {J_MECO},
  author       = {Xu, Xin-Xin and Jiang, Yi and Sang, Hong-Yan and Gong, Hui-Li and Ding, Xiang-Qian and Kwong, Sam and Zhan, Zhi-Hui},
  doi          = {10.1007/s12293-025-00447-5},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--18},
  shortjournal = {Memet. Comput.},
  title        = {A receding horizon control-based holistic ant colony system approach for multi-runway aircraft arrival sequencing and scheduling},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A differential evolution algorithm for numerical optimization based on the cosine-exponential population size adaptive method. <em>MECO</em>, <em>17</em>(2), 1--78. (<a href='https://doi.org/10.1007/s12293-025-00445-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of differential evolution algorithms is sensitive to the population size, and most existing population size control methods continuously reduce the population during the iteration process, which decreases the exploration ability and makes it difficult to prevent a premature convergence of the algorithm. To improve the exploration ability of the differential evolution algorithm, this paper proposes a cosine-exponential population size adaptive (CEPSA) method. In the iterative process, CEPSA enables the population size to decrease or increase. The CEPSA periodically enhances the diversity of the population in the iterative process of the algorithm, which improves the exploration ability of the algorithm and prevents it from premature convergence. Based on the CEPSA, this paper proposes a new variant of the differential evolution algorithm, which is known as CEDE. In the experiment, the performance of CEDE was verified via the CEC 2014 and CEC 2017 benchmark test sets and several real-world engineering problems. CEDE was compared with 11 variants of differential evolution and six metaheuristic algorithms. The experimental results show that CEDE was significantly better than the compared algorithms. In addition, we conducted a sensitivity analysis on the parameters of CEDE, and the experimental results show that CEDE was not sensitive to the parameters, indicating that CEDE can be easily applied to various optimization problems.},
  archive      = {J_MECO},
  author       = {Zeng, Zhiqiang and Liang, Wenyi and Gao, Le},
  doi          = {10.1007/s12293-025-00445-7},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--78},
  shortjournal = {Memet. Comput.},
  title        = {A differential evolution algorithm for numerical optimization based on the cosine-exponential population size adaptive method},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multitasking optimization algorithm based on a multitransfer strategy. <em>MECO</em>, <em>17</em>(2), 1--25. (<a href='https://doi.org/10.1007/s12293-025-00446-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To transfer effective knowledge between tasks, improve the effectiveness of intertask interactions and enhance the performance of evolutionary multitasking optimization algorithms, this article presents an adaptive evolutionary multitasking optimization algorithm based on a multitransfer strategy (EMTO-MS). EMTO-MS uses two transfer strategies for intertask knowledge transfer and adaptively allocates computational resources to these transfer strategies based on the performance of each strategy during the evolutionary process. In addition, the strength of interaction between two tasks is adaptively adjusted according to the transfer success rate and the similarity between the two tasks during the optimization process. To evaluate the performance of EMTO-MS, we compared EMTO-MS with nine mainstream evolutionary multitasking algorithms on the single-objective multitasking benchmarks,and with five outstanding EMTO algorithms on a complex multitask benchmark. The experimental results demonstrate that the proposed EMTO-MS outperforms most of the compared algorithms in terms of search accuracy and convergence.},
  archive      = {J_MECO},
  author       = {Li, Xiaoyu and Wang, Lei and Jiang, Qiaoyong},
  doi          = {10.1007/s12293-025-00446-6},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--25},
  shortjournal = {Memet. Comput.},
  title        = {Multitasking optimization algorithm based on a multitransfer strategy},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient local search algorithm for split delivery vehicle routing problem with three-dimensional loading. <em>MECO</em>, <em>17</em>(2), 1--37. (<a href='https://doi.org/10.1007/s12293-025-00451-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The split delivery vehicle routing problem with three-dimensional loading constraints (3L-SDVRP) is a complex capacitated vehicle routing problem variant that considers split delivery and three-dimensional loading. It aims to determine the optimal routes for a fleet of vehicles by minimizing the number of vehicles required and the total travel distance. However, current methods are limited in efficiency and often yield suboptimal solutions. More efficient and effective methods are needed. Building on a state-of-the-art algorithm for solving the 3L-SDVRP, this paper proposes a more efficient algorithm with several novel features. Firstly, improvements to the packing method are introduced to enhance the loading performance and reduce required vehicles. Secondly, three new search operators are proposed to exploit problem characteristics in order to improve search efficiency significantly. Thirdly, a new adaptive splitting strategy dynamically decides when to split boxes according to the current status of the vehicle and node, thereby reducing computational costs. Lastly, the algorithm includes a new post-optimization method to further improve the solution quality. Extensive experiments validate that our proposed method efficiently reduces the number of required vehicles with fewer computational resources. The effectiveness of each novel component has also been confirmed through ablation experiments.},
  archive      = {J_MECO},
  author       = {Zhang, Han and Li, Qing and Yao, Xin},
  doi          = {10.1007/s12293-025-00451-9},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--37},
  shortjournal = {Memet. Comput.},
  title        = {An efficient local search algorithm for split delivery vehicle routing problem with three-dimensional loading},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Archive-based multiple feature construction method using adaptive genetic programming. <em>MECO</em>, <em>17</em>(2), 1--16. (<a href='https://doi.org/10.1007/s12293-025-00453-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of features is an important factor that affects the classification performance of machine learning algorithms. Feature construction based on Genetic Programming (GP) can automatically create more discriminative features, sometimes greatly improving classification performance. However, constructing a single feature or a small number of features may make the linkage information between labels and features insufficient, resulting in poor classification performance, so we introduce a multi-feature construction method. In addition, premature convergence of the GP may also affect classification performance. This paper proposes an archive-based multiple feature construction method which uses elite archive strategy to preserve and select effective constructed features, and employs an adaptive strategy for GP to adjust the crossover and mutation probabilities based on fitness values. Experiments on ten datasets show that our proposed archive-based multiple feature construction method without using adaptive GP can significantly improve the classification performance compared with traditional single feature construction method, and the classification performance can be maintained or further improved by adding the adaptive strategy. The comparisons with four state-of-the-art techniques show that our proposed method can significantly achieve better classification performance.},
  archive      = {J_MECO},
  author       = {Jia, Kaixuan and Zhang, Fan and Gao, Xiaoying and Ma, Jianbin},
  doi          = {10.1007/s12293-025-00453-7},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--16},
  shortjournal = {Memet. Comput.},
  title        = {Archive-based multiple feature construction method using adaptive genetic programming},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An ensemble learning algorithm based on multimodal differential evolution and extreme learning machine. <em>MECO</em>, <em>17</em>(2), 1--22. (<a href='https://doi.org/10.1007/s12293-025-00461-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The neural network ensemble (NNE) is a widely recognized and effective classification method. It is imperative to concurrently optimize the topological structures and weight parameters of all base neural networks (NNs) within the NNE. This simultaneous optimization is crucial for balancing the accuracy and diversity of the base NNs, leading to superior classification performance. The extreme learning machine (ELM) is a rapid non-iterative learning strategy that has garnered significant attention recently due to its robust generalization capabilities, though effective only for fixed-structure NNs. Hence, to tackle these intricate challenges, this paper introduces a novel ensemble learning algorithm based on a multimodal differential evolution (MMDE) and ELM, called MMDE-ELM-NNE. The proposed algorithm optimizes both the structures and weight parameters of all the base NNs within an NNE in one run. MMDE-ELM-NNE employs a unique coding scheme to optimize the structures and input parameters of the base NNs, while the ELM’s output parameters are computed directly. Furthermore, the MMDE algorithm has been enhanced better to meet the high-dimensional optimization demands of NNE tasks, ultimately enhancing classification accuracy. The experiments on twenty multimodal optimization problems are carried out and compared with eleven existing algorithms to verify the effectiveness of the proposed MMDE. Additionally, the experimental results on classification benchmark datasets relying on a Friedman test demonstrate that MMDE-ELM-NNE significantly outperforms ensembles of MMDE or ELM in terms of generalization prowess. Furthermore, the proposed algorithm showcases competitive capabilities when compared against other state-of-the-art classification algorithms.},
  archive      = {J_MECO},
  author       = {Ma, Jie and Li, Hong and Gao, Weifeng and Xie, Jin},
  doi          = {10.1007/s12293-025-00461-7},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--22},
  shortjournal = {Memet. Comput.},
  title        = {An ensemble learning algorithm based on multimodal differential evolution and extreme learning machine},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multi-agent architecture based on decomposition and learning automata to hybridize multi-objective metaheuristics. <em>MECO</em>, <em>17</em>(2), 1--28. (<a href='https://doi.org/10.1007/s12293-025-00460-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid metaheuristics can effectively tackle multi-objective optimization problems. Recently, researchers gained interest in procedures, referred to as architectures, that can provide generic functionalities and features for hybridizing arbitrary metaheuristics. Although a previously proposed multi-agent architecture, MO-MAHM, achieved high-quality solutions for bi-objective problems, its application for more than two objectives requires further discussions. To this end, MO- $$\hbox {MAHM}_E$$ , a MO-MAHM extension for handling two or more objectives, is proposed in this paper. MO- $$\hbox {MAHM}_E$$ maintains concepts from particle swarm optimization and multi-agent paradigms, including particle movement and agent intelligence. Further, it uses a decomposition-based velocity operator prescinding from aggregation functions and reinforcement learning automata scheme for supporting the decisions of the agents. This paper shows that these algorithmic components can significantly improve the architectural performance. We apply MO- $$\hbox {MAHM}_E$$ to the quadratic assignment problem with up to four objectives. Hybridization combines three evolutionary algorithms and a local search. A comparison of the experimental results of MO- $$\hbox {MAHM}_E$$ and ten algorithms (including hybrid approaches, hyper-heuristics, and algorithms from the quadratic assignment problem literature) is presented.},
  archive      = {J_MECO},
  author       = {Fernandes, Islame F. C. and Goldbarg, Elizabeth F. G. and Maia, Silvia M. D. M.},
  doi          = {10.1007/s12293-025-00460-8},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--28},
  shortjournal = {Memet. Comput.},
  title        = {A novel multi-agent architecture based on decomposition and learning automata to hybridize multi-objective metaheuristics},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bio-inspired model for oil production prediction: Combining gene regulation-based optimization and radial basis function network. <em>MECO</em>, <em>17</em>(2), 1--19. (<a href='https://doi.org/10.1007/s12293-025-00455-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oil production prediction plays a crucial role in the process of oilfield development, deployment, and production planning, especially when it comes to reservoir management, yet its accuracy is often unsatisfying. To address this, we proposed a bio-inspired model for oil production prediction, which combined a new genetic algorithm, known as DNA-GA, with a radical basis function (RBF) neural network. The DNA-GA was designed based on the regulation mechanism of DNA and was applied to optimize the RBF network together with the gradient descent method. The DNA-GA can effectively improve the population’s diversity and prevent premature convergence, resulting in high convergence accuracy and excellent optimization ability. The tests based on Schaffer and Rosenbrock functions showed that the convergence accuracy of DNA-GA was increased by 65.38% and 67.69%, respectively, compared with the existing optimization algorithms such as the Firefly algorithm, and the convergence speed was also increased by 50%. Applied into real-world oil fields, the bio-inspired model greatly outperformed traditional neural network models in both prediction accuracy and convergence speed. Comparative analyses against the traditional RBF neural network and GA-optimized RBF neural network revealed a substantial enhancement in the prediction performance of the bio-inspired model. Specifically, the mean absolute error (MAE) was reduced by 75% and 50%, respectively. Moreover, convergence speed, as measured by average convergence iterations, was improved by 57% compared to the GA-optimized RBF neural network. These results proved that the combination of the RBF neural network and the DNA-GA algorithm could greatly improve the prediction accuracy of oil production.},
  archive      = {J_MECO},
  author       = {Liu, Bao and Liang, Yuqing and Zhu, Zirun and Gao, Lei},
  doi          = {10.1007/s12293-025-00455-5},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--19},
  shortjournal = {Memet. Comput.},
  title        = {Bio-inspired model for oil production prediction: Combining gene regulation-based optimization and radial basis function network},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image denoising with hybrid classical-quantum convolutional neural network. <em>MECO</em>, <em>17</em>(2), 1--16. (<a href='https://doi.org/10.1007/s12293-025-00463-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Noises can be introduced during the image acquisition process due to the factors such as electronic device malfunctions, making denoising essential for enhancing image quality and interpretability. However, existing denoising neural networks often struggle with generalization when training data is limited, resulting in suboptimal performance. To address these challenges, a novel quantum denoising convolutional neural network (QDnCNN) is proposed to enhance image denoising effectiveness. This approach integrates quantum circuits prior to the input of a classical convolutional network to extract features from noisy images in quantum space. The processed images are then rendered as the input of the convolutional neural network, significantly improving denoising performance. The quantum layers enable the network to effectively extract and represent image information in a higher-dimensional feature space, capturing more noises while preserving finer image details, thereby enhancing robustness to noise. Additionally, a quantum-parameterized convolutional layer is introduced to perform local transformations on image data, facilitating more efficient feature extraction. Experimental results demonstrate that the QDnCNN outperforms traditional networks under the Set12, BSD68, and MNIST datasets. Under the real-world datasets Set12 and BSD68, the QDnCNN achieves performance comparable to the conventional deep learning methods, while under the MNIST dataset, it improves the structural similarity index by 11.4% and the peak signal-to-noise ratio by 7.6%. The QDnCNN shows excellent potential as an image denoising algorithm suitable for future quantum computing devices.},
  archive      = {J_MECO},
  author       = {He, Xiaochang and Gong, Lihua and Zhou, Nanrun},
  doi          = {10.1007/s12293-025-00463-5},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--16},
  shortjournal = {Memet. Comput.},
  title        = {Image denoising with hybrid classical-quantum convolutional neural network},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simultaneous prediction of bauxite quality parameters using TC-unet and near-infrared spectroscopy. <em>MECO</em>, <em>17</em>(2), 1--12. (<a href='https://doi.org/10.1007/s12293-025-00457-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Near-infrared (NIR) spectroscopy, renowned for its rapid and non-destructive analytical capabilities, faces substantial hurdles in bauxite quality assessment due to the material’s complex composition and inherent spectral noise. These factors lead to overlapping absorption bands and highly nonlinear relationships between spectra and quality parameters. Existing chemometric methods, such as partial least squares regression (PLSR), fail to model such nonlinearity, while other conventional machine learning methods encounter difficulties in spectral feature extraction. This paper introduces TC-Unet, a novel deep learning framework for simultaneous prediction of multiple parameters, which successfully addresses these limitations through the technical integration of self-attention mechanisms, multi-scale feature extraction, and multi-task learning. The framework is specifically equipped with a transformer-based self-attention module that establishes long-range dependencies between spectral bands, a U-Net architecture that captures local absorption peak structures through encoder-decoder pathways with skip connections, and a multi-task decoupled head that ensures parameter independence leveraging inter-task correlations. Additionally, a channel-squeeze-and-excitation network (cSENet) dynamically adjusts spectral feature importance, optimizing shared representations for multi-target regression. The preprocessing pipeline, which includes an iterative Mahalanobis distance method for robust outlier detection and a standard normal variate (SNV) algorithm for scatter correction, significantly enhances the quality of spectral data. Evaluated on 424 NIR spectra, the TC-Unet outperformed classical machine learning and other deep learning methods, achieving average $$R^2$$ of 0.9177 for $$\text {Al}_2\text {O}_3$$ (%), 0.9174 for $$\text {SiO}_2$$ (%), and 0.9688 for $$\text {Fe}_2\text {O}_3$$ (%). This demonstrates the framework’s capability to disentangle complex spectral interactions, reinforcing its potential as an advanced approach for nonlinear multivariate spectral analysis.},
  archive      = {J_MECO},
  author       = {Zou, Liang and Kou, Shaoping and Xu, Zhibin and Tan, Zhiyi and Lei, Meng},
  doi          = {10.1007/s12293-025-00457-3},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--12},
  shortjournal = {Memet. Comput.},
  title        = {Simultaneous prediction of bauxite quality parameters using TC-unet and near-infrared spectroscopy},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On recent computational results for a dynamic pickup and delivery problem. <em>MECO</em>, <em>17</em>(2), 1--6. (<a href='https://doi.org/10.1007/s12293-025-00462-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A few years ago, a dynamic pickup-and-delivery problem was introduced in the context of a competition Hao et al. ( ICAPS 2021 Competition). Since then, the problem has attracted the attention of many researchers. Recently, Zhou et al. (Memet Computing 16:1-8, 2014) proposed a solution approach to the problem, however, we found a flaw in their study that leads to a lot of misunderstanding. Our paper aims to clear up these misunderstandings. In this paper, we state and prove that contrary to their claim, Zhou et al. (Memet Computing 16:1-8, 2014) did not study and solve the original problem, but a relaxation of it. Accordingly, but without mentioning it, the authors modified the benchmark dataset and then applied state-of-the-art methods tailored to the original problem. Therefore, their published results are misleading as the authors did not clarify that the results are not for the original problem but for a relaxation.},
  archive      = {J_MECO},
  author       = {Horváth, Markó and Kis, Tamás},
  doi          = {10.1007/s12293-025-00462-6},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--6},
  shortjournal = {Memet. Comput.},
  title        = {On recent computational results for a dynamic pickup and delivery problem},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-task ant colony optimization for multi-vehicle path planning. <em>MECO</em>, <em>17</em>(2), 1--20. (<a href='https://doi.org/10.1007/s12293-025-00464-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Multi-vehicle Path Planning (MVPP) problem involves simultaneously solving multiple vehicle path planning tasks within a transportation network that may share similarities in space, tasks, or constraints. Existing methods for the MVPP problem mainly depend on single-task optimization approaches like the traditional ant colony optimization, which typically use either centralized pooling for collaborative optimization or sequential independent optimization of each vehicle’s path. However, as the size of the transportation network expands, single-task optimization faces increasing challenges in solving the MVPP problem. Multi-task optimization is an emerging and promising field that aims to enhance the performance of optimization algorithms through multi-task learning and knowledge sharing, thereby positively impacting various applications like the MVPP. This paper proposes a Multi-Task Ant Colony Optimization (MTACO) method, which allows multiple ant colonies to explore their respective pheromone matrices, thereby facilitating implicit knowledge sharing. In MTACO, each ant colony is responsible for a single vehicle path planning task, and knowledge transfer between tasks is achieved through an archive-based initialization strategy and a probabilistic knowledge transfer strategy, which leverage similarities between tasks to improve overall optimization performance. Furthermore, a similar-task association strategy is introduced to assess the correlation between different vehicle path planning tasks, enabling more effective sharing of valuable search information. Experimental results demonstrate that MTACO outperforms several state-of-the-art methods in various test instances, especially when dealing with multiple vehicle path planning tasks with similarities, exhibiting significant advantages and delivering globally optimal or near-optimal path solutions for all tasks even in large-scale networks.},
  archive      = {J_MECO},
  author       = {Liu, Wei-Li and Yu, Zhenjian and Huang, Zhixing and Zhong, Jinghui and Lu, Xu and Lin, Zhiyong and Zhao, Huimin},
  doi          = {10.1007/s12293-025-00464-4},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--20},
  shortjournal = {Memet. Comput.},
  title        = {Multi-task ant colony optimization for multi-vehicle path planning},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensemble mating strategy in evolutionary algorithms for multiobjective optimization. <em>MECO</em>, <em>17</em>(2), 1--18. (<a href='https://doi.org/10.1007/s12293-025-00458-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Elite-based mating selection and neighbor-based mating restriction are two popular strategies for selecting promising parents for offspring generation in multiobjective evolutionary algorithms (MOEAs). However, few studies have explored the combination of these distinct mating strategies to enhance the search efficiency of MOEAs. To address this issue, we propose an ensemble mating strategy-based multiobjective evolutionary algorithm (EMSEA) that incorporates both mating selection and mating restriction strategies for promising offspring generation. In EMSEA, a clustering learning method is adopted to extract the population structure by partitioning the population into distinct clusters. To generate a new trial solution from the solutions within a cluster, we utilize a competitive approach to select an elite individual from the cluster as a mating parent, while restricting the selection of additional parents to the same cluster. We empirically compare the performance of our algorithm with several representative MOEAs on test instances with complex Pareto sets and Pareto fronts. The experimental results validate the effectiveness of the proposed ensemble mating strategy, as our algorithm outperforms the compared algorithms on these test instances.},
  archive      = {J_MECO},
  author       = {Lu, Yulan and Wang, Shuai and Chen, Yi and Zhang, Hu and Zhang, Yi},
  doi          = {10.1007/s12293-025-00458-2},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--18},
  shortjournal = {Memet. Comput.},
  title        = {Ensemble mating strategy in evolutionary algorithms for multiobjective optimization},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-objective two-phase cascaded memetic algorithm for multi-shop integrated scheduling problem with AGV transportation. <em>MECO</em>, <em>17</em>(2), 1--28. (<a href='https://doi.org/10.1007/s12293-025-00456-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The manufacturing of complex products requires more than one workshop. As a result, regarding the scheduling problem, how to assign the job processing sequence in heterogeneous workshops is a significant consideration. Meanwhile, it is completely different from the single workshop scheduling problem. In this paper, we study the cascaded flowshop joint scheduling problem, including a distributed permutation flowshop scheduling problem and a hybrid flowshop scheduling problem. The objective is to minimize the makespan, total flowtime, and total tardiness simultaneously. This paper first formulates the working principle and establishes a mixed-integer linear programming model. Second, a two-phase cascaded memetic algorithm (TCMA) is proposed to solve the multi-objective cascaded flowshop joint scheduling problem, whose search space varies sequentially in two distinct production phases to explore as many Pareto-optimal solutions as possible. Combining the problem-specific characteristic, a decomposition-based multi-objective heuristic is proposed to generate a high-quality initial population. Meanwhile, a limited range crossover operator, a limited range mutation operator, and a limited range local search operator are proposed to explore more valuable solution space. The key parameters and operators of the TCMA are calibrated and analyzed using the Taguchi method of design-of-experiment. Computational experiments and comparisons demonstrate the effectiveness of the proposed TCMA for the considered problem.},
  archive      = {J_MECO},
  author       = {Wang, Chuang and Pan, Quan-Ke},
  doi          = {10.1007/s12293-025-00456-4},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--28},
  shortjournal = {Memet. Comput.},
  title        = {A multi-objective two-phase cascaded memetic algorithm for multi-shop integrated scheduling problem with AGV transportation},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the dynamics of mating preferences in genetic programming. <em>MECO</em>, <em>17</em>(2), 1--18. (<a href='https://doi.org/10.1007/s12293-025-00466-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several mating restriction techniques have been implemented in Evolutionary Algorithms to promote diversity. From similarity-based selection to niche preservation, the general goal is to avoid premature convergence by not having fitness pressure as the single evolutionary force. In a way, such methods can resemble the mechanisms involved in Sexual Selection, although generally assuming a simplified approach. Recently, a selection method called mating Preferences as Ideal Mating Partners (PIMP) has been applied to GP, providing promising results both in performance and diversity maintenance. The method mimics Mate Choice through the unbounded evolution of personal preferences rather than having a single set of rules to shape parent selection. As such, PIMP allows ideal mate representations to evolve freely, thus potentially taking advantage of Sexual Selection as a dynamic secondary force to fitness pressure. However, it is still unclear how mating preferences affect the overall population and how dependent they are on set-up choices. In this work, we tracked the evolution of individual preferences through different mutation types, searching for patterns and evidence of self-reinforcement. Results suggest that mating preferences do not stand on their own, relying on subtree mutation to avoid convergence to single-node trees. Nevertheless, they consistently promote smaller and more balanced solutions depth-wise than a standard tournament selection, reducing the impact of bloat. Furthermore, when coupled with subtree mutation it also results in more solution diversity with statistically significant results.},
  archive      = {J_MECO},
  author       = {Simões, José Maria and Lourenço, Nuno and Machado, Penousal},
  doi          = {10.1007/s12293-025-00466-2},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1--18},
  shortjournal = {Memet. Comput.},
  title        = {On the dynamics of mating preferences in genetic programming},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive matrix-based evolutionary computation framework for EEG feature selection. <em>MECO</em>, <em>17</em>(1), 1--19. (<a href='https://doi.org/10.1007/s12293-024-00434-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram (EEG) plays a significant role in emotion recognition because it contains abundant information. However, due to the highly correlated EEG channels, a lot of redundant EEG features exist, which not only potentially degrade the emotion recognition accuracy, but also bring high computational costs. To address this challenge, this paper proposes an adaptive matrix-based evolutionary computation framework (AMEC) to select as few informative EEG features as possible for effective emotion recognition. Unlike most existing EC algorithms that utilize vector-based operations, this framework leverages matrix-based operations to reduce feature redundancy and improve classification accuracy by dynamically adjusting the feature subset size according to the characteristics of the dataset. In such a way, the selection efficiency is largely improved. To verify the effectiveness and efficiency of this framework, the classical genetic algorithm, the typical particle swarm optimization algorithm, and the classical differential evolution algorithm, are respectively embedded into this framework for EEG feature selection, and then evaluated on three widely used public EEG datasets for emotion recognition. Compared with several state-of-the-art EEG feature selection algorithms, the devised framework is much more effective in terms of the classification accuracy and the computational efficiency. In addition, the experimental results further reveal that the selected feature subsets are very different for different genders. This indicates the demand of gender-sensitive EEG feature selection for emotion recognition.},
  archive      = {J_MECO},
  author       = {Duan, Danting and Sun, Bing and Yang, Qiang and Ye, Long and Zhang, Qin and Zhang, Jun},
  doi          = {10.1007/s12293-024-00434-2},
  journal      = {Memetic Computing},
  month        = {3},
  number       = {1},
  pages        = {1--19},
  shortjournal = {Memet. Comput.},
  title        = {An adaptive matrix-based evolutionary computation framework for EEG feature selection},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated design of state transition rules in ant colony optimization by genetic programming: A comprehensive investigation. <em>MECO</em>, <em>17</em>(1), 1--22. (<a href='https://doi.org/10.1007/s12293-025-00435-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automated design of Ant Colony Optimization (ACO) algorithms has become increasingly significant, particularly in addressing complex combinatorial optimization problems. Although existing methods have achieved some success, they still face limitations, particularly the high dependency on expert knowledge, pre-solved data, and challenges in interpretability. Genetic Programming (GP), as a proven technology, has shown potential in optimizing the automated design state transition rules of ACO. However, existing research on GP-ACO is insufficient, particularly in terms of experimental validation and systematic evaluation. To address these issues, this study conducts comprehensive experiments to explore several key questions: the generality of GP-ACO on homogeneously distributed maps, the impact of different ACO variants on the learning capabilities of GP-ACO, the effect of 2-opt local search on the learning capabilities of GP-ACO, the enhancement of learning capabilities through the addition of more global information, and the interpretability of GP-ACO. The findings indicate that GP-ACO exhibits robust generality; variations among ACO variants have minimal impact on learning performance; 2-opt local search can somewhat diminish the performance of GP-ACO in the Max–Min Ant System; additional global information can significantly enhance the learning capabilities of GP-ACO; and GP-ACO has good interpretability.},
  archive      = {J_MECO},
  author       = {Lin, Bo-Cheng and Mei, Yi and Zhang, Mengjie},
  doi          = {10.1007/s12293-025-00435-9},
  journal      = {Memetic Computing},
  month        = {3},
  number       = {1},
  pages        = {1--22},
  shortjournal = {Memet. Comput.},
  title        = {Automated design of state transition rules in ant colony optimization by genetic programming: A comprehensive investigation},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event extraction based on self-data augmentation with large language models. <em>MECO</em>, <em>17</em>(1), 1--15. (<a href='https://doi.org/10.1007/s12293-025-00436-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event extraction plays a crucial role in natural language processing (NLP), facilitating the transformation of unstructured text into structured representations. This conversion significantly enhances the performance of various applications, such as automated question answering and information retrieval systems. However, traditional event extraction methodologies often encounter challenges stemming from limited datasets, imbalanced sample distributions, the necessity for extra resources to annotate large datasets, and the potential for data quality degradation during the augmentation process. To surmount these obstacles, this study introduces an innovative self-data augmentation strategy that leverages a single large language model (LLM) to concurrently perform data augmentation and event extraction. By dynamically assessing and refining the quality of generated samples, this approach mitigates the inclusion of noisy data, ultimately bolstering the model’s performance. Demonstrable enhancements in precision, recall, and F1 scores across various model configurations underscore the efficacy of this strategy in managing small and imbalanced datasets. Furthermore, the incorporation of Logical Thoughts for Self-Data Augmentation (LoTSA) ensures the superior quality of augmented data, culminating in more accurate and reliable extraction outcomes.},
  archive      = {J_MECO},
  author       = {Yang, Lishan and Fan, Xi and Wang, Xiangyu and Wang, Xin and Chen, Qiuju},
  doi          = {10.1007/s12293-025-00436-8},
  journal      = {Memetic Computing},
  month        = {3},
  number       = {1},
  pages        = {1--15},
  shortjournal = {Memet. Comput.},
  title        = {Event extraction based on self-data augmentation with large language models},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel efficient bi-objective evolutionary algorithm for frequent and high utility itemsets mining. <em>MECO</em>, <em>17</em>(1), 1--13. (<a href='https://doi.org/10.1007/s12293-025-00437-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining frequent and high utility itemsets (FHUIs) from transaction database is an important task in data mining. In order to overcome the difficulties of parameter setting and huge search space in traditional algorithms for mining FHUIs, the task of mining FHUIs was modeled as a bi-objective problem and then solved by multi-objective evolutionary algorithms (MOEAs) in previous works. However, MOEAs may be inefficient when the number of transactions and items in the transaction database becomes large. To address this problem, we propose a novel efficient bi-objective evolutionary algorithm for mining FHUIs (NBOEA-FHUI). In NBOEA-FHUI, a novel initialization strategy is proposed, which takes the support, utility, and diversity of the initial population into account. The proposed initial strategy can make the initial population have relative high utility and support values with high population diversity. To improve the quality of the offspring, a method for estimating the support and utility value of itemsets and an offspring generation strategy are proposed in NBOEA-FHUI. The support and utility values of itemsets which are roughly proportional to their true values can be calculated by the estimation method with little computation. The proposed offspring generation strategy can generate better offspring based on the estimated support and utility value. Experimental results on several real datasets demonstrate that the proposed algorithm has better performance than the state-of-the-art MOEAs in terms of the convergence speed, search efficiency, and solution accuracy in the task of mining FHUIs.},
  archive      = {J_MECO},
  author       = {Ma, Li and Li, Chongyang and Lu, Heng-yang and Fang, Wei and Lin, Jerry Chun-Wei},
  doi          = {10.1007/s12293-025-00437-7},
  journal      = {Memetic Computing},
  month        = {3},
  number       = {1},
  pages        = {1--13},
  shortjournal = {Memet. Comput.},
  title        = {A novel efficient bi-objective evolutionary algorithm for frequent and high utility itemsets mining},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A constrained large-scale lever evolutionary algorithm for white-box problems and its application in spectral-energy efficiency tradeoff of massive MIMO. <em>MECO</em>, <em>17</em>(1), 1--18. (<a href='https://doi.org/10.1007/s12293-025-00438-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing constrained multi-objective evolutionary algorithms are not so efficient when handling constrained large-scale multi-objective problems (CLSMOPs). To overcome white-box CLSMOPs with definitive objective functions, a spatial–temporal lever evolutionary algorithm (STLEA), consisting of the lever evolutionary algorithm (LEA) and spatial–temporal preference strategy (STPS), is proposed. LEA ditches the thought of the mainstream algorithms for the similar problems, which changes the structure of the large-scale decision space, but handles the large-scale decision space by a certain small-scale decision space. Specifically, inspired by the lever principle, LEA explores the way to pry up the large-scale decision space, as the “load”, by the small-scale decision space, as the “force”. Meanwhile, LEA rotates the optimizations in between “load” and “force” for dual-balance: balance between objectives and constraints, and balance between convergence and diversity of solutions. STPS dynamically adjusts the proportion of optimizations in “load” and “force”. Different from existing preference strategies, which only consider the stage of the evolutionary procedure, STPS considers both stage, related to time, and varying scale of the decision space, related to space, for the comprehensive balance of feasibility, convergence, and diversity of solutions. Eleven representative and state-of-the-art constrained multi-objective evolutionary algorithms have been compared to the proposed STLEA to demonstrate its effectiveness through comparative experiments on through comparative experiments on CLSMOPs with equality and inequality constraints and 1000 decision variables and three typical MaMIMO-LU models with 1024 antennas and 128, 256, and 512 users. Experimental results show that STLEA achieves the best SE-EE tradeoff.},
  archive      = {J_MECO},
  author       = {Wang, Qingzhu and Li, Tianyang},
  doi          = {10.1007/s12293-025-00438-6},
  journal      = {Memetic Computing},
  month        = {3},
  number       = {1},
  pages        = {1--18},
  shortjournal = {Memet. Comput.},
  title        = {A constrained large-scale lever evolutionary algorithm for white-box problems and its application in spectral-energy efficiency tradeoff of massive MIMO},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clinical causal analysis via iterative active structure learning. <em>MECO</em>, <em>17</em>(1), 1--13. (<a href='https://doi.org/10.1007/s12293-025-00439-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning has achieved considerable success in clinical applications such as image-based diagnostics, predictive modeling for patient outcomes, and personalized treatment planning. However, the black-box nature of deep neural networks often results in poor interpretability and reliability of predictions. Traditional neural network architectures, focusing primarily on correlations, fall short in elucidating underlying causal medical mechanisms. Addressing this, causal discovery, aimed at elucidating the structure of causal graphical models from observational or experimental data, is gaining prominence in clinical fields demanding high reliability. Nevertheless, the complexity of search algorithms, the scarcity of real-world data, and the challenges in identifying unique results significantly hinder the reliability of these approaches. To overcome these challenges, we propose an iterative active structure learning approach to ensure reliable clinical causal analysis. Our method begins with the recovery of a causal structure, guided by a set of prior causal presence, followed by an iterative process of active refinement to enhance the output reliability. This involves using violations of known clinical mechanisms as structural constraints to guide successive rounds of learning, thereby correcting and refining the model iteratively. The process continues until there is a convergence between expertise and the data-derived solutions. Our experiments on real-world clinical data demonstrate that Our approach can improve the quality of causal findings and discover new causal associations beyond the basis of expert knowledge. Furthermore, our approach has yielded novel and significant insights from various datasets, which we explore in our discussion.},
  archive      = {J_MECO},
  author       = {Tao, Zhenchao and Chi, Meiyan and Chen, Lyuzhou and Ban, Taiyu and Tu, Qiang and Gao, Fei and Wang, Wei},
  doi          = {10.1007/s12293-025-00439-5},
  journal      = {Memetic Computing},
  month        = {3},
  number       = {1},
  pages        = {1--13},
  shortjournal = {Memet. Comput.},
  title        = {Clinical causal analysis via iterative active structure learning},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simro-dino: A rotary positional DINO with siamese structure for traffic object detection under adverse conditions. <em>MECO</em>, <em>17</em>(1), 1--13. (<a href='https://doi.org/10.1007/s12293-025-00440-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection on traffic road is crucial for enabling real-time analysis of road conditions and can be applied in intelligent transportation systems. However, in real world, we may encounter cases of low visibility, occlusion and lens contamination, where general methods of object detection usually degrade. In order to address this problem, we propose a Rotary Positional DINO with Siamese Structure (SimRo-DINO) framework, which efficiently overcomes the difficulty associated with object detection under adverse conditions. Specifically, to extract salient detail features and distinguish them from extraneous interference information, we leverage siamese representation learning along with random masking, which is named Mask Siamese Subnetwork, improving the robustness under adverse conditions. Furthermore, to enhance the connection between features scattered by various interferences and capture latent positional information under adverse conditions, we introduce Rotary Position Embedding into Co-DINO framework, an end-to-end detector with the capacity of capturing long-range dependency relationships within images. Extensive experiments have been conduct on UA-DETRAC and our self-built dataset, both under the adverse conditions. The results from our experiments indicate a substantial advancement in mean Average Precision (mAP) of 2.3 and 2.5% on these two datasets, respectively, compared to the Co-DINO baseline. The related codes are publicly available at https://github.com/xhzhou123/SimRo-DINO .},
  archive      = {J_MECO},
  author       = {Lei, Meng and Zhou, Xinghan and Zhao, Tianju and Xu, Shifan and Zou, Liang},
  doi          = {10.1007/s12293-025-00440-y},
  journal      = {Memetic Computing},
  month        = {3},
  number       = {1},
  pages        = {1--13},
  shortjournal = {Memet. Comput.},
  title        = {Simro-dino: A rotary positional DINO with siamese structure for traffic object detection under adverse conditions},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-task assisted multi-objective optimization algorithm for autonomous underwater vehicle path planning. <em>MECO</em>, <em>17</em>(1), 1--22. (<a href='https://doi.org/10.1007/s12293-025-00441-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the application of multi-objective optimization algorithms to craft feasible paths considering multiple factors has garnered significant attention in handling path planning problems for autonomous underwater vehicles. However, the construction of appropriate multi-objective problem models coupled with efficient search strategies emerges as a pivotal determinant influencing the performance of multi-objective path planning algorithms. This paper introduces a multi-task assisted multi-objective optimization algorithm (MAMO) tailored to address autonomous underwater vehicle path planning problems. The proposed multi-task framework encompasses two tasks: the original path planning task and a devised simple task. These two tasks have different decision spaces due to distinct encoding strategies. Additionally, two different yet interconnected multi-objective problem models are deployed in the above two tasks. Furthermore, two knowledge transfer strategies, domain mapping-based and reconstruction-based knowledge transfer strategies, are introduced to leverage the knowledge from the simple task to assist the original task. The efficacy of the proposed MAMO is compared against eight counterparts and evaluated on three autonomous underwater vehicle path planning cases with different numbers of obstacles. The empirical findings corroborate the efficacy of the algorithm proffered.},
  archive      = {J_MECO},
  author       = {Liu, Tianyu and Wu, Yu and Xu, He},
  doi          = {10.1007/s12293-025-00441-x},
  journal      = {Memetic Computing},
  month        = {3},
  number       = {1},
  pages        = {1--22},
  shortjournal = {Memet. Comput.},
  title        = {Multi-task assisted multi-objective optimization algorithm for autonomous underwater vehicle path planning},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
