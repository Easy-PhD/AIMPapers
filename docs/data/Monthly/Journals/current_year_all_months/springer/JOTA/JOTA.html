<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JOTA</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jota">JOTA - 48</h2>
<ul>
<li><details>
<summary>
(2026). A positive semidefinite safe approximation of multivariate distributionally robust constraints determined by simple functions. <em>JOTA</em>, <em>208</em>(1), 1--27. (<a href='https://doi.org/10.1007/s10957-025-02791-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-level reformulations of (nonconvex) distributionally robust optimization (DRO) problems are often intractable, as they contain semi-infinite dual constraints. Based on such a semi-infinite reformulation, we present a safe approximation that allows for the computation of feasible solutions for DROs that depend on nonconvex multivariate simple functions. Moreover, the approximation allows to address ambiguity sets that can incorporate information on moments as well as confidence sets. The typical strong assumptions on the structure of the underlying constraints, such as convexity in the decisions or concavity in the uncertainty found in the literature were, at least in part, recently overcome in [16]. We start from the duality-based reformulation approach in [16] that can be applied for DRO constraints based on simple functions that are univariate in the uncertainty parameters. We significantly extend their approach to multivariate simple functions, which leads to a considerably wider applicability of the proposed reformulation approach. In order to achieve algorithmic tractability, the presented safe approximation is then realized by a discretized counterpart for the semi-infinite dual constraints. The approximation leads to a computationally tractable mixed-integer positive semidefinite problem for which state-of-the-art software implementations are readily available. The tractable safe approximation provides sufficient conditions for distributional robustness of the original problem, i.e., obtained solutions are provably robust.},
  archive      = {J_JOTA},
  author       = {Dienstbier, Jana and Liers, Frauke and Rolfes, Jan},
  doi          = {10.1007/s10957-025-02791-5},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--27},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {A positive semidefinite safe approximation of multivariate distributionally robust constraints determined by simple functions},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the optimal control existence for multi-term multi-order fractional differential equations with impulsive conditions. <em>JOTA</em>, <em>208</em>(1), 1--24. (<a href='https://doi.org/10.1007/s10957-025-02830-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the existence of solutions to nonlinear impulsive fractional optimal control problems, where the state equations are linear with respect to their control variables and governed by multi-order systems of multi-term fractional differential ones. Initial and impulsive conditions are also given. The performance index is considered as an integral functional, whose integrand is continuous with respect to its variables. At first, we transform the state equations into the integral ones to prove the existence and uniqueness of solutions, assuming that the nonlinear functions in the equations are Lipschitz continuous in a bounded domain. Secondly, using the generalized Arzela-Ascoli theorem, we establish that sets of our admissible processes are compact ones in a piecewise continuous function space to show the optimal control existence.},
  archive      = {J_JOTA},
  author       = {Choe, HuiChol and Han, SuRim and Pak, SunAe and Kim, GwangHyok and Kim, GyongGuk and U, DanOh},
  doi          = {10.1007/s10957-025-02830-1},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--24},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {On the optimal control existence for multi-term multi-order fractional differential equations with impulsive conditions},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the existence and the stability of solutions in nonconvex vector optimization $$^\dagger $$. <em>JOTA</em>, <em>208</em>(1), 1--26. (<a href='https://doi.org/10.1007/s10957-025-02831-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper is devoted to the existence of weak Pareto solutions and the weak sharp minima at infinity property for a general class of constrained nonconvex vector optimization problems with unbounded constraint set via asymptotic cones and generalized asymptotic functions. Then we show that these conditions are useful for studying the solution stability of nonconvex vector optimization problems with linear perturbation. We also provide some applications for a subclass of robustly quasiconvex vector optimization problems.},
  archive      = {J_JOTA},
  author       = {Nghi, Tran Van and Kien, Le Ngoc and Tuyen, Nguyen Van},
  doi          = {10.1007/s10957-025-02831-0},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--26},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {On the existence and the stability of solutions in nonconvex vector optimization $$^\dagger $$},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Derivative-free optimization on riemannian manifolds using simplex gradient approximations. <em>JOTA</em>, <em>208</em>(1), 1--22. (<a href='https://doi.org/10.1007/s10957-025-02832-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In optimization problems with complex or unknown gradients, using a derivative-free algorithm is an efficient approach. In this paper, we present a new derivative-free optimization method designed for problems in which the search space is a Riemannian manifold. The method utilizes a simplex gradient approximation and incorporates a line search strategy. We state the conditions under which the proposed algorithm is well-defined and establish its convergence to critical points on Riemannian manifolds from any starting point. Lastly, we demonstrate the practical implementation of this technique on two commonly used manifolds and compare its performance to some existing Riemannian derivative-free methods.},
  archive      = {J_JOTA},
  author       = {Najafi, Shahabeddin and Hajarian, Masoud},
  doi          = {10.1007/s10957-025-02832-z},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--22},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Derivative-free optimization on riemannian manifolds using simplex gradient approximations},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A three-term conjugate gradient-type method with sufficient descent property for vector optimization. <em>JOTA</em>, <em>208</em>(1), 1--42. (<a href='https://doi.org/10.1007/s10957-025-02815-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of vector optimization represents a critical domain within the broader spectrum of optimization problems. Extensive research efforts are currently dedicated to developing solution methods for vector optimization problems. A range of classical approaches, originally designed for scalar optimization, have been adapted to address issues in vector optimization. These include techniques such as the steepest descent method, Newton’s method, quasi-Newton method and conjugate gradient method, among others. However, limited attention has been given to the three-term conjugate gradient method in the context of vector optimization. In this paper, based on the modified self-scaling memoryless Broyden-Fletcher-Goldfarb-Shanno (BFGS) method proposed by Kou and Dai (J. Optim. Theory Appl., 165(1): 209-224, 2015), we propose a novel three-term conjugate gradient-type method specifically designed for vector optimization problems. This method ensures the sufficient descent property independent of any line search strategy. Furthermore, the improved Wolfe line search is extended to vector optimization. The global convergence of the proposed method under the improved Wolfe line search is analyzed, demonstrating that at least one accumulation point of the sequence generated by the proposed algorithm is a K-critical point of vector optimization problem. Numerical experiments conducted on a set of benchmark test problems highlight the effectiveness of the proposed method compared to some existing gradient-based approaches.},
  archive      = {J_JOTA},
  author       = {Chen, Yu and Chen, Helong and Zhu, Zhibin},
  doi          = {10.1007/s10957-025-02815-0},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--42},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {A three-term conjugate gradient-type method with sufficient descent property for vector optimization},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Preconditioned barzilai-borwein methods for multiobjective optimization problems. <em>JOTA</em>, <em>208</em>(1), 1--43. (<a href='https://doi.org/10.1007/s10957-025-02824-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preconditioning is a powerful strategy for addressing ill-conditioned problems in optimization. It involves utilizing a preconditioning matrix to reduce the condition number and speed up the convergence of first-order methods. However, in multiobjective optimization, capturing the curvature of all objective functions using a single preconditioning matrix is challenging. Consequently, second-order methods tailored for multiobjective optimization problems (MOPs) employ distinct matrices for each of the objectives in direction-finding subproblems, resulting in expensive per-step costs. To strike a balance between per-step costs and better curvature exploration, we develop a “preconditioning” $$+$$ “preconditioning” strategy to devise a preconditioned Barzilai-Borwein descent method for MOPs (PBBMO). Specifically, this method integrates a single scaling matrix to capture the local geometry of an implicit scalarization problem, leading to reduced per-step costs. We then incorporate the Barzilai-Borwein rule relative to the matrix metric to tune the gradients within the direction-finding subproblem. This can be interpreted as an additional diagonal preconditioner tailored to each objective for better curvature exploration. From a preconditioning perspective, we employ the BFGS update formula to approximate a trade-off of Hessian matrices. Subsequently, we develop a Barzilai-Borwein quasi-Newton method with Wolfe line search for MOPs. Under mild assumptions, we provide a convergence analysis for the Barzilai-Borwein quasi-Newton method. Finally, comparative numerical results validate the efficiency of the proposed method, even when applied to higher-dimensional and ill-conditioned problems.},
  archive      = {J_JOTA},
  author       = {Chen, Jian and Chen, Wang and Tang, Liping and Yang, Xinmin},
  doi          = {10.1007/s10957-025-02824-z},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--43},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Preconditioned barzilai-borwein methods for multiobjective optimization problems},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A new infeasible projection method for stochastic variational inequality problem. <em>JOTA</em>, <em>208</em>(1), 1--28. (<a href='https://doi.org/10.1007/s10957-025-02825-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new infeasible stochastic approximation projection method based on the golden ratio for a nonmonotone stochastic variational inequality problem. In the traditional golden ratio methods, the constant $$\phi $$ is taken as $$\frac{1+\sqrt{5}}{2}$$ . However, the constant is relaxed to the interval $$(1,\infty )$$ in our method. A new self-adaptive step size which is admitted to be increasing is generated for dealing with the unknown Lipschitz constant of the mapping. The almost sure convergence and convergence rate of the proposed method are shown. Some numerical examples are given to illustrate the competitiveness of our algorithm compared to the related algorithms in the literature. Finally, we apply our method to solve a network bandwidth allocation problem.},
  archive      = {J_JOTA},
  author       = {Wang, Shenghua and Zhang, Yueyao and Cho, Yeol Je},
  doi          = {10.1007/s10957-025-02825-y},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--28},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {A new infeasible projection method for stochastic variational inequality problem},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A unified derivative-free projection framework for convex-constrained nonlinear equations. <em>JOTA</em>, <em>208</em>(1), 1--26. (<a href='https://doi.org/10.1007/s10957-025-02826-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a framework and a unified convergence analysis for derivative-free projection methods to solve large-scale constrained nonlinear equations. The framework combines the inertial extrapolation technique with the concept of approximate projections, thereby encompassing and generalising the results of previous studies. Additionally, we introduce a new function-based line search based on the stabilised Barzilai and Borwein method, as introduced by Burdakov et al. The framework further explores the impact of six distinct, well-known line search schemes on its overall performance. Through numerical experiments, we highlight the theoretical findings.},
  archive      = {J_JOTA},
  author       = {Ibrahim, Abdulkarim Hassan and Alshahrani, Mohammed and Al-Homidan, Suliman},
  doi          = {10.1007/s10957-025-02826-x},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--26},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {A unified derivative-free projection framework for convex-constrained nonlinear equations},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust n-agent heterogeneous investment-consumption game under $$\alpha $$ -maxmin mean-variance-utility criterion. <em>JOTA</em>, <em>208</em>(1), 1--38. (<a href='https://doi.org/10.1007/s10957-025-02834-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a robust heterogeneous n-agent stochastic differential game under a mean-variance-utility criterion, where agents compete based on relative performance in the presence of model uncertainty. Model uncertainty is represented by a set of equivalent probability measures, with Novikov’s condition imposed to guarantee their mutual equivalence. Ambiguity attitudes are characterized by the $$\alpha $$ -maxmin model. Agents invest and consume in a financial market exposed to both common and idiosyncratic risks, aiming to maximize relative terminal wealth with the mean-variance criterion and the expected utility of relative consumption under the $$\alpha $$ -maxmin model. We formulate a heterogeneous game that emphasizes outperforming a specific group of competitors. Agents focus on a weighted average of their peers’ wealth and consumption. This optimization problem is inherently time-inconsistent, and we derive the associated extended Hamilton-Jacobi-Bellman-Isaacs (HJBI) equations within a game-theoretic framework. The robust best response strategies are composed of a myopic component and another component that reacts to the actions of other agents. We obtain closed-form solutions for the robust Nash equilibrium investment-consumption strategies through a system of linear equations. This paper explores how levels of ambiguity, ambiguity aversion, risk aversion, and competition affect Nash equilibrium strategies, uncovering the herd effect that competition has on agents’ strategies.},
  archive      = {J_JOTA},
  author       = {Guan, Guohui and Liang, Zongxia},
  doi          = {10.1007/s10957-025-02834-x},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--38},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Robust n-agent heterogeneous investment-consumption game under $$\alpha $$ -maxmin mean-variance-utility criterion},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unique solvability of infinite dimensional differential sweeping systems. <em>JOTA</em>, <em>208</em>(1), 1--37. (<a href='https://doi.org/10.1007/s10957-025-02837-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the existence and uniqueness of solutions to a differential sweeping system. This system is an implicit coupled dynamical system consisting of a nonlinear differential equation and a history/state-dependent sweeping process. First, an existence result to a perturbed state-dependent sweeping process is proved based on Schauder’s fixed-point theorem. Next, the unique solvability of a history/state-dependent sweeping process is established by employing a fixed-point theorem for a history-dependent operator. Finally, using tools from nonsmooth analysis and Banach’s fixed-point theorem, we establish the existence and uniqueness of solutions to a differential sweeping system.},
  archive      = {J_JOTA},
  author       = {Du, Jinsheng and Migórski, Stanisław and Vilches, Emilio and Zeng, Shengda},
  doi          = {10.1007/s10957-025-02837-8},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--37},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Unique solvability of infinite dimensional differential sweeping systems},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Variational analysis of generalized ordinal nash games on banach spaces. <em>JOTA</em>, <em>208</em>(1), 1--25. (<a href='https://doi.org/10.1007/s10957-025-02838-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the generalized ordinal Nash games defined over Banach spaces by employing variational techniques. To reformulate these games in terms of quasi-variational inequality problems, we will first form a suitable principal operator and study some significant properties of this operator. Then, we deduce the sufficient conditions to obtain an equilibrium for the proposed game by solving an auxiliary quasi-variational inequality. Based on this quasi-variational reformulation, we derive the existence of equilibrium for generalized ordinal Nash games with mid-point continuous preference maps. We apply the derived results to ensure the presence of Pareto equilibrium for multi-objective games and dynamic electricity markets.},
  archive      = {J_JOTA},
  author       = {Valecha, Shivani and Sultana, Asrifa},
  doi          = {10.1007/s10957-025-02838-7},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--25},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Variational analysis of generalized ordinal nash games on banach spaces},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Estimating mean and variance of random coefficients in stochastic variational problems using second-order methods. <em>JOTA</em>, <em>208</em>(1), 1--48. (<a href='https://doi.org/10.1007/s10957-025-02805-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the need to identify both deterministic and stochastic coefficients in various stochastic partial differential equations, we have developed an abstract inversion framework. The inverse problem is studied in a stochastic optimization framework. Essential properties of solution maps are derived to prove the solvability of the optimization problems and to establish optimality conditions. A comprehensive regularization framework, including total-variation regularization, has been created to identify rapidly varying coefficients. By using the Bregman distance, we provide new convergence rates for stochastic inverse problems in the abstract formulation without the need for the so-called smallness condition. Assuming finite-dimensional noise, the inverse problem is parameterized and solved using the stochastic Galerkin framework. The numerical schemes utilize Hessian-based optimization methods, resulting in rapid convergence. The numerical results are promising, demonstrating the feasibility and effectiveness of the proposed framework.},
  archive      = {J_JOTA},
  author       = {Gong, Zi-Jia and Khan, Akhtar A. and Sama, Miguel and Starkloff, Hans-Jörg},
  doi          = {10.1007/s10957-025-02805-2},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--48},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Estimating mean and variance of random coefficients in stochastic variational problems using second-order methods},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Differential inclusions for measures and lyapunov stability. <em>JOTA</em>, <em>208</em>(1), 1--22. (<a href='https://doi.org/10.1007/s10957-025-02828-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on differential inclusions for measures, that are differential relations whose solutions are time-evolving measures. The definition of evolution equations for measures attracted a lot of attention recently. We start by recalling the main concepts developed in the latest literature and comparing them. In particular, we show how the definition of Measure Differential Inclusion is the most general allowing to model phenomena as diffusion from a Dirac delta. Then we pass to Lyapunov-type stability proposing two concepts of stability, based on the measure support and first moment, and show relationships between such definitions depending on the assumptions on the evolution equation used.},
  archive      = {J_JOTA},
  author       = {D’Apice, Ciro and Manzo, Rosanna and Piccoli, Benedetto},
  doi          = {10.1007/s10957-025-02828-9},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--22},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Differential inclusions for measures and lyapunov stability},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Majorization-minimization bregman proximal gradient algorithms for NMF with the Kullback–Leibler divergence. <em>JOTA</em>, <em>208</em>(1), 1--34. (<a href='https://doi.org/10.1007/s10957-025-02833-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonnegative matrix factorization (NMF) is a popular method in machine learning and signal processing to decompose a given nonnegative matrix into two nonnegative matrices. In this paper, we propose new algorithms, called majorization-minimization Bregman proximal gradient algorithm (MMBPG) and MMBPG with extrapolation (MMBPGe) to solve NMF. These iterative algorithms minimize the objective function and its potential function monotonically. Assuming the Kurdyka–Łojasiewicz property, we establish that a sequence generated by MMBPG(e) globally converges to a stationary point. We apply MMBPG and MMBPGe to the Kullback–Leibler (KL) divergence-based NMF. While most existing KL-based NMF methods update two blocks or each variable alternately, our algorithms update all variables simultaneously. MMBPG and MMBPGe for KL-based NMF are equipped with a separable Bregman distance that satisfies the smooth adaptable property and that makes its subproblem solvable in closed form. Using this fact, we guarantee that a sequence generated by MMBPG(e) globally converges to a Karush–Kuhn–Tucker (KKT) point of KL-based NMF. In numerical experiments, we compare proposed algorithms with existing algorithms on synthetic data and real-world data.},
  archive      = {J_JOTA},
  author       = {Takahashi, Shota and Tanaka, Mirai and Ikeda, Shiro},
  doi          = {10.1007/s10957-025-02833-y},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--34},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Majorization-minimization bregman proximal gradient algorithms for NMF with the Kullback–Leibler divergence},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stochastic elastography inverse problem of tumor identification by an equation error approach. <em>JOTA</em>, <em>208</em>(1), 1--23. (<a href='https://doi.org/10.1007/s10957-025-02839-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an equation error framework for the identification of stochastic coefficients in stochastic saddle point problems. As a key application, we demonstrate how this framework encompasses the inverse problem of stochastic parameter estimation in the nearly incompressible elasticity system, the underlying mathematical model for the elastography inverse problem of locating cancerous tumor. Beyond this, the framework is general and applies to a range of other problems. The proposed approach reformulates the nonlinear inverse problem as a stochastic quadratic optimization problem. We establish the existence and uniqueness of the solution under a quadratic regularization and analyze the impact of data perturbation. To enable numerical solution, we employ a stochastic Galerkin discretization, derive the corresponding discrete optimization problem, and provide explicit expressions for the gradient and Hessian of the objective function. To validate the framework, we apply it to a test case involving the identification of a random coefficient in a nearly incompressible elasticity system, demonstrating its capability to accurately recover both the mean and variance of an unknown stochastic Lamé coefficient.},
  archive      = {J_JOTA},
  author       = {Gong, Zi-Jia and Gwinner, Joachim and Khan, Akhtar A.},
  doi          = {10.1007/s10957-025-02839-6},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--23},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Stochastic elastography inverse problem of tumor identification by an equation error approach},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). First and second order optimality conditions for nonsmooth multiobjective problems with equilibrium constraints. <em>JOTA</em>, <em>208</em>(1), 1--33. (<a href='https://doi.org/10.1007/s10957-025-02853-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we first extend the constant positive linear dependence (CPLD) condition in terms of convexificators given by Rimpi and Lalitha [Constraint qualifications in terms of convexificators for nonsmooth programming problems with mixed constraints. Optimization. 2023;72(8):2019-2038] for nonsmooth scalar optimization problems to nonsmooth multiobjective optimization problems with mixed constraints (MOP) which we denote by MOP-CPLD. It also extends the CPLD condition given by Andreani et al. [On the relation between constant positive linear dependence condition and quasinormality constraint qualification. J Optim Theory Appl. 2005;125(2):473-483] involving continuously differentiable functions. We establish a strong Karush-Kuhn-Tucker (KKT) optimality condition to identify local Pareto efficient solutions under the MOP-CPLD framework. We also introduce a suitable CPLD condition for a nonsmooth multiobjective optimization problem with equilibrium constraints in terms of convexificators which is denoted by MOPEC-CPLD. We introduce several nonsmooth strong Pareto stationary points for the MOPEC which extend the notions of strong Pareto stationary points given by Zhang et al. [Constraint qualifications and proper Pareto optimality conditions for multiobjective problems with equilibrium constraints. J Optim Theory Appl. 2018;176:763-782] for continuously differentiable functions. We provide necessary and sufficient optimality conditions to identify a stationary point as a Pareto efficient solution of the MOPEC under the MOPEC-CPLD condition. Further, we introduce Abadie constraint qualifications for MOPEC which is denoted by MOPEC-SOACQ in terms of Clarke generalized derivative and second-order upper directional derivative given by Páles and Zeidan. This notion utilizes second-order ACQ given by Anchal and Lalita [Second-order optimality conditions for locally Lipschitz vector optimization problems. Optimization. 2023;1-20] for multiobjective optimization problems. We derive second-order necessary optimality conditions in both the primal and the dual forms to identify weak Pareto efficient solutions and strict Pareto efficient solutions of order two for MOPEC by utilizing MOPEC-SOACQ. We give some applications of the results in interval-valued multiobjective optimization problems with equilibrium constraints and in portfolio optimization.},
  archive      = {J_JOTA},
  author       = {Sachan, Prachi and Laha, Vivek and Anshika},
  doi          = {10.1007/s10957-025-02853-8},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--33},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {First and second order optimality conditions for nonsmooth multiobjective problems with equilibrium constraints},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Accelerated adaptive cubic regularized quasi-newton methods. <em>JOTA</em>, <em>208</em>(1), 1--46. (<a href='https://doi.org/10.1007/s10957-025-02804-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose the first Quasi-Newton method with a global convergence rate of $$O(k^{-1})$$ for general convex functions. Quasi-Newton methods, such as BFGS and SR-1, are well-known for their impressive practical performance. However, they are theoretically slower than gradient descent for general convex functions. This gap between impressive practical performance and poor theoretical guarantees was an open question for a long period of time. In this paper, we make a significant step to close this gap. We improve upon the existing rate and propose the Cubic Regularized Quasi-Newton Method with a convergence rate of $$O({k^{-1}})$$ . The key to achieving this improvement is to use the Cubic Regularized Newton Method over the Damped Newton Method as an outer method, where the Quasi-Newton update is an inexact Hessian approximation. Using this approach, we propose the first Accelerated Quasi-Newton method with a global convergence rate of $$O({k^{-2}})$$ for general convex functions. In special cases where we have access to additional computations, for example, Hessian-vector products, we can improve the inexact Hessian approximation and achieve a global convergence rate of $$O({k^{-3}})$$ , which makes it intermediate second-order method. To make these methods practical, we introduce the Adaptive Inexact Cubic Regularized Newton Method and its accelerated version, which provide real-time control of the approximation error. We show that the proposed methods have impressive practical performance and outperform both first and second-order methods.},
  archive      = {J_JOTA},
  author       = {Kamzolov, Dmitry and Ziu, Klea and Agafonov, Artem and Takáč, Martin},
  doi          = {10.1007/s10957-025-02804-3},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--46},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Accelerated adaptive cubic regularized quasi-newton methods},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Special issue in memory of boris polyak. <em>JOTA</em>, <em>208</em>(1), 1--2. (<a href='https://doi.org/10.1007/s10957-025-02814-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOTA},
  author       = {Mordukhovich, Boris and Nemirovski, Arkadi and Nesterov, Yurii},
  doi          = {10.1007/s10957-025-02814-1},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--2},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Special issue in memory of boris polyak},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed nash equilibrium seeking in disturbed multi-agent systems under DoS attacks. <em>JOTA</em>, <em>208</em>(1), 1--25. (<a href='https://doi.org/10.1007/s10957-025-02840-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the problem of achieving distributed Nash equilibrium (DNE) in multi-agent systems (MASs) under denial-of-service (DoS) attacks and external disturbances. Existing approaches often fail to ensure convergence when communication is disrupted and coordination is impaired. To address these challenges, we propose a fully distributed algorithm that combines a linear extended state observer for real-time disturbance estimation with a gradient-based control protocol. Key innovations include: (1) a computationally efficient local behavior estimation strategy based on observed states and gradient information, which replaces global estimation to reduce complexity; and (2) a unified control framework applicable to both first- and second-order MASs, guaranteeing convergence to the DNE despite DoS attacks and external perturbations. Rigorous Lyapunov-based analysis establishes sufficient conditions for stability and convergence. Simulation results demonstrate that the proposed method enables agents to reach the Nash equilibrium under persistent attacks and disturbances, highlighting its robustness and scalability.},
  archive      = {J_JOTA},
  author       = {Zhang, Hebing and Lu, Qun and Shen, Zhezhou},
  doi          = {10.1007/s10957-025-02840-z},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--25},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Distributed nash equilibrium seeking in disturbed multi-agent systems under DoS attacks},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Strong and fast convergences for damping, scaling and tikhonov regularization. <em>JOTA</em>, <em>208</em>(1), 1--29. (<a href='https://doi.org/10.1007/s10957-025-02842-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reach a minimizer of a convex and continuously differentiable function, we investigate the long-time behavior of the trajectories of a vanishing damped nonlinear dynamical system with a positive viscous damping coefficient on the velocity term, a scaling coefficient on the gradient of this function and an appropriate Tikhonov regularization parameter. We justify that each of these parameters plays its relative role in improving the asymptotic behavior of the solution of the proposed dynamical system. In doing so, we improve some recent results on the subject. In addition, this paper generates new results ensuring better convergence of values, gradients and velocities.},
  archive      = {J_JOTA},
  author       = {Riahi, Hassan},
  doi          = {10.1007/s10957-025-02842-x},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--29},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Strong and fast convergences for damping, scaling and tikhonov regularization},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal control problems with vector-valued impulse controls and time delays. <em>JOTA</em>, <em>208</em>(1), 1--33. (<a href='https://doi.org/10.1007/s10957-025-02845-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a nonlinear control system with vector-valued measures as controls and with dynamics depending on time delayed states. First, we introduce a concept of discontinuous, bounded variation solution associated with this system and establish an equivalent representation formula for it, inspired by the approach known in delay-free impulsive control as the ‘graph completion’ method. Then, thanks to this equivalent formulation, we prove well-posedness properties of these solutions and also derive necessary optimality conditions in the form of a Maximum Principle for an associated optimization problem.},
  archive      = {J_JOTA},
  author       = {Fusco, Giovanni and Motta, Monica and Vinter, Richard},
  doi          = {10.1007/s10957-025-02845-8},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--33},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Optimal control problems with vector-valued impulse controls and time delays},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Variational methods for equilibrium problems applied to electricity markets. <em>JOTA</em>, <em>208</em>(1), 1--29. (<a href='https://doi.org/10.1007/s10957-025-02846-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the study of an economic equilibrium problem for an electricity market model in a multistage-stochastic framework, where,stage by stage, the uncertainty evolves with continuity. We analyze the point of view of a finite number of power companies in a sequence of competitive markets.Each of them produces electricity, both with conventional and renewable-based plants, participates in the trade in the spot markets that open after the uncertainty is revealed, and signs bilateral and forward contracts. Moreover, we capture the risk attitude of each power company by considering a suitable coherent risk measure in the problem’s formulation. In order to prove the existence of at least one equilibrium solution, we introduce a suitable quasi-variational inequality formulation. In this light, we also investigate suitable regularity properties of the involved superdifferential operator in the presence of certain parameter perturbations in Banach spaces.},
  archive      = {J_JOTA},
  author       = {De Giuli, Maria Elena and Milasi, Monica and Oggioni, Giorgia and Scopelliti, Domenico},
  doi          = {10.1007/s10957-025-02846-7},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--29},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Variational methods for equilibrium problems applied to electricity markets},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing sharp augmented lagrangian methods with smoothing techniques for nonlinear programming. <em>JOTA</em>, <em>208</em>(1), 1--43. (<a href='https://doi.org/10.1007/s10957-025-02847-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel approach to solving nonlinear programming problems using a sharp augmented Lagrangian method with a smoothing technique. Traditional sharp augmented Lagrangian methods are known for their effectiveness but are often hindered by the need for global minimization of nonconvex, nondifferentiable functions at each iteration. To address this challenge, we introduce a smoothing function that approximates the sharp augmented Lagrangian, enabling the use of primal minimization strategies similar to those in Powell–Hestenes–Rockafellar (PHR) methods. Our approach retains the theoretical rigor of classical duality schemes while allowing for the use of stationary points in the primal optimization process. We present two algorithms based on this method–one utilizing standard descent and the other employing coordinate descent. Numerical experiments demonstrate that our smoothing–based method compares favorably with the PHR augmented Lagrangian approach, offering both robustness and practical efficiency. The proposed method is particularly advantageous in scenarios where exact minimization is computationally infeasible, providing a balance between theoretical precision and computational tractability.},
  archive      = {J_JOTA},
  author       = {Romero, José Luis and Fernández, Damián and Torres, Germán Ariel},
  doi          = {10.1007/s10957-025-02847-6},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--43},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Enhancing sharp augmented lagrangian methods with smoothing techniques for nonlinear programming},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A principle for global optimization with gradients. <em>JOTA</em>, <em>208</em>(1), 1--23. (<a href='https://doi.org/10.1007/s10957-025-02848-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work demonstrates the utility of gradients for the global optimization of certain differentiable functions with many suboptimal local minima. To this end, a principle for generating non-local quadratic approximants, and the associated search directions, from gradient information of multimodal objective functions is analyzed. Experiments measure the quality of non-local search directions as well as the performance of the principle embedded into a simplistic algorithm, of the covariance matrix adaptation evolution strategy (CMA-ES), and of a randomly reinitialized Broyden-Fletcher-Goldfarb-Shanno (BFGS) method.},
  archive      = {J_JOTA},
  author       = {Müller, Nils},
  doi          = {10.1007/s10957-025-02848-5},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--23},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {A principle for global optimization with gradients},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Directionally variational analysis and second-order optimality conditions for mathematical programs with switching constraints. <em>JOTA</em>, <em>208</em>(1), 1--45. (<a href='https://doi.org/10.1007/s10957-025-02849-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The switching constraint refers to a constraint in which the product of two functions is equal to zero, which exists extensively in the control and optimization community. This paper is devoted to investigate directionally variational analysis and the second-order optimality conditions for mathematical programs with switching constraints (MPSC) originated from optimal control theory. Developing the variational analysis associated with switching constraints, we present explicit formulas of radial cone, (directional) tangent cones, (directional) normal cones, outer (inner) second-order tangent set as well as geometrically derivability and parabolically derivability of the cross set. The relations among the (directional) tangent cones and normal cones, and second-order tangent set are established. The decompositions of normal cones, tangent cones and second-order tangent sets associated with Cartesian product of the cross set and a nonempty closed set are also obtained. We derive the characterizations, such as the non-emptiness, uniqueness, convexity and compactness, of the multiplier sets and directional multiplier sets associated with the stationary points and directional stationary points of MPSC. Then the second-order necessary conditions and the second-order growth conditions of MPSC are established by the second-order tangent sets. Besides, the second-order optimality conditions of MPSC are also established by using the Fréchet second-order subdifferentials, where the involved functions are lack of the twice-differentiability.},
  archive      = {J_JOTA},
  author       = {Chen, Jiawei and Liu, Luyu and Dai, Yuhong and Köbis, Elisabeth},
  doi          = {10.1007/s10957-025-02849-4},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--45},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Directionally variational analysis and second-order optimality conditions for mathematical programs with switching constraints},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Solution stability and well-posedness for classes of parametric set optimization problems. <em>JOTA</em>, <em>208</em>(1), 1--25. (<a href='https://doi.org/10.1007/s10957-025-02850-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the solution stability and well-posedness for a parametric set optimization problem (PSOP), where lower and upper set order relations are induced by an improvement set. We provide new sufficient conditions for the outer-continuity, outer-openness and inner-openness of the solution mapping of (PSOP). By utilizing the property of cone-continuity, we derive sufficient conditions ensuring the Levitin-Polyak well-posedness for (PSOP) and the Hadamard well-posedness for a related parametric implicit set optimization problem (ISOP). Numerical examples are also given to illustrate the main results.},
  archive      = {J_JOTA},
  author       = {Peng, Zai-Yun and Zeng, Yue and Chuong, Thai Doan and Yun, Sangwoon and Yang, Xin},
  doi          = {10.1007/s10957-025-02850-x},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--25},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Solution stability and well-posedness for classes of parametric set optimization problems},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Pareto well-posedness for set-valued optimization problems in geoffroy spaces. <em>JOTA</em>, <em>208</em>(1), 1--52. (<a href='https://doi.org/10.1007/s10957-025-02851-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the well-posedness of set-valued optimization problems within a new topological conlinear structure called Geoffroy space. We first study the nonemptyness and the closedness of the set of Pareto minimal solutions. Then, we introduce three notions of well-posedness related to this class of minimal solutions and give some necessary and sufficient conditions ensuring the well-posedness of set-valued optimization problems. We conclude our study by applying our theoretical results to non-convex portfolio optimization problems arising in finance.},
  archive      = {J_JOTA},
  author       = {Larrouy, James},
  doi          = {10.1007/s10957-025-02851-w},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--52},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Pareto well-posedness for set-valued optimization problems in geoffroy spaces},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Convergence of solutions in set optimization based on null set. <em>JOTA</em>, <em>208</em>(1), 1--27. (<a href='https://doi.org/10.1007/s10957-025-02852-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main objective of the paper is to study the convergence of solution sets in set optimization where the set order relation is based on the concept of null set. The perturbed problems involve perturbation of both the objective map and the feasible set. Upper and lower Painlevé–Kuratowski convergence results are established for the minimal and weak minimal solution sets in the domain space. Additionally, a new notion of convergence is defined in terms of the scalarizing function in the hyperspace to establish a convergence in the image space.},
  archive      = {J_JOTA},
  author       = {Lalitha, C. S. and Moar, Anveksha},
  doi          = {10.1007/s10957-025-02852-9},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--27},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Convergence of solutions in set optimization based on null set},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal structures of crop irrigation strategies with state constraints. <em>JOTA</em>, <em>208</em>(1), 1--29. (<a href='https://doi.org/10.1007/s10957-025-02854-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate an optimal control problem of crop irrigation with non-autonomous and non-smooth dynamics. Depending on contexts and objectives, several formulations associated to different constraints and criteria can be derived. Our work aims at providing optimal feedback solutions for these problems by deriving and analyzing the optimality necessary conditions. To this end, we assemble the different problems into a common formulation, and we carry out a dedicated way of handling state constraints. We show that all optimal irrigation strategies belong to a family of simple parameterized time-varying feedback controls, independently of the context and objective, and suitable for computational purposes.},
  archive      = {J_JOTA},
  author       = {Chenevat, Ruben and Cheviron, Bruno and Roux, Sébastien and Rapaport, Alain},
  doi          = {10.1007/s10957-025-02854-7},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--29},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Optimal structures of crop irrigation strategies with state constraints},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Necessary optimality conditions for a class of bilevel problems. <em>JOTA</em>, <em>208</em>(1), 1--30. (<a href='https://doi.org/10.1007/s10957-025-02855-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a class of bilevel optimization problems involving an upper level problem which is a static optimization problem aimed at minimizing a first performance criterion over optimal trajectories. These trajectories are parameterized by a set of parameters (which has the structure of a metric space) and evaluated at a finite set of prescribed time instants. The optimal trajectories are the minimizers of a lower level problem, which is a dynamic optimization problem where the objective is to minimize a second cost functional over trajectory/control pairs on a given time interval. We consider intermediate-point problems (i.e. performance criteria take into account the values of the trajectories in the middle of the underlying time interval) including problems with free final and intermediate-point constraints, as well as problems with more general endpoint and intermediate-point constraints. We introduce, to the best of our knowledge, a new notion of solution for the reference bilevel problem: this is a pair composed of a control function and a family of associated trajectories that are optimal for both the upper and lower problems. We establish necessary conditions of optimality for these classes of bilevel problems by transforming them into single ‘min-min’ optimal control problems with uncertainty parameters. To derive our results, we employ perturbation methods to construct, with the help of Ekeland’s variational principle, a sequence of multiprocess optimization problems, on which we apply Clarke and Vinter’s multiprocesses theory together with techniques recently developed for optimal control problems with uncertainty parameters which can be adapted to the bilevel problem studied in the present paper.},
  archive      = {J_JOTA},
  author       = {Abdel Wahab, Abdallah and Bettiol, Piernicola},
  doi          = {10.1007/s10957-025-02855-6},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--30},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Necessary optimality conditions for a class of bilevel problems},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimization on the quaternion stiefel manifold with Applications—Part i: Basic geometry. <em>JOTA</em>, <em>208</em>(1), 1--37. (<a href='https://doi.org/10.1007/s10957-025-02859-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quaternion Stiefel manifold, denoted by $${{\,\textrm{St}\,}}_{\mathbb {Q}}(n,p)$$ , is the set of $$n\times p$$ partially unitary quaternion matrices. Optimization problems on $${{\,\textrm{St}\,}}_{\mathbb {Q}}(n,p)$$ arise in several areas, including color image processing, numerical quaternion linear algebra, and airborne direct georeferencing. This work, with its two parts, is aimed at developing a Riemannian optimization approach to problems over $${{\,\textrm{St}\,}}_{\mathbb {Q}}(n,p)$$ and presenting its application to robust dimension reduction of quaternion data. In this part, we focus on the relevant geometric tools. We first study the basic geometry of $${{\,\textrm{St}\,}}_{\mathbb {Q}}(n,p)$$ ; in particular, its relations to the complex and real Stiefel manifolds are established. Then, formulas for tangent space, Riemannian gradient, Riemannian Hessian, various retractions, and three types of vector transports are derived. With these tools, Riemannian optimization algorithms can be adapted to the quaternion domain. Application to a novel model of quaternion principal component analysis based on $$\ell _1$$ -norm is given in the second part.},
  archive      = {J_JOTA},
  author       = {Wang, Ying and Yang, Yuning},
  doi          = {10.1007/s10957-025-02859-2},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--37},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Optimization on the quaternion stiefel manifold with Applications—Part i: Basic geometry},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fully adaptive zeroth-order method for minimizing functions with compressible gradients. <em>JOTA</em>, <em>208</em>(1), 1--25. (<a href='https://doi.org/10.1007/s10957-025-02860-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an adaptive zeroth-order method for minimizing differentiable functions with L-Lipschitz continuous gradients. The method is designed to take advantage of the eventual compressibility of the gradient of the objective function, but it does not require knowledge of the approximate sparsity level s or the Lipschitz constant L of the gradient. We show that the new method performs no more than $$\mathcal {O}\left( n^{2}\epsilon ^{-2}\right) $$ function evaluations to find an $$\epsilon $$ -approximate stationary point of an objective function with n variables. Assuming additionally that the gradients of the objective function are compressible, we obtain an improved complexity bound of $$\mathcal {O}\left( s\log \left( n\right) \epsilon ^{-2}\right) $$ function evaluations, which holds with high probability. Preliminary numerical results illustrate the efficiency of the proposed method and demonstrate that it can significantly outperform its non-adaptive counterpart.},
  archive      = {J_JOTA},
  author       = {Grapiglia, Geovani N. and McKenzie, Daniel},
  doi          = {10.1007/s10957-025-02860-9},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--25},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Fully adaptive zeroth-order method for minimizing functions with compressible gradients},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Solvability and optimal feedback control results for higher order fractional differential systems. <em>JOTA</em>, <em>208</em>(1), 1--22. (<a href='https://doi.org/10.1007/s10957-025-02862-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary objective of this manuscript is to develop a systematic framework for analysing feedback control systems governed by fractional differential equations involving the Caputo derivative of order $$1< \mu < 2$$ in Banach spaces. Initially, the existence of mild solutions is established through fractional calculus, cosine operator families, and Schauder’s fixed-point theorem. Subsequently, by employing the Filippov theorem and the Cesari property, we derive a set of novel conditions that guarantee the existence of feasible control-state pairs for the system. To identify the optimal feedback control pairs, the main theoretical findings are systematically applied. Finally, a theoretical example is presented to illustrate the applicability and validate the proposed methodology and results.},
  archive      = {J_JOTA},
  author       = {Dhanush, A. and Vijayakumar, V.},
  doi          = {10.1007/s10957-025-02862-7},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--22},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Solvability and optimal feedback control results for higher order fractional differential systems},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Anderson acceleration of derivative-free projection methods for constrained monotone nonlinear equations. <em>JOTA</em>, <em>208</em>(1), 1--30. (<a href='https://doi.org/10.1007/s10957-025-02841-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The derivative-free projection method (DFPM) is an efficient algorithm for solving monotone nonlinear equations. As problems grow larger, there is a strong demand for speeding up the convergence of DFPM. This paper considers the application of Anderson acceleration (AA) to DFPM for constrained monotone nonlinear equations. By employing a nonstationary relaxation parameter and interleaving with slight modifications in each iteration, a globally convergent variant of AA for DFPM named AA-DFPM is proposed. Further, the linear convergence rate is proved under some mild assumptions. Experiments on both mathematical examples and a real-world application show encouraging results of AA-DFPM and confirm the suitability of AA for accelerating DFPM in solving optimization problems.},
  archive      = {J_JOTA},
  author       = {Jin, Jiachen and Wang, Hongxia and Deng, Kangkang},
  doi          = {10.1007/s10957-025-02841-y},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--30},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Anderson acceleration of derivative-free projection methods for constrained monotone nonlinear equations},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimal testing strategies in long-term care facilities during pandemics. <em>JOTA</em>, <em>208</em>(1), 1--33. (<a href='https://doi.org/10.1007/s10957-025-02843-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic has significantly impacted long-term care facilities, with retirement homes being particularly vulnerable due to the high mortality risk among infected elderly residents. Once an outbreak occurs, containing the virus is challenging due to frequent resident interactions and limited isolation measures. While regular testing has proven effective in preventing outbreaks, high-frequency testing can strain staff resources, creating a trade-off between testing efforts and essential care provision. This paper addresses this challenge by proposing two novel optimization models for testing schedules that minimize infection risk while balancing staff workload. Using a probabilistic approach, the models incorporate factors such as contact rates, incidence status, and infection probabilities among residents. To solve these models, we introduce an enhanced local search algorithm that leverages the symmetry property of optimal solutions. Experimental results demonstrate the effectiveness of the proposed approach, outperforming a genetic algorithm in deriving optimal testing strategies.},
  archive      = {J_JOTA},
  author       = {Davoodi, Mansoor and Batista, Ana and Senapati, Abhishek and Schlechte-Welnicz, Weronika and Wagner, Birgit and Calabrese, Justin M.},
  doi          = {10.1007/s10957-025-02843-w},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--33},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Optimal testing strategies in long-term care facilities during pandemics},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Two-variable domination structures and applications in vector optimization. <em>JOTA</em>, <em>208</em>(1), 1--35. (<a href='https://doi.org/10.1007/s10957-025-02857-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce and study domination structures in real topological Hausdorff linear spaces that take into account the two involved points at each comparison. These binary relations are then applied to define notions of minimizer of a set and optimality concepts for vector optimization problems in the usual way, and their basic properties are obtained. Results on nonlinear scalarization to characterize them are also stated, which can be applied to vector optimization problems with variable ordering structures where the known ones do not work. Comparisons with results of the literature and illustrative examples are given as well.},
  archive      = {J_JOTA},
  author       = {Ngoan, Dang Thi and Gutiérrez, César and An, Duong Thi Viet},
  doi          = {10.1007/s10957-025-02857-4},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--35},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Two-variable domination structures and applications in vector optimization},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid deep reinforcement learning method for insurance portfolio management. <em>JOTA</em>, <em>208</em>(1), 1--42. (<a href='https://doi.org/10.1007/s10957-025-02858-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a hybrid deep reinforcement learning approach to manage an insurance portfolio for diffusion models. To address the model uncertainty, we adopt the recently developed modelling of exploration and exploitation strategies in a continuous-time decision-making process with reinforcement learning. We consider an insurance portfolio management problem in which an entropy-regularized reward function and corresponding relaxed stochastic controls are formulated. To obtain the optimal relaxed stochastic controls, we develop a Markov chain approximation and stochastic approximation-based iterative deep reinforcement learning algorithm where the probability distribution of the optimal stochastic controls is approximated by neural networks. In our hybrid algorithm, both Markov chain approximation and stochastic approximation are adopted in the learning processes. The idea of using the Markov chain approximation method to find initial guesses is proposed. A stochastic approximation is adopted to estimate the parameters of neural networks. Convergence analysis of the algorithm is presented. Numerical examples are provided to illustrate the performance of the algorithm.},
  archive      = {J_JOTA},
  author       = {Cheng, Xiang and Jin, Zhuo and Yang, Hailiang and Yin, George},
  doi          = {10.1007/s10957-025-02858-3},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--42},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {A hybrid deep reinforcement learning method for insurance portfolio management},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The R-linear convergence of IPPDA for symmetric low rank orthogonal tensor approximation. <em>JOTA</em>, <em>208</em>(1), 1--28. (<a href='https://doi.org/10.1007/s10957-025-02861-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we establish the generic R-linear convergence of an improved proximal polar decomposition algorithm (iPPDA) for the symmetric low rank orthogonal tensor approximation problem. For this purpose, the map from the parametrization space to the set of symmetric low rank orthogonally decomposable tensors is studied. We show that there is a natural stratification of the set of symmetric low rank orthogonally decomposable tensors, and there is a local diffeomorphism from the parametrization manifold to the smooth part of the set of symmetric low rank orthogonally decomposable tensors. As a result, properties of the Euclidean projection onto a manifold via Morse theory can be employed, and the generic R-linear convergence can be shown.},
  archive      = {J_JOTA},
  author       = {Hu, Shenglong and Zhou, Ying},
  doi          = {10.1007/s10957-025-02861-8},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--28},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {The R-linear convergence of IPPDA for symmetric low rank orthogonal tensor approximation},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Convergence of first-order algorithms with momentum from the perspective of an inexact gradient descent method. <em>JOTA</em>, <em>208</em>(1), 1--38. (<a href='https://doi.org/10.1007/s10957-025-02864-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel inexact gradient descent method with momentum (IGDm) considered as a general framework for various first-order methods with momentum. This includes, in particular, the inexact proximal point method (IPPm), extragradient method (EGm) coming from variational inequalities, and sharpness-aware minimization (SAMm). Asymptotic convergence properties of IGDm are established under both global and local assumptions on objective functions with providing constructive convergence rates depending on the Polyak-Łojasiewicz-Kurdyka (PLK) conditions for the objective function. Global convergence of EGm and SAMm for general smooth functions and of IPPM for weakly convex functions is derived in this way. Moreover, local convergence properties of EGm and SAMm for locally smooth functions as well as of IPPm for prox-regular functions are established. Numerical experiments for derivative-free optimization problems are conducted to confirm the efficiency of the momentum effects of the developed methods under the inexactness of gradient computations.},
  archive      = {J_JOTA},
  author       = {Khanh, Pham Duy and Mordukhovich, Boris S. and Tran, Dat Ba},
  doi          = {10.1007/s10957-025-02864-5},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--38},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Convergence of first-order algorithms with momentum from the perspective of an inexact gradient descent method},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nonsmooth techniques for computing projected solutions of quasiequilibria via gap functions. <em>JOTA</em>, <em>208</em>(1), 1--21. (<a href='https://doi.org/10.1007/s10957-025-02865-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Projected solutions to a quasiequilibrium problem allow overcoming the possible lack of solutions when the constraining set-valued map is not a self-map. This paper aims at providing a descent algorithm for computing projected solutions by relying on a reformulation of the problem as a nonsmooth optimization problem. The nonsmoothness of the gap function can be dealt with successfully through the nonexpansiveness of the projection and tools such as Clarke subdifferentials. Nonetheless, some additional difficulties arise since the projection brings in nonsmoothness also in constraints that are provided by differentiable bifunctions. Monotonicity assumptions on the constraints have to cope with this further issue both to devise the algorithm and prove its convergence. Preliminary numerical tests show a promising behaviour of the algorithm.},
  archive      = {J_JOTA},
  author       = {Bigi, Giancarlo and Castellani, Marco and Latini, Sara},
  doi          = {10.1007/s10957-025-02865-4},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--21},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Nonsmooth techniques for computing projected solutions of quasiequilibria via gap functions},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On differential stability of a class of convex optimization problems. <em>JOTA</em>, <em>208</em>(1), 1--17. (<a href='https://doi.org/10.1007/s10957-025-02856-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent results of An, Luan, and Yen [Differential stability in convex optimization via generalized polyhedrality. Vietnam Journal of Mathematics 53, 721–734 (2025)] on differential stability of parametric optimization problems described by proper generalized polyhedral convex functions and generalized polyhedral convex set-valued maps are analyzed, developed, and sharpened in this paper. Namely, keeping the Hausdorff locally convex topological vector spaces setting, we clarify the relationships between the upper estimates and lower estimates for the subdifferential and the singular subdifferential of the optimal value function. As shown by an example, the lower estimates can be strict. But, surprisingly, each upper estimate is an equality. Thus, exact formulas for the subdifferential and the singular subdifferential under consideration are obtained. In addition, it is proved that each subdifferential upper estimate coincides with the corresponding lower estimate if either the objective function or the constraint set-valued map is polyhedral convex.},
  archive      = {J_JOTA},
  author       = {Yen, Nguyen Dong and An, Duong Thi Viet and Huong, Vu Thi and Luan, Nguyen Ngoc},
  doi          = {10.1007/s10957-025-02856-5},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--17},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {On differential stability of a class of convex optimization problems},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cyclic stochastic gradient descent method. <em>JOTA</em>, <em>208</em>(1), 1--32. (<a href='https://doi.org/10.1007/s10957-025-02867-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic gradient descent (SGD) method is a commonly used optimization method in machine learning. Its stepsize is a crucial factor for convergence property. The cyclic stepsize update strategy for SGD is proposed, where the approximated Cauchy step and the constant stepsize are combined. The current Cauchy step is approximated by the BB step in the next iteration. Combining with both monotone and nonmonotone linesearches, we establish the convergence results for the cyclic SGD method. The convergence analysis for different types of problems are provided. Compared to the theoretical results in literatures, the convergence assumptions for convex and strongly convex problems are weaker, where the impractical interpolation condition assumption is removed. Numerical experiments show that the proposed stepsize easily satisfies the linesearch requirement; the proposed method outperforms the benchmark methods, and enjoys the insensitivity to initialization.},
  archive      = {J_JOTA},
  author       = {Xie, Zhijie and Sun, Cong},
  doi          = {10.1007/s10957-025-02867-2},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--32},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Cyclic stochastic gradient descent method},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Normal cones in groups and optimality conditions. <em>JOTA</em>, <em>208</em>(1), 1--36. (<a href='https://doi.org/10.1007/s10957-025-02866-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce the notion of normal cone to a set in the setting of groups. With appropriate assumptions on the groups involved, we establish various calculus rules including the normal cone intersection rule and the subdifferential sum rule. These results in turn lead to optimality conditions for constrained optimization problems in terms of normal cones and subdifferentials.},
  archive      = {J_JOTA},
  author       = {Meenakshi and Moar, Anveksha and Lalitha, C. S.},
  doi          = {10.1007/s10957-025-02866-3},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--36},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Normal cones in groups and optimality conditions},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). New constraint qualifications based on the decomposition of the cone defined by the karush-kuhn-tucker conditions.. <em>JOTA</em>, <em>208</em>(1), 1--28. (<a href='https://doi.org/10.1007/s10957-025-02868-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce new constraint qualifications for optimization problems in Banach spaces. These are derived from a suitable decomposition of the cone associated with the Karush-Kuhn-Tucker (KKT) conditions into a linear subspace and a pointed cone. Based on this decomposition, we propose novel sequential (or asymptotic) constraint qualifications. Due to the geometric appeal of our new constraint qualifications, they fit naturally into general conic optimization problems and thus enhance the applicability of our approach. Furthermore, when applied to nonlinear optimization problems, the proposed qualifications are weaker than Robinson’s and other constant rank-type constraint qualifications commonly found in the literature, yet they remain strong enough to guarantee the validity of the error bound property, which plays a central role in sensitivity analysis and algorithmic convergence. All important statements are illustrated by examples.},
  archive      = {J_JOTA},
  author       = {Ramos, Alberto},
  doi          = {10.1007/s10957-025-02868-1},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--28},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {New constraint qualifications based on the decomposition of the cone defined by the karush-kuhn-tucker conditions.},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A quasi-optimization problem for a family of functions. <em>JOTA</em>, <em>208</em>(1), 1--19. (<a href='https://doi.org/10.1007/s10957-025-02869-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we deal with an optimization problem: finding a common maximum point for a family of objective functions on a set-valued map. We reformulate this problem in terms of a suitable variational problem to establish the existence of a solution. In this variational approach, the notion of quasiconcave family is of central importance. Finally, we apply our study to the Kantian equilibrium.},
  archive      = {J_JOTA},
  author       = {Giordano, Mario Diego Emanuele and Milasi, Monica},
  doi          = {10.1007/s10957-025-02869-0},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--19},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {A quasi-optimization problem for a family of functions},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Computing proximity operators of scale and signed permutation invariant functions. <em>JOTA</em>, <em>208</em>(1), 1--28. (<a href='https://doi.org/10.1007/s10957-025-02871-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the computation of proximity operators for scale and signed permutation invariant functions. A scale invariant function remains unchanged under uniform scaling, while a signed permutation invariant function retains its structure despite permutations and sign changes applied to its input variables. Noteworthy examples include the $$\ell _0$$ function, the ratio of $$\ell _1/\ell _2$$ , and its square, with their proximity operators being particularly crucial in sparse signal recovery. We delve into the properties of scale and signed permutation invariant functions, delineating the computation of their proximity operators into three sequential steps: the $${\varvec{w}}$$ -step, r-step, and d-step. These steps collectively form a procedure termed as WRD, with the $${\varvec{w}}$$ -step being of utmost importance and requiring careful treatment. Leveraging this procedure, we present a method for explicitly and efficiently computing the proximity operator of $$(\ell _1/\ell _2)^2$$ and introduce an algorithm for the proximity operator of $$\ell _1/\ell _2$$ . Numerical experiments on sparse signal recovery corroborate the analysis and show that first-order methods equipped with these proximity operators outperform $$\ell _1$$ -based baselines in reconstruction accuracy.},
  archive      = {J_JOTA},
  author       = {Jia, Jianqing and Prater-Bennette, Ashley and Shen, Lixin},
  doi          = {10.1007/s10957-025-02871-6},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--28},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Computing proximity operators of scale and signed permutation invariant functions},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stationary and nonstationary equilibria of duel and truel with random shooting order. <em>JOTA</em>, <em>208</em>(1), 1--30. (<a href='https://doi.org/10.1007/s10957-025-02873-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study duel and truel variants in which two or three players, respectively, shoot each other in random order (or abstain from shooting). Depending on the final outcome of the game (number of survivors), each player may receive both positive, zero or negative payoff. We compute payoffs under stationary strategies by solving a system of linear equations, which always has a unique solution. Then we compute Nash equilibria under stationary strategies and shown that there is always a shooting NE and, under appropriate conditions, the truel also has a nonshooting stationary NE. We also provide a number of nonstationary NE, obtained by using a “grim triggering mechanism” to punish deviations from equilibrium. Finally, we briefly discuss: (a) extensions to the case of more than three players (nuel) (b) the connection of our model to applied problems and (c) the relationship to the Prisoner’s Dilemma and to the family of contest games.},
  archive      = {J_JOTA},
  author       = {Kehagias, Athanasios and Mastrakoulis, Symeon},
  doi          = {10.1007/s10957-025-02873-4},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--30},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Stationary and nonstationary equilibria of duel and truel with random shooting order},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On growth error bound conditions with an application to heavy ball method. <em>JOTA</em>, <em>208</em>(1), 1--30. (<a href='https://doi.org/10.1007/s10957-025-02880-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the growth error bound condition. By using the proximal point algorithm, we first provide a more accessible and elementary proof of the fact that Kurdyka-Łojasiewicz conditions imply growth error bound conditions for convex functions which has been established before via a subgradient flow. We then extend the result for nonconvex functions. Furthermore we show that every definable function in an o-minimal structure must satisfy a growth error bound condition. Finally, as an application, we consider the heavy ball method for solving convex optimization problems and nonlinear equations and propose an adaptive strategy for selecting the momentum coefficient. Under growth error bound conditions, we derive convergence rates of the proposed method. A numerical experiment is conducted to demonstrate its acceleration effect over the gradient method.},
  archive      = {J_JOTA},
  author       = {Jin, Qinian},
  doi          = {10.1007/s10957-025-02880-5},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--30},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {On growth error bound conditions with an application to heavy ball method},
  volume       = {208},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
