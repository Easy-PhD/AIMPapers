<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JCO</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jco">JCO - 115</h2>
<ul>
<li><details>
<summary>
(2025). An improvement on the louvain algorithm using random walks. <em>JCO</em>, <em>50</em>(2), 1-26. (<a href='https://doi.org/10.1007/s10878-025-01337-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present improvements to famous algorithms for community detection, namely Newman’s spectral method algorithm and the Louvain algorithm. The Newman algorithm begins by treating the original graph as a single cluster, then repeats the process to split each cluster into two, based on the signs of the eigenvector corresponding to the second-largest eigenvalue. Our improvement involves replacing the time-consuming computation of eigenvalues with a random walk during the splitting process. The Louvain algorithm iteratively performs the following steps until no increase in modularity can be achieved anymore: each step consists of two phases–phase 1 for partitioning the graph into clusters, and phase 2 for constructing a new graph where each vertex represents one cluster obtained from phase 1. We propose an improvement to this algorithm by adding our random walk algorithm as an additional phase for refining clusters obtained from phase 1. It maintains a complexity comparable to the Louvain algorithm while exhibiting superior efficiency. To validate the robustness and effectiveness of our proposed algorithms, we conducted experiments using randomly generated graphs and real-world data.},
  archive      = {J_JCO},
  author       = {Do, Duy Hieu and Phan, Thi Ha Duong},
  doi          = {10.1007/s10878-025-01337-9},
  journal      = {Journal of Combinatorial Optimization},
  month        = {9},
  number       = {2},
  pages        = {1-26},
  shortjournal = {J. Comb. Optim.},
  title        = {An improvement on the louvain algorithm using random walks},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strategy-proof mechanisms for maximizing social satisfaction in the facility location game. <em>JCO</em>, <em>50</em>(2), 1-20. (<a href='https://doi.org/10.1007/s10878-025-01341-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The facility location game, where the agents’ locations are on a line, is considered in this paper. The input consists of the reported locations of agents, which are collected as part of the game setup. We introduce the concept of a fairness baseline and define a function to characterize each agent’s satisfaction with the facility location. Our objective is to establish a mechanism that obtains the true information of agents and outputs a single facility location so that the sum of all agents’ satisfaction with the location is maximized. For the game with two agents, we propose a $$\frac{5}{4}$$ -approximate strategy-proof mechanism, which is the best possible. In the general case, we demonstrate that the median mechanism achieves an approximation ratio of $$\frac{3}{2}$$ . In particular, the median mechanism is an optimal group strategy-proof mechanism for the game with three agents. Additionally, we devise a $$\frac{1+\sqrt{3}}{2}$$ -approximation group strategy-proof mechanism by modifying the median mechanism. We also consider social satisfaction in the obnoxious facility location game and design a mechanism based on the median of the input.},
  archive      = {J_JCO},
  author       = {Li, Xiaowei and Lu, Xiwen},
  doi          = {10.1007/s10878-025-01341-z},
  journal      = {Journal of Combinatorial Optimization},
  month        = {9},
  number       = {2},
  pages        = {1-20},
  shortjournal = {J. Comb. Optim.},
  title        = {Strategy-proof mechanisms for maximizing social satisfaction in the facility location game},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximum expert consensus models with both type- $$\alpha $$ and type- $$\varepsilon $$ constraints. <em>JCO</em>, <em>50</em>(2), 1-23. (<a href='https://doi.org/10.1007/s10878-025-01342-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximum expert consensus model (MECM) aims to maximize the number of consensual decision-makers (DMs) within a limited budget. However, it may fail to achieve high group satisfaction or even cannot reach an acceptable consensus due to its neglect of the group consensus level, resulting in type- $$\alpha $$ constraints not being satisfied. To address this issue, we extend the existing MECM by considering both type- $$\alpha $$ and type- $$\varepsilon $$ consensus constraints to enable the group consensus level and the number of consensual DMs as large as possible. Firstly, we construct a dual-MECM that considers the above two constraints. Secondly, we further develop a dual-MECM considering compromise limits (dual-MECM-CL). To provide a reference for budgeting, a dual minimum cost consensus model (dual-MCCM) is established to determine the upper and lower bounds of the budget. Subsequently, we explore the relationships between the two proposed MECMs and the existing MECM. Finally, the effectiveness of the proposed models is illustrated by numerical examples. The results show that: (1) The dual-MECM can ensure that the majority of DMs reach consensus while maintaining a high group consensus level. (2) With a limited budget, the improvement of the overall consensus level will lead to the reduction in the number of consensual DMs. (3) Consideration of individual compromise limits may reduce the number of consensual DMs within the same budget. Therefore, the proposed models can derive a more reasonable consensus result due to full consideration of consensus measurements and DMs’ behaviors.},
  archive      = {J_JCO},
  author       = {Cheng, Dong and Zhang, Huina and Wu, Yong},
  doi          = {10.1007/s10878-025-01342-y},
  journal      = {Journal of Combinatorial Optimization},
  month        = {9},
  number       = {2},
  pages        = {1-23},
  shortjournal = {J. Comb. Optim.},
  title        = {Maximum expert consensus models with both type- $$\alpha $$ and type- $$\varepsilon $$ constraints},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Moving horizon capacitated arc routing problem. <em>JCO</em>, <em>50</em>(2), 1-35. (<a href='https://doi.org/10.1007/s10878-025-01344-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In transportation networks, routing problems are cursed with arbitrary changes occurring in the dataset due to unpredictable events like agent breakdown (sensor or vehicle failure), network connectivity changes, resource/demand fluctuations, etc. Moreover, capacity restriction on the agents may require multi-trip solutions for meeting large demands over networks. For example, a battery-powered inspection wagon can only service a limited number of track sections in a single trip. We investigate a moving horizon approach for the multi-trip dynamic capacitated arc routing problem with limited duration to mitigate the limitations of CARP variants in the literature. The proposed approach addresses arbitrary changes in the underlying network, agent unavailability scenarios, and simultaneously satisfies the time limit on meeting all demands. The moving horizon approach subdivides the planning horizon to determine the current trip (single-trip) for all agents, hence coined as Moving Horizon Capacitated Arc Routing Problem (MH-CARP). The proposed MH-CARP is formulated as a set covering problem that considers both partial and full trips (trips may not start at the depot), making it suitable for tackling arbitrary events by re-planning. Theoretical results for the computation of dual variables are derived and then implemented in the column generation algorithm to obtain lower bounds. The algorithm is validated on a widely available dataset for CARP, having instances of up to 147 tasks that require servicing by up to 20 agents. Using this benchmark data, the partial-trip based re-planning strategy is also validated. Lastly, a simulation study is presented to demonstrate the re-planning strategy and compare an MH-CARP solution to two CARP based solutions - one with no arbitrary events and the other with known arbitrary events. The results also convey that greedy solutions are avoided to satisfy the limited duration restriction, and automatic re-ordering of the trips is achieved to compensate for arbitrary events.},
  archive      = {J_JCO},
  author       = {Buriuly, Somnath and Vachhani, Leena and Sinha, Arpita and Ravitharan, Sivapragasam and Chauhan, Sunita},
  doi          = {10.1007/s10878-025-01344-w},
  journal      = {Journal of Combinatorial Optimization},
  month        = {9},
  number       = {2},
  pages        = {1-35},
  shortjournal = {J. Comb. Optim.},
  title        = {Moving horizon capacitated arc routing problem},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semistrong edge colorings of planar graphs. <em>JCO</em>, <em>50</em>(2), 1-30. (<a href='https://doi.org/10.1007/s10878-025-01346-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strengthened notions of a matching M of a graph G have been considered, requiring that the matching M has some properties with respect to the subgraph $$G_M$$ of G induced by the vertices covered by M: If M is the unique perfect matching of $$G_M,$$ then M is a uniquely restricted matching of G; if all the edges of M are pendant edges of $$G_M,$$ then M is a semistrong matching of G; if all the vertices of $$G_M$$ are pendant, then M is an induced matching of G. Strengthened notions of edge coloring and of the chromatic index follow. In this paper, we consider the maximum semistrong chromatic index of planar graphs with given maximum degree $$\Delta .$$ We prove that graphs with maximum average degree less than 14/5 have semistrong chromatic index (hence uniquely restricted chromatic index) at most $$2\Delta +4,$$ and we reduce the bound to $$2\Delta +2$$ if the maximum average degree is less than 8/3. These cases cover, in particular, the cases of planar graphs with girth at least 7 (resp. at least 8). Our result makes some progress on the conjecture of Lužar et al. (J Graph Theory 105:612–632, 2024), which asserts that every planar graph G has a semistrong edge coloring with $$2\Delta +C$$ colors, for some universal constant C. (Note that such a conjecture would fail for strong edge coloring as there exist graphs with arbitrarily large maximum degree that are not strongly $$(4\Delta -5)$$ -edge-colorable.) We provide an example of a planar graph showing that the maximum semistrong chromatic index of planar graphs with maximum degree $$\Delta $$ is at least $$2\Delta +4.$$},
  archive      = {J_JCO},
  author       = {Lin, Yuquan and Lin, Wensong},
  doi          = {10.1007/s10878-025-01346-8},
  journal      = {Journal of Combinatorial Optimization},
  month        = {9},
  number       = {2},
  pages        = {1-30},
  shortjournal = {J. Comb. Optim.},
  title        = {Semistrong edge colorings of planar graphs},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A divide-and-conquer based preprocessing for routing in a simple polygon. <em>JCO</em>, <em>50</em>(2), 1-18. (<a href='https://doi.org/10.1007/s10878-025-01345-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a simple polygon P defined with n vertices in the plane, we preprocess P and compute routing tables at every vertex of P. In the routing phase, a packet originating at any source vertex of P is routed to its destination vertex belonging to P. At every vertex v of P along the routing path, until the packet reaches its destination, the next hop is determined using the routing tables at v and the additional information (including the packet’s destination vertex label) in the packet. We show our routing scheme constructs routing tables in $$O\big (n \big (1+\frac{1}{\epsilon }\big ) \big (\lg {n}\big )^3\big )$$ time and the routing tables at all the vertices of P together use $$O\big (n+\frac{n}{\epsilon }\big (\lg {n}\big )^3\big )$$ space. The multiplicative stretch factor of the routing path computed by our algorithm is upper bounded by $$(2+\epsilon )\lg {n}$$ . Here, $$\epsilon > 0$$ is an input parameter.},
  archive      = {J_JCO},
  author       = {Gaur, Siddharth and Inkulu, R.},
  doi          = {10.1007/s10878-025-01345-9},
  journal      = {Journal of Combinatorial Optimization},
  month        = {9},
  number       = {2},
  pages        = {1-18},
  shortjournal = {J. Comb. Optim.},
  title        = {A divide-and-conquer based preprocessing for routing in a simple polygon},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Embedding crossed cube into diverse product graphs and tree-derived architectures. <em>JCO</em>, <em>50</em>(2), 1-21. (<a href='https://doi.org/10.1007/s10878-025-01350-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The embedding of graphs plays a vital role in simulating parallel architectures into other parallel topologies. Out of all parallel computing architectures in super-computing, hypercube, and its variants cannot be ignored because of the desirable, easily implementable, and applicable properties. One such variant of hypercube is the crossed cube $$CQ^r$$ . With exponential growth in the layout of VLSI designs, the concept of embedding has attained paramount importance. Crossed cube, a highly cited one among the variants of hypercube is explored with respect to embedding in this work. As a sequel, we derive the exact wirelength of embedding crossed cube into certain tree-derived architectures, corona product of a path on $$2^{r-1}$$ nodes into an isolated node (comb), Cartesian product of path on 2 nodes into a path on $$2^{r-1}$$ nodes (ladder) and path (MinLA).},
  archive      = {J_JCO},
  author       = {Immanuel, Paul and Greeni, A. Berin},
  doi          = {10.1007/s10878-025-01350-y},
  journal      = {Journal of Combinatorial Optimization},
  month        = {9},
  number       = {2},
  pages        = {1-21},
  shortjournal = {J. Comb. Optim.},
  title        = {Embedding crossed cube into diverse product graphs and tree-derived architectures},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph coloring problem solving using monte carlo tree search and deep reinforcement learning. <em>JCO</em>, <em>50</em>(2), 1-21. (<a href='https://doi.org/10.1007/s10878-025-01338-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The graph coloring problem, as a well-known NP-hard problem, holds significant value in practical applications. In this paper, a self-learning method that combines Monte Carlo tree search with deep reinforcement learning is proposed to efficiently solve the graph coloring problem. This method offers two principal advantages. Firstly, it leverages deep reinforcement learning to eliminate the necessity for manual feature construction and data labeling. Secondly, by combining the neural network with Monte Carlo tree search, the neural network can provide comprehensive guidance based on the structural information of the graph, facilitating a more effective balance between exploration and exploitation, thereby leading to superior solutions. Finally, experimental results demonstrate that the method proposed herein has distinct advantages over existing graph coloring algorithms. Moreover, this approach also exhibits outstanding performance when dealing with graph instances whose vertex size surpasses those encountered during the training phase.},
  archive      = {J_JCO},
  author       = {Yang, Wenzhu and Li, Zhanshan},
  doi          = {10.1007/s10878-025-01338-8},
  journal      = {Journal of Combinatorial Optimization},
  month        = {9},
  number       = {2},
  pages        = {1-21},
  shortjournal = {J. Comb. Optim.},
  title        = {Graph coloring problem solving using monte carlo tree search and deep reinforcement learning},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). General sombor index: A study of branching in trees and solution for maximal trees with prescribed maximum degree. <em>JCO</em>, <em>50</em>(2), 1-23. (<a href='https://doi.org/10.1007/s10878-025-01343-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The general Sombor ( $$\mathcal{S}\mathcal{O}_\alpha $$ ) index of a graph G is defined as the sum of weights $$\Big (d^2_x(G) +d^2_y(G)\Big )^\alpha $$ over all edges xy of G, where $$\alpha \ne 0$$ is a real number and $$d_x(G)$$ denotes the degree of a vertex x in G. In this paper, we focus on two specific classes of trees: $${{\mathcal {T}}}_{n,b}$$ , the set of all n-vertex trees with b branching vertices, and $${{\mathcal {T}}}_{n,\Delta }$$ , the set of all n-vertex trees with prescribed maximum degree $$\Delta $$ . Thus the purpose of this paper is twofold concerning the $$\mathcal{S}\mathcal{O}_\alpha $$ index: (i) to characterize the minimal trees in $${{\mathcal {T}}}_{n,b}$$ when $$\alpha > 0$$ , and (ii) to characterize the maximal trees in $${{\mathcal {T}}}_{n,\Delta }$$ when $$0<\alpha < 1$$ . The results of (i) hold true even when the class $${{\mathcal {T}}}_{n,b}$$ is confined to the class of chemical trees and also recover previously known results for the Sombor index. The findings in (ii) resolve a previously posed problem for the $$\mathcal{S}\mathcal{O}_{\alpha }\,(0<\alpha <1)$$ index and, moreover, establish analogous results for the well-known general sum-connectivity index, thereby addressing the corresponding unresolved cases for both indices.},
  archive      = {J_JCO},
  author       = {Ahmad, Sultan and Das, Kinkar Chandra},
  doi          = {10.1007/s10878-025-01343-x},
  journal      = {Journal of Combinatorial Optimization},
  month        = {9},
  number       = {2},
  pages        = {1-23},
  shortjournal = {J. Comb. Optim.},
  title        = {General sombor index: A study of branching in trees and solution for maximal trees with prescribed maximum degree},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quaternion-based formulations for volume maximisation problems. <em>JCO</em>, <em>50</em>(2), 1-35. (<a href='https://doi.org/10.1007/s10878-025-01351-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a mathematical formulation for the problem of determining the optimal position for a three-dimensional item inside a convex container, where its scale can be increased the most and thus its volume maximised. Until now, no methods have been presented that guarantee optimal solutions to this volume maximisation problem while considering continuous free rotation of the item, with approaches relying on heuristics, approximations or enforcing a discrete number of rotations. We aim to find optimal solutions when considering continuous rotation, represented using quaternions. This enables modelling rotation through quadratic constraints. The resulting quadratically constrained problem can be solved to optimality by mathematical solvers. To keep the required computation time within reasonable limits, various improvements to the model such as symmetry breaking are introduced. Experiments show that the majority of our benchmark instances can be solved to optimality within minutes. The expansion to concave containers is also explored, but proves to be more challenging as the required number of quadratic constraints quickly becomes prohibitive.},
  archive      = {J_JCO},
  author       = {Tollenaere, Jonas and Wauters, Tony},
  doi          = {10.1007/s10878-025-01351-x},
  journal      = {Journal of Combinatorial Optimization},
  month        = {9},
  number       = {2},
  pages        = {1-35},
  shortjournal = {J. Comb. Optim.},
  title        = {Quaternion-based formulations for volume maximisation problems},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synchronizing production planning and job scheduling: MILP models and exact algorithms. <em>JCO</em>, <em>50</em>(1), 1-21. (<a href='https://doi.org/10.1007/s10878-025-01326-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the synchronization of a resource production process with the consumption of related resources by jobs. Both processes interact through transfer transactions, which become the key components of the resulting scheduling problem. This Synchronized Resource Production/Job Processing problem (SRPJP) problem typically arises when the resource is a form of renewable energy (e.g., hydrogen, photovoltaic) stored in tanks or batteries. We first cast SRPJP into the Mixed-Integer Linear Programming (MILP) format and handle it through a branch-and-cut process involving specific No_Antichain constraints derived from the structure of the feasible transfer transactions. Subsequently, we explore another approach, which involves eliminating non-binary decision variables and applying a Benders decomposition scheme. Finally, we reformulate the SRPJP problem as a path search problem, which we efficiently handle by designing a tailored adaptation of the A* algorithm.},
  archive      = {J_JCO},
  author       = {Mombelli, Aurélien and Quilliot, Alain},
  doi          = {10.1007/s10878-025-01326-y},
  journal      = {Journal of Combinatorial Optimization},
  month        = {8},
  number       = {1},
  pages        = {1-21},
  shortjournal = {J. Comb. Optim.},
  title        = {Synchronizing production planning and job scheduling: MILP models and exact algorithms},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single machine lot scheduling to minimize maximum weighted completion time. <em>JCO</em>, <em>50</em>(1), 1-36. (<a href='https://doi.org/10.1007/s10878-025-01327-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of artificial intelligence is a significant factor in the surge in demand for micro-products. Consequently, optimizing production scheduling for micro-products has become crucial in improving efficiency, quality, and competitiveness, which is essential for the sustainable development of the industry. In micro-product manufacturing, it is common for manufacturers to receive customized orders with varying quantities and priority levels. This work focuses on situations where orders are processed in lots with unified capacity on a single machine. Each lot has the potential to accommodate multiple orders, and if necessary, any order can be split and processed in consecutive lots. Each order is characterized by its size and weight. The objective of the problem is to minimize the maximum weighted completion time. In order to investigate the differences in the calculation of completion times for split orders, two mixed-integer linear programming models are established, and the optimal characteristics of these problems are subsequently analyzed. Furthermore, in consideration of the inherent unpredictability of order arrival over time in practice, we also explore the potential of online versions of these problems and propose an online algorithm for online problems. Finally, the experimental results assess the efficacy of the proposed optimality rules and the online algorithm and derive several managerial insights.},
  archive      = {J_JCO},
  author       = {Zheng, Feifeng and Li, Na and Liu, Ming and Xu, Yinfeng},
  doi          = {10.1007/s10878-025-01327-x},
  journal      = {Journal of Combinatorial Optimization},
  month        = {8},
  number       = {1},
  pages        = {1-36},
  shortjournal = {J. Comb. Optim.},
  title        = {Single machine lot scheduling to minimize maximum weighted completion time},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the initial transition of graphs of kirkman schedules by the partial team swap. <em>JCO</em>, <em>50</em>(1), 1-19. (<a href='https://doi.org/10.1007/s10878-025-01329-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kirkman schedule is one of the typical single round-robin (abbrev. SRR) tournaments. The partial team swap (abbrev. PTS) is one of the typical procedures of changing from an SRR tournament to another SRR tournament, which is used in local search for solving the traveling tournament problem. An SRR of n teams (of even number) can be represented by a 1-factorization of the complete graph $$K_n$$ . It is known that the 1-factorization of any Kirkman schedule is “perfect” when $$n=p+1$$ for prime numbers p, meaning that any pair of 1-factors in the 1-factorization forms a Hamilton cycle $$C_n$$ in $$K_n$$ , called a 2-edge-colored Hamilton cycle. We are concerned with the cycle structure after applying the PTS to Kirkman schedules, that is, how a 2-edge-colored Hamilton cycle $$C_n$$ is decomposed into two 2-edge-colored cycles of length 2d and $$n-2d$$ , say, $$C_{2d}$$ and $$C_{n-2d}$$ for some number $$d\in [n/2]$$ . We characterize the numbers d such that any cycle $$C_{2d}$$ is not generated by any PTS. Moreover, in case that a cycle $$C_{2d}$$ is generated, we show that the number of $$C_{2d}$$ for any $$d\ne n/4$$ generated by any PTS is at most $$n-2$$ . For the case of $$d=n/4$$ (i.e., $$C_{n/2}$$ ), the number of $$C_{n/2}$$ generated by any PTS is at most $$2(n-2)$$ , and there is some PTS to achieve the upper bound.},
  archive      = {J_JCO},
  author       = {Kashiwagi, Yusuke and Yamamoto, Masaki and Yashima, Takamasa},
  doi          = {10.1007/s10878-025-01329-9},
  journal      = {Journal of Combinatorial Optimization},
  month        = {8},
  number       = {1},
  pages        = {1-19},
  shortjournal = {J. Comb. Optim.},
  title        = {On the initial transition of graphs of kirkman schedules by the partial team swap},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New challenges in combinatorial optimization. <em>JCO</em>, <em>50</em>(1), 1-5. (<a href='https://doi.org/10.1007/s10878-025-01330-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JCO},
  author       = {Chen, Bo and Kulikov, Alexander and Martello, Silvano},
  doi          = {10.1007/s10878-025-01330-2},
  journal      = {Journal of Combinatorial Optimization},
  month        = {8},
  number       = {1},
  pages        = {1-5},
  shortjournal = {J. Comb. Optim.},
  title        = {New challenges in combinatorial optimization},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximate maximin share allocation for indivisible goods under a knapsack constraint. <em>JCO</em>, <em>50</em>(1), 1-16. (<a href='https://doi.org/10.1007/s10878-025-01331-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximin share (MMS) allocation problem under a knapsack constraint is to allocate a set of indivisible goods to a set of n heterogeneous agents, such that the total cost of the allocated goods does not exceed the given budget, and the approximation ratio of the MMS allocation is as large as possible. For any $$\epsilon \in (0, 1)$$ , we prove that $$(\frac{93}{95}+ \epsilon )$$ -approximate MMS allocation does not always exist for two agents, while the MMS allocation problem without a knapsack constraint always has an MMS allocation for two agents. We propose a bag-filling based algorithm that can produce a $$\frac{n}{3n-2}$$ -approximate MMS allocation. When $$n=2$$ and $$n=3$$ , by more careful analysis, we improve the approximation ratios to $$\frac{2}{3}$$ and $$\frac{1}{2}$$ , respectively.},
  archive      = {J_JCO},
  author       = {Deng, Bin and Li, Weidong},
  doi          = {10.1007/s10878-025-01331-1},
  journal      = {Journal of Combinatorial Optimization},
  month        = {8},
  number       = {1},
  pages        = {1-16},
  shortjournal = {J. Comb. Optim.},
  title        = {Approximate maximin share allocation for indivisible goods under a knapsack constraint},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algorithms for 2-balanced connected k-partition problem in graphs. <em>JCO</em>, <em>50</em>(1), 1-19. (<a href='https://doi.org/10.1007/s10878-025-01332-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the result of balanced connected graph edge partition problem for trees, we investigate the 2-balanced connected graph vertex k-partition problem. This paper leverages the charity vertex method and proposes several algorithms for 2-balanced vertex-connected partitioning. Furthermore, we prove that these algorithms are polynomial-time solvable on degree-bounded graphs, thereby refining and extending the results of Caragiannis et al.},
  archive      = {J_JCO},
  author       = {Yu, Junran and Hu, Jing and Gao, Jiaquan and Du, Donglei and Zhang, Xiaoyan},
  doi          = {10.1007/s10878-025-01332-0},
  journal      = {Journal of Combinatorial Optimization},
  month        = {8},
  number       = {1},
  pages        = {1-19},
  shortjournal = {J. Comb. Optim.},
  title        = {Algorithms for 2-balanced connected k-partition problem in graphs},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hardness and algorithms for several new optimization problems on the weighted massively parallel computation model. <em>JCO</em>, <em>50</em>(1), 1-40. (<a href='https://doi.org/10.1007/s10878-025-01297-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The topology-aware Massively Parallel Computation (MPC) model is proposed and studied recently, which enhances the classical MPC model by the awareness of network topology. The work of Hu et. al. on topology-aware MPC model considers only the tree topology. In this paper a more general case is considered, where the underlying network is a weighted complete graph. We then call this model as Weighted Massively Parallel Computation (WMPC) model, and study the problem of minimizing communication cost under it. Three communication cost minimization problems are defined based on different patterns of communication, which are the Data Redistribution Problem, Data Allocation Problem on Continuous data, and Data Allocation Problem on Categorized data. We also define four kinds of objective functions for communication cost, which consider the total cost, bottleneck cost, maximum of send and receive cost, and summation of send and receive cost, respectively. Combining the three problems in different communication patterns with the four kinds of objective cost functions, 12 problems are obtained. The hardness results and algorithms of the 12 problems make up the content of this paper. With rigorous proof, we prove that some of the 12 problems are in P, some FPT, some NP-complete, and some W[1]-complete. Approximate algorithms are proposed for several selected problems.},
  archive      = {J_JCO},
  author       = {Ma, Hengzhao and Li, Jianzhong},
  doi          = {10.1007/s10878-025-01297-0},
  journal      = {Journal of Combinatorial Optimization},
  month        = {8},
  number       = {1},
  pages        = {1-40},
  shortjournal = {J. Comb. Optim.},
  title        = {Hardness and algorithms for several new optimization problems on the weighted massively parallel computation model},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A Branch–Reduction–Bound algorithm for linear fractional multi-product planning problems. <em>JCO</em>, <em>50</em>(1), 1-21. (<a href='https://doi.org/10.1007/s10878-025-01333-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a Branch–Reduction–Bound (BRB) algorithm to solve fractional multiplicative product programming problems, with the aim of finding globally optimal solutions. The method introduces two innovative linear transformation techniques that simplify the solution process by converting the original problem into two equivalent linear relaxation problems. Building on this, a novel branch-and-delete rule is developed to efficiently manage sub-problem selection using a dynamic priority queue approach, and the computational process is further optimized through a region deletion rule. The synergy of these techniques significantly accelerates the algorithm's convergence rate, providing an efficient global optimization strategy. We compare the BRB algorithm with four other algorithms through numerical experiments, and the results confirm its feasibility, effectiveness, and superior computational efficiency, highlighting its advantages in solving complex optimization problems.},
  archive      = {J_JCO},
  author       = {Ding, Xianfeng and Hu, Meiling},
  doi          = {10.1007/s10878-025-01333-z},
  journal      = {Journal of Combinatorial Optimization},
  month        = {8},
  number       = {1},
  pages        = {1-21},
  shortjournal = {J. Comb. Optim.},
  title        = {A Branch–Reduction–Bound algorithm for linear fractional multi-product planning problems},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated operating room and physician scheduling problem solved by a hybrid variable neighborhood search-based algorithm. <em>JCO</em>, <em>50</em>(1), 1-35. (<a href='https://doi.org/10.1007/s10878-025-01335-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses an integrated operating room (OR) and physician scheduling problem driven by the real-world needs in the surgical department. The OR scheduling problem involves determining the number of ORs to be opened each day, the operation date of each surgery, and the schedule of surgeries in each OR. The physician scheduling problem considers two primary work for physicians: surgery service and consultation service, aiming to assign physicians to shifts and determine their responsibilities for either performing surgeries or providing consultation services in the outpatient department. The integration of these two scheduling problems improves coordination between OR availability and physician schedules, which can directly reduce operational costs and enhance resource utilization in the surgical department. The objective of the integrated problem is to minimize the total costs of the hospital and the patients, including the total waiting cost of patients, the total working cost of physicians, the total opening cost of ORs, and the total overtime cost of ORs. To solve the problem, a hybrid approach DP-H-VNS is proposed, which incorporates dynamic programming (DP), heuristics, and a variable neighborhood search (VNS) algorithm. The DP algorithm is used to assign surgeries to specific ORs, while the proposed heuristic rules are presented to determine the number of ORs to open each day and the scheduling of physicians. The presented VNS algorithm can search for high-quality solutions for the proposed problem and serves as a framework to integrate the DP, heuristics, local search, and shaking procedures. Experimental results demonstrate that the proposed DP-H-VNS is superior to the other compared algorithms on the quality of the found solutions and the performance. These results confirm the effectiveness of the proposed approach in optimizing the resource allocation in the surgical department and improving patient care.},
  archive      = {J_JCO},
  author       = {Wang, Yuli and Fan, Wenjuan and Lan, Shaowen and Zhu, Shuwan and Du, Jianmei},
  doi          = {10.1007/s10878-025-01335-x},
  journal      = {Journal of Combinatorial Optimization},
  month        = {8},
  number       = {1},
  pages        = {1-35},
  shortjournal = {J. Comb. Optim.},
  title        = {An integrated operating room and physician scheduling problem solved by a hybrid variable neighborhood search-based algorithm},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mutually dependent, balanced contributions, and the priority value. <em>JCO</em>, <em>50</em>(1), 1-16. (<a href='https://doi.org/10.1007/s10878-025-01340-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Priority value (Béal et al. in Int J Game Theory 51:431–450, 2022) is an allocation rule for TU-games with a priority structure, which distributes the Harsanyi dividend of each coalition among the set of its priority players. In this paper we propose two variants of the differential marginality of mutually dependent players axiom for TU-games with a priority structure, and extend the classical axiom of balanced contributions to TU-games with a priority structure. We provide several new characterizations of the Priority value which invoke these modified axioms and the standard axioms: efficiency, the null player property, the priority player out and the null player out.},
  archive      = {J_JCO},
  author       = {He, Songtao and Shan, Erfang and Sun, Yuxin},
  doi          = {10.1007/s10878-025-01340-0},
  journal      = {Journal of Combinatorial Optimization},
  month        = {8},
  number       = {1},
  pages        = {1-16},
  shortjournal = {J. Comb. Optim.},
  title        = {Mutually dependent, balanced contributions, and the priority value},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid quantum-enhanced reinforcement learning for energy-efficient resource allocation in fog-edge computing. <em>JCO</em>, <em>50</em>(1), 1-36. (<a href='https://doi.org/10.1007/s10878-025-01336-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of Internet of Things (IoT) devices has intensified the need for intelligent, adaptive, and energy-efficient resource management across mobile edge–fog–cloud infrastructures. Conventional optimization approaches often fail to manage the dynamic interplay among fluctuating workloads, energy constraints, and real-time scheduling. To address this, a Hybrid Quantum-Enhanced Reinforcement Learning (HQERL) framework is introduced, unifying quantum-inspired heuristics, swarm intelligence, and reinforcement learning into a co-adaptive sched uling system. HQERL employs a feedback-driven architecture to synchronize exploration, optimization, and policy refinement for enhanced task scheduling and resource control. The Maximum Likelihood Swarm Whale Optimization (MLSWO) module encodes dynamic task and system states using swarm intelligence guided by statistical likelihood, generating information-rich inputs for the learning controller. To prevent premature convergence and expand the scheduling search space, the Quantum Brainstorm Optimization (QBO) component incorporates probabilistic memory and collective learning to diversify scheduling solutions. These enhanced representations and exploratory strategies feed into the Proximal Policy Optimization (PPO) controller, which dynamically adapts resource allocation policies in real time based on system feedback, ensuring resilience to workload shifts. Furthermore, Dynamic Voltage Scaling (DVS) is integrated to improve energy efficiency by adjusting processor voltages and frequencies according to workload demands. This seamless coordination enables HQERL to balance task latency, resource use, and power consumption. Evaluation on the LSApp dataset reveals HQERL yields a 15% energy efficiency gain, 12% makespan reduction, and a 23.3% boost in peak system utility, validating its effectiveness for sustainable IoT resource management.},
  archive      = {J_JCO},
  author       = {Sureka Nithila Princy, S. and kumar, Paulraj Ranjith},
  doi          = {10.1007/s10878-025-01336-w},
  journal      = {Journal of Combinatorial Optimization},
  month        = {8},
  number       = {1},
  pages        = {1-36},
  shortjournal = {J. Comb. Optim.},
  title        = {Hybrid quantum-enhanced reinforcement learning for energy-efficient resource allocation in fog-edge computing},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bivalent quadratic optimization with sum-of-square of quadratic penalties. <em>JCO</em>, <em>50</em>(1), 1-17. (<a href='https://doi.org/10.1007/s10878-025-01339-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of maximizing the sum-of-square of quadratic functions with bivalent variables, denoted by (P), arises from bivalent quadratic optimization with K quadratic disjunctive penalties. Though NP-hard in general, (P) is polynomially solvable when the input matrices can concatenate to a fixed-rank matrix. We present a nonconvex quadratic semidefinite programming (SDP) relaxation, which provides a 0.4-approximate solution for (P). We show that the quadratic SDP relaxation can be approximately and globally solved to a precision $$\epsilon $$ via solving at most $$O((Kn^3/\epsilon )^{K/2})$$ linear SDP subproblems.},
  archive      = {J_JCO},
  author       = {Zhang, Tongli and Xia, Yong},
  doi          = {10.1007/s10878-025-01339-7},
  journal      = {Journal of Combinatorial Optimization},
  month        = {8},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Comb. Optim.},
  title        = {Bivalent quadratic optimization with sum-of-square of quadratic penalties},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Impact of payment schemes on performance in a medical cost-sharing system: Bundled payment vs. total prepayment. <em>JCO</em>, <em>49</em>(5), 1-27. (<a href='https://doi.org/10.1007/s10878-025-01301-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, many countries are on the process of reforming their health care payment systems from post-payment to pre-payment. To explore the impact of pre-payment schemes on health system performance we investigate the two payment schemes, bundled payment (BP) and total prepayment (TP), on performance in a medical cost-sharing system. Under the BP scheme, the government compensates hospitals with a lump sum for the entire course of each patient’s care. Under the TP scheme, the government provides the total amount of integrated compensation within a period. A three Stackelberg game with an embedded queueing model is used to explore the interactions among participants: government, hospital, and patients. The government determines the compensation received by hospitals and the copayment paid by patients to maximize social welfare. Next, the hospital determines its service rate for each medical episode to maximize profit. Last, patients make decisions on whether to appeal to the hospital for medical services. We derive the optimal strategy for the participants under the BP and TP schemes, and compare the system performance through numerical analysis. Results show that BP is better than TP in reducing patient expected waiting time, while it outperforms TP in terms of system accessibility and service quality. Our study is the first to consider the total prepayment scheme in the healthcare system decision analysis and the findings offer important insights for policymakers regarding implementing medical insurance reform in practice.},
  archive      = {J_JCO},
  author       = {Yu, Miao and Zhou, Wang and Zhao, Yu},
  doi          = {10.1007/s10878-025-01301-7},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-27},
  shortjournal = {J. Comb. Optim.},
  title        = {Impact of payment schemes on performance in a medical cost-sharing system: Bundled payment vs. total prepayment},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The independent quadratic assignment problem: Complexity and polynomially solvable special cases. <em>JCO</em>, <em>49</em>(5), 1-11. (<a href='https://doi.org/10.1007/s10878-025-01302-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the independent quadratic assignment problem which is a variation of the well-known Koopmans–Beckman quadratic assignment problem. The problem is strongly NP-hard and is also hard to approximate. Some polynomially solvable special cases are identified along with a complete characterization of linearizable instances of the problem, the validity of which is shown to be verifiable in linear time. This improves the existing quadratic bound for this problem. Additional complexity results are also presented.},
  archive      = {J_JCO},
  author       = {Ćustić, Ante and Yang, Wei and Wang, Yang and Punnen, Abraham P.},
  doi          = {10.1007/s10878-025-01302-6},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-11},
  shortjournal = {J. Comb. Optim.},
  title        = {The independent quadratic assignment problem: Complexity and polynomially solvable special cases},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximating combinatorial contracts with a cardinality constraint. <em>JCO</em>, <em>49</em>(5), 1-16. (<a href='https://doi.org/10.1007/s10878-025-01307-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore the problem of combinatorial contract design, a subject introduced and studied by Dütting et al. (2023). Previous research has focused on the challenge of selecting an unconstrained subset of agents, particularly when the principal’s utility function exhibits XOS or submodular characteristics related to the subset of agents that exert effort. Our study extends this existing line of research by examining scenarios in which the principal aims to select a subset of agents with a specific k-cardinality constraint. In these scenarios, the actions that each agent can take are binary values: effort or no effort. We focus on linear contracts, where the expected reward function is XOS or submodular. Our contribution is an approximation of 0.0197 for the problem of designing multi-agent hidden-action principal-agent contracts with the k-cardinality constraint. This result stands in contrast to the unconstrained setting, where Dütting et al. (2023) achieved an approximation of nearly 0.0039.},
  archive      = {J_JCO},
  author       = {Gong, Qinqin and Gai, Ling and Jiang, Yanjun and Lv, Yang and Yang, Ruiqi},
  doi          = {10.1007/s10878-025-01307-1},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-16},
  shortjournal = {J. Comb. Optim.},
  title        = {Approximating combinatorial contracts with a cardinality constraint},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mechanism design with predictions for facility location games with candidate locations. <em>JCO</em>, <em>49</em>(5), 1-27. (<a href='https://doi.org/10.1007/s10878-025-01310-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study mechanism design with predictions in the single (obnoxious) facility location games with candidate locations on the real line, which complements the existing literature on mechanism design with predictions. We first consider the single facility location games with candidate locations, where each agent prefers the facility (e.g., a school) to be located as close to her as possible. We study two social objectives: minimizing the maximum cost and the social cost, and provide deterministic, anonymous, and group strategy-proof mechanisms with predictions that achieve the best possible trade-offs between consistency and robustness, respectively. Additionally, we represent the approximation ratio as a function of the prediction error, indicating that mechanisms can achieve better performance even when predictions are not fully accurate. We also consider the single obnoxious facility location games with candidate locations, where each agent prefers the facility (e.g., a garbage transfer station) to be located as far away from her as possible. For the objective of maximizing the minimum utility, we prove that any strategy-proof mechanism with predictions is unbounded robust. For the objective of maximizing the social utility, we provide a deterministic, anonymous, and group strategy-proof mechanism with prediction that achieves the best possible trade-off between consistency and robustness.},
  archive      = {J_JCO},
  author       = {Fang, Jiazhu and Fang, Qizhi and Liu, Wenjing and Nong, Qingqin and Voudouris, Alexandros A.},
  doi          = {10.1007/s10878-025-01310-6},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-27},
  shortjournal = {J. Comb. Optim.},
  title        = {Mechanism design with predictions for facility location games with candidate locations},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On combinatorial network flows algorithms and circuit augmentation for pseudoflows. <em>JCO</em>, <em>49</em>(5), 1-32. (<a href='https://doi.org/10.1007/s10878-025-01313-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are numerous combinatorial algorithms for classical min-cost flow problems and their simpler variants like max flow or shortest path problems. It is well-known that many of these algorithms are related to the Simplex method and the more general circuit augmentation schemes: prime examples are the network Simplex method, a refinement of the primal Simplex method, and min-mean cycle canceling, which corresponds to a steepest-descent circuit augmentation scheme. We are interested in a deeper understanding of the relationship between circuit augmentation and combinatorial network flows algorithms. To this end, we generalize from primal flows to so-called pseudoflows, which adhere to arc capacities but allow for a violation of flow balance. We introduce ‘pseudoflow polyhedra,’ wherein slack variables are used to quantify this violation, and characterize their circuits. This enables the study of combinatorial network flows algorithms in view of the walks they trace in these polyhedra, and the pivot rules for the steps. In doing so, we provide an ‘umbrella,’ a general framework, that captures several algorithms. We show that the Successive Shortest Path Algorithm for min-cost flow problems, the Shortest Augmenting Path Algorithm for max flow problems, and the Preflow-Push algorithm for max flow problems lead to (non-edge) circuit walks in these polyhedra. The former two are replicated by circuit augmentation schemes for simple pivot rules. Further, we show that the Hungarian Method leads to an edge walk and is replicated, equivalently, as a circuit augmentation scheme or a primal Simplex run for a simple pivot rule.},
  archive      = {J_JCO},
  author       = {Borgwardt, Steffen and Morrison, Angela},
  doi          = {10.1007/s10878-025-01313-3},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-32},
  shortjournal = {J. Comb. Optim.},
  title        = {On combinatorial network flows algorithms and circuit augmentation for pseudoflows},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximation algorithms for the W-prize-collecting scheduling problem on a single machine with submodular rejection penalties. <em>JCO</em>, <em>49</em>(5), 1-13. (<a href='https://doi.org/10.1007/s10878-025-01314-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the W-prize-collecting scheduling problem on a single machine with submodular rejection penalties. In this problem, we are given one machine, n jobs and a value W. Every job has a processing time and a profit. Each job is either accepted and processed on the machine, or rejected and a rejection penalty is paid. The objective is to minimize the sum of the makespan of the accepted jobs and the rejection penalties of the rejected jobs which is determined by a submodular function, provided that the total profit of the accepted jobs is at least W. Under the assumption that the submodular penalty function is polymatriod, we design a 2-approximation algorithm based on the primal-dual framework.},
  archive      = {J_JCO},
  author       = {Guo, Tianjiao and Liu, Wen and Zhang, Gengsheng and Hou, Bo},
  doi          = {10.1007/s10878-025-01314-2},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-13},
  shortjournal = {J. Comb. Optim.},
  title        = {Approximation algorithms for the W-prize-collecting scheduling problem on a single machine with submodular rejection penalties},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Further combinatorial analysis of substar reliability in star networks. <em>JCO</em>, <em>49</em>(5), 1-28. (<a href='https://doi.org/10.1007/s10878-025-01315-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Substar reliability defined as the probability that a fault-free substar of a certain scale is still available in the star network $$S_n$$ when the occurrence of faults. The substar reliability is one of the most practical reliability measures because a user in the current star multiprocessors is given a certain substar for the execution of his/her program. Wu and Latifi(Inf. Sci. 178 (2008)) derived upper-bound on the substar reliability of $$S_n$$ by analysing the intersection of no more than three substars. Later, Li et al.(IEEE. Trans. Rel. 65 (2016)) derived lower-bound on the substar reliability of $$S_n$$ by considering the intersection of no more than four substars. In the paper, we further derive the upper- and lower bounds on the substar reliability of $$S_n$$ by taking into account the intersection of no more than five or four substars, respectively. At a result, we obtain more accurate value of the upper-bound on substar reliability of $$S_n$$ . The experimental study indicates that both the upper- and lower bounds are very close to approximate results especially for the low value of the node reliability.},
  archive      = {J_JCO},
  author       = {Li, Hao and Sabir, Eminjan},
  doi          = {10.1007/s10878-025-01315-1},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-28},
  shortjournal = {J. Comb. Optim.},
  title        = {Further combinatorial analysis of substar reliability in star networks},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximation algorithms for the partition set cover problem with penalties. <em>JCO</em>, <em>49</em>(5), 1-15. (<a href='https://doi.org/10.1007/s10878-025-01317-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the partition set cover problem with penalties. In this problem, we have a universe U, a partition $$\mathscr {P}=\{P_{1},\ldots ,P_{r}\}$$ of U, and a collection $$\mathscr {S}=\{S_{1},\ldots ,S_{m}\}$$ of nonempty subsets of U satisfying $$\bigcup _{S_i\in \mathscr {S}} S_i=U$$ . In addition, each $$P_t$$ $$(t\in [r])$$ is associated with a covering requirement $$k_t$$ as well as a penalty $$\pi _t$$ , and each $$S_i$$ $$(i\in [m])$$ is associated with a cost. A class $$P_t$$ attains its covering requirement by a subcollection $$\mathscr {A}$$ of $$\mathscr {S}$$ if at least $$k_t$$ elements in $$P_t$$ are contained in $$\bigcup _{S_i\in \mathscr {A}} S_i$$ . Each $$P_t$$ is either attaining its covering requirement or paid with its penalty. The objective is to find a subcollection $$\mathscr {A}$$ of $$\mathscr {S}$$ such that the sum of the cost of $$\mathscr {A}$$ and the penalties of classes not attaining covering requirements by $$\mathscr {A}$$ is minimized. We present two approximation algorithms for this problem. The first is based on the LP-rounding technique with approximation ratio $$K+O(\beta +\ln r)$$ , where $$K=\max _{t\in [r]}k_t$$ , and $$\beta $$ denotes the approximation guarantee for a related set cover instance obtained by rounding the standard LP. The second is based on the primal-dual method with approximation ratio lf, where $$f=\max _{e\in U}|\{S_i\in \mathscr {S}\mid e\in S_i\}|$$ and $$l=\max _{t\in [r]}|P_t|$$ .},
  archive      = {J_JCO},
  author       = {Wang, Qi and Hou, Bo and Zhang, Gengsheng and Zhou, Yisheng and Liu, Wen},
  doi          = {10.1007/s10878-025-01317-z},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-15},
  shortjournal = {J. Comb. Optim.},
  title        = {Approximation algorithms for the partition set cover problem with penalties},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pseudo-shapley value for weak games of threats. <em>JCO</em>, <em>49</em>(5), 1-9. (<a href='https://doi.org/10.1007/s10878-025-01319-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a real number $$\omega $$ , a weak game of threats (N, v) consists of a set N of n players and a function $$v:2^N\rightarrow \mathbb {R}$$ such that $$\omega v(\emptyset )+(1-\omega )v(N)=0$$ , where $$v(\emptyset )\ne 0$$ possibly. It is shown that there exists a unique value with respect to $$\omega $$ for weak games of threats that satisfies efficiency, linearity, symmetry and the null player property.},
  archive      = {J_JCO},
  author       = {Li, Daniel Li and Shan, Erfang},
  doi          = {10.1007/s10878-025-01319-x},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-9},
  shortjournal = {J. Comb. Optim.},
  title        = {Pseudo-shapley value for weak games of threats},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust static and dynamic maximum flows. <em>JCO</em>, <em>49</em>(5), 1-42. (<a href='https://doi.org/10.1007/s10878-025-01298-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the robust maximum flow problem and the robust maximum flow over time problem where a given number of arcs $$\Gamma $$ may fail or may be delayed. Two prominent models have been introduced for these problems: either one assigns flow to arcs fulfilling weak flow conservation in any scenario, or one assigns flow to paths where an arc failure or delay affects a whole path. We provide a unifying framework by presenting novel general models, in which we assign flow to subpaths. These models contain the known models as special cases and unify their advantages in order to obtain less conservative robust solutions. We give a thorough analysis with respect to complexity of the general models. In particular, we show that the general models are essentially NP-hard, whereas, e.g., in the static case with $$\Gamma =1$$ an optimal solution can be computed in polynomial time. Further, we answer the open question about the complexity of the dynamic path model for $$\Gamma =1$$ . We also compare the solution quality of the different models. In detail, we show that the general models have better robust optimal values than the known models and we prove bounds on these gaps.},
  archive      = {J_JCO},
  author       = {Biefel, Christian and Kuchlbauer, Martina and Liers, Frauke and Waldmüller, Lisa},
  doi          = {10.1007/s10878-025-01298-z},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-42},
  shortjournal = {J. Comb. Optim.},
  title        = {Robust static and dynamic maximum flows},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smart health system with deep kronecker network-based key generation for privacy-aware aggregate authentication and access control in IoT. <em>JCO</em>, <em>49</em>(5), 1-26. (<a href='https://doi.org/10.1007/s10878-025-01303-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) application is an application and service that incorporates both the physical and information world. Similarly, it is difficult for existing health systems to provide privacy-aware aggregate authentication and fine-grained access control. To bridge the concern, a smart health system (SHS) with Deep Kronecker Network_key generation (DKN_keyGen) for privacy-aware aggregate authentication and access control in IoT is implemented. Here, entities employed for this model such as data owner (DO), registration center (RC), data user (DU) and cloud service provider (CSP). The method follows four steps, such as system initialization, user registration, Health data outsourcing and Health data access. Initially, the RC needs to initialize the security parameters, random parameters and public keys. After that, DO and DU must be registered in RC. Moreover, the smart health care data of DO generates the secret parameter and also obtains the secret parameter from the RC. The cloud storage stores and manages health care data in the health data outsourcing step. Finally, for health data access, the user gives appropriate parameters and access to the data which is implemented in the data access phase. The model is established considering different security functionalities including Encryption, ECC, XoR and hashing function. Here, the key is generated using DKN. The proposed model obtained a minimum computation time of 6.857 s, memory usage of 30 MB, and communication cost of 20.},
  archive      = {J_JCO},
  author       = {Sathya, M. and Mareeswari, V. and Jeyaselvi, M. and Solairaj, A.},
  doi          = {10.1007/s10878-025-01303-5},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-26},
  shortjournal = {J. Comb. Optim.},
  title        = {Smart health system with deep kronecker network-based key generation for privacy-aware aggregate authentication and access control in IoT},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ZeSAI: AI vigilant malware detection in email security with zero shot-based hybrid network and threat intelligence integration. <em>JCO</em>, <em>49</em>(5), 1-45. (<a href='https://doi.org/10.1007/s10878-025-01306-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this ever-evolving world of threats, e-mail security is becoming one of the biggest concerns because attackers are constantly searching for new techniques to bypass the existing security measures. Emails containing phishing, malware and other security threats have become far more common place, which is why there is a need to implement new and more efficient adaptive threat detection frameworks. Typically, email security products are outdated within these emerging threats hence the need to evolve into something more effective and smarter in the detection systems. In this regard, Zero Short learning based Artificial Intelligence (ZeSAI)-model is proposed as a new approach to improve threat identification in the context of email security. Initially, to ensure generalization and robust performance, the model uses three broad sets of input data: augmented data based on Context-Preserving Synthetic Email Generation (CPSEG) method and adversarial data, both generated from six datasets and Threat Intelligence feeds offering real-time updates. The proposed ZeSAI model enhances email threat detection through a structured workflow: eXtreme Language Network (XLNet) first generates bidirectional contextual embeddings from email content, capturing nuanced semantic relationships. The Recurrent GRU Network (RGN) then analyses temporal patterns in the email data, identifying complex relationships and variations over time. These RGN-extracted features are integrated with XLNet-generated semantic embeddings in the Cross-Modal Fusion Layer. Finally, Zero-Shot Learning (ZSL) utilizes these combined semantic descriptions and contextual insights to identify new threats based on their similarities to known threats, enabling robust and adaptive threat detection. The proposed approach yields good accuracy and other performance measures; precision, recall, and F1-score; under fivefold and tenfold cross-validation. An ablation study is also carried out to pinpoint the contribution of each module. Specifically, ZeSAI has accuracy of 98.51% in Business Email Compromise (BEC) threat detection, 96.8% in spam detection, 99.18% in phishing detection, 97.2% in malware attachment detection and 98.58% in detecting insider threats.},
  archive      = {J_JCO},
  author       = {Ramalingam, Venkadeshan and Gopal, R. and Rahman, Syed Ziaur and Senthil, R.},
  doi          = {10.1007/s10878-025-01306-2},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-45},
  shortjournal = {J. Comb. Optim.},
  title        = {ZeSAI: AI vigilant malware detection in email security with zero shot-based hybrid network and threat intelligence integration},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On some path-critical ramsey numbers. <em>JCO</em>, <em>49</em>(5), 1-9. (<a href='https://doi.org/10.1007/s10878-025-01312-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For graphs G and H, the Ramsey number R(G, H) is the smallest r such that any red-blue edge coloring of $$K_r$$ contains a red G or a blue H. The path-critical Ramsey number $$R_{\pi }(G,H)$$ is the largest n such that any red-blue edge coloring of $$K_r \setminus P_{n}$$ contains a red G or a blue H, where $$r=R(G,H)$$ and $$P_{n}$$ is a path of order n. In this note, we show a general upper bound for $$R_{\pi }(G,H)$$ , and determine the exact values for some cases of $$R_{\pi }(G,H)$$ .},
  archive      = {J_JCO},
  author       = {Wang, Ye and Song, Yanyan},
  doi          = {10.1007/s10878-025-01312-4},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-9},
  shortjournal = {J. Comb. Optim.},
  title        = {On some path-critical ramsey numbers},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The influence of carbon sink trading on carbon emission reduction in agricultural supply chains. <em>JCO</em>, <em>49</em>(5), 1-30. (<a href='https://doi.org/10.1007/s10878-025-01316-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As global climate change intensifies, the agricultural sector, responsible for over 30% of global greenhouse gas emissions, faces an urgent imperative to mitigate emissions and align with international climate commitments. Carbon sink trading, a market-based mechanism that incentivizes emission reductions through sequestration credits, has emerged as an important tool for accelerating carbon peaking and neutrality goals. This study investigates the influence of carbon sink trading on the strategic interactions between farmers and retailers in agricultural supply chains. Employing differential game theory, we construct three cooperative models: decentralized, Stackelberg leader-follower, and centralized, and derive equilibrium strategies for each using the Hamilton-Jacobi-Bellman framework. Through numerical simulations, we evaluate the influence of carbon sink trading on the emission reduction efforts of farmers and retailers, the extent of emission reductions in the supply chain, and the overall profits. Comparative analysis against baseline scenarios without carbon trading reveals that the integration of carbon sink markets enhances profit margins across all models and improves the level of emission reduction in the agricultural supply chain. In addition, our results show that the centralized model outperforms other configurations, followed by the Stackelberg model, with the decentralized model exhibiting the least effectiveness. These findings provide actionable insights for policymakers and supply chain managers to design carbon trading frameworks that harmonize economic incentives with ecological sustainability.},
  archive      = {J_JCO},
  author       = {Meng, Tingting and Cheng, Yukun and Pu, Xujin and Li, Rui},
  doi          = {10.1007/s10878-025-01316-0},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-30},
  shortjournal = {J. Comb. Optim.},
  title        = {The influence of carbon sink trading on carbon emission reduction in agricultural supply chains},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An exponential cone integer programming and piece-wise linear approximation approach for 0-1 fractional programming. <em>JCO</em>, <em>49</em>(5), 1-16. (<a href='https://doi.org/10.1007/s10878-025-01318-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a class of binary fractional programs commonly encountered in important application domains such as assortment optimization and facility location. These problems are known to be NP-hard to approximate within any constant factor, and existing solution approaches typically rely on mixed-integer linear programming or second-order cone programming reformulations. These methods often utilize linearization techniques (e.g., big-M or McCormick inequalities), which can result in weak continuous relaxations. In this work, we propose a novel approach based on an exponential cone reformulation combined with piecewise linear approximation. This allows the problem to be solved efficiently using standard cutting-plane or branch-and-cut procedures. We further provide a theoretical analysis of the approximation quality yielded by our reformulation and discuss strategies for optimizing the problem size of the exponential cone formulation. Experiments on instances of various sizes demonstrate that our approach delivers competitive performance on small and medium instances while offering superior performance on large instances compared to state-of-the-art baselines.},
  archive      = {J_JCO},
  author       = {Pham, Hoang Giang and Ta, Thuy Anh and Mai, Tien},
  doi          = {10.1007/s10878-025-01318-y},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-16},
  shortjournal = {J. Comb. Optim.},
  title        = {An exponential cone integer programming and piece-wise linear approximation approach for 0-1 fractional programming},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Refining waste and elevating customer service: Assessing the efficacy of reverse logistics strategies for product returns management. <em>JCO</em>, <em>49</em>(5), 1-31. (<a href='https://doi.org/10.1007/s10878-025-01320-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance the utilization rate of remanufactured products and further facilitate their widespread circulation, it is crucial to identify the responsible party for processing and refurbishing these items. This paper explores the potential contributions of various entities within a supply chain, including new product manufacturers, retailers, and third-party entities, in providing services for recycling and refurbishing remanufactured products. That is to say. It explores the question of which side of the production process of refurbished products can be done in a more economically and environmentally efficient way. The aim is to promote the rational use of resources and address the necessity to enhance the resilience of green supply chains. In this supply chain, remanufactured and new products are introduced to the market simultaneously. This research has developed three competitive cooperation models based on different recycling and refurbishment subjects for refurbished products by considering the return policy, the cost of new and remanufactured products, and the interaction between product prices. These include a model of competition between a separate manufacturer of new products and a separate manufacturer of refurbished products (Model A), a basic model in which a manufacturer of new products also carries on the business of refurbished products (Model B), and a model of competition and cooperation between a manufacturer of new products and a retailer that carries on the business of refurbished products (Model C). Based on a game theory framework, this study analyses in-depth the preference differences among members for different supply relationships of refurbished products in three supply chain models. In this model, owing to diverse return policies, refurbishment costs, and other factors, different members will undertake refurbishing products to maximize the interests of all parties involved. The findings of this paper indicate that the supplier favors Model B when the return policy (r) is small. However, for larger r values, the supplier will opt for either Model A or Model C. Additionally, this paper finds that retailers are more likely to choose Model C when the return policy reaches a specific value. Theoretically, this study extends the existing literature on the value of return policy and fills the gap in research on the impact of return policy on expanding green supply chains. Through developing a new game model, the impact mechanism of return policy in the competition between remanufactured and new products is analyzed in depth, providing academics with a fresh perspective on how to reshape supply chain structures to increase members' profitability. The study provides market management professionals and business managers with valuable insights for strategic decision-making, especially determining which party is responsible for recycling and refurbishing remanufactured products. In addition, the findings provide an important reference for government intervention to effectively expand the market for remanufactured products by adjusting the gap between product return policies, thereby optimizing resource utilization, promoting environmental protection, and enhancing the resilience and sustainability of green supply chains.},
  archive      = {J_JCO},
  author       = {Li, Xiaoyao and Jiang, Bing and Meng, Xueying and Bai, Yang},
  doi          = {10.1007/s10878-025-01320-4},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-31},
  shortjournal = {J. Comb. Optim.},
  title        = {Refining waste and elevating customer service: Assessing the efficacy of reverse logistics strategies for product returns management},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency allocation problem over an algebraic structure. <em>JCO</em>, <em>49</em>(5), 1-20. (<a href='https://doi.org/10.1007/s10878-025-01321-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In wireless telecommunication networks, where a multitude of communication links exist but only a restricted number of frequencies are available, the challenge of strategically assigning these frequencies to transmitters to minimize interference is known as the frequency allocation problem. This problem is commonly represented and approached through the lens of graph L(2, 1)-coloring, a recognized methodology for resolving such allocation challenges. In this paper, we consider frequency allocation as a graph L(2, 1)-coloring problem over an algebraic structure, a ring R with unity 1 not equal to zero. In L(2, 1)-coloring model of a network adjacent transceivers situated in very close proximity are assigned frequencies with a minimum difference of two. Meanwhile, transceivers in close vicinity are assigned frequencies that differ by at least one. This coloring scheme ensures effective frequency allocation while managing interference in wireless communication networks.},
  archive      = {J_JCO},
  author       = {Ali, Annayat and Raja, Rameez},
  doi          = {10.1007/s10878-025-01321-3},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-20},
  shortjournal = {J. Comb. Optim.},
  title        = {Frequency allocation problem over an algebraic structure},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximating the maximum weight cycle/path partition in graphs with weights one and two. <em>JCO</em>, <em>49</em>(5), 1-26. (<a href='https://doi.org/10.1007/s10878-025-01322-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the maximum weight k-cycle (k-path) partition problem (MaxWkCP/MaxWkPP for short). The input consists of an undirected complete graph $$G=(V,E)$$ with $$|V|=kn$$ , where k, n are positive integers, and a non-negative weight function on E, the objective is to determine n vertex disjoint k-cycles (k-paths), which are cycles (paths) containing exactly k vertices, covering all the vertices such that the total edge weight of these cycles (paths) is as large as possible. We propose improved approximation algorithms for the MaxWkCP/MaxWkPP in graphs with weights one and two. For the MaxWkCP in graphs with weights one and two, we obtain an approximation algorithm having an approximation ratio of $$\frac{37}{48}$$ for $$k=6$$ , which improves upon the best available $$\frac{91}{120}$$ -approximation algorithm by Zhao and Xiao 2024a. When $$k=4$$ , we show that the same algorithm is a $$\frac{7}{8}$$ -approximation algorithm and give a tight example. This ratio ties with the state-of-the-art result, also given by Zhao and Xiao 2024a. However, we demonstrate that our algorithm can be applied to the minimization variant of MaxWkCP in graphs with weights one and two and achieve a tight approximation ratio of $$\frac{5}{4}$$ . For the MaxW5PP in graphs with weights one and two, we devise a novel $$\frac{19}{24}$$ -approximation algorithm by combining two separate algorithms, each of which handles one of the two complementary scenarios of the optimal solution well. This ratio is better than the previous best ratio of $$\frac{3}{4}$$ due to Li and Yu 2023.},
  archive      = {J_JCO},
  author       = {Guo, Xinmeng and Yu, Wei and Liu, Zhaohui},
  doi          = {10.1007/s10878-025-01322-2},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-26},
  shortjournal = {J. Comb. Optim.},
  title        = {Approximating the maximum weight cycle/path partition in graphs with weights one and two},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrated airline aircraft routing and crew pairing by alternating lagrangian decomposition. <em>JCO</em>, <em>49</em>(5), 1-15. (<a href='https://doi.org/10.1007/s10878-025-01324-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the aircraft routing and crew pairing problems, a sequential approach is usually used to solve they. When solving the crew pairing problem, the impact of aircraft routing problem is often neglected so that these two problems are independent. This approach reduces the complexity of the solution process, but it may obtain a suboptimal solution. In this paper, we consider an integrated aircraft routing and crew pairing problem. We propose an integrated model that integrates the aircraft routing and crew pairing problems. We propose a solution algorithm based on a heuristic alternating Lagrangian decomposition to address coupling constraint of the integrated model. The solution algorithm iterates between the first Lagrangian subproblem about aircraft routing and the second Lagrangian subproblem about crew pairing. These two Lagrangian subproblems are solved by a branch-and-price algorithm. In the branch-and-price algorithm, we present a heuristic branching strategy. The computational experiments are conducted on several real-world data sets.},
  archive      = {J_JCO},
  author       = {Li, Cong and Gao, Suixiang and Yang, Wenguo and Jiang, Zhipeng},
  doi          = {10.1007/s10878-025-01324-0},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-15},
  shortjournal = {J. Comb. Optim.},
  title        = {Integrated airline aircraft routing and crew pairing by alternating lagrangian decomposition},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved approximation algorithms for multiprocessor indivisible coflow scheduling. <em>JCO</em>, <em>49</em>(5), 1-17. (<a href='https://doi.org/10.1007/s10878-025-01325-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coflow scheduling is a challenging optimization problem that underlies many data transmission and parallel computing applications. In this paper, we study the indivisible coflow scheduling problem on parallel identical machines with the objective to minimize the makespan, i.e., the completion time of the last flow. In our problem setting, the number of the input/output ports in each machine is a fixed constant, each port has a unit capacity, and all the flows inside a coflow should be scheduled on the same machine. We present a $$(2 + \epsilon )$$ -approximation algorithm for the problem, for any $$\epsilon > 0$$ , in which the number of machines can be either a fixed constant or part of the input.},
  archive      = {J_JCO},
  author       = {Gong, Mingyang and Chen, Guangting and Lin, Guohui and Su, Bing},
  doi          = {10.1007/s10878-025-01325-z},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-17},
  shortjournal = {J. Comb. Optim.},
  title        = {Improved approximation algorithms for multiprocessor indivisible coflow scheduling},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The multiple steiner TSP with cyclic order on terminals: Valid inequalities and polyhedra. <em>JCO</em>, <em>49</em>(5), 1-51. (<a href='https://doi.org/10.1007/s10878-025-01288-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with a variant of the Traveling Salesman Problem (TSP), called the Multiple Steiner TSP with Order Constraints (MSTSPOC). Consider an undirected graph with nonnegative weights on the edges, and a set of salesmen such that with each salesman is associated a set of ordered terminals. The MSTSPOC consists in finding a minimum-weight subgraph containing for each salesman a tour going in order through its terminals. We study the polytope associated with the Integer Linear Programming (ILP) formulation proposed in Borne et al. (2013). We characterize when the basic inequalities define facets. We also describe new valid inequalities along with necessary conditions and sufficient conditions for these inequalities to be facet-defining. Further families of valid inequalities, coming from closely related problems, are also discussed. The theoretical results presented in this paper are computationally tested in a companion paper (Taktak 2024).},
  archive      = {J_JCO},
  author       = {Mahjoub, A. Ridha and Taktak, Raouia and Uchoa, Eduardo},
  doi          = {10.1007/s10878-025-01288-1},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-51},
  shortjournal = {J. Comb. Optim.},
  title        = {The multiple steiner TSP with cyclic order on terminals: Valid inequalities and polyhedra},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finding a b-matching that embeds the maximum number of edge pairs in a given set. <em>JCO</em>, <em>49</em>(5), 1-15. (<a href='https://doi.org/10.1007/s10878-025-01305-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a set of edge pairs in a complete bipartite graph, the objective of the maximum edge-pair embedding bipartite b-matching problem (MEEBbM) is to find a bipartite b-matching that includes the maximum number of these edge pairs. The original problem, known as the maximum edge-pair embedding bipartite matching, was demonstrated to be NP-hard and inapproximable by Nguyen et al. in 2021. Building on this, and being inspired by the optimization of reconfigurable networks, we extend the problem in this paper to consider b-matchings, with a focus on scenarios where the number of edge pairs per node is bounded. Let $$ k $$ represent the maximum number of edge pairs that can be incident on a single node. We prove that when $$k > b$$ , the problem is NP-hard. For the case when $$b = 2$$ , we provide an exact algorithm for $$k = 1,2$$ . Additionally, for any values of k and b, we provide a $$\Theta (k)$$ -approximation algorithm for this problem.},
  archive      = {J_JCO},
  author       = {Buahong, Siraphob and Suppakitpaisarn, Vorapong and Sripratak, Piyashat},
  doi          = {10.1007/s10878-025-01305-3},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-15},
  shortjournal = {J. Comb. Optim.},
  title        = {Finding a b-matching that embeds the maximum number of edge pairs in a given set},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximation algorithms for the total dominating set problem. <em>JCO</em>, <em>49</em>(5), 1-15. (<a href='https://doi.org/10.1007/s10878-025-01311-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a network graph $$G=(V,E)$$ , a subset $$T\subseteq V$$ is said to be a total dominating set (TDS) if every $$v\in V$$ is adjacent to at least one node in T. In this paper, we first present a distributed algorithm for the minimum TDS problem via the LP relaxation techniques. For a positive integer k and maximum degree $$\Delta $$ , the proposed algorithm outputs a fractional total dominating set of expected size $$O(k\Delta ^\frac{2}{k})|TDS_{OPT}|$$ , where $$TDS_{OPT}$$ is an optimal TDS. The distributed algorithm runs in $$O(k^2)$$ communication rounds, and the algorithm uses messages of size $$O(\log \Delta )$$ . Then we give a rounding algorithm. The fractional solution is rounded to obtain an integer total dominating set for the original problem.},
  archive      = {J_JCO},
  author       = {Wang, Limin and Zhang, Zhao and Du, Donglei and Mao, Yaping and Zhang, Xiaoyan},
  doi          = {10.1007/s10878-025-01311-5},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-15},
  shortjournal = {J. Comb. Optim.},
  title        = {Approximation algorithms for the total dominating set problem},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fitting and analyzing data with convex-area-wise linear regression models. <em>JCO</em>, <em>49</em>(5), 1-29. (<a href='https://doi.org/10.1007/s10878-025-01323-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new type of regression methodology named as Convex-Area-Wise Linear Regression(CALR), which separates given datasets by disjoint convex areas and fits different linear regression models for different areas. This regression model is highly interpretable for its close-form local models and boundaries, and it is able to interpolate any given finite datasets even when the underlying relationship between explanatory and response variables are non-linear and discontinuous. In order to construct CALR models for given datasets, accurate algorithms and an incremental algorithm are proposed under different assumptions. The analysis of correctness and time complexity of the algorithms are given, indicating that the problem can be solved in $$o(n^2)$$ time accurately when the input datasets have some special features, or be solved in $$O(T(n_s)+n(M+d^2))$$ time incrementally using an $$n_s$$ -size initial subset to construct initial accurate model.},
  archive      = {J_JCO},
  author       = {Lyu, Bohan and Li, Jianzhong},
  doi          = {10.1007/s10878-025-01323-1},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-29},
  shortjournal = {J. Comb. Optim.},
  title        = {Fitting and analyzing data with convex-area-wise linear regression models},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sufficient conditions for some graphical properties in terms of the lanzhou index and the ad-hoc lanzhou index. <em>JCO</em>, <em>49</em>(5), 1-20. (<a href='https://doi.org/10.1007/s10878-025-01328-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the past decade, several research groups have published sufficient conditions for Hamiltonicity of graphs in terms of the first Zagreb index, the second Zagreb index and the forgotten topological index. The forgotten topological index (F-index) is defined as $$F(G)=\sum \limits _{uv\in E(G)}(d^{2}(u)+d^{2}(v))=\sum \limits _{v\in V(G)}d^{3}(v)$$ . The forgotten topological coindex (F-coindex) is defined as $${\overline{F}}(G)=\sum \limits _{uv\notin E(G)}(d^{2}(u)+d^{2}(v))=\sum \limits _{v\in V(G)}d^{2}(v)(n-d(v)-1)$$ and it can be also called the Lanzhou index Lz(G). The Lanzhou index of the complement of G is the ad-hoc Lanzhou index and defined as $$\widetilde{Lz}(G)=\sum \limits _{v\in V(G)}d(v)(n-d(v)-1)^{2}$$ . This paper mainly focuses on sufficient conditions for graphs to be traceable, Hamiltonian, Hamilton-connected, k-path-coverable, k-Hamiltonian, k-edge-Hamiltonian and k-leaf-connected in terms of the Lanzhou index and the ad-hoc Lanzhou index.},
  archive      = {J_JCO},
  author       = {Liu, Xiangge and Lu, Yong and Zhou, Qiannan},
  doi          = {10.1007/s10878-025-01328-w},
  journal      = {Journal of Combinatorial Optimization},
  month        = {7},
  number       = {5},
  pages        = {1-20},
  shortjournal = {J. Comb. Optim.},
  title        = {Sufficient conditions for some graphical properties in terms of the lanzhou index and the ad-hoc lanzhou index},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The two-center problem of uncertain points on cactus graphs. <em>JCO</em>, <em>49</em>(4), 1-17. (<a href='https://doi.org/10.1007/s10878-025-01292-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the two-center problem on cactus graphs in facility locations, which aims to place two facilities on the graph network to serve customers in order to minimize the maximum transportation cost. In our problem, the location of each customer is uncertain and may appear at O(m) points on the network with probabilities. More specifically, given are a cactus graph G and a set $$\mathcal {P}$$ of n (weighted) uncertain points where every uncertain point has O(m) possible locations on G each associated with a probability and is of a non-negative weight. The problem aims to compute two centers (points) on G so that the maximum (weighted) expected distance of the n uncertain points to their own expected closest center is minimized. No previous algorithms are known for this problem. In this paper, we present the first algorithm for this problem and it solves the problem in $$O(|G|+ m^{2}n^{2}\log mn)$$ time.},
  archive      = {J_JCO},
  author       = {Xu, Haitao and Zhang, Jingru},
  doi          = {10.1007/s10878-025-01292-5},
  journal      = {Journal of Combinatorial Optimization},
  month        = {5},
  number       = {4},
  pages        = {1-17},
  shortjournal = {J. Comb. Optim.},
  title        = {The two-center problem of uncertain points on cactus graphs},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chaotic guided local search algorithm for solving global optimization and engineering problems. <em>JCO</em>, <em>49</em>(4), 1-21. (<a href='https://doi.org/10.1007/s10878-025-01281-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chaos optimization algorithm (COA) is an interesting alternative in a global optimization problem. Due to the non-repetition and ergodicity of chaos, it can explore the global search space at higher speeds than stochastic searches that depend on probabilities. To adjust the solution obtained by COA, guided local search algorithm (GLS) is integrated with COA to form a hybrid algorithm. GLS is a metaheuristic optimization algorithm that combines elements of local search with strategic guidance to efficiently explore the solution space. This study proposes a chaotic guided local search algorithm to search for global solutions. The proposed algorithm, namely COA-GLS, contributes to optimization problems by providing a balance between quick convergence and good solution quality. Its combination of local refinement, strategic guidance, diversification strategies, and adaptability makes it a powerful metaheuristic capable of efficiently navigating complex solution spaces and finding high-quality solutions in a relatively short amount of time. Simulation results show that the present algorithms significantly outperform the existing methods in terms of convergence speed, numerical stability, and a better optimal solution than other algorithms.},
  archive      = {J_JCO},
  author       = {Naanaa, Anis},
  doi          = {10.1007/s10878-025-01281-8},
  journal      = {Journal of Combinatorial Optimization},
  month        = {5},
  number       = {4},
  pages        = {1-21},
  shortjournal = {J. Comb. Optim.},
  title        = {Chaotic guided local search algorithm for solving global optimization and engineering problems},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-objective perspective on the cable-trench problem. <em>JCO</em>, <em>49</em>(4), 1-29. (<a href='https://doi.org/10.1007/s10878-025-01289-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cable-trench problem is defined as a linear combination of the shortest path and the minimum spanning tree problem. In particular, the goal is to find a spanning tree that simultaneously minimizes its total length and the total path length from a pre-defined root to all other vertices. Both, the minimum spanning tree and the shortest path problem are known to be efficiently solvable. However, a linear combination of these two objectives results in a highly complex problem. In this article, we introduce the bi-objective cable-trench problem which separates the two cost functions. We show that in general, the bi-objective formulation has additional compromise solutions compared to the cable-trench problem in its original formulation. To determine the set of non-dominated points and efficient solutions, we use $$\varepsilon $$ -constraint scalarizations in combination with a problem-specific cutting plane. Moreover, we present numerical results on different types of graphs analyzing the impact of density and cost structure on the cardinality of the non-dominated set and the solution time.},
  archive      = {J_JCO},
  author       = {Löhken, Lara and Stiglmayr, Michael},
  doi          = {10.1007/s10878-025-01289-0},
  journal      = {Journal of Combinatorial Optimization},
  month        = {5},
  number       = {4},
  pages        = {1-29},
  shortjournal = {J. Comb. Optim.},
  title        = {A multi-objective perspective on the cable-trench problem},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Path survival reliabilities as measures of reliability for lifeline utility networks. <em>JCO</em>, <em>49</em>(4), 1-24. (<a href='https://doi.org/10.1007/s10878-025-01291-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lifeline utility networks have been studied extensively within the domain of network reliability due to the prevalence of natural hazards. The reliability of these networks is typically investigated through graphs that retain their structural characteristics. This paper introduces novel connectivity-based reliability measures tailored for stochastic graphs with designated source vertices and failure-probability-weighted edges. In particular, the per-vertex path survival reliability quantifies the average survival likelihood of single-source paths from a vertex to any source. A consolidated per-graph reliability measure is also presented, incorporating graph density and the shortest distance to a source as regulating elements for network comparison. To highlight the advantages of the proposed reliability measures, a theoretical discussion of their key properties is presented, along with a comparison against standard reliability measurements. The proposal is further accompanied by an efficient calculation procedure utilizing the zero-suppressed binary decision diagram, constructed through the frontier-based search, to compactly represent all single-source paths. Finally, the path survival reliabilities are calculated for a set of real-world networks and demonstrated to provide practical insights.},
  archive      = {J_JCO},
  author       = {Lim, Brian Godwin and Tan, Renzo Roel and de Jesus, Richard and Garciano, Lessandro Estelito and Garciano, Agnes and Ikeda, Kazushi},
  doi          = {10.1007/s10878-025-01291-6},
  journal      = {Journal of Combinatorial Optimization},
  month        = {5},
  number       = {4},
  pages        = {1-24},
  shortjournal = {J. Comb. Optim.},
  title        = {Path survival reliabilities as measures of reliability for lifeline utility networks},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analyzing the 3-path vertex cover problem in selected graph classes. <em>JCO</em>, <em>49</em>(4), 1-24. (<a href='https://doi.org/10.1007/s10878-025-01285-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on analyzing the 3-path vertex cover (3PVC) problem in a number of graph classes. Let $$G=(V,E)$$ be a simple graph. A set $$C \subseteq V$$ is called a k-path vertex cover of G, if each path of order k in G, contains at least one vertex from C. In the k-path vertex cover problem, we are given a graph G, and asked to find a k-path vertex cover of minimum size. For $$k=3$$ , the problem becomes the well-known 3PVC problem. A problem that is closely related to the 3PVC problem is the dissociation set (DS) problem. Given a graph $$G=(V,E)$$ , a dissociation set is any $$D \subseteq V$$ , such that the vertex-induced subgraph $$G'= (D,E')$$ consists of vertices having degree 0 or 1. In the dissociation set problem, we are required to find a dissociation set of maximum cardinality. Both these problems have also been studied extensively as per the literature. In this paper, we focus on pipartite (planar and bipartite) graphs for the most part. We first show that the 3PVC problem is NP-hard, even in pipartite graphs having maximum degree 4. We then show that the 3PVC problem on this class of graphs admits a linear time $$\frac{8}{5}$$ -approximation algorithm. Next, we show that the 3PVC problem is APX-complete in bipartite graphs having maximum degree 4 and cubic graphs. Finally, we discuss an elegant and alternative proof for the APX-completeness of the vertex cover problem in cubic graphs and establish lower bounds for the 3PVC problem in special graph classes. It is important to note that our work is the first of its kind to establish APX-completeness of the 3PVC problem in graphs.},
  archive      = {J_JCO},
  author       = {Jena, Sangram K. and Subramani, K.},
  doi          = {10.1007/s10878-025-01285-4},
  journal      = {Journal of Combinatorial Optimization},
  month        = {5},
  number       = {4},
  pages        = {1-24},
  shortjournal = {J. Comb. Optim.},
  title        = {Analyzing the 3-path vertex cover problem in selected graph classes},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-online scheduling with non-increasing job sizes and a buffer. <em>JCO</em>, <em>49</em>(4), 1-23. (<a href='https://doi.org/10.1007/s10878-025-01293-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work considers a semi-online version of scheduling on m identical machines, where the objective is to minimize the makespan. In the variant studied here, jobs are presented sorted by non-increasing sizes, and a buffer of size k is available for storing at most k jobs. Every arriving job has to be either placed into the buffer until its assignment, or else it has to be assigned immediately to a machine. We prove a lower bound greater than 1 on the competitive ratio of the problem for any m and any buffer size. To complement this negative result, we design a simple algorithm for any m whose competitive ratio tends to 1 as the buffer size grows. Using those results, we show the best possible competitive ratio is $$1+\Theta (\frac{m}{k})$$ . We provide additional bounds for small values of m. In particular, we show that for $$m=2$$ the case $$k=1$$ is not different from the case without a buffer, while $$k=2$$ admits an improved competitive ratio.},
  archive      = {J_JCO},
  author       = {Epstein, Leah and Zebedat-Haider, Hanan},
  doi          = {10.1007/s10878-025-01293-4},
  journal      = {Journal of Combinatorial Optimization},
  month        = {5},
  number       = {4},
  pages        = {1-23},
  shortjournal = {J. Comb. Optim.},
  title        = {Semi-online scheduling with non-increasing job sizes and a buffer},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A 3-space dynamic programming heuristic for the cubic knapsack problem. <em>JCO</em>, <em>49</em>(4), 1-32. (<a href='https://doi.org/10.1007/s10878-025-01294-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cubic knapsack problem (CKP) is a combinatorial optimization problem, which can be seen both as a generalization of the quadratic knapsack problem (QKP) and of the linear Knapsack problem (KP). This problem consists of maximizing a cubic function of binary decision variables subject to one linear knapsack constraint. It has many applications in biology, project selection, capital budgeting problem, and in logistics. The QKP is known to be strongly NP-hard, which implies that the CKP is also NP-hard in the strong sense. Unlike its linear and quadratic counterparts, the CKP has not received much of attention in the literature. Thus the few exact solution methods known for this problem can only handle problems with up to 60 decision variables. In this paper, we propose a deterministic dynamic programming-based heuristic algorithm for finding a good quality solution for the CKP. The novelty of this algorithm is that it operates in three different space variables and can produce up to three different solutions with different levels of computational effort. The algorithm has been tested on a set of 1570 test instances, which include both standard and challenging instances. The computational results show that our algorithm can find optimal solutions for nearly 98% of the standard test instances that could be solved to optimality and for 92% for the challenging instances. Finally, the computational experiments present comparisons between our algorithm, an existing heuristic algorithm for the CKP found in the literature, as well as adaptations to the CKP of some heuristic algorithms designed for the QKP. The results show that our algorithm outperforms all these methods.},
  archive      = {J_JCO},
  author       = {Dan Dije, Ibrahim and Djeumou Fomeni, Franklin and Coelho, Leandro C.},
  doi          = {10.1007/s10878-025-01294-3},
  journal      = {Journal of Combinatorial Optimization},
  month        = {5},
  number       = {4},
  pages        = {1-32},
  shortjournal = {J. Comb. Optim.},
  title        = {A 3-space dynamic programming heuristic for the cubic knapsack problem},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scheduling problems with rejection in green manufacturing industry. <em>JCO</em>, <em>49</em>(4), 1-19. (<a href='https://doi.org/10.1007/s10878-025-01295-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Green manufacturing is used to describe an environmentally friendly manufacturing approach, which explicitly considers the impact of production on the environment and resources. Therefore, the production scheduling of solving energy conscious is in line with the focus of green manufacturing. In this paper, we consider the scheduling problems with rejection in the green manufacturing industry. The objective is to minimize the makespan of the accepted jobs plus the total rejection penalty of the rejected jobs, subject to the constraint that the total machine cost of the processed jobs is not more than a given threshold. We present pseudo-polynomial time algorithms and 2-approximation algorithms for the single-machine and the parallel-machine problems, respectively.},
  archive      = {J_JCO},
  author       = {Kong, Fanyu and Song, Jiaxin and Miao, Cuixia and Zhang, Yuzhong},
  doi          = {10.1007/s10878-025-01295-2},
  journal      = {Journal of Combinatorial Optimization},
  month        = {5},
  number       = {4},
  pages        = {1-19},
  shortjournal = {J. Comb. Optim.},
  title        = {Scheduling problems with rejection in green manufacturing industry},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review on the versions of artificial bee colony algorithm for scheduling problems. <em>JCO</em>, <em>49</em>(4), 1-46. (<a href='https://doi.org/10.1007/s10878-025-01296-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, artificial bee colony (ABC) algorithm is one of the most popular swarm intelligence based optimization techniques. Although it was originally introduced to work on continuous space for numerical optimization problems, several researchers also successfully use the ABC for other problem types. In this study, variants of the ABC for scheduling problems are surveyed. Since the scheduling problems are combinatorial type problems, generally some modifications related to the solution representation or neighborhood search operators are introduced in these studies. Additionally, several enhancement ideas are also presented for the ABC algorithm such as the improvements of initialization, employed bee, onlooker bee, scout bee phases and hybrid usage with other metaheuristics or local search methods. This paper evaluates the literature, provides some analyses on its current state and gaps, and addresses possible future works. It is hoped that this review study would be beneficial for the researchers interested in this field.},
  archive      = {J_JCO},
  author       = {Gorkemli, Beyza and Kaya, Ebubekir and Karaboga, Dervis and Akay, Bahriye},
  doi          = {10.1007/s10878-025-01296-1},
  journal      = {Journal of Combinatorial Optimization},
  month        = {5},
  number       = {4},
  pages        = {1-46},
  shortjournal = {J. Comb. Optim.},
  title        = {A review on the versions of artificial bee colony algorithm for scheduling problems},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Faster parameterized algorithms for variants of 3-hitting set. <em>JCO</em>, <em>49</em>(4), 1-14. (<a href='https://doi.org/10.1007/s10878-025-01300-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the A-Multi3-Hitting Set problem (A-M3HS), where $$A \subseteq \{1,2,3\}$$ , the input is a hypergraph G in which the hyperedges have sizes at most 3 and an integer k, and the goal is to decide if there is a set S of at most k vertices such that $$|S \cap e| \in A$$ for every hyperedge e. In this paper we give $$O^*(2.027^k)$$ -time algorithms for $$\{1\}$$ -M3HS and $$\{1,3\}$$ -M3HS, and an $$O^*(1.381^k)$$ -time algorithm for $$\{2\}$$ -M3HS.},
  archive      = {J_JCO},
  author       = {Tsur, Dekel},
  doi          = {10.1007/s10878-025-01300-8},
  journal      = {Journal of Combinatorial Optimization},
  month        = {5},
  number       = {4},
  pages        = {1-14},
  shortjournal = {J. Comb. Optim.},
  title        = {Faster parameterized algorithms for variants of 3-hitting set},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear-time algorithm for generating L-shaped floorplans using canonical ordering technique. <em>JCO</em>, <em>49</em>(4), 1-35. (<a href='https://doi.org/10.1007/s10878-025-01287-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {L-shaped floorplans are defined by rectangular modules enclosed within a rectilinear outer boundary, forming an L-shape that can not be altered through simple extension or contraction of a boundary wall. The boundary of such floorplans comprises five convex corners and one concave corner. The concave corner on the boundary of the plan can not be converted into a convex corner without altering the horizontal and vertical adjacency among the modules. This paper introduces a linear-time algorithm based on canonical ordering to generate L-shaped floorplans from properly triangulated plane graphs (PTPGs). Here, modules in the floorplan correspond to the nodes of the given graph, while edges in the graph represent wall adjacency between modules. The proposed algorithm assigns a unique labeling to the given graph, ensuring the presence of a concave corner on the resulting floorplan’s boundary. Simple boundary wall extensions or contractions cannot eliminate this concave corner. It also produces multiple L-shaped floorplans corresponding to the given PTPG, with variations mainly on their concave corners, highlighting the unique configurations possible within the same boundary constraints. Our algorithm offers simplicity over existing methods and is easy to implement. Additionally, we have implemented the algorithm in Python, enabling easy integration for generating L-shaped floorplans in various architectural and VLSI circuit design applications.},
  archive      = {J_JCO},
  author       = {Shiksha and Shekhawat, Krishnendra and Chandna, Ritu and Gupta, Akshaj},
  doi          = {10.1007/s10878-025-01287-2},
  journal      = {Journal of Combinatorial Optimization},
  month        = {5},
  number       = {4},
  pages        = {1-35},
  shortjournal = {J. Comb. Optim.},
  title        = {Linear-time algorithm for generating L-shaped floorplans using canonical ordering technique},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Randomized approximation algorithms for monotone k-submodular function maximization with constraints. <em>JCO</em>, <em>49</em>(4), 1-28. (<a href='https://doi.org/10.1007/s10878-025-01299-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, k-submodular functions have garnered significant attention due to their natural extension of submodular functions and their practical applications, such as influence maximization and sensor placement. Influence maximization involves selecting a set of nodes in a network to maximize the spread of information, while sensor placement focuses on optimizing the locations of sensors to maximize coverage or detection efficiency. This paper first proposes two randomized algorithms aimed at improving the approximation ratio for maximizing monotone k-submodular functions under matroid constraints and individual size constraints. Under the matroid constraints, we design a randomized algorithm with an approximation ratio of $$\frac{nk}{2nk-1}$$ and a complexity of $$O(rn(\text {RO}+k\text {EO}))$$ , where n represents the total number of elements in the ground set, k represents the number of disjoint sets in a k-submodular function, r denotes the size of the largest independent set, $$\text {RO}$$ indicates the time required for the matroid’s independence oracle, and $$\text {EO}$$ denotes the time required for the evaluation oracle of the k-submodular function.Meanwhile, under the individual size constraints, we achieve an approximation factor of $$\frac{nk}{3nk-2}$$ with a complexity of O(knB), where n is the total count of elements in the ground set, and B is the upper bound on the total size of the k disjoint subsets, belonging to $$\mathbb {Z_{+}}$$ . Additionally, this paper designs two double randomized algorithms to accelerate the algorithm’s running speed while maintaining the same approximation ratio, with success probabilities of ( $$1-\delta $$ ), where $$\delta $$ is a positive parameter input by the algorithms. Under the matroid constraint, the complexity is reduced to $$O(n\log r\log \frac{r}{\delta }(\text {RO}+k\text {EO}))$$ . Under the individual size constraint, the complexity becomes $$O(k^{2}n\log \frac{B}{k}\log \frac{B}{\delta })$$ .},
  archive      = {J_JCO},
  author       = {Li, Yuying and Li, Min and Zhou, Yang and Niu, Shuxian and Liu, Qian},
  doi          = {10.1007/s10878-025-01299-y},
  journal      = {Journal of Combinatorial Optimization},
  month        = {5},
  number       = {4},
  pages        = {1-28},
  shortjournal = {J. Comb. Optim.},
  title        = {Randomized approximation algorithms for monotone k-submodular function maximization with constraints},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Big data-driven optimal weighted fused features-based ensemble learning classifier for thyroid prediction with heuristic algorithm. <em>JCO</em>, <em>49</em>(4), 1-44. (<a href='https://doi.org/10.1007/s10878-025-01304-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagnosis of thyroid disease is a most important cause in the field of medicinal research and it is a complex onset axiom. Secretion of Thyroid hormone plays a major role in the regulation of metabolism. Hence, it is very significant to predict thyroid disease in the initial stage, which is helpful for preventing more serious health complications due to thyroid cancer. The diagnostic accuracy of machine leaning-based approaches is greater but these techniques require large amounts of data for the diagnosis process. In the conventional approaches, the time needed for the prediction process is also high. Feature engineering is less investigated in conventional models and hence error produced during the prediction process is high. Hence, in this research work, a machine learning-aided thyroid disease prediction technique is designed to provide higher prediction accuracy and reliability. Initially, the thyroid data is gathered from the standard benchmark resources. Next, the data transformation process is carried out to make the data usable for analysis and visualization. After, the features are extracted using Principal Component Analysis (PCA), “One-Dimensional Convolutional Neural Network Model (1DCNN). Moreover, the statistical features are also extracted for getting more relevant information from the data. The three sets of features such as PCA-based, 1DCNN-based and statistical are concatenated and fed to the “optimal weighted feature selection” process, where the optimal features and weights are tuned by an Improved Archimedes Optimization Algorithm (IAOA). Next, the selected optimally fused features are given to the Ensemble Learning (EL) for predicting the thyroid diseases, where the EL with be suggested by incorporating stacking classifier, XGboost, and Multivariate regression classifier. Ensembling of three different classifiers provides higher thyroid disease prediction accuracy and it makes the decision about normal and abnormal classes. Here, the same IAOA is used for optimizing the parameters of every classifier. The investigational outcomes demonstrate that the proposed ensemble classifier provides higher performance than others. Experimental results prove that the thyroid prediction accuracy of the developed EL approach is 96.30%, precision is 99.67% and F1-score is 97.93%, which is more extensive than the state-of-the-art approaches.},
  archive      = {J_JCO},
  author       = {Priya, K. Hema and Valarmathi, K.},
  doi          = {10.1007/s10878-025-01304-4},
  journal      = {Journal of Combinatorial Optimization},
  month        = {5},
  number       = {4},
  pages        = {1-44},
  shortjournal = {J. Comb. Optim.},
  title        = {Big data-driven optimal weighted fused features-based ensemble learning classifier for thyroid prediction with heuristic algorithm},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Better approximating SONET k-edge partition for small capacity k. <em>JCO</em>, <em>49</em>(4), 1-24. (<a href='https://doi.org/10.1007/s10878-025-01308-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the SONET edge partition problem that models telecommunication network design to partition the edge set of a given graph into several edge-disjoint subgraphs, such that each subgraph has size no greater than a given capacity k and the sum of the orders of these subgraphs is minimized. The problem is NP-hard when $$k \ge 3$$ and admits an $$O(\log k)$$ -approximation algorithm. For small capacity $$k = 3, 4, 5$$ , by observing that some subgraph structures are more favorable than the others, we propose modifications to existing algorithms and design novel amortization schemes to prove their improved performance. Our algorithmic results include a $$\frac{4}{3}$$ -approximation for $$k = 3$$ , improving the previous best $$\frac{13}{9}$$ -approximation, a $$\frac{4}{3}$$ -approximation for $$k = 4$$ , improving the previous best $$(\frac{4}{3} + \epsilon )$$ -approximation, and a $$\frac{3}{2}$$ -approximation for $$k = 5$$ , improving the previous best $$\frac{5}{3}$$ -approximation. Besides these improved algorithms, our main contribution is the amortization scheme design, which can be helpful for similar algorithms and problems.},
  archive      = {J_JCO},
  author       = {Ye, Junhui and Jiang, Huihuang and Chen, Guangting and Chen, Yong and Lin, Guohui and Zhang, An},
  doi          = {10.1007/s10878-025-01308-0},
  journal      = {Journal of Combinatorial Optimization},
  month        = {5},
  number       = {4},
  pages        = {1-24},
  shortjournal = {J. Comb. Optim.},
  title        = {Better approximating SONET k-edge partition for small capacity k},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neighbor sum distinguishable $$k$$ -edge colorings of joint graphs. <em>JCO</em>, <em>49</em>(4), 1-12. (<a href='https://doi.org/10.1007/s10878-025-01309-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a graph G, the normal k-edge coloring $$\sigma $$ is defined as the conventional edge coloring of G using the color set $$\left[ k \right] =\left\{ 1,2,\cdots ,k \right\} $$ . If the condition $$S\left( u \right) \ne S\left( v \right) $$ holds for any edge $$uv\in E\left( G \right) $$ , where $$S\left( u \right) =\sum \nolimits _{uv\in E\left( G \right) }{\sigma \left( uv \right) }$$ , then $$\sigma $$ is termed a neighbor sum distinguishable k-edge coloring of the graph G, abbreviated as k-VSDEC. The minimum number of colors $$ k $$ needed for this type of coloring is referred to as the neighbor sum distinguishable edge chromatic number of $$ G $$ , represented as $$ \chi '_{\varSigma }(G) $$ . This paper examines neighbor sum distinguishable k-edge colorings in the joint graphs of an h-order path $${{P}_{h}}$$ and an $$\left( z+1 \right) $$ -order star $${{S}_{z}}$$ , providing exact values for their neighboring and distinguishable edge coloring numbers, which are either $$\varDelta $$ or $$\varDelta +1$$ .},
  archive      = {J_JCO},
  author       = {Tu, Xiangzhi and Li, Peng and Long, Yangjing and Wang, Aifa},
  doi          = {10.1007/s10878-025-01309-z},
  journal      = {Journal of Combinatorial Optimization},
  month        = {5},
  number       = {4},
  pages        = {1-12},
  shortjournal = {J. Comb. Optim.},
  title        = {Neighbor sum distinguishable $$k$$ -edge colorings of joint graphs},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Testing higher-order clusterability on graphs. <em>JCO</em>, <em>49</em>(3), 1-21. (<a href='https://doi.org/10.1007/s10878-025-01262-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analysis of higher-order organizations, represented as small connected subgraphs, is a fundamental task on complex networks. This paper studies a new problem of testing higher-order clusterability: given neighbor query access to an undirected graph, can we judge whether this graph can be partitioned into a few clusters of highly-connected cliques? This problem is an extension of the former work proposed by Czumaj et al. (STOC’ 15), who recognized cluster structure on graphs using the framework of property testing. In this paper, the problem of testing whether a well-defined higher-order cluster exists is first defined. Then, an $$\varOmega (\sqrt{n})$$ query lower bound of this problem is given. After that, a baseline algorithm is provided by an edge-cluster tester on k-clique dual graph. Finally, an optimized $$\tilde{O}(\sqrt{n})$$ -time algorithm is developed for testing clusterability based on triangles.},
  archive      = {J_JCO},
  author       = {Li, Yifei and Yang, Donghua and Li, Jianzhong},
  doi          = {10.1007/s10878-025-01262-x},
  journal      = {Journal of Combinatorial Optimization},
  month        = {4},
  number       = {3},
  pages        = {1-21},
  shortjournal = {J. Comb. Optim.},
  title        = {Testing higher-order clusterability on graphs},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Some results on the total (zero) forcing number of a graph. <em>JCO</em>, <em>49</em>(3), 1-22. (<a href='https://doi.org/10.1007/s10878-025-01268-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let F(G) and $$F_t(G)$$ be the zero forcing number and the total forcing number of a graph G, respectively. In this paper, we study the relationship between the total forcing number of a graph and its vertex covering number (or independence number), and prove that $$F_t(G) \le \Delta \alpha (G)$$ and $$F_t(G) \le (\Delta - 1)\beta (G) + 1$$ for any connected graph G with the maximum degree $$\Delta $$ , where $$\alpha (G)$$ and $$\beta (G)$$ are the independence number and the vertex covering number of G. In particular, we prove that $$F_t(T) \le F(T) + \beta (T)$$ for any tree T and characterize all trees T with $$F_t(T) = F(T) + \beta (T)$$ . At the same time, all trees T with $$F_t(T) = (\Delta - 1)\beta (T) + 1$$ are completely characterized. In addition, we explore trees, unicycle graphs and Halin graphs satisfying $$F(G) \le \alpha (G)+1$$ .},
  archive      = {J_JCO},
  author       = {Li, Jianxi and Tu, Dongxin and Shiu, Wai Chee},
  doi          = {10.1007/s10878-025-01268-5},
  journal      = {Journal of Combinatorial Optimization},
  month        = {4},
  number       = {3},
  pages        = {1-22},
  shortjournal = {J. Comb. Optim.},
  title        = {Some results on the total (zero) forcing number of a graph},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved black widow optimization algorithm for multi-objective hybrid flow shop batch-scheduling problem. <em>JCO</em>, <em>49</em>(3), 1-29. (<a href='https://doi.org/10.1007/s10878-025-01270-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustainable scheduling is getting more and more attention with economic globalization and sustainable manufacturing. However, fewer studies on the batch scheduling problem consider energy consumption. This paper conducts an investigation into the multi-objective hybrid flow shop batch-scheduling problem with the objectives of minimizing both the makespan and electrical energy consumption. The study aims to select the optimal scheduling solution for the problem by considering batch splitting for all products. In this paper, we propose an improved black widow optimization (IBWO) algorithm to study the problem, which incorporates procreation, cannibalism, and mutation behaviors to maintain the population’s diversity and stability. To achieve our objectives, we use the dynamic entropy weight topsis method to select individual spiders. Finally, we use the nature theorem construction method, which relies on the property theorem, to solve the Pareto solution set and derive the optimization scheme for the hybrid flow shop batch scheduling problem. We verify the effectiveness of the proposed IBWO on instances of varying sizes. When we keep all other factors and cases constant, we compare the IBWO to the NSGA2 algorithm and find that it converges faster for both goals and has lower goals than the NSGA2.},
  archive      = {J_JCO},
  author       = {Liu, Xiyang and Luan, Fangjun},
  doi          = {10.1007/s10878-025-01270-x},
  journal      = {Journal of Combinatorial Optimization},
  month        = {4},
  number       = {3},
  pages        = {1-29},
  shortjournal = {J. Comb. Optim.},
  title        = {Improved black widow optimization algorithm for multi-objective hybrid flow shop batch-scheduling problem},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-machine scheduling with the learning effect of processing time and the deterioration effect of delivery time for prefabricated components. <em>JCO</em>, <em>49</em>(3), 1-26. (<a href='https://doi.org/10.1007/s10878-025-01271-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the production scheduling of prefabricated components, a scheduling model considering the learning effect of processing time and the deterioration effect of delivery time in this paper is provided. More precisely, it asks for an assignment of a series of independent prefabricated jobs that arrived over time to a single machine for processing, and once the execution of a job is finished, it will be transported to the destination. The information of each prefabricated job including its basic processing time $$b_{j}$$ , release time $$r_j$$ , and deterioration rate $$e_j$$ of delivery time is unknown in advance and is revealed upon the arrival of this job. Moreover, the actual processing time of prefabricated job $$J_j$$ with learning effect is $$p_{j}=b_{j}(a-b t)$$ , where a and b are non-negative parameters and t denotes the starting time of prefabricated job $$J_j$$ , respectively. And the delivery time of prefabricated job $$J_j$$ is $$q_{j}=e_{j}C_{j}$$ . The goal of scheduling is to minimize the maximum time by which all jobs have been delivered. For the problem, we first analyze offline optimal scheduling and then propose an online algorithm with a competitive ratio of $$2-bb_{\min }$$ . Furthermore, the effectiveness of the online algorithm is demonstrated by numerical experiments and managerial insights are derived.},
  archive      = {J_JCO},
  author       = {Li, Na and Ma, Ran and Zhang, Yuzhong},
  doi          = {10.1007/s10878-025-01271-w},
  journal      = {Journal of Combinatorial Optimization},
  month        = {4},
  number       = {3},
  pages        = {1-26},
  shortjournal = {J. Comb. Optim.},
  title        = {Single-machine scheduling with the learning effect of processing time and the deterioration effect of delivery time for prefabricated components},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Superposed semi-markov decision process with application to optimal maintenance systems. <em>JCO</em>, <em>49</em>(3), 1-19. (<a href='https://doi.org/10.1007/s10878-025-01272-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the superposition problem of two or more individual semi-Markov decision processes (SMDPs). The new sequential decision process superposed by individual SMDPs is no longer an SMDP and cannot be handled by routine iterative algorithms, but we can expand its state spaces to obtain a hybrid-state SMDP. Using this hybrid-state SMDP as an auxiliary and inspired by the Robbins–Monro algorithm underlying the reinforcement learning method, we propose an iteration algorithm based on a combination of dynamic programming and reinforcement learning to numerically solve the superposed sequential decision problem. As an illustration example, we apply our superposition model and algorithm to solve the optimal maintenance problem of a two-component independent parallel system.},
  archive      = {J_JCO},
  author       = {Shi, Jianmin},
  doi          = {10.1007/s10878-025-01272-9},
  journal      = {Journal of Combinatorial Optimization},
  month        = {4},
  number       = {3},
  pages        = {1-19},
  shortjournal = {J. Comb. Optim.},
  title        = {Superposed semi-markov decision process with application to optimal maintenance systems},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Link fault tolerability of the cartesian product power graph $$(K_{9}-c_{9})^{n}$$: Conditional edge-connectivities under six link fault patterns. <em>JCO</em>, <em>49</em>(3), 1-20. (<a href='https://doi.org/10.1007/s10878-025-01273-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-performance computing extensively depends on parallel and distributed systems, necessitating the establishment of quantitative parameters to evaluate the fault tolerability of interconnection networks. The topological structures of interconnection networks in some parallel and distributed systems are designed as n-dimensional $$(K_{9}-C_{9})^{n}$$ , obtained through the repeatedly application of the n-th Cartesian product operation. Since the $$\mathcal {P}$$ -conditional edge-connectivity is proposed by Harary, as a parameter for evaluating the link fault tolerability of the underlying topology graph of the interconnection network system, it has been widely studied in many interconnection networks. The $$\mathcal {P}$$ -conditional edge-connectivity of a connected graph G, denoted by $$\lambda (\mathcal {P};G)$$ , if any, describes the minimum cardinality of the fault edge-cut of the graph G, whose malfunction divides G into multiple components, with each component satisfying a given property $$\mathcal {P}$$ of the graph. In this paper, we primarily define $$\mathcal {P}_{i}^{t}$$ to be properties of containing at least $$9^t$$ processors, every remaining processor lying in a lower dimensional subnetwork of the $$(K_{9}-C_{9})^{n}$$ , $$(K_{9}-C_{9})^{t}$$ , having a minimum degree or average degree of at least 6t, existing two components with each component having at least $$9^t$$ processors, and containing at least one cycle, respectively. We use the properties of the optimal solution to the edge isoperimetric problem of $$(K_{9}-C_{9})^{n}$$ and find that the exact values of the $$\mathcal {P}_{i}$$ -conditional edge-connectivities of the graph $$(K_{9}-C_{9})^{n}$$ share a common value of $$6(n-t)9^t$$ for $$1\le i\le 5$$ and $$0\le t\le n-1$$ , except for $$i=6$$ , the value is $$18n - 6$$ .},
  archive      = {J_JCO},
  author       = {Huang, Zhaoman and Yang, Yayu and Zhang, Mingzu and Yang, Weihua},
  doi          = {10.1007/s10878-025-01273-8},
  journal      = {Journal of Combinatorial Optimization},
  month        = {4},
  number       = {3},
  pages        = {1-20},
  shortjournal = {J. Comb. Optim.},
  title        = {Link fault tolerability of the cartesian product power graph $$(K_{9}-c_{9})^{n}$$: Conditional edge-connectivities under six link fault patterns},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inefficiency of multiplicative approximate nash equilibrium for scheduling games. <em>JCO</em>, <em>49</em>(3), 1-21. (<a href='https://doi.org/10.1007/s10878-025-01274-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the inefficiency of multiplicative approximate Nash Equilibrium for scheduling games. There is a set of machines and a set of jobs. Each job could choose one machine and be processed by the chosen one. A schedule is a $$\theta $$ -NE if no player has the incentive to deviate so that it decreases its cost by a factor larger than $$1+\theta $$ . The $$\theta $$ -NE is a generation of Nash Equilibrium and its inefficiency can be measured by the $$\theta $$ -PoA, which is also a generalization of the Price of Anarchy. For the game with the social cost of minimizing the makespan, the exact $$\theta $$ -PoA for any number of machines and any $$\theta \ge 0$$ is obtained. For the game with the social cost of maximizing the minimum machine load, we present upper and lower bounds on the $$\theta $$ -PoA. Tight bounds are provided for cases where the number of machines is between 2 and 7 and for any $$\theta \ge 0$$ .},
  archive      = {J_JCO},
  author       = {Wang, Zhuyinan and Zhang, Chen and Tan, Zhiyi},
  doi          = {10.1007/s10878-025-01274-7},
  journal      = {Journal of Combinatorial Optimization},
  month        = {4},
  number       = {3},
  pages        = {1-21},
  shortjournal = {J. Comb. Optim.},
  title        = {Inefficiency of multiplicative approximate nash equilibrium for scheduling games},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guaranteeing fairness and efficiency under budget constraints. <em>JCO</em>, <em>49</em>(3), 1-21. (<a href='https://doi.org/10.1007/s10878-025-01275-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of how to fairly and efficiently allocate indivisible items (goods) to agents under budget constraints. Each item has a specific size, and each agent has a budget that limits the total size of the items received. To better explore efficiency, we introduce the concept of tightness, where all agents are tight. An agent is considered as tight if adding any unallocated item to her bundle would exceed her budget. Interestingly, we observe that all individual optimal (IO) allocations, which contain Pareto optimal (PO) allocations, can be extended into a tight allocation while maintaining the values of the agents’ bundles. We achieve an overall negative result for general even identical or binary valuations: there exists no allocation meeting both tightness and envy-freeness up to any item (EFX), and even relaxing it to any desired approximate EFX has been proven to be impossible. However, for single-valued valuations, we illustrate that an EFX and tight (or IO) allocation always exist, and it can be computed using a polynomial algorithm. For single-valued valuations, we establish the existence of 1/2-EFX and PO allocations, with the approximation ratio being the best possible. To further our efforts to study fairness and efficiency, we introduce a relaxed concept of tightness, partial tightness (PT), in which only the unenvied agents are tight. We find that 1/2-EFX and PT allocations are achievable by providing a pseudo-polynomial time algorithm. When agents’ budgets are identical, we can compute a 1/2-EFX and PT allocation in polynomial time.},
  archive      = {J_JCO},
  author       = {Wang, Yuanyuan and Chen, Xin and Fang, Qizhi and Nong, Qingqin and Liu, Wenjing},
  doi          = {10.1007/s10878-025-01275-6},
  journal      = {Journal of Combinatorial Optimization},
  month        = {4},
  number       = {3},
  pages        = {1-21},
  shortjournal = {J. Comb. Optim.},
  title        = {Guaranteeing fairness and efficiency under budget constraints},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mathematical models for the one-dimensional cutting stock problem with setups and open stacks. <em>JCO</em>, <em>49</em>(3), 1-35. (<a href='https://doi.org/10.1007/s10878-025-01276-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-life production, the cutting stock problem is often associated with additional constraints and objectives. Among the auxiliary objectives, two of the most relevant are the minimization of the number of different cutting patterns used and the minimization of the maximum number of simultaneously open stacks. The first auxiliary objective arises in manufacturing environments where the adjustment of the cutting tools when changing the cutting patterns incurs increased costs and time spent in production. The second is crucial to face scenarios where the space near the cutting machine or the number of automatic unloading stations is limited. In this paper, we address the one-dimensional cutting stock problem, considering the additional goals of minimizing the number of different cutting patterns used and the maximum number of simultaneously open stacks. We propose two Integer Linear Programming (ILP) formulations and a Constraint Programming (CP) model for the problem. Moreover, we develop new upper bounds on the frequency of the cutting patterns in a solution and address some special cases in which the problem may be simplified. All three approaches are embedded into an iterative exact framework to find efficient solutions. We perform computational experiments using two sets of instances from the literature. The proposed approaches proved effective in determining the entire Pareto front for small problem instances, and several solutions for medium-sized instances with minimum trim loss, a reduced maximum number of simultaneously open stacks, and a small number of different used cutting patterns.},
  archive      = {J_JCO},
  author       = {Guimarães, Gabriel Gazzinelli and Poldi, Kelly Cristina and Martin, Mateus},
  doi          = {10.1007/s10878-025-01276-5},
  journal      = {Journal of Combinatorial Optimization},
  month        = {4},
  number       = {3},
  pages        = {1-35},
  shortjournal = {J. Comb. Optim.},
  title        = {Mathematical models for the one-dimensional cutting stock problem with setups and open stacks},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Steiner trees with infinitely many terminals on the sides of an angle. <em>JCO</em>, <em>49</em>(3), 1-28. (<a href='https://doi.org/10.1007/s10878-025-01277-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Euclidean Steiner problem is the problem of finding a set $$\mathcal{S}\mathcal{t}$$ , with the shortest length, such that $$\mathcal{S}\mathcal{t}\cup \mathcal {A}$$ is connected, where $$\mathcal {A}$$ is a given set in a Euclidean space. The solutions $$\mathcal{S}\mathcal{t}$$ to the Steiner problem will be called Steiner sets while the set $$\mathcal {A}$$ will be called input. Since every Steiner set is acyclic we call it Steiner tree in the case when it is connected. We say that a Steiner tree is indecomposable if it does not contain any Steiner tree for a subset of the input. We are interested in finding the Steiner set when the input consists of infinitely many points distributed on two lines. In particular we would like to find a configuration which gives an indecomposable Steiner tree. It is natural to consider a self-similar input, namely the set $$\mathcal {A}_{\alpha ,\lambda }$$ of points with coordinates $$(\lambda ^{k-1}\cos \alpha ,$$ $$\pm \lambda ^{k-1}\sin \alpha )$$ , where $$\lambda >0$$ and $$\alpha >0$$ are small fixed values and $$k \in \mathbb {N}$$ . These points are distributed on the two sides of an angle of size $$2\alpha $$ in such a way that the distances from the points to the vertex of the angle are in a geometric progression. To our surprise, we show that in this case the solutions to the Steiner problem for $$\mathcal {A}_{\alpha ,\lambda }$$ , when $$\alpha $$ and $$\lambda $$ are small enough, are always decomposable trees. More precisely, any Steiner tree for $$\mathcal {A}_{\alpha ,\lambda }$$ is a countable union of Steiner trees, each one connecting 5 points from the input. Each component of the decomposition can be mirrored with respect to the angle bisector providing $$2^{\mathbb N}$$ different solutions with the same length. By considering only a finite number of components we obtain many solutions to the Steiner problem for finite sets composed of $$4k+1$$ points distributed on the two lines ( $$2k+1$$ on a line and 2k on the other line). These solutions are very similar to the ladders of Chung and Graham. We are able to obtain an indecomposable Steiner tree by adding, to the previous input, a single point strategically placed inside the angle. In this case the solution is in fact a self-similar tree (in the sense that it contains a homothetic copy of itself). Finally, we show how the position of the Steiner points in the Steiner tree can be described by a discrete dynamical system which turns out to be equivalent to a 2-interval piecewise linear contraction.},
  archive      = {J_JCO},
  author       = {Cherkashin, Danila and Paolini, Emanuele and Teplitskaya, Yana},
  doi          = {10.1007/s10878-025-01277-4},
  journal      = {Journal of Combinatorial Optimization},
  month        = {4},
  number       = {3},
  pages        = {1-28},
  shortjournal = {J. Comb. Optim.},
  title        = {Steiner trees with infinitely many terminals on the sides of an angle},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximation algorithms for solving the heterogeneous rooted tree/path cover problems. <em>JCO</em>, <em>49</em>(3), 1-19. (<a href='https://doi.org/10.1007/s10878-025-01278-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the heterogeneous rooted tree cover (HRTC) problem, which further generalizes the rooted tree cover problem. Specifically, given a complete graph $$G=(V,E; w,f; r)$$ and k construction teams, having nonuniform construction speeds $$\lambda _{1}$$ , $$\lambda _{2}$$ , $$\ldots $$ , $$\lambda _{k}$$ , where $$r\in V$$ is a fixed common root, $$w:E\rightarrow {\mathbb {R}}^{+}$$ is an edge-weight function, satisfying the triangle inequality, and $$f:V\rightarrow {\mathbb {R}}^{+}_{0}$$ (i.e., $${\mathbb {R}}^{+}\cup \{0\})$$ is a vertex-weight function with $$f(r)=0$$ , we are asked to find k trees for these k construction teams, each tree having the same root r, and collectively covering all vertices in V, the objective is to minimize the maximum completion time of k construction teams, where the completion time of each team is the total construction weight of its related tree divided by its construction speed. In addition, substituting k paths for k trees in the HRTC problem, we also consider the heterogeneous rooted path cover (HRPC) problem. Our main contributions are as follows. (1) Given any small constant $$\delta >0$$ , we first design a $$58.3286(1+\delta )$$ -approximation algorithm to solve the HRTC problem, and this algorithm runs in time $$O(n^{2}(n+\frac{\log n}{\delta })+\log (w(E)+f(V)))$$ . Meanwhile, we present a simple $$116.6572(1+\delta )$$ -approximation algorithm to solve the HRPC problem, whose time complexity is the same as the preceding algorithm. (2) We provide a $$\max \{2\rho , 2+\rho -\frac{2}{k}\}$$ -approximation algorithm to resolve the HRTC problem, and that algorithm runs in time $$O(n^{2})$$ , where $$\rho $$ is the ratio of the largest team speed to the smallest one. At the same time, we can prove that the preceding $$\max \{2\rho , 2+\rho -\frac{2}{k}\}$$ -approximation algorithm also resolves the HRPC problem.},
  archive      = {J_JCO},
  author       = {Pan, Pengxiang and Lichen, Junran and Yang, Ping and Li, Jianping},
  doi          = {10.1007/s10878-025-01278-3},
  journal      = {Journal of Combinatorial Optimization},
  month        = {4},
  number       = {3},
  pages        = {1-19},
  shortjournal = {J. Comb. Optim.},
  title        = {Approximation algorithms for solving the heterogeneous rooted tree/path cover problems},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved approximation algorithm for covering vertices by $$4^+$$ -paths. <em>JCO</em>, <em>49</em>(3), 1-29. (<a href='https://doi.org/10.1007/s10878-025-01279-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path cover is one of the well-known NP-hard problems that has received much attention. In this paper, we study a variant of path cover, denoted by $$\hbox {MPC}^{{4}+}_v$$ , to cover as many vertices in a given graph $$G = (V, E)$$ as possible by a collection of vertex-disjoint paths each of order four or above. The problem admits an existing $$O(|V|^8)$$ -time 2-approximation algorithm by applying several time-consuming local improvement operations (Gong et al.: Proceedings of MFCS 2022, LIPIcs 241, pp 53:1–53:14, 2022). In contrast, our new algorithm uses a completely different method and it is an improved $$O(\min \{|E|^2|V|^2, |V|^5\})$$ -time 1.874-approximation algorithm, which answers the open question in Gong et al. (2022) in the affirmative. An important observation leading to the improvement is that the number of vertices in a maximum matching M of G is relatively large compared to that in an optimal solution of $$\hbox {MPC}^{{4}+}_v$$ . Our new algorithm forms a feasible solution of $$\hbox {MPC}^{{4}+}_v$$ from a maximum matching M by computing a maximum-weight path-cycle cover in an auxiliary graph to connect as many edges in M as possible.},
  archive      = {J_JCO},
  author       = {Gong, Mingyang and Chen, Zhi-Zhong and Lin, Guohui and Wang, Lusheng},
  doi          = {10.1007/s10878-025-01279-2},
  journal      = {Journal of Combinatorial Optimization},
  month        = {4},
  number       = {3},
  pages        = {1-29},
  shortjournal = {J. Comb. Optim.},
  title        = {An improved approximation algorithm for covering vertices by $$4^+$$ -paths},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact and approximation algorithms for the multi-depot data mule scheduling with handling time and time span constraints. <em>JCO</em>, <em>49</em>(3), 1-22. (<a href='https://doi.org/10.1007/s10878-025-01280-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the data mule scheduling with handling time and time span constraints (DMSTC) in which the goal is to minimize the number of data mules dispatched from a depot that are used to serve target sensors located on a wireless sensor network. Each target sensor is associated with a handling time and each dispatched data mule must return to the original depot before time span $$D$$ . We also study a variant of the DMSTC, denoted by DMSTC $$_l$$ in which the objective is to minimize the total travel distance of the data mules dispatched. We give exact and approximation algorithms for the DMSTC/DMSTC $$_l$$ on a path and their multi-depot version. For the DMSTC, we show an $$O(n^4)$$ polynomial time algorithm for the uniform 2-depot DMSTC on a path with at least one depot being on the endpoint of the path, where $$n$$ indicates the number of target sensors and an instance of the DMSTC is called uniform if all the handling times are identical. We present a new 2-approximation algorithm for the non-uniform DMSTC on a path and conduct extensive computational experiments on randomly generated instances to show its good practical performance. For the DMSTC $$_l$$ , we derive an $$O((n+k)^{2})$$ -time algorithm for the uniform multi-depot DMSTC $$_l$$ on a path, where $$k$$ is the number of depots. For the non-uniform multi-depot DMSTC $$_l$$ on a path or cycle, we give a 2-approximation algorithm.},
  archive      = {J_JCO},
  author       = {Liu, Minqin and Yu, Wei and Liu, Zhaohui and Guo, Xinmeng},
  doi          = {10.1007/s10878-025-01280-9},
  journal      = {Journal of Combinatorial Optimization},
  month        = {4},
  number       = {3},
  pages        = {1-22},
  shortjournal = {J. Comb. Optim.},
  title        = {Exact and approximation algorithms for the multi-depot data mule scheduling with handling time and time span constraints},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximation algorithm for dynamic facility location problem. <em>JCO</em>, <em>49</em>(3), 1-15. (<a href='https://doi.org/10.1007/s10878-025-01282-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider dynamic facility location problem with unit demand (DFLPUD). We propose a 1.52-approximation algorithm that skillfully integrates dual-fitting and greedy augmentation schemes. Our algorithmic framework begins by formulating DFLPUD as a set covering linear integer programming problem. Then we scale the opening cost of all facilities and use the solution of dual-fitting algorithm to seed a local search to yield an improved performance guarantee 1.52. To the best of our knowledge, this is the best known approximation ratio for DFLPUD.},
  archive      = {J_JCO},
  author       = {Zhang, Li and Li, Qiaoliang},
  doi          = {10.1007/s10878-025-01282-7},
  journal      = {Journal of Combinatorial Optimization},
  month        = {4},
  number       = {3},
  pages        = {1-15},
  shortjournal = {J. Comb. Optim.},
  title        = {Approximation algorithm for dynamic facility location problem},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximizing utilitarian and egalitarian welfare of fractional hedonic games on tree-like graphs. <em>JCO</em>, <em>49</em>(3), 1-49. (<a href='https://doi.org/10.1007/s10878-025-01283-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fractional hedonic games are coalition formation games where a player’s utility is determined by the average value they assign to the members of their coalition. These games are a variation of graph hedonic games, which are a class of coalition formation games that can be succinctly represented. Due to their applicability in network clustering and their relationship to graph hedonic games, fractional hedonic games have been extensively studied from various perspectives. However, finding welfare-maximizing partitions in fractional hedonic games is a challenging task due to the nonlinearity of utilities. In fact, it has been proven to be NP-hard and can be solved in polynomial time only for a limited number of graph classes, such as trees. This paper presents (pseudo)polynomial-time algorithms to compute welfare-maximizing partitions in fractional hedonic games on tree-like graphs. We consider two types of social welfare measures: utilitarian and egalitarian. Tree-like graphs refer to graphs with bounded treewidth and block graphs. A hardness result is provided, demonstrating that the pseudopolynomial-time solvability is the best possible under the assumption P $$\ne $$ NP.},
  archive      = {J_JCO},
  author       = {Hanaka, Tesshu and Ikeyama, Airi and Ono, Hirotaka},
  doi          = {10.1007/s10878-025-01283-6},
  journal      = {Journal of Combinatorial Optimization},
  month        = {4},
  number       = {3},
  pages        = {1-49},
  shortjournal = {J. Comb. Optim.},
  title        = {Maximizing utilitarian and egalitarian welfare of fractional hedonic games on tree-like graphs},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A sharp upper bound for the edge dominating number of hypergraphs with minimum degree. <em>JCO</em>, <em>49</em>(3), 1-16. (<a href='https://doi.org/10.1007/s10878-025-01284-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a hypergraph H(V, E), a subset of edges $$A\subseteq E$$ forms an edge dominating set if each edge $$e\in E\setminus A$$ is adjacent to at least one edge in A. The edge dominating number $$\gamma '(H)$$ represents the smallest size of an edge dominating set in H. In this paper, we establish upper bounds on the edge dominating number for hypergraphs with minimum degree $$\delta $$ : (1) For $$\delta \le 4$$ , $$\gamma '(H)\le \frac{m}{\delta }$$ ; (2) For $$\delta \ge 5$$ , $$\gamma '(H)\le \frac{m}{\delta }$$ holds for hypertrees and uniform hypergraphs; (3) For a random hypergraph model $$\mathcal H(n,m)$$ , for any positive number $$\varepsilon >0$$ , $$\gamma ' (H)\le (1+\varepsilon )\frac{m}{\delta }$$ holds with high probability when m is bounded by some polynomial function of n. Based on the proofs, some combinatorial algorithms on the edge dominating number of hypergraphs with minimum degree are designed.},
  archive      = {J_JCO},
  author       = {Tang, Zhongzheng and Diao, Zhuo},
  doi          = {10.1007/s10878-025-01284-5},
  journal      = {Journal of Combinatorial Optimization},
  month        = {4},
  number       = {3},
  pages        = {1-16},
  shortjournal = {J. Comb. Optim.},
  title        = {A sharp upper bound for the edge dominating number of hypergraphs with minimum degree},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uav trajectory optimization for maximizing the ToI-based data utility in wireless sensor networks. <em>JCO</em>, <em>49</em>(3), 1-25. (<a href='https://doi.org/10.1007/s10878-025-01286-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It’s a promising way to use Unmanned Aerial Vehicles (UAVs) as mobile base stations to collect data from sensor nodes, especially for large-scale wireless sensor networks. There are a lot of works that focus on improving the freshness of the collected data or the data collection efficiency by scheduling UAVs. Given that sensing data in certain applications is time-sensitive, with its value diminishing as time progresses based on Timeliness of Information (ToI), this paper delves into the UAV Trajectory optimization problem for Maximizing the ToI-based data utility (TMT). We give the formal definition of the problem and prove its NP-Hardness. To solve the TMT problem, we propose a deep reinforcement learning-based algorithm that combines the Action Rejection Mechanism and the Deep Q-Network with Priority Experience Replay (ARM-PER-DQN). Where the action rejection mechanism could reduce the action space and PER helps improve the utilization of experiences with high value, thus increasing the training efficiency. To avoid the unbalanced data collection problem, we also investigate a variant problem of TMT (named V-TMT), i.e., each sensor node can be visited by the UAV at most once. We prove that the V-TMT problem is also NP-Hard, and propose a 2-approximation algorithm as the baseline of the ARM-PER-DQN algorithm. We conduct extensive simulations for the two problems to validate the performance of our designs, and the results show that our ARM-PER-DQN algorithm outperforms other baselines, especially in the V-TMT problem, the ARM-PER-DQN algorithm always outperforms the proposed 2-approximation algorithm, which suggests the effectiveness of our algorithm.},
  archive      = {J_JCO},
  author       = {Zhao, Qing and Li, Zhen and Li, Jianqiang and Guo, Jianxiong and Ding, Xingjian and Li, Deying},
  doi          = {10.1007/s10878-025-01286-3},
  journal      = {Journal of Combinatorial Optimization},
  month        = {4},
  number       = {3},
  pages        = {1-25},
  shortjournal = {J. Comb. Optim.},
  title        = {Uav trajectory optimization for maximizing the ToI-based data utility in wireless sensor networks},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the parenthesisations of matrix chains: All are useful, few are essential. <em>JCO</em>, <em>49</em>(3), 1-18. (<a href='https://doi.org/10.1007/s10878-025-01290-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The product of a matrix chain consisting of n matrices can be computed in $$C_{n-1}$$ (Catalan’s number) different ways, each identified by a distinct parenthesisation of the chain. The best algorithm to select a parenthesisation that minimises the cost runs in $$O(n \log n)$$ time. Approximate algorithms run in O(n) time and find solutions that are guaranteed to be within a certain factor from optimal; the best factor is currently 1.155. In this article, we first prove two results that characterise different parenthesisations, and then use those results to improve on the best known approximation algorithms. Specifically, we show that (a) each parenthesisation is optimal somewhere in the problem domain, and (b) exactly $$n + 1$$ parenthesisations are essential in the sense that the removal of any one of them causes an unbounded penalty for an infinite number of problem instances. By focusing on essential parenthesisations, we improve on the best known approximation algorithm and show that the approximation factor is at most 1.143.},
  archive      = {J_JCO},
  author       = {López, Francisco and Karlsson, Lars and Bientinesi, Paolo},
  doi          = {10.1007/s10878-025-01290-7},
  journal      = {Journal of Combinatorial Optimization},
  month        = {4},
  number       = {3},
  pages        = {1-18},
  shortjournal = {J. Comb. Optim.},
  title        = {On the parenthesisations of matrix chains: All are useful, few are essential},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Social media actors: Perception and optimization of influence across different types. <em>JCO</em>, <em>49</em>(2), 1-39. (<a href='https://doi.org/10.1007/s10878-024-01238-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper deals with the analysis of the communicative behavior of various types of actors, speech perception and optimization of influence based on social media data and is an extended version of the report presented at CSoNet 2020 and published based on the deliverables of the conference. The paper proposes an improved methodology that is tested on the new material of conflicts regarding urban planning. The research was conducted on the material of social media concerning the construction of the South-East Chord in Moscow (Russia). The study involved a cross-disciplinary approach using neural network technologies, complex networks analysis. The dataset included social networks, microblogs, forums, blogs, videos, reviews. This paper presents the semantic model for the influence maximization analysis in social networks using neural network technologies, also proposed a variant of analyzing the situation with individual and collective actors, multiple opinion leaders, with a dynamic transformation of the hierarchy and ratings according to various parameters.},
  archive      = {J_JCO},
  author       = {Kharlamov, Alexander A. and Raskhodchikov, Aleksey N. and Pilgun, Maria},
  doi          = {10.1007/s10878-024-01238-3},
  journal      = {Journal of Combinatorial Optimization},
  month        = {3},
  number       = {2},
  pages        = {1-39},
  shortjournal = {J. Comb. Optim.},
  title        = {Social media actors: Perception and optimization of influence across different types},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An $$L_2$$ regularization reduced quadratic surface support vector machine model. <em>JCO</em>, <em>49</em>(2), 1-28. (<a href='https://doi.org/10.1007/s10878-024-01250-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a reduced quadratic surface support vector machine (RQSSVM) classification model is proposed and solved using the augmented Lagrange method. The new model can effectively handle nonlinearly separable data without kernel function selection and parameter tuning due to its quadratic surface segmentation facility. Meanwhile, the maximum margin term is replaced by an $$L_2$$ regularization term and the Hessian of the quadratic surface is reduced to a diagonal matrix. This simplification significantly reduces the number of decision variables and improves computational efficiency. The $$L_1$$ loss function is used to transform the problem into a convex composite optimization problem. Then the transformed problem is solved by the Augmented Lagrange method and the non-smoothness of the subproblems is handled by the semi-smooth Newton algorithm. Numerical experiments on artificial and public benchmark datasets show that RQSSVM model not only inherits the superior performance of quadratic surface SVM for segmenting nonlinear surfaces, but also significantly improves the segmentation speed and efficiency.},
  archive      = {J_JCO},
  author       = {Wang, Jiguang and Guo, Fangfang and Shen, Jie},
  doi          = {10.1007/s10878-024-01250-7},
  journal      = {Journal of Combinatorial Optimization},
  month        = {3},
  number       = {2},
  pages        = {1-28},
  shortjournal = {J. Comb. Optim.},
  title        = {An $$L_2$$ regularization reduced quadratic surface support vector machine model},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recognizing integrality of weighted rectangles partitions. <em>JCO</em>, <em>49</em>(2), 1-15. (<a href='https://doi.org/10.1007/s10878-024-01252-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a grid of active and inactive pixels, the weighted rectangles partitioning (WRP) problem is to find a maximum-weight partition of the active pixels into rectangles. WRP is formulated as an integer programming problem and instances with an integral relaxation polyhedron are characterized by a balanced problem matrix. A complete characterization of these balanced instances is proved. In addition, computational results on balancedness recognition and on solving WRP are presented.},
  archive      = {J_JCO},
  author       = {Deuker, Paul and Friedrich, Ulf},
  doi          = {10.1007/s10878-024-01252-5},
  journal      = {Journal of Combinatorial Optimization},
  month        = {3},
  number       = {2},
  pages        = {1-15},
  shortjournal = {J. Comb. Optim.},
  title        = {Recognizing integrality of weighted rectangles partitions},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved PTAS for covering targets with mobile sensors. <em>JCO</em>, <em>49</em>(2), 1-22. (<a href='https://doi.org/10.1007/s10878-024-01253-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a movement minimization problem for mobile sensors. Given a set of n point targets, the k-Sink Minimum Movement Target Coverage Problem is to schedule mobile sensors, initially located at k base stations, to cover all targets minimizing the total moving distance of the sensors. We present a polynomial-time approximation scheme for finding a $$(1+\epsilon )$$ approximate solution running in time $$n^{O(1/\epsilon )}$$ for this problem when k, the number of base stations, is constant. Our algorithm improves the running time exponentially from the previous work that runs in time $$n^{O(1/\epsilon ^2)}$$ , without any target distribution assumption. To devise a faster algorithm, we prove a stronger bound on the number of sensors in any unit area in the optimal solution and employ a more refined dynamic programming algorithm whose complexity depends only on the width of the problem.},
  archive      = {J_JCO},
  author       = {Wongwattanakij, Nonthaphat and Phetmak, Nattawut and Jaikaeo, Chaiporn and Fakcharoenphol, Jittat},
  doi          = {10.1007/s10878-024-01253-4},
  journal      = {Journal of Combinatorial Optimization},
  month        = {3},
  number       = {2},
  pages        = {1-22},
  shortjournal = {J. Comb. Optim.},
  title        = {An improved PTAS for covering targets with mobile sensors},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Degree and betweenness-based label propagation for community detection. <em>JCO</em>, <em>49</em>(2), 1-18. (<a href='https://doi.org/10.1007/s10878-024-01254-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection, as a crucial network analysis technique, holds significant application value in uncovering the underlying organizational structure in complex networks. In this paper, we propose a degree and betweenness-based label propagation method for community detection (DBLPA). First, we calculate the importance of each node by combining node degree and betweenness centrality. A node i is considered as a core node in the network if its importance is maximal among its neighbor nodes. Next, layer-by-layer label propagation starts from core nodes. The first layer of nodes for label propagation consists of the first-order neighbors of all core nodes. In the first layer of label propagation, the labels of core nodes are first propagated to the non-common neighbor nodes between core nodes, and then to the common neighbor nodes between core nodes. At the same time, the flag parameter is set to record the changing times of a node’s label, which is helpful to calibrate the node’s labels during the label propagation. It effectively improves the misclassification in the process of label propagation. We test the DBLPA on four real network datasets and nine synthetic network datasets, and the experimental results show that the DBLPA can effectively improve the accuracy of community detection.},
  archive      = {J_JCO},
  author       = {Ni, Qiufen and Wang, Jun and Tang, Zhongzheng},
  doi          = {10.1007/s10878-024-01254-3},
  journal      = {Journal of Combinatorial Optimization},
  month        = {3},
  number       = {2},
  pages        = {1-18},
  shortjournal = {J. Comb. Optim.},
  title        = {Degree and betweenness-based label propagation for community detection},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The undirected optical indices of trees. <em>JCO</em>, <em>49</em>(2), 1-22. (<a href='https://doi.org/10.1007/s10878-024-01255-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a connected graph G, an instance I is a set of pairs of vertices and a corresponding routing R is a set of paths specified for all vertex-pairs in I. Let $$\mathfrak {R}_I$$ be the collection of all routings with respect to I. The undirected optical index of G with respect to I refers to the minimum integer k to guarantee the existence of a mapping $$\phi :R\rightarrow \{1,2,\ldots ,k\}$$ , such that $$\phi (P)\ne \phi (P')$$ if P and $$P'$$ have common edge(s), over all routings $$R\in \mathfrak {R}_I$$ . A natural lower bound of the undirected optical index is the edge-forwarding index, which is defined to be the minimum of the maximum edge-load over all possible routings. Let w(G, I) and $$\pi (G,I)$$ denote the undirected optical index and edge-forwarding index with respect to I, respectively. In this paper, we derive the inequality $$w(T,I_A)<\frac{3}{2}\pi (T,I_A)$$ for any tree T, where $$I_A:=\{\{x,y\}:\,x,y\in V(T)\}$$ is the all-to-all instance.},
  archive      = {J_JCO},
  author       = {Lo, Yuan-Hsun and Fu, Hung-Lin and Zhang, Yijin and Wong, Wing Shing},
  doi          = {10.1007/s10878-024-01255-2},
  journal      = {Journal of Combinatorial Optimization},
  month        = {3},
  number       = {2},
  pages        = {1-22},
  shortjournal = {J. Comb. Optim.},
  title        = {The undirected optical indices of trees},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). $$(K_{1}\vee {P_{t})}$$ -saturated graphs with minimum number of edges. <em>JCO</em>, <em>49</em>(2), 1-15. (<a href='https://doi.org/10.1007/s10878-024-01256-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a fixed graph F, a graph G is F-saturated if G does not contain F as a subgraph, but adding any edge in $$E(\overline{G})$$ will result in a copy of F. The minimum size of an F-saturated graph of order n is called the saturation number of F, denoted by sat(n, F). In this paper, we are interested in saturation problem of graph $$K_1\vee {P_t}$$ for $$t\ge 2$$ . As some known results, $$sat(n,K_1\vee {P_t})$$ is determined for $$2\le t\le 4$$ . We will show that $$sat(n,K_1\vee {P_t})=(n-1)+sat(n-1,P_t)$$ for $$t\ge 5$$ and n sufficiently large. Moreover, $$(K_1\vee {P_t})$$ -saturated graphs with $$sat(n,K_1\vee {P_t})$$ edges are characterized.},
  archive      = {J_JCO},
  author       = {Hu, Jinze and Ji, Shengjin and Cui, Qing},
  doi          = {10.1007/s10878-024-01256-1},
  journal      = {Journal of Combinatorial Optimization},
  month        = {3},
  number       = {2},
  pages        = {1-15},
  shortjournal = {J. Comb. Optim.},
  title        = {$$(K_{1}\vee {P_{t})}$$ -saturated graphs with minimum number of edges},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advertising meets assortment planning: Joint advertising and assortment optimization under multinomial logit model. <em>JCO</em>, <em>49</em>(2), 1-35. (<a href='https://doi.org/10.1007/s10878-024-01257-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the assortment optimization problem has been widely studied in the past decades, the interplay between advertising and its implications for this issue remains under-explored. This study seeks to bridge this research gap by tackling the combined challenge of advertising and assortment optimization. We assume that advertising can increase the awareness of specific products, and the magnitude of this effect is jointly depends on the product-specific effectiveness of advertising and the allocated advertising budget. For this joint problem, our objective is to maximize the expected revenue by finding the optimal advertising strategy and the displayed assortment. In this work, we analyze the structure of this problem and propose efficient approaches to solve it across different scenarios. In the unconstrained setting, we demonstrate that the optimal assortment includes products whose revenue exceeds a certain threshold. When there is a cardinality constraint for the assortment, we consider a relaxed problem and propose an efficient method to identify a near-optimal solution. We also examine the joint assortment, pricing, and advertising problem in both unconstrained and cardinality-constrained settings, incorporating the fairness constraint for the advertising strategy and extending our findings to account for consumer sequential decision-making patterns. Through a series of numerical tests, we confirm the validity of our methods and demonstrate that they outperform existing heuristic approaches.},
  archive      = {J_JCO},
  author       = {Wang, Chenhao and Wang, Yao and Tang, Shaojie},
  doi          = {10.1007/s10878-024-01257-0},
  journal      = {Journal of Combinatorial Optimization},
  month        = {3},
  number       = {2},
  pages        = {1-35},
  shortjournal = {J. Comb. Optim.},
  title        = {Advertising meets assortment planning: Joint advertising and assortment optimization under multinomial logit model},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Agent-constrained truthful facility location games. <em>JCO</em>, <em>49</em>(2), 1-24. (<a href='https://doi.org/10.1007/s10878-025-01258-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a truthful facility location game in which there is a set of agents with private locations on the line of real numbers, and the goal is to place a number of facilities at different locations chosen from the set of those reported by the agents. Given a feasible solution, each agent suffers an individual cost that is either its total distance to all facilities (sum-variant) or its distance to the farthest facility (max-variant). For both variants, we show tight bounds on the approximation ratio of strategyproof mechanisms in terms of the social cost, the total individual cost of the agents.},
  archive      = {J_JCO},
  author       = {Deligkas, Argyrios and Lotfi, Mohammad and Voudouris, Alexandros A.},
  doi          = {10.1007/s10878-025-01258-7},
  journal      = {Journal of Combinatorial Optimization},
  month        = {3},
  number       = {2},
  pages        = {1-24},
  shortjournal = {J. Comb. Optim.},
  title        = {Agent-constrained truthful facility location games},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Embedded-filter ACO using clustering based mutual information for feature selection. <em>JCO</em>, <em>49</em>(2), 1-30. (<a href='https://doi.org/10.1007/s10878-025-01259-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of machine learning algorithms is significantly influenced by the quality of the underlying dataset, which often comprises a mix of essential and redundant features. Feature selection, which identifies and discards these redundant features, plays a pivotal role in reducing computational and storage overheads. Current methodologies for this task primarily span filter-based and wrapper-based techniques. While Ant Colony Optimization, a popular bio-inspired meta-heuristic technique, has been extensively used for feature selection, employing mutual information as a principal heuristic measure, traditional mutual information is primarily suited for categorical features. To address this limitation, this study introduces an Embedded-Filter Ant Colony Optimization feature selection strategy that incorporates Clustering-Based Mutual Information. This integration offers enhanced support for classification tasks involving continuous features. To validate the efficiency of the proposed approach, various datasets were used, and a diverse range of machine learning algorithms were employed to evaluate the derived feature subsets. In addition to comparing the proposed method with Grey Wolf Optimization and Cuckoo Search Optimization-based feature selection approaches, a comprehensive evaluation was also carried out against established Ant Colony Optimization wrapper techniques. Experimental results indicate that the proposed Embedded-Filter Ant Colony Optimization consistently selects the minimal yet most relevant feature set while largely maintaining the efficacy of machine learning algorithms.},
  archive      = {J_JCO},
  author       = {Mallidi, S. Kumar Reddy and Ramisetty, Rajeswara Rao},
  doi          = {10.1007/s10878-025-01259-6},
  journal      = {Journal of Combinatorial Optimization},
  month        = {3},
  number       = {2},
  pages        = {1-30},
  shortjournal = {J. Comb. Optim.},
  title        = {Embedded-filter ACO using clustering based mutual information for feature selection},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving the optimal order quantity with unknown parameters for products with stock-dependent demand and variable holding cost rate. <em>JCO</em>, <em>49</em>(2), 1-22. (<a href='https://doi.org/10.1007/s10878-025-01260-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving the optimal order quantity for products with stock-dependent demand is a challenging task as both exact values of multiple parameters and complicated procedures are required. Motivated by this practical dilemma, this paper develops a new method to overcome the above-mentioned two challenges simultaneously. This new method, referred as two-stage AEOQ (adaptive economic order quantity) policy, includes the following two merits when managing products with stock-dependent demand and variable holding cost rate. First, it is feasible even when the values of underlying parameters are unknown. Second, it is easy-to-implement as decisions are made via adaptively recalibrating the inputs of classical EOQ formula by observable variables in the previous period. Theoretical analysis and numerical example show that this two-stage AEOQ policy could obtain the optimal order quantity. Moreover, this two-stage AEOQ policy is robust to parameter misestimation, and performs better than the traditional solution method when the underlying parameters are volatile. Finally, it is shown that this two-stage AEOQ policy could be further simplified when the fixed ordering cost is negligible. Therefore, this study provides a feasible order policy when the exact values of underlying parameters are unable to gain or when the economic environment is volatile.},
  archive      = {J_JCO},
  author       = {Guo, Zhanbing and Zhang, Yejie},
  doi          = {10.1007/s10878-025-01260-z},
  journal      = {Journal of Combinatorial Optimization},
  month        = {3},
  number       = {2},
  pages        = {1-22},
  shortjournal = {J. Comb. Optim.},
  title        = {Solving the optimal order quantity with unknown parameters for products with stock-dependent demand and variable holding cost rate},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fuzzy approach for the intuitionistic multi-objective linear fractional programming problem using a bisection method. <em>JCO</em>, <em>49</em>(2), 1-24. (<a href='https://doi.org/10.1007/s10878-025-01261-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, intuitionistic fuzzy multi-objective linear fractional programming problems (IFMOLFPs) with several fractional criteria, including profit/cost, profit/time, or profitability ratio maximization, are considered. Moreover, all parameters, with the exception of the decision variables, are characterized as triangular intuitionistic fuzzy numbers. The component-wise optimization method is employed to transform IFMOLFP into an equivalent crisp multi-objective linear fractional problem. Then, we use an iterative fuzzy methodology that integrates linear programming with a bisection approach. The proposed approach addresses single-objective and real-life multi-objective organizational planning problems, which are approached using various methods in the literature. It is used for non-linear membership functions in solving these problems. Furthermore, the values obtained using the ranking function are compared. Ultimately, the decision-maker selects the most appropriate solution technique based on the weights of the objective functions.},
  archive      = {J_JCO},
  author       = {Kara, Nurdan and Kocken, Hale Gonce and Akdemir, Hande Günay},
  doi          = {10.1007/s10878-025-01261-y},
  journal      = {Journal of Combinatorial Optimization},
  month        = {3},
  number       = {2},
  pages        = {1-24},
  shortjournal = {J. Comb. Optim.},
  title        = {A fuzzy approach for the intuitionistic multi-objective linear fractional programming problem using a bisection method},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The edge-vertex domination and weighted edge-vertex domination problem. <em>JCO</em>, <em>49</em>(2), 1-9. (<a href='https://doi.org/10.1007/s10878-025-01263-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a simple (edge weighted) graph $$G = \left( {V,E} \right)$$ with $$\left| V \right| = n$$ and $$\left| E \right| = m$$ . Let $$xy \in E$$ . The domination of a vertex $$z \in V$$ by an edge $$xy$$ is defined as $$z$$ belonging to the closed neighborhood of either $$x$$ or $$y$$ . An edge set $$W$$ is considered as an edge-vertex dominating set of $$G$$ if each vertex of $$V$$ is dominated by some edge of $$W$$ . The (weighted) edge-vertex domination problem aims to find an edge-vertex dominating set of $$G$$ with the minimum cardinality. Let $$M \subseteq V$$ and $$N \subseteq E$$ . Given a positive integer $$p$$ , if a vertex $$z$$ is dominated by $$p$$ edges in set $$N$$ , then set $$N$$ is called a $$p$$ edge-vertex dominating set of graph $$G$$ with respect to $$M$$ . This study investigates the edge-vertex domination problem and the $$p$$ edge-vertex domination problem, presents an algorithm with a time complexity of $$O\left( {nm^{2} } \right)$$ for solving the weighted edge-vertex domination problem on unit interval graphs. Moreover, algorithms have been developed with time complexities of $$O\left( {m\lg m + p\left| M \right| + n} \right)$$ and $$O\left( {n\left| M \right|} \right)$$ for identifying a minimum $$p$$ edge-vertex dominating set of an interval graph $$G$$ and a tree $$T$$ , respectively, with respect to any subset $$M \subseteq V$$ .},
  archive      = {J_JCO},
  author       = {Li, Peng and Xue, Xinyi and Zhou, Xingli},
  doi          = {10.1007/s10878-025-01263-w},
  journal      = {Journal of Combinatorial Optimization},
  month        = {3},
  number       = {2},
  pages        = {1-9},
  shortjournal = {J. Comb. Optim.},
  title        = {The edge-vertex domination and weighted edge-vertex domination problem},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved lower bound for estimating the number of defective items. <em>JCO</em>, <em>49</em>(2), 1-19. (<a href='https://doi.org/10.1007/s10878-025-01264-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a set of items, X, with a total of n items, among which a subset, denoted as $$I\subseteq X$$ , consists of defective items. In the context of group testing, a test is conducted on a subset of items Q, where $$Q \subset X$$ . The result of this test is positive, yielding 1, if Q includes at least one defective item, that is if $$Q \cap I \ne \emptyset $$ . It is negative, yielding 0, if no defective items are present in Q. We introduce a novel method for deriving lower bounds in the context of non-adaptive randomized group testing. For any given constant j, any non-adaptive randomized algorithm that, with probability at least 2/3, estimates the number of defective items |I| within a constant factor requires at least $$\Omega \left( \dfrac{\log n}{\log \log {\mathop {\cdots }\limits ^{j}}\log n}\right) $$ tests. Our result almost matches the upper bound of $$O(\log n)$$ and addresses the open problem posed by Damaschke and Sheikh Muhammad in (Combinatorial Optimization and Applications - 4th International Conference, COCOA 2010, pp 117–130, 2010; Discrete Math Alg Appl 2(3):291–312, 2010). Furthermore, it enhances the previously established lower bound of $$\Omega (\log n/\log \log n)$$ by  Ron and Tsur (ACM Trans Comput Theory 8(4): 15:1–15:19, 2016), and independently by Bshouty (30th International Symposium on Algorithms and Computation, ISAAC 2019, LIPIcs, vol 149, pp 2:1–2:9, 2019). For estimation within a non-constant factor $$\alpha (n)$$ , we show: If a constant j exists such that $$\alpha >{\log \log {\mathop {\cdots }\limits ^{j}}\log n}$$ , then any non-adaptive randomized algorithm that, with probability at least 2/3, estimates the number of defective items |I| to within a factor $$\alpha $$ requires at least $$\Omega \left( \dfrac{\log n}{\log \alpha }\right) .$$ In this case, the lower bound is tight.},
  archive      = {J_JCO},
  author       = {Bshouty, Nader H.},
  doi          = {10.1007/s10878-025-01264-9},
  journal      = {Journal of Combinatorial Optimization},
  month        = {3},
  number       = {2},
  pages        = {1-19},
  shortjournal = {J. Comb. Optim.},
  title        = {Improved lower bound for estimating the number of defective items},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy-efficient real-time multi-workflow scheduling in container-based cloud. <em>JCO</em>, <em>49</em>(2), 1-21. (<a href='https://doi.org/10.1007/s10878-025-01265-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing has a powerful capability to handle a large number of tasks. However, this capability comes with significant energy requirements. It is critical to overcome the challenge of minimizing energy consumption within cloud service platforms without compromising service quality. In this paper, we propose a heuristic energy-saving scheduling algorithm, called Real-time Multi-workflow Energy-efficient Scheduling (RMES), which aims to minimize the total energy consumption in a container-based cloud. RMES schedules tasks in the most parallelized way to improve the resource utilization of the running machines in the cluster, thus reducing the time of the global process and saving energy. This paper also considers the affinity constraints between containers and machines, and RMES has the ability to satisfy the resource quantity and performance requirements of containers during the scheduling process. We introduce a re-scheduling mechanism that automatically adjusts the scheduling decisions of remaining tasks to account for the dynamic system states over time. The results show that RMES outperforms other scheduling algorithms in energy consumption and success rate. In the higher arrival rate scenario, the proposed algorithm saves energy consumption by more than 19.42%. The RMES approach can enhance the reliability and efficiency of scheduling systems.},
  archive      = {J_JCO},
  author       = {Sun, Zaixing and Huang, Hejiao and Li, Zhikai and Gu, Chonglin},
  doi          = {10.1007/s10878-025-01265-8},
  journal      = {Journal of Combinatorial Optimization},
  month        = {3},
  number       = {2},
  pages        = {1-21},
  shortjournal = {J. Comb. Optim.},
  title        = {Energy-efficient real-time multi-workflow scheduling in container-based cloud},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The minimum orientable genus of the repeated cartesian product of graphs. <em>JCO</em>, <em>49</em>(2), 1-13. (<a href='https://doi.org/10.1007/s10878-025-01266-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining the minimum genus of a graph is a fundamental optimisation problem in the study of network design and implementation as it gives a measure of non-planarity of graphs. In this paper, we are concerned with determining the smallest value of g such that a given graph G has an embedding on the orientable surface of genus g. In particular, we consider the Cartesian product of graphs since this is a well studied graph operation which is often used for modeling interconnection networks. The s-cube $$Q_i^{(s)}$$ is obtained by taking the repeated Cartesian product of i complete bipartite graphs $$K_{s,s}$$ . We determine the genus of the Cartesian product of the 2r-cube with the repeated Cartesian product of cycles and of the Cartesian product of the 2r-cube with the repeated Cartesian product of paths.},
  archive      = {J_JCO},
  author       = {Galea, Marietta and Gauci, John Baptist},
  doi          = {10.1007/s10878-025-01266-7},
  journal      = {Journal of Combinatorial Optimization},
  month        = {3},
  number       = {2},
  pages        = {1-13},
  shortjournal = {J. Comb. Optim.},
  title        = {The minimum orientable genus of the repeated cartesian product of graphs},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple identical serial-batch machines scheduling with release dates and submodular rejection penalties. <em>JCO</em>, <em>49</em>(2), 1-27. (<a href='https://doi.org/10.1007/s10878-025-01267-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study a scheduling problem with release dates and submodular rejection penalties on multiple (parallel) identical serial-batch machines. For this problem, each machine processes jobs in batches, jobs in a common batch start and finish simultaneously, and the duration of a batch is equal to the sum of a setup time and the total processing time of jobs in it. Some jobs are accepted and processed on the machines, while the left jobs are rejected with penalty and the total rejection penalty is determined by a submodular function. The objective function to be minimized is the sum of the makespan of accepted jobs and the total rejection penalty. For the scenario of an arbitrary number of machines and submodular rejection penalties, we give a 2-approximation algorithm by which the objective function value of the obtained schedule is no more than twice that of the optimal schedule. For the scenario of a fixed number of machines and linear rejection penalties, we give a pseudo-polynomial-time dynamic programming exact algorithm and a fully polynomial-time approximation scheme.},
  archive      = {J_JCO},
  author       = {Geng, Zhichao and Lu, Lingfa},
  doi          = {10.1007/s10878-025-01267-6},
  journal      = {Journal of Combinatorial Optimization},
  month        = {3},
  number       = {2},
  pages        = {1-27},
  shortjournal = {J. Comb. Optim.},
  title        = {Multiple identical serial-batch machines scheduling with release dates and submodular rejection penalties},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing decision-making in cloud service provider selection using probabilistic p, q-rung orthopair fuzzy model. <em>JCO</em>, <em>49</em>(2), 1-44. (<a href='https://doi.org/10.1007/s10878-025-01269-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Desktop cloud technology has revolutionized modern computing by enabling remote desktop functionality through cloud computing and virtualization. However, traditional fuzzy set theories struggle with the uncertainties inherent in these environments. This study addresses this gap by introducing the probabilistic p, q-rung orthopair fuzzy model, a novel extension that integrates probabilistic elements to improve precision and robustness in decision-making. Key contributions include the development of advanced aggregation operators, such as probabilistic weighted averaging and geometric operators, and their application in a multi-attribute decision-making algorithm. The model is validated through a case study on cloud service provider selection, demonstrating its effectiveness in supporting sustainable development and planning. The results show that the proposed model outperforms existing approaches, offering enhanced accuracy and reliability. This contribution advances decision-making frameworks in desktop cloud environments, fostering sustainability and improving the efficiency of daily office tasks.},
  archive      = {J_JCO},
  author       = {Yiarayong, Pairote},
  doi          = {10.1007/s10878-025-01269-4},
  journal      = {Journal of Combinatorial Optimization},
  month        = {3},
  number       = {2},
  pages        = {1-44},
  shortjournal = {J. Comb. Optim.},
  title        = {Enhancing decision-making in cloud service provider selection using probabilistic p, q-rung orthopair fuzzy model},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incentive mechanism design for value-decreasing tasks in dynamic competitive edge computing networks. <em>JCO</em>, <em>49</em>(1), 1-18. (<a href='https://doi.org/10.1007/s10878-024-01228-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of network architectures and application technologies, there is an increasing number of latency-sensitive tasks generated by user devices, necessitating real-time processing on edge servers. During peak periods, user devices compete for limited edge resources to execute their tasks, while different edge servers also compete for transaction opportunities. This article focus on resource allocation problems in competitive edge networks with multiple participants. Considering the decreasing value of tasks over time, a Greedy Method with Priority Order (GMPO) mechanism based on auction theory is designed to maximize the overall utility of the entire network. This mechanism consists of a short-slot optimal resource allocation phase, a winner determination phase that ensures monotonicity, and a pricing phase based on critical prices. Theoretical analysis demonstrates that the GMPO mechanism can prevent user devices from engaging in dishonest transactions. Experimental results indicate that it significantly enhances the overall utility of competitive edge networks.},
  archive      = {J_JCO},
  author       = {Li, Qie and Wang, Zichen and Du, Hongwei},
  doi          = {10.1007/s10878-024-01228-5},
  journal      = {Journal of Combinatorial Optimization},
  month        = {1},
  number       = {1},
  pages        = {1-18},
  shortjournal = {J. Comb. Optim.},
  title        = {Incentive mechanism design for value-decreasing tasks in dynamic competitive edge computing networks},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced deterministic approximation algorithm for non-monotone submodular maximization under knapsack constraint with linear query complexity. <em>JCO</em>, <em>49</em>(1), 1-14. (<a href='https://doi.org/10.1007/s10878-024-01232-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider the Submodular Maximization under Knapsack ( $$\textsf{SMK}$$ ) constraint problem over the ground set of size n. The problem recently attracted a lot of attention due to its applications in various domains of combinatorial optimization, artificial intelligence, and machine learning. We improve the approximation factor of the fastest deterministic algorithm from $$6+\epsilon $$ to $$5+\epsilon $$ while keeping the best query complexity of O(n), where $$\epsilon >0$$ is a constant parameter. Our technique is based on optimizing the performance of two components: the threshold greedy subroutine and the building of two disjoint sets as candidate solutions. Besides, by carefully analyzing the cost of candidate solutions, we obtain a tighter approximation factor.},
  archive      = {J_JCO},
  author       = {Pham, Canh V.},
  doi          = {10.1007/s10878-024-01232-9},
  journal      = {Journal of Combinatorial Optimization},
  month        = {1},
  number       = {1},
  pages        = {1-14},
  shortjournal = {J. Comb. Optim.},
  title        = {Enhanced deterministic approximation algorithm for non-monotone submodular maximization under knapsack constraint with linear query complexity},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel arctic fox survival strategy inspired optimization algorithm. <em>JCO</em>, <em>49</em>(1), 1-73. (<a href='https://doi.org/10.1007/s10878-024-01233-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of optimization algorithms, nature-inspired techniques have garnered attention for their adaptability and problem-solving prowess. This research introduces the Arctic Fox Algorithm (AFA), an innovative optimization technique inspired by the adaptive survival strategies of the Arctic fox, designed to excel in dynamic and complex optimization landscapes. Incorporating gradient flow dynamics, stochastic differential equations, and probability distributions, AFA is equipped to adjust its search strategies dynamically, enhancing both exploration and exploitation capabilities. Through rigorous evaluation on a set of 25 benchmark functions, AFA consistently outperformed established algorithms particularly in scenarios involving high-dimensional and multi-modal problems, demonstrating faster convergence and improved solution quality. Application of AFA to real-world problems, including wind farm layout optimization and financial portfolio optimization, highlighted its ability to increase energy outputs by up to 15% and improve portfolio Sharpe ratios by 20% compared to conventional methods. These results showcase AFA’s potential as a robust tool for complex optimization tasks, paving the way for future research focused on refining its adaptive mechanisms and exploring broader applications.},
  archive      = {J_JCO},
  author       = {Subha, E. and Jothi Prakash, V. and Antran Vijay, S. Arul},
  doi          = {10.1007/s10878-024-01233-8},
  journal      = {Journal of Combinatorial Optimization},
  month        = {1},
  number       = {1},
  pages        = {1-73},
  shortjournal = {J. Comb. Optim.},
  title        = {A novel arctic fox survival strategy inspired optimization algorithm},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study on $$k$$ - $$walk$$ generation algorithm to prevent the tottering in graph edit distance heuristic algorithms. <em>JCO</em>, <em>49</em>(1), 1-15. (<a href='https://doi.org/10.1007/s10878-024-01236-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph edit distance is usually used for graph similarity checking due to its low information loss and flexibility advantages. However, graph edit distance can’t be used efficiently because it is an NP-Hard problem. Many graph edit distance heuristic algorithms have been proposed to solve this problem. However, some heuristic algorithms for generating $$walk$$ generate unnecessary sequences because of the tottering, which leads to many problems. Because of this, various problems arise, like a decrease in approximation accuracy and an increase in execution time. In this paper, we propose an accurate and efficient graph edit distance heuristic algorithm that prevents tottering when generating $$walk$$ . When generating $$walk$$ , the traversed node‘s information is saved into the queue and then proceeds to traverse the next node. Then, it is possible to prevent the tottering by comparing an existing traversed node with an enqueued one. Through this, we propose a new $$walk$$ generation algorithm that prevents generating unnecessary $$walk$$ and applies it to existing algorithms to prevent the tottering.},
  archive      = {J_JCO},
  author       = {Yoon, SeongCheol and Seo, Daehee and Kim, Su-Hyun and Lee, Im-Yeong},
  doi          = {10.1007/s10878-024-01236-5},
  journal      = {Journal of Combinatorial Optimization},
  month        = {1},
  number       = {1},
  pages        = {1-15},
  shortjournal = {J. Comb. Optim.},
  title        = {A study on $$k$$ - $$walk$$ generation algorithm to prevent the tottering in graph edit distance heuristic algorithms},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximation algorithms for the airport and railway problem. <em>JCO</em>, <em>49</em>(1), 1-33. (<a href='https://doi.org/10.1007/s10878-024-01237-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present approximation algorithms for the Airport and Railway problem (AR) on several classes of graphs. The $$\text{ AR }$$ problem, introduced as reported by Adamaszek et al. (in: Ollinger, Vollmer (eds) 33rd symposium on theoretical aspects of computer science (STACS 2016). Leibniz international proceedings in informatics (LIPIcs), Dagstuhl, 2016), is a combination of the Capacitated Facility Location problem (CFL) and the Network Design Problem (NDP). An $$\text{ AR }$$ instance consists of a set of points (cities) V in a metric d(., .), each of which is associated with a non-negative cost $$f_v$$ and a number k, which represent respectively the cost of establishing an airport (facility) in the corresponding point, and the universal airport capacity. A feasible solution is a network of airports and railways providing services to all cities without violating any capacity, where railways are edges connecting pairs of points, with their costs equivalent to the distance between the respective points. The objective is to find such a network with the least cost. In other words, find a forest, each component having at most k points and one open facility, minimizing the total cost of edges and airport opening costs. As reported by Adamaszek et al. (in: Ollinger, Vollmer (eds) 33rd symposium on theoretical aspects of computer science (STACS 2016). Leibniz international proceedings in informatics (LIPIcs), Dagstuhl, 2016) presented a PTAS for $$\text{ AR }$$ in the two-dimensional Euclidean metric $$\mathbb {R}^2$$ with a uniform opening cost. In subsequent work (as reported by Adamaszek et al. (in: Niedermeier, Vallée (eds) 35th symposium on theoretical aspects of computer science (STACS 2018). Leibniz international proceedings in informatics (LIPIcs), Dagstuhl, 2018).) presented a bicriteria $$\frac{4}{3}\left( 2+\frac{1}{\alpha }\right) $$ -approximation algorithm for $$\text{ AR }$$ with non-uniform opening costs but violating the airport capacity by a factor of $$1+\alpha $$ , i.e. $$(1+\alpha )k$$ capacity where $$0<\alpha \le 1$$ , a $$\left( 2+\frac{k}{k-1}+\varepsilon \right) $$ -approximation algorithm and a bicriteria Quasi-Polynomial Time Approximation Scheme (QPTAS) for the same problem in the Euclidean plane $$\mathbb {R}^2$$ . In this work, we give a 2-approximation for $$\text{ AR }$$ with a uniform opening cost for general metrics and an $$O(\log n)$$ -approximation for non-uniform opening costs. We also give a QPTAS for $$\text{ AR }$$ with a uniform opening cost in graphs of bounded treewidth and a QPTAS for a slightly relaxed version in the non-uniform setting. The latter implies O(1)-approximation on graphs of bounded doubling dimensions, graphs of bounded highway dimensions and planar graphs in quasi-polynomial time.},
  archive      = {J_JCO},
  author       = {Salavatipour, Mohammad R. and Tian, Lijiangnan},
  doi          = {10.1007/s10878-024-01237-4},
  journal      = {Journal of Combinatorial Optimization},
  month        = {1},
  number       = {1},
  pages        = {1-33},
  shortjournal = {J. Comb. Optim.},
  title        = {Approximation algorithms for the airport and railway problem},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New bounds on the price of anarchy of selfish bin packing with partial punishment. <em>JCO</em>, <em>49</em>(1), 1-17. (<a href='https://doi.org/10.1007/s10878-024-01239-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The selfish bin packing with partial punishment is studied in this paper. In this problem, the utility of an item is defined as the load of the bin it is in. Each item plays the role of a selfish agent and wants to maximize its own utility. If an item with size $$s_i$$ moves to another bin, it has to pay the partial punishment of $$\alpha s_{i}$$ , where $$0<\alpha <1$$ . We prove that the price of anarchy (PoA) of this game is at least 1.6424 for any $$\alpha \in (0,1)$$ . In particular, the PoA of this game is at least $$5/3 \approx 1.6667$$ for any $$\alpha \in (\frac{2}{5},1)$$ . Furthermore, we obtain a new upper bound of $$h(\alpha ) \le 31/18 \approx 1.7222$$ on the PoA.},
  archive      = {J_JCO},
  author       = {Li, Xiaowei and Liu, Peihai and Lu, Xiwen},
  doi          = {10.1007/s10878-024-01239-2},
  journal      = {Journal of Combinatorial Optimization},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Comb. Optim.},
  title        = {New bounds on the price of anarchy of selfish bin packing with partial punishment},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Greedy algorithms for stochastic monotone k-submodular maximization under full-bandit feedback. <em>JCO</em>, <em>49</em>(1), 1-25. (<a href='https://doi.org/10.1007/s10878-024-01240-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we theoretically study the Combinatorial Multi-Armed Bandit problem with stochastic monotone k-submodular reward function under full-bandit feedback. In this setting, the decision-maker is allowed to select a super arm composed of multiple base arms in each round and then receives its k-submodular reward. The k-submodularity enriches the application scenarios of the problem we consider in contexts characterized by diverse options. We present two simple greedy algorithms for two budget constraints (total size and individual size) and provide the theoretical analysis for upper bound of the regret value. For the total size budget, the proposed algorithm achieves a $$\frac{1}{2}$$ -regret upper bound by $$\tilde{\mathcal {O}}\left( T^\frac{2}{3}(kn)^{\frac{1}{3}}B\right) $$ where T is the time horizon, n is the number of base arms and B denotes the budget. For the individual size budget, the proposed algorithm achieves a $$\frac{1}{3}$$ -regret with the same upper bound. Moreover, we conduct numerical experiments on these two algorithms to empirically demonstrate the effectiveness.},
  archive      = {J_JCO},
  author       = {Sun, Xin and Guo, Tiande and Han, Congying and Zhang, Hongyang},
  doi          = {10.1007/s10878-024-01240-9},
  journal      = {Journal of Combinatorial Optimization},
  month        = {1},
  number       = {1},
  pages        = {1-25},
  shortjournal = {J. Comb. Optim.},
  title        = {Greedy algorithms for stochastic monotone k-submodular maximization under full-bandit feedback},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Facial expression-based emotion recognition across diverse age groups: A multi-scale vision transformer with contrastive learning approach. <em>JCO</em>, <em>49</em>(1), 1-39. (<a href='https://doi.org/10.1007/s10878-024-01241-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression-based Emotion Recognition (FER) is crucial in human–computer interaction and affective computing, particularly when addressing diverse age groups. This paper introduces the Multi-Scale Vision Transformer with Contrastive Learning (MViT-CnG), an age-adaptive FER approach designed to enhance the accuracy and interpretability of emotion recognition models across different classes. The MViT-CnG model leverages vision transformers and contrastive learning to capture intricate facial features, ensuring robust performance despite diverse and dynamic facial features. By utilizing contrastive learning, the model's interpretability is significantly enhanced, which is vital for building trust in automated systems and facilitating human–machine collaboration. Additionally, this approach enriches the model's capacity to discern shared and distinct features within facial expressions, improving its ability to generalize across different age groups. Evaluations using the FER-2013 and CK + datasets highlight the model's broad generalization capabilities, with FER-2013 covering a wide range of emotions across diverse age groups and CK + focusing on posed expressions in controlled environments. The MViT-CnG model adapts effectively to both datasets, showcasing its versatility and reliability across distinct data characteristics. Performance results demonstrated that the MViT-CnG model achieved superior accuracy across all emotion recognition labels on the FER-2013 dataset with a 99.6% accuracy rate, and 99.5% on the CK + dataset, indicating significant improvements in recognizing subtle facial expressions. Comprehensive evaluations revealed that the model's precision, recall, and F1-score are consistently higher than those of existing models, confirming its robustness and reliability in facial emotion recognition tasks.},
  archive      = {J_JCO},
  author       = {Balachandran, G. and Ranjith, S. and Chenthil, T. R. and Jagan, G. C.},
  doi          = {10.1007/s10878-024-01241-8},
  journal      = {Journal of Combinatorial Optimization},
  month        = {1},
  number       = {1},
  pages        = {1-39},
  shortjournal = {J. Comb. Optim.},
  title        = {Facial expression-based emotion recognition across diverse age groups: A multi-scale vision transformer with contrastive learning approach},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online scheduling on an unbounded parallel-batch machine to minimize the weighted makespan. <em>JCO</em>, <em>49</em>(1), 1-17. (<a href='https://doi.org/10.1007/s10878-024-01242-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study the online over-time scheduling on an unbounded parallel-batch machine to minimize the weighted makespan. First, we show that the general problem has a low bound 2 and then design a 4-competitive online algorithm. Furthermore, we consider a special case in which the jobs have agreeable processing times and weights. When all jobs have the same weights (the task is to minimize the makespan), an online algorithm with the best possible competitive ratio $$\frac{\sqrt{5}+1}{2}\approx 1.618$$ has been established in the literature. We show that, after a slightly modification, this known online algorithm also has the best possible competitive ratio $$\frac{\sqrt{5}+1}{2}\approx 1.618$$ for our problem. Finally, we introduce limited restarts into the above special case and present an online algorithm with a better competitive ratio $$\frac{11}{7}\approx 1.571$$ .},
  archive      = {J_JCO},
  author       = {Zhang, Han and Lu, Lingfa and Yuan, Jinjiang},
  doi          = {10.1007/s10878-024-01242-7},
  journal      = {Journal of Combinatorial Optimization},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Comb. Optim.},
  title        = {Online scheduling on an unbounded parallel-batch machine to minimize the weighted makespan},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Customer segmentation using flying fox optimization algorithm. <em>JCO</em>, <em>49</em>(1), 1-20. (<a href='https://doi.org/10.1007/s10878-024-01243-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customer segmentation, a critical strategy in marketing, involves grouping consumers based on shared characteristics like age, income, and geographical location, enabling firms to effectively establish different strategies depending on the target group of customers. Clustering is a widely utilized data analysis technique that facilitates the identification of diverse groups, each distinguished by their unique set of characteristics. Traditional clustering techniques often lack in handling the complexity of consumer data. This paper introduces a novel approach employing the Flying Fox Optimization algorithm, inspired by the survival strategies of flying foxes, to determine customer segments. Applied to two different datasets, this method demonstrates superior capability in identifying distinct customer groups, thereby facilitating the development of targeted marketing strategies. Our comparative analysis with existing state-of-the-art as well as recently developed clustering methods reveals that the proposed method outperforms them in terms of segmentation capabilities. This research not only presents an innovative clustering technique in market segmentation but also showcases the potential of computational intelligence in improving marketing strategies, enhancing their alignment with each customer’s needs.},
  archive      = {J_JCO},
  author       = {Zervoudakis, Konstantinos and Tsafarakis, Stelios},
  doi          = {10.1007/s10878-024-01243-6},
  journal      = {Journal of Combinatorial Optimization},
  month        = {1},
  number       = {1},
  pages        = {1-20},
  shortjournal = {J. Comb. Optim.},
  title        = {Customer segmentation using flying fox optimization algorithm},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectral influence in networks: An application to input-output analysis. <em>JCO</em>, <em>49</em>(1), 1-43. (<a href='https://doi.org/10.1007/s10878-024-01244-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the concepts of spectral influence and spectral cyclicality, both derived from the largest eigenvalue of a graph’s adjacency matrix. These two novel centrality measures capture both diffusion and interdependence from a local and global perspective respectively. We propose a new clustering algorithm that identifies communities with high cyclicality and interdependence, allowing for overlaps. To illustrate our method, we apply it to input-output analysis within the context of the Moroccan economy.},
  archive      = {J_JCO},
  author       = {Riane, Nizar},
  doi          = {10.1007/s10878-024-01244-5},
  journal      = {Journal of Combinatorial Optimization},
  month        = {1},
  number       = {1},
  pages        = {1-43},
  shortjournal = {J. Comb. Optim.},
  title        = {Spectral influence in networks: An application to input-output analysis},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Np-completeness and bounds for disjunctive total domination subdivision. <em>JCO</em>, <em>49</em>(1), 1-10. (<a href='https://doi.org/10.1007/s10878-024-01245-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A subset $$ S\subseteq V(G) $$ , where V(G) is the vertex set of a graph G, is a disjunctive total dominating set of G if each vertex has a neighbour in S or has at least two vertices in S at distance two from it. The minimum cardinality of such a set is the disjunctive total domination number. There are some graph modifications on the edge or vertex of a graph, one of which is subdividing an edge. The disjunctive total domination subdivision number of G is the minimum number of edges which must be subdivided (each edge in G can be subdivided exactly once) to increase the disjunctive total domination number. Firstly, we prove that the disjunctive total domination subdivision problem is NP-complete in bipartite graphs. We next establish some bounds on disjunctive total domination subdivision.},
  archive      = {J_JCO},
  author       = {Çiftçi, Canan and Aytaç, Aysun},
  doi          = {10.1007/s10878-024-01245-4},
  journal      = {Journal of Combinatorial Optimization},
  month        = {1},
  number       = {1},
  pages        = {1-10},
  shortjournal = {J. Comb. Optim.},
  title        = {Np-completeness and bounds for disjunctive total domination subdivision},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discrete circles: Analytical definition and generation in the hexagonal grid. <em>JCO</em>, <em>49</em>(1), 1-23. (<a href='https://doi.org/10.1007/s10878-024-01246-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an analytical definition of discrete circles in the hexagonal grid. Our approach is based on a non-constant thickness function. We determine the thickness using the (edge and vertex) flake model. Both types of circles are connected. We prove that edge flake circles are without simple points for integer radii. Incremental generation algorithms are deduced from the analytical characterization of both edge and vertex flake circles. We compare our approach with existing algorithms for the circle generation on the hexagonal grid. Our approach offers simpler algorithm and an analytical characterization that the other algorithms do not offer. The benefit of an analytical characterization is that it makes the question of the membership of a point to a primitive trivial.},
  archive      = {J_JCO},
  author       = {Zrour, Rita and Čomić, Lidija and Andres, Eric and Largeteau Skapin, Gaëlle},
  doi          = {10.1007/s10878-024-01246-3},
  journal      = {Journal of Combinatorial Optimization},
  month        = {1},
  number       = {1},
  pages        = {1-23},
  shortjournal = {J. Comb. Optim.},
  title        = {Discrete circles: Analytical definition and generation in the hexagonal grid},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online multiple one way non-preemptive time series search with interrelated prices. <em>JCO</em>, <em>49</em>(1), 1-21. (<a href='https://doi.org/10.1007/s10878-024-01247-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the online multiple time series search problem with interrelated prices (MTSS-ip). This perspective narrows the distance between the problem and the reality of market prices with limited variation. In MTSS-ip, the products arrive periodically, and the decision maker has a limited storage size without knowing future prices. The prices of two adjacent periods are interrelated. This study proposes an online zero-inventory algorithm (ZIA) and proves an upper bound of $$K+1-\frac{K}{\theta _2}$$ on the competitive ratio of ZIA. In addition, a lower bound on the competitive ratio of problem MTSS-ip for any deterministic online algorithm is established. For the case with a large storage size K, a lower bound of $$\frac{K}{48\log _{\theta _2} K}$$ on the competitive ratio for MTSS-ip is proved.},
  archive      = {J_JCO},
  author       = {Zhao, Jinghan and Cheng, Yongxi and Eube, Jan and Liu, Haodong},
  doi          = {10.1007/s10878-024-01247-2},
  journal      = {Journal of Combinatorial Optimization},
  month        = {1},
  number       = {1},
  pages        = {1-21},
  shortjournal = {J. Comb. Optim.},
  title        = {Online multiple one way non-preemptive time series search with interrelated prices},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lollipop and cubic weight functions for graph pebbling. <em>JCO</em>, <em>49</em>(1), 1-17. (<a href='https://doi.org/10.1007/s10878-024-01248-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a configuration of pebbles on the vertices of a graph G, a pebbling move removes two pebbles from a vertex and puts one pebble on an adjacent vertex. The pebbling number of a graph G is the smallest number of pebbles required such that, given an arbitrary initial configuration of pebbles, one pebble can be moved to any vertex of G through some sequence of pebbling moves. Through constructing a non-tree weight function for $$Q_4$$ , we improve the weight function technique, introduced by Hurlbert and extended by Cranston et al., that gives an upper bound for the pebbling number of graphs. Then, we propose a conjecture on weight functions for the n-dimensional cube. We also construct a set of valid weight functions for variations of lollipop graphs, extending previously known constructions.},
  archive      = {J_JCO},
  author       = {Yang, Marshall and Yerger, Carl and Zhou, Runtian},
  doi          = {10.1007/s10878-024-01248-1},
  journal      = {Journal of Combinatorial Optimization},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Comb. Optim.},
  title        = {Lollipop and cubic weight functions for graph pebbling},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal blocks for maximizing the transaction fee revenue of bitcoin miners. <em>JCO</em>, <em>49</em>(1), 1-27. (<a href='https://doi.org/10.1007/s10878-024-01249-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider a combinatorial optimization problem with direct applications in blockchain mining, namely finding the most lucrative blocks for Bitcoin miners, and propose optimal algorithmic solutions. Our experiments show that our algorithms increase the miners’ revenues by more than a million dollars per month. Modern blockchains reward their miners in two ways: (i) a base reward for each block that is mined, and (ii) the transaction fees of those transactions that are included in the mined block. The base reward is fixed by the respective blockchain’s protocol and is not under the miner’s control. Hence, for a miner who wishes to maximize earnings, the fundamental problem is to form a valid block with maximal total transaction fees and then try to mine it. Moreover, in many protocols, including Bitcoin itself, the base reward halves at predetermined intervals, hence increasing the importance of maximizing transaction fees and mining an optimal block. This problem is further complicated by the fact that transactions can be prerequisites of each other or have conflicts (in case of double-spending). In this work, we consider the problem of forming an optimal block, i.e. a valid block with maximal total transaction fees, given a set of unmined transactions. On the theoretical side, we first formally model our problem as an extension of Knapsack and then show that, unlike classical Knapsack, our problem is strongly NP-hard. We also show a hardness-of-approximation result. As such, there is no hope in solving it efficiently for general instances. However, we observe that its real-world instances are quite sparse, i.e. the transactions have very few dependencies and conflicts. Using this fact, and exploiting three well-known graph sparsity parameters, namely treedepth, treewidth and pathwidth, we present exact linear-time parameterized algorithms that are applicable to the real-world instances and obtain optimal results. On the practical side, we provide an extensive experimental evaluation demonstrating that our approach vastly outperforms the current Bitcoin miners in practice, obtaining a significant per-block average increase of 11.34 percent in transaction fee revenues which amounts to almost one million dollars per month.},
  archive      = {J_JCO},
  author       = {Alambardar Meybodi, Mohsen and Goharshady, Amir and Hooshmandasl, Mohammad Reza and Shakiba, Ali},
  doi          = {10.1007/s10878-024-01249-0},
  journal      = {Journal of Combinatorial Optimization},
  month        = {1},
  number       = {1},
  pages        = {1-27},
  shortjournal = {J. Comb. Optim.},
  title        = {Optimal blocks for maximizing the transaction fee revenue of bitcoin miners},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal dispatching of electric vehicles based on optimized deep learning in IoT. <em>JCO</em>, <em>49</em>(1), 1-28. (<a href='https://doi.org/10.1007/s10878-024-01251-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed a growing trend in the utilization of Electric Vehicles (EVs), however with the increased usage of EVs, appropriate strategies for supporting the charging demands has not garnered much attention. The absence of adaptable plans in charging may result in minimized participation; further, the charging demands have to be addressed with utmost care for ensuring reliability and efficiency of the grid. In this paper, an efficient EV charging technique based on blockchain based user transaction and smart contract is devised. Here, charge scheduling is performed by acquiring the information the charging demand of the EV over Internet of things. In case the EV does not have sufficient power to reach the target, nearest Charging Station (CS) with the minimal electricity price is identified. The CS is selected considering various factors, such average waiting time, distance, power, traffic, and so on. Here, power prediction is performed using the Deep Maxout Network (DMN), whose weights are adapted based on the devised Exponentially Snake Optimization (ESO) algorithm. Furthermore, the efficacy of the devised ESO-DMN is examined considering metrics, like average waiting time, distance, and number of EVs charged and power and is found to have attained values of 1.937 s, 13.952 km, 55 and 2.876 J.},
  archive      = {J_JCO},
  author       = {Agalya, V. and Muthuvinayagam, M. and Gandhi, R.},
  doi          = {10.1007/s10878-024-01251-6},
  journal      = {Journal of Combinatorial Optimization},
  month        = {1},
  number       = {1},
  pages        = {1-28},
  shortjournal = {J. Comb. Optim.},
  title        = {Optimal dispatching of electric vehicles based on optimized deep learning in IoT},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
