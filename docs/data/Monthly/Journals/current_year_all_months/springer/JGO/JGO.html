<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JGO</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jgo">JGO - 100</h2>
<ul>
<li><details>
<summary>
(2025). Publisher correction: On a tractable single-level reformulation of a multilevel model of the european entry-exit gas market with market power. <em>JGO</em>, <em>93</em>(2), 571-603. (<a href='https://doi.org/10.1007/s10898-025-01498-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a framework that allows to quantitatively analyze the interplay of the different agents involved in gas trade and transport in the context of the European entry-exit system. Previous contributions have focused on the case of perfectly competitive buyers and sellers of gas, which allows to replace the respective market equilibrium problem by a single welfare maximization problem. Our novel framework considers the mathematically more challenging case of a monopolistic and thus strategic gas seller. In this framework, the objective functions of the gas sellers and buyers cannot be aggregated into a common objective function, which is why a multilevel formulation is necessary to accurately capture the sequential nature of the decisions taken. For this setup, we derive sufficient conditions that allow for reformulating the challenging four-level model as a computationally tractable single-level reformulation. We prove the correctness of this reformulation and use it for solving several test instances to illustrate the applicability of our approach.},
  archive      = {J_JGO},
  author       = {Grimm, Veronika and Grübel, Julia and Schmidt, Martin and Schwartz, Alexandra and Wiertz, Ann-Kathrin and Zöttl, Gregor},
  doi          = {10.1007/s10898-025-01498-1},
  journal      = {Journal of Global Optimization},
  month        = {10},
  number       = {2},
  pages        = {571-603},
  shortjournal = {J. Glob. Optim.},
  title        = {Publisher correction: On a tractable single-level reformulation of a multilevel model of the european entry-exit gas market with market power},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting nesterov’s acceleration via high-resolution differential equations. <em>JGO</em>, <em>93</em>(2), 551-569. (<a href='https://doi.org/10.1007/s10898-025-01543-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nesterov’s accelerated gradient descent (NAG) stands as a landmark in the development of first-order optimization algorithms. Its acceleration mechanism, which originates from a gradient correction term, was elucidated through the high-resolution ordinary differential equation (ODE) framework, as referenced in [1]. This framework has been vital in demystifying the effectiveness of NAG. Moreover, it is worth noting that the construction of Lyapunov functions within this framework is methodical and principled. In this paper, we leverage this framework to conduct an in-depth analysis of the convergence properties of NAG for $$\mu $$ -strongly convex functions. First, we refine the proof of the gradient-correction scheme, streamlining the process with straightforward calculations akin to that in [2]. This also allows us to enlarge the step size to $$s=1/L$$ with only slight modifications. Furthermore, our analysis via the implicit-velocity scheme reveals that its associated Lyapunov function is more succinct to construct, as it simplifies the structure and eases the computation of the iterative difference. This resulting simplicity, coupled with the optimal step size derived, indicates the superiority of the implicit velocity scheme over the gradient correction scheme within the high-resolution ODE framework.},
  archive      = {J_JGO},
  author       = {Chen, Shuo and Shi, Bin and Yuan, Ya-xiang},
  doi          = {10.1007/s10898-025-01543-z},
  journal      = {Journal of Global Optimization},
  month        = {10},
  number       = {2},
  pages        = {551-569},
  shortjournal = {J. Glob. Optim.},
  title        = {Revisiting nesterov’s acceleration via high-resolution differential equations},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The projected-type method for the extended vertical linear complementarity problem revisited. <em>JGO</em>, <em>93</em>(2), 535-550. (<a href='https://doi.org/10.1007/s10898-024-01392-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we further study the projected-type method for the extended vertical linear complementarity problem. By making use of some basic absolute value inequalities, some new convergence properties of the projected-type method are obtained. Compared with the existing results in the literature, the convergence range of the projected-type method is enlarged. By several numerical experiments, we also show the performance of the projected-type method.},
  archive      = {J_JGO},
  author       = {Li, Cui-Xia and Wu, Shi-Liang},
  doi          = {10.1007/s10898-024-01392-2},
  journal      = {Journal of Global Optimization},
  month        = {10},
  number       = {2},
  pages        = {535-550},
  shortjournal = {J. Glob. Optim.},
  title        = {The projected-type method for the extended vertical linear complementarity problem revisited},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving a generalization of the p-regularized subproblems by matrix simultaneous diagonalization via congruence. <em>JGO</em>, <em>93</em>(2), 523-534. (<a href='https://doi.org/10.1007/s10898-025-01536-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are concerned with solving a generalization of the p-regularized subproblems (denoted by (Gp-RS) for short). On one hand, the (Gp-RS) with nonsingular regularized term is the main ingredient of the regularization methods for unconstrained problems and has been studied intensively. On the other hand, (Gp-RS) itself arises in many practical applications and in those cases its regularized term may be singular so that it may have no optimal solutions. It is interesting that if the matrices in the quadratic term and in the regularized term are not simultaneously diagonalizable via congruence (SDC), the (Gp-RS) can only be unbounded from below. If those two matrices are SDC, the (Gp-RS) can be reformulated into one of three cases: an unbounded problem, a p-regularized subproblem (p-RS) of smaller size, or a sum of a (p-RS) of smaller size and an unconstrained quadratic problem with separable variables.},
  archive      = {J_JGO},
  author       = {Nguyen, Van-Bong},
  doi          = {10.1007/s10898-025-01536-y},
  journal      = {Journal of Global Optimization},
  month        = {10},
  number       = {2},
  pages        = {523-534},
  shortjournal = {J. Glob. Optim.},
  title        = {Solving a generalization of the p-regularized subproblems by matrix simultaneous diagonalization via congruence},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-step inertial extragradient algorithm for nonsmooth and nonconvex composite optimization problems. <em>JGO</em>, <em>93</em>(2), 489-521. (<a href='https://doi.org/10.1007/s10898-025-01532-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are concerned with minimizing a composite objective function, which can be decomposed into a differentiable but not necessarily convex part and a convex but possibly nonsmooth function. To efficiently exploit the decomposable structure, in this paper, we propose a Multi-step inertial ExtraGradient Algorithm (MEGA), which consists of two inertial steps involving the combination of finite historical iterates and two proximal gradient steps evaluating the proximal operators of a convex function at some points. With the help of Kurdyka-Łojasiewicz property, we theoretically prove that the sequence generated by our MEGA is globally convergent to a stationary point of the problem under consideration. A series of numerical experiments on Lasso and nonconvex quadratic optimization problems show that the proposed MEGA works well in practice. Particularly exciting is the illustration by some computational results that our MEGA can escape local minima points (at least with high probability) to reach a global solution. This strongly supports the idea that utilizing more historical information in extragradient methods is beneficial for solving nonconvex optimization problems.},
  archive      = {J_JGO},
  author       = {Wang, Zhixue and He, Hongjin},
  doi          = {10.1007/s10898-025-01532-2},
  journal      = {Journal of Global Optimization},
  month        = {10},
  number       = {2},
  pages        = {489-521},
  shortjournal = {J. Glob. Optim.},
  title        = {A multi-step inertial extragradient algorithm for nonsmooth and nonconvex composite optimization problems},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimality conditions for zero-one composite optimization problems. <em>JGO</em>, <em>93</em>(2), 471-487. (<a href='https://doi.org/10.1007/s10898-025-01524-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to study of the second-order optimality conditions for zero-one composite optimization problems via the second subderivatives. This kind of problem has a wide range of applications including support vector machines and 1-bit compressed sensing and so on. To this end, we develop the calculations of the first and second-order subderivative of the zero-one function and the composition of a zero-one function with an affine operator by using some tools in variational analysis.},
  archive      = {J_JGO},
  author       = {Li, Guo-Ping and Feng, Jia-Li and Kan, Chao and Song, Wen},
  doi          = {10.1007/s10898-025-01524-2},
  journal      = {Journal of Global Optimization},
  month        = {10},
  number       = {2},
  pages        = {471-487},
  shortjournal = {J. Glob. Optim.},
  title        = {Optimality conditions for zero-one composite optimization problems},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Point-based sufficient conditions for sharp solutions in nonsmooth optimization. <em>JGO</em>, <em>93</em>(2), 451-470. (<a href='https://doi.org/10.1007/s10898-025-01550-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present some sufficient optimality conditions for sharp and for isolated solutions of constrained scalar and set-valued nonsmooth optimization problems in terms of several types of subgradients and coderivatives. We make use of Shapiro properties for sets and the employment of different kinds of generalized differentiation objects allows to describe several degrees of sharpness. The main assertions generalize related results from literature.},
  archive      = {J_JGO},
  author       = {DUREA, Marius and FLOREA, Elena-Andreea and STRUGARIU, Radu},
  doi          = {10.1007/s10898-025-01550-0},
  journal      = {Journal of Global Optimization},
  month        = {10},
  number       = {2},
  pages        = {451-470},
  shortjournal = {J. Glob. Optim.},
  title        = {Point-based sufficient conditions for sharp solutions in nonsmooth optimization},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tropical gradient descent. <em>JGO</em>, <em>93</em>(2), 413-449. (<a href='https://doi.org/10.1007/s10898-025-01533-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a gradient descent method for solving optimization problems arising in settings of tropical geometry—a variant of algebraic geometry that has attracted growing interest in applications such as computational biology, economics, and computer science. Our approach takes advantage of the polyhedral and combinatorial structures arising in tropical geometry to propose a versatile method for approximating local minima in tropical statistical optimization problems—a rapidly growing body of work in recent years. Theoretical results establish global solvability for 1-sample problems and a convergence rate matching classical gradient descent. Numerical experiments demonstrate the method’s superior performance compared to classical gradient descent for tropical optimization problems which exhibit tropical convexity but not classical convexity. We also demonstrate the seamless integration of tropical descent into advanced optimization methods, such as Adam, offering improved overall accuracy.},
  archive      = {J_JGO},
  author       = {Talbut, Roan and Monod, Anthea},
  doi          = {10.1007/s10898-025-01533-1},
  journal      = {Journal of Global Optimization},
  month        = {10},
  number       = {2},
  pages        = {413-449},
  shortjournal = {J. Glob. Optim.},
  title        = {Tropical gradient descent},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence analysis of primal-dual augmented lagrangian methods and duality theory. <em>JGO</em>, <em>93</em>(2), 359-411. (<a href='https://doi.org/10.1007/s10898-025-01534-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a unified theory of augmented Lagrangians for nonconvex optimization problems that encompasses both duality theory and convergence analysis of primal-dual augmented Lagrangian methods in the infinite dimensional setting. Our goal is to present many well-known concepts and results related to augmented Lagrangians in a unified manner and bridge a gap between existing convergence analysis of primal-dual augmented Lagrangian methods and abstract duality theory. Within our theory we specifically emphasize the role of various fundamental duality concepts (such as duality gap, optimal dual solutions, global saddle points, etc.) in convergence analysis of augmented Lagrangians methods and underline interconnections between all these concepts and convergence of primal and dual sequences generated by such methods. In particular, we prove that the zero duality gap property is a necessary condition for the boundedness of the primal sequence, while the existence of an optimal dual solution is a necessary condition for the boundedness of the sequences of multipliers and penalty parameters, irrespective of the way in which the multipliers and the penalty parameter are updated. Our theoretical results are applicable to many different augmented Lagrangians for various types of cone constrained optimization problems, including Rockafellar-Wets’ augmented Lagrangian, (penalized) exponential/hyperbolic-type augmented Lagrangians, modified barrier functions, etc.},
  archive      = {J_JGO},
  author       = {Dolgopolik, M.V.},
  doi          = {10.1007/s10898-025-01534-0},
  journal      = {Journal of Global Optimization},
  month        = {10},
  number       = {2},
  pages        = {359-411},
  shortjournal = {J. Glob. Optim.},
  title        = {Convergence analysis of primal-dual augmented lagrangian methods and duality theory},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global solution algorithms for DC programming via polyhedral approximations of convex functions. <em>JGO</em>, <em>93</em>(2), 335-357. (<a href='https://doi.org/10.1007/s10898-025-01535-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider difference of convex (DC) programming problems and propose three algorithms to solve them globally. The main working mechanism of the proposed algorithms is to generate polyhedral underestimators to convex functions. Two of these algorithms generate a ‘fine’ polyhedral approximation of the first convex component over the compact feasible region of the DC programming problem. We prove the finiteness of these algorithms, establish the convergence rate of one of them. Moreover, we show that using the polyhedral approximation of the first component, it is possible to compute an approximate global solution of the corresponding DC programming problem without further computational effort. The third algorithm also computes a polyhedral underestimator of the first component of the DC function. Different from the first two algorithms, the third algorithm approximates it locally until finding an approximate global solution to the DC programming problem. It is shown that for any positive approximation error, the third algorithm stops after finitely many iterations. Computational results based on some test instances from the literature are provided.},
  archive      = {J_JGO},
  author       = {Pirani, Fahaar M. and Ulus, Firdevs},
  doi          = {10.1007/s10898-025-01535-z},
  journal      = {Journal of Global Optimization},
  month        = {10},
  number       = {2},
  pages        = {335-357},
  shortjournal = {J. Glob. Optim.},
  title        = {Global solution algorithms for DC programming via polyhedral approximations of convex functions},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of exact and approximation algorithms for linear-parametric optimization problems. <em>JGO</em>, <em>93</em>(1), 299-333. (<a href='https://doi.org/10.1007/s10898-025-01512-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear-parametric optimization, where multiple objectives are combined into a single objective using linear combinations with parameters as coefficients, has numerous links to other fields in optimization and a wide range of application areas. In this survey, we provide a comprehensive overview of structural results and algorithmic strategies for solving linear-parametric optimization problems exactly and approximately. Transferring concepts from related areas such as multi-objective optimization provides further relevant results. The survey consists of two parts: First, we list strategies that work in a general fashion and do not rely on specific problem structures. Second, we look at well-studied parametric optimization problems and cover both important theoretical results and specialized algorithmic approaches for these problems. Among these problems are parametric variants of shortest path problems, minimum cost flow and maximum flow problems, spanning tree problems, the knapsack problem, and matching problems. Overall, we cover the results from 128 publications (and refer to 35 supplemental works) published between 1963 and 2024.},
  archive      = {J_JGO},
  author       = {Nemesch, Levin and Ruzika, Stefan and Thielen, Clemens and Wittmann, Alina},
  doi          = {10.1007/s10898-025-01512-6},
  journal      = {Journal of Global Optimization},
  month        = {9},
  number       = {1},
  pages        = {299-333},
  shortjournal = {J. Glob. Optim.},
  title        = {A survey of exact and approximation algorithms for linear-parametric optimization problems},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solution methods for partial inverse combinatorial optimization problems in which weights can only be increased. <em>JGO</em>, <em>93</em>(1), 263-298. (<a href='https://doi.org/10.1007/s10898-025-01529-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial inverse combinatorial optimization problems are bilevel optimization problems in which the leader aims to incentivize the follower to include respectively not include given sets of elements in the solution of their combinatorial problem. If the sets of required and forbidden elements define a complete follower solution and the follower problem is solvable in polynomial time, then the inverse combinatorial problem is also solvable in polynomial time. In contrast, partial inverse problems can be NP-complete when the follower problem is solvable in polynomial time. This applies e.g. to the partial inverse min cut problem. In this paper, we consider partial inverse combinatorial optimization problems in which weights can only be increased. Furthermore, we assume that the lower-level combinatorial problem can be solved as a linear program. In this setting, we show that the partial inverse shortest path problem on a directed acyclic graph is NP-complete. Moreover, the partial inverse assignment problem is NP-complete. Both results even hold if there is only one required arc or edge, respectively. For solving partial inverse combinatorial optimization problems with only weight increases, we present a novel branch-and-bound scheme that exploits the difference in complexity between complete inverse and partial inverse versions of a problem. For both primal heuristics and node relaxations, we use auxiliary problems that are basically complete inverse problems on similar instances. Branching is done on follower variables. We test our approach on partial inverse shortest path, assignment and min cut problems, and computationally compare it to an MPCC reformulation as well as a decomposition scheme.},
  archive      = {J_JGO},
  author       = {Ley, Eva and Merkert, Maximilian},
  doi          = {10.1007/s10898-025-01529-x},
  journal      = {Journal of Global Optimization},
  month        = {9},
  number       = {1},
  pages        = {263-298},
  shortjournal = {J. Glob. Optim.},
  title        = {Solution methods for partial inverse combinatorial optimization problems in which weights can only be increased},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A first-order regularized algorithm with complexity properties for the unconstrained and the convexly constrained low order-value optimization problem. <em>JGO</em>, <em>93</em>(1), 241-261. (<a href='https://doi.org/10.1007/s10898-025-01521-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the minimization of the unconstrained low order-value function. We also consider the case in which the feasible region is given by a closed convex set, assuming that the projection operation is affordable. For both cases, we introduce regularized first-order algorithms and prove worst-case iteration and evaluation complexity results. Asymptotic convergence results are also presented. The proposed algorithm for the case of constraints given by an arbitrary closed convex set has the classical projected gradient method as a particular case. The algorithms are implemented and several numerical examples illustrate their application. From a theoretical point of view, there is no method for the low order-value problem that has a complexity analysis and for which the relation between complexity results and asymptotic results has been analyzed. From a practical point of view, one of the applications considered is the training of a neural network. In this example, it is shown that the introduced method outperforms another recently introduced method that represents the state of the art for solving low order-value problems.},
  archive      = {J_JGO},
  author       = {Álvarez, G. Q. and Birgin, E. G. and Martínez, J. M.},
  doi          = {10.1007/s10898-025-01521-5},
  journal      = {Journal of Global Optimization},
  month        = {9},
  number       = {1},
  pages        = {241-261},
  shortjournal = {J. Glob. Optim.},
  title        = {A first-order regularized algorithm with complexity properties for the unconstrained and the convexly constrained low order-value optimization problem},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal transport-based distributionally robust optimization with polynomial uncertainty. <em>JGO</em>, <em>93</em>(1), 215-240. (<a href='https://doi.org/10.1007/s10898-025-01530-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies distributionally robust optimization (DRO) problems with polynomial uncertainty where the stochastic functions are polynomials of the random variables and the ambiguity set is defined as a ball in the space of probability measures centered at the empirical probability measure. This ball is measured using the optimal transport discrepancy, which includes Wasserstein’s distances as particular cases. The DRO problem can be equivalently reformulated as a linear conic optimization problem with nonnegative polynomial cones when the objective function is affine in the decision variables. We propose a Moment-SOS hierarchy relaxations method for solving the transformed problem and prove its convergent properties. Moreover, we can also obtain the worst-case probability measure. Numerical experiments are presented to illustrate the efficiency of our proposed algorithm.},
  archive      = {J_JGO},
  author       = {Rao, Bo and Yang, Liu and Cai, Jingmin},
  doi          = {10.1007/s10898-025-01530-4},
  journal      = {Journal of Global Optimization},
  month        = {9},
  number       = {1},
  pages        = {215-240},
  shortjournal = {J. Glob. Optim.},
  title        = {Optimal transport-based distributionally robust optimization with polynomial uncertainty},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scenario consensus algorithms for solving stochastic and dynamic problems. <em>JGO</em>, <em>93</em>(1), 175-213. (<a href='https://doi.org/10.1007/s10898-025-01531-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In transportation problems and many other planning problems, there are important sources of uncertainty that must be addressed to find effective and efficient solutions. A common approach for solving these dynamic and stochastic problems is the multiple scenario approach (MSA), which has been proven effective for transportation problems, but it does not provide flexibility for finding solutions that account for all the uncertainty of the problem. Alternative approaches for solving problems with a finite number of scenarios are the progressive hedging algorithm (PHA) and the subgradient algorithm (SA). There are many similarities between PHA and SA; however, there are some differences that lead them to have very different theoretical guarantees and performance. We present a new exact algorithm, the dynamic progressive hedging algorithm (DPHA), for which we provide theoretical guarantees that help to understand both this algorithm and the PHA from a new point of view. We also propose a DPHA-based heuristic (DPHH) and show optimality guarantees for the solution obtained. Our analysis highlights the advantages and disadvantages of the DPHA, the SA, and the MSA, which gives guidance for future research in choosing the proper method for the problem in hand. In a computational study, we consider the stochastic server location problem (SSLP) and the two-stage stochastic assignment and team-orienteering problem (TSSATOP), and we show the empirical performance of the proposed algorithms.},
  archive      = {J_JGO},
  author       = {Lagos, Felipe},
  doi          = {10.1007/s10898-025-01531-3},
  journal      = {Journal of Global Optimization},
  month        = {9},
  number       = {1},
  pages        = {175-213},
  shortjournal = {J. Glob. Optim.},
  title        = {Scenario consensus algorithms for solving stochastic and dynamic problems},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A theoretical and empirical study of new adaptive algorithms with additional momentum steps and shifted updates for stochastic non-convex optimization. <em>JGO</em>, <em>93</em>(1), 113-173. (<a href='https://doi.org/10.1007/s10898-025-01518-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that adaptive optimization algorithms represent the key pillar behind the rise of the machine learning field. In the optimization literature numerous studies have been devoted to accelerated gradient methods but only recently adaptive iterative techniques were analyzed from a theoretical point of view. In the present paper we introduce new adaptive algorithms endowed with momentum terms for stochastic non-convex optimization problems. Our purpose is to show a deep connection between accelerated methods endowed with different inertial steps and AMSGrad-type momentum methods. Our methodology is based on the framework of stochastic and possibly non-convex objective mappings, along with some assumptions that are often used in the investigation of adaptive algorithms. In addition to discussing the finite-time horizon analysis in relation to a certain final iteration and the almost sure convergence to stationary points, we shall also look at the worst-case iteration complexity. This will be followed by an estimate for the expectation of the squared Euclidean norm of the gradient. Various computational simulations for the training of neural networks are being used to support the theoretical analysis. For future research we emphasize that there are multiple possible extensions to our work, from which we mention the investigation regarding non-smooth objective functions and the theoretical analysis of a more general formulation that encompasses our adaptive optimizers in a stochastic framework.},
  archive      = {J_JGO},
  author       = {Alecsa, Cristian Daniel},
  doi          = {10.1007/s10898-025-01518-0},
  journal      = {Journal of Global Optimization},
  month        = {9},
  number       = {1},
  pages        = {113-173},
  shortjournal = {J. Glob. Optim.},
  title        = {A theoretical and empirical study of new adaptive algorithms with additional momentum steps and shifted updates for stochastic non-convex optimization},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new branch-and-bound algorithm for generalized affine multiplicative programming. <em>JGO</em>, <em>93</em>(1), 87-112. (<a href='https://doi.org/10.1007/s10898-025-01519-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a type of affine multiplicative programming (AMP) problem with exponents, which is known to be NP-hard. We initially transform AMP into an equivalent problem (EP) by the logarithmic transformation and the introduction of auxiliary variables. Utilizing a piecewise linear technique, we then develop a mixed-integer linear programming (MILP) relaxation to determine a lower bound for the optimal value of EP. In addition, we propose a successive linear optimization (SLO) method that converges to a KKT point of EP, thereby tightening the upper bound to the optimum of EP. Also, a rectangular contraction rule is introduced to eliminate regions that do not contain the optimal solution of AMP. By combining the MILP relaxation, the SLO method and the rectangular contraction rule, we formulate a new branch-and-bound algorithm for solving EP. Moreover, the convergence and the maximum number of iterations for the algorithm are presented. Finally, numerical experiments are conducted to verify the effectiveness and feasibility of the constructed algorithm.},
  archive      = {J_JGO},
  author       = {Deng, Yaping and Shen, Peiping},
  doi          = {10.1007/s10898-025-01519-z},
  journal      = {Journal of Global Optimization},
  month        = {9},
  number       = {1},
  pages        = {87-112},
  shortjournal = {J. Glob. Optim.},
  title        = {A new branch-and-bound algorithm for generalized affine multiplicative programming},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the numerical solution of lasserre relaxations of unconstrained binary quadratic optimization problem. <em>JGO</em>, <em>93</em>(1), 63-85. (<a href='https://doi.org/10.1007/s10898-025-01523-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to solve linear semidefinite programs arising from higher-order Lasserre relaxations of unconstrained binary quadratic optimization problems. For this we use an interior point method with a preconditioned conjugate gradient method solving the linear systems. The preconditioner utilizes the low-rank structure of the solution of the relaxations. In order to fully exploit this, we need to re-write the moment relaxations. To treat the arising linear equality constraints we use an $$\ell _1$$ -penalty approach within the interior-point solver. The efficiency of this approach is demonstrated by numerical experiments with the MAXCUT and other randomly generated problems and a comparison with a state-of-the-art semidefinite solver and the ADMM method. We further propose a hybrid ADMM-interior-point method that proves to be efficient for certain problem classes. As a by-product, we observe that the second-order relaxation is often high enough to deliver a globally optimal solution of the original problem.},
  archive      = {J_JGO},
  author       = {Habibi, Soodeh and Kočvara, Michal and Stingl, Michael},
  doi          = {10.1007/s10898-025-01523-3},
  journal      = {Journal of Global Optimization},
  month        = {9},
  number       = {1},
  pages        = {63-85},
  shortjournal = {J. Glob. Optim.},
  title        = {On the numerical solution of lasserre relaxations of unconstrained binary quadratic optimization problem},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discretization algorithms for generalized semi-infinite programs with coupling equality constraints under local solution stability. <em>JGO</em>, <em>93</em>(1), 27-61. (<a href='https://doi.org/10.1007/s10898-025-01515-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing algorithms for generalized semi-infinite programs can only handle lower-level constraints containing equality constraints depending on upper-level variables (so-called coupling equality constraints) under limiting assumptions. More specifically, discretization-based algorithms require that the coupling equality constraints result in some lower-level variables being determined uniquely as implicit functions of the other lower-level and upper-level variables. We propose an adaptation of the discretization-based algorithm of Blankenship & Falk and demonstrate it can handle coupling equality constraints under the weaker assumption of stability of the solution set for these constraints in the sense of Lipschitz lower semi-continuity. The key idea is to allow a perturbation of the lower-level variable values from discretization points in connection with changes in the upper-level variables in the discretized upper-level problem. We enforce that these perturbed values satisfy the coupling equality constraints while remaining close to the discretization point, provided we can guarantee the stability of the solution in the sense that a nearby solution exists for small changes of the upper-level variables. We provide concrete realizations of the algorithm for three different situations: i) when knowledge about a certain Lipschitz constant is available, ii) when the coupling equality constraints are assumed to have full rank, and iii) when the coupling equality constraints are additionally linear in the lower-level variables. Numerical experiments on small test problems and a physically motivated problem related to power flow illustrate that the approach can be successfully applied to solve the challenging problems, but is currently limited in terms of scalability.},
  archive      = {J_JGO},
  author       = {Zingler, Aron and Lipow, Adrian W. and Mitsos, Alexander},
  doi          = {10.1007/s10898-025-01515-3},
  journal      = {Journal of Global Optimization},
  month        = {9},
  number       = {1},
  pages        = {27-61},
  shortjournal = {J. Glob. Optim.},
  title        = {Discretization algorithms for generalized semi-infinite programs with coupling equality constraints under local solution stability},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixed-integer bilevel optimization with nonconvex quadratic lower-level problems: Complexity and a solution method. <em>JGO</em>, <em>93</em>(1), 1-25. (<a href='https://doi.org/10.1007/s10898-025-01522-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study bilevel problems with a convex quadratic mixed-integer upper-level, integer linking variables, and a nonconvex quadratic, purely continuous lower-level problem. We prove $$\Sigma _2^p$$ -hardness of this class of problems, derive an iterative lower- and upper-bounding scheme, and show its finiteness and correctness in the sense that it computes globally optimal points or proves infeasibility of the instance. To this end, we make use of the Karush–Kuhn–Tucker conditions of the lower-level problem for the lower-bounding step, since these conditions are only necessary but not sufficient in our setting. Moreover, integer no-good cuts as well as a simple optimality cut are used to obtain finiteness of the method. Finally, we illustrate the applicability of our approach by the first large-scale numerical experiment for this class of problems in the literature.},
  archive      = {J_JGO},
  author       = {Bomze, Immanuel and Horländer, Andreas and Schmidt, Martin},
  doi          = {10.1007/s10898-025-01522-4},
  journal      = {Journal of Global Optimization},
  month        = {9},
  number       = {1},
  pages        = {1-25},
  shortjournal = {J. Glob. Optim.},
  title        = {Mixed-integer bilevel optimization with nonconvex quadratic lower-level problems: Complexity and a solution method},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An extragradient algorithm for a lifted reformulation of projected solutions for quasiequilibria. <em>JGO</em>, <em>92</em>(4), 1071-1090. (<a href='https://doi.org/10.1007/s10898-025-01508-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Projected solutions of a quasiequilibrium problem are shown to coincide with the (canonical) solutions of an auxiliary problem, that is obtained by doubling the variables and adding suitable penalty terms to the equilibrium bifunction. Unfortunately, the assumptions of existing algorithms for computing quasiequilibria are never met by this lifted reformulation due to its peculiar structure. Therefore, an ad-hoc version of the hyperplane extragradient algorithm is devised and its parameters are tuned appropriately to cope with the auxiliary problem. Finally, preliminary numerical results show the behaviour of the algorithm.},
  archive      = {J_JGO},
  author       = {Bigi, Giancarlo and Castellani, Marco and Latini, Sara},
  doi          = {10.1007/s10898-025-01508-2},
  journal      = {Journal of Global Optimization},
  month        = {8},
  number       = {4},
  pages        = {1071-1090},
  shortjournal = {J. Glob. Optim.},
  title        = {An extragradient algorithm for a lifted reformulation of projected solutions for quasiequilibria},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Properties of a generalized oriented distance function and applications to set optimization with a variable structure. <em>JGO</em>, <em>92</em>(4), 1045-1070. (<a href='https://doi.org/10.1007/s10898-025-01510-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we aim to apply an oriented distance function to investigate minimal and weak minimal solutions of set optimization with a variable structure. We investigate some properties of the oriented distance function of type sup-inf with a variable structure. Moreover, we use this function to characterize the set relation with respect to a variable structure and obtain properties of the Dini directional derivatives for set-valued mappings. By using Dini directional derivatives, necessary and sufficient optimality conditions for the solutions are established, respectively. We show the separation between two suitable sets in image space to obtain the optimality conditions for constrained set optimization and introduce a generalized Lagrangian set-valued mapping to obtain the relationship between the saddle point and the existence of a nonlinear separation. Finally, as an application, we examine medical image registration.},
  archive      = {J_JGO},
  author       = {Wang, Wenqing and Xu, Yihong},
  doi          = {10.1007/s10898-025-01510-8},
  journal      = {Journal of Global Optimization},
  month        = {8},
  number       = {4},
  pages        = {1045-1070},
  shortjournal = {J. Glob. Optim.},
  title        = {Properties of a generalized oriented distance function and applications to set optimization with a variable structure},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Existence and stability for a class of variational–hemivariational inequalities involving multivalued brezis pseudomonotone operators. <em>JGO</em>, <em>92</em>(4), 1021-1043. (<a href='https://doi.org/10.1007/s10898-025-01487-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we provide existence and stability results for a new multivalued variational-hemivariational inequality (MVHVI, for short) involving Brezis pseudomonotone operators in a reflexive Banach space. First, we use the Moreau-Yosida approximation to introduce an approximated problem corresponding to (MVHVI), and apply an existence result for nonlinear equilibrium problems, convergence techniques as well as Sion’s Minimax Theorem to prove the existence of solutions of (MVHVI). Then, a stability result for (MVHVI) is obtained via employing Tikhonov regularization and perturbed approach. The theoretical results established in this paper extend the ones in (J Glob Optim 52:743–756, 2012) and (J Glob Optim 56:605–622, 2013). Finally, we study a stationary Navier–Stokes equation with nonmonotone and multivalued constitutive laws for illustrating the validity of the main theoretical results in this paper.},
  archive      = {J_JGO},
  author       = {Zeng, Shengda and Chen, Xi and Cen, Jinxia and Winkert, Patrick},
  doi          = {10.1007/s10898-025-01487-4},
  journal      = {Journal of Global Optimization},
  month        = {8},
  number       = {4},
  pages        = {1021-1043},
  shortjournal = {J. Glob. Optim.},
  title        = {Existence and stability for a class of variational–hemivariational inequalities involving multivalued brezis pseudomonotone operators},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Covering constants for metric projection operator with applications to stochastic fixed-point problems. <em>JGO</em>, <em>92</em>(4), 993-1020. (<a href='https://doi.org/10.1007/s10898-025-01501-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of generalized differentiation in set-valued analysis is based on Mordukhovich derivative (Mordukhovich coderivative), which has been widely applied to optimization theory, equilibrium theory, variational analysis, with respect to set-valued mappings. In this paper, we use the Mordukhovich derivatives to precisely find the covering constants for metric projection onto nonempty closed and convex subsets in uniformly convex and uniformly smooth Banach spaces. This is considered as optimizing the metric projection with respect to covering values. We study three cases: closed balls in uniformly convex and uniformly smooth Banach spaces, closed and convex cylinders in lp and positive cones in Lp, for some p with 1 < p < $$\infty$$ . By Arutyunov Mordukhovich and Zhukovskiy Parameterized Coincidence Point Theorem (Theorem 3.1 in (J Optim Theory Appl 196:177–198, 2023)), which is simply called Arutyunov Mordukhovich Zhukovskiy Theorem, and as applications of covering constants obtained in this paper, we prove solvability of some locally stochastic fixed-point problems. We also provide three examples with specific solutions of both locally and globally stochastic fixed-point problems.},
  archive      = {J_JGO},
  author       = {Li, Jinlu},
  doi          = {10.1007/s10898-025-01501-9},
  journal      = {Journal of Global Optimization},
  month        = {8},
  number       = {4},
  pages        = {993-1020},
  shortjournal = {J. Glob. Optim.},
  title        = {Covering constants for metric projection operator with applications to stochastic fixed-point problems},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An exact approach for the stackelberg knapsack problem with weight selection. <em>JGO</em>, <em>92</em>(4), 973-991. (<a href='https://doi.org/10.1007/s10898-025-01488-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Stackelberg knapsack game with weight selection (SKPW) is a variation of the bilevel knapsack problem in which the leader must determine the weights of a given subset of items, and then, the follower solves the knapsack problem to maximize the profit sum. The leader’s objective is to maximize the sum of the weights of the leader’s items included in the follower’s knapsack solution. In this paper, we present an exact algorithm to solve SKPW for the first time in the literature. We establish a strict linear inequality system with an exponential number of constraints, whose feasibility can be utilized to find an optimal solution for SKPW. To address the challenge posed by the strict inequalities more effectively, we propose a linear program with exponentially many constraints. We report computational results on several randomly generated instances and compare the solutions derived from the proposed exact algorithm with those obtained using heuristic algorithms.},
  archive      = {J_JGO},
  author       = {Lee, Yeonghun and Seo, Kiho and Joung, Seulgi and Park, Sungsoo},
  doi          = {10.1007/s10898-025-01488-3},
  journal      = {Journal of Global Optimization},
  month        = {8},
  number       = {4},
  pages        = {973-991},
  shortjournal = {J. Glob. Optim.},
  title        = {An exact approach for the stackelberg knapsack problem with weight selection},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double interdiction problem on trees on the sum of root-leaf distances by upgrading edges. <em>JGO</em>, <em>92</em>(4), 951-972. (<a href='https://doi.org/10.1007/s10898-025-01490-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The double interdiction problem on trees (DIT) for the sum of root-leaf distances (SRD) has significant implications in diverse areas such as transportation networks, military strategies, and counter-terrorism efforts. It aims to maximize the SRD by upgrading edge weights subject to two constraints. One gives an upper bound for the cost of upgrades under certain norm and the other specifies a lower bound for the shortest root-leaf distance (StRD). We utilize both weighted $$l_\infty $$ norm and Hamming distance to measure the upgrade cost and denote the corresponding (DIT) problem by ( $$\hbox {DIT}_{H\infty }$$ ) and its minimum cost problem by ( $$\hbox {MCDIT}_{H\infty }$$ ). We establish the $$\mathcal{N}\mathcal{P}$$ -hardness of problem ( $$\hbox {DIT}_{H\infty }$$ ) by building a reduction from the 0–1 knapsack problem. We solve the problem ( $$\hbox {DIT}_{H\infty }$$ ) by two scenarios based on the number N of upgrade edges. When $$N=1$$ , a greedy algorithm with O(n) complexity is proposed. For the general case, an exact dynamic programming algorithm within a pseudo-polynomial time is proposed, which is established on a structure of left subtrees by maximizing a convex combination of the StRD and SRD. Furthermore, we confirm the $$\mathcal{N}\mathcal{P}$$ -hardness of problem ( $$\hbox {MCDIT}_{H\infty }$$ ) by reducing from the 0–1 knapsack problem. To tackle problem ( $$\hbox {MCDIT}_{H\infty }$$ ), a binary search algorithm with pseudo-polynomial time complexity is outlined, which iteratively solves problem ( $$\hbox {DIT}_{H\infty }$$ ). We culminate our study with numerical experiments, showcasing effectiveness of the algorithm.},
  archive      = {J_JGO},
  author       = {Li, Xiao and Guan, Xiucui and Jia, Junhua and Pardalos, Panos M.},
  doi          = {10.1007/s10898-025-01490-9},
  journal      = {Journal of Global Optimization},
  month        = {8},
  number       = {4},
  pages        = {951-972},
  shortjournal = {J. Glob. Optim.},
  title        = {Double interdiction problem on trees on the sum of root-leaf distances by upgrading edges},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weak sharp minima at infinity and solution stability in mathematical programming via asymptotic analysis. <em>JGO</em>, <em>92</em>(4), 933-950. (<a href='https://doi.org/10.1007/s10898-025-01516-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop sufficient conditions for the existence of the weak sharp minima at infinity property for nonsmooth optimization problems via asymptotic cones and generalized asymptotic functions. Next, we show that these conditions are also useful for studying the solution stability of nonconvex optimization problems under linear perturbations. Finally, we provide applications for a subclass of quasiconvex functions which is stable under linear additivity and includes the convex ones.},
  archive      = {J_JGO},
  author       = {Lara, Felipe and Van Tuyen, Nguyen and Van Nghi, Tran},
  doi          = {10.1007/s10898-025-01516-2},
  journal      = {Journal of Global Optimization},
  month        = {8},
  number       = {4},
  pages        = {933-950},
  shortjournal = {J. Glob. Optim.},
  title        = {Weak sharp minima at infinity and solution stability in mathematical programming via asymptotic analysis},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computing local minimizers in polynomial optimization under genericity conditions. <em>JGO</em>, <em>92</em>(4), 909-932. (<a href='https://doi.org/10.1007/s10898-025-01500-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on computing local minimizers of a multivariate polynomial optimization problem under certain genericity conditions. Using a technique from computer algebra and the second-order optimality condition, we provide a univariate representation for the set of local minimizers. In particular, for the unconstrained problem, i.e., the constraint set is $${{\,\mathrm{\mathbb {R}}\,}}^n$$ , the coordinates of all local minimizers can be represented by the values of n univariate polynomials at the real solutions of a univariate system containing a polynomial equation and a polynomial matrix inequality. We also develop the technique for problems with equality/inequality constraints. Based on the above technique, we design algorithms to enumerate the local minimizers and provide some experimental examples based on hybrid symbolic-numerical computations. For the case that the genericity conditions fail, at the end of the paper we propose a perturbation technique to compute approximately a global minimizer, provided that the constraint set is compact.},
  archive      = {J_JGO},
  author       = {Hieu, Vu Trung and Takeda, Akiko},
  doi          = {10.1007/s10898-025-01500-w},
  journal      = {Journal of Global Optimization},
  month        = {8},
  number       = {4},
  pages        = {909-932},
  shortjournal = {J. Glob. Optim.},
  title        = {Computing local minimizers in polynomial optimization under genericity conditions},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Addressing mixed constraints: An improved framework for black-box optimization. <em>JGO</em>, <em>92</em>(4), 889-908. (<a href='https://doi.org/10.1007/s10898-025-01486-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel hybrid Bayesian optimization framework designed to solve problems with equality, inequality constraints, and their combinations. We develop a new variant of the expected improvement acquisition function that effectively addresses constraints during iteration. This function balances exploration and exploitation within the constrained search space. Our framework adeptly manages inequality and equality constraints and can initiate the iterative process even from infeasible starting points. Finally, we evaluate our proposed framework against existing approaches using synthetic test problems and a real-world engineering design and hydrology problem. By integrating Bayesian optimization techniques with advanced constraint handling, our framework provides a promising avenue for addressing mixed constraints in black-box optimization scenarios.},
  archive      = {J_JGO},
  author       = {Chowdhury, Raju and Upadhye, Neelesh S.},
  doi          = {10.1007/s10898-025-01486-5},
  journal      = {Journal of Global Optimization},
  month        = {8},
  number       = {4},
  pages        = {889-908},
  shortjournal = {J. Glob. Optim.},
  title        = {Addressing mixed constraints: An improved framework for black-box optimization},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MUSE-BB: A decomposition algorithm for nonconvex two-stage problems using strong multisection branching. <em>JGO</em>, <em>92</em>(4), 837-888. (<a href='https://doi.org/10.1007/s10898-025-01489-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present MUSE-BB, a branch-and-bound (B&B) based decomposition algorithm for the deterministic global solution of nonconvex two-stage stochastic programming problems. In contrast to three recent decomposition algorithms, which solve this type of problem in a projected form by nesting an inner B&B in an outer B&B on the first-stage variables, we branch on all variables within a single B&B tree. This results in a higher convergence order of the lower bounding scheme, avoids repeated consideration of subdomains, inherent to the nesting of B&B searches, and enables the use of cheaper subproblems. In particular, when branching on second-stage variables, we employ a multisection variant of strong-branching, in which we simultaneously consider one candidate variable from each scenario for branching. By our decomposable lower bounding scheme, the resulting subproblems are independent and can be solved in parallel. We then use strong-branching scores to filter less promising candidate variables and only generate child nodes corresponding to a multisection involving the remaining variables by combining the appropriate subproblem results. We prove finite $$\varepsilon _f$$ -convergence, and demonstrate that the lower-bounding scheme of MUSE-BB has at least first-order convergence under the mild assumption of Lipschitz continuous functions and relaxations. MUSE-BB is implemented and made available open source, as an extension of our deterministic global solver for mixed-integer nonlinear programs, MAiNGO, with OpenMP-parallelization of the decomposable subroutines. Numerical results show that MUSE-BB requires less CPU time than solving the deterministic equivalent using the standard version of MAiNGO; moreover, the parallelized decomposition allows for further reduction in wall time.},
  archive      = {J_JGO},
  author       = {Langiu, Marco and Dahmen, Manuel and Bongartz, Dominik and Mitsos, Alexander},
  doi          = {10.1007/s10898-025-01489-2},
  journal      = {Journal of Global Optimization},
  month        = {8},
  number       = {4},
  pages        = {837-888},
  shortjournal = {J. Glob. Optim.},
  title        = {MUSE-BB: A decomposition algorithm for nonconvex two-stage problems using strong multisection branching},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A strategy to tighten the relaxation of bilinear terms towards petrochemical scheduling problem. <em>JGO</em>, <em>92</em>(3), 809-835. (<a href='https://doi.org/10.1007/s10898-025-01491-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a strategy to improve the relaxation of the normalized multiparametric disaggregation technique. By introducing additional partitions to continuous variables, a bivariate relaxation scheme, piece-wise normalized disaggregation technique (PNMDT) is developed. The proposed approach is first tested over numerical nonlinear programming examples. Based on such a strategy, a global optimization algorithm is then proposed to handle nonconvex optimization problems which involve plentiful bilinear terms. This proposed algorithm is evaluated through solving common scheduling problems in the petrochemical industry, the multi-period blending problem, and the multi-period crude oil scheduling problem. The computational results show that the proposed method can efficiently improve the quality of relaxation and speed up the convergence by reducing the required iterations within the algorithm procedure.},
  archive      = {J_JGO},
  author       = {Zhang, Lifeng and Ge, Congqin and Zhang, Yanfeng and Yang, Wenhui and Chen, Bingzhen and Yuan, Zhihong},
  doi          = {10.1007/s10898-025-01491-8},
  journal      = {Journal of Global Optimization},
  month        = {7},
  number       = {3},
  pages        = {809-835},
  shortjournal = {J. Glob. Optim.},
  title        = {A strategy to tighten the relaxation of bilinear terms towards petrochemical scheduling problem},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computing one-bit compressive sensing via zero-norm regularized DC loss model and its surrogate. <em>JGO</em>, <em>92</em>(3), 775-807. (<a href='https://doi.org/10.1007/s10898-025-01495-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-bit compressed sensing is very popular in signal processing and communications due to its low storage costs and hardware complexity, but it is challenging to recover the signal by the one-bit information. In this paper, we propose a zero-norm regularized smooth difference of convexity (DC) loss model and derive a family of equivalent nonconvex surrogates covering the MCP and SCAD ones. Compared with the existing models, the new model and its SCAD surrogate have better robustness. To apply the proximal gradient (PG) methods with extrapolation to compute their $$\tau $$ -critical points, we provide the expression of the proximal mapping of the zero-norm (resp. $$\ell _1$$ -norm) plus the indicator of unit sphere. In particular, we prove that under a mild condition, the objective functions of the proposed model and its SCAD surrogate are the KL function of exponent 0, so that the PG methods with extrapolation applied to them possess a local R-linear convergence rate and the PG methods applied to them have a finite termination. Numerical comparisons with several state-of-art methods show that in terms of the quality of solution, the proposed models are remarkably superior to the $$\ell _p$$ -norm regularized models, and are comparable even superior to those models with a sparsity constraint involving the true sparsity and the sign flip ratio as inputs.},
  archive      = {J_JGO},
  author       = {Chen, Kai and Liang, Ling and Pan, Shaohua},
  doi          = {10.1007/s10898-025-01495-4},
  journal      = {Journal of Global Optimization},
  month        = {7},
  number       = {3},
  pages        = {775-807},
  shortjournal = {J. Glob. Optim.},
  title        = {Computing one-bit compressive sensing via zero-norm regularized DC loss model and its surrogate},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual adaptive algorithm for matrix optimization with sparse group lasso regularization. <em>JGO</em>, <em>92</em>(3), 737-774. (<a href='https://doi.org/10.1007/s10898-025-01492-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix optimization has various applications in finance, statistics, and engineering, etc. In this paper, we derive the Lagrangian dual of the matrix optimization problem with sparse group lasso regularization, and develop an adaptive gradient/semismooth Newton algorithm for this dual. The algorithm adaptively switches between semismooth Newton and gradient descent iterations, relying on the decrease of the residuals or values of the dual objective function. Specifically, the algorithm starts with the gradient iteration and switches to the semismooth Newton iteration when the residual decreases to a given threshold value. If the trial step size for the semismooth Newton iteration has been shrunk several times or the residual does not decrease sufficiently, the algorithm switches back to the gradient iteration and reduces the threshold value for invoking the semismooth Newton iteration. Under some mild conditions, the global convergence of the proposed algorithm is proved. Moreover, local superlinear convergence is achieved under one of two scenarios: either when the constraint nondegeneracy condition is met, or when both the strict complementarity and the local error bound conditions are simultaneously satisfied. Some numerical results on synthetic and real data sets demonstrate the efficiency and robustness of our proposed algorithm.},
  archive      = {J_JGO},
  author       = {Yang, Jinji and Hu, Jiang and Shen, Chungen},
  doi          = {10.1007/s10898-025-01492-7},
  journal      = {Journal of Global Optimization},
  month        = {7},
  number       = {3},
  pages        = {737-774},
  shortjournal = {J. Glob. Optim.},
  title        = {A dual adaptive algorithm for matrix optimization with sparse group lasso regularization},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the convergence result of the gradient-push algorithm on directed graphs with constant stepsize. <em>JGO</em>, <em>92</em>(3), 713-736. (<a href='https://doi.org/10.1007/s10898-025-01506-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed optimization has received a lot of interest due to its wide applications in various fields. It involves multiple agents connected by a graph that optimize a total cost in a collaborative way. Often, in applications, the graph of the agents is a directed graph. The gradient-push algorithm is a fundamental algorithm for distributed optimization when the agents are connected by a directed graph. Despite its wide usage in the literature, its convergence property has not been well established for the important case where the stepsize is constant and the domain is the entire space. This work proves that the gradient-push algorithm with stepsize $$\alpha >0$$ converges exponentially fast to an $$O(\alpha )$$ -neighborhood of the optimizer if the stepsize $$\alpha $$ is less than a specific value. For the result, we assume that each cost is smooth and the total cost is strongly convex. Numerical experiments are provided to support the theoretical convergence result. We also present a numerical test showing that the gradient-push algorithm may approach a small neighborhood of the minimizer faster than the Push-DIGing algorithm which is a variant of the gradient-push algorithm which involves agents sharing their gradient information.},
  archive      = {J_JGO},
  author       = {Choi, Woocheol and Kim, Doheon and Yun, Seok-Bae},
  doi          = {10.1007/s10898-025-01506-4},
  journal      = {Journal of Global Optimization},
  month        = {7},
  number       = {3},
  pages        = {713-736},
  shortjournal = {J. Glob. Optim.},
  title        = {On the convergence result of the gradient-push algorithm on directed graphs with constant stepsize},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quasi-newton type proximal gradient method for nonconvex nonsmooth composite optimization problems. <em>JGO</em>, <em>92</em>(3), 693-711. (<a href='https://doi.org/10.1007/s10898-025-01511-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose two quasi-Newton type proximal gradient methods for a class of nonconvex nonsmooth composite optimization problems, where the objective function is the sum of a smooth nonconvex function and a strictly increasing concave differentiable function composited with a convex nonsmooth function. The first proposed method is called quasi-Newton proximal gradient (QNPG) method, where the variable metric of the proximal operator adopts a quasi-Newton update strategy. The global convergence of QNPG is established under the Kurdyka-Łojasiewicz framework. However, proximal operators with quasi-Newton matrices are not easy to compute for some practical problems. Therefore we further give a general framework for proximal gradient method. Such a framework relies on an implementable inexactness condition for the computation of the proximal operator and on a line search procedure, where the line search directions can be selected arbitrarily. We prove that the line search criterion is well defined and the convergence of subsequences. Additionally, numerical simulations on an image processing model demonstrate the feasibility and effectiveness of the proposed methods.},
  archive      = {J_JGO},
  author       = {Wang, Tanxing and Jiang, Yaning and Cai, Xingju},
  doi          = {10.1007/s10898-025-01511-7},
  journal      = {Journal of Global Optimization},
  month        = {7},
  number       = {3},
  pages        = {693-711},
  shortjournal = {J. Glob. Optim.},
  title        = {Quasi-newton type proximal gradient method for nonconvex nonsmooth composite optimization problems},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel inexact Levenberg–Marquardt method for nearly-separable nonlinear least squares. <em>JGO</em>, <em>92</em>(3), 663-691. (<a href='https://doi.org/10.1007/s10898-025-01494-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by localization problems such as cadastral maps refinements, we consider a generic Nonlinear Least Squares (NLS) problem of minimizing an aggregate squared fit across all nonlinear equations (measurements) with respect to the set of unknowns, e.g., coordinates of the unknown points’ locations. In a number of scenarios, NLS problems exhibit a nearly-separable structure: the set of measurements can be partitioned into disjoint groups (blocks), such that the unknowns that correspond to different blocks are only loosely coupled. We propose an efficient parallel method, termed Parallel Inexact Levenberg–Marquardt (PILM), to solve such generic large scale NLS problems. PILM builds upon the classical Levenberg–Marquard (LM) method, with a main novelty in that the nearly-block separable structure is leveraged in order to obtain a scalable parallel method. Therein, the problem-wide system of linear equations that needs to be solved at every LM iteration is tackled iteratively. At each (inner) iteration, the block-wise systems of linear equations are solved in parallel, while the problem-wide system is then handled via sparse, inexpensive inter-block communication. We establish strong convergence guarantees of PILM that are analogous to those of the classical LM; provide PILM implementation in a master-worker parallel computational environment; and demonstrate its efficiency on huge scale cadastral map refinement problems.},
  archive      = {J_JGO},
  author       = {Fodor, Lidija and Jakovetić, Dušan and Krejić, Nataša and Malaspina, Greta},
  doi          = {10.1007/s10898-025-01494-5},
  journal      = {Journal of Global Optimization},
  month        = {7},
  number       = {3},
  pages        = {663-691},
  shortjournal = {J. Glob. Optim.},
  title        = {Parallel inexact Levenberg–Marquardt method for nearly-separable nonlinear least squares},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Infinite-dimensional convex cones: Internal geometric structure and analytical representation. <em>JGO</em>, <em>92</em>(3), 643-662. (<a href='https://doi.org/10.1007/s10898-025-01484-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main purpose of this paper is to study an internal geometric structure of convex cones in infinite-dimensional vector spaces and to obtain an analytical description of those. We suppose that a convex cone has an elementary (one-piece) internal geometric structure if it is relatively algebraically open. It is proved that an arbitrary convex cone is the disjoint union of the partial ordered family of its relatively algebraically open convex subcones and, moreover, as an ordered set this family is an upper semilattice. We identify the structure of this upper semilattice with the internal geometric structure of the corresponding convex cone. Theorem 16 and Example 17 demonstrate that the internal geometric structure of a convex cone is related to its facial structure but in an infinite-dimensional setting these two structures may differ each other. Further, we study the internal geometric structure of conical halfspaces (convex cones whose complements also are convex cones). We show that every conical halfspace is the disjoint union of the linearly ordered family of relatively algebraically open convex subcones each of which is a conical halfspace in its linear hull. Using the internal geometric structure of conical halfspaces, each conical halfspace is associated with a linearly ordered family of linear functions, which generates in turn a real-valued function, called a step-linear one, analytically describing this conical halfspace. At last, we establish that an arbitrary asymmetric convex cone admits an analytical representation by the family of step-linear functions.},
  archive      = {J_JGO},
  author       = {Gorokhovik, Valentin V.},
  doi          = {10.1007/s10898-025-01484-7},
  journal      = {Journal of Global Optimization},
  month        = {7},
  number       = {3},
  pages        = {643-662},
  shortjournal = {J. Glob. Optim.},
  title        = {Infinite-dimensional convex cones: Internal geometric structure and analytical representation},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Out-of-sample estimation for a branch-and-bound algorithm with growing datasets. <em>JGO</em>, <em>92</em>(3), 615-642. (<a href='https://doi.org/10.1007/s10898-025-01514-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In [Sass et al., Eur. J. Oper. Res., 316 (1): 36 – 45, 2024], we proposed a branch-and-bound (B&B) algorithm with growing datasets for the deterministic global optimization of parameter estimation problems based on large datasets. Therein, we start the B&B algorithm with a reduced dataset and augment it until reaching the full dataset upon convergence. However, convergence may be slowed down by a gap between the lower bounds of the reduced and the original problem, in particular for noisy measurement data. Thus, we propose the use of out-of-sample estimation for improving the lower bounds calculated with reduced datasets. Based on this, we extend the deterministic approach and propose two heuristic approaches. The computational performance of all approaches is compared with the standard B&B algorithm as a benchmark based on real-world estimation problems from process systems engineering, biochemistry, and machine learning covering datasets with and without measurement noise. Our results indicate that the heuristic approaches can improve the final lower bounds on the optimal objective value without cutting off the global solution. Aside from this, we prove that resampling can decrease the variance of the lower bounds calculated based on random initial datasets. In our case study, resampling hardly affects the performance of the approaches which indicates that the B&B algorithm with growing datasets does not suffer from large variances.},
  archive      = {J_JGO},
  author       = {Sass, Susanne and Mitsos, Alexander and Nikolov, Nikolay I. and Tsoukalas, Angelos},
  doi          = {10.1007/s10898-025-01514-4},
  journal      = {Journal of Global Optimization},
  month        = {7},
  number       = {3},
  pages        = {615-642},
  shortjournal = {J. Glob. Optim.},
  title        = {Out-of-sample estimation for a branch-and-bound algorithm with growing datasets},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inexact bilevel stochastic gradient methods for constrained and unconstrained lower-level problems. <em>JGO</em>, <em>92</em>(3), 569-614. (<a href='https://doi.org/10.1007/s10898-025-01502-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two-level stochastic optimization formulations have become instrumental in a number of machine learning contexts such as continual learning, neural architecture search, adversarial learning, and hyperparameter tuning. Practical stochastic bilevel optimization problems become challenging in optimization or learning scenarios where the number of variables is high or there are constraints. In this paper, we introduce a bilevel stochastic gradient method for bilevel problems with nonlinear and possibly nonconvex lower-level constraints. We also present a comprehensive convergence theory that addresses both the lower-level unconstrained and constrained cases and covers all inexact calculations of the adjoint gradient (also called hypergradient), such as the inexact solution of the lower-level problem, inexact computation of the adjoint formula (due to the inexact solution of the adjoint equation or use of a truncated Neumann series), and noisy estimates of the gradients, Hessians, and Jacobians involved. To promote the use of bilevel optimization in large-scale learning, we have developed new low-rank practical bilevel stochastic gradient methods (BSG-N-FD and BSG-1) that do not require second-order derivatives and, in the lower-level unconstrained case, dismiss any matrix–vector products.},
  archive      = {J_JGO},
  author       = {Giovannelli, T. and Kent, G. D. and Vicente, L. N.},
  doi          = {10.1007/s10898-025-01502-8},
  journal      = {Journal of Global Optimization},
  month        = {7},
  number       = {3},
  pages        = {569-614},
  shortjournal = {J. Glob. Optim.},
  title        = {Inexact bilevel stochastic gradient methods for constrained and unconstrained lower-level problems},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convexifiable quadratic inequality systems: New minimax S-lemma and exact SOCPs for classes of distributionally robust optimization problems. <em>JGO</em>, <em>92</em>(3), 535-568. (<a href='https://doi.org/10.1007/s10898-025-01499-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a generalization of the powerful S-lemma, extending it to minimax quadratic functions for the first time. Notably, the convexity of the involved functions is not assumed; instead, our approach leverages the convexifiability of the associated quadratic systems. It provides various verifiable conditions to identify this convexifiability by exploiting the system’s separability. Using the new minimax S-lemma and the simultaneous diagonalization property, the paper presents exact second-order cone program reformulations for classes of distributionally robust optimization problems involving minimax quadratic functions, ensuring that they share the same optimal value and can efficiently be solved. Finally, it also provides numerical validations of our results for concrete models of insurance risk assessment, maximum revenue estimation, and option pricing under distributional uncertainty.},
  archive      = {J_JGO},
  author       = {Huang, Q. Y. and Jeyakumar, V. and Li, G. and Huyen, D. T. K.},
  doi          = {10.1007/s10898-025-01499-0},
  journal      = {Journal of Global Optimization},
  month        = {7},
  number       = {3},
  pages        = {535-568},
  shortjournal = {J. Glob. Optim.},
  title        = {Convexifiable quadratic inequality systems: New minimax S-lemma and exact SOCPs for classes of distributionally robust optimization problems},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributionally robust optimization with polynomial robust constraints. <em>JGO</em>, <em>92</em>(3), 509-534. (<a href='https://doi.org/10.1007/s10898-025-01504-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies distributionally robust optimization (DRO) with polynomial robust constraints. We give a Moment-SOS relaxation approach to solve the DRO. This reduces to solving linear conic optimization with semidefinite constraints. When the DRO problem is SOS-convex, we show that it is equivalent to the linear conic relaxation and it can be solved by the Moment-SOS algorithm. For nonconvex cases, we also give concrete conditions such that the DRO can be solved globally. Numerical experiments are given to show the efficiency of the method.},
  archive      = {J_JGO},
  author       = {Nie, Jiawang and Zhong, Suhan},
  doi          = {10.1007/s10898-025-01504-6},
  journal      = {Journal of Global Optimization},
  month        = {7},
  number       = {3},
  pages        = {509-534},
  shortjournal = {J. Glob. Optim.},
  title        = {Distributionally robust optimization with polynomial robust constraints},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An exact algorithm for disaster-resilience augmentation of planar straight-line graphs. <em>JGO</em>, <em>92</em>(2), 483-508. (<a href='https://doi.org/10.1007/s10898-024-01459-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of adding a minimum length set of edges to a geometric graph so that the resultant graph is resilient against partition from the effect of a single disaster. Disasters are modeled by discs of given maximum radius, and a disaster destroys all edges intersecting its interior. It is assumed that the input and output graphs are planar with a straight-line embedding. We provide a computationally simple characterisation of feasible input instances in terms of the convex hull of the given graph, and present a fast ILP algorithm for generating optimal solutions. We also perform a computational study which shows that our algorithm is able to solve randomly generated instances with hundreds of nodes.},
  archive      = {J_JGO},
  author       = {Westcott, Alexander and Ras, Charl},
  doi          = {10.1007/s10898-024-01459-0},
  journal      = {Journal of Global Optimization},
  month        = {6},
  number       = {2},
  pages        = {483-508},
  shortjournal = {J. Glob. Optim.},
  title        = {An exact algorithm for disaster-resilience augmentation of planar straight-line graphs},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting non-monotone regularized submodular maximization: Bi-criteria and PASS approximations. <em>JGO</em>, <em>92</em>(2), 453-481. (<a href='https://doi.org/10.1007/s10898-025-01473-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of maximizing the difference between a non-monotone submodular function and a modular function. We adopt the convention in the literature and refer to this problem as the non-monotone Regularized Submodular Maximization (RSM) problem. Since the RSM problem is inapproximable, our goal is to design algorithms which are guaranteed to provide the bi-criteria and PASS approximations. For the cardinality-constrained problem, we propose two algorithms: one is based on the maximization of a scaled objective function, and the other one is a refinement of the algorithm given in our previous paper. Our analysis shows that both algorithms have nontrivial approximation bounds. For the matroid-constrained problem, we also design an algorithm based on the scaled function technique. Although its approximation guarantee is weaker than the existing algorithms in the literature, it requires less function evaluations which makes it more practical in applications.},
  archive      = {J_JGO},
  author       = {Lu, Cheng},
  doi          = {10.1007/s10898-025-01473-w},
  journal      = {Journal of Global Optimization},
  month        = {6},
  number       = {2},
  pages        = {453-481},
  shortjournal = {J. Glob. Optim.},
  title        = {Revisiting non-monotone regularized submodular maximization: Bi-criteria and PASS approximations},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extended vertical tensor complementarity problems with finite solution sets. <em>JGO</em>, <em>92</em>(2), 431-452. (<a href='https://doi.org/10.1007/s10898-025-01471-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main propose of the present paper is to investigate the finiteness property of the solution set for the extended vertical tensor complementarity problem (EVTCP). To this end, two classes of structured tensor tuples, that is, vertical non-degenerate (VND) tensor tuples and strong vertical non-degenerate (SVND) tensor tuples , are introduced. Furthermore, the relationship and some properties about them are discussed. Based on the structured tensor tuples, the finiteness property of the solution set of EVTCP is investigated. The results obtained in this paper are extensions of those proposed by Palpandi and Sharma (J Optim Theory Appl 190:951–965, 2021) from the tensor complementarity problem (TCP) to EVTCP.},
  archive      = {J_JGO},
  author       = {Li, Xue-liu and Jiang, Yi-rong and Yang, Yuning and Tang, Guo-ji},
  doi          = {10.1007/s10898-025-01471-y},
  journal      = {Journal of Global Optimization},
  month        = {6},
  number       = {2},
  pages        = {431-452},
  shortjournal = {J. Glob. Optim.},
  title        = {Extended vertical tensor complementarity problems with finite solution sets},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability analysis of split equality and split feasibility problems. <em>JGO</em>, <em>92</em>(2), 411-429. (<a href='https://doi.org/10.1007/s10898-025-01469-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, for the first time in the literature, we study the stability of solutions of two classes of feasibility (i.e., split equality and split feasibility) problems by set-valued and variational analysis techniques. Our idea is to equivalently reformulate the feasibility problems as parametric generalized equations to which set-valued and variational analysis techniques apply. Sufficient conditions, as well as necessary conditions, for the Lipschitz-likeness of the involved solution maps are proved by exploiting special structures of the problems and by using an advanced result of B.S. Mordukhovich [J. Global Optim. 28, 347–362 (2004)]. These conditions stand on a solid interaction among all the input data by means of their dual counterparts, which are transposes of matrices and regular/limiting normal cones to sets. Several examples are presented to illustrate how the obtained results work in practice and also show that the assumption on the existence of a nonzero solution used in the necessity conditions cannot be lifted.},
  archive      = {J_JGO},
  author       = {Huong, Vu Thi and Xu, Hong-Kun and Yen, Nguyen Dong},
  doi          = {10.1007/s10898-025-01469-6},
  journal      = {Journal of Global Optimization},
  month        = {6},
  number       = {2},
  pages        = {411-429},
  shortjournal = {J. Glob. Optim.},
  title        = {Stability analysis of split equality and split feasibility problems},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global convergence of block bregman proximal iteratively reweighted algorithm with extrapolation. <em>JGO</em>, <em>92</em>(2), 381-410. (<a href='https://doi.org/10.1007/s10898-024-01451-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a Bregman proximal iteratively reweighted algorithm with extrapolation based on block coordinate update aimed at solving a class of optimization problems which is the sum of a smooth possibly nonconvex loss function and a general nonconvex regularizer with a separable structure. The proposed algorithm can be used to solve the $$\ell _p(0<p<1)$$ regularization problem by employing an update strategy of the smoothing parameter in its smooth approximation model. When the extrapolation parameter satisfies certain conditions, the global convergence and local convergence rate are obtained by using the Kurdyka–Łojasiewicz (KL) property on the objective function. Numerical experiments are given to indicate the superiority of the proposed algorithm.},
  archive      = {J_JGO},
  author       = {Zhang, Jie and Yang, Xinmin},
  doi          = {10.1007/s10898-024-01451-8},
  journal      = {Journal of Global Optimization},
  month        = {6},
  number       = {2},
  pages        = {381-410},
  shortjournal = {J. Glob. Optim.},
  title        = {Global convergence of block bregman proximal iteratively reweighted algorithm with extrapolation},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partial augmented lagrangian method for non-lipschitz mathematical programs with complementarity constraints. <em>JGO</em>, <em>92</em>(2), 345-379. (<a href='https://doi.org/10.1007/s10898-024-01454-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, mathematical programs with complementarity constraints (MPCC) and a non-Lipschitz objective function have been introduced and are now more prevalent than locally Lipschitz MPCC. This paper proposes a smoothing partial augmented Lagrangian (SPAL) method to tackle this problem. However, due to the disruption of the complementary structure’s integrity by this method, proving its convergence becomes exceptionally challenging. We have achieved global convergence of the SPAL method. Specifically, we demonstrate that the accumulation point of the sequence generated by the SPAL method can be a strongly stationary point under the Mangasarian-Fromovitz qualification (MPCC-MFQ) and the boundedness of the multiplier corresponding to the orthogonal constraint. Moreover, if the aforementioned multiplier is unbounded, the accumulation point can be a Clarke stationary point under MPCC-MFQ and a suitable assumption. Numerical experiments indicate that the SPAL method surpasses existing methods in terms of the quality of accumulation points and running times.},
  archive      = {J_JGO},
  author       = {Li, Gao-Xi and Yang, Xin-Min and Long, Xian-Jun},
  doi          = {10.1007/s10898-024-01454-5},
  journal      = {Journal of Global Optimization},
  month        = {6},
  number       = {2},
  pages        = {345-379},
  shortjournal = {J. Glob. Optim.},
  title        = {Partial augmented lagrangian method for non-lipschitz mathematical programs with complementarity constraints},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rank-one matrix completion via high-rank matrices in sum-of-squares relaxations. <em>JGO</em>, <em>92</em>(2), 321-343. (<a href='https://doi.org/10.1007/s10898-025-01478-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The standard semidefinite programming (SDP) relaxation for quadratically constrained quadratic programming (QCQP) problems generally cannot obtain an exact optimal solution. However, if the optimal solution of the SDP relaxation is of rank-1, then that of QCQP can be constructed. Cosse and Demanet (Found Comput Math 21:891–940, 2021) employed this condition for a rank-one matrix completion problem using the sum-of-squares (SOS) relaxation, which is the dual of the Lasserre’s relaxation. In this paper, we analyze the conditions under which the SOS relaxation provides an exact solution to the rank-one matrix completion problem. In particular, our focus is on obtaining the rank- $$(N-1)$$ dual variable matrix of dimension N, a condition satisfied when the coefficient matrix of the objective function in the SOS relaxation problem exhibits an arrowhead structure. We relax the assumption of the explicit chain structure in Cosse and Demanet (Found Comput Math 21:891–940, 2021), and derive a weaker condition for the SDP relaxation to yield an exact solution compared to the explicit chain structure. We also present a numerical algorithm to find the coefficient matrix with the arrowhead structure, and numerical experiments illustrate the validity of the proposed algorithm.},
  archive      = {J_JGO},
  author       = {Azuma, Godai and Kim, Sunyoung and Yamashita, Makoto},
  doi          = {10.1007/s10898-025-01478-5},
  journal      = {Journal of Global Optimization},
  month        = {6},
  number       = {2},
  pages        = {321-343},
  shortjournal = {J. Glob. Optim.},
  title        = {Rank-one matrix completion via high-rank matrices in sum-of-squares relaxations},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extending interval branch-and-bound from two to few objectives in nonlinear multiobjective optimization. <em>JGO</em>, <em>92</em>(2), 295-320. (<a href='https://doi.org/10.1007/s10898-025-01479-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear multiobjective optimization presents significant challenges, particularly when addressing problems with three or more objectives. Building on our previous work using Interval Branch and Bound (B&B) techniques for biobjective optimization, we extend these methods to handle the increased complexity of multiobjective scenarios. Interval B&B methods involve dividing the original problem into smaller subproblems and solving them recursively to achieve a desired level of accuracy. These methods offer the advantage of guaranteeing global optimality and providing rigorous bounds on solution quality. We introduce a refined representation of non-dominated regions using two sets of vectors: the non dominated feasible vectors found so far and its associated set of extreme vectors. To accurately define the feasible non-dominated region within each subspace, we adapt an “envelope constraint” from biobjective solvers. Additionally, we propose a novel method for computing the distance from a subspace to the dominated region, and enhance a peeling technique for contracting the subspace based on the dominated region and the envelope constraint. Our approach is evaluated on a set of benchmark problems, and our results show a significant improvement in solution quality and convergence speed compared to a basic approach. Specifically, our enhanced strategy achieves a 42% reduction in relative CPU time, with a remarkable average time reduction of 63% in problems with three objectives. The code of our solver can be found in our git repository ( https://github.com/INFPUCV/ibex-lib/tree/master/plugins/optim-mop ).},
  archive      = {J_JGO},
  author       = {Araya, Ignacio and Reyes, Victor and Montero, Javier},
  doi          = {10.1007/s10898-025-01479-4},
  journal      = {Journal of Global Optimization},
  month        = {6},
  number       = {2},
  pages        = {295-320},
  shortjournal = {J. Glob. Optim.},
  title        = {Extending interval branch-and-bound from two to few objectives in nonlinear multiobjective optimization},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quasiconjugate duality and optimality conditions for quasiconvex optimization. <em>JGO</em>, <em>92</em>(2), 279-293. (<a href='https://doi.org/10.1007/s10898-024-01455-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In nonlinear optimization, conjugate functions and subdifferentials play an essential role. In particular, Fenchel conjugate is the most well known conjugate function in convex optimization. In quasiconvex optimization, extra parameters for quasiconjugate functions have been introduced in order to show duality theorems, for example $$\lambda $$ -quasiconjugate and $$\lambda $$ -semiconjugate. By these extra parameters, we can show duality results that hold for general quasiconvex objective functions. On the other hand, extra parameters usually increase the complexity of dual problems. Hence, conjugate functions without extra parameters have also been investigated, for example H-quasiconjugate, R-quasiconjugate, and so on. However, there are some open problems. In this paper, we study quasiconjugate duality and optimality conditions for quasiconvex optimization without extra parameters. We investigate three types of quasiconjugate dual problems, and show sufficient conditions for strong duality. We introduce three types of quasi-subdifferentials, and study optimality conditions and characterizations of the solution set. Additionally, we give a classification of quasiconvex optimization problems in terms of quasiconjugate duality.},
  archive      = {J_JGO},
  author       = {Suzuki, Satoshi},
  doi          = {10.1007/s10898-024-01455-4},
  journal      = {Journal of Global Optimization},
  month        = {6},
  number       = {2},
  pages        = {279-293},
  shortjournal = {J. Glob. Optim.},
  title        = {Quasiconjugate duality and optimality conditions for quasiconvex optimization},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gaussian process regression over discrete probability measures: On the non-stationarity relation between euclidean and wasserstein squared exponential kernels. <em>JGO</em>, <em>92</em>(2), 253-278. (<a href='https://doi.org/10.1007/s10898-025-01463-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian Process regression is a kernel method successfully adopted in many real-life applications. Recently, there is a growing interest on extending this method to non-Euclidean input spaces, like the one considered in this paper, consisting of probability measures. Although a Positive Definite kernel can be defined by using a suitable distance—the Wasserstein distance— the common procedure for learning the Gaussian Process model can fail due to numerical issues, arising earlier and more frequently than in the case of an Euclidean input space and, as demonstrated, impossible to avoid by adding artificial noise (nugget effect) as usually done. This paper uncovers the main reason of these issues, that is a non-stationarity relation between the Wasserstein-based squared exponential kernel and its Euclidean counterpart. As a relevant result, we learn a Gaussian Process model by assuming the input space as Euclidean and then use an algebraic transformation, based on the uncovered relation, to transform it into a non-stationary and Wasserstein-based Gaussian Process model over probability measures. This algebraic transformation is simpler than log-exp maps used on data belonging to Riemannian manifolds and recently extended to consider the pseudo-Riemannian structure of an input space equipped with the Wasserstein distance.},
  archive      = {J_JGO},
  author       = {Candelieri, Antonio and Ponti, Andrea and Archetti, Francesco},
  doi          = {10.1007/s10898-025-01463-y},
  journal      = {Journal of Global Optimization},
  month        = {6},
  number       = {2},
  pages        = {253-278},
  shortjournal = {J. Glob. Optim.},
  title        = {Gaussian process regression over discrete probability measures: On the non-stationarity relation between euclidean and wasserstein squared exponential kernels},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-optimal computation of the rectilinear convex hull with arbitrary orientation of sets of segments and circles. <em>JGO</em>, <em>92</em>(1), 227-251. (<a href='https://doi.org/10.1007/s10898-025-01482-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore an extension to rectilinear convexity of the classic problem of computing the convex hull of a set of geometric objects. Namely, we solve the problem of computing the rectilinear convex hull with arbitrary orientation for a set of segments and circles. We describe efficient algorithms to compute and maintain the objects appearing on the boundary of the rectilinear convex hull of such sets, while we rotate the coordinate axes by an angle that goes from 0 to $$2\pi $$ . We first consider a set of n segments. If the segments are not necessarily disjoint, we describe an algorithm that runs in optimal $$\Theta (n\log n)$$ time and $$O(n\alpha (n))$$ space, where $$\alpha (n)$$ is the extremely slowly growing inverse of Ackermann’s function. If instead the segments form a simple polygonal chain, we describe an algorithm that improves the previous space complexity to $$\Theta (n)$$ . We then extend the techniques used in these algorithms to a set of n circles. The resulting algorithm runs in optimal $$\Theta (n\log n)$$ time and $$\Theta (n)$$ space.},
  archive      = {J_JGO},
  author       = {Alegría, Carlos and Dallant, Justin and Pérez-Lantero, Pablo and Seara, Carlos},
  doi          = {10.1007/s10898-025-01482-9},
  journal      = {Journal of Global Optimization},
  month        = {5},
  number       = {1},
  pages        = {227-251},
  shortjournal = {J. Glob. Optim.},
  title        = {Time-optimal computation of the rectilinear convex hull with arbitrary orientation of sets of segments and circles},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Support vector machines with the hard-margin loss: Optimal training via combinatorial benders’ cuts. <em>JGO</em>, <em>92</em>(1), 205-225. (<a href='https://doi.org/10.1007/s10898-025-01483-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical hinge-loss support vector machines (SVMs) model is sensitive to outlier observations due to the unboundedness of its loss function. To circumvent this issue, recent studies have focused on non-convex loss functions, such as the hard-margin loss, which associates a constant penalty to any misclassified or within-margin sample. Applying this loss function yields much-needed robustness for critical applications, but it also leads to an NP-hard model that makes training difficult: current exact optimization algorithms show limited scalability, whereas heuristics are not able to find high-quality solutions consistently. Against this background, we propose new integer programming strategies that significantly improve our ability to train the hard-margin SVM model to global optimality. We introduce an iterative sampling and decomposition approach, in which smaller subproblems are used to separate combinatorial Benders’ cuts. Those cuts, used within a branch-and-cut algorithm, permit our solution framework to converge much more quickly toward a global optimum. Through extensive numerical analyses on classical benchmark data sets, our solution algorithm solves, for the first time, 117 new data sets out of 873 to optimality and achieves a reduction of 50% in the average optimality gap for the hardest datasets of the benchmark.},
  archive      = {J_JGO},
  author       = {Santana, Ítalo and Serrano, Breno and Schiffer, Maximilian and Vidal, Thibaut},
  doi          = {10.1007/s10898-025-01483-8},
  journal      = {Journal of Global Optimization},
  month        = {5},
  number       = {1},
  pages        = {205-225},
  shortjournal = {J. Glob. Optim.},
  title        = {Support vector machines with the hard-margin loss: Optimal training via combinatorial benders’ cuts},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A refined proximal algorithm for nonconvex multiobjective optimization in hilbert spaces. <em>JGO</em>, <em>92</em>(1), 187-203. (<a href='https://doi.org/10.1007/s10898-024-01453-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to general nonconvex problems of multiobjective optimization in Hilbert spaces. Based on limiting/Mordukhovich subgradients, we define a new notion of Pareto critical points for such problems, establish necessary optimality conditions for them, and then employ these conditions to develop a refined version of the vectorial proximal point algorithm providing its detailed convergence analysis. The obtained results largely extend those initiated by Bonnel et al. [SIAM J Optim, 15 (2005), pp. 953–970] for convex vector optimization problems, specifically in the case where the codomain is an m-dimensional space and by Bento et al. [SIAM J Optim, 28 (2018), pp. 1104-1120] for nonconvex finite-dimensional problems in terms of Clarke’s generalized gradients.},
  archive      = {J_JGO},
  author       = {Bento, G. C. and Cruz Neto, J. X. and Lopes, J. O. and Mordukhovich, B. S. and Silva Filho, P. R.},
  doi          = {10.1007/s10898-024-01453-6},
  journal      = {Journal of Global Optimization},
  month        = {5},
  number       = {1},
  pages        = {187-203},
  shortjournal = {J. Glob. Optim.},
  title        = {A refined proximal algorithm for nonconvex multiobjective optimization in hilbert spaces},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using dual relaxations in multiobjective mixed-integer convex quadratic programming. <em>JGO</em>, <em>92</em>(1), 159-186. (<a href='https://doi.org/10.1007/s10898-024-01440-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a branch-and-bound method for multiobjective mixed-integer convex quadratic programs that computes a superset of efficient integer assignments and a coverage of the nondominated set. The method relies on outer approximations of the upper image set of continuous relaxations. These outer approximations are obtained addressing the dual formulations of specific subproblems where the values of certain integer variables are fixed. The devised pruning conditions and a tailored preprocessing phase allow a fast enumeration of the nodes. Despite we do not require any boundedness of the feasible set, we are able to prove that the method stops after having explored a finite number of nodes. Numerical experiments on a broad set of instances with two, three, and four objectives are presented.},
  archive      = {J_JGO},
  author       = {De Santis, Marianna and Eichfelder, Gabriele and Patria, Daniele and Warnow, Leo},
  doi          = {10.1007/s10898-024-01440-x},
  journal      = {Journal of Global Optimization},
  month        = {5},
  number       = {1},
  pages        = {159-186},
  shortjournal = {J. Glob. Optim.},
  title        = {Using dual relaxations in multiobjective mixed-integer convex quadratic programming},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterisation of zero duality gap for optimization problems in spaces without linear structure. <em>JGO</em>, <em>92</em>(1), 135-158. (<a href='https://doi.org/10.1007/s10898-025-01477-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove sufficient and necessary conditions ensuring zero Lagrangian duality gap for Lagrangians defined with help of general perturbation functions. This kind of Lagrangians include generalized and augmented Lagrangians. To this aim, we use the $$\Phi $$ -convexity theory and we formulate our zero duality gap conditions in terms of elementary functions $$\varphi \in \Phi $$ . The obtained results apply to optimization problems involving prox-bounded functions, DC functions, weakly convex functions and paraconvex functions as well as infinite-dimensional linear optimization problems, including Kantorovich duality which plays an important role in determining Wasserstein distance.},
  archive      = {J_JGO},
  author       = {Bednarczuk, Ewa and Syga, Monika},
  doi          = {10.1007/s10898-025-01477-6},
  journal      = {Journal of Global Optimization},
  month        = {5},
  number       = {1},
  pages        = {135-158},
  shortjournal = {J. Glob. Optim.},
  title        = {Characterisation of zero duality gap for optimization problems in spaces without linear structure},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solution existence for a class of nonsmooth robust optimization problems. <em>JGO</em>, <em>92</em>(1), 111-133. (<a href='https://doi.org/10.1007/s10898-024-01450-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main purpose of this paper is to investigate the existence of global optimal solutions for nonsmooth and nonconvex robust optimization problems. To do this, we first introduce a concept called extended tangency variety and show how a robust optimization problem can be transformed into a minimizing problem of the corresponding tangency variety. We utilize this concept together with a constraint qualification condition and the boundedness of the objective function to provide relationships among the concepts of robust properness, robust M-tamesness and robust Palais-Smale condition related to the considered problem. The obtained results are also employed to derive necessary and sufficient conditions for the existence of global optimal solutions to the underlying robust optimization problem.},
  archive      = {J_JGO},
  author       = {Hung, Nguyen Canh and Chuong, Thai Doan and Le Hoang Anh, Nguyen},
  doi          = {10.1007/s10898-024-01450-9},
  journal      = {Journal of Global Optimization},
  month        = {5},
  number       = {1},
  pages        = {111-133},
  shortjournal = {J. Glob. Optim.},
  title        = {Solution existence for a class of nonsmooth robust optimization problems},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bundle trust region algorithm based on linear subproblem. <em>JGO</em>, <em>92</em>(1), 87-109. (<a href='https://doi.org/10.1007/s10898-025-01485-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bundle algorithms are currently considered as the most efficient methods for nonsmooth optimization. In most existing bundle methods (proximal, level, and trust region versions), it is necessary to solve at least one quadratic subproblem at each iteration. In this paper, a new bundle trust region algorithm with linear programming subproblems is proposed for solving nonsmooth nonconvex optimization problems. At each iteration, a piecewise linear model is defined, and using the infinity norm and the trust region technique, a linear subproblem is generalized. The algorithm is studied from both theoretical and practical points of view. Under the locally Lipschitz assumption on the objective function, global convergence of it is verified to stationary points. In the end, some encouraging numerical results with a MATLAB implementation are also reported. Computational results show that the developed method is efficient and robust for solving nonsmooth problems.},
  archive      = {J_JGO},
  author       = {Hoseini Monjezi, Najmeh},
  doi          = {10.1007/s10898-025-01485-6},
  journal      = {Journal of Global Optimization},
  month        = {5},
  number       = {1},
  pages        = {87-109},
  shortjournal = {J. Glob. Optim.},
  title        = {Bundle trust region algorithm based on linear subproblem},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Limited memory bundle DC algorithm for sparse pairwise kernel learning. <em>JGO</em>, <em>92</em>(1), 55-85. (<a href='https://doi.org/10.1007/s10898-025-01481-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pairwise learning is a specialized form of supervised learning that focuses on predicting outcomes for pairs of objects. In this paper, we formulate the pairwise learning problem as a difference of convex (DC) optimization problem using the Kronecker product kernel, $$\ell _1$$ - and $$\ell _0$$ -regularizations, and various, possibly nonsmooth, loss functions. Our aim is to develop an efficient learning algorithm, SparsePKL, that produces accurate predictions with the desired sparsity level. In addition, we propose a novel limited memory bundle DC algorithm (LMB-DCA) for large-scale nonsmooth DC optimization and apply it as an underlying solver in the SparsePKL. The performance of the SparsePKL-algorithm is studied in seven real-world drug-target interaction data and the results are compared with those of the state-of-art methods in pairwise learning.},
  archive      = {J_JGO},
  author       = {Karmitsa, Napsu and Joki, Kaisa and Airola, Antti and Pahikkala, Tapio},
  doi          = {10.1007/s10898-025-01481-w},
  journal      = {Journal of Global Optimization},
  month        = {5},
  number       = {1},
  pages        = {55-85},
  shortjournal = {J. Glob. Optim.},
  title        = {Limited memory bundle DC algorithm for sparse pairwise kernel learning},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tightening state relaxations for global dynamic optimization using dynamic cuts. <em>JGO</em>, <em>92</em>(1), 21-54. (<a href='https://doi.org/10.1007/s10898-025-01466-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to compute tight convex and concave relaxations of the parametric solutions of ordinary differential equations (i.e., state relaxations) is essential for efficiently solving global dynamic optimization (GDO) problems using spatial branch-and-bound (B&B). The use of cutting planes derived through various techniques is often critical for obtaining tight relaxations for conventional nonlinear programs (NLPs), but has not previously been proposed for GDO (without prior approximation as an NLP). This paper considers the use of dynamic cuts to tighten state relaxations. We present new theoretical results that enable the use of refinements based on dynamic cuts within an existing state-of-the-art state relaxation method, resulting in substantially tighter relaxations. We then develop a specific numerical implementation of this theory for the case of affine cuts. Numerical experiments on two examples show that using dynamic cuts can lead to much tighter relaxations with a moderate increase in computational cost. The results show good potential for the improved accuracy to outweigh the increased cost when implemented in B&B solvers for GDO. Such an implementation, however, requires further work to develop a method for evaluating subgradients of the proposed relaxations, which is not addressed herein.},
  archive      = {J_JGO},
  author       = {Ye, Jason and Scott, Joseph K.},
  doi          = {10.1007/s10898-025-01466-9},
  journal      = {Journal of Global Optimization},
  month        = {5},
  number       = {1},
  pages        = {21-54},
  shortjournal = {J. Glob. Optim.},
  title        = {Tightening state relaxations for global dynamic optimization using dynamic cuts},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simultaneous convexification for the planar obnoxious facility location problem. <em>JGO</em>, <em>92</em>(1), 1-20. (<a href='https://doi.org/10.1007/s10898-025-01464-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonconvex quadratically constrained optimization problems are known to be difficult to solve to global optimality and constitute a very active area of research. We identify a particularly challenging such problem arising from applications in planar obnoxious facility location. Even small instances of this problem are currently beyond the capabilities of modern global optimization solvers, owing to weak convex relaxations. We address this limitation by characterizing the simultaneous convex hull of the intersection of reverse convex reduced domains inherent in these problems. We derive tighter variable bounds and optimality-based cutting planes based on this simultaneous convexification method, along with an efficient algorithm to compute them. Given an optimal solution, our approach embedded within a spatial branch-and-bound scheme is able to certify global optimality two orders of magnitude faster compared to state-of-the-art general purpose global optimization solvers also initialized to the optimal solution. Even when provided with no starting point, it is competitive with global solvers initialized to the global solution. Using our method, global optimality is certified for the first time for 24 open instances from the literature. For three of these instances, we improve upon the previously best known solutions.},
  archive      = {J_JGO},
  author       = {Kuznetsov, Anatoliy and Sahinidis, Nikolaos V.},
  doi          = {10.1007/s10898-025-01464-x},
  journal      = {Journal of Global Optimization},
  month        = {5},
  number       = {1},
  pages        = {1-20},
  shortjournal = {J. Glob. Optim.},
  title        = {Simultaneous convexification for the planar obnoxious facility location problem},
  volume       = {92},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On a tractable single-level reformulation of a multilevel model of the european entry-exit gas market with market power. <em>JGO</em>, <em>91</em>(4), 953-985. (<a href='https://doi.org/10.1007/s10898-025-01475-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a framework that allows to quantitatively analyze the interplay of the different agents involved in gas trade and transport in the context of the European entry-exit system. Previous contributions have focused on the case of perfectly competitive buyers and sellers of gas, which allows to replace the respective market equilibrium problem by a single welfare maximization problem. Our novel framework considers the mathematically more challenging case of a monopolistic and thus strategic gas seller. In this framework, the objective functions of the gas sellers and buyers cannot be aggregated into a common objective function, which is why a multilevel formulation is necessary to accurately capture the sequential nature of the decisions taken. For this setup, we derive sufficient conditions that allow for reformulating the challenging four-level model as a computationally tractable single-level reformulation. We prove the correctness of this reformulation and use it for solving several test instances to illustrate the applicability of our approach.},
  archive      = {J_JGO},
  author       = {Grimm, Veronika and Grübel, Julia and Schmidt, Martin and Schwartz, Alexandra and Wiertz, Ann-Kathrin and Zöttl, Gregor},
  doi          = {10.1007/s10898-025-01475-8},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {953-985},
  shortjournal = {J. Glob. Optim.},
  title        = {On a tractable single-level reformulation of a multilevel model of the european entry-exit gas market with market power},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic red-blue set covering: A decomposition approach. <em>JGO</em>, <em>91</em>(4), 923-951. (<a href='https://doi.org/10.1007/s10898-025-01472-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents the two-stage stochastic red-blue set covering problem (2S-SRBSC). The red-blue set covering problem (RBSC) selects a subcollection of sets to cover all the blue elements while minimizing the number of red elements covered. Although RBSC has many application areas, such as classification and fraud detection, it does not capture randomness related to set membership and color uncertainty or any sense of recourse in response to the uncertainty. This work motivates these considerations via a fraud-prevention problem mortgage lenders face in practice. 2S-SRBSC is introduced to address this. In the proposed problem, uncertainty is represented via scenarios, and the decision-maker pays for sets in the first stage and has recourse to cover blue elements in the second stage that remain uncovered post-uncertainty. Different variants of 2S-SRBSC are considered, highlighting how they can model the real-life problem mortgage lenders face. In the case of 2S-SRBSC with simple recourse, a Benders decomposition (BD) and Benders dual decomposition (BDD) are presented and implemented in a commercial branch-and-cut solver. The resulting BDD subproblems yield cuts that are significantly tighter than those BD produces. The decompositions are tested and offer improvements in terms of solution quality and time for large-scale instances relative to the extensive form. Furthermore, the BDD exhibits desirable performance for instances where the commercial solver can quickly solve the mixed-binary subproblems. This work presents the first computational experience with decomposition algorithms applied to 2S-SRBSC problems.},
  archive      = {J_JGO},
  author       = {Islip, David and Kwon, Roy H.},
  doi          = {10.1007/s10898-025-01472-x},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {923-951},
  shortjournal = {J. Glob. Optim.},
  title        = {Stochastic red-blue set covering: A decomposition approach},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained optimization in simulation: Efficient global optimization and karush-kuhn-tucker conditions. <em>JGO</em>, <em>91</em>(4), 897-922. (<a href='https://doi.org/10.1007/s10898-024-01448-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a novel methodology for solving constrained optimization problems in deterministic simulation. In these problems, the goal (or objective) output is to be minimized, subject to one or more constraints for the other outputs and for the inputs. Our methododology combines the“Karush-Kuhn-Tucker”(KKT) conditions with“efficient global optimization”(EGO).These KKT conditions are well-known first-order necessary optimality conditions in white-box mathematical optimization, but our method is the first EGO method that uses these conditions. EGO is a popular type of algorithm that is closely related to“Bayesian optimization” and“active machine learning”, as they all use Gaussian processes or Kriging to approximate the input/output behavior of black-box models. We numerically compare the performance of our KKT-EGO algorithm and two alternative EGO algorithms, in several popular examples. In some examples our algorithm converges faster to the true optimum, so our algorithm may provide a suitable alternative.},
  archive      = {J_JGO},
  author       = {Kleijnen, Jack P. C. and Angün, Ebru and van Nieuwenhuyse, Inneke and van Beers, Wim C. M.},
  doi          = {10.1007/s10898-024-01448-3},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {897-922},
  shortjournal = {J. Glob. Optim.},
  title        = {Constrained optimization in simulation: Efficient global optimization and karush-kuhn-tucker conditions},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). System architecture optimization strategies: Dealing with expensive hierarchical problems. <em>JGO</em>, <em>91</em>(4), 851-895. (<a href='https://doi.org/10.1007/s10898-024-01443-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Choosing the right system architecture for the problem at hand is challenging due to the large design space and high uncertainty in the early stage of the design process. Formulating the architecting process as an optimization problem may mitigate some of these challenges. This work investigates strategies for solving system architecture optimization (SAO) problems: expensive, black-box, hierarchical, mixed-discrete, constrained, multi-objective problems that may be subject to hidden constraints. Imputation ratio, correction ratio, correction fraction, and max rate diversity metrics are defined for characterizing hierarchical design spaces. This work considers two classes of optimization algorithms for SAO: multi-objective evolutionary algorithms such as NSGA-II, and Bayesian optimization (BO) algorithms. A new Gaussian process kernel is presented that enables modeling hierarchical categorical variables, extending previous work on modeling continuous and integer hierarchical variables. Next, a hierarchical sampling algorithm that uses design space hierarchy to group design vectors by active design variables is developed. Then, it is demonstrated that integrating more hierarchy information in the optimization algorithms yields better optimization results for BO algorithms. Several realistic single-objective and multi-objective test problems are used for investigations. Finally, the BO algorithm is applied to a jet engine architecture optimization problem. This work shows that the developed BO algorithm can effectively solve the problem with one order of magnitude less function evaluations than NSGA-II. The algorithms and problems used in this work are implemented in the open-source Python library SBArchOpt.},
  archive      = {J_JGO},
  author       = {Bussemaker, Jasper H. and Saves, Paul and Bartoli, Nathalie and Lefebvre, Thierry and Lafage, Rémi},
  doi          = {10.1007/s10898-024-01443-8},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {851-895},
  shortjournal = {J. Glob. Optim.},
  title        = {System architecture optimization strategies: Dealing with expensive hierarchical problems},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic golden ratio algorithm to non-convex stochastic mixed variational inequality problem. <em>JGO</em>, <em>91</em>(4), 829-850. (<a href='https://doi.org/10.1007/s10898-024-01445-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In [Grad and Lara, J. Optim. Theory Appl. 190(2), 565–580 (2021)], the authors proposed a golden ratio algorithm for solving the deterministic mixed variational inequality problem with prox-convex function. In this paper, we study a new class of stochastic mixed variational inequality problems with the expectation of a prox-convex stochastic function and present a stochastic golden ratio algorithm for solving the proposed problem. The convergence and the convergence rate of our algorithm are shown under some simple and necessary conditions. Finally, we present some numerical examples to illustrate the efficiency of the proposed algorithm.},
  archive      = {J_JGO},
  author       = {Wang, Shenghua and Zhu, Ziqi and Yu, Lanxiang},
  doi          = {10.1007/s10898-024-01445-6},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {829-850},
  shortjournal = {J. Glob. Optim.},
  title        = {Stochastic golden ratio algorithm to non-convex stochastic mixed variational inequality problem},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximizing the smallest eigenvalue of grounded laplacian matrix. <em>JGO</em>, <em>91</em>(4), 807-828. (<a href='https://doi.org/10.1007/s10898-025-01470-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a connected graph $$\mathcal {G}=(V,E)$$ with n nodes, m edges, and Laplacian matrix $${\varvec{ L }}$$ , a grounded Laplacian matrix $${\varvec{ L }}(S)$$ of $$\mathcal {G}$$ is a $$(n-k) \times (n-k)$$ principal submatrix of $${\varvec{ L }}$$ , obtained from $${\varvec{ L }}$$ by deleting k rows and columns corresponding to k selected nodes forming a set $$S\subseteq V$$ . The smallest eigenvalue $$\lambda (S)$$ of $${\varvec{ L }}(S)$$ plays a pivotal role in various dynamics defined on $$\mathcal {G}$$ . For example, $$\lambda (S)$$ characterizes the convergence rate of leader-follower consensus, as well as the effectiveness of a pinning scheme for the pinning control problem, with larger $$\lambda (S)$$ corresponding to smaller convergence time or better effectiveness of a pinning scheme. In this paper, we focus on the problem of optimally selecting a subset S of fixed $$k \ll n$$ nodes, in order to maximize the smallest eigenvalue $$\lambda (S)$$ of the grounded Laplacian matrix $${\varvec{ L }}(S)$$ . We show that this optimization problem is NP-hard and that the objective function is non-submodular but monotone. Due to the difficulty of obtaining the optimal solution, we first propose a naïve heuristic algorithm selecting one optimal node at each time for k iterations. Then we propose a fast heuristic scalable algorithm to solve this problem, using the derivative matrix, matrix perturbations, and Laplacian solvers as tools. Our naïve heuristic algorithm takes $$\tilde{O}(knm)$$ time, while the fast greedy heuristic has a nearly linear time complexity of $$\tilde{O}(km)$$ , where $$\tilde{O}(\cdot )$$ notation suppresses the $$\textrm{poly} (\log n)$$ factors. We also conduct numerous experiments on different networks sized up to one million nodes, demonstrating the superiority of our algorithm in terms of efficiency and effectiveness compared to baseline methods.},
  archive      = {J_JGO},
  author       = {Zhou, Xiaotian and Wang, Run and Li, Wei and Zhang, Zhongzhi},
  doi          = {10.1007/s10898-025-01470-z},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {807-828},
  shortjournal = {J. Glob. Optim.},
  title        = {Maximizing the smallest eigenvalue of grounded laplacian matrix},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximations of unbounded convex projections and unbounded convex sets. <em>JGO</em>, <em>91</em>(4), 787-805. (<a href='https://doi.org/10.1007/s10898-024-01461-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of projecting a convex set onto a subspace or, equivalently formulated, the problem of computing a set obtained by applying a linear mapping to a convex feasible set. This includes the problem of approximating convex sets by polyhedrons. The existing literature on convex projections provides methods for bounded convex sets only, in this paper we propose a method that can handle both bounded and unbounded problems. The algorithms we propose build on the ideas of inner and outer approximation. In particular, we adapt the recently proposed methods for solving unbounded convex vector optimization problems to handle also the class of projection problems.},
  archive      = {J_JGO},
  author       = {Kováčová, Gabriela and Rudloff, Birgit},
  doi          = {10.1007/s10898-024-01461-6},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {787-805},
  shortjournal = {J. Glob. Optim.},
  title        = {Approximations of unbounded convex projections and unbounded convex sets},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Applying augmented weak subdifferentials and normal cones for nonconvex mathematical programming problems. <em>JGO</em>, <em>91</em>(4), 765-786. (<a href='https://doi.org/10.1007/s10898-025-01474-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper is devoted to the study of some necessary and sufficient optimality conditions for a nonconvex extended-real-valued function having a global minimum/and a vector-valued mapping having a weakly efficient solution at a given point in terms of the augmented weak subdifferentials and the augmented normal cones in reflexive Banach spaces without any convexity assumption. By applying a special separation theorem for the nonconvex sets in reflexive Banach spaces, some necessary optimality conditions for a nonconvex (scalar/vector) function having a global minimum/and a (weakly) efficient solution concern the existence of a weakly subgradient pair are derived. Under some suitable assumptions, one of such conditions becomes the sufficient optimality condition respectively. An application of the obtained result for the nonsmooth nonconvex multiobjective mathematical programming problem having set, inequality and equality constraints is presented accordingly.},
  archive      = {J_JGO},
  author       = {Su, Tran Van and Tiep, Chu Van},
  doi          = {10.1007/s10898-025-01474-9},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {765-786},
  shortjournal = {J. Glob. Optim.},
  title        = {Applying augmented weak subdifferentials and normal cones for nonconvex mathematical programming problems},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conic relaxations for conic minimax convex polynomial programs with extensions and applications. <em>JGO</em>, <em>91</em>(4), 743-763. (<a href='https://doi.org/10.1007/s10898-025-01465-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we analyze conic minimax convex polynomial optimization problems. Under a suitable regularity condition, an exact conic programming relaxation is established based on a positivity characterization of a max function over a conic convex system. Further, we consider a general conic minimax $$\rho $$ -convex polynomial optimization problem, which is defined by appropriately extending the notion of conic convexity of a vector-valued mapping. For this problem, it is shown that a Karush-Kuhn-Tucker condition at a global minimizer is necessary and sufficient for ensuring an exact relaxation with attainment of the conic programming relaxation. The exact conic programming relaxations are applied to SOS-convex polynomial programs, where appropriate choices of the data allow the associated conic programming relaxation to be reformulated as a semidefinite programming problem. In this way, we can further elaborate the obtained results for other special settings including conic robust SOS-convex polynomial problems and difference of SOS-convex polynomial programs.},
  archive      = {J_JGO},
  author       = {Doan Chuong, Thai and Vicente-Pérez, José},
  doi          = {10.1007/s10898-025-01465-w},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {743-763},
  shortjournal = {J. Glob. Optim.},
  title        = {Conic relaxations for conic minimax convex polynomial programs with extensions and applications},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the convergence order of value function relaxations used in decomposition-based global optimization of nonconvex stochastic programs. <em>JGO</em>, <em>91</em>(4), 701-742. (<a href='https://doi.org/10.1007/s10898-024-01458-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes the convergence rate of decomposition algorithms for globally solving nonconvex stochastic programming problems. We focus on two recent algorithms, termed CZ (Cao and Zavala in J Glob Optim 75:393–416, 2019) and LG (Li and Grossmann in J Glob Optim 75:247–272, 2019), that guarantee global optimality while achieving a favorable decomposed scaling with respect to the number of scenarios. Both methods project the problem into the space of first-stage decisions and apply a spatial-B&B search in this reduced space. Consequently, we observe that they are subject to the results of prior studies on the efficiency of general spatial-B&B algorithms. Such studies have concluded that, to avoid very slow convergence due to the cluster problem, it is necessary (but not sufficient) for the B&B lower bounding problems to have a sufficiently high Hausdorff convergence order. We apply this concept to the CZ and LG decomposition algorithms by first arguing that their lower bounding procedures can be interpreted as defining relaxations in the reduced space of first-stage decisions, and then analyzing the Hausdorff convergence of these relaxations in detail. The results are found to depend strongly on the regularity of the recourse optimal value functions. The relaxations used by CZ are found to be first-order convergent or less, while second order is generally necessary to avoid clustering. In contrast, the relaxations used by LG achieve the highest order possible within the decomposition framework we consider, which is second order when the value functions are smooth, but first order or less otherwise. Unfortunately, these functions are only guaranteed to be lower semi-continuous under standard assumptions. This alludes to a larger limitation of the projection-based decomposition approach, which is discussed at length.},
  archive      = {J_JGO},
  author       = {Robertson, Dillard and Cheng, Pengfei and Scott, Joseph K.},
  doi          = {10.1007/s10898-024-01458-1},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {701-742},
  shortjournal = {J. Glob. Optim.},
  title        = {On the convergence order of value function relaxations used in decomposition-based global optimization of nonconvex stochastic programs},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence of solutions to set optimization problems with variable ordering structures. <em>JGO</em>, <em>91</em>(3), 677-699. (<a href='https://doi.org/10.1007/s10898-024-01452-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider set optimization problems with variable ordering structures. Within the framework of the set less order relation with variable ordering structures, we investigate the existence, the upper convergence, and the lower convergence of solutions to such problems in the image spaces. For both the existence and the upper convergence of solutions, we employ new techniques to obtain various results without assuming the compactness of the constraint sets. Additionally, we utilize the domination property concerning the variable ordering cones to address the lower convergence of solutions. The obtained results are presented in several versions from different aspects for convenient comparison with existing results. Many examples are provided to illustrate the novelty of our results or to compare them with existing ones in the literature.},
  archive      = {J_JGO},
  author       = {Anh, L. Q. and Hien, D. V.},
  doi          = {10.1007/s10898-024-01452-7},
  journal      = {Journal of Global Optimization},
  month        = {3},
  number       = {3},
  pages        = {677-699},
  shortjournal = {J. Glob. Optim.},
  title        = {Convergence of solutions to set optimization problems with variable ordering structures},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive nested monte carlo approach for multi-objective efficient global optimization. <em>JGO</em>, <em>91</em>(3), 647-676. (<a href='https://doi.org/10.1007/s10898-024-01442-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel algorithm, namely the adaptive nested Monte Carlo based multi-objective Efficient Global Optimization (ANMC-MOEGO), which aims to enhance efficiency and accuracy while minimizing programming complexity in contrast to traditional multi-objective Efficient Global Optimization (MOEGO). In this algorithm, the programming complexity is streamlined by employing Monte Carlo simulation for both hypervolume improvement (HVI) and expected hypervolume improvement (EHVI) calculations. Furthermore, the efficiency and accuracy of HVI and EHVI calculations are improved through the utilization of a novel technique called adaptive Monte Carlo hypercube boundaries (AMCHB), which is based on the bisection method. The algorithm is validated via a set of test functions from the open literature. The numerical results demonstrate that the ANMC-MOEGO algorithm produces solutions closer to the theoretical results, with improved distributions on the corresponding Pareto fronts compared to the algorithm without AMCHB technique. Moreover, when obtaining a better Pareto front, the proposed algorithm is found to be more time-efficient, achieving speedups of up to 22.57 times.},
  archive      = {J_JGO},
  author       = {Xu, Shengguan and Tan, Jianfeng and Zhang, Jiale and Chen, Hongquan and Gao, Yisheng},
  doi          = {10.1007/s10898-024-01442-9},
  journal      = {Journal of Global Optimization},
  month        = {3},
  number       = {3},
  pages        = {647-676},
  shortjournal = {J. Glob. Optim.},
  title        = {Adaptive nested monte carlo approach for multi-objective efficient global optimization},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inexact proximal methods for weakly convex functions. <em>JGO</em>, <em>91</em>(3), 611-646. (<a href='https://doi.org/10.1007/s10898-024-01460-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes and develops inexact proximal methods for finding stationary points of the sum of a smooth function and a nonsmooth weakly convex one, where an error is present in the calculation of the proximal mapping of the nonsmooth term. A general framework for finding zeros of a continuous mapping is derived from our previous paper on this subject to establish convergence properties of the inexact proximal point method when the smooth term is vanished and of the inexact proximal gradient method when the smooth term satisfies a descent condition. The inexact proximal point method achieves global convergence with constructive convergence rates when the Moreau envelope of the objective function satisfies the Kurdyka–Łojasiewicz (KL) property. Meanwhile, when the smooth term is twice continuously differentiable with a Lipschitz continuous gradient and a differentiable approximation of the objective function satisfies the KL property, the inexact proximal gradient method achieves the global convergence of iterates with constructive convergence rates.},
  archive      = {J_JGO},
  author       = {Khanh, Pham Duy and Mordukhovich, Boris S. and Phat, Vo Thanh and Tran, Dat Ba},
  doi          = {10.1007/s10898-024-01460-7},
  journal      = {Journal of Global Optimization},
  month        = {3},
  number       = {3},
  pages        = {611-646},
  shortjournal = {J. Glob. Optim.},
  title        = {Inexact proximal methods for weakly convex functions},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New iterative algorithms for solving split variational inclusions. <em>JGO</em>, <em>91</em>(3), 587-609. (<a href='https://doi.org/10.1007/s10898-024-01444-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study a class of split variational inclusion (SVI) and regularized split variational inclusion (RSVI) problems in real Hilbert spaces. We discuss various analytical properties of the net generated by the RSVI and establish the existence and uniqueness of the solution to the RSVI. Using analytical properties of this net and under certain assumptions on the parameters and mappings associated with the SVI, we establish the strong convergence of the sequence generated by our proposed iterative algorithm. We also deduce another iterative algorithm by taking the regularization parameters to be zero in our proposed algorithm. We establish the weak convergence of the sequence generated by our new algorithm under certain assumptions. Moreover, we discuss two special cases of the SVI, namely the split convex minimization and the split variational inequality problems, and give several numerical examples.},
  archive      = {J_JGO},
  author       = {Dey, Soumitra and Izuchukwu, Chinedu and Taiwo, Adeolu and Reich, Simeon},
  doi          = {10.1007/s10898-024-01444-7},
  journal      = {Journal of Global Optimization},
  month        = {3},
  number       = {3},
  pages        = {587-609},
  shortjournal = {J. Glob. Optim.},
  title        = {New iterative algorithms for solving split variational inclusions},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new modified halpern-type splitting algorithm for solving monotone inclusion problems in reflexive banach spaces. <em>JGO</em>, <em>91</em>(3), 559-585. (<a href='https://doi.org/10.1007/s10898-025-01467-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly introduces a new modified Halpern-type splitting algorithm for solving the monotone inclusion problem in real reflexive Banach spaces. Furthermore, the strong convergence of the sequence generated by our algorithm is proved under some mild assumptions imposed on the operators and parameters. Finally, several numerical experiments are performed, which illustrate the effectiveness of our algorithm.},
  archive      = {J_JGO},
  author       = {Chen, Lulu and Cai, Gang and Cholamjiak, Prasit and Inkrong, Papatsara},
  doi          = {10.1007/s10898-025-01467-8},
  journal      = {Journal of Global Optimization},
  month        = {3},
  number       = {3},
  pages        = {559-585},
  shortjournal = {J. Glob. Optim.},
  title        = {A new modified halpern-type splitting algorithm for solving monotone inclusion problems in reflexive banach spaces},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On generalized KKT points for the Motzkin–Straus program. <em>JGO</em>, <em>91</em>(3), 535-557. (<a href='https://doi.org/10.1007/s10898-024-01457-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 1965, T.S. Motzkin and E. G. Straus established an elegant connection between the clique number of a graph and the global maxima of a quadratic program defined on the standard simplex. Over the years, this seminal finding has inspired a number of studies aimed at characterizing the properties of the (local and global) solutions of the Motzkin–Straus program. The result has also been generalized in various ways and has served as the basis for establishing new bounds on the clique number and developing powerful clique-finding heuristics. Despite the extensive work done on the subject, apart from a few exceptions, the existing literature pays little or no attention to the Karush–Kuhn–Tucker (KKT) points of the program. In the conviction that these points might reveal interesting structural properties of the graph underlying the program, this paper tries to fill in the gap. In particular, we study the generalized KKT points of a parameterized version of the Motzkin–Straus program, which are defined via a relaxation of the usual first-order optimality conditions, and we present a number of results that shed light on the symmetries and regularities of certain substructures associated with the underlying graph. These combinatorial structures are further analyzed using barycentric coordinates, thereby providing a link to a related quadratic program that encodes local structural properties of the graph. This turns out to be particularly useful in the study of the generalized KKT points associated with a certain class of graphs that generalize the notion of a star graph. Finally, we discuss the associations between the generalized KKT points of the Motzkin–Straus program and the so-called replicator dynamics, thereby offering an alternative, dynamical-system perspective on the results presented in the paper.},
  archive      = {J_JGO},
  author       = {Beretta, Guglielmo and Torcinovich, Alessandro and Pelillo, Marcello},
  doi          = {10.1007/s10898-024-01457-2},
  journal      = {Journal of Global Optimization},
  month        = {3},
  number       = {3},
  pages        = {535-557},
  shortjournal = {J. Glob. Optim.},
  title        = {On generalized KKT points for the Motzkin–Straus program},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Iterative mix thresholding algorithm with continuation technique for mix sparse optimization and application. <em>JGO</em>, <em>91</em>(3), 511-534. (<a href='https://doi.org/10.1007/s10898-024-01441-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mix sparse structure is inherited in a wide class of practical applications, namely, the sparse structure appears as the inter-group and intra-group manners simultaneously. In this paper, we propose an iterative mix thresholding algorithm with continuation technique (IMTC) to solve the $$\ell _0$$ regularized mix sparse optimization. The significant advantage of the IMTC is that it has a closed-form expression and low storage requirement, and it is able to promote the mix sparse structure of the solution. We prove the convergence property and the linear convergence rate of the ITMC to a local minimum; moreover, we show that the ITMC approaches an approximate true mix sparse solution within a tolerance relevant to the noise level under an assumption of restricted isometry property. We also apply the mix sparse optimization to model the differential optical absorption spectroscopy analysis with the wavelength misalignment, and numerical results indicate that the IMTC can exactly and quantitatively predict the existing materials and the factual wavelength misalignment simultaneously within 0.1 s, which meets the demand of improvement of the automatic analysis software.},
  archive      = {J_JGO},
  author       = {Hu, Yaohua and Lu, Jian and Yang, Xiaoqi and Zhang, Kai},
  doi          = {10.1007/s10898-024-01441-w},
  journal      = {Journal of Global Optimization},
  month        = {3},
  number       = {3},
  pages        = {511-534},
  shortjournal = {J. Glob. Optim.},
  title        = {Iterative mix thresholding algorithm with continuation technique for mix sparse optimization and application},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complexity of linearized quadratic penalty for optimization with nonlinear equality constraints. <em>JGO</em>, <em>91</em>(3), 483-510. (<a href='https://doi.org/10.1007/s10898-024-01456-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider a nonconvex optimization problem with nonlinear equality constraints. We assume that both, the objective function and the functional constraints, are locally smooth. For solving this problem, we propose a linearized quadratic penalty method, i.e., we linearize the objective function and the functional constraints in the penalty formulation at the current iterate and add a quadratic regularization, thus yielding a subproblem that is easy to solve, and whose solution is the next iterate. Under a new adaptive regularization parameter choice, we provide convergence guarantees for the iterates of this method to an $$\epsilon $$ first-order optimal solution in $${\mathcal {O}}({\epsilon ^{-2.5}})$$ iterations. Finally, we show that when the problem data satisfy Kurdyka–Lojasiewicz property, e.g., are semialgebraic, the whole sequence generated by the proposed algorithm converges and we derive improved local convergence rates depending on the KL parameter. We validate the theory and the performance of the proposed algorithm by numerically comparing it with some existing methods from the literature.},
  archive      = {J_JGO},
  author       = {Bourkhissi, Lahcen El and Necoara, Ion},
  doi          = {10.1007/s10898-024-01456-3},
  journal      = {Journal of Global Optimization},
  month        = {3},
  number       = {3},
  pages        = {483-510},
  shortjournal = {J. Glob. Optim.},
  title        = {Complexity of linearized quadratic penalty for optimization with nonlinear equality constraints},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A branch-and-bound algorithm for parametric mixed-binary nonlinear programs. <em>JGO</em>, <em>91</em>(3), 457-481. (<a href='https://doi.org/10.1007/s10898-024-01447-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As rapid response to changes becomes more imperative, optimization under uncertainty has continued to grow in both the continuous and mixed-integer fields. We design a branch-and-bound (BB) algorithm for mixed-binary nonlinear optimization problems with parameters in general locations. At every node of the BB tree we apply a state-of-the-art algorithm we have recently developed to approximately optimize parametric programs containing objectives and constraints biconvex in the variables and parameters. Numerical results are included.},
  archive      = {J_JGO},
  author       = {Pangia, Andrew C. and Wiecek, Margaret M.},
  doi          = {10.1007/s10898-024-01447-4},
  journal      = {Journal of Global Optimization},
  month        = {3},
  number       = {3},
  pages        = {457-481},
  shortjournal = {J. Glob. Optim.},
  title        = {A branch-and-bound algorithm for parametric mixed-binary nonlinear programs},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybridizing two linear relaxation techniques in interval-based solvers. <em>JGO</em>, <em>91</em>(3), 437-456. (<a href='https://doi.org/10.1007/s10898-024-01449-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In deterministic global optimization, techniques for linear relaxation of a non-convex program are used in the lower bound calculation phase. To achieve this phase, most deterministic global optimization codes use reformulation-linearization techniques. However, there exist also two interval-based polyhedral relaxation techniques which produce reliable bounds without adding new auxiliary variables, and which can take into account mathematical operations and most transcendental functions: (i) the affine relaxation technique, used in the IBBA code, based on affine forms and affine arithmetic, and (ii) the extremal Taylor technique, used in the Ibex-Opt code, which is based on a specific interval-based Taylor form. In this paper, we describe how these two interval-based linear relaxation techniques can be hybridized. These two approaches appear to be complementary, and such a hybrid method performs well on a representative sample of constrained global optimization instances.},
  archive      = {J_JGO},
  author       = {Araya, Ignacio and Messine, Frédéric and Ninin, Jordan and Trombettoni, Gilles},
  doi          = {10.1007/s10898-024-01449-2},
  journal      = {Journal of Global Optimization},
  month        = {3},
  number       = {3},
  pages        = {437-456},
  shortjournal = {J. Glob. Optim.},
  title        = {Hybridizing two linear relaxation techniques in interval-based solvers},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the use of overlapping convex hull relaxations to solve nonconvex MINLPs. <em>JGO</em>, <em>91</em>(2), 415-436. (<a href='https://doi.org/10.1007/s10898-024-01376-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel relaxation for general nonconvex sparse MINLP problems, called overlapping convex hull relaxation (CHR). It is defined by replacing all nonlinear constraint sets by their convex hulls. If the convex hulls are disjunctive, e.g. if the MINLP is block-separable, the CHR is equivalent to the convex hull relaxation obtained by (standard) column generation (CG). The CHR can be used for computing an initial lower bound in the root node of a branch-and-bound algorithm, or for computing a start vector for a local-search-based MINLP heuristic. We describe a dynamic block and column generation (DBCG) MINLP algorithm to generate the CHR by dynamically adding aggregated blocks. The idea of adding aggregated blocks in the CHR is similar to the well-known cutting plane approach. Numerical experiments on nonconvex MINLP instances show that the duality gap can be significantly reduced with the results of CHRs. DBCG is implemented as part of the CG-MINLP framework Decogo, see https://decogo.readthedocs.io/en/latest/index.html .},
  archive      = {J_JGO},
  author       = {Wu, Ouyang and Muts, Pavlo and Nowak, Ivo and Hendrix, Eligius M. T.},
  doi          = {10.1007/s10898-024-01376-2},
  journal      = {Journal of Global Optimization},
  month        = {2},
  number       = {2},
  pages        = {415-436},
  shortjournal = {J. Glob. Optim.},
  title        = {On the use of overlapping convex hull relaxations to solve nonconvex MINLPs},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heteroscedastic bayesian optimization using generalized product of experts. <em>JGO</em>, <em>91</em>(2), 393-413. (<a href='https://doi.org/10.1007/s10898-023-01333-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real world optimization problems observations are corrupted by a heteroscedastic noise, which depends on the input location. Bayesian optimization (BO) is an efficient approach for global optimization of black-box functions, but the performance of using a Gaussian process (GP) model can degrade with changing levels of noise due to a homoscedastic noise assumption. However, a generalized product of experts (GPOE) model allows us to build independent GP experts on the subsets of observations with individual set of hyperparameters, which is flexible enough to capture the changing levels of noise. In this paper we propose a heteroscedastic Bayesian optimization algorithm by combining the GPOE model with two modifications of existing acquisition functions, which are capable of representing and penalizing heteroscedastic noise across the input space. We compare and evaluate the performance of GPOE based BO (GPOEBO) model on 6 synthetic global optimization functions corrupted with the heteroscedastic noise as well as on two real-world scientific datasets. The results show that GPOEBO is able to improve the accuracy compared to other methods.},
  archive      = {J_JGO},
  author       = {Tautvaišas, Saulius and Žilinskas, Julius},
  doi          = {10.1007/s10898-023-01333-5},
  journal      = {Journal of Global Optimization},
  month        = {2},
  number       = {2},
  pages        = {393-413},
  shortjournal = {J. Glob. Optim.},
  title        = {Heteroscedastic bayesian optimization using generalized product of experts},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On polling directions for randomized direct-search approaches: Application to beam angle optimization in intensity-modulated proton therapy. <em>JGO</em>, <em>91</em>(2), 371-392. (<a href='https://doi.org/10.1007/s10898-024-01400-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deterministic direct-search methods have been successfully used to address real-world challenging optimization problems, including the beam angle optimization (BAO) problem in radiation therapy treatment planning. BAO is a highly non-convex optimization problem typically treated as the optimization of an expensive multi-modal black-box function which results in a computationally time consuming procedure. For the recently available modalities of radiation therapy with protons (instead of photons) further efficiency in terms of computational time is required despite the success of the different strategies developed to accelerate BAO approaches. Introducing randomization into otherwise deterministic direct-search approaches has been shown to lead to excellent computational performance, particularly when considering a reduced number (as low as two) of random poll directions at each iteration. In this study several randomized direct-search strategies are tested considering different sets of polling directions. Results obtained using a prostate and a head-and-neck cancer cases confirmed the high-quality results obtained by deterministic direct-search methods. Randomized strategies using a reduced number of polling directions showed difficulties for the higher dimensional search space (head-and-neck) and, despite the excellent mean results for the prostate cancer case, outliers were observed, a result that is often ignored in the literature. While, for general global optimization problems, mean results (or obtaining the global optimum once) might be enough for assessing the performance of the randomized method, in real-world problems one should not disregard the worst-case scenario and beware of the possibility of poor results since, many times, it is only possible to run the optimization problem once. This is even more important in healthcare applications where the mean patient does not exist and the best treatment possible must be assured for every patient.},
  archive      = {J_JGO},
  author       = {Rocha, H. and Dias, J.},
  doi          = {10.1007/s10898-024-01400-5},
  journal      = {Journal of Global Optimization},
  month        = {2},
  number       = {2},
  pages        = {371-392},
  shortjournal = {J. Glob. Optim.},
  title        = {On polling directions for randomized direct-search approaches: Application to beam angle optimization in intensity-modulated proton therapy},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Node selection through upper bounding local search methods in branch & bound solvers for NCOPs. <em>JGO</em>, <em>91</em>(2), 355-369. (<a href='https://doi.org/10.1007/s10898-024-01403-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval-based branch & bound solvers are commonly used for solving Nonlinear Continuous global Optimization Problems (NCOPs). In each iteration, the solver strategically chooses and processes a node within the search tree. The node is bisected and the two generated offspring nodes are processed by filtering methods. For each of these nodes, the solver also searches for new feasible solutions in order to update the best candidate solution. The cost of this solution is used for pruning non-optimal branches of the search tree. Thus, node selection and finding new solutions, stands as pivotal aspects in the functionality of these kind of solvers. The ability to find close-to-optimal solutions early in the search process may discard extensive non-optimal search space regions, thereby effectively reducing the overall size of the search tree. In this work, we propose three novel node selection algorithms that use the feasible solutions obtained through a cost-effective iterative method. Upon updating the best candidate solution, these algorithms strategically choose the node containing this solution for subsequent processing. The newly introduced strategies have been incorporated as node selection methods in a state-of-the-art branch & bound solver, showing promising results in a set of 57 benchmark instances.},
  archive      = {J_JGO},
  author       = {Reyes, Victor and Araya, Ignacio},
  doi          = {10.1007/s10898-024-01403-2},
  journal      = {Journal of Global Optimization},
  month        = {2},
  number       = {2},
  pages        = {355-369},
  shortjournal = {J. Glob. Optim.},
  title        = {Node selection through upper bounding local search methods in branch & bound solvers for NCOPs},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global solution of quadratic problems using interval methods and convex relaxations. <em>JGO</em>, <em>91</em>(2), 331-353. (<a href='https://doi.org/10.1007/s10898-024-01370-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval branch-and-bound solvers provide reliable algorithms for handling non-convex optimization problems by ensuring the feasibility and the optimality of the computed solutions, i.e. independently from the floating-point rounding errors. Moreover, these solvers deal with a wide variety of mathematical operators. However, these solvers are not dedicated to quadratic optimization and do not exploit nonlinear convex relaxations in their framework. We present an interval branch-and-bound method that can efficiently solve quadratic optimization problems. At each node explored by the algorithm, our solver uses a quadratic convex relaxation which is as strong as a semi-definite programming relaxation, and a variable selection strategy dedicated to quadratic problems. The interval features can then propagate efficiently this information for contracting all variable domains. We also propose to make our algorithm rigorous by certifying firstly the convexity of the objective function of our relaxation, and secondly the validity of the lower bound calculated at each node. In the non-rigorous case, our experiments show significant speedups on general integer quadratic instances, and when reliability is required, our first results show that we are able to handle medium-sized instances in a reasonable running time.},
  archive      = {J_JGO},
  author       = {Elloumi, Sourour and Lambert, Amélie and Neveu, Bertrand and Trombettoni, Gilles},
  doi          = {10.1007/s10898-024-01370-8},
  journal      = {Journal of Global Optimization},
  month        = {2},
  number       = {2},
  pages        = {331-353},
  shortjournal = {J. Glob. Optim.},
  title        = {Global solution of quadratic problems using interval methods and convex relaxations},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local search versus linear programming to detect monotonicity in simplicial branch and bound. <em>JGO</em>, <em>91</em>(2), 311-330. (<a href='https://doi.org/10.1007/s10898-023-01310-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on exhaustive global optimization algorithms over a simplicial feasible set with simplicial partition sets. Bounds on the objective function value and its partial derivative are based on interval automatic differentiation over the interval hull of a simplex. A monotonicity test may be used to decide to either reject a simplicial partition set or to reduce its simplicial dimension to a relative border (at the boundary of the feasible set) facet (or face) by removing one (or more) vertices. A monotonicity test is more complicated for a simplicial sub-set than for a box, because its orientation does not coincide with the components of the gradient. However, one can focus on directional derivatives (DD). In a previous study, we focused on either basic directions, such as centroid to vertex or vertex to vertex directions, or finding the best directional derivative by solving an LP or MIP. The research question of this paper refers to using local search (LS) based sampling of directions from vertex to facet. Results show that most of the monotonic DD found by LP are also found by LS, but with much less computational cost. Notice that finding a monotone direction does not require to find the direction in which a derivative bound is the steepest.},
  archive      = {J_JGO},
  author       = {Casado, L. G. and G.-Tóth, B. and Hendrix, E. M. T. and Messine, F.},
  doi          = {10.1007/s10898-023-01310-y},
  journal      = {Journal of Global Optimization},
  month        = {2},
  number       = {2},
  pages        = {311-330},
  shortjournal = {J. Glob. Optim.},
  title        = {Local search versus linear programming to detect monotonicity in simplicial branch and bound},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global optimization of mixed-integer nonlinear programs with SCIP 8. <em>JGO</em>, <em>91</em>(2), 287-310. (<a href='https://doi.org/10.1007/s10898-023-01345-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For over 10 years, the constraint integer programming framework SCIP has been extended by capabilities for the solution of convex and nonconvex mixed-integer nonlinear programs (MINLPs). With the recently published version 8.0, these capabilities have been largely reworked and extended. This paper discusses the motivations for recent changes and provides an overview of features that are particular to MINLP solving in SCIP. Further, difficulties in benchmarking global MINLP solvers are discussed and a comparison with several state-of-the-art global MINLP solvers is provided.},
  archive      = {J_JGO},
  author       = {Bestuzheva, Ksenia and Chmiela, Antonia and Müller, Benjamin and Serrano, Felipe and Vigerske, Stefan and Wegscheider, Fabian},
  doi          = {10.1007/s10898-023-01345-1},
  journal      = {Journal of Global Optimization},
  month        = {2},
  number       = {2},
  pages        = {287-310},
  shortjournal = {J. Glob. Optim.},
  title        = {Global optimization of mixed-integer nonlinear programs with SCIP 8},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A revised monotonicity-based method for computing tight image enclosures of functions. <em>JGO</em>, <em>91</em>(2), 257-286. (<a href='https://doi.org/10.1007/s10898-024-01405-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computation of tight interval image enclosures of functions over bounded variable domains is in the heart of interval-based branch and bound optimization (and constraint satisfaction) solvers. Interval arithmetic extends arithmetic operators, such as $$+$$ , −, $$*$$ , $$\backslash $$ , $$\sin $$ , $$\cos $$ , etc., to intervals. In this way, the operators can be used directly for computing image enclosures of real functions over bounded domains (i.e., natural interval evaluations). Importantly, it is widely recognized that when a function f is monotonic w.r.t. some variable(s) in a given domain, we can compute tighter images of f on this domain than by using natural interval evaluations. This work presents a more general monotonicity-based method that may be applied even if the function is non-monotonic w.r.t. its variables. The method combines basic interval-based filtering techniques with a straightforward analysis of function derivatives. First, filtering based on partial derivatives detects sub-intervals in the domain where the function certainly increase or decrease. Then, we can determine in which subdomains within the interval the value should be maximizing (or minimizing) the function. Finally, we use the natural interval evaluation on the subdomains where f is maximized to compute an upper bound of the enclosure. We show that this method is equivalent to computing an enclosure by using the traditional method when f is monotonic. However, it may be more effective when f is not.},
  archive      = {J_JGO},
  author       = {Araya, Ignacio and Reyes, Victor},
  doi          = {10.1007/s10898-024-01405-0},
  journal      = {Journal of Global Optimization},
  month        = {2},
  number       = {2},
  pages        = {257-286},
  shortjournal = {J. Glob. Optim.},
  title        = {A revised monotonicity-based method for computing tight image enclosures of functions},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preface. <em>JGO</em>, <em>91</em>(2), 255-256. (<a href='https://doi.org/10.1007/s10898-025-01462-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JGO},
  author       = {Csendes, Tibor and G.-Tóth, Boglárka and Vinkó, Tamás},
  doi          = {10.1007/s10898-025-01462-z},
  journal      = {Journal of Global Optimization},
  month        = {2},
  number       = {2},
  pages        = {255-256},
  shortjournal = {J. Glob. Optim.},
  title        = {Preface},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inexact primal-dual active set iteration for optimal distribution control of stationary heat or cold source. <em>JGO</em>, <em>91</em>(1), 235-253. (<a href='https://doi.org/10.1007/s10898-024-01437-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on efficient numerical methods for optimal distribution control problem of stationary heat or cold source. With the application of finite element method to discretize the model problem, we aim to take advantage of the benefits of primal-dual active set method and develop an inexact iteration strategy for approximating the optimal solution. In addition to the iteration error, the discretization error accounts for the significant portion of the total error when utilizing the numerical scheme to solve the problem. From this perspective, we present the error analysis that mingles both the discretization error and iteration error together. Based on our analysis, an adequate criterion is tailored for discretization mesh sizes to terminate the iteration, and the approximate solutions can achieve the acceptable precision consistent with discretization level. Numerical experiments are performed to verify the efficiency of the proposed method.},
  archive      = {J_JGO},
  author       = {Hu, Mengdi and Song, Haiming and Wu, Jiageng and Yang, Jinda},
  doi          = {10.1007/s10898-024-01437-6},
  journal      = {Journal of Global Optimization},
  month        = {1},
  number       = {1},
  pages        = {235-253},
  shortjournal = {J. Glob. Optim.},
  title        = {Inexact primal-dual active set iteration for optimal distribution control of stationary heat or cold source},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unboundedness of the images of set-valued mappings having closed graphs: Application to vector optimization. <em>JGO</em>, <em>91</em>(1), 217-234. (<a href='https://doi.org/10.1007/s10898-024-01438-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose criteria for unboundedness of the images of set-valued mappings having closed graphs in Euclidean spaces. We focus on mappings whose domains are non-closed or whose values are connected. These criteria allow us to see structural properties of solutions in vector optimization, where solution sets can be considered as the images of solution mappings associated to specific scalarization methods. In particular, we prove that if the domain of a certain solution mapping is non-closed, then the weak Pareto solution set is unbounded. Furthermore, for a quasi-convex problem, we demonstrate two criteria to ensure that if the weak Pareto solution set is disconnected then each connected component is unbounded.},
  archive      = {J_JGO},
  author       = {Hieu, V. T. and Köbis, E. A. S. and Köbis, M. A. and Schmölling, P. H.},
  doi          = {10.1007/s10898-024-01438-5},
  journal      = {Journal of Global Optimization},
  month        = {1},
  number       = {1},
  pages        = {217-234},
  shortjournal = {J. Glob. Optim.},
  title        = {Unboundedness of the images of set-valued mappings having closed graphs: Application to vector optimization},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Existence of weak efficient solutions of set-valued optimization problems. <em>JGO</em>, <em>91</em>(1), 199-215. (<a href='https://doi.org/10.1007/s10898-024-01431-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a novel scalarization function for set-valued maps and establish several significant properties that highlight its utility. We extend the concept of regular-global-inf functions, initially studied in the context of single-valued maps, to the realm of set-valued maps. As the first main result, we derive a new Weierstrass-type theorem for set-valued maps satisfying the coercivity condition. Furthermore, utilizing tools from asymptotic analysis, we present an existence theorem for strict weakly l-efficient solutions of set optimization problems under certain non-coercive conditions. To underscore the relevance and applicability of our findings, we provide several corollaries and illustrative examples.},
  archive      = {J_JGO},
  author       = {Fakhar, Fatemeh and Hajisharifi, Hamid Reza and Soltani, Zeinab},
  doi          = {10.1007/s10898-024-01431-y},
  journal      = {Journal of Global Optimization},
  month        = {1},
  number       = {1},
  pages        = {199-215},
  shortjournal = {J. Glob. Optim.},
  title        = {Existence of weak efficient solutions of set-valued optimization problems},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pointwise expected hypervolume improvement for expensive multi-objective optimization. <em>JGO</em>, <em>91</em>(1), 171-197. (<a href='https://doi.org/10.1007/s10898-024-01436-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expected hypervolume improvement (EHVI) is a popular infill criterion used in the multi-objective efficient global optimization algorithm for solving expensive multi-objective optimization problems. However, its exact calculation is complex and time-consuming when the number of objectives is larger than three, which prohibits its usage in problems with more than three objectives. To tackle this problem, we propose a new simple and fast criterion called pointwise expected hypervolume improvement (pEHVI) in this work. In the proposed criterion, we first compute the EHVI values of the studying point by considering one non-dominated front point at a time, and then take the minimum of these EHVI values as the final measurement. The proposed pEHVI is derived in closed-form expression and has linear time complexity with respect to the number of objectives. In addition, we theoretically prove the monotonicity and convergence properties of the proposed pEHVI criterion in this work. Compared with the traditional expected hypervolume improvement, the new infill criterion is significantly faster to compute, especially when the number of objectives is larger than three. Numerical experiments show that the proposed criterion is also able to achieve competitive optimization performance compared with five state-of-the-art multi-objective efficient global optimization algorithms. This work provides a fast and efficient hypervolume-based expected improvement infill criterion for expensive multi-objective optimization.},
  archive      = {J_JGO},
  author       = {Mei, Li and Dawei, Zhan},
  doi          = {10.1007/s10898-024-01436-7},
  journal      = {Journal of Global Optimization},
  month        = {1},
  number       = {1},
  pages        = {171-197},
  shortjournal = {J. Glob. Optim.},
  title        = {Pointwise expected hypervolume improvement for expensive multi-objective optimization},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On e-monotonicity and maximality of operators in banach spaces. <em>JGO</em>, <em>91</em>(1), 155-170. (<a href='https://doi.org/10.1007/s10898-024-01435-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we extend some well known properties of monotone and maximal monotone operators to the wider class of e-monotone and maximal e-monotone operators. The main results concern local boundedness of maximal e-monotone operators, maximal 2e-monotonicity of the Clarke–Rockafellar subdifferential $$\partial ^{CR}f$$ for an e-convex function f, and the characterization of e-monotonicity of an operator T via the behaviour of its e-Fitzpatrick function outside the graph of T.},
  archive      = {J_JGO},
  author       = {Alizadeh, M. H. and Bianchi, M. and Pini, R.},
  doi          = {10.1007/s10898-024-01435-8},
  journal      = {Journal of Global Optimization},
  month        = {1},
  number       = {1},
  pages        = {155-170},
  shortjournal = {J. Glob. Optim.},
  title        = {On e-monotonicity and maximality of operators in banach spaces},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving a class of two-stage stochastic nonlinear integer programs using value functions. <em>JGO</em>, <em>91</em>(1), 129-153. (<a href='https://doi.org/10.1007/s10898-024-01433-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a level-set characterization of the value function of a class of nonlinear integer programs with finite domain. We study the theoretical properties of this characterization and show the equivalence between the set of level-set minimal vectors and a set of non-dominated right-hand side vectors. We use these properties to develop a solution approach for two-stage nonconvex integer programs with stochastic right-hand sides. The proposed approach can solve problems with pure integer variables in both stages. We demonstrate the effectiveness of the proposed approach using a nonlinear generalized assignment problem with uncertain capacity. We also conduct computational experiments using two-stage quadratically-constrained quadratic integer programs with stochastic right-hand sides. The proposed value function-based approach can solve instances whose extensive forms are among the largest stochastic quadratic integer programs solved in the literature with respect to the number of rows and variables in extensive form, and with considerably more rows.},
  archive      = {J_JGO},
  author       = {Zhang, Junlong and Özaltın, Osman Y. and Trapp, Andrew C.},
  doi          = {10.1007/s10898-024-01433-w},
  journal      = {Journal of Global Optimization},
  month        = {1},
  number       = {1},
  pages        = {129-153},
  shortjournal = {J. Glob. Optim.},
  title        = {Solving a class of two-stage stochastic nonlinear integer programs using value functions},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nested benders decomposition for a deterministic biomass feedstock logistics problem. <em>JGO</em>, <em>91</em>(1), 95-127. (<a href='https://doi.org/10.1007/s10898-024-01439-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address a biomass feedstock logistics problem to supply biomass from production fields to satellite storage locations (SSLs) and from there to bioenergy plants (BePs) and then to a biorefinery. It entails a new problem feature of routing load-out equipment sets among the SSLs to perform loading/unloading of biomass and/or its pre-processing operations. The ownership of the loading equipment is a very capital-intensive link of the ethanol production supply chain, which when loaded onto trucks and routed along the logistics chain significantly brings down the ethanol production costs. This will make ethanol a cost-competitive alternative to fossil fuels, lead to sustainable use of fossil fuels and add to the overall relevance of the bioenergy sector. In this regard, the objective of our problem is to minimize the total cost incurred due to the ownership of equipment sets, fixed setups, and land rental cost, as well as the cost of transporting biomass from the fields to the BePs and biocrude oil from the BePs to the refinery. A mixed-integer mathematical model of the problem is presented, and a nested Benders decomposition-based solution approach is developed which involves decomposing this large problem into three stages. Stage 1 deals with the selection of fields, BePs, and SSLs, and assignment of fields to the SSLs. The remaining model consists of multiple Capacitated Vehicle Routing Problems (CVRPs) that are separable over individual BePs. For each BeP, the CVRP is further decomposed into Stage 2 and Stage 3 sub-problems where the Stage 2 problem is an allocation problem that assigns SSLs to tours associated to each BeP, and the Stage 3 problem is a variant of Traveling Salesman Problem (TSP) that determines the sequence in which equipment is routed over the predesignated set of SSLs for each tour. These sub-problems are integer programs rather than linear programs. First novelty of our proposed approach is to effectively handle the integrality of variables arising due to the consideration of the routing of load-out equipment. Second is solution methodology and in the use of proposed multi-cut version of optimality cuts that capture the solution value at an integer solution for the sub-problems. These cuts aid in faster convergence and are shown to be stronger than those proposed in the literature. The applicability of the proposed methodology is demonstrated by applying it to a real-life problem that utilizes available GIS data for the catchment area of regions around Gretna and Bedford in Virginia. We then solved a set of varying problem size instances using the state-of-the-art CPLEX® Branch-and-Bound and Benders Strategy methods. The CPLEX® algorithms struggled to solve instances even 10 times smaller than the real-life problem size instances; with MIP optimality gaps ranging from 5.85% to 82.79% in the allowed time limit of 10,000 s. On the other hand, our proposed nested Benders decomposition algorithm was able to achieve faster convergence and provided optimal solutions for all the considered problem instances with an average CPU run-time of around 3,700 s. This validates the efficacy and superiority of our solution approach. Lastly, we summarize our work and point out some interesting potential future research opportunities.},
  archive      = {J_JGO},
  author       = {Singh, Sanchit and Sarin, Subhash C. and Sangha, Sandeep Singh},
  doi          = {10.1007/s10898-024-01439-4},
  journal      = {Journal of Global Optimization},
  month        = {1},
  number       = {1},
  pages        = {95-127},
  shortjournal = {J. Glob. Optim.},
  title        = {Nested benders decomposition for a deterministic biomass feedstock logistics problem},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic decomposition for risk-averse two-stage stochastic linear programs. <em>JGO</em>, <em>91</em>(1), 59-93. (<a href='https://doi.org/10.1007/s10898-024-01432-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two-stage risk-averse stochastic programming goes beyond the classical expected value framework and aims at controlling the variability of the cost associated with different outcomes based on a choice of a risk measure. In this paper, we study stochastic decomposition (SD) for solving large-scale risk-averse stochastic linear programs with deviation and quantile risk measures. Large-scale problems refer to instances involving too many outcomes to handle using a direct solver, requiring the use of sampling approaches. SD follows an internal sampling approach in which only one sample is randomly generated at each iteration of the algorithm and has been successful for the risk-neutral setting. We extend SD to the risk-averse setting and establish asymptotic convergence of the algorithm to an optimal solution if one exists. A salient feature of the SD algorithm is that the number of samples is not fixed a priori, which allows obtaining good candidate solutions using a relatively small number of samples. We derive two variations of the SD algorithm, one with a single cut (Single-Cut SD) to approximate both the expected recourse function and dispersion statistic, and the other with two separate cuts (Separate-Cut SD). We report on a computational study based on standard test instances to evaluate the empirical performance of the SD algorithms in the risk-averse setting. The study shows that both SD algorithms require a relatively small number of scenarios to converge to an optimal solution. In addition, the comparative performance of the Single-Cut and Separate-Cut SD algorithms is problem-dependent.},
  archive      = {J_JGO},
  author       = {Parab, Prasad and Ntaimo, Lewis and Pagnoncelli, Bernardo},
  doi          = {10.1007/s10898-024-01432-x},
  journal      = {Journal of Global Optimization},
  month        = {1},
  number       = {1},
  pages        = {59-93},
  shortjournal = {J. Glob. Optim.},
  title        = {Stochastic decomposition for risk-averse two-stage stochastic linear programs},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smoothing penalty approach for solving second-order cone complementarity problems. <em>JGO</em>, <em>91</em>(1), 39-58. (<a href='https://doi.org/10.1007/s10898-024-01427-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a smoothing penalty approach for solving the second-order cone complementarity problem (SOCCP). The SOCCP is approximated by a smooth nonlinear equation with penalization parameter. We show that any solution sequence of the approximating equations converges to the solution of the SOCCP under the assumption that the associated function of the SOCCP satisfies a uniform Cartesian-type property. We present a corresponding algorithm for solving the SOCCP based on this smoothing penalty approach, and we demonstrate the efficiency of our method for solving linear, nonlinear and tensor complementarity problems in the second-order cone setting.},
  archive      = {J_JGO},
  author       = {Nguyen, Chieu Thanh and Alcantara, Jan Harold and Hao, Zijun and Chen, Jein-Shan},
  doi          = {10.1007/s10898-024-01427-8},
  journal      = {Journal of Global Optimization},
  month        = {1},
  number       = {1},
  pages        = {39-58},
  shortjournal = {J. Glob. Optim.},
  title        = {Smoothing penalty approach for solving second-order cone complementarity problems},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global optimization: A machine learning approach. <em>JGO</em>, <em>91</em>(1), 1-37. (<a href='https://doi.org/10.1007/s10898-024-01434-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many approaches for addressing global optimization problems typically rely on relaxations of nonlinear constraints over specific mathematical primitives. This is restricting in applications with constraints that are implicit or consist of more general primitives. Trying to address such limitations, Bertsimas and Ozturk (2023) proposed OCTHaGOn as a way of solving very general global optimization problems by approximating the nonlinear constraints using hyperplane-based decision-trees and then using those trees to construct a unified MIO approximation of the original problem. We provide extensions to this approach, by (i) approximating the original problem using other MIO-representable ML models besides decision trees, such as gradient boosted trees, multi layer perceptrons and suport vector machines (ii) proposing adaptive sampling procedures for more accurate ML-based constraint approximations, (iii) utilizing robust optimization to account for the uncertainty of the sample-dependent training of the ML models, (iv) leveraging a family of relaxations to address the infeasibilities of the final MIO approximation. We then test the enhanced framework in 81 global optimization instances. We show improvements in solution feasibility and optimality in the majority of instances. We also compare against BARON, showing improved optimality gaps and solution times in more than 9 instances.},
  archive      = {J_JGO},
  author       = {Bertsimas, Dimitris and Margaritis, Georgios},
  doi          = {10.1007/s10898-024-01434-9},
  journal      = {Journal of Global Optimization},
  month        = {1},
  number       = {1},
  pages        = {1-37},
  shortjournal = {J. Glob. Optim.},
  title        = {Global optimization: A machine learning approach},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
