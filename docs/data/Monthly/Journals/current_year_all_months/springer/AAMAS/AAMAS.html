<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AAMAS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aamas">AAMAS - 42</h2>
<ul>
<li><details>
<summary>
(2025). The cost and complexity of minimizing envy in house allocation. <em>AAMAS</em>, <em>39</em>(2), 1-54. (<a href='https://doi.org/10.1007/s10458-025-09710-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study almost envy-freeness in house allocation, where m houses are to be allocated among n agents so that every agent receives exactly one house. An envy-free allocation need not exist, and therefore we may have to settle for relaxations. We study different aggregate measures of envy as markers of fairness. In particular, we define the amount of envy experienced by an agent a w.r.t. an allocation to be the number of agents that agent a envies under that allocation. We quantify the envy generated by an allocation using three different metrics: 1) the number of agents who are envious; 2) the maximum amount of envy experienced by any agent; and 3) the total amount of envy experienced by all agents, and look for allocations that minimize one of the three metrics. We prove a host of algorithmic and hardness results. We also suggest practical approaches for these problems via integer linear program (ILP) formulations and report the findings of our experimental evaluation of ILPs. Finally, we study the price of fairness, which quantifies the loss of welfare we must suffer due to the fairness requirements, and present tight bounds as well as algorithms that simultaneously optimize both welfare and fairness.},
  archive      = {J_AAMAS},
  author       = {Madathil, Jayakrishnan and Misra, Neeldhara and Sethia, Aditi},
  doi          = {10.1007/s10458-025-09710-y},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-54},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {The cost and complexity of minimizing envy in house allocation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Behavioral QLTL. <em>AAMAS</em>, <em>39</em>(2), 1-29. (<a href='https://doi.org/10.1007/s10458-025-09712-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces Behavioral QLTL, a “behavioral” variant of Linear Temporal Logic (ltl) with second-order quantifiers. Behavioral qltl is characterized by the fact that the functions that assign the truth value of the quantified propositions along the trace can only depend on the past. In other words, such functions must be “processes” (Abadi et al., Realizable and Unrealizable Specifications of Reactive Systems, 1989) . This gives the logic a strategic flavor that we usually associate with planning. Indeed we show that temporally extended planning in nondeterministic domains and ltl synthesis are expressed in Behavioral qltl through formulas with a simple quantification alternation. As such alternation increases, we get to forms of planning/synthesis in which contingent and conformant planning aspects get mixed. We study this logic from the computational point of view and compare it to the original qltl (with non-behavioral semantics) and simpler forms of behavioral semantics.},
  archive      = {J_AAMAS},
  author       = {De Giacomo, Giuseppe and Perelli, Giuseppe},
  doi          = {10.1007/s10458-025-09712-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-29},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Behavioral QLTL},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-stage generalized deferred acceptance mechanism: Strategyproof mechanism for handling general hereditary constraints. <em>AAMAS</em>, <em>39</em>(2), 1-25. (<a href='https://doi.org/10.1007/s10458-025-09713-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of two-sided matching has been extensively developed and applied to many real-life application domains. As the theory has been applied to increasingly diverse types of environments, researchers and practitioners have encountered various forms of distributional constraints. Arguably, the most general class of distributional constraints would be hereditary constraints; if a matching is feasible, then any matching that assigns weakly fewer students at each college is also feasible. However, under general hereditary constraints, it is shown that no strategyproof mechanism exists that simultaneously satisfies fairness and weak nonwastefulness, which is an efficiency (students’ welfare) requirement weaker than nonwastefulness. We propose a new strategyproof mechanism that works for hereditary constraints called the Multi-Stage Generalized Deferred Acceptance mechanism (MS-GDA). It uses the Generalized Deferred Acceptance mechanism (GDA) as a subroutine, which works when distributional constraints belong to a well-behaved class called hereditary M $$^{\natural }$$ -convex set. We show that GDA satisfies several desirable properties, most of which are also preserved in MS-GDA. We experimentally show that MS-GDA strikes a good balance between fairness and efficiency (students’ welfare) compared to existing strategyproof mechanisms when distributional constraints are close to an M $$^{\natural }$$ -convex set*.},
  archive      = {J_AAMAS},
  author       = {Kimura, Kei and Liu, Kweiguu and Sun, Zhaohong and Yahiro, Kentaro and Yokoo, Makoto},
  doi          = {10.1007/s10458-025-09713-9},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-25},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Multi-stage generalized deferred acceptance mechanism: Strategyproof mechanism for handling general hereditary constraints},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hedonic seat arrangement problems. <em>AAMAS</em>, <em>39</em>(2), 1-31. (<a href='https://doi.org/10.1007/s10458-025-09711-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a variant of hedonic games, called Seat Arrangement. The model is defined by a bijection from agents with preferences for each other to vertices in a graph G. The utility of an agent depends on the neighbors assigned in the graph. More precisely, it is the sum over all neighbors of the preferences that the agent has towards the agent assigned to the neighbor. We first consider the price of stability and fairness for different classes of preferences. In particular, we show that there is an instance such that the price of fairness (PoF) is unbounded in general. Moreover, we show an upper bound $$\tilde{d}(G)$$ and an almost tight lower bound $$\tilde{d}(G)-1/4$$ of PoF, where $$\tilde{d}(G)$$ is the average degree of an input graph. Then we investigate the computational complexity of problems to find certain “good” seat arrangements, say Utilitarian Arrangement, Egalitarian Arrangement, Stable Arrangement, and Envy-free Arrangement. We give dichotomies of computational complexity of four Seat Arrangement problems from the perspective of the maximum order of connected components in an input graph. For the parameterized complexity, Utilitarian Arrangement can be solved in time $$n^{O(\gamma )}$$ , while it cannot be solved in time $$f(\gamma )n^{o(\gamma )}$$ under ETH, where n is the number of agents and $$\gamma$$ is the vertex cover number of an input graph. Moreover, we show that Egalitarian Arrangement and Envy-free Arrangement are weakly NP-hard even on graphs of bounded vertex cover number. Finally, we prove that determining whether a stable arrangement can be obtained from a given arrangement by k swaps is W[1]-hard when parameterized by $$k+\gamma$$ , whereas it can be solved in time $$n^{O(k)}$$ .},
  archive      = {J_AAMAS},
  author       = {Bodlaender, Hans L. and Hanaka, Tesshu and Jaffke, Lars and Ono, Hirotaka and Otachi, Yota and van der Zanden, Tom C.},
  doi          = {10.1007/s10458-025-09711-x},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-31},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Hedonic seat arrangement problems},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diversity-seeking jump games in networks. <em>AAMAS</em>, <em>39</em>(2), 1-37. (<a href='https://doi.org/10.1007/s10458-025-09714-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, strategic games inspired by Schelling’s influential model of residential segregation have been studied in the TCS and AI literature. In these games, agents of k different types occupy the nodes of a network topology aiming to maximize their utility, which is a function of the fraction of same-type agents they are adjacent to in the network. As such, the agents exhibit similarity-seeking strategic behavior. In this paper, we introduce a class of strategic jump games in which the agents are diversity-seeking: The utility of an agent is defined as the fraction of its neighbors that are of different type than itself. We show that in general it is computationally hard to determine the existence of an equilibrium in such games. However, when the network is a tree, diversity-seeking jump games always admit an equilibrium assignment. For regular graphs and spider graphs with a single empty node, we prove a stronger result: The game is potential, that is, the improving response dynamics always converge to an equilibrium from any initial placement of the agents. We also show (nearly tight) bounds on the price of anarchy and price of stability in terms of the social welfare (the total utility of the agents).},
  archive      = {J_AAMAS},
  author       = {Narayanan, Lata and Sabbagh, Yasaman and Voudouris, Alexandros A.},
  doi          = {10.1007/s10458-025-09714-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-37},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Diversity-seeking jump games in networks},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coordinating monetary contributions in participatory budgeting. <em>AAMAS</em>, <em>39</em>(2), 1-30. (<a href='https://doi.org/10.1007/s10458-025-09715-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We formalize a framework for coordinating funding and selecting projects, the costs of which are shared among agents with quasi-linear utility functions and individual budgets. Our model contains the discrete participatory budgeting model as a special case, while capturing other useful scenarios. We propose several important axioms and objectives and study how well they can be simultaneously satisfied. We show that whereas welfare maximization admits an FPTAS, welfare maximization subject to a natural and very weak participation requirement leads to a strong inapproximability. This result is bypassed if we consider some natural restricted valuations, namely laminar single-minded valuations and symmetric valuations. Our analysis for the former restriction leads to the discovery of a new class of tractable instances for the Set Union Knapsack problem, a classical problem in combinatorial optimization.},
  archive      = {J_AAMAS},
  author       = {Aziz, Haris and Gujar, Sujit and Padala, Manisha and Suzuki, Mashbat and Vollen, Jeremy},
  doi          = {10.1007/s10458-025-09715-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-30},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Coordinating monetary contributions in participatory budgeting},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). POSGGym: A library for decision-theoretic planning and learning in partially observable, multi-agent environments. <em>AAMAS</em>, <em>39</em>(2), 1-45. (<a href='https://doi.org/10.1007/s10458-025-09716-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seamless integration of Planning Under Uncertainty and Reinforcement Learning (RL) promises to bring the best of both model-driven and data-driven worlds to multi-agent decision-making, resulting in an approach with assurances on performance that scales well to more complex problems. Despite this potential, progress in developing such methods has been hindered by the lack of adequate evaluation and simulation platforms. Researchers have had to rely on creating custom environments, which reduces efficiency and makes comparing new methods difficult. In this paper, we introduce POSGGym : a library for facilitating planning and RL research in partially observable, multi-agent domains. It provides a diverse collection of discrete and continuous environments, complete with their dynamics models and a reference set of policies that can be used to evaluate generalization to novel co-players. Leveraging POSGGym, we empirically investigate existing state-of-the-art planning methods and a method that combines planning and RL in the type-based reasoning setting. Our experiments corroborate that combining planning and RL can yield superior performance compared to planning or RL alone, given the model of the environment and other agents is correct. However, our particular setup also reveals that this integrated approach could result in worse performance when the model of other agents is incorrect. Our findings indicate the benefit of integrating planning and RL in partially observable, multi-agent domains, while serving to highlight several important directions for future research. Code available at: https://github.com/RDLLab/posggym .},
  archive      = {J_AAMAS},
  author       = {Schwartz, Jonathon and Newbury, Rhys and Kulić, Dana and Kurniawati, Hanna},
  doi          = {10.1007/s10458-025-09716-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-45},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {POSGGym: A library for decision-theoretic planning and learning in partially observable, multi-agent environments},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing node selection in search based multi-agent path finding. <em>AAMAS</em>, <em>39</em>(2), 1-24. (<a href='https://doi.org/10.1007/s10458-025-09719-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Multi-Agent Path Finding (MAPF) problem involves the task of finding paths for multiple agents that want to reach their destinations without obstructing other agents. Although MAPF is essential for numerous real-world applications, finding an optimal solution to this problem is NP-hard. Many approaches have been proposed in the literature, offering sub-optimal solutions to improve runtime efficiency. Lazy Constraints Addition search for MAPF (LaCAM) is a state-of-the-art sub-optimal MAPF algorithm that employs tree-based lazy successor generation to minimize planning effort. However, the success of the algorithm heavily relies on the effective selection of nodes for expansion. LaCAM employs a fixed heuristic throughout the entire search process, disregarding the agents’ preferences or characteristics of the underlying environment. Nevertheless, experiments with various heuristics indicate that no single heuristic consistently outperforms others across all scenarios. Consequently, in diverse environments, as the number of agents increases, reliance on a single, general heuristic leads to diminished runtime performance. Against this backdrop, with the intent to further speed up the runtime, we propose a novel approach, called eLaCAM, that adaptively selects nodes during the search process considering the current scenario of the environment and agents preferences. We introduce two distinct variants of eLaCAM. The first, eLaCAM-stat, statistically analyses previous results of using different heuristics and selects nodes accordingly. The second variant, eLaCAM-ML, analyze the environment by extracting necessary features to guide a machine learning framework in assisting adaptive node selection during the search process. Our extensive empirical results illustrate a notable improvement in runtime and a reduction in the search space compared to state-of-the-art MAPF algorithms.},
  archive      = {J_AAMAS},
  author       = {Alam, Md. Ahasanul and Mahmud, Shekhar and Mamun-or-Rashid, Md. and Khan, Md. Mosaddek},
  doi          = {10.1007/s10458-025-09719-3},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-24},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Optimizing node selection in search based multi-agent path finding},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information elicitation mechanisms for bayesian auctions. <em>AAMAS</em>, <em>39</em>(2), 1-45. (<a href='https://doi.org/10.1007/s10458-025-09718-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we design information elicitation mechanisms for Bayesian auctions. While in Bayesian mechanism design the distributions of the players’ private types are often assumed to be common knowledge, information elicitation considers the situation where the players know the distributions better than the decision maker. To weaken the information assumption in Bayesian auctions, we consider an information structure where the knowledge about the distributions is arbitrarily scattered among the players. In such an unstructured information setting, we design mechanisms for unit-demand auctions and additive auctions that aggregate the players’ knowledge, generating revenue that are constant approximations to the optimal Bayesian mechanisms with a common prior. Our mechanisms are 2-step dominant-strategy truthful and the approximation ratios improve gracefully with the amount of knowledge the players collectively have.},
  archive      = {J_AAMAS},
  author       = {Chen, Jing and Li, Bo and Li, Yingkai},
  doi          = {10.1007/s10458-025-09718-4},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-45},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Information elicitation mechanisms for bayesian auctions},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Designing policies for transition-independent multiagent systems that are robust to communication loss. <em>AAMAS</em>, <em>39</em>(2), 1-49. (<a href='https://doi.org/10.1007/s10458-025-09721-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a cooperative multiagent system, a collection of agents executes a joint policy in order to achieve some common objective. The successful deployment of such systems hinges on the availability of reliable inter-agent communication. However, many sources of potential disruption to communication exist in practice, such as radio interference, hardware failure, and adversarial attacks. In this work, we develop joint policies for cooperative multiagent systems that are robust to potential losses in communication. More specifically, we develop joint policies for cooperative Markov games with independent transitions and joint reach-avoid objectives. First, we propose an algorithm for the decentralized execution of joint policies during periods of communication loss. This algorithm is designed to work under arbitrary communication partitions between the agents. Next, we use the total correlation of the state-action process induced by a joint policy as a measure of the intrinsic dependencies between the agents. We then use this measure to lower-bound the performance of a joint policy under randomly intermittent or adversarial communication loss scenarios. We show the existence of a multiagent decision-making environment in which this bound is tight—the highest performance under intermittent communication loss, for any policy execution mechanism, is of the same order as the bound. We then present an algorithm that maximizes a proxy to this lower bound in order to synthesize minimum-dependency joint policies that remain performant under communication loss. Through two-agent and three-agent numerical experiments, we show that the proposed minimum-dependency policies require minimal coordination between the agents while incurring little to no loss in performance; the total correlation value of the synthesized policy is significantly lower than the total correlation value of the baseline policy which does not take potential communication losses into account. As a result, the performance of the minimum-dependency policies remains consistently high regardless of whether or not communication is available. By contrast, the performance of the baseline policy decreases drastically when communication is lost.},
  archive      = {J_AAMAS},
  author       = {Karabag, Mustafa O. and Neary, Cyrus and Topcu, Ufuk},
  doi          = {10.1007/s10458-025-09721-9},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-49},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Designing policies for transition-independent multiagent systems that are robust to communication loss},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the graph theory of majority illusions: Theoretical results and computational experiments. <em>AAMAS</em>, <em>39</em>(2), 1-55. (<a href='https://doi.org/10.1007/s10458-025-09720-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popularity of an opinion in one’s direct circles is not necessarily a good indicator of its popularity in one’s entire community. Network structures make local information about global properties of the group potentially inaccurate, and the way a social network is wired constrains what kind of information distortion can actually occur. In this paper, we discuss which classes of networks allow for a large enough proportion of the population to get a wrong enough impression about the overall distribution of opinions. We start by focusing on the ‘majority illusion’, the case where one sees a majority opinion in one’s direct circles that differs from the global majority. We show that no network structure can guarantee that most agents see the correct majority. We then perform computational experiments to study the likelihood of majority illusions in different classes of networks. Finally, we generalize to other types of illusions.},
  archive      = {J_AAMAS},
  author       = {Venema-Los, Maaike and Christoff, Zoé and Grossi, Davide},
  doi          = {10.1007/s10458-025-09720-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-55},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {On the graph theory of majority illusions: Theoretical results and computational experiments},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Open-ended coordination for multi-agent systems using modular open policies. <em>AAMAS</em>, <em>39</em>(2), 1-28. (<a href='https://doi.org/10.1007/s10458-025-09723-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant multi-agent advances addressing the challenge of learning policies for acting in ad hoc teamwork have been made. In ad hoc teamwork, a team of agents must cooperate effectively without prior coordination or communication. Many existing approaches, however, struggle to perform well in open environments where the setting can change significantly during deployment. This paper presents a new reinforcement learning approach to tackle collaboration in open environments controlling one agent with a changing number of distinct other agents, each with an individual task. The approach uses policy blending based on an online goal inference module and a collection of learned policies modeling the individual interaction impact between the agent and populations of partners with different tasks. Blending is done using the estimated goals of others and a posterior-based action blending with entropy adjustment and regularization. Our approach addresses issues of existing policy blending mechanisms, such as handling conflicting modes in action distributions leading to oscillation and instability and adapting to uncertain states dynamically. In experiments in two collaborative open environments based on Overcooked and Level-based Foraging, our approach outperforms a baseline learner, trained with the joint reward of all agents, across changes to both agents and tasks. Ablation studies further highlight the importance of our posterior-based blending mechanism to achieve high rewards as well as the provided goal weighting. The proposed approach provides an important step towards the application of reinforcement learning to AI assistance beyond strictly closed worlds and towards more realistic scenarios.},
  archive      = {J_AAMAS},
  author       = {Rother, David and Pajarinen, Joni and Peters, Jan and Weisswange, Thomas H.},
  doi          = {10.1007/s10458-025-09723-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-28},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Open-ended coordination for multi-agent systems using modular open policies},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous facility location games with fractional preferences and limited resources. <em>AAMAS</em>, <em>39</em>(2), 1-36. (<a href='https://doi.org/10.1007/s10458-025-09722-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the heterogeneous facility location game with fractional preferences under resource constraints. In this model, a group of agents are positioned along the interval [0, 1], where each agent has position information and fractional preferences indicated as support weights for facilities. Our main focus is to design mechanisms that choose and locate one facility out of two facilities while motivating agents to truthfully report their information, aiming to approximately maximize the social utility, defined as the sum of utilities of all agents. Based on the types of private information held by agents, we consider three different settings. For the known-preferences setting, we provide a deterministic group strategy-proof mechanism with 2-approximation and a randomized group strategy-proof mechanism with $$\frac{4}{3}$$ -approximation. We also provide lower bounds of 2 on the approximation ratio for any deterministic strategy-proof mechanism and 1.043 for any randomized strategy-proof mechanism. For the known-positions setting and the general setting, we present a deterministic group strategy-proof mechanism with 6-approximation and a randomized strategy-proof mechanism with 4-approximation, respectively. Furthermore, we give lower bounds of 1.554 for any deterministic strategy-proof mechanism and 1.2 for any randomized strategy-proof mechanism in the known-positions setting. Finally, we extend the model to the scenario of choosing k facilities out of m facilities. For the known-preferences setting, we provide a 2-approximate deterministic group strategy-proof mechanism, which is also the best deterministic strategy-proof mechanism. For the known-positions setting, when $$k \ge 2$$ , we give a lower bound of $$2-\frac{1}{k}$$ for any deterministic strategy-proof mechanism.},
  archive      = {J_AAMAS},
  author       = {Fang, Jiazhu and Fang, Qizhi and Liu, Wenjing and Li, Minming},
  doi          = {10.1007/s10458-025-09722-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-36},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Heterogeneous facility location games with fractional preferences and limited resources},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The distortion of threshold approval matching. <em>AAMAS</em>, <em>39</em>(2), 1-21. (<a href='https://doi.org/10.1007/s10458-025-09724-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study matching settings in which a set of agents have private utilities over a set of items. Each agent reports a partition of the items into approval sets of different threshold utility levels. Given this limited information on input, the goal is to compute an assignment of the items to the agents (subject to cardinality constraints depending on the application) that (approximately) maximizes the social welfare (the total utility of the agents for their assigned items). We first consider the well-known, simple one-sided matching problem in which each of n agents is to be assigned exactly one of n items. We show that with t threshold utility levels, the distortion of deterministic matching algorithms is $$\Theta (\root t \of {n})$$ while that of randomized algorithms is $$\Theta (\root t+1 \of {n})$$ . We then show that our distortion bounds extend to a more general setting in which there are multiple copies of the items, each agent can be assigned a number of items (even copies of the same one) up to a capacity, and the utility of an agent for an item depends on the number of its copies that the agent is given.},
  archive      = {J_AAMAS},
  author       = {Latifian, Mohamad and Voudouris, Alexandros A.},
  doi          = {10.1007/s10458-025-09724-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {12},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {The distortion of threshold approval matching},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Epistemic selection of costly alternatives: The case of participatory budgeting. <em>AAMAS</em>, <em>39</em>(1), 1-19. (<a href='https://doi.org/10.1007/s10458-024-09677-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We initiate the study of voting rules for participatory budgeting using the so-called epistemic approach, where one interprets votes as noisy reflections of some ground truth regarding the objectively best set of projects to fund. Using this approach, we first show that both the most studied rules in the literature and the most widely used rule in practice cannot be justified on epistemic grounds: they cannot be interpreted as maximum likelihood estimators, whatever assumptions we make about the accuracy of voters. Focusing then on welfare-maximising rules, we obtain both positive and negative results regarding epistemic guarantees.},
  archive      = {J_AAMAS},
  author       = {Rey, Simon and Endriss, Ulle},
  doi          = {10.1007/s10458-024-09677-2},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Epistemic selection of costly alternatives: The case of participatory budgeting},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ability and knowledge: From epistemic transition systems to labelled stit models. <em>AAMAS</em>, <em>39</em>(1), 1-41. (<a href='https://doi.org/10.1007/s10458-024-09661-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is possible to know that one can guarantee a certain result and yet not know how to guarantee it. In such cases one has the ability to guarantee something in a causal sense, but not in an epistemic sense. In this paper we focus on two formalisms used to model both conceptions of ability: one formalism based on epistemic transition systems and the other on labelled stit models. We show a strong correspondence between the two formalisms by providing mappings from the former to the latter for both the languages and the structures. Moreover, we demonstrate that our extension of labelled stit logic is more expressive than the logic of epistemic transition systems.},
  archive      = {J_AAMAS},
  author       = {Kuncová, Alexandra and Broersen, Jan and Duijf, Hein and Ramírez Abarca, Aldo Iván},
  doi          = {10.1007/s10458-024-09661-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-41},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Ability and knowledge: From epistemic transition systems to labelled stit models},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information gathering in POMDPs using active inference. <em>AAMAS</em>, <em>39</em>(1), 1-22. (<a href='https://doi.org/10.1007/s10458-024-09683-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gathering information about the environment state is the main goal in several planning tasks for autonomous agents, such as surveillance, inspection and tracking of objects. Such planning tasks are typically modeled using a Partially Observable Markov Decision Process (POMDP), and in the literature several approaches have emerged to consider information gathering during planning and execution. Similar developments can be seen in the field of active inference, which focuses on active information collection in order to be able to reach a goal. Both fields use POMDPs to model the environment, but the underlying principles for action selection are different. In this paper we create a bridge between both research fields by discussing how they relate to each other and how they can be used for information gathering. Our contribution is a tailored approach to model information gathering tasks directly in the active inference framework. A series of experiments demonstrates that our approach enables agents to gather information about the environment state. As a result, active inference becomes an alternative to common POMDP approaches for information gathering, which opens the door towards more cross cutting research at the intersection of both fields. This is advantageous, because recent advancements in POMDP solvers may be used to accelerate active inference, and the principled active inference framework may be used to model POMDP agents that operate in a neurobiologically plausible fashion.},
  archive      = {J_AAMAS},
  author       = {Walraven, Erwin and Sijs, Joris and Burghouts, Gertjan J.},
  doi          = {10.1007/s10458-024-09683-4},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Information gathering in POMDPs using active inference},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aggregating bipolar opinions through bipolar assumption-based argumentation. <em>AAMAS</em>, <em>39</em>(1), 1-34. (<a href='https://doi.org/10.1007/s10458-024-09684-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel method to aggregate bipolar argumentation frameworks expressing opinions of different parties in debates. We use Bipolar Assumption-based Argumentation (ABA) as an all-encompassing formalism for bipolar argumentation under different semantics. By leveraging on recent results on judgement aggregation in social choice theory, we prove several preservation results for relevant properties of bipolar ABA using quota and oligarchic rules. Specifically, we prove (positive and negative) results about the preservation of conflict-free, closed, admissible, preferred, complete, set-stable, well-founded and ideal extensions in bipolar ABA, as well as the preservation of acceptability, acyclicity and coherence for individual assumptions. Finally, we illustrate our methodology and results in the context of a case study on opinion aggregation for the treatment of long COVID patients.},
  archive      = {J_AAMAS},
  author       = {Dickie, Charles and Lauren, Stefan and Belardinelli, Francesco and Rago, Antonio and Toni, Francesca},
  doi          = {10.1007/s10458-024-09684-3},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-34},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Aggregating bipolar opinions through bipolar assumption-based argumentation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). La VIDA: Towards a motivated goal reasoning agent. <em>AAMAS</em>, <em>39</em>(1), 1-36. (<a href='https://doi.org/10.1007/s10458-024-09685-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An autonomous agent deployed to operate over extended horizons in uncertain environments will encounter situations for which it was not designed. A class of these situations involves an invalidation of agent goals and limited guidance in establishing a new set of goals to pursue. An agent will benefit from some mechanism that will allow it to pursue new goals under these circumstances such that the goals are broadly useful in its environment and take advantage of its existing skills while aligning with societal norms. We propose augmenting a goal reasoning agent, i.e., an agent that can deliberate on and self-select its goals, with a motivation system that can be used to both constrain and motivate agent behavior. A human-like motivation system coupled with a goal-self concordant selection technique allows the approach to be framed as an optimization problem in which the agent selects goals that have high utility while simultaneously in harmony with its motivations. Over the agent’s operational lifespan its motivation system adjusts incrementally to more closely reflect the reality of its goal reasoning and goal pursuit experiences. Experiments performed with an ablation testing technique comparing the average utility of goals achieved in the presence and absence of a motivation system suggest that the motivated version of the system leads to pursuing more useful goals than the baseline.},
  archive      = {J_AAMAS},
  author       = {Addison, Ursula},
  doi          = {10.1007/s10458-024-09685-2},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-36},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {La VIDA: Towards a motivated goal reasoning agent},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Budget-feasible egalitarian allocation of conflicting jobs. <em>AAMAS</em>, <em>39</em>(1), 1-29. (<a href='https://doi.org/10.1007/s10458-024-09686-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Allocating conflicting jobs among individuals while respecting a budget constraint for each individual is an optimization problem that arises in various real-world scenarios. In this paper, we consider the situation where each individual derives some satisfaction from each job. We focus on finding a feasible allocation of conflicting jobs that maximize egalitarian cost, i.e., the satisfaction of the individual who is worst-off. To the best of our knowledge, this is the first paper to combine egalitarianism, budget-feasibility, and conflict-freeness in allocations. We provide a systematic study of the computational complexity of finding budget-feasible conflict-free egalitarian allocation and show that our problem generalizes a large number of classical optimization problems. Therefore, unsurprisingly, our problem is NP-hard even for two individuals and when there is no conflict between any jobs. We show that the problem admits algorithms when studied in the realm of approximation algorithms and parameterized algorithms with a host of natural parameters that match and in some cases improve upon the running time of known algorithms.},
  archive      = {J_AAMAS},
  author       = {Gupta, Sushmita and Jain, Pallavi and Mohanapriya, A. and Tripathi, Vikash},
  doi          = {10.1007/s10458-024-09686-1},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Budget-feasible egalitarian allocation of conflicting jobs},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reflexive anticipatory reasoning by BDI agents. <em>AAMAS</em>, <em>39</em>(1), 1-26. (<a href='https://doi.org/10.1007/s10458-025-09687-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates how predictions about the future behaviour of an agent can be exploited to improve its decision-making in the present. Future states are foreseen by a simulation technique, which is based on models of both the environment and the agent. Although the environment model is usually taken into account for prediction in artificial intelligence (e.g., in automated planning), the agent model receives less attention. We leverage the agent model to speed up the simulation and as a source of alternative decisions. Our proposal bases the agent model on the practical knowledge the developer has given to the agent, especially in the case of BDI agents. This knowledge is thus exploited in the proposed future-concerned reasoning mechanisms. We present a prototype implementation of our approach as well as the results from its evaluation on static and dynamic environments. This allows us to better understand the relation between the improvement in agent decisions and the quality of the knowledge provided by the developer.},
  archive      = {J_AAMAS},
  author       = {Hübner, Jomi Fred and Burattini, Samuele and Ricci, Alessandro and Mayer, Simon},
  doi          = {10.1007/s10458-025-09687-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Reflexive anticipatory reasoning by BDI agents},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disagree and commit: Degrees of argumentation-based agreements. <em>AAMAS</em>, <em>39</em>(1), 1-38. (<a href='https://doi.org/10.1007/s10458-025-09688-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cooperative human decision-making, agreements are often not total; a partial degree of agreement is sufficient to commit to a decision and move on, as long as one is somewhat confident that the involved parties are likely to stand by their commitment in the future, given no drastic unexpected changes. In this paper, we introduce the notion of agreement scenarios that allow artificial autonomous agents to reach such agreements, using formal models of argumentation, in particular abstract argumentation and value-based argumentation. We introduce the notions of degrees of satisfaction and (minimum, mean, and median) agreement, as well as a measure of the impact a value in a value-based argumentation framework has on these notions. We then analyze how degrees of agreement are affected when agreement scenarios are expanded with new information, to shed light on the reliability of partial agreements in dynamic scenarios. An implementation of the introduced concepts is provided as part of an argumentation-based reasoning software library.},
  archive      = {J_AAMAS},
  author       = {Kampik, Timotheus and Nieves, Juan Carlos},
  doi          = {10.1007/s10458-025-09688-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-38},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Disagree and commit: Degrees of argumentation-based agreements},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-level explainability framework for engineering and understanding BDI agents. <em>AAMAS</em>, <em>39</em>(1), 1-42. (<a href='https://doi.org/10.1007/s10458-025-09689-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the complexity of software systems rises, explainability - i.e. the ability of systems to provide explanations of their behaviour - becomes a crucial property. This is true for any AI-based systems, including autonomous systems that exhibit decisionmaking capabilities such as multi-agent systems. Although explainabil- ity is generally considered useful to increase the level of trust for end-users, we argue it is also an interesting property for software engineers, developers, and designers to debug and validate the system’s behaviour. In this paper, we propose a multi-level explainability framework for BDI agents to generate explanations of a running system from logs at different levels of abstraction, tailored to different users and their needs. We describe the mapping from logs to explanations, and present a prototype tool based on the JaCaMo platform which implements the framework.},
  archive      = {J_AAMAS},
  author       = {Yan, Elena and Burattini, Samuele and Hübner, Jomi Fred and Ricci, Alessandro},
  doi          = {10.1007/s10458-025-09689-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-42},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {A multi-level explainability framework for engineering and understanding BDI agents},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A formal testing method for multi-agent systems using colored petri nets. <em>AAMAS</em>, <em>39</em>(1), 1-30. (<a href='https://doi.org/10.1007/s10458-025-09690-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomy in software, a system’s ability to make decisions and take actions independently without human intervention, is a fundamental characteristic of multi-agent systems. Testing, a crucial phase of software validation, is particularly challenging in multi-agent systems due to its complexity, as the interaction between autonomous agents can result in emergent behaviors and collective intelligence, leading to system properties not found in individual agents. A multi-agent system operates on at least three main dimensions: the individual level, the social level, and the communication interfaces. An organizational model formally defines a multi-agent system’s structure, roles, relationships, and interactions. It represents the social layer, capturing agents’ collective dynamics and dependencies, facilitating coherent and efficient collaboration to achieve individual and collective goals. During the literature review, a gap was identified when testing the social layer of multi-agent systems. This paper presents a testing approach by formally introducing steps to map an organizational model, here $$\mathcal {M}$$ oise $$^+$$ , into a colored Petri net. This mapping aims to generate a formal system model, which is used to generate and count test cases based on a coverage criterion. Finally, a use case called Inspector was presented to demonstrate the method by generating test cases, executing the test, and identifying execution errors.},
  archive      = {J_AAMAS},
  author       = {Machado, Ricardo Arend and Cardoso, Arthur da Silva Zelindro and Farias, Giovani Parente and Gonçalves, Eder Mateus Nunes and Adamatti, Diana Francisca},
  doi          = {10.1007/s10458-025-09690-z},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {A formal testing method for multi-agent systems using colored petri nets},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An introduction to computational argumentation research from a human argumentation perspective. <em>AAMAS</em>, <em>39</em>(1), 1-59. (<a href='https://doi.org/10.1007/s10458-025-09692-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational Argumentation studies how human argumentative reasoning can be approached from a computational viewpoint. Human argumentation is a complex process that has been studied from different perspectives (e.g., philosophical or linguistic) and that involves many different aspects beyond pure reasoning, such as the role of emotions, values, social contexts, and practical constraints, which are often overlooked in computational approaches to argumentation. The heterogeneity of human argumentation is present in Computational Argumentation research, in the form of various tasks that approach the main phases of argumentation individually. With the increasing interest of researchers in Artificial Intelligence, we consider that it is of great importance to provide guidance on the Computational Argumentation research area. Thus, in this paper, we present a general overview of Computational Argumentation, from the perspective of how humans argue. For that purpose, the following contributions are produced: (i) a consistent structure for Computational Argumentation research mapped with the human argumentation process; (ii) a collective understanding of the tasks approached by Computational Argumentation and their synergies; (iii) a thorough review of important advances in each of these tasks; and (iv) an analysis and a classification of the future trends in Computational Argumentation research and relevant open challenges in the area.},
  archive      = {J_AAMAS},
  author       = {Ruiz-Dolz, Ramon and Heras, Stella and García-Fornes, Ana},
  doi          = {10.1007/s10458-025-09692-x},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-59},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {An introduction to computational argumentation research from a human argumentation perspective},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low variance trust region optimization with independent actors and sequential updates in cooperative multi-agent reinforcement learning. <em>AAMAS</em>, <em>39</em>(1), 1-34. (<a href='https://doi.org/10.1007/s10458-025-09695-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative multi-agent reinforcement learning assumes each agent shares the same reward function and can be trained effectively using the Trust Region framework of single-agent. Instead of relying on other agents’ actions, the independent actors setting considers each agent to act based only on its local information, thus having more flexible applications. However, in the sequential update framework, it is required to re-estimate the joint advantage function after each individual agent’s policy step. Despite the practical success of importance sampling, the updated advantage function suffers from exponentially high variance problems, which likely results in unstable convergence. In this work, we first analyze the high variance advantage both empirically and theoretically. To overcome this limitation, we introduce a clipping objective to control the upper bounds of the advantage fluctuation in sequential updates. With the proposed objective, we provide a monotonic bound with sub-linear convergence to $$\varepsilon$$ -Nash Equilibria. We further derive two new practical algorithms using our clipping objective. The experiment results on three popular multi-agent reinforcement learning benchmarks show that our proposed method outperforms the tested baselines in most environments. By carefully analyzing different training settings, our proposed method is highlighted with both stable convergence properties and the desired low advantage variance estimation. For reproducibility purposes, our source code is publicly available at https://github.com/giangbang/Low-Variance-Trust-Region-MARL .},
  archive      = {J_AAMAS},
  author       = {Le, Bang Giang and Ta, Viet Cuong},
  doi          = {10.1007/s10458-025-09695-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-34},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Low variance trust region optimization with independent actors and sequential updates in cooperative multi-agent reinforcement learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving multi-agent games on networks. <em>AAMAS</em>, <em>39</em>(1), 1-37. (<a href='https://doi.org/10.1007/s10458-025-09696-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent games on networks (GoNs) have nodes that represent agents and edges that represent interactions among agents. A special class of GoNs is composed of 2-players games on each of their edges. General GoNs have games that are played by all agents in each neighborhood. Solutions to games on networks are stable states (i.e., pure Nash equilibria), and in general one is interested in efficient solutions (of high global social welfare). This study addresses the multi-agent aspect of games on networks—a system of multiple agents that compose a game and seek a solution by performing a multi-agent (distributed) algorithm. The agents playing the game are assumed to be strategic and an iterative distributed algorithm is proposed, that lets the agents interact (i.e., negotiate) in neighborhoods in a process that guarantees the convergence of any multi-agent game on network to a globally stable state. The proposed algorithm—the TECon algorithm—iterates, one neighborhood at a time, performing a repeated social choice action. A truth-enforcing mechanism is integrated into the algorithm, collecting the valuations of agents in each neighborhood and computing incentives while eliminating strategic behavior. The proposed method is proven to converge to globally stable states that are at least as efficient as the initial state, for any game on network. A specific version of the algorithm is given for the class of Public Goods Games, where the main properties of the algorithm are guaranteed even when the strategic agents playing the game consider their possible future valuations when interacting. An extensive experimental evaluation on randomly generated games on networks demonstrates that the TECon algorithm converges very rapidly. On general forms of public goods games, the proposed algorithm outperforms former solving methods, where former methods are applicable.},
  archive      = {J_AAMAS},
  author       = {Vaknin, Yair and Meisels, Amnon},
  doi          = {10.1007/s10458-025-09696-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Solving multi-agent games on networks},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A game-theoretic approach for hierarchical epidemic control. <em>AAMAS</em>, <em>39</em>(1), 1-37. (<a href='https://doi.org/10.1007/s10458-025-09697-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We design and analyze a multi-level game-theoretic model of hierarchical policy interventions for epidemic control, such as those in response to the COVID-19 pandemic. Our model captures the potentially mismatched priorities among a hierarchy of policy-makers (e.g., federal, state, and local governments) with respect to two cost components that have opposite dependence on the policy strength—post-intervention infection rates and the socio-economic cost of policy implementation. Additionally, our model includes a crucial third factor in decisions: a cost of non-compliance with the policy-maker immediately above in the hierarchy, such as non-compliance of counties with state-level policies. We propose two novel algorithms for approximating solutions to such games. The first is based on best response dynamics (BRD) and exploits the tree structure of the game. The second combines quadratic integer programming (QIP), which enables us to collapse the two lowest levels of the game, with the best response dynamics. We experimentally characterize the scalability and equilibrium approximation quality of our two approaches against model parameters. Finally, we conduct experiments in simulations based on both synthetic and real-world data under various parameter configurations and analyze the resulting (approximate) equilibria to gain insight into the impact of decentralization on overall welfare (measured as the negative sum of costs) as well as emergent properties like social welfare, free-riding, and fairness in cost distribution among policy-makers.},
  archive      = {J_AAMAS},
  author       = {Jia, Feiran and Mate, Aditya and Li, Zun and Jabbari, Shahin and Chakraborty, Mithun and Tambe, Milind and Wellman, Michael P. and Vorobeychik, Yevgeniy},
  doi          = {10.1007/s10458-025-09697-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {A game-theoretic approach for hierarchical epidemic control},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emergent language: A survey and taxonomy. <em>AAMAS</em>, <em>39</em>(1), 1-73. (<a href='https://doi.org/10.1007/s10458-025-09691-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of emergent language represents a novel area of research within the domain of artificial intelligence, particularly within the context of multi-agent reinforcement learning. Although the concept of studying language emergence is not new, early approaches were primarily concerned with explaining human language formation, with little consideration given to its potential utility for artificial agents. In contrast, studies based on reinforcement learning aim to develop communicative capabilities in agents that are comparable to or even superior to human language. Thus, they extend beyond the learned statistical representations that are common in natural language processing research. This gives rise to a number of fundamental questions, from the prerequisites for language emergence to the criteria for measuring its success. This paper addresses these questions by providing a comprehensive review of relevant scientific publications on emergent language in artificial intelligence. Its objective is to serve as a reference for researchers interested in or proficient in the field. Consequently, the main contributions are the definition and overview of the prevailing terminology, the analysis of existing evaluation methods and metrics, and the description of the identified research gaps.},
  archive      = {J_AAMAS},
  author       = {Peters, Jannik and Waubert de Puiseau, Constantin and Tercan, Hasan and Gopikrishnan, Arya and Lucas de Carvalho, Gustavo Adolpho and Bitter, Christian and Meisen, Tobias},
  doi          = {10.1007/s10458-025-09691-y},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-73},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Emergent language: A survey and taxonomy},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal matchings with one-sided preferences: Fixed and cost-based quotas. <em>AAMAS</em>, <em>39</em>(1), 1-36. (<a href='https://doi.org/10.1007/s10458-025-09693-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the well-studied many-to-one bipartite matching problem of assigning applicants $${\varvec{\mathcal {A}}}$$ to posts $${\varvec{\mathcal {P}}}$$ where applicants rank posts in the order of preference. This setting models many important real-world allocation problems like assigning students to courses, applicants to jobs, amongst many others. In such scenarios, it is natural to ask for an allocation that satisfies guarantees of the form “match at least 80% of applicants to one of their top three choices” or “it is unacceptable to leave more than 10% of applicants unassigned”. The well-studied notions of rank-maximality and fairness fail to capture such requirements due to their property of optimizing extreme ends of the signature of a matching. We, therefore, propose a novel optimality criterion, which we call the “weak dominance ” of ranks. We investigate the computational complexity of the new notion of optimality in the setting where posts have associated fixed quotas. We prove that under the fixed quota setting, the problem turns out to be NP-hard under natural restrictions. We provide randomized algorithms in the fixed quota setting when the number of ranks is constant. We also study the problem under a cost-based quota setting and show that a matching that weakly dominates the input signature and has minimum total cost can be computed efficiently. Apart from circumventing the hardness, the cost-based quota setting is motivated by real-world applications like course allocation or school choice where the capacities or quotas need not be rigid. We also show that when the objective is to minimize the maximum cost, the problem under the cost-based quota setting turns out to be NP-hard. To complement the hardness, we provide a randomized algorithm when the number of ranks is constant. We also provide an approximation algorithm which is an asymptotic faster alternative to the randomized algorithm.},
  archive      = {J_AAMAS},
  author       = {Santhini, K. A. and Sankar, Govind S. and Nasre, Meghana},
  doi          = {10.1007/s10458-025-09693-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-36},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Optimal matchings with one-sided preferences: Fixed and cost-based quotas},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating the impact of direct punishment on the emergence of cooperation in multi-agent reinforcement learning systems. <em>AAMAS</em>, <em>39</em>(1), 1-37. (<a href='https://doi.org/10.1007/s10458-025-09698-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving the problem of cooperation is fundamentally important for the creation and maintenance of functional societies. Problems of cooperation are omnipresent within human society, with examples ranging from navigating busy road junctions to negotiating treaties. As the use of AI becomes more pervasive throughout society, the need for socially intelligent agents capable of navigating these complex cooperative dilemmas is becoming increasingly evident. Direct punishment is a ubiquitous social mechanism that has been shown to foster the emergence of cooperation in both humans and non-humans. In the natural world, direct punishment is often strongly coupled with partner selection and reputation and used in conjunction with third-party punishment. The interactions between these mechanisms could potentially enhance the emergence of cooperation within populations. However, no previous work has evaluated the learning dynamics and outcomes emerging from multi-agent reinforcement learning populations that combine these mechanisms. This paper addresses this gap. It presents a comprehensive analysis and evaluation of the behaviors and learning dynamics associated with direct punishment, third-party punishment, partner selection, and reputation. Finally, we discuss the implications of using these mechanisms on the design of cooperative AI systems.},
  archive      = {J_AAMAS},
  author       = {Dasgupta, Nayana and Musolesi, Mirco},
  doi          = {10.1007/s10458-025-09698-5},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Investigating the impact of direct punishment on the emergence of cooperation in multi-agent reinforcement learning systems},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relationship design for socially-aware behavior in static games. <em>AAMAS</em>, <em>39</em>(1), 1-17. (<a href='https://doi.org/10.1007/s10458-025-09699-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous agents can adopt socially-aware behaviors to reduce social costs, mimicking the way animals interact in nature and humans in society. We present a new approach to model socially-aware decision-making that includes two key elements: bounded rationality and inter-agent relationships. We capture the inter-agent relationships by introducing a novel model called a relationship game and encode agents’ bounded rationality using quantal response equilibria. For each relationship game, we define a social cost function and formulate a mechanism design problem to optimize weights for relationships that minimize social cost at the equilibrium. We address the multiplicity of equilibria by presenting the problem in two forms: Min-Max and Min-Min, aimed respectively at minimization of the highest and lowest social costs in the equilibria. We compute the quantal response equilibrium by solving a least-squares problem defined with its Karush-Kuhn-Tucker conditions, and propose two projected gradient descent algorithms to solve the mechanism design problems. Numerical results, including two-lane congestion and congestion with an ambulance, confirm that these algorithms consistently reach the equilibrium with the intended social costs.},
  archive      = {J_AAMAS},
  author       = {Chen, Shenghui and Bayiz, Yigit E. and Fridovich-Keil, David and Topcu, Ufuk},
  doi          = {10.1007/s10458-025-09699-4},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Relationship design for socially-aware behavior in static games},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double mixing networks based monotonic value function decomposition algorithm for swarm intelligence in UAVs. <em>AAMAS</em>, <em>39</em>(1), 1-21. (<a href='https://doi.org/10.1007/s10458-025-09700-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-agent systems, particularly when facing challenges of partial observability, reinforcement learning demonstrates significant autonomous decision-making capabilities. Aiming at addressing resource allocation and collaboration issues in drone swarms operating in dynamic and unknown environments, we propose a novel deep reinforcement learning algorithm, DQMIX. We employ a framework of centralized training with decentralized execution and incorporate a partially observable Markov game model to describe the complex game environment of drone swarms. The core innovation of the DQMIX algorithm lies in its dual-mixing network structure and soft-switching mechanism. Two independent mixing networks handle local Q-values and synthesize them into a global Q-value. This structure enhances decision accuracy and system adaptability under different scenarios and data conditions. The soft-switching module allows the system to transition smoothly between the two networks, selecting the output of the network with smaller TD-errors to enhance decision stability and coherence. Simultaneously, we introduce Hindsight Experience Replay to learn from failed experiences. Experimental results using JSBSim demonstrate that DQMIX provides an effective solution for drone swarm game problems, especially in resource allocation and adversarial environments.},
  archive      = {J_AAMAS},
  author       = {Qu, Pingping and He, Chenglong and Wu, Xiaotong and Wang, Ershen and Xu, Song and Liu, Huan and Sun, Xinhui},
  doi          = {10.1007/s10458-025-09700-0},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Double mixing networks based monotonic value function decomposition algorithm for swarm intelligence in UAVs},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). “Provably fair” algorithms may perpetuate racial and gender bias: A study of salary dispute resolution. <em>AAMAS</em>, <em>39</em>(1), 1-15. (<a href='https://doi.org/10.1007/s10458-025-09703-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prior work suggests automated dispute resolution tools using “provably fair” algorithms can address disparities between demographic groups. These methods use multi-criteria elicited preferences from all disputants and satisfy constraints to generate “fair” solutions. However, we analyze the potential for inequity to permeate proposals through the preference elicitation stage. This possibility arises if differences in dispositional attitudes differ between demographics, and those dispositions affect elicited preferences. Specifically, risk aversion plays a prominent role in predicting preferences. Risk aversion predicts a weaker relative preference for salary and a softer within-issue utility for each issue; this leads to worse compensation packages for risk-averse groups. These results raise important questions in AI-value alignment about whether an AI mediator should take explicit preferences at face value.},
  archive      = {J_AAMAS},
  author       = {Hale, James and Kim, Peter H. and Gratch, Jonathan},
  doi          = {10.1007/s10458-025-09703-x},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {“Provably fair” algorithms may perpetuate racial and gender bias: A study of salary dispute resolution},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On fair and efficient solutions for budget apportionment. <em>AAMAS</em>, <em>39</em>(1), 1-31. (<a href='https://doi.org/10.1007/s10458-025-09694-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article deals with an apportionment problem involving n agents and a common budget B. Each agent submits some demands which are indivisible portions of the budget, and a central authority has to decide which demands to accept. The utility of an agent corresponds to the total amount of her accepted demands. In this context, it is desirable to be fair among the agents and efficient by not wasting the budget. An ideal solution would be to spend exactly B/n for every agent but this is rarely possible because of the indivisibility of the demands. Since combining fairness with efficiency is highly desirable but often impossible, we explore relaxed notions of fairness and efficiency, in order to determine if they go together. Our approach is also constructive because polynomial algorithms that build fair and efficient solutions are also given. The fairness criteria under consideration are the maximization of the minimum agent utility (max–min), proportionality, a customized notion of envy-freeness called jealousy-freeness, and the relaxations up to one or any demand of the previous two concepts. Efficiency in this work is either the maximization of the utilitarian social welfare or Pareto optimality. First we consider fairness and efficiency separately. The existence and computation of solutions that are either fair or efficient are studied. A complete picture of the relations that connect the fairness and efficiency concepts is provided. Second, we determine when fairness and efficiency can be combined for every possible instance. We prove that Pareto optimality is compatible with two notions of fairness, namely max–min and proportionality up to any demand. In contrast, none of the fairness concepts under consideration can be paired with the maximization of utilitarian social welfare. Therefore, we finally conduct a thorough analysis of the price of fairness which bounds the loss of efficiency caused by imposing fairness or one of its relaxations.},
  archive      = {J_AAMAS},
  author       = {Cardi, Pierre and Gourvès, Laurent and Lesca, Julien},
  doi          = {10.1007/s10458-025-09694-9},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-31},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {On fair and efficient solutions for budget apportionment},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptation procedure in misinformation games. <em>AAMAS</em>, <em>39</em>(1), 1-47. (<a href='https://doi.org/10.1007/s10458-025-09704-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study interactions between agents in multi-agent systems, in which the agents are misinformed with regards to the game that they play, essentially having a subjective and incorrect understanding of the setting, without being aware of it. For that, we introduce a new game-theoretic concept, called misinformation games, that provides the necessary toolkit to study this situation. Subsequently, we enhance this framework by developing a time-discrete procedure (called the Adaptation Procedure) that captures iterative interactions in the above context. During the Adaptation Procedure, the agents update their information and reassess their behaviour in each step. We demonstrate our ideas through an implementation, which is used to study the efficiency and characteristics of the Adaptation Procedure.},
  archive      = {J_AAMAS},
  author       = {Varsos, Konstantinos and Papamichail, Merkouris and Flouris, Giorgos and Bitsaki, Marina},
  doi          = {10.1007/s10458-025-09704-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-47},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Adaptation procedure in misinformation games},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypertension and total-order forward decomposition optimizations. <em>AAMAS</em>, <em>39</em>(1), 1-27. (<a href='https://doi.org/10.1007/s10458-025-09705-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical Task Network (HTN) planners generate plans using a decomposition process with extra domain knowledge to guide search towards a planning task. Domain experts develop such domain knowledge through recipes of how to decompose higher level tasks, specifying which tasks can be decomposed and under what conditions. In most realistic domains, such recipes contain recursions, i.e., tasks that can be decomposed into other tasks that contain the original task. Such domains require that either the domain expert tailor such domain knowledge to the specific HTN planning algorithm, or an algorithm that can search efficiently using such domain knowledge. By leveraging a three-stage compiler design we can easily support more language descriptions and preprocessing optimizations that when chained can greatly improve runtime efficiency in such domains. In this paper we evaluate such optimizations with the HyperTensioN HTN planner, winner of the HTN IPC 2020 total-order track.},
  archive      = {J_AAMAS},
  author       = {Cecílio Magnaguagno, Maurício and Meneguzzi, Felipe and de Silva, Lavindra},
  doi          = {10.1007/s10458-025-09705-9},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Hypertension and total-order forward decomposition optimizations},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving execution concurrency in partial-order plans via block-substitution. <em>AAMAS</em>, <em>39</em>(1), 1-43. (<a href='https://doi.org/10.1007/s10458-025-09706-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial-order plans in AI planning facilitate execution flexibility and several other tasks, such as plan reuse, modification, and decomposition, due to their less constrained nature. A Partial-Order Plan (POP) specifies partial-order over actions, providing the flexibility of executing unordered actions in different sequences. This flexibility can be further extended by enabling parallel execution of actions in the POP to reduce its overall execution time. While extensive studies exist on improving the flexibility of a POP by optimizing its action orderings through plan deordering and reordering, there has been limited focus on the flexibility of executing actions concurrently in a plan. Flexibility of executing actions concurrently, referred to as concurrency, in a POP can be achieved by incorporating action non-concurrency constraints, specifying which actions can not be executed in parallel. This work establishes the necessary and sufficient conditions for non-concurrency constraints between two actions or two subplans with respect to a planning task. We also introduce an algorithm to improve a plan’s concurrency by optimizing resource utilization through substitutions of the plan’s subplans with respect to the corresponding planning task. Our algorithm employs block deordering that eliminates orderings in a POP by encapsulating coherent actions in blocks, and then exploits blocks as candidate subplans for substitutions. Experiments over the benchmark problems from International Planning Competitions (IPC) exhibit considerable improvement in plan concurrency.},
  archive      = {J_AAMAS},
  author       = {Noor, Sabah Binte and Siddiqui, Fazlul Hasan},
  doi          = {10.1007/s10458-025-09706-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-43},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Improving execution concurrency in partial-order plans via block-substitution},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Epistemic selection of costly alternatives: The case of participatory budgeting. <em>AAMAS</em>, <em>39</em>(1), 1-2. (<a href='https://doi.org/10.1007/s10458-025-09702-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AAMAS},
  author       = {Rey, Simon and Endriss, Ulle},
  doi          = {10.1007/s10458-025-09702-y},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Correction: Epistemic selection of costly alternatives: The case of participatory budgeting},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Entropy based blending of policies for multi-agent coexistence. <em>AAMAS</em>, <em>39</em>(1), 1-28. (<a href='https://doi.org/10.1007/s10458-025-09707-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on multi-agent interaction involving humans is still in its infancy. Most approaches have focused on environments with collaborative human behavior or a small, defined set of situations. When deploying robots in human-inhabited environments in the future, the diversity of interactions surpasses the capabilities of pre-trained collaboration models. ”Coexistence” environments, characterized by agents with varying or partially aligned objectives, present a unique challenge for robotic collaboration. Traditional reinforcement learning methods fall short in these settings. These approaches lack the flexibility to adapt to changing agent counts or task requirements without undergoing retraining. Moreover, existing models do not adequately support scenarios where robots should exhibit helpful behavior toward others without compromising their primary goals. To tackle this issue, we introduce a novel framework that decomposes interaction and task-solving into separate learning problems and blends the resulting policies at inference time using a goal inference model for task estimation. We create impact-aware agents and linearly scale the cost of training agents with the number of agents and available tasks. To this end, a weighting function blending action distributions for individual interactions with the original task action distribution is proposed. To support our claims we demonstrate that our framework scales in task and agent count across several environments and considers collaboration opportunities when present. The new learning paradigm opens the path to more complex multi-robot, multi-human interactions.},
  archive      = {J_AAMAS},
  author       = {Rother, David and Herbert, Franziska and Kalter, Fabian and Koert, Dorothea and Pajarinen, Joni and Peters, Jan and Weisswange, Thomas H.},
  doi          = {10.1007/s10458-025-09707-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Entropy based blending of policies for multi-agent coexistence},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed course allocation with asymmetric friendships. <em>AAMAS</em>, <em>39</em>(1), 1-30. (<a href='https://doi.org/10.1007/s10458-025-09708-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Students’ decisions on whether to take a class are strongly affected by whether their friends plan to take the class with them. A student may prefer to be assigned to a course they like less, just to be with their friends, rather than taking a more preferred class alone. It has been shown that taking classes with friends positively affects academic performance. Thus, academic institutes should prioritize friendship relations when assigning course seats. The introduction of friendship relations results in several non-trivial changes to current course allocation methods. This paper explores how course allocation mechanisms can account for friendships between students and provide a unique, distributed solution. Specifically, we approach the problem by framing it as an asymmetric distributed constraint optimization problem and develop a new dedicated algorithm. Our extensive evaluation includes both simulated data and a study involving 177 students, focusing on their preferences regarding both courses and friendships. The findings indicate that our algorithm achieves significant utility for the students, maintaining fairness in the solution and adhering to the limitations on course seat capacities.},
  archive      = {J_AAMAS},
  author       = {Dery, Lihi and Grinshpoun, Tal and Khakhiashvili, Ilya},
  doi          = {10.1007/s10458-025-09708-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Distributed course allocation with asymmetric friendships},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augmenting the action space with conventions to improve multi-agent cooperation in hanabi. <em>AAMAS</em>, <em>39</em>(1), 1-36. (<a href='https://doi.org/10.1007/s10458-025-09709-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The card game Hanabi is considered a strong medium for the testing and development of multi-agent reinforcement learning (MARL) algorithms, due to its cooperative nature, partial observability, limited communication and remarkable complexity. Previous research efforts have explored the capabilities of MARL algorithms within Hanabi, focusing largely on advanced architecture design and algorithmic manipulations to achieve state-of-the-art performance for various number of cooperators. However, this often leads to complex solution strategies with high computational cost and requiring large amounts of training data. For humans to solve the Hanabi game effectively, they require the use of conventions, which often allows for a means to implicitly convey ideas or knowledge based on a predefined, and mutually agreed upon, set of “rules” or principles. Multi-agent problems containing partial observability, especially when limited communication is present, can benefit greatly from the use of implicit knowledge sharing. In this paper, we propose a novel approach to augmenting an agent’s action space using conventions, which act as a sequence of special cooperative actions that span over and include multiple time steps and multiple agents, requiring agents to actively opt in for it to reach fruition. These conventions are based on existing human conventions, and result in a significant improvement on the performance of existing techniques for self-play and cross-play for various number of cooperators within Hanabi.},
  archive      = {J_AAMAS},
  author       = {Bredell, Francois and Engelbrecht, Herman A. and Schoeman, J. C.},
  doi          = {10.1007/s10458-025-09709-5},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-36},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Augmenting the action space with conventions to improve multi-agent cooperation in hanabi},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
