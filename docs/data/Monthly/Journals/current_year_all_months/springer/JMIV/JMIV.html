<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JMIV</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jmiv">JMIV - 54</h2>
<ul>
<li><details>
<summary>
(2025). Sigma flows for image and data labeling and learning structured prediction. <em>JMIV</em>, <em>67</em>(6), 1-38. (<a href='https://doi.org/10.1007/s10851-025-01270-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the sigma flow model for the prediction of structured labelings of data observed on Riemannian manifolds, including Euclidean image domains as special case. The approach combines the Laplace–Beltrami framework for image denoising and enhancement, introduced by Sochen, Kimmel and Malladi about 25 years ago, and the assignment flow approach introduced and studied by the authors. The sigma flow arises as the Riemannian gradient flow of generalized harmonic energies and is thus governed by a nonlinear geometric PDE which determines a harmonic map from a closed Riemannian domain manifold to a statistical manifold, equipped with the Fisher–Rao metric from information geometry. A specific ingredient of the sigma flow is the mutual dependency of the Riemannian metric of the domain manifold on the evolving state. This makes the approach amenable to machine learning in a specific way, by realizing this dependency through a mapping with compact time-variant parametrization that can be learned from data. Proof-of-concept experiments demonstrate the expressivity of the sigma flow model and prediction performance. Structural similarities to transformer network architectures and networks generated by the geometric integration of sigma flows are pointed out, which highlights the connection to deep learning and, conversely, may stimulate the use of geometric design principles for structured prediction in other areas of scientific machine learning.},
  archive      = {J_JMIV},
  author       = {Cassel, Jonas and Boll, Bastian and Petra, Stefania and Albers, Peter and Schnörr, Christoph},
  doi          = {10.1007/s10851-025-01270-w},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {12},
  number       = {6},
  pages        = {1-38},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Sigma flows for image and data labeling and learning structured prediction},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptively inexact method for bilevel learning using Primal–Dual-style differentiation. <em>JMIV</em>, <em>67</em>(5), 1-15. (<a href='https://doi.org/10.1007/s10851-025-01262-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a bilevel learning framework for learning linear operators. In this framework, the learnable parameters are optimized via a loss function that also depends on the minimizer of a convex optimization problem (denoted lower-level problem). We utilize an iterative algorithm called ‘piggyback’ to compute the gradient of the loss and minimizer of the lower-level problem. Given that the lower-level problem is solved numerically, the loss function and thus its gradient can only be computed inexactly. To estimate the accuracy of the computed hypergradient, we derive an a-posteriori error bound, which provides guides for setting the tolerance for the lower-level problem, as well as the piggyback algorithm. To efficiently solve the upper-level optimization, we also propose an adaptive method for choosing a suitable step size. To illustrate the proposed method, we consider a few learned regularizer problems, such as training an input-convex neural network.},
  archive      = {J_JMIV},
  author       = {Bogensperger, Lea and Ehrhardt, Matthias J. and Pock, Thomas and Salehi, Mohammad Sadegh and Wong, Hok Shing},
  doi          = {10.1007/s10851-025-01262-w},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {5},
  pages        = {1-15},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {An adaptively inexact method for bilevel learning using Primal–Dual-style differentiation},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Empirical bayesian image restoration by langevin sampling with a denoising diffusion implicit prior. <em>JMIV</em>, <em>67</em>(5), 1-19. (<a href='https://doi.org/10.1007/s10851-025-01265-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Score-based diffusion methods provide a powerful strategy to solve image restoration tasks by flexibly combining a pre-trained foundational prior model with a likelihood function specified during test time . Such methods are predominantly derived from two stochastic processes: reversing Ornstein–Uhlenbeck, which underpins the celebrated denoising diffusion probabilistic models (DDPM) and denoising diffusion implicit models (DDIM), and the Langevin diffusion process. The solutions delivered by DDPM and DDIM are often remarkably realistic, but they are not always consistent with measurements because of likelihood intractability issues and the associated required approximations. Alternatively, using a Langevin process circumvents the intractable likelihood issue, but usually leads to restoration results of inferior quality. This paper presents a novel and highly computationally efficient image restoration method that carefully embeds a foundational DDPM denoiser within an empirical Bayesian Langevin algorithm, which jointly calibrates key model hyper-parameters as it estimates the model’s posterior mean. Extensive experimental results on three canonical tasks (image deblurring, super-resolution, and inpainting) demonstrate that the proposed approach improves on state-of-the-art strategies both in image estimation accuracy and computing time.},
  archive      = {J_JMIV},
  author       = {Kemajou Mbakam, Charlesquin and Giovannelli, Jean-Francois and Pereyra, Marcelo},
  doi          = {10.1007/s10851-025-01265-7},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {5},
  pages        = {1-19},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Empirical bayesian image restoration by langevin sampling with a denoising diffusion implicit prior},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interior object geometry via fitted frames. <em>JMIV</em>, <em>67</em>(5), 1-16. (<a href='https://doi.org/10.1007/s10851-025-01266-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a means of computing fitted frames on the boundary and in the interior of objects and using them to provide the basis for producing geometric features from them that are not only alignment-free but most importantly can be made to correspond locally across a population of objects. We describe a representation targeted for anatomic objects which is designed to enable this strong locational correspondence within object populations and thus to provide powerful object statistics. It accomplishes this by understanding an object as the diffeomorphic deformation of the closure of the interior of an ellipsoid and by using a skeletal representation fitted throughout the deformation to produce a model of the target object, where the object is provided initially in the form of a boundary mesh. Via classification performance on hippocampi shape between individuals with a disorder vs. others, we compare our method to two state-of-the-art methods for producing object representations that are intended to capture geometric correspondence across a population of objects and to yield geometric features useful for statistics, and we show notably improved classification performance by this new representation, which we call the evolutionary s-rep. The geometric features that are derived from each of the representations, especially via fitted frames, are discussed.},
  archive      = {J_JMIV},
  author       = {Pizer, Stephen M. and Liu, Zhiyuan and Zhao, Junjie and Tapp-Hughes, Nicholas and Damon, James and Zhang, Miaomiao and Marron, J. S. and Taheri, Mohsen and Vicory, Jared},
  doi          = {10.1007/s10851-025-01266-6},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {5},
  pages        = {1-16},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Interior object geometry via fitted frames},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Matrix-valued LogSumExp approximation for colour morphology. <em>JMIV</em>, <em>67</em>(5), 1-28. (<a href='https://doi.org/10.1007/s10851-025-01267-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mathematical morphology is a part of image processing that employs a moving window to modify pixel values through the application of specific operations. The supremum and infimum are pivotal concepts, yet defining them in a general sense for high-dimensional data such as colour is a challenging endeavour. As a result, a number of different approaches have been taken to try to find a solution, with certain compromises being made along the way. In this paper, we present an analysis of a novel approach that replaces the supremum within a morphological operation with the LogExp approximation of the maximum for matrix-valued colours. This approach has the advantage of extending the associativity of dilation from the one-dimensional to the higher-dimensional case. Furthermore, the minimality property is investigated and a relaxation specified to ensure that the approach is continuously dependent on the input data.},
  archive      = {J_JMIV},
  author       = {Kahra, Marvin and Breuß, Michael and Kleefeld, Andreas and Welk, Martin},
  doi          = {10.1007/s10851-025-01267-5},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {5},
  pages        = {1-28},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Matrix-valued LogSumExp approximation for colour morphology},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vertex characterization via second-order topological derivatives. <em>JMIV</em>, <em>67</em>(5), 1-19. (<a href='https://doi.org/10.1007/s10851-025-01269-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on identifying vertex characteristics in 2D images using topological asymptotic analysis. Vertex characteristics include both the location and the type of the vertex, with the latter defined by the number of lines forming it and the corresponding angles. This problem is crucial for computer vision tasks, such as distinguishing between fore- and background objects in 3D scenes. We compute the second-order topological derivative of a Mumford–Shah-type functional with respect to inclusion shapes representing various vertex types. This derivative assigns a likelihood to each pixel that a particular vertex type appears there. Numerical tests demonstrate the effectiveness of the proposed approach.},
  archive      = {J_JMIV},
  author       = {Gangl, Peter and Mejri, Bochra and Scherzer, Otmar},
  doi          = {10.1007/s10851-025-01269-3},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {10},
  number       = {5},
  pages        = {1-19},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Vertex characterization via second-order topological derivatives},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 2D bijective rigid rotation: Quantitative and qualitative study. <em>JMIV</em>, <em>67</em>(4), 1-19. (<a href='https://doi.org/10.1007/s10851-025-01252-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preserving surfaces or volumes is crucial when applying rigid transformations of 2D/3D digital objects in medical images and computer vision. To achieve this goal, the digital geometry community has focused on characterizing bijective digitized rotations and reflections. However, the angular distribution of these bijective rigid transformations is far from being dense. Other bijective approximations of rigid transformations have been proposed, but the state-of-the-art methods lack the experimental evaluations necessary to include them in real-life applications. This paper presents several new methods to approximate digitized rotations with bijective transformations, including the composition of bijective digitized reflections, bijective rotation by circles, and bijective rotation through optimal transport. These new methods and several classical ones are compared in terms of accuracy with respect to Euclidean rotations, as well as computational complexity and practical speed in real-time applications and continuity. Finally, we determine some topological stability results of bijective rigid rotations.},
  archive      = {J_JMIV},
  author       = {Breuils, Stéphane and Coeurjolly, David and Lachaud, Jacques-Olivier},
  doi          = {10.1007/s10851-025-01252-y},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {8},
  number       = {4},
  pages        = {1-19},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {2D bijective rigid rotation: Quantitative and qualitative study},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vectorial fractional-order regularizer-based diffeomorphic image registration model and its numerical algorithm. <em>JMIV</em>, <em>67</em>(4), 1-27. (<a href='https://doi.org/10.1007/s10851-025-01254-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A diffeomorphic image registration model with a vectorial fractional-order regularizer is introduced to handle displacement fields with varying smoothness and to avoid mesh folding. Furthermore, we combine the damped Newton method with the Armijo line search and apply a multilevel strategy to solve the discretized version of the new model. Furthermore, both the existence of solutions to the model and the convergence of the algorithm have been established. Numerical experiments on synthetic and real images confirm the superiority of the proposed model and the effectiveness of the algorithm.},
  archive      = {J_JMIV},
  author       = {Zhang, Jin and Kong, Xu and Zhang, Jianping and Yang, Fenlin and Chen, Ke},
  doi          = {10.1007/s10851-025-01254-w},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {8},
  number       = {4},
  pages        = {1-27},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Vectorial fractional-order regularizer-based diffeomorphic image registration model and its numerical algorithm},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Plug-and-play ADMM for embedded noise level estimation. <em>JMIV</em>, <em>67</em>(4), 1-24. (<a href='https://doi.org/10.1007/s10851-025-01256-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the plug-and-play alternate direction method of multipliers (PnP-ADMM) has been extensively studied, leading to significant advancements in image restoration. However, existing PnP-ADMM algorithms typically assume the noise level parameter in the denoiser to be a known constant. This assumption limits the adaptability of the denoiser to varying noise levels and may compromise the algorithm’s convergence due to its dependence on the noise level. To address these limitations, this paper establishes a relationship between the noise level and the denoising intensity of the denoiser, enabling the denoiser in the PnP-ADMM algorithm to adaptively adjust its denoising intensity. Consequently, we propose a PnP-ADMM algorithm with embedded noise level estimation, termed the embedded noise level estimation PnP-ADMM (NLPnP) algorithm. We also prove that the iterative sequence generated by the algorithm is a Cauchy sequence, thereby guaranteeing its convergence. Additionally, experiments on grayscale images, color images, and various image datasets demonstrate the effectiveness of the algorithm in image restoration tasks, such as image deblurring, super-resolution, and image inpainting. Numerically, the NLPnP algorithm achieves higher peak signal-to-noise ratio and structural similarity values compared to the PnP algorithm.},
  archive      = {J_JMIV},
  author       = {Liu, Hanxin and Fang, Zhuang and Tang, Liming and Lu, Wenjing},
  doi          = {10.1007/s10851-025-01256-8},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {8},
  number       = {4},
  pages        = {1-24},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Plug-and-play ADMM for embedded noise level estimation},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unrestricted sequential discrete morphological neural networks. <em>JMIV</em>, <em>67</em>(4), 1-22. (<a href='https://doi.org/10.1007/s10851-025-01255-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There have been attempts to insert mathematical morphology (MM) operators into convolutional neural networks (CNN), and the most successful endeavor to date has been the morphological neural networks (MNN). Although MNN have performed better than CNN in solving some problems, they inherit their black-box nature. Furthermore, in the case of binary images, they are approximations that lose the Boolean lattice structure of MM operators and, thus, it is not possible to represent a specific class of W-operators with desired properties. In a recent work, we proposed the discrete morphological neural networks (DMNN) for binary image transformation to represent specific classes of W-operators and estimate them via machine learning. We also proposed a stochastic lattice descent algorithm (SLDA) to learn the parameters of canonical discrete morphological neural networks (CDMNN), whose architecture is composed only of operators that can be decomposed as the supremum, infimum, and complement of erosions and dilations. In this paper, we propose an algorithm to learn unrestricted sequential DMNN (USDMNN) for image processing and binary classification, whose architecture is given by the composition of general W-operators. With an efficient implementation that leverages GPUs for matrix computations, we illustrate the algorithm in an example of image transformation, for learning the transition W-operator of the Conway’s Game of Life and for classifying the manuscript digits of the MNIST dataset. The performance of USDMNN on the MNIST dataset was compared with a CNN and the USDMNN performed better when trained with small sample sizes. These examples illustrate the robustness of the method to noise and its advantages over CNN related to the ability to learn with fewer samples and the interpretability of the results.},
  archive      = {J_JMIV},
  author       = {Marcondes, Diego and Feldman, Mariana and Barrera, Junior},
  doi          = {10.1007/s10851-025-01255-9},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {8},
  number       = {4},
  pages        = {1-22},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Unrestricted sequential discrete morphological neural networks},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convexity in ReLU neural networks: Beyond ICNNs?. <em>JMIV</em>, <em>67</em>(4), 1-32. (<a href='https://doi.org/10.1007/s10851-025-01253-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convex functions and their gradients play a critical role in mathematical imaging, from proximal optimization to Optimal Transport. The successes of deep learning has led many to use learning-based methods, where fixed functions or operators are replaced by learned neural networks. Regardless of their empirical superiority, establishing rigorous guarantees for these methods often requires to impose structural constraints on neural architectures, in particular convexity. The most popular way to do so is to use so-called Input Convex Neural Networks (ICNNs). In order to explore the expressivity of ICNNs, we provide necessary and sufficient conditions for a ReLU neural network to be convex. Such characterizations are based on product of weights and activations, and write nicely for any architecture in the path-lifting framework. As particular applications, we study our characterizations in depth for 1 and 2-hidden-layer neural networks: we show that every convex function implemented by a 1-hidden-layer ReLU network can be also expressed by an ICNN with the same architecture; however this property no longer holds with more layers. Finally, we provide a numerical procedure that allows an exact check of convexity for ReLU neural networks with a large number of affine regions.},
  archive      = {J_JMIV},
  author       = {Gagneux, Anne and Massias, Mathurin and Soubies, Emmanuel and Gribonval, Rémi},
  doi          = {10.1007/s10851-025-01253-x},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {8},
  number       = {4},
  pages        = {1-32},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Convexity in ReLU neural networks: Beyond ICNNs?},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchy-based fuzzy segmentation and marker learning layer: Theory and algorithms. <em>JMIV</em>, <em>67</em>(4), 1-25. (<a href='https://doi.org/10.1007/s10851-025-01251-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation is inherently challenging because it is often difficult to automatically identify the object of interest in an image. To mitigate this, human-provided markers can be incorporated into the segmentation process, greatly improving accuracy. However, human interaction is an expensive resource and methods that reduce effort in interactive segmentation are of great interest. In this work, we introduce a novel marker-based segmentation layer for deep neural networks, enabling end-to-end training of a marker creation network. Our training methodology includes a loss function with two main components: (i) segmentation loss using the new differentiable segmentation layer and (ii) a set of regularization functions that ensure the generated markers have the desired shape properties. We show that by using the proposed method, the network can automatically generate markers that achieve effective segmentation and have desirable shape characteristics. We validate our results in the training dataset and in five unseen datasets.},
  archive      = {J_JMIV},
  author       = {Barbosa da Fonseca, Gabriel and Negrel, Romain and Perret, Benjamin and Cousty, Jean and Jamil F. Guimarães, Silvio},
  doi          = {10.1007/s10851-025-01251-z},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {8},
  number       = {4},
  pages        = {1-25},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Hierarchy-based fuzzy segmentation and marker learning layer: Theory and algorithms},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing dynamic CT image reconstruction with neural fields and optical flow. <em>JMIV</em>, <em>67</em>(4), 1-22. (<a href='https://doi.org/10.1007/s10851-025-01259-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate image reconstruction for dynamic computed tomography. The motion of the target with respect to the measurement acquisition rate leads to highly resolved in time but highly undersampled in space measurements. Such problems pose a major challenge: not accounting for the dynamics of the process leads to a poor reconstruction with non-realistic motion. Variational approaches that penalize time evolution have been proposed to relate subsequent frames and improve image quality based on classical grid-based discretizations. Neural fields have emerged as a novel way to parameterize the quantity of interest using a neural network with a low-dimensional input, benefiting from being lightweight, continuous, and biased towards smooth representations. The latter property has been exploited when solving dynamic inverse problems with neural fields by minimizing a data-fidelity term only. We investigate and show the benefits of introducing explicit motion regularizers for dynamic inverse problems based on partial differential equations, namely the optical flow equation, for the optimization of neural fields. We compare it against its unregularized counterpart and show the improvements in the reconstruction. We also compare neural fields against a grid-based solver and show that the former outperforms the latter in terms of PSNR in this task.},
  archive      = {J_JMIV},
  author       = {Arratia, Pablo and Ehrhardt, Matthias J. and Kreusser, Lisa},
  doi          = {10.1007/s10851-025-01259-5},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {8},
  number       = {4},
  pages        = {1-22},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Enhancing dynamic CT image reconstruction with neural fields and optical flow},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear optimal transport subspaces for point set classification. <em>JMIV</em>, <em>67</em>(4), 1-13. (<a href='https://doi.org/10.1007/s10851-025-01261-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from point sets is an essential component in many computer vision and machine learning applications. Native, unordered, and permutation-invariant set structure space is challenging to model, particularly for point set classification under spatial deformations. Here, we propose a framework for classifying point sets experiencing certain types of spatial deformations, with a particular emphasis on datasets featuring affine deformations. Our approach employs the linear optimal transport (LOT) transform to obtain a linear embedding of set-structured data. Utilizing the mathematical properties of the LOT transform, we demonstrate its capacity to accommodate variations in point sets by constructing a convex data space, effectively simplifying point set classification problems. Our method, which employs a nearest-subspace algorithm in the LOT space, demonstrates label efficiency, non-iterative behavior, and requires no hyperparameter tuning. It achieves competitive accuracies compared to state-of-the-art methods across various point set classification tasks. Furthermore, our approach exhibits robustness in out-of-distribution scenarios where training and test distributions vary in terms of deformation magnitudes.},
  archive      = {J_JMIV},
  author       = {Shifat-E-Rabbi, Mohammad and Pathan, Naqib Sad and Li, Shiying and Zhuang, Yan and Rubaiyat, Abu Hasnat Mohammad and Rohde, Gustavo K.},
  doi          = {10.1007/s10851-025-01261-x},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {8},
  number       = {4},
  pages        = {1-13},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Linear optimal transport subspaces for point set classification},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unified theory for joint covariance properties under geometric image transformations for spatio-temporal receptive fields according to the generalized gaussian derivative model for visual receptive fields. <em>JMIV</em>, <em>67</em>(4), 1-49. (<a href='https://doi.org/10.1007/s10851-025-01247-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The influence of natural image transformations on receptive field responses is crucial for modelling visual operations in computer vision and biological vision. In this regard, covariance properties with respect to geometric image transformations in the earliest layers of the visual hierarchy are essential for expressing robust image operations and for formulating invariant visual operations at higher levels. This paper defines and proves a set of joint covariance properties for spatio-temporal receptive fields in terms of spatio-temporal derivative operators applied to spatio-temporally smoothed image data under compositions of spatial scaling transformations, spatial affine transformations, Galilean transformations and temporal scaling transformations. Specifically, the derived relations show how the parameters of the receptive fields need to be transformed, in order to match the output from spatio-temporal receptive fields under composed spatio-temporal image transformations. For this purpose, we also fundamentally extend the notion of scale-normalized derivatives to affine-normalized derivatives, which are computed based on spatial smoothing with affine Gaussian kernels, and analyse the covariance properties of the resulting affine-normalized derivatives for the affine group as well as for important subgroups thereof. We conclude with a geometric analysis, showing how the derived joint covariance properties make it possible to relate or match spatio-temporal receptive field responses, when observing, possibly moving, local surface patches from different views, under locally linearized perspective or projective transformations, as well as when observing different instances of spatio-temporal events, that may occur either faster or slower between different views of similar spatio-temporal events. We do furthermore describe how the parameters in the studied composed spatio-temporal image transformation models directly relate to geometric entities in the image formation process and the 3-D scene structure. In these ways, this paper presents a unified theory for the interaction between spatio-temporal receptive field responses and geometric image transformations, with generic implications for both: (i) designing computer vision systems that are to compute image features and image descriptors, to be robust under the variabilities in spatio-temporal image structures as caused by geometric image transformations, and (ii) understanding fundamental geometric constraints for interpreting and constructing models of biological vision.},
  archive      = {J_JMIV},
  author       = {Lindeberg, Tony},
  doi          = {10.1007/s10851-025-01247-9},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {8},
  number       = {4},
  pages        = {1-49},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Unified theory for joint covariance properties under geometric image transformations for spatio-temporal receptive fields according to the generalized gaussian derivative model for visual receptive fields},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Texture matching GAN for CT image enhancement. <em>JMIV</em>, <em>67</em>(4), 1-15. (<a href='https://doi.org/10.1007/s10851-025-01260-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are commonly used to denoise and sharpen X-ray computed tomography (CT) images with the goal of reducing patient X-ray dosage while maintaining reconstruction quality. However, naive application of DNN-based methods can result in image texture that is undesirable in clinical applications. Alternatively, generative adversarial network (GAN)-based methods can produce appropriate texture, but naive application of GANs can introduce inaccurate or even unreal image detail. In this paper, we propose a texture matching generative adversarial network (TMGAN) that enhances CT images while generating an image texture that can be matched to a target texture. We use parallel generators to separate anatomical features from the generated texture, which allows the GAN to be trained to match the desired texture without directly affecting the underlying CT image. We demonstrate that TMGAN generates enhanced image quality while also producing image texture that is desirable for clinical application.},
  archive      = {J_JMIV},
  author       = {Nagare, Madhuri and Buzzard, Gregery T. and Bouman, Charles A.},
  doi          = {10.1007/s10851-025-01260-y},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {8},
  number       = {4},
  pages        = {1-15},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Texture matching GAN for CT image enhancement},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Practical operator sketching framework for accelerating iterative data-driven solutions in linear inverse problems. <em>JMIV</em>, <em>67</em>(4), 1-20. (<a href='https://doi.org/10.1007/s10851-025-01263-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new operator sketching paradigm for designing efficient iterative data-driven reconstruction (IDR) schemes, such as plug-and-play algorithms and deep unrolling networks. These IDR schemes are the state-of-the-art solutions for imaging inverse problems. However, for high-dimensional imaging tasks, such as X-ray CT, PET and MRI imaging, these IDR schemes typically become inefficient in terms of computation, due to the need to compute the high-dimensional forward and adjoint operators multiple times. In this work, we introduce a universal dimensionality reduction framework for accelerating IDR schemes in solving imaging inverse problems, based on leveraging the sketching techniques from stochastic optimization. Using this framework, we derive several accelerated IDR schemes, including the plug-and-play multistage sketched gradient (PnP-MS2G) and sketching-based primal–dual (LSPD and SkLSPD) deep unrolling networks. Meanwhile, to fully accelerate PnP schemes when the denoisers are computationally expensive, we further propose novel stochastic lazy denoising schemes (Lazy-PnP and Lazy-PnP-EQ), leveraging the ProxSkip scheme in optimization and equivariant image denoisers, to significantly enhance the practicality and efficiency of PnP algorithms. We provide theoretical analysis for recovery guarantees of instances of the proposed framework. Our numerical experiments on natural image processing and tomographic image reconstruction demonstrate the remarkable effectiveness of our sketched IDR schemes.},
  archive      = {J_JMIV},
  author       = {Tang, Junqi and Xu, Guixian and Mukherjee, Subhadip and Schönlieb, Carola-Bibiane},
  doi          = {10.1007/s10851-025-01263-9},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {8},
  number       = {4},
  pages        = {1-20},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Practical operator sketching framework for accelerating iterative data-driven solutions in linear inverse problems},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural field equations with time-periodic external inputs and some applications to visual processing. <em>JMIV</em>, <em>67</em>(4), 1-19. (<a href='https://doi.org/10.1007/s10851-025-01257-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this work is to present a mathematical framework for the study of flickering inputs in visual processing tasks. When combined with geometric patterns, these inputs influence and induce interesting psychophysical phenomena, such as the MacKay and the Billock–Tsou effects, where the subjects perceive specific afterimages typically modulated by the flickering frequency. Due to the symmetry-breaking structure of the inputs, classical bifurcation theory and multi-scale analysis techniques are not very effective in our context. We thus take an approach based on the input–output framework of control theory for Amari-type neural fields. This allows us to prove that, when driven by periodic inputs, the dynamics converge to a periodic state. Moreover, we study under which assumptions these nonlinear dynamics can be effectively linearized, and in this case we present a precise approximation of the integral kernel for short-range excitatory and long-range inhibitory neuronal interactions. Finally, for inputs concentrated at the center of the visual field with a flickering background, we directly relate the width of the illusory contours appearing in the afterimage with both the flickering frequency and the strength of the inhibition.},
  archive      = {J_JMIV},
  author       = {Bolelli, M. Virginia and Prandi, Dario},
  doi          = {10.1007/s10851-025-01257-7},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {8},
  number       = {4},
  pages        = {1-19},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Neural field equations with time-periodic external inputs and some applications to visual processing},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability bounds for the unfolded Forward–Backward algorithm. <em>JMIV</em>, <em>67</em>(4), 1-20. (<a href='https://doi.org/10.1007/s10851-025-01258-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a neural network architecture designed to solve inverse problems where the degradation operator is linear and known. This architecture is constructed by unrolling a forward–backward algorithm derived from the minimization of an objective function that combines a data-fidelity term, a Tikhonov-type regularization term, and a potentially nonsmooth convex penalty. The robustness of this inversion method to input perturbations is analyzed theoretically. Ensuring robustness complies with the principles of inverse problem theory, as it ensures both the continuity of the inversion method and the resilience to small noise—a critical property given the known vulnerability of deep neural networks to adversarial perturbations. A key novelty of our work lies in examining the robustness of the proposed network to perturbations in its bias, which represents the observed data in the inverse problem. Additionally, we provide numerical illustrations of the analytical Lipschitz bounds derived in our analysis.},
  archive      = {J_JMIV},
  author       = {Chouzenoux, Emilie and Valle, Cecile Della and Pesquet, Jean-Christophe},
  doi          = {10.1007/s10851-025-01258-6},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {8},
  number       = {4},
  pages        = {1-20},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Stability bounds for the unfolded Forward–Backward algorithm},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Randomized primal-dual algorithm with arbitrary sampling: Convergence theory and applications to parallel MRI. <em>JMIV</em>, <em>67</em>(3), 1-17. (<a href='https://doi.org/10.1007/s10851-025-01231-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic Primal-Dual Hybrid Gradient (SPDHG) is an algorithm proposed by Chambolle et al. (SIAM J Optim 28:2783–2808) to efficiently solve a wide class of nonsmooth large-scale optimization problems. Alacaoglu et al. (SIAM J Optim 32:1288–1318, 2022) filled an important gap and proved its almost sure convergence for serial sampling. In this paper, we study the performance of SPDHG with arbitrary sampling (not necessarily serial sampling) and its applications to parallel magnetic resonance imaging (MRI), where data from different coils are randomly selected at each iteration. In order to do this, we extend the convergence result of Alacaoglu et al. and prove the almost sure convergence of SPDHG for any arbitrary sampling. We then apply SPDHG on real MRI data using a wide range of random sampling methods and compare its performance across a range of settings, including mini-batch size and step size parameters. We show that the sampling can significantly affect the convergence speed of SPDHG and that for many cases an optimal sampling can be identified.},
  archive      = {J_JMIV},
  author       = {Gutierrez, Eric B. and Delplancke, Claire and Ehrhardt, Matthias J.},
  doi          = {10.1007/s10851-025-01231-3},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {3},
  pages        = {1-17},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Randomized primal-dual algorithm with arbitrary sampling: Convergence theory and applications to parallel MRI},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decomposition of rational discrete hyperplanes. <em>JMIV</em>, <em>67</em>(3), 1-17. (<a href='https://doi.org/10.1007/s10851-025-01242-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is a contribution to the study of rational discrete hyperplanes, i.e., sets of points with integer coordinates lying between two parallel planes. Up to translation and symmetry, they are completely determined by a nonzero normal vector $$\textbf{a}\in {\mathbbm {N}}^d$$ . If $$\Vert \textbf{a}\Vert _1 > 2^{d-1}$$ , there are two approximations $$\textbf{b},\textbf{c}\in {\mathbbm {N}}^d$$ of $$\textbf{a}$$ , satisfying $$\textbf{a}=\textbf{b}+\textbf{c}$$ , such that the discrete hyperplane plane of normal $$\textbf{a}$$ can be partitioned into two disjoint sets having, respectively, the combinatorial structure of discrete hyperplanes of normal $$\textbf{b}$$ and $$\textbf{c}$$ . The result is based on explicit geometrical mappings described by unimodular $$d\times d$$ matrices derived from $$\textbf{a}$$ and its approximations. It may have practical interest in discrete geometry for the generation and recognition of discrete hyperplanes as well as for the decomposition of boundaries of discrete sets into planar patches.},
  archive      = {J_JMIV},
  author       = {Roussillon, Tristan},
  doi          = {10.1007/s10851-025-01242-0},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {3},
  pages        = {1-17},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Decomposition of rational discrete hyperplanes},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cell counting with trainable h-maxima and connected component layers. <em>JMIV</em>, <em>67</em>(3), 1-27. (<a href='https://doi.org/10.1007/s10851-025-01243-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bright objects on a dark background, such as cells in microscopy images, can sometimes be modeled as maxima of sufficient dynamic, called h-maxima. Such a model could be sufficient to count these objects in images, provided we know the dynamic threshold that tells apart actual objects from irrelevant maxima. In a previous study we introduced a neural architecture that includes a morphological pipeline counting the number of h-maxima in an image, preceded by a classical CNN which estimates the dynamic h yielding the right number of objects. This was made possible by geodesic reconstruction layers, and a new module counting connected components. The resulting architecture could be trained end-to-end to count cells by minimizing a loss function focusing mainly on an intermediate image and very marginally on the counting errors. In the present paper, we extend that work with a detailed theoretical analysis of the derivability of such pipeline, and with more cell counting experiments on different datasets. Our analysis explains why it is difficult to train the proposed pipeline when penalizing counting errors, and ends up with a solution to that challenge. Our experiments show that our approach can obtain results comparable to the state of the art with much fewer parameters and an increased interpretability of the model.},
  archive      = {J_JMIV},
  author       = {Blusseau, Samy and Liu, Xiaohu and Velasco-Forero, Santiago},
  doi          = {10.1007/s10851-025-01243-z},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {3},
  pages        = {1-27},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Cell counting with trainable h-maxima and connected component layers},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear and nonlinear generative models for ‘Zero-shot’ image denoising in the limit of few photons. <em>JMIV</em>, <em>67</em>(3), 1-17. (<a href='https://doi.org/10.1007/s10851-025-01244-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images acquired in very low-light conditions have (on average) just few photons recorded per image pixel. Consequently, such images are very noisy, and any image enhancement is considered difficult. In this work, we study denoising of very low-light images, and we consider approaches that are applicable when solely the noisy image itself is available for training. While applicability in such a ‘zero-shot’ setting is attractive in domains with few data and high noise, suitable methods have to overcome considerable challenges. Here, we primarily investigate two methods. Both assume observed data to follow a Poisson distribution, which canonically models photon counts at low lights, and both assume a prior which can flexibly model sparsity. However, one of the used probabilistic generative models assumes a linear superposition to reconstruct image patches, while the other assumes a fixed nonlinear superposition more aligned with occlusions. For both models, parameters are estimated based on an approximate maximum likelihood approach. Concretely, we derive iterative fixed-point equations for parameter updates, which are combined with a recently suggested variational optimization approach. We are specifically interested in the differences between the two approaches as well as in their performance compared to other ‘zero-shot’ algorithms that can operate in the considered setting. In numerical experiments, we found both models to be very competitive for denoising benchmarks. Moreover, the nonlinear model was observed to be preferable to the linear one in most cases. For some settings, we here report new state-of-the-art results, which also recommends the investigated methods for count data beyond low-light images.},
  archive      = {J_JMIV},
  author       = {Mousavi, Hamid and Lücke, Jörg},
  doi          = {10.1007/s10851-025-01244-y},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {3},
  pages        = {1-17},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Linear and nonlinear generative models for ‘Zero-shot’ image denoising in the limit of few photons},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scale generalisation properties of extended scale-covariant and scale-invariant gaussian derivative networks on image datasets with spatial scaling variations. <em>JMIV</em>, <em>67</em>(3), 1-39. (<a href='https://doi.org/10.1007/s10851-025-01245-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the variabilities in image structures caused by perspective scaling transformations, it is essential for deep networks to have an ability to generalise to scales not seen during training. This paper presents an in-depth analysis of the scale generalisation properties of the scale-covariant and scale-invariant Gaussian derivative networks, complemented with both conceptual and algorithmic extensions. For this purpose, Gaussian derivative networks (GaussDerNets) are evaluated on new rescaled versions of the Fashion-MNIST and the CIFAR-10 datasets, with spatial scaling variations over a factor of 4 in the testing data, that are not present in the training data. Additionally, evaluations on the previously existing STIR datasets show that the GaussDerNets achieve better scale generalisation than previously reported for these datasets for other types of deep networks. We first experimentally demonstrate that the GaussDerNets have quite good scale generalisation properties on the new datasets and that average pooling of feature responses over scales may sometimes also lead to better results than the previously used approach of max pooling over scales. Then, we demonstrate that using a spatial max pooling mechanism after the final layer enables localisation of non-centred objects in the image domain, with maintained scale generalisation properties. We also show that regularisation during training, by applying dropout across the scale channels, referred to as scale-channel dropout, improves both the performance and the scale generalisation. In additional ablation studies, we show that, for the rescaled CIFAR-10 dataset, basing the layers in the GaussDerNets on derivatives up to order three leads to better performance and scale generalisation for coarser scales, whereas networks based on derivatives up to order two achieve better scale generalisation for finer scales. Moreover, we demonstrate that discretisations of GaussDerNets based on the discrete analogue of the Gaussian kernel in combination with central difference operators perform best or among the best, compared to a set of other discrete approximations of the Gaussian derivative kernels. Furthermore, we show that the improvement in performance obtained by learning the scale values of the Gaussian derivatives, as opposed to using the previously proposed choice of a fixed logarithmic distribution of the scale levels, is usually only minor, thus supporting the previously postulated choice of using a logarithmic distribution as a very reasonable prior. Finally, by visualising the activation maps and the learned receptive fields, we demonstrate that the GaussDerNets have very good explainability properties.},
  archive      = {J_JMIV},
  author       = {Perzanowski, Andrzej and Lindeberg, Tony},
  doi          = {10.1007/s10851-025-01245-x},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {3},
  pages        = {1-39},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Scale generalisation properties of extended scale-covariant and scale-invariant gaussian derivative networks on image datasets with spatial scaling variations},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LAMA-net: A convergent network architecture for dual-domain reconstruction. <em>JMIV</em>, <em>67</em>(3), 1-17. (<a href='https://doi.org/10.1007/s10851-025-01249-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a learnable variational model that learns the features and leverages complementary information from both image and measurement domains for image reconstruction. In particular, we introduce a learned alternating minimization algorithm (LAMA) from our prior work, which tackles two-block non-convex and non-smooth optimization problems by incorporating a residual learning architecture in a proximal alternating framework. In this work, our goal is to provide a complete and rigorous convergence proof of LAMA and show that all accumulation points of a specified subsequence of LAMA must be Clarke stationary points of the problem. LAMA directly yields a highly interpretable neural network architecture called LAMA-Net. Notably, in addition to the results shown in our prior work, we demonstrate that the convergence property of LAMA yields outstanding stability and robustness of LAMA-Net in this work. We also show that the performance of LAMA-Net can be further improved by integrating a properly designed network that generates suitable initials, which we call iLAMA-Net. To evaluate LAMA-Net/iLAMA-Net, we conduct several experiments and compare them with several state-of-the-art methods on popular benchmark datasets for sparse-view computed tomography.},
  archive      = {J_JMIV},
  author       = {Ding, Chi and Zhang, Qingchao and Wang, Ge and Ye, Xiaojing and Chen, Yunmei},
  doi          = {10.1007/s10851-025-01249-7},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {3},
  pages        = {1-17},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {LAMA-net: A convergent network architecture for dual-domain reconstruction},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient maximum euclidean distance transform computation in component trees using the differential image foresting transform. <em>JMIV</em>, <em>67</em>(3), 1-23. (<a href='https://doi.org/10.1007/s10851-025-01248-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distance transform is a crucial technique in binary image processing, assigning the distance to the nearest contour to each foreground pixel. In this extended version of our previous work, we enhance our method for computing the maximum distance transform (DT) value, now utilizing the optimized differential image foresting transform (DIFT) and improved contour extraction processes. These advancements enable more efficient computation of the maximum DT value across all connected components of a grayscale image, significantly reducing computational time by intelligently reusing DIFT trees rooted at contour points (DIFT seeds). Our optimized algorithm now achieves processing speeds that are twice as fast as our previous differential method. The proposed attribute, maximum distance, which measures the thickness of objects within the image, has proven pivotal in different image processing approaches. We showcase this through detailed illustrations of attribute opening, extinction value filters, watershed, and ultimate attribute openings.},
  archive      = {J_JMIV},
  author       = {Silva, Dennis J. and Miranda, Paulo A. V. and Alves, Wonder A. L. and Hashimoto, Ronaldo F. and Kosinka, Jiří and Roerdink, Jos B. T. M.},
  doi          = {10.1007/s10851-025-01248-8},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {3},
  pages        = {1-23},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Efficient maximum euclidean distance transform computation in component trees using the differential image foresting transform},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative assignment flows for representing and learning joint distributions of discrete data. <em>JMIV</em>, <em>67</em>(3), 1-24. (<a href='https://doi.org/10.1007/s10851-025-01239-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel generative model for the representation of joint probability distributions of a possibly large number of discrete random variables. The approach uses measure transport by randomized assignment flows on the statistical submanifold of factorizing distributions, which enables to represent and sample efficiently from any target distribution and to assess the likelihood of unseen data points. The complexity of the target distribution only depends on the parametrization of the affinity function of the dynamical assignment flow system. Our model can be trained in a simulation-free manner by conditional Riemannian flow matching, using the training data encoded as geodesics on the assignment manifold in a closed form, with respect to the e-connection of information geometry. Numerical experiments devoted to distributions of structured image labelings demonstrate the applicability to large-scale problems, which may include discrete distributions in other application areas. Performance measures show that our approach scales better with the increasing number of classes than the recent related work.},
  archive      = {J_JMIV},
  author       = {Boll, Bastian and Gonzalez-Alvarado, Daniel and Petra, Stefania and Schnörr, Christoph},
  doi          = {10.1007/s10851-025-01239-9},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {3},
  pages        = {1-24},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Generative assignment flows for representing and learning joint distributions of discrete data},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the role of datasets in the generalization of motion deblurring methods to real images. <em>JMIV</em>, <em>67</em>(3), 1-18. (<a href='https://doi.org/10.1007/s10851-025-01246-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Successfully training end-to-end deep networks for real motion deblurring requires datasets of sharp/blurred image pairs that are realistic and diverse enough to achieve generalization to real blurred images. Obtaining such datasets remains a challenging task. In this paper, we first review the limitations of existing deblurring benchmark datasets and analyze the underlying causes for deblurring networks’ lack of generalization to blurry images in the wild. Based on this analysis, we propose an efficient procedural methodology to generate sharp/blurred image pairs based on a simple yet effective model. This allows for generating virtually unlimited diverse training pairs mimicking realistic blur properties. We demonstrate the effectiveness of the proposed dataset by training existing deblurring architectures on the simulated pairs and performing cross-dataset evaluation on three standard datasets of real blurred images. When training with the proposed method, we observed superior generalization performance for the ultimate task of deblurring real motion-blurred photographs of dynamic scenes.},
  archive      = {J_JMIV},
  author       = {Carbajal, Guillermo and Vitoria, Patricia and Lezama, José and Musé, Pablo},
  doi          = {10.1007/s10851-025-01246-w},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {3},
  pages        = {1-18},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Assessing the role of datasets in the generalization of motion deblurring methods to real images},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The maximum cover with rotating field of view. <em>JMIV</em>, <em>67</em>(3), 1-15. (<a href='https://doi.org/10.1007/s10851-025-01250-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the maximum cover problem of a rotating field of view (FOV) with a convex polygon $$\mathcal {P}$$ with n vertices. The problem is defined as determining the optimal rotation angle $$\theta $$ of the FOV, characterised by a fixed centre and inner angle $$\phi $$ , such that the intersection between the FOV and $$\mathcal {P}$$ has the maximum possible area. This problem is relevant for applications in visibility optimisation and uncertainty reduction in localisation tasks. We present a theoretical framework and a corresponding algorithm to approximate the value of the maximum, ensuring that the solution is close to the optimal within the specified precision. The intersection between the rotating FOV and $$\mathcal {P}$$ forms a convex polygon whose number of vertices varies with the rotation angle $$\theta $$ . We analytically derive the area of the intersection when it takes its simplest form, a quadrilateral, as a two-variable function $$A(\theta ,\phi )$$ . The function $$A(\theta ,\phi )$$ , with the angle of rotation $$\theta $$ and the fixed inner angle $$\phi $$ , denoted as $$A_{\phi }(\theta )$$ , is non-monotonic and has multiple local extreme points inside of a given domain which poses a challenge in identifying them and approximating the global maximum. We found an alternative way to express it by various compositions of a function $$A_{\theta }(\phi )$$ (with a restricted inner angle $$\phi $$ and a fixed direction $$\theta $$ ). We show that $$A_{\theta }(\phi )$$ has an analytical solution in the special case of a two-sector intersection and later provides a constrictive solution for the original problem. We develop an algorithm that approximates the direction of the field of view, with precision $$\varepsilon >1$$ , and complexity $$\mathcal {O}(n(\log {n}+(\log {\varepsilon })/\phi ))$$ .},
  archive      = {J_JMIV},
  author       = {Potapov, Igor and Ralph, Jason F. and Triommatis, Theofilos},
  doi          = {10.1007/s10851-025-01250-0},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {3},
  pages        = {1-15},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {The maximum cover with rotating field of view},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite rotations on $${\mathbb {Z}}^{2}$$: A hierarchical framework for bijectivity analysis. <em>JMIV</em>, <em>67</em>(3), 1-26. (<a href='https://doi.org/10.1007/s10851-025-01233-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Euclidean spaces ( $${\mathbb {R}}^{d}$$ , $$d \geqslant 2$$ ), rotations preserve distances and angles; they are also bijective. These important properties are no longer guaranteed when rotations are considered in discrete spaces. This is especially the case in the Cartesian spaces ( $${\mathbb {Z}}^{d}$$ , $$d \geqslant 2$$ ), where rotations are, however, crucial for various applications, from image processing to computer graphics. In this article, we deal with the issue of bijectivity of discrete rotations in the 2-dimensional case ( $${\mathbb {Z}}^{2}$$ ). We contribute to the state of the art from two points of view. First, we investigate the structure of the (finite and infinite) rotations in $${\mathbb {Z}}^{2}$$ , and we shed light on the nature of this combinatorial space, which is analogue to a watershed tree. Second, we focus on the finite rotations, i.e. rotations that act on (finite) Euclidean balls instead of the (infinite) set $${\mathbb {Z}}^{2}$$ . Under these hypotheses, we investigate the bijective rotations either as the restrictions of bijective rotations on $${\mathbb {Z}}^{2}$$ , or as injective rotations on the Euclidean balls (thus bijective from their domain to their image). We provide two algorithmic schemes for building the combinatorial space of these finite rotations. Codes are freely available at the following url: https://github.com/ngophuc/DiscreteRotationSpace .},
  archive      = {J_JMIV},
  author       = {Passat, Nicolas and Ngo, Phuc and Kenmochi, Yukiko},
  doi          = {10.1007/s10851-025-01233-1},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {6},
  number       = {3},
  pages        = {1-26},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Finite rotations on $${\mathbb {Z}}^{2}$$: A hierarchical framework for bijectivity analysis},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wavelet-based multiscale flow for realistic image deformation in the large diffeomorphic deformation model framework. <em>JMIV</em>, <em>67</em>(2), 1-28. (<a href='https://doi.org/10.1007/s10851-024-01219-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating accurate high-dimensional transformations remains very challenging, especially in a clinical setting. In this paper, we introduce a multiscale parameterization of deformations to enhance registration and atlas estimation in the large deformation diffeomorphic metric mapping framework. Using the Haar wavelet transform, a multiscale representation of the initial velocity fields is computed to optimize transformations in a coarse-to-fine fashion. This additional layer of spatial regularization does not modify the underlying model of deformations. As such, it preserves the original kernel Hilbert space structure of the velocity fields, enabling the algorithm to perform efficient gradient descent. Numerical experiments on several datasets, including abnormal fetal brain images, show that compared to the original algorithm, the coarse-to-fine strategy reaches higher performance and yields template images that preserve important details while avoiding unrealistic features. This highly versatile strategy can easily be applied to other mathematical frameworks for almost no additional computational cost.},
  archive      = {J_JMIV},
  author       = {Gaudfernau, Fleur and Blondiaux, Eléonore and Allassonnière, Stéphanie and Le Pennec, Erwan},
  doi          = {10.1007/s10851-024-01219-5},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-28},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Wavelet-based multiscale flow for realistic image deformation in the large diffeomorphic deformation model framework},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding the deltoid phenomenon in the perspective 3-point (P3P) problem. <em>JMIV</em>, <em>67</em>(2), 1-14. (<a href='https://doi.org/10.1007/s10851-024-01228-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concerning the perspective 3-point (P3P) problem, Grunert’s system of three quadratic equations has a repeated solution if and only if the cubic polynomial introduced by Finsterwalder has a repeated root. This polynomial is here shown to be obtainable from a particularly simple cubic polynomial with complex coefficients via a simple Möbius transformation. This provides surprising geometric insight into the P3P problem. In particular, (1) the discriminant of Finsterwalder’s polynomial can be written using the formula for the standard deltoid curve, and (2) this discriminant, when regarded as a function of camera position, vanishes on a surface that approaches a deltoid shape when the camera is moved infinitely far from the control points in a direction perpendicular to the control points plane (the “limit case"). These two facts have been previously reported, but obscure reasoning was required to establish them. In contrast, the present article uses the newly discovered cubic polynomial to easily produce the first fact, which then provides a basis for better understanding the second fact. Also presented are quartic polynomials whose real roots are the P3P solution point coordinates. A detailed geometric description of the P3P solution points in the “limit case" is also supplied.},
  archive      = {J_JMIV},
  author       = {Rieck, Michael Q.},
  doi          = {10.1007/s10851-024-01228-4},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-14},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Understanding the deltoid phenomenon in the perspective 3-point (P3P) problem},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PDE-CNNs: Axiomatic derivations and applications. <em>JMIV</em>, <em>67</em>(2), 1-25. (<a href='https://doi.org/10.1007/s10851-025-01230-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PDE-based group convolutional neural networks (PDE-G-CNNs) use solvers of evolution PDEs as substitutes for the conventional components in G-CNNs. PDE-G-CNNs can offer several benefits simultaneously: fewer parameters, inherent equivariance, better accuracy, and data efficiency. In this article, we focus on Euclidean equivariant PDE-G-CNNs where the feature maps are two-dimensional throughout. We call this variant of the framework a PDE-CNN. From a machine learning perspective, we list several practically desirable axioms and derive from these which PDEs should be used in a PDE-CNN, this being our main contribution. Our approach to geometric learning via PDEs is inspired by the axioms of scale-space theory, which we generalize by introducing semifield-valued signals. Our theory reveals new PDEs that can be used in PDE-CNNs and we experimentally examine what impact these have on the accuracy of PDE-CNNs. We also confirm for small networks that PDE-CNNs offer fewer parameters, increased accuracy, and better data efficiency when compared to CNNs.},
  archive      = {J_JMIV},
  author       = {Bellaard, Gijs and Sakata, Sei and Smets, Bart M. N. and Duits, Remco},
  doi          = {10.1007/s10851-025-01230-4},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-25},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {PDE-CNNs: Axiomatic derivations and applications},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale hierarchical decomposition methods for images corrupted by multiplicative noise. <em>JMIV</em>, <em>67</em>(2), 1-27. (<a href='https://doi.org/10.1007/s10851-024-01220-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recovering images corrupted by multiplicative noise is a well-known challenging task. Motivated by the success of multiscale hierarchical decomposition methods (MHDM) in image processing, we adapt a variety of both classical and new multiplicative noise removing models to the MHDM form. On the basis of previous work, we further present a tight and a refined version of the corresponding multiplicative MHDM. We discuss existence and uniqueness of solutions for the proposed models and, additionally, provide convergence properties. Moreover, we present a discrepancy principle stopping criterion which prevents recovering excess noise in the multiscale reconstruction. Through comprehensive numerical experiments and comparisons, we qualitatively and quantitatively evaluate the validity of all proposed models for denoising and deblurring images degraded by multiplicative noise. By construction, these multiplicative multiscale hierarchical decomposition methods have the added benefit of recovering many scales of an image, which can provide features of interest beyond image denoising.},
  archive      = {J_JMIV},
  author       = {Barnett, Joel and Li, Wen and Resmerita, Elena and Vese, Luminita},
  doi          = {10.1007/s10851-024-01220-y},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-27},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Multiscale hierarchical decomposition methods for images corrupted by multiplicative noise},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrected Laplace–Beltrami operators for digital surfaces. <em>JMIV</em>, <em>67</em>(2), 1-16. (<a href='https://doi.org/10.1007/s10851-024-01226-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defining consistent calculus frameworks on discrete meshes is useful for processing the geometry of meshes or model numerical simulations and variational problems onto them. However, digital surfaces (boundary of voxels) cannot benefit directly from the classical mesh calculus frameworks, since their vertex and face geometry is too poor to capture the geometry of the underlying smooth Euclidean surface well enough. This paper proposes three new calculus frameworks dedicated to digital surfaces, which exploit a corrected normal field, in a manner similar to the recent digital calculus of Coeurjolly and Lachaud (IAPR second international conference on discrete geometry and mathematical morphology, Springer, Berlin 2022). First, we build a corrected interpolated calculus by defining inner products with position and normal interpolation in the Grassmannian. Second, we present a corrected finite element method which adapts the standard Finite Element Method with a corrected metric per element. Third, we present a corrected virtual refinement method adapting the method of Bunge et al. (Comput Graph Forum 39(2):303–313, 2020, https://doi.org/10.1111/cgf.13931 ). Experiments show that these digital calculus frameworks seem to converge toward the continuous calculus, offer a valid alternative to classical mesh calculus, and induce effective tools for digital surface processing tasks. We then use these corrected Laplace–Beltrami operators in order to build a regularization method for digital surface, using geometric information given by discrete normal and curvature estimators.},
  archive      = {J_JMIV},
  author       = {Weill–Duflos, Colin and Coeurjolly, David and Lachaud, Jacques-Olivier},
  doi          = {10.1007/s10851-024-01226-6},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-16},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Corrected Laplace–Beltrami operators for digital surfaces},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recognition of pieces of arithmetic hyperplanes using the Stern–Brocot tree. <em>JMIV</em>, <em>67</em>(2), 1-21. (<a href='https://doi.org/10.1007/s10851-025-01229-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical problem of discrete structure recognition is revisited in this paper. We focus on pieces of naive lines and, more generally, naive arithmetic hyperplanes, and present a new approach to recognising these discrete structures based on the Stern–Brocot tree. The algorithm for pieces of lines in dimension 2 proposes an alternative method to the state of the art, retaining linear complexity and incrementality for the segments. While most of the concepts can be generalised to planes in dimension 3 and hyperplanes in higher dimensions, certain points in the management of the descent in the Stern–Brocot tree merit further study. The proposed algorithm calculates separating chords characterising the membership of planes to cones generated by the branch of the Stern–Brocot tree. This generalisation shows the close link between arithmetic hyperplanes and the generalised Stern–Brocot tree and opens up interesting prospects for recognising pieces of arithmetic hyperplanes. Finally, we propose a geometric interpretation of separating chords and an interpretation of plane probing algorithms in the Stern–Brocot tree, showing both the links and the differences with our approach.},
  archive      = {J_JMIV},
  author       = {Laboureix, Bastien and Mattei, Alban and Lachaud, Jacques-Olivier and Debled-Rennesson, Isabelle},
  doi          = {10.1007/s10851-025-01229-x},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-21},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Recognition of pieces of arithmetic hyperplanes using the Stern–Brocot tree},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Morse sequences: A simple approach to discrete morse theory. <em>JMIV</em>, <em>67</em>(2), 1-22. (<a href='https://doi.org/10.1007/s10851-025-01232-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop the notion of a Morse sequence, offering an alternative approach to discrete Morse theory that is both simple and effective. A Morse sequence on a finite simplicial complex consists solely of two elementary operations: expansions (the inverse of collapses) and fillings (the inverse of perforations). Alternatively, a Morse sequence can be constructed using only collapses and perforations, providing a dual perspective. Such sequences serve as another representation of the gradient vector field of an arbitrary discrete Morse function. To each Morse sequence, we associate a reference map and an extension map. The reference map assigns a set of critical simplices to each simplex in the complex, while the extension map assigns a set of simplices to each critical simplex. By considering the boundary of each critical simplex, these maps yield a chain complex that corresponds exactly to the Morse complex. We demonstrate that, when restricted to homology, the extension map is the inverse of the reference map. Furthermore, these maps enable a direct derivation of the isomorphism theorem, which establishes the equivalence between the homology of a given object and that of its Morse complex. Finally, we introduce the notion of an extension complex, defined exclusively in terms of extension maps. We prove that this concept is equivalent to the classical flow complex.},
  archive      = {J_JMIV},
  author       = {Bertrand, Gilles},
  doi          = {10.1007/s10851-025-01232-2},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-22},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Morse sequences: A simple approach to discrete morse theory},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing a kernel method for shape analysis in kendall space. <em>JMIV</em>, <em>67</em>(2), 1-10. (<a href='https://doi.org/10.1007/s10851-025-01235-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In learning methods defined on a manifold, it is often important to embed the manifold into a Hilbert space to apply kernel methods, as it enables the utilization of linear techniques in the transformed space, thereby facilitating complex data analysis and classification tasks with nonlinear structures [10]. In [6], the authors define an embedding of the $$\textit{m}$$ -dimensional Kendall shape space into an $$\mathbb {R}^{\textit{N}}$$ space, from which kernel methods are introduced in the Kendall shape space. In this paper, we significantly simplify this result by achieving an embedding of the Kendall shape space into a Euclidean space $$\mathbb {R}^{\textit{n}}$$ of much lower dimension $$\textit{n}$$ than $$\textit{N}$$ , greatly simplifying calculations and computational costs of applications. Additionally, we characterize the image of the Kendall shape space in $$\mathbb {R}^{\textit{n}}$$ , allowing us to define a new extrinsic mean of shapes in the Kendall shape space.},
  archive      = {J_JMIV},
  author       = {Gual-Arnau, Ximo and Monterde, Juan},
  doi          = {10.1007/s10851-025-01235-z},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-10},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Enhancing a kernel method for shape analysis in kendall space},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Out-of-core algorithms for binary partition hierarchies. <em>JMIV</em>, <em>67</em>(2), 1-18. (<a href='https://doi.org/10.1007/s10851-025-01234-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary partition hierarchies (BPH) and minimum spanning trees are essential data structures for hierarchical analysis, such as quasi-flat zones and watershed segmentation. Traditional BPH construction algorithms are limited by their requirement to load the data entirely into memory, making them impractical for processing large images whose processing exceeds the capacity of the computer’s main memory. To overcome this limitation, an algebraic framework was introduced, enabling the out-of-core computation of BPH leveraging three key operations: select, join, and insert. In this publication, we present two distinct calculi based on these operations: one designed for general spatial partitions and another optimized for causal partitioning. The second calculus is specifically tailored to meet out-of-core constraints, ensuring efficient processing of large-scale data. We provide detailed algorithms, including pseudo-code and complexity analysis, and conduct experimental comparisons between the two approaches.},
  archive      = {J_JMIV},
  author       = {Lefèvre, Josselin and Cousty, Jean and Perret, Benjamin and Phelippeau, Harold},
  doi          = {10.1007/s10851-025-01234-0},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-18},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Out-of-core algorithms for binary partition hierarchies},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Statistical modeling of deep features to reduce false alarms in video change detection. <em>JMIV</em>, <em>67</em>(2), 1-40. (<a href='https://doi.org/10.1007/s10851-025-01238-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting relevant changes is a fundamental problem of video surveillance. Because of the high variability of data and the difficulty of properly annotating changes, unsupervised methods dominate the field. Arguably one of the most critical issues to make them practical is to reduce their false alarm rate. In this work, we develop a non-semantic, method-agnostic, weakly supervised a-contrario validation process, based on high-dimensional statistical modeling of deep features using a Gaussian mixture model, that can reduce the number of false alarms of any change detection algorithm. We also raise the insufficiency of the conventionally used pixel-wise evaluation, as it fails to precisely capture the performance needs of most real applications. For this reason, we complement pixel-wise metrics with component-wise metrics and evaluate the impact of our approach at both pixel and object levels, on six methods and several sequences from different datasets. Our experimental results reveal that the a-contrario theory can be applied to a statistical model of the background of a scene and largely reduce the number of false positives at both pixel and component levels.},
  archive      = {J_JMIV},
  author       = {Bou, Xavier and Artola, Aitor and Ehret, Thibaud and Facciolo, Gabriele and Morel, Jean-Michel and Gioi, Rafael Grompone von},
  doi          = {10.1007/s10851-025-01238-w},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-40},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Statistical modeling of deep features to reduce false alarms in video change detection},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoRRECT: A deep unfolding framework for motion-corrected quantitative r2* mapping. <em>JMIV</em>, <em>67</em>(2), 1-16. (<a href='https://doi.org/10.1007/s10851-025-01236-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative MRI (qMRI) refers to a class of MRI methods for quantifying the spatial distribution of biological tissue parameters. Traditional qMRI methods usually deal separately with artifacts arising from accelerated data acquisition, involuntary physical motion, and magnetic field inhomogeneities, leading to sub-optimal end-to-end performance. This paper presents CoRRECT, a unified deep unfolding (DU) framework for qMRI consisting of a model-based end-to-end neural network, a method for motion artifact reduction, and a self-supervised learning scheme. The network is trained to produce R2* maps whose k-space data matches the real data by also accounting for motion and field inhomogeneities. When deployed, CoRRECT only uses the k-space data without any pre-computed parameters for motion or inhomogeneity correction. Our results on experimentally collected multi-gradient recalled echo (mGRE) MRI data show that CoRRECT recovers motion and inhomogeneity artifact-free R2* maps in highly accelerated acquisition settings. This work opens the door to DU methods that can integrate physical measurement models, biophysical signal models, and learned prior models for high-quality qMRI.},
  archive      = {J_JMIV},
  author       = {Xu, Xiaojian and Gan, Weijie and Kothapalli, Satya V. V. N. and Yablonskiy, Dmitriy A. and Kamilov, Ulugbek S.},
  doi          = {10.1007/s10851-025-01236-y},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-16},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {CoRRECT: A deep unfolding framework for motion-corrected quantitative r2* mapping},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient model-based deep learning via network pruning and fine-tuning. <em>JMIV</em>, <em>67</em>(2), 1-14. (<a href='https://doi.org/10.1007/s10851-025-01241-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based deep learning (MBDL) is a powerful methodology for designing deep models to solve imaging inverse problems. MBDL networks can be seen as iterative algorithms that estimate the desired image using a physical measurement model and a learned image prior specified using convolutional neural networks (CNNs). The iterative nature of MBDL networks increases the test-time computational complexity, which limits their applicability in certain large-scale applications. Here we make two contributions to address this issue: First, we show how structured pruning can be adopted to reduce the number of parameters in MBDL networks. Second, we present three methods to fine-tune the pruned MBDL networks to mitigate potential performance loss. Each fine-tuning strategy has a unique benefit that depends on the presence of a pre-trained model and a high-quality ground truth. We show that our pruning and fine-tuning approach can accelerate image reconstruction using popular deep equilibrium learning (DEQ) and deep unfolding (DU) methods by 50% and 32%, respectively, with nearly no performance loss. This work thus offers a step forward for solving inverse problems by showing the potential of pruning to improve the scalability of MBDL. Code is available at https://github.com/wustl-cig/MBDL_Pruning .},
  archive      = {J_JMIV},
  author       = {Park, Chicago Y. and Gan, Weijie and Zou, Zihao and Hu, Yuyang and Sun, Zhixin and Kamilov, Ulugbek S.},
  doi          = {10.1007/s10851-025-01241-1},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-14},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Efficient model-based deep learning via network pruning and fine-tuning},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A second-order TGV discretization with $$90^{^{\circ }}$$ rotational invariance property. <em>JMIV</em>, <em>67</em>(2), 1-33. (<a href='https://doi.org/10.1007/s10851-024-01224-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a new discretization for second-order total generalized variation (TGV) with some distinct properties compared to existing discrete formulations. The introduced model is based on the same design principles as Condat’s discrete total variation model (Condat in SIAM J Imaging Sci 10(3):1258-1290, 2017) and shares its benefits, particularly improved solution quality for imaging problems. We propose an algorithm for general discrete inverse problems with second-order TGV using the new discretization. Numerical results obtained with this algorithm for denoising and upscaling demonstrate the advantages of the discretization. Moreover, to assess the invariance properties of the new model, we compare the results of the proposed TGV and the classic discrete TGV for original data and $$90^{^{\circ }}$$ rotated versions. Additionally, we provide an algorithm for calculating the TGV value with respect to the new discretization model.},
  archive      = {J_JMIV},
  author       = {Hosseini, Alireza and Bredies, Kristian},
  doi          = {10.1007/s10851-024-01224-8},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-33},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {A second-order TGV discretization with $$90^{^{\circ }}$$ rotational invariance property},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the singular points approached by the medial axis. <em>JMIV</em>, <em>67</em>(2), 1-11. (<a href='https://doi.org/10.1007/s10851-025-01237-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The medial axis of a closed set collects all the points of the ambient space with nonunique distance realiser in a set. This paper studies which of the set’s singular points are reached by the medial axis. The investigation of $$\mathscr {C}^1$$ smoothness points extends earlier results of Birbrair and Denkowski of superquadratic points to dimensions greater than two and to general o-minimal structures. The collection of points where the set fails to be $$\mathscr {C}^1$$ smooth is studied from the perspective of its tangent cone and the biggest submanifold found in the set.},
  archive      = {J_JMIV},
  author       = {Bialozyt, Adam},
  doi          = {10.1007/s10851-025-01237-x},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-11},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {On the singular points approached by the medial axis},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-order DIP-VBTV: An image restoration model combining a deep image prior and a high-order total variation on vector bundles. <em>JMIV</em>, <em>67</em>(2), 1-27. (<a href='https://doi.org/10.1007/s10851-025-01240-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a high-order total variation (TV) for sections of vector bundles over Riemannian manifolds, which is determined by the following geometric quadruplet: a connection and a positive definite metric on the vector bundle as well as a connection and a positive definite metric on the tangent bundle of the manifold. Then, we insert the high-order TV into the deep image prior (DIP), yielding a variational model for image restoration. The proposed model can be viewed as a combination of three classes of efficient variational models for image restoration: high-order TV-based models which promote the reconstruction of both edges and fine structures of the original image, geometric TV-based models which can encode extra properties of natural images, and DIP-based models which take benefit of the generative property of neural networks to reconstruct the original image. Experiments conducted up to the order 3 for image deblurring and super-resolution show that the higher the order, the better the results. Moreover, for a given order, the experiments also show that the proposed model outperforms its Euclidean restriction.},
  archive      = {J_JMIV},
  author       = {Batard, Thomas},
  doi          = {10.1007/s10851-025-01240-2},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-27},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {High-order DIP-VBTV: An image restoration model combining a deep image prior and a high-order total variation on vector bundles},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Curvature-guided color image restoration by saturation-value total variation. <em>JMIV</em>, <em>67</em>(1), 1-26. (<a href='https://doi.org/10.1007/s10851-024-01218-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel curvature-guided saturation-value total variation model for color image restoration. Specifically, we incorporate the curvature prior into the traditional variational model to guide the evolution in the direction that maintains the curvature information. Theoretically, we investigate the properties of the proposed model and give a detailed discussion based on the mathematical foundation about the existence of the solution. Numerically, we formulate an effective and efficient algorithm to solve the proposed minimization problem based on the framework of alternating direction method of multipliers. Numerical examples are presented to demonstrate that the performance of the proposed model is better than that of other testing methods for several testing color images.},
  archive      = {J_JMIV},
  author       = {Wang, Wei and Wang, Jingjie and Ng, Michael K.},
  doi          = {10.1007/s10851-024-01218-6},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {1-26},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Curvature-guided color image restoration by saturation-value total variation},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the axial symmetry of 2D star-shaped sets. <em>JMIV</em>, <em>67</em>(1), 1-15. (<a href='https://doi.org/10.1007/s10851-024-01222-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An essential aspect of the study of shapes is the symmetry because of its importance from a theoretical point of view and its applicability in multiple real-life problems. In this manuscript, the axial symmetry of 2D star-shaped sets is analyzed. For such a purpose, different measures of axial symmetry of a star-shaped set are proposed and the concept of a best symmetry axis is also introduced. By means of them, families of symmetry measures for star-shaped sets quantifying the degree of symmetry of a set of that class are introduced. All of them are discussed in detail, providing their main properties and the existence of at least a best axis of symmetry, which could be not unique, for any star-shaped set. Some examples illustrate the concepts and results of the manuscript.},
  archive      = {J_JMIV},
  author       = {López-Díaz, María Concepción and López-Díaz, Miguel},
  doi          = {10.1007/s10851-024-01222-w},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {1-15},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {On the axial symmetry of 2D star-shaped sets},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A structured L-BFGS method with diagonal scaling and its application to image registration. <em>JMIV</em>, <em>67</em>(1), 1-20. (<a href='https://doi.org/10.1007/s10851-024-01215-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We devise an L-BFGS method for optimization problems in which the objective is the sum of two functions, where the Hessian of the first function is computationally unavailable while the Hessian of the second function has a computationally available approximation that allows for cheap matrix–vector products. This is a prototypical setting for many inverse problems. The proposed L-BFGS method exploits the structure of the objective to construct a more accurate Hessian approximation than in standard L-BFGS. In contrast with existing works on structured L-BFGS, we choose the first part of the seed matrix, which approximates the Hessian of the first function, as a diagonal matrix rather than a multiple of the identity. We derive two suitable formulas for the coefficients of the diagonal matrix and show that this boosts performance on real-life image registration problems, which are highly non-convex inverse problems. The new method converges globally and linearly on non-convex problems under mild assumptions in a general Hilbert space setting, making it applicable to a broad class of inverse problems. An implementation of the method is freely available.},
  archive      = {J_JMIV},
  author       = {Mannel, Florian and Aggrawal, Hari Om},
  doi          = {10.1007/s10851-024-01215-9},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {1-20},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {A structured L-BFGS method with diagonal scaling and its application to image registration},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cartoon–Texture image decomposition using least squares and low-rank regularization. <em>JMIV</em>, <em>67</em>(1), 1-17. (<a href='https://doi.org/10.1007/s10851-024-01216-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel model for the decomposition of cartoon–texture images, which integrates the edge-aware weighted least squares (WLS) with low-rank regularization. Unlike conventional methodologies that depend on total variation-based penalty functions, our model represents cartoon images using an edge-preserving WLS penalty. This approach effectively enhances edges and suppresses texture through iterative updates of an edge-preserving weight matrix. For the texture component, we introduce a low-rank penalty function to capture the structured regularity of texture patterns. By leveraging the repetitive nature of texture, our low-rank models can accurately represent these components. We employ a prediction–correction approach based on a three-block separable alternating direction multiplier method to solve the minimization problem, providing closed-form solutions for all subproblems. We also provide a convergence proof for the proposed algorithm. Numerical experiments validate the efficacy of our proposed method in successfully separating cartoon and texture components while preserving edges.},
  archive      = {J_JMIV},
  author       = {Li, Kexin and Wen, You-wei and Chan, Raymond H.},
  doi          = {10.1007/s10851-024-01216-8},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Cartoon–Texture image decomposition using least squares and low-rank regularization},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy circularity: A new fuzzy shape-based descriptor of the object. <em>JMIV</em>, <em>67</em>(1), 1-24. (<a href='https://doi.org/10.1007/s10851-024-01217-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new family of fuzzy shape measures, called fuzzy circularity, to evaluate the degree to which a considered fuzzy shape matches a fuzzy disk. A new family of fuzzy shape-based measures ranges the interval (0, 1] where a maximum value equal to 1 is reached if and only if the shape under consideration is a fuzzy disk. This family is theoretically well grounded having the behavior that corresponds to human perception and can be predicted in advance. Additionally, a new family of fuzzy shape-based measures is invariant to rotation, translation, and scaling of the considered fuzzy shape. Various experiments on both synthetically generated and real images are included to provide a better understanding of the behavior of the new measures and to confirm the theoretically proven results. The performance of the new family of fuzzy circularity is extensively tested on several standard, well-known image datasets such as MPEG-7 CE-1, Animal, Swedish Leaf, and Galaxy Zoo datasets. Experimental evaluations also illustrate the effectiveness and advantages of the new shape descriptors in various object classification and recognition tasks by comparing them with other known analysis approaches.},
  archive      = {J_JMIV},
  author       = {Ilić, Vladimir and Ralević, Nebojša M.},
  doi          = {10.1007/s10851-024-01217-7},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {1-24},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Fuzzy circularity: A new fuzzy shape-based descriptor of the object},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blind image deconvolution: When patch-wise minimal pixels prior meets fractional-order method. <em>JMIV</em>, <em>67</em>(1), 1-20. (<a href='https://doi.org/10.1007/s10851-024-01221-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blind image deconvolution is a challenging issue in image processing. In blind image deconvolution, the typical approach involves iteratively estimating both the blur kernel and latent image until convergence to the blur kernel of the observed image is achieved. Recently, several approaches have been attempted to develop a sophisticated regularization to obtain the clean image. However, existing methods often struggle to effectively handle ringing artifacts and local blur. To overcome these limitations, we introduce a fractional-order variational model. This model alleviates the ringing artifacts through the selection of an optimal derivative. Subsequently, to refine the latent image further, we leverage the local prior, namely patch-wise minimal pixels (PMP) prior. Since the PMP prior of clean images blocks is much sparser than that of blurred ones, it is capable of discriminating between clean and blurred image blocks. We illustrate the effective integration of the fractional-order operations and the PMP prior within our proposed approach. Moreover, the convergence of our algorithm has been proved as the values of the objective function monotonically decrease. Extensive experiments on different datasets demonstrate the superiority of the proposed method compared with other methods in terms of reconstruction quality for blind deconvolution.},
  archive      = {J_JMIV},
  author       = {Wu, Tingting and Wan, Shaojie and Feng, Chenchen and Zhang, Hao and Zeng, Tieyong},
  doi          = {10.1007/s10851-024-01221-x},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {1-20},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Blind image deconvolution: When patch-wise minimal pixels prior meets fractional-order method},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anisotropic diffusion in riemannian colour geometry. <em>JMIV</em>, <em>67</em>(1), 1-10. (<a href='https://doi.org/10.1007/s10851-024-01223-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anisotropic diffusion has long been an important tool in image processing. More recently, it has also found its way to colour imaging. Until now, mainly Euclidean colour spaces have been considered in this context, but recent years have seen a renewed interest in and importance of non-Euclidean colour geometry. The main contribution of this paper is the derivation of the equations for anisotropic diffusion in Riemannian colour geometry. It is demonstrated that it contains several well-known solutions such as Perona–Malik diffusion and Tschumperlé–Deriche diffusion as special cases. Furthermore, it is shown how it is non-trivially connected to Sochen’s general framework for low-level vision. The main significance of the method is that it decouples the coordinates used for solving the diffusion equation from the ones that define the metric of the colour manifold, and thus directs the magnitude and direction of the diffusion through the diffusion tensor. It also enables the use of non-Euclidean colour manifolds and metrics for applications such as denoising, inpainting, and demosaicing, based on anisotropic diffusion.},
  archive      = {J_JMIV},
  author       = {Farup, Ivar and Rivertz, Hans Jakob},
  doi          = {10.1007/s10851-024-01223-9},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {1-10},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Anisotropic diffusion in riemannian colour geometry},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New properties for full convex sets and full convex hulls. <em>JMIV</em>, <em>67</em>(1), 1-13. (<a href='https://doi.org/10.1007/s10851-024-01225-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Full convexity has been recently proposed as an alternative definition of digital convexity in $$\mathbb {Z}^n$$ . In contrast to classical definitions, fully convex sets are always connected and even simply connected whatever the dimension, while remaining digitally convex in the usual sense. In order to better understand the properties of full convexity, we present here two new and radically different characterizations of full convexity. The first one mimics the usual continuous convexity via segments inclusion. We show an equivalence of full convexity with this segment convexity in dimensions 1 and 2, and counterexamples starting from dimension 3. If we now ask that the cells touched by all d-simplices (instead of just 2-simplices aka segments) are within the cells touched by the digital set, we achieve an equivalence in arbitrary dimension d. The second characterization is recursive with respect to the dimension and relies on convexity of its axis-aligned projections. We provide several applications of these characterizations: the full convexity of balls and subsets of the hypercube, a natural measure of full convexity for digital sets, a new and faster algorithm to check the full convexity of digital sets. Finally, we study the main drawback of full convexity: Its envelope operator may not be an increasing operator. We characterize fully convex sets that have anti-monotonous subsets, and we show that they must be thin in a precise sense.},
  archive      = {J_JMIV},
  author       = {Feschet, Fabien and Lachaud, Jacques-Olivier},
  doi          = {10.1007/s10851-024-01225-7},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {1-13},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {New properties for full convex sets and full convex hulls},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new insight into the epipole from four point correspondences in two calibrated views. <em>JMIV</em>, <em>67</em>(1), 1-12. (<a href='https://doi.org/10.1007/s10851-024-01227-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new insight into the epipole from four given image point correspondences in two calibrated views. Firstly, we propose an algebraic constraint on the relation between the epipole and a plane-induced homography. Secondly, we show a novel algorithm for determining the 10-degree curve about possible epipoles from four image point correspondences in two calibrated views by using algebraic method directly. In particular, we show that the problem of determining the epipole has at most four distinct real solutions when the left image plane is parallel to a certain face of the tetrahedron consisting of four control points. Furthermore, we also confirm that the upper bound of four distinct physically valid solutions is attainable. Lastly, we give some examples to validate our results.},
  archive      = {J_JMIV},
  author       = {Guo, Yang and Qu, Yingqi},
  doi          = {10.1007/s10851-024-01227-5},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {1},
  number       = {1},
  pages        = {1-12},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {A new insight into the epipole from four point correspondences in two calibrated views},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
