<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SOCO</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="soco">SOCO - 286</h2>
<ul>
<li><details>
<summary>
(2025). Power quality control in electric vehicle connected PV-grid using soft computing techniques. <em>SOCO</em>, <em>29</em>(13), 5095-5113. (<a href='https://doi.org/10.1007/s00500-025-10666-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Renewable Energy Systems and Electrical Vehicles are penetrating the power system exponentially. This penetration of both systems reckons stable working of the overall system and power balancing in the system to maintain frequency and voltage stability. This paper employs soft computing techniques to achieve power balancing in a photovoltaic (PV)-integrated grid with electric vehicle (EV) loads. Power system stability is improved through the use of an orthogonal real and reactive power controller. Soft computing techniques like Fuzzy Logic Controller and Adaptive Neuro-Fuzzy Inference System(ANFIS) are applied to the Orthogonal Controller (DQ controller) to control the power quality disturbances. The system consists of two loops: the power stability loop, which regulates the Voltage Source Inverter (VSI) connecting the photovoltaic (PV) system to the grid, and the bidirectional power flow loop, designed to manage vehicle-to-grid and grid-to-vehicle power exchanges. A MATLAB based simulation is developed using Fuzzy Logic Controller (FLC) and Adaptive Neuro-Fuzzy Inference System (ANFIS) controllers to visualize their performance. The performance enhancement of these soft computing techniques is evaluated in comparison to the traditional Proportional-Integral (PI) controller. The topology of the bidirectional controller is adopted with dual converters instead of a single bidirectional converter in the proposed study. Although the cost of the setup increases, but the adoption in performance-intensive applications would make it a relevant topological variation. It is observed that the advanced soft computing techniques of FLC and ANFIS performed better than the PI controller considering harmonic reduction, power factor enhancement and voltage regulation as the criterion of performance. Considering advanced algorithms for the performance evaluation has given a good percentage change in harmonic reduction which is measured in terms of Total Harmonic Distortion. A significant improvement in the THD is observed while using the ANFIS algorithm as opposed while using the PI controller. The results demonstrated by the ANFIS controller surpassed the other controllers in minimizing THD and effectively managing the combined impact of PV penetration and EV loading on the grid.},
  archive      = {J_SOCO},
  author       = {MP, Kishore and Shrivastava, Ashish and Soni, Amit},
  doi          = {10.1007/s00500-025-10666-0},
  journal      = {Soft Computing},
  month        = {7},
  number       = {13},
  pages        = {5095-5113},
  shortjournal = {Soft Comput.},
  title        = {Power quality control in electric vehicle connected PV-grid using soft computing techniques},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced COVID-19 detection from chest X-rays using ERBMAHE and a channel attention-based hybrid CNN model. <em>SOCO</em>, <em>29</em>(13), 5071-5093. (<a href='https://doi.org/10.1007/s00500-025-10853-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Coronavirus disease (COVID-19) has significantly impacted global health, creating an urgent demand for efficient and accurate diagnostic methods. Chest X-ray (CXR) imaging has emerged as an essential tool for early detection; however, issues such as low contrast and poor image quality can hinder accurate classification. To address these challenges, this study proposes a novel hybrid deep learning model that integrates VGG16 and ResNet101 architectures through a channel-wise attention fusion mechanism. This innovative design allows the model to adaptively emphasize the most informative features across both networks, improving diagnostic accuracy. To further enhance performance, we introduce Exposure Region-Based Modified Adaptive Histogram Equalization (ERBMAHE), a novel image enhancement technique that improves contrast and detail visibility in CXR images. Additionally, we employ Gradient-weighted Class Activation Mapping (Grad-CAM) to visualize and interpret the discriminative regions used by the model during prediction, thereby enhancing the model’s explainability and clinical trustworthiness. The system is trained using five-fold cross-validation with data augmentation to ensure robustness and generalization. Experimental results demonstrate that the proposed attention-based hybrid model, when paired with ERBMAHE-enhanced images, achieves a test accuracy of 97.94%, precision of 99.06%, F1-score of 97.92%, and recall of 96.80%, outperforming existing state-of-the-art methods. This framework provides a promising tool for rapid, interpretable, and reliable COVID-19 diagnosis, particularly in resource-limited healthcare settings.},
  archive      = {J_SOCO},
  author       = {Gangwar, Shivam and Devi, Reeta and Mat Isa, Nor Ashidi and Oraintara, Soontorn},
  doi          = {10.1007/s00500-025-10853-z},
  journal      = {Soft Computing},
  month        = {7},
  number       = {13},
  pages        = {5071-5093},
  shortjournal = {Soft Comput.},
  title        = {Enhanced COVID-19 detection from chest X-rays using ERBMAHE and a channel attention-based hybrid CNN model},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging artificial intelligence and optimization for agile AGV scheduling in an edge-to-cloud manufacturing framework. <em>SOCO</em>, <em>29</em>(13), 5041-5069. (<a href='https://doi.org/10.1007/s00500-025-10851-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing the scheduling of Automated Guided Vehicles (AGVs) is a critical task in the context of smart manufacturing, particularly in Industry 4.0, where operational efficiency, sustainability, and adaptability are key drivers of innovation. This paper introduces an innovative scheduling model incorporating real-time AGV battery status as a key parameter, using a machine learning algorithm to predict energy consumption and optimize task allocation accordingly. The primary objective is to extend AGV battery life, reduce energy consumption, and contribute to environmental sustainability, all while maintaining high operational efficiency. In addition to the scheduling algorithm, we present a comprehensive application framework designed to integrate this optimization model into real-world factory environments. This architecture leverages cloud-edge computing to process real-time data from AGVs, enabling dynamic scheduling adjustments and seamless execution of tasks. The proposed approach has been experimentally validated, demonstrating improvements in energy efficiency when compared to a conventional AGV scheduling strategy. This result demonstrates the effectiveness of our solution in improving energy efficiency while maintaining high performance in AGV operations. By providing the necessary infrastructure for data input, processing, and output implementation, the framework ensures that the algorithm can be effectively deployed and scaled in industrial settings. This research offers a robust solution for AGV scheduling, balancing operational efficiency with sustainability.},
  archive      = {J_SOCO},
  author       = {Lepore, Mario and Serra, Domenico and Maccioni, Raffaele},
  doi          = {10.1007/s00500-025-10851-1},
  journal      = {Soft Computing},
  month        = {7},
  number       = {13},
  pages        = {5041-5069},
  shortjournal = {Soft Comput.},
  title        = {Leveraging artificial intelligence and optimization for agile AGV scheduling in an edge-to-cloud manufacturing framework},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decision tree-based machine learning models for yarn quality prediction in the textile industry: A comparative analysis. <em>SOCO</em>, <em>29</em>(13), 5025-5039. (<a href='https://doi.org/10.1007/s00500-025-10669-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality of textile yarns are decisively influenced by the fibre properties and process parameters. Various mathematical and statistical models have been used in the past for modelling the yarn properties. Machine learning (ML) models have started to make their way in the textile industry since they are able to counter several limitations of the mathematical and statistical models. In this work, an attempt has been made to predict three properties of cotton yarns (tenacity, unevenness and hairiness) using two decision tree-based ML models, namely Random Forest and XGBoost. These models yielded better results compared to traditional models and existing ML models (ANN, SVM and KNN). Particularly, XGBoost performed better than all other models and also gave the best predictions (MAPE = 2.53, 2.69 and 2.13; R2 = 0.776, 0.881 and 0.937; RMSE = 0.496, 0.731 and 0.144; and MAE = 0.375, 0.548 and 0.115 for tenacity, unevenness and hairiness, respectively) for all three yarn quality parameters for unseen test data. Synthetic data was also generated to improve the generalisability of the XGBoost model and it was found that the prediction accuracy improved with the synthetic data. Significance test of input features was conducted to analyse the importance of cotton fibre properties. The results reveal that there is a good agreement between the outcome of ML models and established perception of fibre-yarn property relationships.},
  archive      = {J_SOCO},
  author       = {Majumdar, Abhijit and Sarda, Shubham and Agarwal, Tanya and Bhattacharyya, Rajib},
  doi          = {10.1007/s00500-025-10669-x},
  journal      = {Soft Computing},
  month        = {7},
  number       = {13},
  pages        = {5025-5039},
  shortjournal = {Soft Comput.},
  title        = {Decision tree-based machine learning models for yarn quality prediction in the textile industry: A comparative analysis},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel computational strategy for solving electrohydrodynamic flow problem. <em>SOCO</em>, <em>29</em>(13), 5009-5023. (<a href='https://doi.org/10.1007/s00500-025-10852-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present study, we design a novel computational procedure to obtain highly accurate solutions for the electrohydrodynamic flow model, which depicts the velocity of ionized fluid motion in a circular cylindrical conduit. The study investigates the velocity fields of electrohydrodynamic flow in relation to two crucial parameters: the level of nonlinearity and the electrical Hartmann number. A comprehensive examination of convergence and error analysis is also conducted. Furthermore, the effectiveness of the proposed approach is demonstrated through various test scenarios. In order to justify the advantages of the proposed numerical algorithm, the computed results are compared with those obtained using several existing methods in the literature, including the Lucas and Galerkin Collocation Methods, the Haar Wavelet Collocation Method, the Discrete Optimized Homotopy Analysis Method, the Least Squares Method, the Chebyshev and Legendre Spectral Methods, and Shifted Airfoil Polynomials of the Second Kind Method. These tests and comparisons highlight the efficacy and reliability of the proposed methodology in addressing electrohydrodynamic flow problems.},
  archive      = {J_SOCO},
  author       = {Aydinlik, Soner and Kiris, Ahmet and Roul, Pradip},
  doi          = {10.1007/s00500-025-10852-0},
  journal      = {Soft Computing},
  month        = {7},
  number       = {13},
  pages        = {5009-5023},
  shortjournal = {Soft Comput.},
  title        = {A novel computational strategy for solving electrohydrodynamic flow problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancement of performance through optimized intelligent static random access memory design. <em>SOCO</em>, <em>29</em>(13), 4999-5008. (<a href='https://doi.org/10.1007/s00500-025-10781-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel Horned Lizard Elman Model (HLEM) aimed at optimizing the performance of Static Random Access Memory (SRAM). The Horned Lizard optimization explores the design space to identify optimal parameter configurations that enhance performance metrics such as speed, power consumption, and space utilization. The adaptive properties of the optimization are leveraged to improve the factors of SRAM, including cell size, access restrictions, and cache settings, to handle large data. Additionally, it includes a data compression process to optimize memory utilization, minimize power consumption, and reduce memory access time. This approach not only enhances SRAM efficiency but also addresses increasing demands for more capacity and faster processing in the modern computing environment. Hence, it is implemented in the Python system and the effectiveness of the proposed HLEM is evaluated by analyzing significant metrics such as the computation time, the processing speed, power consumption, capacity, and the memory Usage. These performance metrics are compared with other conventional models to validate the necessity and advantages of the optimized design.},
  archive      = {J_SOCO},
  author       = {Ravikumar, K. I. and Sukumar, R. and Anusha, K.},
  doi          = {10.1007/s00500-025-10781-y},
  journal      = {Soft Computing},
  month        = {7},
  number       = {13},
  pages        = {4999-5008},
  shortjournal = {Soft Comput.},
  title        = {Enhancement of performance through optimized intelligent static random access memory design},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective prediction of alkali-activated material properties and material parameter design. <em>SOCO</em>, <em>29</em>(13), 4983-4997. (<a href='https://doi.org/10.1007/s00500-025-10710-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of alkali-activated materials (AAM) derived from industrial waste is increasingly prevalent in engineering as a sustainable construction material capable of significantly reducing carbon emissions. However, the diverse composition of AAM complicates the prediction of its properties, necessitating empirical and somewhat arbitrary material parameter designs. To address this challenge, this study proposes a soft computing framework employing machine learning and heuristic algorithms for predicting the compressive strength and fluidity of AAM, as well as for optimizing material parameters. Microchemical compositions (e.g., CaO, SiO2, Al2O3) serve as input parameters for the first-time prediction of AAM engineering properties. Firstly, a Particle Swarm Optimization-based XGBoost model (PSO-XGBoost) and corresponding evaluation metrics were developed to predict compressive strength and fluidity based on 11 input parameters. Feature importance analysis revealed that water-to-binder ratio (W/B) is the most critical parameter governing AAM properties. Secondly, leveraging the data mapping capabilities of PSO-XGBoost, the Simulated Annealing (SA) algorithm was employed for inverse analysis to optimize material parameters. $${\text{MAPE}}_{multi - objective}$$ reduced the prediction error from 18.84% to 0.27%, demonstrating the efficacy and efficiency of the proposed parameter design methodology.},
  archive      = {J_SOCO},
  author       = {He, Yueji and Zhu, Zhijing and Bai, Jiwen and Zhao, Dukun and Liu, Rentai and Chen, Mengjun and Zhang, Lianzhen},
  doi          = {10.1007/s00500-025-10710-z},
  journal      = {Soft Computing},
  month        = {7},
  number       = {13},
  pages        = {4983-4997},
  shortjournal = {Soft Comput.},
  title        = {Multi-objective prediction of alkali-activated material properties and material parameter design},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive review of generative AI techniques and their impact on cybersecurity. <em>SOCO</em>, <em>29</em>(13), 4945-4982. (<a href='https://doi.org/10.1007/s00500-025-10702-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s digital landscape, cybersecurity stands as the cornerstone of defense against an ever-evolving array of threats, ranging from ransomware attacks to state-sponsored espionage. With our increasing reliance on interconnected systems, the vulnerability to sophisticated threats has become pronounced. In response, Generative Artificial Intelligence (AI) has emerged as a formidable tool, offering the potential to revolutionize cybersecurity strategies. It encompasses algorithms and models designed to produce new content, often indistinguishable from human-generated data, thus holding promise not only for creative content generation but also for offensive and defensive cybersecurity applications. This paper explores the intersection of Generative AI and cybersecurity, conducting a critical analysis of the current state of generative AI techniques and their practical implementations in cybersecurity. Specifically, we delve into key generative AI methodologies such as Generative Adversarial Networks and Variational Autoencoders, evaluating their efficacy in addressing cybersecurity challenges. Through a comprehensive examination of existing literature, case studies, and emerging trends, our objective is to insight into the promises, challenges, and ethical considerations associated with integrating generative AI into the cybersecurity landscape. This paper contributes to the cybersecurity field by synthesizing existing literature, identifying trends, and highlighting areas for future research and development in the realm of generative AI for cybersecurity. We emphasize the potential for enhanced security through the adoption of generative AI techniques while stressing the importance of robust defenses against potential misuse by malicious actors. Furthermore, we address the ethical implications of employing generative AI for offensive purposes, advocating for responsible and ethical implementation practices.},
  archive      = {J_SOCO},
  author       = {Alqahtani, Hamed and Kumar, Gulshan},
  doi          = {10.1007/s00500-025-10702-z},
  journal      = {Soft Computing},
  month        = {7},
  number       = {13},
  pages        = {4945-4982},
  shortjournal = {Soft Comput.},
  title        = {A comprehensive review of generative AI techniques and their impact on cybersecurity},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent convolutional strategy for the pose and face recognition. <em>SOCO</em>, <em>29</em>(13), 4933-4944. (<a href='https://doi.org/10.1007/s00500-025-10692-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face pose prediction is a fundamental computer vision job crucial to many applications like facial biometrics, surveillance, Human-computer Interaction (HCI), and surveillance. Several methods have been developed to identify the pose of the face. But, the existence of multiple traits made the forecast more difficult to make. Additionally, the model’s accuracy of recognition declined. So, a novel Chimp-based Zfnet Recognition Mechanism (CbZRM) was designed in this work. The face image data are initialized and filtered for the noise features. Subsequently, the meaningful facial image features from the image are analyzed using the fitness function of the Chimp to identify the facial pose. Later, the detected postures are categorized. The designed CbZRM is implemented in Python with the face pose dataset. The accuracy, Recall, recognition rate, precision, f1-score, and error rate results are obtained and compared with the previous approaches. The CbZRM method achieved a higher performance than the current methods.},
  archive      = {J_SOCO},
  author       = {Jyothi, Ponukumati and Haritha, Dasari and Arava, Karuna},
  doi          = {10.1007/s00500-025-10692-y},
  journal      = {Soft Computing},
  month        = {7},
  number       = {13},
  pages        = {4933-4944},
  shortjournal = {Soft Comput.},
  title        = {Intelligent convolutional strategy for the pose and face recognition},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent techniques for processing and taxonomy of smart city data in mobile ad hoc networks. <em>SOCO</em>, <em>29</em>(13), 4915-4931. (<a href='https://doi.org/10.1007/s00500-025-10690-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile ad hoc networks (MANETs) secured data transmission is crucial for improving the network reliability and efficiency. This study aims to predict a secure way to transmit a data packet to a destination node by developing the route building (RB) stage to ensure secure transmission. The proposed methodology consists of two phases; initially, we harness the Salp Swarm Optimization approach to perform routing refinements and the Cat Swarm Optimization method employed for conducting trust calculations. To improve the network adaptability, we utilized a graphical neural network (GNNs) to develop Virtual Domain Construction (VRC), which creates virtual groups determined by the node power, transmission mode, transmission type packet, as well as distance between the nodes. We build temporary clusters to get around common clustering problems while still satisfying the scalability requirements. The proposed system was simulated using an NS2 simulator and the effectiveness of the system was analysed using the parameters including throughput (96.00%), packet delivery ratio (97.00%), end-to-end delay (3.04s), and network lifetime (95.63%) outperforms the existing methodologies.},
  archive      = {J_SOCO},
  author       = {Sumithra, M. and Vidhyalakshmi, M. and Umamaheshwar, Soma and Mukkapati, Naveen},
  doi          = {10.1007/s00500-025-10690-0},
  journal      = {Soft Computing},
  month        = {7},
  number       = {13},
  pages        = {4915-4931},
  shortjournal = {Soft Comput.},
  title        = {Intelligent techniques for processing and taxonomy of smart city data in mobile ad hoc networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel meta-heuristic optimization algorithm based on cell division: Cell division optimizer. <em>SOCO</em>, <em>29</em>(13), 4879-4913. (<a href='https://doi.org/10.1007/s00500-025-10670-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization algorithms are crucial for solving some of the most intricate problems in engineering and science. Among these methods, meta-heuristic methods use stochastic elements to reach convergence, which is helpful in problems where the landscape is too complex for deterministic exploration. This paper introduces Cell Division Optimizer (CDO), a new meta-heuristic algorithm inspired by the two cell division processes: mitosis and meiosis. Mitosis is used to model exploitation whereas Meiosis is used for exploration. The method incorporates genetic diversity using mutation and crossovers, enhancing the algorithm’s ability to avoid premature convergence at local optima. The proposed method is evaluated over 50 well-known benchmark functions which include simple, unimodal, multimodal, and complex landscape benchmarks. Experiments are also performed for two classical engineering problems to verify the applications of CDO in real-world problems. This performance is compared with eight state-of-the-art algorithms including recently proposed methods and their specialized variants. A statistical analysis was performed to verify the significance of the results. Statistical analysis of 390 sub-experiments shows that CDO significantly outperformed competitors in 280 cases. In our experiments, it is seen that CDO consistently results in giving better solutions which is verified by studying the standard deviation among the results of the experiments. Finally, a convergence analysis is conducted for all the chosen methods. In most experiments, CDO converges to the global best earlier than the other algorithms, while avoiding local optima values.},
  archive      = {J_SOCO},
  author       = {Jain, Sehej and Bharti, Kusum Kumari},
  doi          = {10.1007/s00500-025-10670-4},
  journal      = {Soft Computing},
  month        = {7},
  number       = {13},
  pages        = {4879-4913},
  shortjournal = {Soft Comput.},
  title        = {A novel meta-heuristic optimization algorithm based on cell division: Cell division optimizer},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved butterfly optimization algorithm-support vector machine: Short-term wind power forecasting model. <em>SOCO</em>, <em>29</em>(13), 4857-4877. (<a href='https://doi.org/10.1007/s00500-025-10694-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a hybrid improved butterfly optimization algorithm-support vector machine (SVM) to address the nonlinear and nonstationary characteristics of short-term wind power signals caused by uncertain wind speed factors. (1) This study proposes the Levy flight strategy after each iteration to improve the optimization performance of the butterfly algorithm because the dynamic switching probability strategy and adaptive weight are considered in the traditional butterfly algorithm; (2) the influence of different meteorological factors on wind power output is analyzed, and the input features of the short-term wind power prediction model are determined; and (3) the short-term wind power prediction model is applied to predict the wind power in different seasons and compared with existing prediction methods. High-precision wind power prediction is the solution for promoting the exploitation and utilization of wind. Large-scale wind power grid connections lead to challenges for the safe operation of power grids. The testing results reveal that the proposed improved butterfly optimization algorithm-SVM model improves the short-term wind power prediction accuracy, with a mean value of less than 0.21 compared with those of the butterfly optimization algorithm-SVM, particle swarm optimization-SVM, genetic algorithm-SVM, and back propagation neural network models. High-precision short-term wind power prediction can be used to establish a reasonable economic dispatch plan for power systems and improve the economic benefits of wind farms.},
  archive      = {J_SOCO},
  author       = {Li, Ling-Ling and Qu, Li-Nan and Lin, Guo-Qian and Lim, Ming K. and Tseng, Ming-Lang},
  doi          = {10.1007/s00500-025-10694-w},
  journal      = {Soft Computing},
  month        = {7},
  number       = {13},
  pages        = {4857-4877},
  shortjournal = {Soft Comput.},
  title        = {Improved butterfly optimization algorithm-support vector machine: Short-term wind power forecasting model},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive review of frugal artificial intelligence: Challenges, applications, and the road to sustainable AI. <em>SOCO</em>, <em>29</em>(13), 4823-4856. (<a href='https://doi.org/10.1007/s00500-025-10854-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) has demonstrated its transformative impact in creating learning models, processing extensive datasets, and executing intricate calculations rapidly. Nevertheless, achieving optimal performance with AI models demands substantial investment in powerful and expensive high-end hardware. The learning models running on the hardware are complex, requiring massive data and huge training time. However, the race to achieve higher accuracy and computational limitations of AI further poses a threat to the environment and thus provides motivation to develop AI technology that is cost-effective, scalable, and suitable for resource-constrained environments, Frugal Artificial Intelligence, or Frugal AI. The objective of this paper is to present a detailed survey of the latest concepts and applications of Frugal AI. The definition, concept, history, and evolution of Frugal AI are discussed in the paper. The article presents the key characteristics of Frugal AI, as well as the ethical considerations and techniques needed for developing Frugal AI systems. Further, the challenges in Frugal AI are discussed along with potential future research directions. The paper concludes by highlighting the role of Frugal AI in Industry 4.0. This paper provides a comprehensive overview of Frugal AI and will help researchers, practitioners, and policymakers to better understand the technology and aim for sustainable and green computation.},
  archive      = {J_SOCO},
  author       = {Girdhar, Nancy and Raj, Aditya and Sharma, Deepak and Singh, Vinay and Doucet, Antoine and Renz, Matthias},
  doi          = {10.1007/s00500-025-10854-y},
  journal      = {Soft Computing},
  month        = {7},
  number       = {13},
  pages        = {4823-4856},
  shortjournal = {Soft Comput.},
  title        = {A comprehensive review of frugal artificial intelligence: Challenges, applications, and the road to sustainable AI},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constructing 2-uninorms on bounded lattices by using additive generators. <em>SOCO</em>, <em>29</em>(13), 4807-4821. (<a href='https://doi.org/10.1007/s00500-025-10674-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present two methods to construct 2-uninorms on bounded lattices by using additive generators, which are further used for inducing uninorms, nullnorms, uni-nullnorms and null-uninorms, respectively. We also provide some examples for illustrating the constructing methods of 2-uninorms.},
  archive      = {J_SOCO},
  author       = {Liang, Shudi and Wang, Xue-ping},
  doi          = {10.1007/s00500-025-10674-0},
  journal      = {Soft Computing},
  month        = {7},
  number       = {13},
  pages        = {4807-4821},
  shortjournal = {Soft Comput.},
  title        = {Constructing 2-uninorms on bounded lattices by using additive generators},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Properties and applications of some generalized means of positive sequences. <em>SOCO</em>, <em>29</em>(11), 4791-4805. (<a href='https://doi.org/10.1007/s00500-025-10675-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a simple procedure, in order to aggregate a finite number of real nonnegative values into a unique indicator. Possible applications of this tool can be found in social sciences, including demography, sociology, etc. In particular, the indicator we consider may represent a generalized mean, to be used as an aggregate measure combining several inhomogeneous parameters. Observe that some alternatives to our approach, including complex multicriteria or multiobjective methods, are often discarded by stakeholders (say politicians, public administrators, managers, investors, etc.), since the latters are typically keen on taking decisions based on a reduced number of parameters (possibly only one), and they may be likely reluctant to be responsible for multiple choices. Hence, administrators often show scarce attitude to adopt those methods which provide multiple alternatives, e.g. a Pareto front, since this fact implies an additional responsibility in the process of selection.},
  archive      = {J_SOCO},
  author       = {Corazza, Marco and Fasano, Giovanni and Favaretto, Daniela and Giove, Silvio},
  doi          = {10.1007/s00500-025-10675-z},
  journal      = {Soft Computing},
  month        = {6},
  number       = {11},
  pages        = {4791-4805},
  shortjournal = {Soft Comput.},
  title        = {Properties and applications of some generalized means of positive sequences},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic diabetic retinopathy detection using an ensemble learning approach and classifiers with self-adjusting weights. <em>SOCO</em>, <em>29</em>(11), 4775-4789. (<a href='https://doi.org/10.1007/s00500-025-10773-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR), a common eye disease, can cause extreme damage to the vitals of the patients or even blindness. This disease can cause vision impairment and possibly full blindness in diabetic patients who do not receive the correct diagnosis and treatment in the early stages. Diabetic retinopathy must be detected early since the disease will gradually damage the eye. A computer-aided prognosis-based technique is currently being used to assist clinicians in identifying DR in its earliest stages. The existing approaches for classifying stages of DR have an inadequate ability to reliably detect early stages due to their inability to capture the complex underlying features. The present study aimed to automatically identify the stages of DR disease by evaluating retina image samples using a proposed ensemble machine learning approach with self-adjusting classifier weights. To improve the categorization of various stages of DR, the present study trained an ensemble of three deep Convolutional Neural Network (CNN) models and two machine learning models (ResNet50, Densenet121, Squeezenet1_0, SVM, and decision tree as base learners) using the openly accessible Kaggle dataset of retina pictures, to encode rich characteristics. The study results demonstrate that, in contrast to existing approaches, the proposed model identifies all stages of DR and outperforms state-of-the-art methods on the identical Kaggle dataset, with an accuracy of 98.35%.},
  archive      = {J_SOCO},
  author       = {Nadda, Rahul and Singh, Jitender and Shrivastava, Ullas},
  doi          = {10.1007/s00500-025-10773-y},
  journal      = {Soft Computing},
  month        = {6},
  number       = {11},
  pages        = {4775-4789},
  shortjournal = {Soft Comput.},
  title        = {Automatic diabetic retinopathy detection using an ensemble learning approach and classifiers with self-adjusting weights},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chemical reaction optimization for solving maximum diversity problem. <em>SOCO</em>, <em>29</em>(11), 4759-4773. (<a href='https://doi.org/10.1007/s00500-025-10804-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding a specific-sized set of vertices with the highest pairwise distance from a given graph is known as the Maximum Diversity Problem (MDP). So, the goal of MDP is to determine the largest diverse set of a particular size from a given weighted graph. Multiple metaheuristic approaches were proposed to solve the problem as it is an NP-hard problem. This paper presents a metaheuristic method based on the chemical reaction optimization (CRO) algorithm to solve the problem. CRO is a population-based metaheuristic algorithm to solve optimization problems. Over the past few years, it has effectively solved numerous optimization problems with better results than other metaheuristic algorithms in use. With the help of its four reaction operators, it can explore the solution space locally and globally over the population. Our proposal involves redesigning the four elementary reaction operators of the CRO algorithm and fine-tuning the initial parameters to solve MDP efficiently, as well as building an extra repair operator to increase the quality of the solution in less computational time. A dataset with more than 150 instances is used to observe the performance of our proposed method. The proposed method gives better results with fewer average errors in comparison to methods in the literature. For most of the graphs, the algorithm gives the best-known results mentioned in the datasets. To determine the statistical significance of the difference between our method and other methods, we utilized the Wilcoxon Signed Rank Test on two parts of the dataset, and the results of the tests are significant in both cases.},
  archive      = {J_SOCO},
  author       = {Hasan, Mahmudul and Islam, Md. Rafiqul},
  doi          = {10.1007/s00500-025-10804-8},
  journal      = {Soft Computing},
  month        = {6},
  number       = {11},
  pages        = {4759-4773},
  shortjournal = {Soft Comput.},
  title        = {Chemical reaction optimization for solving maximum diversity problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LDANet: Enhancing USV's capacity for better segmentation of complex waterway scenes. <em>SOCO</em>, <em>29</em>(11), 4743-4757. (<a href='https://doi.org/10.1007/s00500-025-10703-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation-based Complex Waterway Scene Understanding exhibits significant promise in the environmental perception of Unmanned Surface Vehicles (USVs). Existing methods suffer from poor edge estimation of obstacles under blurred water surface conditions and high false positive rates in extreme water conditions. To address these issues, we propose a novel Lightweight Dual-branch Attention Network—LDANet. To enable the model to better analyze scenes from different perspectives, we have refined the dual-branch network structure by incorporating multiple atrous branches for local fusion. Furthermore, to better integrate highly diverse feature information, we introduce the Difference-feature Attention Fusion (DAF) method. This approach utilizes spatial dimension information reorganization to achieve mixed-domain attention calculations. Finally, we employ a clever connection scheme that combines DAF with Parallel Aggregation Pyramid Pooling Module (PAPPM) multi-scale processing, adaptively enhancing both local and global information. Our method achieves an mIoU of 96.2% at 81FPS on the MaSTr1325 dataset, 95.6% mIoU on the LaRS dataset, and 99.13% mIoU on Water Segmentation in the USV Inland. Notably, it excels in handling challenging waterway images with complex lighting conditions, fluctuations, and inhomogeneous reflections. Experimental results demonstrate that LDANet not only provides an effective tool for Complex Waterway Scene Understanding but also serves as a reference for semantic segmentation tasks in other complex environments.},
  archive      = {J_SOCO},
  author       = {Dai, Tongyang and Xiang, Huiyu and Leng, Chongjie and Huang, Song and He, Guanghui and Han, Shishuo},
  doi          = {10.1007/s00500-025-10703-y},
  journal      = {Soft Computing},
  month        = {6},
  number       = {11},
  pages        = {4743-4757},
  shortjournal = {Soft Comput.},
  title        = {LDANet: Enhancing USV's capacity for better segmentation of complex waterway scenes},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Triplet dissimilarity: A texture classification approach using dissimilarity and siamese networks. <em>SOCO</em>, <em>29</em>(11), 4725-4742. (<a href='https://doi.org/10.1007/s00500-025-10677-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Texture classification is a crucial field of investigation in pattern recognition due to its wide-ranging applicability in real-world tasks. In this study, we introduce a novel integration of siamese neural networks and dissimilarity for enhanced texture identification. Unlike traditional dissimilarity approaches that rely on static distance functions (e.g., Euclidean, Manhattan, cosine similarity), our method learns a task-specific dissimilarity function through joint training and triplet loss within a siamese neural network. This adaptive approach allows for a more discriminative feature space, improving robustness in problems with many overlapping classes and limited samples per class. The approach was evaluated on three texture datasets, achieving 99.6% accuracy on the Forest Species Database (FSD), 74.2% on T1K+, and 73.1% on the Describable Texture Dataset (DTD). The results are comparable to state-of-the-art methods on DTD and T1K+ and surpass the state-of-the-art on FSD.},
  archive      = {J_SOCO},
  author       = {Teixeira, Lucas O. and Bertolini, Diego and Oliveira, Luiz S. and Cavalcanti, George D. C. and Costa, Yandre M. G.},
  doi          = {10.1007/s00500-025-10677-x},
  journal      = {Soft Computing},
  month        = {6},
  number       = {11},
  pages        = {4725-4742},
  shortjournal = {Soft Comput.},
  title        = {Triplet dissimilarity: A texture classification approach using dissimilarity and siamese networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep gaussian processes with higher-order interface systems: A novel framework for predictive energy management in electric direct-drive wheels. <em>SOCO</em>, <em>29</em>(11), 4711-4724. (<a href='https://doi.org/10.1007/s00500-025-10750-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient predictive models can contribute to derive improved energy management systems for electric direct-drive wheels. This paper presents Deep Gaussian Processes (DGPs) as the extension of traditional GPs based on additional layered architectures. A controlled lab experiment with a quarter-scale vehicular setup was used to acquire experimental data needed to develop the predictive model. The experimental setup simulates a commercial vehicle driving environment and measures force dynamics converted to energy consumed by the electric direct-drive wheels. In order to develop the predictive model, the higher-order interface systems were first introduced to consider the nonlinear interconnections between GP layers and improve uncertainty propagation along with complex data. A fundamental characteristic of this paper is the theoretical exploration of DGPs based on a methodical technique for adding layers within the DGP framework. This approach helps to manage complex energy consumption predictions in electric commercial vehicles. The inherent properties of DGPs, which emphasize their compositionality are examined. At the same time, the combination of multiple GPs that remain Gaussian are also assessed. Finally, the convergence patterns of the marginal likelihood in deep structures are demonstrated, which defines conditions for its stability and guarantees the model’s adaptability to various data complexities.},
  archive      = {J_SOCO},
  author       = {Taghavifar, Hamid and Mardani, Aref and Mohammadzadeh, Ardashir},
  doi          = {10.1007/s00500-025-10750-5},
  journal      = {Soft Computing},
  month        = {6},
  number       = {11},
  pages        = {4711-4724},
  shortjournal = {Soft Comput.},
  title        = {Deep gaussian processes with higher-order interface systems: A novel framework for predictive energy management in electric direct-drive wheels},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable-AI-assisted feature selection for software change-proneness prediction. <em>SOCO</em>, <em>29</em>(11), 4685-4709. (<a href='https://doi.org/10.1007/s00500-025-10751-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying change-prone areas in software is vital for effective maintenance, as it reduces effort and costs while ensuring high-quality software. Achieving real-time predictions of software change-proneness requires training machine learning (ML) models. However, training ML models on high-dimensional open-source datasets is computationally intensive. Therefore, selecting an optimal set of representative features prior to training is essential to reduce computational demands and improve model performance. To this end, existing studies have applied various feature reduction methods; however, the resulting reduced feature sets can sometimes be less suitable or challenging for software practitioners to interpret effectively. To address this, we propose an end-to-end framework utilizing an explainable AI (XAI) method– SHapley Additive explanations (SHAP)– to identify a minimal, meaningful set of predictors. We tested this approach on six open-source software datasets and statistically compared its feature selection capabilities against three traditional methods using six ML algorithms. Our results indicate that machine learning models built using features selected by SHAP achieved higher AUC scores and demonstrated more consistent performance across most of the evaluated datasets. The average AUC obtained through 10-fold cross-validation using SHAP-selected features was $$0.61 \pm 0.05$$ at the 95% confidence level. In addition to improved performance, SHAP-based models offered enhanced interpretability, enabling software practitioners to devise more effective maintenance strategies while monitoring a reduced set of features.},
  archive      = {J_SOCO},
  author       = {Rajpal, Ankit and Khanna, Megha and Singhal, Naman},
  doi          = {10.1007/s00500-025-10751-4},
  journal      = {Soft Computing},
  month        = {6},
  number       = {11},
  pages        = {4685-4709},
  shortjournal = {Soft Comput.},
  title        = {Explainable-AI-assisted feature selection for software change-proneness prediction},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient thermal comfort estimation employing the C-mantec constructive neural network model. <em>SOCO</em>, <em>29</em>(11), 4673-4684. (<a href='https://doi.org/10.1007/s00500-025-10676-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermal comfort is the condition in which a person feels satisfaction with the thermal environment through a subjective evaluation. In this work, a compact and efficient estimation of thermal comfort perception by human subjects is performed using a constructive neurocomputational model trained with data generated in controlled conditions with 49 volunteers giving 705 different scenarios, allowing, thanks to the versatility of the model, an interpretable and simple resulting function facilitating an easy handling of the results by people from different fields. The results have been compared with two of the most used standard methods for modelling thermal comfort: Fanger and COMFA models, and they show an improvement in terms of accuracy and mean square error both in a binary decision scenario (comfort or not) as well as for a discrete decision-making case in which different thermal comfort regions are considered. The flexibility of the neural model permits the incorporation of extra subject-related variables that increases further the thermal comfort estimation and, also, permits the implementation of the model in distributed and low cost/low consumption systems.},
  archive      = {J_SOCO},
  author       = {Ortega-Zamorano, Francisco and Jerez, José M. and Rodríguez-Alabarce, José and Goreishi, Kusha and Franco, Leonardo},
  doi          = {10.1007/s00500-025-10676-y},
  journal      = {Soft Computing},
  month        = {6},
  number       = {11},
  pages        = {4673-4684},
  shortjournal = {Soft Comput.},
  title        = {Efficient thermal comfort estimation employing the C-mantec constructive neural network model},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Q-learning improved RBM for rate prediction in recommendation systems. <em>SOCO</em>, <em>29</em>(11), 4659-4671. (<a href='https://doi.org/10.1007/s00500-025-10744-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems play a critical role in enhancing user experiences across various online platforms by delivering personalized content. However, traditional learning algorithms, including Restricted Boltzmann Machines (RBMs), often face significant challenges when dealing with large data volumes and sparse data distributions, which can lead to instability and poor performance. To address these shortcomings, this paper presents two novel algorithms: RBM-Q-Learning 1 and RBM-Q-Learning 2. These algorithms introduce advanced mechanisms for state representation and action selection, specifically designed to improve stability and robustness during the training process. The effectiveness of the proposed methods is evaluated through extensive experiments on three datasets from the MovieLens platform—MovieLens 100K, 1M and 10M. Performance is measured using MAE, RMSE, HR, ARHR, Diversity, and Novelty metrics. Our findings demonstrate that the proposed algorithms achieve significantly improved stability and performance, particularly in handling large-scale and sparse data, thus offering a more reliable solution compared to conventional approaches.},
  archive      = {J_SOCO},
  author       = {Yelği, Arif},
  doi          = {10.1007/s00500-025-10744-3},
  journal      = {Soft Computing},
  month        = {6},
  number       = {11},
  pages        = {4659-4671},
  shortjournal = {Soft Comput.},
  title        = {Q-learning improved RBM for rate prediction in recommendation systems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective mobile robot path planner by optimizing multiple performance parameters inspired by sparrow’s anti-predation exploration ability. <em>SOCO</em>, <em>29</em>(11), 4641-4658. (<a href='https://doi.org/10.1007/s00500-025-10686-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile robot path planning is a significant area of research that involves determining the most effective path for a robot to reach its destination by avoiding obstacles. The most crucial aspect of mobile robot path planning is selecting the appropriate algorithm. The existing optimization algorithms used different strategies but still faced some issues, such as longer path length, slow convergence rate, less smoothness, and frequent oscillation. Therefore, considering the challenges faced by existing algorithms, a novel smart sparrow search algorithm (SSSA) is proposed. The proposed technique takes advantage of the sparrow’s anti-predation exploration ability for mobile robot path planning. Three different strategies are proposed in the smart sparrow search algorithm. Firstly, a smooth path search (SPS) approach based on the Steiner waypoint is adopted to enhance the attained path smoothness. Secondly, a neighborhood search approach based on predator (obstacles) distance is employed to improve the predation rate of the population. Lastly, a new location update approach based on a robust learning factor is applied to increase the convergence rate. Several comparative experiments are carried out in three different test situations of varying complexity. Different multiple path planning performance parameters such as path length, convergence rate, path smoothness, and execution time are being assessed to prove the efficacy of the proposed technique. The comparative analysis signifies that the proposed technique surpasses the improved ACO, ACO- $$\:{A}^{*}$$ , and ISSA with a maximum improvement (%) of 14.28% in path length, 49.01% in execution time, 36.88% in path smoothness, and 29.02% in convergence rate.},
  archive      = {J_SOCO},
  author       = {Kumar, Sunil and Sikander, Afzal},
  doi          = {10.1007/s00500-025-10686-w},
  journal      = {Soft Computing},
  month        = {6},
  number       = {11},
  pages        = {4641-4658},
  shortjournal = {Soft Comput.},
  title        = {An effective mobile robot path planner by optimizing multiple performance parameters inspired by sparrow’s anti-predation exploration ability},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TODIM-EDAS decision-making framework for emergency management capability evaluation of large-scale sports events under the background of rural revitalization. <em>SOCO</em>, <em>29</em>(11), 4627-4639. (<a href='https://doi.org/10.1007/s00500-025-10769-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sports emergencies refer to a type of event that suddenly occurs in the field of sports, has close ties with events or individuals in the sports field, endangers the safety of sports participants or the general public’s lives and property, causes or may cause serious social harm, and requires emergency measures from sports management departments, relevant organizations, and individuals to respond. Sports emergencies have characteristics such as suddenness, variability, publicness, and harmfulness. It is necessary to summarize the characteristics and occurrence patterns of sports emergencies to achieve effective prevention and response. The emergency management capability evaluation of large-scale sports events is a multiple-attribute decision-making (MADM). Recently, the TODIM and EDAS approach was employed to manage MADM. The Z-number is employed as a tool for portraying uncertain information during the emergency management capability evaluation of large-scale sports events. In this paper, the Z-number TODIM-EDAS (ZN-TODIM-EDAS) approach is built to manage the MADM under Z-number. Finally, a numerical case study for emergency management capability evaluation of large-scale sports events is built to verify the ZN-TODIM-EDAS approach.},
  archive      = {J_SOCO},
  author       = {Yang, Feng and Xiao, Minyu and Xu, Ke},
  doi          = {10.1007/s00500-025-10769-8},
  journal      = {Soft Computing},
  month        = {6},
  number       = {11},
  pages        = {4627-4639},
  shortjournal = {Soft Comput.},
  title        = {TODIM-EDAS decision-making framework for emergency management capability evaluation of large-scale sports events under the background of rural revitalization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modified framework for sports event brand building evaluation with 2-tuple linguistic neutrosophic number group decision-making. <em>SOCO</em>, <em>29</em>(11), 4613-4625. (<a href='https://doi.org/10.1007/s00500-025-10787-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sports event branding evaluation focuses on measuring the effectiveness of a brand in building recognition, loyalty, and emotional connections with its audience. Key aspects include brand visibility, consistency, audience engagement, sponsorship effectiveness, and reputation management. A strong brand can elevate the event’s value, attract high-profile sponsors, and boost fan loyalty. Metrics such as social media impressions, merchandise sales and audience surveys are used to assess branding success. Effective evaluation helps refine strategies, ensuring long-term growth and a competitive edge in the sports industry. The sports event brand building evaluation involves MAGDM. Currently, the Logarithmic TODIM (LogTODIM) approach and the grey relational analysis (GRA) approach have been widely applied to address multi-attribute group decision-making (MAGDM) challenges. To better handle uncertain and imprecise information in the evaluation of sports event brand building, the 2-tuple linguistic neutrosophic set (2TLNS) framework has emerged as a valuable tool. This paper proposes a novel method that integrates the 2-tuple linguistic neutrosophic number (2TLNN) with Logarithmic TODIM-GRA (2TLNN-LogTODIM-GRA) approach. The method leverages the 2TLNN Hamming distance (2TLNNHD) and the 2TLNN Euclidean distance (2TLNNED) to effectively address MAGDM problems in complex, uncertain environments using 2TLNSs. By combining the strengths of Logarithmic TODIM and GRA, this approach provides a robust and comprehensive framework for evaluating sports event brand building while accommodating linguistic and neutrosophic uncertainty. Furthermore, to demonstrate the practicality and reliability of this approach, a numerical case study is conducted. The results validate the effectiveness of the 2TLNN-LogTODIM-GRA method in handling MAGDM problems and its applicability in the context of sports event brand building evaluation. This study contributes a novel perspective to the field, offering a powerful tool for decision-makers to navigate uncertainty in brand evaluation processes.},
  archive      = {J_SOCO},
  author       = {Lian, Jie and Hwan, Choi Kyung and Hu, Yongqing},
  doi          = {10.1007/s00500-025-10787-6},
  journal      = {Soft Computing},
  month        = {6},
  number       = {11},
  pages        = {4613-4625},
  shortjournal = {Soft Comput.},
  title        = {Modified framework for sports event brand building evaluation with 2-tuple linguistic neutrosophic number group decision-making},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fine-kinney-based new approach for occupational health and safety risk assessment using interval-valued neutrosophic MCDM and HOQ model integration. <em>SOCO</em>, <em>29</em>(11), 4583-4612. (<a href='https://doi.org/10.1007/s00500-025-10693-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Risk assessment in the ergonomics area is critical for controlling hazards and ensuring occupational health and safety (OHS) in workplaces. Risk assessment often employs the Fine-Kinney method (FKM). The FKM-based evaluation approach has the disadvantages of not addressing uncertainties arising from the assessments of OHS specialists’ and from the imprecise data, and of not determining the risk precedence of occupational hazards and the precedence of measures to be taken. Thus, a novel system is needed to provide a more comprehensive and accurate assessment. In this study, an integrated model is developed that combines FKM, Multi-Criteria Decision-Making (MCDM) methods AHP and CoCoSo, and the House of Quality (HOQ) method under the interval-valued neutrosophic (IVN) environment. For this purpose, the risk parameters of FKM are evaluated using IVN-AHP, and the hazards are ranked through the IVN-CoCoSo method. Then, the preventive measures are prioritized by the IVN-HOQ method. The proposed model is applied for the risk assessment of the excavation work at a building construction site. The findings show that the failure to determine the location of the lines is the most important hazard while taking specific safety measures appropriate for critical activities and ensuring strict compliance is the most important measure with a 13% significance share. To validate the new risk assessment approach, a comparative study is also provided. This study will enhance the current ergonomics risk evaluation mechanism in the construction industry and contribute to making better decisions in this field.},
  archive      = {J_SOCO},
  author       = {Toptanci, Şura and Erginel, Nihal and Acar, Ilgin},
  doi          = {10.1007/s00500-025-10693-x},
  journal      = {Soft Computing},
  month        = {6},
  number       = {11},
  pages        = {4583-4612},
  shortjournal = {Soft Comput.},
  title        = {A fine-kinney-based new approach for occupational health and safety risk assessment using interval-valued neutrosophic MCDM and HOQ model integration},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conformable modeling of normalization and recursional soft spacelike magnetic curves. <em>SOCO</em>, <em>29</em>(11), 4571-4582. (<a href='https://doi.org/10.1007/s00500-025-10689-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate spacelike magnetic curves according to Bishop frame. Firstly, we present conformable derivatives of Lorentz magnetic fields of these magnetic curves. Moreover, we calculate the conformable derivatives of the normalization and recursional electromagnetic vector fields. Finally, we give conformable energies of normalization and recursional electromagnetic fields related to spacelike magnetic curves.},
  archive      = {J_SOCO},
  author       = {Körpinar, Talat and Körpinar, Zeliha and Özdemir, Hatice},
  doi          = {10.1007/s00500-025-10689-7},
  journal      = {Soft Computing},
  month        = {6},
  number       = {11},
  pages        = {4571-4582},
  shortjournal = {Soft Comput.},
  title        = {Conformable modeling of normalization and recursional soft spacelike magnetic curves},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced ExpTODIM framework based on VIKOR for interval-valued intuitionistic fuzzy multiple-attribute group decision-making and applications to for college english blended teaching quality evaluation. <em>SOCO</em>, <em>29</em>(11), 4559-4570. (<a href='https://doi.org/10.1007/s00500-025-10778-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In college education, English is a mandatory course for all students, with undergraduate institutions setting specific proficiency requirements. The quality of college English blended teaching (CEBT) is crucial as it directly impacts student learning outcomes. Teaching quality serves as a vital indicator for assessing the effectiveness of English instruction. However, evaluating learning quality is a complex process that encompasses numerous factors, including evaluation indicators and methods. Consequently, developing an objective and scientific system for assessing English teaching quality presents a significant challenge. The quality evaluation of CEBT is a multi-attribute group decision-making (MAGDM) problem. To address this, the Exponential TODIM (ExpTODIM) and VIKOR methods were utilized to establish a MAGDM framework. Interval-valued intuitionistic fuzzy sets (IVIFSs) are employed to depict uncertain information during the CEBT quality evaluation. In this study, entropy and score values are used to determine objective weights. Subsequently, an integrated interval-valued intuitionistic fuzzy number ExpTODIM -VIKOR (IVIFN-ExpTODIM-VIKOR) method is developed to tackle the MAGDM challenge. An illustrative example of CEBT quality evaluation, along with comparative analysis, is provided to demonstrate the validity and reliability of the IVIFN-ExpTODIM-VIKOR method.},
  archive      = {J_SOCO},
  author       = {Huang, Yuan and Tang, Ming},
  doi          = {10.1007/s00500-025-10778-7},
  journal      = {Soft Computing},
  month        = {6},
  number       = {11},
  pages        = {4559-4570},
  shortjournal = {Soft Comput.},
  title        = {Enhanced ExpTODIM framework based on VIKOR for interval-valued intuitionistic fuzzy multiple-attribute group decision-making and applications to for college english blended teaching quality evaluation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An empirical analysis to test the ability of multi-criteria methods to explain some behavioural anomalies. <em>SOCO</em>, <em>29</em>(9), 4549-4558. (<a href='https://doi.org/10.1007/s00500-025-10630-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of the processes that lead to choices and the elements that condition them converges in decision theory Keeney and Raiffa (1993). In most cases, the theories that deal with decisions presuppose the perfect rationality of the decision-maker and therefore, the ability to identify the best choice through an essentially analytical process that can always be traced back to logical structures. In this sense, for years the theory par excellence was the theory of expected utility Von Neumann and Morgenstern (1947). In reality, however, perfect rationality does not always represent a model capable of interpreting the processes of choice Tversky and Kahneman (1974). In fact, empirical studies have shown that decision-makers implement a series of heuristics in making a choice, which causes the violation of the axioms of rationality. Re-proposing a famous Kahneman and Tversky empirical experiment based on prospects Tversky and Kahneman (1989), this work aims to study the preferences of decision-makers by relating the behavioural anomalies found and multi-criteria methods. On the obtained outputs, we test three different multi-criteria methods – ELECTRE III, PROMETHEE and TOPSIS – to determine whether they are able to explain the behaviour of the decision-makers. The results of our study show that the TOPSIS method provides a ranking that reflects the preferences expressed by the majority of individuals.},
  archive      = {J_SOCO},
  author       = {Fattoruso, Gerarda and Marcarelli, Gabriella},
  doi          = {10.1007/s00500-025-10630-y},
  journal      = {Soft Computing},
  month        = {5},
  number       = {9},
  pages        = {4549-4558},
  shortjournal = {Soft Comput.},
  title        = {An empirical analysis to test the ability of multi-criteria methods to explain some behavioural anomalies},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating the dynamics of digital technology in enhancing the overall effectiveness of china's national innovation systems: A study based on VHSD and EM approach. <em>SOCO</em>, <em>29</em>(9), 4525-4547. (<a href='https://doi.org/10.1007/s00500-025-10613-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with the gradual entry of the world into the digital era, digital technologies have flourished and have been silently integrated into the innovation processes of technology research and development, transformation, application, and diffusion. In the countries' efforts to establish and strengthen national innovation systems (NIS), the development of digital technologies has received increasing attention. It has become a key driving force for the optimal growth and effective operation of national innovation systems. This study quantitatively assesses the overall effectiveness of China's national innovation system (NIS) using data from 30 provinces in China from 2012 to 2022, employing the Vertical and Horizontal Scatter Degree Method (VHSD), Entropy Method (EM), and coupled coordination models, and examines the external impact, internal mechanism and spatial heterogeneity of the development of digital technologies on the overall effectiveness of national innovation systems in the light of the characteristics of the digital era. The study results show spatial aggregation in the overall effectiveness of national innovation systems, with regions with high overall effectiveness clustering and areas with low overall effectiveness clustering. Second, the development of digital technology improves the overall effectiveness of national innovation systems, which is confirmed by endogeneity treatment and various robustness tests. Third, digital technology improves the overall effectiveness of national innovation systems by promoting the development of a service-oriented industrial structure and active labor market. Fourth, the impact of digital technologies on the overall effectiveness of national innovation systems is spatially heterogeneous. It is less pronounced in the Northeast and East but very significant in the Central and West, and the main reasons for this counterfactual result can perhaps be explained in terms of both diminishing marginal effects and policy tilting effects. Finally, this study not only gives corresponding policy recommendations but also further discusses the dilemmas and challenges that may be encountered in implementing these policies.},
  archive      = {J_SOCO},
  author       = {Wei, Chen and Hong-ti, Song},
  doi          = {10.1007/s00500-025-10613-z},
  journal      = {Soft Computing},
  month        = {5},
  number       = {9},
  pages        = {4525-4547},
  shortjournal = {Soft Comput.},
  title        = {Evaluating the dynamics of digital technology in enhancing the overall effectiveness of china's national innovation systems: A study based on VHSD and EM approach},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strategies for capital and carbon emission constrained manufacturer in a retailer-led supply chain: Credit financing vs. bank loan. <em>SOCO</em>, <em>29</em>(9), 4505-4523. (<a href='https://doi.org/10.1007/s00500-025-10576-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To promote sustainable development, manufacturers must effectively reduce their carbon emissions. However, doing so often incurs higher costs for carbon emission reduction (CER), which can worsen the capital-constrained problems faced by manufacturers operating within a retailer-led supply chain. To address this challenge and optimize CER efficiency within limited funds, we propose a two-echelon supply chain model led by a retailer. We then analyze six different scenarios, including no financing, bank loan financing and retailer credit financing, both with and without CER investment, to identify optimal strategies for each situation. The results show that: (1) Increasing interest rates on bank loans and retailer credit will have a negative impact on the CER efficiency and retailer’s profits. (2) If the initial funds are below a certain threshold, a higher interest rate on bank loans will reduce the manufacturer’s profits. However, as the initial funds increase, a higher interest rate can improve the manufacturer’s profits with the retailer’s credit financing strategy. (3) The manufacturer’s optimal financing strategy depends on both the interest rates and initial funds, while the retailer's credit decision is solely based on the manufacturer’s initial funds. (4) The retailer credit financing strategy can lead to a mutually beneficial outcome by adjusting the interest rate of the retailer credit, thereby improving the CER efficiency and relieving financial pressure. However, the bank loan financing strategy does not have this advantage.},
  archive      = {J_SOCO},
  author       = {Yu, Zhaoqing and Li, Jing},
  doi          = {10.1007/s00500-025-10576-1},
  journal      = {Soft Computing},
  month        = {5},
  number       = {9},
  pages        = {4505-4523},
  shortjournal = {Soft Comput.},
  title        = {Strategies for capital and carbon emission constrained manufacturer in a retailer-led supply chain: Credit financing vs. bank loan},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating the role of external information on the choice of weights for aggregating judgments in group decisionmaking: The impact of financial education on investors’ choices. <em>SOCO</em>, <em>29</em>(9), 4495-4503. (<a href='https://doi.org/10.1007/s00500-025-10604-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the last few decades, the attention to Financial Education has produced a growing interest to explore the link between Financial Literacy and Financial Behaviour. However, the first consequence of this attention is that there is no clear definition of Financial Literacy. Moreover, the review of the literature on this topic shows a fragmentation, and this has prevented the formulation of a unified point of view on Financial Literacy and investors’ behaviour relation. For these reasons, this topic requires new and deeper studies. In this paper, we propose a theoretical model to study if financial education and Financial Literacy influence the diversification strategies in financial choices. Following the model suggested by Rossi et al. (Int J Anal Hierarchy Process 12(2) 2020), for evaluating an investment choice, we analyse three criteria: the return of the stock market, the performance of government bonds and the calendar effects in the financial markets. Then, in order to test the impact of Financial Education on decision-making investors’ process, we submitted a questionnaire to three groups of operators with different levels of financial education. Since group membership may affect the investment choice, we consider external information Takane and Shibayama (Psychometrika 56(1):97–120, 1991) to compute a set of suitable weights and aggregate individual judgments in a common group preference matrix according to the procedure introduced by Amenta et al. (Euro J Oper Res 288(1):294-301, 2021). The analysis takes into account this information and produces three different priority vectors: the first one concerns the global analysis, the second one shows the ranking due to membership to the different groups and the last one represents what cannot be explained by external information.},
  archive      = {J_SOCO},
  author       = {Amenta, Pietro and Lucadamo, Antonio and Marcarelli, Gabriella and Rossi, Matteo},
  doi          = {10.1007/s00500-025-10604-0},
  journal      = {Soft Computing},
  month        = {5},
  number       = {9},
  pages        = {4495-4503},
  shortjournal = {Soft Comput.},
  title        = {Evaluating the role of external information on the choice of weights for aggregating judgments in group decisionmaking: The impact of financial education on investors’ choices},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatio-temporal graph neural networks to improve precipitation forecasts from numerical models. <em>SOCO</em>, <em>29</em>(9), 4481-4494. (<a href='https://doi.org/10.1007/s00500-025-10635-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weather forecasting has always been a fascinating challenge due to the randomness, difficulty and multiple intersections in the spatiotemporal distribution of several atmospheric processes. The classical approach for weather forecasting is based on numerical weather prediction (NWP). However, this approach is subject to errors and criticism as it is unable to predict severe events accurately, especially if located in complex areas characterized by steep orographic effects or strong air-sea interactions. In this work, a Deep Learning (DL) methodology has been applied to improve the one-day ahead precipitation accuracy of the Weather Research and Forecasting (WRF) NWP system by correcting the prediction error. The WRF data consists of a spatial resolution of 2 km and refers to a portion of the Calabria region (Italy). A weather station network of 22 gauges has been considered inside this latter area. The meteorological data for the whole year of 2021 and 4 months of 2022 is considered for training and evaluation respectively. The developed DL model is based on Spatio-Temporal Graph Neural Network (called WRF-GNN). The improved prediction has been compared with observed precipitation data from the rain gauge network, the WRF output, Random Forest (WRF-RF), XGBoost (WRF-XGB), and another Artificial Neural Network (WRF-ANN) model. The WRF-GNN significantly enhanced the prediction accuracy compared to the WRF and WRF-ANN models, with an improvement from + 16 to + 34% with respect to WRF, by minimizing the error compared to observations.},
  archive      = {J_SOCO},
  author       = {Yousaf, Umair and De Rango, Alessio and Furnari, Luca and D’Ambrosio, Donato and Senatore, Alfonso and Mendicino, Giuseppe},
  doi          = {10.1007/s00500-025-10635-7},
  journal      = {Soft Computing},
  month        = {5},
  number       = {9},
  pages        = {4481-4494},
  shortjournal = {Soft Comput.},
  title        = {Spatio-temporal graph neural networks to improve precipitation forecasts from numerical models},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A life cycle-oriented patent quality analysis: A machine learning approach. <em>SOCO</em>, <em>29</em>(9), 4461-4479. (<a href='https://doi.org/10.1007/s00500-025-10654-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The early identification of high-quality patents is the bedrock of decision-making. However, traditional patent quality evaluations pay little attention to the legal stability or the evolving technology circumstance, nor the phenomenon that patent quality changes during its life cycle. This paper proposes a life cycle-oriented patent quality analysis with the legal stability, technology circumstance and multiple patent life stages considered. To begin with, a proxy variable for high-quality patents is found, and 8810 patents are searched in line with the proxy variable to build the dataset. Furthermore, 11 pre-application indicators and 11 post-authorization indicators are collected, among which 18 are patent-based internal indicators and 4 are technology-based external indicators. Moreover, two analysis models are constructed with one for pre-application stage and the other for post-authorization stage, and machine learning techniques are employed to make the assessment more objective and automatic. In addition, the importance of each indicator is evaluated to identify their ranks and check whether the results are in line with previous research. The proposed analysis saves valuable time orientating to the early identification of high-quality patents and provides effective decision-making supports targeting for the formulation of patent strategies.},
  archive      = {J_SOCO},
  author       = {Guo, Qing and Qi, Yong and Kang, Zhengyang and Jiang, Fan},
  doi          = {10.1007/s00500-025-10654-4},
  journal      = {Soft Computing},
  month        = {5},
  number       = {9},
  pages        = {4461-4479},
  shortjournal = {Soft Comput.},
  title        = {A life cycle-oriented patent quality analysis: A machine learning approach},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust prediction method for pedestrian trajectories in occluded video scenarios. <em>SOCO</em>, <em>29</em>(9), 4449-4459. (<a href='https://doi.org/10.1007/s00500-025-10664-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In smart surveillance and intelligent transportation systems, accurately predicting pedestrian movements, especially under occlusions, remains a significant challenge. Traditional surveillance methods, primarily based on fixed CCTV footage, often overlook occlusions, noise, and camera angle changes, leading to inaccuracies in pedestrian trajectory predictions. Addressing this gap, our research introduces a novel trajectory prediction system optimized for various walking and filming conditions. By leveraging the ETH/UCY dataset, we simulate scenarios where pedestrians are temporarily obscured, employing re-identification techniques upon their reappearance to ensure path continuity. Our system utilizes linear prediction to reconstruct missing paths, integrating these with the PECNET baseline model for future path forecasting. This methodology allows for the effective handling of occlusions, a common yet underaddressed issue in current studies. Performance evaluation using Average Displacement Error (ADE) and Final Displacement Error (FDE) metrics reveals our system achieves an ADE of 0.25 m and an FDE of 0.50 m, demonstrating comparable accuracy to predictions based on fully visible paths within the same dataset. These results highlight our approach's efficacy in complex environments, marking a significant step forward in occlusion-aware pedestrian movement analysis and prediction for enhanced surveillance system accuracy.},
  archive      = {J_SOCO},
  author       = {Seo, Aria and Jeon, Hyeonjin and Son, Yunsik},
  doi          = {10.1007/s00500-025-10664-2},
  journal      = {Soft Computing},
  month        = {5},
  number       = {9},
  pages        = {4449-4459},
  shortjournal = {Soft Comput.},
  title        = {Robust prediction method for pedestrian trajectories in occluded video scenarios},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A class of embedded fuzzy PD controller for robot manipulator: Analytical structures and stability analysis. <em>SOCO</em>, <em>29</em>(9), 4423-4448. (<a href='https://doi.org/10.1007/s00500-025-10663-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a two-degree-of-freedom (2-DOF) fuzzy proportional-derivative (FPD) controller for controlling a robot manipulator practically. The suggested controller combines the advantages of a 2-DOF structure and the FPD structure to obtain an intelligent controller, which can reduce the system’s uncertainties. These uncertainties are unknown disturbances, variation, payload, and cross-coupling effects between joints. The analytical structure for the developed scheme is derived to show the relationship between the inputs and output of the controller. Moreover, the sufficient conditions for the bounded-input bounded-output (BIBO) stability of the proposed control system have been performed based on the well-known small gain theorem. The proposed 2-DOF FPD is designed experimentally using a microcontroller. The proposed controller's performance is compared with conventional PID, 2-DOF PID, and fuzzy PD controllers through simulations and practical experiments. The 2-DOF FPD controller achieved a 20–30% reduction in mean absolute error and root mean square error during trajectory tracking and disturbance rejection tasks. This significant improvement is attributed to the controller's ability to effectively handle nonlinearities and uncertainties in the system.},
  archive      = {J_SOCO},
  author       = {El-Nagar, Ahmad M. and Abdrabou, Atef and El-Bardini, Mohammad and Elsheikh, Emad A.},
  doi          = {10.1007/s00500-025-10663-3},
  journal      = {Soft Computing},
  month        = {5},
  number       = {9},
  pages        = {4423-4448},
  shortjournal = {Soft Comput.},
  title        = {A class of embedded fuzzy PD controller for robot manipulator: Analytical structures and stability analysis},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A modified fruit fly optimization algorithm to active disturbance rejection control parameters tuning for trajectory tracking of omnidirectional mobile robotic chassis. <em>SOCO</em>, <em>29</em>(9), 4401-4421. (<a href='https://doi.org/10.1007/s00500-025-10638-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve the more effective and robust trajectory tracking performance for the omnidirectional mobile robotic chassis (OMRC), a control system is designed by combining the linear active disturbance rejection control (LADRC) and proportional-integral-derivative (PID) methods, while a novel modified fruit fly optimization algorithm (Le-OFFO) is proposed to achieve the optimal parameters for the designed controller. The PID controller is utilized to the outer loop for trajectory tracking and LADRC controller is applied to the inner loop for the control of torque of each motor. A fitness function is established to evaluate the cost of control system, with several metrics and constraints taking into consideration. The proposed Le-OFFO algorithm combines the levy flight and the opposition-based learning (OBL) operators, in which the levy flight can help to escape from local optimum and the OBL-based mutation operator can enhance the exploration ability. The optimal parameters combination for the designed control system can be achieved by using the Le-OFFO to minimize the objective function. Numerous results show that the Le-OFFO has better performance of convergence speed and exploitation capability compared with other optimization algorithms in solving the controller parameter tuning problem. In addition, the effectiveness of the optimized LADRC controller is validated by results of experiments when compared with basic PID controller and original ADRC controller.},
  archive      = {J_SOCO},
  author       = {Zhang, Xiangyin and Wu, Weihuan and Li, Xiuzhi},
  doi          = {10.1007/s00500-025-10638-4},
  journal      = {Soft Computing},
  month        = {5},
  number       = {9},
  pages        = {4401-4421},
  shortjournal = {Soft Comput.},
  title        = {A modified fruit fly optimization algorithm to active disturbance rejection control parameters tuning for trajectory tracking of omnidirectional mobile robotic chassis},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thinking fast: A bionic approach to soft computing. <em>SOCO</em>, <em>29</em>(9), 4377-4399. (<a href='https://doi.org/10.1007/s00500-025-10619-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolution has enabled living organisms to respond to sensory input very fast in order to safeguard their chances of survival. This ability is largely based on the classification of perceptions into categories and their collective processing in associative structures. These associative structures, in turn, have a remarkable similarity to the biological neural networks which perform them. The author has chosen this natural way of thinking fast as a model for an innovative bionic approach to soft computing.},
  archive      = {J_SOCO},
  author       = {Grotrian, Jens},
  doi          = {10.1007/s00500-025-10619-7},
  journal      = {Soft Computing},
  month        = {5},
  number       = {9},
  pages        = {4377-4399},
  shortjournal = {Soft Comput.},
  title        = {Thinking fast: A bionic approach to soft computing},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimising transportation plans for multi-warehouse, multi-product systems: Mitigating the impact of new purchase and sales orders. <em>SOCO</em>, <em>29</em>(9), 4359-4376. (<a href='https://doi.org/10.1007/s00500-025-10621-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the rapidly evolving landscape of supply chain management, the agility to adapt to changing demands while maintaining operational efficiency is paramount. This paper introduces a novel approach to managing transportation plans within a multi-warehouse, multi-product framework, focussing on minimising disruptions to existing schedules in response to new purchase and sales orders. Our research aims to redefine existing transportation plans, originally set before the arrival of additional orders, with the objective of implementing the least possible alterations while satisfying all customer requirements. The primary challenge addressed in this study is to maintain stock levels above a predefined minimum threshold in various warehouses without compromising the efficiency of the distribution network. Unlike traditional routing problems, the focus is not on selecting the routes for transportation, but on strategically deciding when to initiate a vehicle trip or adjusting the number of products in already scheduled trips. To address the problem, a mixed-integer linear programming model based on a flow network graph is proposed. To reduce the size of the network, exact and heuristic pre-processing procedures are developed. A first set of computational tests was conducted on data provided by a textile industry that needs to minimise changes in the transport plan to meet the variation in demand for different goods. A detailed analysis of the results of instances with up to 14,000 products and 23 million items is reported. Further computational tests were randomly generated to verify the efficiency of the proposed techniques in different scenarios. The promising results of the computational tests highlight the applicability of the proposed approach in the industrial scenario analysed.},
  archive      = {J_SOCO},
  author       = {Carmine, Cerrone and Raffaele, Dragone and Anna Franca, Sciomachen},
  doi          = {10.1007/s00500-025-10621-z},
  journal      = {Soft Computing},
  month        = {5},
  number       = {9},
  pages        = {4359-4376},
  shortjournal = {Soft Comput.},
  title        = {Optimising transportation plans for multi-warehouse, multi-product systems: Mitigating the impact of new purchase and sales orders},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: One-phasemulti-view clustering with unified graph and data representation convolution. <em>SOCO</em>, <em>29</em>(9), 4357. (<a href='https://doi.org/10.1007/s00500-025-10665-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Dornaika, F. and Charafeddine, J.},
  doi          = {10.1007/s00500-025-10665-1},
  journal      = {Soft Computing},
  month        = {5},
  number       = {9},
  pages        = {4357},
  shortjournal = {Soft Comput.},
  title        = {Correction: One-phasemulti-view clustering with unified graph and data representation convolution},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One-phase multi-view clustering with unified graph and data representation convolution. <em>SOCO</em>, <em>29</em>(9), 4335-4356. (<a href='https://doi.org/10.1007/s00500-025-10533-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of multi-view clustering is to partition unlabeled objects into disjoint clusters or groups using consistent and complementary information provided by the different features of the same object. Most existing methods perform this clustering task sequentially: Computation of the individual or consistent graph matrices, spectral embedding, and clustering. In this work, we present an approach that can overcome some of the limitations of previous multiview clustering methods. We introduce a single objective function whose minimization can jointly determine the consistent graph matrix for all views, the unified spectral data representation, the soft cluster indices, and the view weights. We present a constraint term that relates the cluster indices to the convolution of the consistent spectral data representations over the consistent graph. The method we present has two interesting features that are not simultaneously present in recent work. First, the cluster indices can be estimated directly without the need for an additional clustering step, which depends heavily on initialization. Second, the soft cluster indices are directly linked to the kernel representation of the features of the views. Moreover, our proposed method automatically determines the weights of each view, thus requiring fewer hyperparameters. A series of experiments have been conducted on real datasets. These demonstrate the efficiency of the proposed method, which compares favorably to many multi-view clustering methods.},
  archive      = {J_SOCO},
  author       = {Dornaika, F. and Charafeddine, J.},
  doi          = {10.1007/s00500-025-10533-y},
  journal      = {Soft Computing},
  month        = {5},
  number       = {9},
  pages        = {4335-4356},
  shortjournal = {Soft Comput.},
  title        = {One-phase multi-view clustering with unified graph and data representation convolution},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploiting the geometry of heterogeneous networks: A case study of the indian stock market. <em>SOCO</em>, <em>29</em>(9), 4317-4334. (<a href='https://doi.org/10.1007/s00500-025-10606-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we model the Indian stock market as heterogenous scale free network, which is then embedded in a two dimensional hyperbolic space through a machine learning based technique called as coalescent embedding. This allows us to apply the hyperbolic kmeans algorithm on the Poincare disc and the clusters so obtained resemble the original network communities more closely than the clusters obtained via Euclidean kmeans on the basis of well-known measures normalised mutual information and adjusted mutual information. Through this, we are able to clearly distinguish between periods of market stability and volatility by applying non-parametric statistical tests with a significance level of 0.05 to geometric measures namely hyperbolic distance and hyperbolic shortest path distance. After that, we are able to spot significant market change early by leveraging the Bollinger Band analysis on the time series of modularity in the embedded networks of each window. Finally, the radial distance and the Equidistance Angular coordinates help in visualizing the embedded network in the Poincare disc and it is seen that specific market sectors cluster together.},
  archive      = {J_SOCO},
  author       = {Pawanesh and Sharma, Charu and Sahni, Niteesh},
  doi          = {10.1007/s00500-025-10606-y},
  journal      = {Soft Computing},
  month        = {5},
  number       = {9},
  pages        = {4317-4334},
  shortjournal = {Soft Comput.},
  title        = {Exploiting the geometry of heterogeneous networks: A case study of the indian stock market},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-induced topological space: From topologies to separation axioms. <em>SOCO</em>, <em>29</em>(9), 4301-4316. (<a href='https://doi.org/10.1007/s00500-025-10633-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topology can be constructed using a collection known as a subbasis or basis with remarkable characteristics. Recently, there has been growing interest in the problem of reconstructing topology from graph vertices, which involves concepts such as incident, adjacent, block, and maximal-block topologies. This paper introduces the new concept of graph-induced topology, which extends the idea of topologies derived from connected simple undirected graphs. The paper thoroughly examines various properties related to separation axioms in graph-induced topological spaces and introduces a novel concept of weak-separation axioms for these topological spaces. The presented properties are supported by rigorous mathematical arguments and accompanied by apparent counterexamples to illustrate their validity.},
  archive      = {J_SOCO},
  author       = {Bui, Quang-Thinh and Nguyen, Thanh Nha and Hong, Tzung-Pei and Vo, Bay},
  doi          = {10.1007/s00500-025-10633-9},
  journal      = {Soft Computing},
  month        = {5},
  number       = {9},
  pages        = {4301-4316},
  shortjournal = {Soft Comput.},
  title        = {Graph-induced topological space: From topologies to separation axioms},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Infinite numbers, infinity computing the philosophy of grossone. <em>SOCO</em>, <em>29</em>(8), 4287-4299. (<a href='https://doi.org/10.1007/s00500-025-10573-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-standard methods are a thriving business since the sixties of past century; their application in practically every field of mathematics has confirmed that infinitesimals’ intuition shortens proofs and facilitates discovery, although it is questioned by a large part of the mathematical community. A different case is that of Sergeyev’s work of the last twenty years. He introduces axiomatically an infinite natural number , Grossone, which is meant to be the cardinality of natural numbers, and shows that arithmetical calculations with infinite and infinitesimal numbers give more precise and discriminating results in many areas. Even automated computing can be extended. Behind Sergeyev’s theory and techniques there lurks an unusual approach to mathematics which could qualify as an original philosophy of mathematical practice, if it could be cast in a consistent proposal. We explain how for the moment it is a mix of threads with elements of realism (in the idea of a reality observed through stronger and stronger lenses), of formalism (in his refusing to fix such reality through a definition), and of finitism (in his insistence that only a finite number of finite operations are within human capabilities). We try to trace a common source in Sergeyev’s conception of the mathematician’s work being similar to the physicist’s and in the idea of the changing strength of the available observation tools. We propose as a possible frame a Russell-type knowledge by acquaintance. We indicate a few critical points needing mending or further enlightenments.},
  archive      = {J_SOCO},
  author       = {Lolli, Gabriele},
  doi          = {10.1007/s00500-025-10573-4},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4287-4299},
  shortjournal = {Soft Comput.},
  title        = {Infinite numbers, infinity computing the philosophy of grossone},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new model and DCA based algorithm for clustering. <em>SOCO</em>, <em>29</em>(8), 4275-4285. (<a href='https://doi.org/10.1007/s00500-025-10662-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel optimization model for partitional clustering with unknown number of clusters, combining the Minimum of Sum of Squared Clustering (MSSC) as the loss term and the $$\ell _{2}$$ grouping centers as the regularization term. This combination leads to a nonconvex, nonsmooth optimization problem, for which we investigate efficient techniques based on DC (Difference of Convex functions) programming and DC Algorithm (DCA). Using a suitable DC decomposition we derive a simple and efficient DCA scheme which requires only matrix–vector products at each iteration. The proposed DCA starts with a very large number of clusters and provides as output an optimal partition along with the optimal number of clusters. Numerical experiments on various synthetic and real-world datasets demonstrate the efficiency of our algorithm in terms of both clustering quality and convergence speed. They outperform four reference algorithms, including k-means variants (X-means, G-means), penalized regression approaches (PRclust), and the Gaussian mixture model (mclust), not only in terms of quality but also on scalability. Notably, it realizes an excellent trade-off between solution quality and running time, making it a good choice for practical clustering tasks with Big data.},
  archive      = {J_SOCO},
  author       = {Le Thi, Hoai An},
  doi          = {10.1007/s00500-025-10662-4},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4275-4285},
  shortjournal = {Soft Comput.},
  title        = {A new model and DCA based algorithm for clustering},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimised resilience measures for supply chain using portfolio selection. <em>SOCO</em>, <em>29</em>(8), 4259-4273. (<a href='https://doi.org/10.1007/s00500-025-10561-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper the portfolio selection theory of Markowitz is applied to the field of supply chain resilience using two simulations based on the empirical supply chain resilience data. The main objective of the paper is to explore how portfolio selection theory can be deployed to obtain an efficient portfolio of resilience measures that is optimised with a view in further research to minimise the area of the resilience recovery triangle. The paper begins with a discussion on causation analysis and the evolution in modelling resilience with a brief review of supply chain resilience and the literature related to Markowitz theory of portfolio selection in the supply chain literature. There follows a description of how to apply Markowitz theory of portfolio selection to supply chain resilience measures and two simulations are presented with their findings together with suggestions for further research. The proposed methodology helps to optimise resilience measures.},
  archive      = {J_SOCO},
  author       = {Talas, Risto and Labib, Ashraf and Dhesi, Gurjeet},
  doi          = {10.1007/s00500-025-10561-8},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4259-4273},
  shortjournal = {Soft Comput.},
  title        = {Optimised resilience measures for supply chain using portfolio selection},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An exterior algebra approach to generalised variances and cross-covariances. <em>SOCO</em>, <em>29</em>(8), 4247-4257. (<a href='https://doi.org/10.1007/s00500-025-10600-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been shown by Pronzato et al. (Bernoulli 23(4A):2617–2642, 2017; J Multivar Anal 168:276–289, 2018) that simplicial volumes formed by independent copies of random variables can be used to extend the definition of generalised variances. It is shown in this paper that exterior algebra is a natural environment in which to study these constructions. This is used to extend the formulation to covariances and correlations. The theory leads naturally to dispersion ordering, that is partial orderings in which one random variable is more disperse than another if one squared simplicial volume stochastically dominates the other.},
  archive      = {J_SOCO},
  author       = {Wynn, Henry P. and Zhigljavsky, Anatoly},
  doi          = {10.1007/s00500-025-10600-4},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4247-4257},
  shortjournal = {Soft Comput.},
  title        = {An exterior algebra approach to generalised variances and cross-covariances},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mean–variance–skewness portfolio optimization with uncertain returns via co-skewness. <em>SOCO</em>, <em>29</em>(8), 4233-4246. (<a href='https://doi.org/10.1007/s00500-025-10623-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mean–variance–skewness portfolio selection model optimizes investment portfolios by considering the mean, variance, and skewness of different assets, aiming to construct a portfolio that maximizes expected return while minimizing risk and maximizing skewness. This model endeavors to achieve a harmonious equilibrium between risk and return by taking into account not only the average return and risk but also the asymmetrical characteristics of returns. Through the inclusion of skewness in the portfolio selection process, investors can gain a comprehensive perspective on the likelihood of experiencing exceptional positive or negative returns. In order to compute skewness of total uncertain returns, this paper presents the concept of co-skewness for uncertain variables. Also, a formula for calculating of co-skewness is obtained via inverse uncertainty distributions and applied to Monte-Carlo simulation. As an application of skewness, mean–variance–skewness portfolio optimizations are provided.},
  archive      = {J_SOCO},
  author       = {Gao, Jinwu and Hu, Haomiao and Zou, Zezhou and Ahmadzade, Hamed},
  doi          = {10.1007/s00500-025-10623-x},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4233-4246},
  shortjournal = {Soft Comput.},
  title        = {Mean–variance–skewness portfolio optimization with uncertain returns via co-skewness},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time series clustering for high-dimensional portfolio selection: A comparative study. <em>SOCO</em>, <em>29</em>(8), 4219-4231. (<a href='https://doi.org/10.1007/s00500-025-10656-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high-dimensional portfolio selection, traditional asset allocation techniques often yield suboptimal results out-of-sample, while equally weighted portfolios have shown better performances in such scenarios. To leverage the advantages of diversification while addressing the curse of dimensionality, we turn to clustering techniques. Specifically, we explore the application of k-means clustering for time series, which offers a clear financial interpretation as the prototype of each cluster represents an equally weighted portfolio of the assets within the cluster. In this paper, we conduct a comprehensive comparison of various time series clustering techniques in the context of portfolio performance. By evaluating the out-of-sample performance of portfolios constructed using different clustering approaches, we aim to identify the most effective method for investment purposes.},
  archive      = {J_SOCO},
  author       = {Mattera, Raffaele and Scepi, Germana and Kaur, Parmjit},
  doi          = {10.1007/s00500-025-10656-2},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4219-4231},
  shortjournal = {Soft Comput.},
  title        = {Time series clustering for high-dimensional portfolio selection: A comparative study},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Do oil prices impact on transportation? evidence from random matrix theory. <em>SOCO</em>, <em>29</em>(8), 4207-4218. (<a href='https://doi.org/10.1007/s00500-025-10580-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our economic system is based on the consumption of oil and its derivatives for a very long time. Far from ending this status quo, certain institutions warn that by 2050 the demand for fossil fuels will remain stable at around 70% out of total. Energy dependence on fossil fuels has an unprecedented impact on consumer prices, financial markets and several industries. One of these, transportation, is the largest oil-consuming industry, with more than 50 million barrels of crude oil consumed daily. According to this data, oil prices are expected to impact the transportation. However, the literature continues failing to give a clear answer about that. From Random Matrix Theory approach, the main goal is to analyze whether the price of oil, natural gas and their derivatives really affect the financial performance of two transportation sub-sectors (Passenger Transportation Services and Freight & Logistics Services) globally. Contrary to much of the previous literature, the extracted results reveal that the prices of oil, natural gas and its derivatives to not affect stock prices of the transportation industry. Through an approach not employed so far, the extracted results allow to continue the debate on the influence of oil prices, thus giving a different perspective that allows policy-makers, shareholders and investors to make a better decision on the industry under study.},
  archive      = {J_SOCO},
  author       = {Garcia-Amate, Antonio and Molero-Gonzalez, Laura and Sanchez-Granero, Miguel Angel and Trinidad-Segovia, Juan Evangelista},
  doi          = {10.1007/s00500-025-10580-5},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4207-4218},
  shortjournal = {Soft Comput.},
  title        = {Do oil prices impact on transportation? evidence from random matrix theory},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unobserved expected returns in a diffusive price process: Is filtering effective?. <em>SOCO</em>, <em>29</em>(8), 4191-4205. (<a href='https://doi.org/10.1007/s00500-025-10637-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a stock price that follows a diffusion process whose drift is mean-reverting and unobservable. We learn about the latent process by filtering the observed log-returns via the Kalman filter. The parameters of the latent process are estimated using two different methodologies. First, we employ the expectation-maximization (EM) algorithm, a maximum likelihood method tailored for such settings. Next, we maximize the likelihood of the innovation process. We assess the estimation performance of both methodologies using simulated data. The surprising result is that even with 30 years of daily data, substantial estimation errors persist across many individual path realizations. We attempt to explain this finding by recognizing that the actual importance of the hidden factor within the observable process is determined by the ratio of their volatilities scaled by the inverse frequency of observations. This scaling factor renders the latent process elusive within the observed time-series.},
  archive      = {J_SOCO},
  author       = {Antonini, Paride and Angelini, Flavio and Nicolosi, Marco},
  doi          = {10.1007/s00500-025-10637-5},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4191-4205},
  shortjournal = {Soft Comput.},
  title        = {Unobserved expected returns in a diffusive price process: Is filtering effective?},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pygrossone: A python-powered library for operating with the infinity computer arithmetic. <em>SOCO</em>, <em>29</em>(8), 4175-4189. (<a href='https://doi.org/10.1007/s00500-025-10661-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents PyGrossone, a general-purpose and domain-independent Python library for the Infinity Computer arithmetic allowing one to work numerically with different infinite and infinitesimal numbers. PyGrossone offers a set of arithmetic, elementary, trigonometric, and differentiation modules to perform computations with $$\textcircled {1}$$ -based numbers (where $$\textcircled {1}$$ is a new infinite number introduced in the series of papers by the last author) with exact precision up to the machine one, since the computations on the Infinity Computer are numeric, not symbolic. Experiments have been conducted to evaluate the validity and performances of the proposed library. The availability of a Python-based implementation of the Infinity Computer arithmetic enables its exploitation in further research fields, such as artificial intelligence, scientific computing, and machine learning.},
  archive      = {J_SOCO},
  author       = {Falcone, Alberto and Garro, Alfredo and Sergeyev, Yaroslav D.},
  doi          = {10.1007/s00500-025-10661-5},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4175-4189},
  shortjournal = {Soft Comput.},
  title        = {Pygrossone: A python-powered library for operating with the infinity computer arithmetic},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Early stopping strategies in deep image prior. <em>SOCO</em>, <em>29</em>(8), 4153-4174. (<a href='https://doi.org/10.1007/s00500-025-10642-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The so-called Deep Image Prior approach is an unsupervised deep learning methodology which has gained great interest in recent years due to its effectiveness in tackling imaging problems. However, a well known drawback of Deep Image Prior is the need for a proper early stopping technique to prevent undesired corruptions in the reconstructed images. Determining the optimal number of iterations depends on both the specific application and the features of the images being processed. As a consequence, several numerical trials are typically required to decide when to stop the Deep Image Prior procedure, resulting in significant computational costs and time requirements. This paper aims to introduce two early stopping techniques for Deep Image Prior, based on different approaches and different perspectives. The first approach relies on the neural architecture search (NAS) strategy. The aim is to equip the neural network used in Deep Image Prior with hyperparameter configurations that produce high-quality reconstructed images that are (i) comparable to those obtained with the optimally stopped, originally configured Deep Image Prior, and (ii) achieved with significantly fewer iterations. The second proposed early stopping strategy is based on a modified version of the BRISQUE metric, a no-reference image quality measure, and it aims to track the behaviour of the PSNR curve, obtained by applying Deep Image Prior, without knowing the ground truth image. While the NAS-based early stopping technique is particularly suited in those situations where the computational time is limited, this latter one is also relevant when a larger number of iterations is allowed. Several numerical experiments on different denoising applications show a promising performance of Deep Image Prior combined with the suggested early stopping procedures.},
  archive      = {J_SOCO},
  author       = {Benfenati, Alessandro and Catozzi, Ambra and Franchini, Giorgia and Porta, Federica},
  doi          = {10.1007/s00500-025-10642-8},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4153-4174},
  shortjournal = {Soft Comput.},
  title        = {Early stopping strategies in deep image prior},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PGA-net: Progressive granularity-aware training network for fine-grained image recognition. <em>SOCO</em>, <em>29</em>(8), 4139-4152. (<a href='https://doi.org/10.1007/s00500-025-10632-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained image recognition (FGIR) presents significant challenges due to the subtle distinctions between highly similar subcategories. Most existing methods, which typically focusing on a single feature granularity, often fail to capture the nuanced differences essential for accurate classification. To address this problem, we propose the Progressive Granularity-Aware Training Network (PGA-Net), a novel framework designed to enhance the discriminative power of FGIR models by incorporating multi-granularity feature recognition. Specifically, our PGA-Net utilizes a Partial Dislocation Module (PDM) to generate images of various granularities for input, and is complemented by a progressive granularity-aware training methodology that adjusts the receptive fields dynamically to integrate both coarse and fine feature details at different stages. Further refinement is achieved through a Feature Enhancement Module (FEM), which intensifies the discernibility of multi-granularity features. Additionally, PGA-Net employs a dual supervision strategy, combining cross-entropy loss and center loss, which allows it to train deep learning models effectively to capture distinct inter-class features and strong intra-class similarities, all without the need for bounding box or part annotations. This methodology allows the network to be trained end-to-end, enhancing both efficiency and accuracy. Extensive experiments and analyses on three fine-grained benchmark datasets demonstrate that the proposed PGA-Net approach can achieve new state-of-the-art.},
  archive      = {J_SOCO},
  author       = {He, Wei and He, Zhixiang and Chen, Siyuan and Li, Wujing and Wu, Jianhui},
  doi          = {10.1007/s00500-025-10632-w},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4139-4152},
  shortjournal = {Soft Comput.},
  title        = {PGA-net: Progressive granularity-aware training network for fine-grained image recognition},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An approach of multi-viewed graph embedding with adaptive heat kernel based diffusion and global expressive learning. <em>SOCO</em>, <em>29</em>(8), 4121-4137. (<a href='https://doi.org/10.1007/s00500-025-10582-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, graph neural networks (GNNs) have been extensively studied and applied to various graph learning problems. There are numerous studies have demonstrated the strong capabilities of GNN-based architectures in addressing fundamental tasks such as node and graph classification, as well as link prediction. Most of canonical GNN-based models have been developed upon the node feature aggregation (a.k.a. message passing) learning paradigm to achieve the node/graph-levelled representations. However, because graph-structural information is propagated through direct relationships between nodes, the representation of a target/ego node becomes heavily dependent on a fixed set of neighboring nodes. As the results, this approach has encountered several certain limitations. To address this limitation, the graph diffusion learning approach has been introduced. There are several generalized graph diffusion techniques have been proposed to enhance the graph propagation learning process, allowing for richer information to be obtained from a larger set of neighboring nodes. Thus, they can enable to achieve better node representations as well as task-driven fine-tuning performance. However, most previous graph diffusion learning techniques have been designed primarily for node categorization, with a strong emphasis on local structural information. As a result, the global expressivity of the GNN-based architecture is often overlooked, making these techniques less suitable for graph-level learning tasks such as molecular graph embedding and categorization. To overcome these limitations, we introduce a novel structure-enhanced adaptive diffusion graph convolutional network, naming SADC. Our proposed SADC combines an expressive graph neural embedding approach with the existing adaptive diffusion graph learning paradigm to achieve more robust and varied graph structure representations. Thus, it can support to benefit graph-levelled learning tasks like as molecular graph categorization. The extensive empirical studies on real-world molecular graph datasets demonstrate that our proposed SADC model outperforms previous baselines. Specifically, our proposed SADC model has leverage the accuracy performance of molecular graph classification averagely 28.52%/75.32% in terms of accuracy/F-1 evaluation metrics in all datasets.},
  archive      = {J_SOCO},
  author       = {Pham, Phu},
  doi          = {10.1007/s00500-025-10582-3},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4121-4137},
  shortjournal = {Soft Comput.},
  title        = {An approach of multi-viewed graph embedding with adaptive heat kernel based diffusion and global expressive learning},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Yolo-tir: An improved YOLOv5 model for vehicle and pedestrian in thermal infrared images. <em>SOCO</em>, <em>29</em>(8), 4107-4119. (<a href='https://doi.org/10.1007/s00500-025-10641-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, in order to detect vehicles and pedestrians more effectively in thermal infrared images, we propose a multi-level feature fusion method based on YOLOv5 named YOLO-TIR. In the backbone network, we design an inverted bottleneck parallel convolution (IBPC) module, which uses wide-channel convolution in place of the deep convolutional extraction module and makes use of the Simplified SPP-Fast(SimSPPF) feature aggregation module to improve the network’s capability to localize objects. Moreover, in order to reduce the loss of information about small objects in multiple downsampling, a feature pyramid structure with jump connections called Shortcut-FPN(SFPN) is proposed, which effectively retains the shallow small object information. In addition, Shuffle-Upsample(SUP) is proposed to decrease the noise interference caused by interpolation, which splices multiple channels of the feature map to achieve the upsampling operation. Further, due to the problem of category imbalance in the public dataset, we create a new dataset called HTU_TIR to compensate for the categories with less data. The experimental results show that our proposed method has effective improvement in detection accuracy. Compared with YOLOv5m, we achieve 1.9% improvement on mAP scores, and the number of parameters and computation are decreased by 45.7% and 52.2%, respectively.},
  archive      = {J_SOCO},
  author       = {Yao, Shangshu and Yu, Kun and Li, Longfei and Zhang, Kaihua and Liu, Yufang},
  doi          = {10.1007/s00500-025-10641-9},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4107-4119},
  shortjournal = {Soft Comput.},
  title        = {Yolo-tir: An improved YOLOv5 model for vehicle and pedestrian in thermal infrared images},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meet MASKS: Integrating distributed knowledge and verification for multi-agent systems. <em>SOCO</em>, <em>29</em>(8), 4091-4106. (<a href='https://doi.org/10.1007/s00500-025-10577-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of collaborative intelligent systems, ensuring the accuracy and reliability of decisions, especially under critical conditions, represents a formidable and ongoing challenge. This study introduces a novel verification technique aimed at improving the performance of multiple collaborative classifiers. We utilize a modal logic model to reason about the distributed information among classifiers and develop a specialized language to define verification properties. Our approach, the Multi-Agent System Knowledge-Sharing algorithm, evaluates these properties by checking the satisfaction of defined formulas within the model. One key challenge addressed is the difficulty of defining suitable properties. Despite this challenge, our empirical results reveal that even with suboptimal properties, the technique substantially enhances error reduction. Extensive evaluation on datasets such as Fashion-MNIST, MNIST, and Fruit-360 demonstrates significant improvements. For instance, using 1000 agents, the number of incorrect verifications in Fashion-MNIST decreased from 89 to 17; with 700 agents, incorrect verifications in MNIST dropped from 71 to 3; and with 80 agents, incorrect verifications in Fruit-360 were reduced from 233 to 0.},
  archive      = {J_SOCO},
  author       = {Alizadeh, Majid and Hoseinpour Dehkordi, Amirhoshang and Movaghar, Ali},
  doi          = {10.1007/s00500-025-10577-0},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4091-4106},
  shortjournal = {Soft Comput.},
  title        = {Meet MASKS: Integrating distributed knowledge and verification for multi-agent systems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight image super-resolution via an adaptive information fusion attention network. <em>SOCO</em>, <em>29</em>(8), 4075-4089. (<a href='https://doi.org/10.1007/s00500-025-10639-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Convolutional Neural Networks (CNNs) have achieved outstanding performance in the field of Image Super-Resolution (SR). However, many existing methods focus excessively on increasing network depth, which leads to an excessive number of parameters and computational complexity. Some methods, aimed at reducing model capacity, significantly reduce the receptive field of the network, and employ a single upsampling method, resulting in suboptimal model performance. To better balance model size and performance, this paper proposes a lightweight Adaptive Information Fusion Attention Network (AIFAN). Specifically, a Dual Path Block (DPB) is designed to adaptively aggregate multi-scale features from different paths through the Adaptive Path Fusion Block (APFB). To take full advantage of the hierarchical features, all DPBs are connected using a dense connection mode. Meanwhile, a receptive field attention (RFA) module is proposed to increase the receptive field of the network and force the network to pay attention to the region with more information in the feature. In addition, a hybrid up-sampling module is designed. The Adaptive Multi-scale Up-sampling (AMSU) module and Feature Update Up-sampling Block (FUUB) are combined in the module to obtain better reconstruction results. The experimental results show that the proposed AIFAN achieves an effective balance between performance and model complexity.},
  archive      = {J_SOCO},
  author       = {He, Yi and Huan, Hai and Zou, Nan and Zhang, Yi and Xie, Yaqin and Wang, Chao},
  doi          = {10.1007/s00500-025-10639-3},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4075-4089},
  shortjournal = {Soft Comput.},
  title        = {Lightweight image super-resolution via an adaptive information fusion attention network},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GA-based partial high-order-cascaded-deep time series forecasting model. <em>SOCO</em>, <em>29</em>(8), 4055-4074. (<a href='https://doi.org/10.1007/s00500-025-10591-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is undoubtedly an essential yet challenging issue for researchers in academia and various industries. The superior performance of computational methods, particularly machine learning and deep learning algorithms, over traditional time series techniques, has made them increasingly attractive and successful. However, most current computational approaches focus solely on nonlinear relationships due to the nature of the algorithms employed and utilize all consecutive lagged variables in high-order models. This approach often leads to the inclusion of lagged variables that do not significantly contribute to model performance. This study aims to address these two fundamental issues. Rather than relying on a purely high-order model that can only capture either linear or nonlinear relationships, we propose a deep partial high-order forecasting model capable of modeling both types of relationships simultaneously. The proposed model is called a partial high-order deep-cascaded forecasting model. In the proposed model, a genetic algorithm is used to select the input variables that determine the model order. The relationships between the selected inputs and the target variables are modeled using a deep cascade-forward neural network (D-CFNM), which can capture both linear and nonlinear dependencies. The proposed model was applied to various time series, and the performance of the proposed model was comparatively evaluated with some state-of-the-art models. The results demonstrate that the proposed model significantly outperforms its counterparts across all tested datasets.},
  archive      = {J_SOCO},
  author       = {Birim, Gulseren and Cagcag Yolcu, Ozge},
  doi          = {10.1007/s00500-025-10591-2},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4055-4074},
  shortjournal = {Soft Comput.},
  title        = {GA-based partial high-order-cascaded-deep time series forecasting model},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). N-gram opcode frequency based malware detection using CNN algorithm. <em>SOCO</em>, <em>29</em>(8), 4045-4053. (<a href='https://doi.org/10.1007/s00500-025-10659-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the Internet develops and the utilization rate of computers increases, the threats posed by malware keep increasing. As the number of newly developed malware is rapidly increasing, the demand for an automatic system for analyzing large volumes of malware also grows together. In this paper, we introduce a technique to automatically analyze malware targeting the Windows environment using a deep learning algorithm. Our proposed method employs convolutional neural network algorithm, which is highly effective in image classification, to detect malware represented as images. To reflect the semantic information of malware for detection, our method uses the opcode frequency data of binary files to generate images while transforming frequency data into spatial data. After calculating the correlation degree among opcodes of malware samples, our method performs clustering using the correlation values as the distances between opcodes. The opcodes in the same cluster are located in a close region in each image, and a CNN model analyzes the generated image. In our evaluation, we conducted the experiments using a large dataset consisting of 10,000 malicious files and 10,000 benign files, and our proposed method was verified to achieve 91% accuracy rate in detecting malicious files.},
  archive      = {J_SOCO},
  author       = {Ko, Seok Min and Yang, JaeHyeok and Kim, TaeGuen and You, Ilsun},
  doi          = {10.1007/s00500-025-10659-z},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4045-4053},
  shortjournal = {Soft Comput.},
  title        = {N-gram opcode frequency based malware detection using CNN algorithm},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive RoI-aware network for accurate banknote recognition using natural images. <em>SOCO</em>, <em>29</em>(8), 4033-4043. (<a href='https://doi.org/10.1007/s00500-025-10649-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intelligent banknote recognition system using deep learning can significantly improve the accuracy and efficiency of cash handling, particularly benefiting visually impaired individuals. However, in practical applications, issues like scale and angle variations, complex backgrounds, wear, and lighting changes can cause inaccuracies in recognizing key features of banknotes. In this paper, we propose an adaptive RoI-aware network that can dynamically capture the regions of interest (RoIs) to ensure that key regions, such as serial numbers, watermarks, and specific patterns, are accurately detected. The proposed network consists of two main components. First, we develop a multiscale deformable convolution module that adjusts the receptive fields to capture multi-scale features based on the shape of the RoIs. This module is designed to effectively handle scale variations, perspective distortions, and other challenges in complex banknote images. Second, a non-local attention module is employed to model global context, enabling the network to focus more precisely on key regions of banknote images. This approach minimizes the effects of irrelevant backgrounds and damaged areas on detection accuracy. Extensive experiments conducted on banknotes from various countries to demonstrate that the proposed model possesses strong generalization capabilities to handle variations in banknote designs and subtle differences across different national currencies. The proposed network significantly outperforms state-of-the-art methods in both detection accuracy and robustness, achieving the highest accuracy rates of 92.29%, 97.42%, 99.63%, and 99.64% on the INR, PLN, BTN, and UAE datasets, respectively.},
  archive      = {J_SOCO},
  author       = {Lin, Zhijie and He, Zhaoshui and Wang, Jing and Wang, Xu and Su, Wenqing and Wang, Peitao and Liang, Hao},
  doi          = {10.1007/s00500-025-10649-1},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4033-4043},
  shortjournal = {Soft Comput.},
  title        = {Adaptive RoI-aware network for accurate banknote recognition using natural images},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward almost-zero fault acceptance of deep learning-based voice authentication using small training dataset. <em>SOCO</em>, <em>29</em>(8), 4021-4032. (<a href='https://doi.org/10.1007/s00500-025-10617-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In various applications, such as access to mobile device, web application access, etc., user’s voice biometric authentication is one of the easy and excellent authentication factors for these applications. It can increase user’s usability, be believed to provide enhanced security unlike PINs, and improves customer experience. However, generally, in the authentication process, false acceptance is one of the fatal weaknesses since it leads to system access for the unauthorized person. Especially, in the case of the mobile environment with only a small training dataset, it is very hard to reduce the fault acceptance rate. To address this limitation of user’s voice biometric authentication, in this paper, we propose a novel approach that dramatically reduces the weakness of mis-acceptance from a given deep learning-based voice authentication with a small training dataset. To prove this improvement, we experimentally show that all test samples that were mis-accepted in a given deep learning-based voice authentication trained with a small dataset are correctly validated after applying our technique.},
  archive      = {J_SOCO},
  author       = {Park, Seung-A. and Kwon, Sun-Beom and Lee, Yong Woo and Jo, Jejin and Kim, Jun-Seob and Han, Mee Lan and Choi, Dooho},
  doi          = {10.1007/s00500-025-10617-9},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4021-4032},
  shortjournal = {Soft Comput.},
  title        = {Toward almost-zero fault acceptance of deep learning-based voice authentication using small training dataset},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparison of different sway control algorithms for multi carriages crane system. <em>SOCO</em>, <em>29</em>(8), 4001-4020. (<a href='https://doi.org/10.1007/s00500-025-10544-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crane systems, are widely used for the transport of heavyweight and high-volume loads in various fields. Increasing the number of carriages in the crane system is a method frequently used in the industry so that the load is in the form of a distributed load. For applications with high sensitivity needs, anti-swing control of multi-car crane systems should also be performed. In this study, a dynamic model of an overhead crane with three cars operating in cartesian coordinates is derived. In this model, six different methods were used for oscillation reduction. Control methods are traditional proportional + integral + derivative (PID), fuzzy logic, fuzzy logic-based adaptive PID, Adaptive Neuro-Fuzzy Inference System(ANFIS), combined ANFIS-PID, and Genetic Algorithm Based PID Control (GAPID) methods. The reason for choosing the six methods here is to compare their performance in multi-car crane systems in the case of classic, modern control, and hybrid use. Model system and control systems were established and simulated in MATLAB Simulink environment. By comparing the obtained results with each other, it has been examined which techniques are more successful in controlling this system. Finally, the performance of the ANFIS–PID control system is better than other controllers. The simulation results obtained in this study are expected to contribute to experimental studies.},
  archive      = {J_SOCO},
  author       = {Esim, Emir and Yıldırım, Şahin and Gördebil, Ayşegül},
  doi          = {10.1007/s00500-025-10544-9},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {4001-4020},
  shortjournal = {Soft Comput.},
  title        = {Comparison of different sway control algorithms for multi carriages crane system},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification of protein-coding regions using optimized sinusoidal assisted variational mode decomposition based on swarm optimization algorithm. <em>SOCO</em>, <em>29</em>(8), 3985-4000. (<a href='https://doi.org/10.1007/s00500-025-10588-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of protein-coding regions using the three-base periodicity property is a challenging task in the field of bioinformatics. Many digital signal processing (DSP)-based techniques have been used to extract the period-3 component. An effective DSP-based technique must satisfy three crucial requirements: being independent of window length, having an adaptive frequency spectrum, and having a center frequency of f/3 to identify the protein-coding regions (exons). The sinusoidal-assisted variational mode decomposition (SAVMD) resolves the issue to some extent by utilizing a sinusoidal-assisted framework with fixed parameters of VMD. However, the performance of the SAVMD has been reduced because of the fixed parameters used in VMD. Further, the fixed parameters have not been suitable for different DNA sequences to properly identify the exons. Therefore, a novel optimized SAVMD (OSAVMD) method is proposed based on different swarm optimization algorithms for the accurate identification of protein-coding regions. Here the least energy loss coefficient is used as the fitness function to optimize the parameters (α and K) of the standard variational mode decomposition to achieve better accuracy in the prediction of the exons. In order to evaluate the efficacy of the proposed method compared to existing methods, some critical performance parameters are used at the nucleotide level for benchmark gene sets like C. elegans, Homosapiens, Mus musculus, etc. The results reveal that the OSAVMD technique achieves superior performance than the other existing methods.},
  archive      = {J_SOCO},
  author       = {Jayasree, K. and Hota, Malaya Kumar},
  doi          = {10.1007/s00500-025-10588-x},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {3985-4000},
  shortjournal = {Soft Comput.},
  title        = {Identification of protein-coding regions using optimized sinusoidal assisted variational mode decomposition based on swarm optimization algorithm},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel variant of moth swarm algorithm for flexible AC transmission system-based optimal power flow problem. <em>SOCO</em>, <em>29</em>(8), 3943-3983. (<a href='https://doi.org/10.1007/s00500-025-10618-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to develop a novel variant of the moth swarm algorithm (MSA) for addressing nonlinearity coupled and complex flexible AC transmission systems integrated optimal power flow problems for two standard IEEE test systems. The MSA is a swarm intelligence-based technique that imitates the moth’s navigational strategy towards moonlight. Despite its simple algorithmic structure and ability to explore a large search space for better solutions, the MSA has some drawbacks, including a sluggish convergence rate, insufficient intensification, and high chances of getting entrapped in the sub-optimal solution point. To address the limitations of the orthodox MSA, this paper devises a chaos-incorporated partial opposition-based MSA with rank-based mutation (CPOMSA-RM). A chaotic mapping technique is used in the proposed algorithm to initialize the moth’s population to enhance the global search ability. The proposed CPOMSA-RM is integrated with a chaotic local search scheme to fortify the local search skill. Furthermore, the number of prospector moths in the proposed algorithm is chaotically determined to achieve a better balance between diversification and intensification. The proposed algorithm is integrated with a rank oriented Levy flights based mutation technique to improve the intensification and the convergence speed. In addition, partial opposition-based learning is combined in the proposed algorithm to prevent sub-optimal solution entrapment. Here, diversification is the process of searching for new areas of the search space, while intensification is the process of refining the current solution. To confirm the proposed algorithm’s efficacy, it is compared with different algorithms using statistical measures and non-parametric statistical tests are performed on evolutionary computation based 2017 benchmark functions. Moreover, the proposed algorithm is applied to solve the optimal power flow problem while considering the optimal placement and configuration of a single flexible AC transmission system device, i.e. static synchronous series compensator, and the results are compared with existing sophisticated algorithms. The simulation results confirm that the proposed algorithm outperforms its competitors in terms of solution quality, accuracy, convergence speed, and statistical metrics for the optimal power flow problem and benchmark functions.},
  archive      = {J_SOCO},
  author       = {Banerjee, Dhiman and Roy, Provas Kumar and Panda, Goutam Kumar},
  doi          = {10.1007/s00500-025-10618-8},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {3943-3983},
  shortjournal = {Soft Comput.},
  title        = {A novel variant of moth swarm algorithm for flexible AC transmission system-based optimal power flow problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient scheduling of integrated operating rooms and post-anesthesia care units under uncertain surgery and recovery times: An artificial neural network-metaheuristic framework. <em>SOCO</em>, <em>29</em>(8), 3909-3941. (<a href='https://doi.org/10.1007/s00500-025-10620-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hospital managers must plan and schedule their operating rooms (ORs) and related units to increase productivity and deliver high-quality care. In this situation, some surgery parameters, like surgery and recovery times, are subject to uncertainty due to the unstable environment of hospital processes. Therefore, efficient methodologies should be designed to address these uncertainty sources and provide acceptable solutions in a reasonable time. Typically, solving the problem involves simulation-optimization approaches known to be time-consuming. This work presents a new data mining-optimization approach for integrated ORs and post-anesthesia care unit (PACU) scheduling, known as the operating theater room (OTR) scheduling problem, under uncertainty in surgery and PACU times. Concerning the complexity of the problem, we design four metaheuristics, including genetic algorithm (GA), particle swarm optimization (PSO), simulated annealing (SA), and tabu search (TS) based on the problem features to search the solution space. Our presented approach aims to improve the traditional simulation-optimization frameworks, and utilizes simulation experiment results to train an artificial neural network (ANN), which evaluates the generated sequences of metaheuristic algorithms. The goal is to optimize the patients’ scheduling to minimize the problems’ single objective function. Two cases of the problem are defined based on makespan and total tardiness objectives. Extensive analysis of the results is established by providing three different sizes of example categories from the literature with several probability distributions for surgery and PACU times of patients. The input parameters of metaheuristic algorithms are tunned using the Taguchi design of experiments method, and the results are analyzed using several computational measures. The analysis of results reveals that GA performs better than the other algorithms regarding the solution quality measure for both cases. For the makespan objective case, the average relative percentage deviation (RPD) of GA is zero, while for PSO, SA, and TS, the deviations are 0.03, 0.01, and 0.04, respectively. This difference becomes even more pronounced in the total tardiness objective case, where the average RPD of GA is 0.04, compared to 0.36, 0.41, and 0.84 for PSO, SA, and TS, respectively. Finally, analysis of variance (ANOVA) and Kruskal–Wallis tests are utilized as parametric and non-parametric tests for statistical comparisons. The p value of the conducted tests is less than 0.05 at the 0.05 significance level, confirming a significant difference in the performance of the algorithms. Some managerial insights and practical implications are presented based on obtained results.},
  archive      = {J_SOCO},
  author       = {Ahmadian, Mohammad Amin and Varmazyar, Mohsen and Fallahi, Ali},
  doi          = {10.1007/s00500-025-10620-0},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {3909-3941},
  shortjournal = {Soft Comput.},
  title        = {Efficient scheduling of integrated operating rooms and post-anesthesia care units under uncertain surgery and recovery times: An artificial neural network-metaheuristic framework},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Public health events emergency management supervision strategy with multi-agent participation. <em>SOCO</em>, <em>29</em>(8), 3889-3908. (<a href='https://doi.org/10.1007/s00500-025-10575-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the main body responsible for emergency management, local governments must take actions to respond to public health events. However, these actions may be delayed or inadequate, which can affect the efficiency and effectiveness of emergency management. Therefore, the actions of local governments in public health events need to be monitored and supervised. To explore how to prompt the multi-agent supervision of emergency management, we construct a four-agent game model with the participation of the central government, local governments, citizens and new media. By solving the Nash equilibrium, conducting simulation analysis and discussing the results with the relevant literature, we find that for the central government, establishing an accountability mechanism and increasing the accountability cost for local governments can motivate local governments to actively cope with public health events. Second, the greater the impact of citizen evaluation and complaints or new media reporting on local governments, the greater the probability of local governments choosing “actively coping” strategy. Third, raising citizens' awareness of risk and providing appropriate incentives can prompt citizens to participate in emergency management supervision. Fourth, the ways of stimulating new media to choose “reporting” strategy include lowering the cost of reporting, raising the subsidies for reporting, and increasing the additional traffic revenue from reporting. Finally, combined with the main findings of this study, we provide some recommendations for improving the supervision of public health events emergency management.},
  archive      = {J_SOCO},
  author       = {Lu, Bingjie and Wen, Decheng},
  doi          = {10.1007/s00500-025-10575-2},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {3889-3908},
  shortjournal = {Soft Comput.},
  title        = {Public health events emergency management supervision strategy with multi-agent participation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-objective genetic algorithm for unequal area facility layout problem considering safety and cost. <em>SOCO</em>, <em>29</em>(8), 3869-3887. (<a href='https://doi.org/10.1007/s00500-025-10605-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facility layout problem is crucial in the design of manufacturing systems across industries due to its significant economic implications and considerable impact on various decision criteria, including safety considerations in industries like casting. The presence of hazardous equipment, such as furnaces and melt casting units, necessitates layouts that mitigate safety risks effectively. This research develops a model that optimizes both transportation costs and safety risks concurrently. To achieve this, we introduce a multi-objective programming model specifically designed for addressing unequal area layouts. The proposed nonlinear model is converted into a linear equivalent to facilitate solution finding. We employ the NSGA-II algorithm to generate non-dominated Pareto solutions, which is further refined through the Taguchi method for optimal parameter settings. Additionally, goal programming is utilized to extract a single solution from the Pareto set. Empirical validation is performed using real-world data from a casting workshop, revealing objective function values in goal programming of 4253, 20, and 495—closely aligning with the solutions derived from the NSGA-II algorithm. The results demonstrate the model's practicality and effectiveness in real-world applications.},
  archive      = {J_SOCO},
  author       = {Koosha, Hamidreza and Mirsaeedi, Fatemeh and Assadi, Mohammad Taghi},
  doi          = {10.1007/s00500-025-10605-z},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {3869-3887},
  shortjournal = {Soft Comput.},
  title        = {A multi-objective genetic algorithm for unequal area facility layout problem considering safety and cost},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Min-cost route problems for multimodal sustainable logistics cooperation. <em>SOCO</em>, <em>29</em>(8), 3855-3868. (<a href='https://doi.org/10.1007/s00500-025-10647-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the pressing need for sustainable logistics practices in light of the current global climate emergency. Specifically, we tackle the problem of defining the shortest routes for various carriers in a multimodal logistics network while simultaneously reducing environmental impact. A novel aspect of our approach is that each transport demand from origin to destination is satisfied by considering all the routes within the multimodal network that intersect with the path associated with the transportation request. The primary goal is to minimise the number of circulating vehicles by fully utilising their available cargo capacity. To achieve this, we propose a mixed-integer linear programming model based on a multimodal graph. The objective function comprises various cost components, taking into account the transportation and service costs of different vehicle types (trucks, trains, ships, and aeroplanes). Additionally, the search for the optimal solution incorporates several parameters aligned with the paradigm of cooperative logistics and environmental sustainability. Specifically, pollutant emissions and payload utilisation are factored in through specifically tailored cost coefficients. A total of 3,240 test instances, derived from routes within the Italian multimodal transportation network, were generated and solved to optimality. The results underscore the effectiveness of the proposed model in addressing the aforementioned environmental concerns.},
  archive      = {J_SOCO},
  author       = {Cerrone, Carmine and Sciomachen, Anna and Truvolo, Maria},
  doi          = {10.1007/s00500-025-10647-3},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {3855-3868},
  shortjournal = {Soft Comput.},
  title        = {Min-cost route problems for multimodal sustainable logistics cooperation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel deep learning-based side-channel attack on different-device. <em>SOCO</em>, <em>29</em>(8), 3847-3854. (<a href='https://doi.org/10.1007/s00500-025-10610-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By exploiting advances in deep learning (DL), several DL-based profiled side-channel analyses (SCAs) have been performed. DL-based profiling analysis is a technique that trains the relationship between side-channel information (e.g., electromagnetic leaks and power consumption) and the intermediate values of side-channel information on a neural network (NN) and then finds the secret key of an attack device using the trained NN. Recently, cross-device profiled SCA has been proposed to consider the realistic DL-based profiled SCA scenarios. However, it has a limitation in that attack performance is lowered if the profiling and attack devices have different target chips. In this study, an environment in which the attack device has a target chip different from the profiling device is defined as different-device and a novel DL-based profiled SCA on different-device is proposed. In addition, multiscale convolution NN, an NN architecture that trains preprocessed and original data in batches, is used to extract and train the characteristics of each data. We experimented with six boards to verify the attack performance of the proposed method. As a result, applying the proposed method reduced the number of attack traces required for the guessing entropy to converge to zero by up to 45 times compared with without applying it.},
  archive      = {J_SOCO},
  author       = {Woo, Ji-Eun and Jeon, Yongsung and Kim, Ju-Hwan and Han, Dong-Guk},
  doi          = {10.1007/s00500-025-10610-2},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {3847-3854},
  shortjournal = {Soft Comput.},
  title        = {Novel deep learning-based side-channel attack on different-device},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Color-channel adversarial attack with resolution based camouflaging. <em>SOCO</em>, <em>29</em>(8), 3835-3846. (<a href='https://doi.org/10.1007/s00500-025-10660-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of deep neural networks in real-world applications, the vulnerability of deep neural networks has drawn a lot of interest in the research community. An important technique for probing the security issues of deep neural network models is to design as strong as possible attacks. Though existing white-box attacks can offer effective attacks, most of them are vulnerable to human inspection. On the other hand, some attacks are stealthy and imperceptible, but their damaging effect is largely weakened. It remains open challenge to reconcile the attack effectiveness and the imperceptibility. In this work, we propose a novel approach of crafting adversarial attacks. In particular, instead of attacking all image channels adopted in existing methods, we aim at specific color channel and the local region related to classification, wherein adversarial perturbations are exerted. In order to fool human visual system, we propose an improved bilinear interpolation approach to camouflage adversarial samples with enhanced resolution. The experiments on three benchmark datasets (MNIST, CIFAR10, IMAGENET-10) demonstrate that, compared to several strong attack methods, our model strikes a better balance between attack strength and human inspection. Moreover, the adversarial samples created by our method are more effective than those generated by the comparison methods in improving the robustness of the base classification model.},
  archive      = {J_SOCO},
  author       = {Li, Guowei and Li, Ping and Zhu, Xinpeng},
  doi          = {10.1007/s00500-025-10660-6},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {3835-3846},
  shortjournal = {Soft Comput.},
  title        = {Color-channel adversarial attack with resolution based camouflaging},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification of block cipher algorithms using multi-layer perception algorithm. <em>SOCO</em>, <em>29</em>(8), 3823-3834. (<a href='https://doi.org/10.1007/s00500-025-10595-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cryptographic algorithm identification is the process of distinguishing or identifying the cryptographic algorithm by analysing the potential information of various features in the ciphertext under the condition of known ciphertext, which is the basis of cryptanalysis work. As the complexity of ciphertext increases, the interference between ciphertext data and encryption algorithms increases, and the identification effect of single-layer cryptographic algorithms in encryption algorithm identification work is poor. In order to solve the problems of low recognition accuracy and poor stability of the block cipher algorithm in the single-layer identification scheme, we propose a cryptographic algorithm identification scheme of block cipher algorithm using deep learning algorithm Multi-Layer Perception (MLP) in this paper. In this scheme, 15 NIST randomness test methods are used to extract ciphertext feature, and 10 meaningful features are selected as input to MLP classifier to make predictions. In the ciphertext-only scenario, five block cipher algorithms, AES, 3DES, Blowfish, CAST and RC2 are selected for the study of cryptographic algorithm identification, then binary classification and multiclassification identification are carried out. The experimental results demonstrate that, when the size of the ciphertext files and other experimental conditions are the same as for the five conventional machine learning models, the proposed scheme has superior accuracy and stability. Among them, the average identification accuracy of binary classification is 76.5% for ciphertext files of 1KB to 512KB size, which is 35.3%, 37.5%, 34.2%, 38.5%, and 41.6% higher than that of the traditional classical machine learning models SVM, GNB, KNN, RF, and LR respectively. The average identification accuracy of the multiclassification is 36.2%, which is significantly higher than the other five classical machine learning algorithms. When the ciphertext file sizes are different, among the identification rates of the six models fluctuate, the MLP model has the greatest stability and the least amount of influence.},
  archive      = {J_SOCO},
  author       = {Yuan, Ke and Yu, Daoming and Yang, Wei and Du, Zhanfei and Shen, Lin and Li, Zheng},
  doi          = {10.1007/s00500-025-10595-y},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {3823-3834},
  shortjournal = {Soft Comput.},
  title        = {Identification of block cipher algorithms using multi-layer perception algorithm},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertain fox equation. <em>SOCO</em>, <em>29</em>(8), 3811-3822. (<a href='https://doi.org/10.1007/s00500-025-10657-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential equations are essential tools for studying and managing fisheries resources. It can describe the pattern of changes in population size over time, including growth or decline trends, and provide the scientific basis for formulating management measures. This paper proposes an uncertain Fox equation by selecting a regulatory function of the rate of population increase, which corresponds to the Gompertz growth form. Then the solution of the uncertain Fox equation and the inverse uncertainty distribution of the solution are discussed. Based on the proposed uncertain Fox equation, three applications of the solution are also studied. Furthermore, the moment estimation based on residuals is applied to estimating the unknown parameters of the uncertain Fox equation, and a brief study of the cod population is provided. Finally, a paradox of the stochastic Fox equation is deduced.},
  archive      = {J_SOCO},
  author       = {Chen, Dan and Liu, Yang},
  doi          = {10.1007/s00500-025-10657-1},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {3811-3822},
  shortjournal = {Soft Comput.},
  title        = {Uncertain fox equation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Environmental impact assessment using bipolar complex intuitionistic fuzzy sets. <em>SOCO</em>, <em>29</em>(8), 3795-3809. (<a href='https://doi.org/10.1007/s00500-025-10608-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The environmental impact assessment is substantial in protecting the environment and preserving natural resources. While describing the environmental impact characterizations by use of objective indicators mean values is frequently not possible, there is a high degree of uncertainty associated with the estimation caused by the different criteria and judgments on values. Therefore, for conveying these values to a mathematical form and vice versa short of losing the meaning of information is an essential step to solve the problem of assigning membership and non-membership degrees of an object to a set by decision-makers. This kind of information has built-in suitable uncertainty sets called bipolar complex intuitionistic fuzzy sets (BCIFS) by extending the range of membership and non-membership degrees in BIFS from [− 1, 1] to unit squares in the complex plane. In this research, a BCIFS has been generalized to represent the magnitude and impact indicators in the EIA. Therefore, the formal definition of BCIFS is introduced as its ability to employ both real and imaginary parts for bipolar intuitionistic fuzzy information representation, and some basic operations on BCIFS have also been presented. This study presents a decision-making algorithm and real-life applications to display the success and usability of BCIFS in environmental impact evaluation.},
  archive      = {J_SOCO},
  author       = {Alkouri, Abd Ulazeez M. J. S. and Alshboul, Zeyad A.},
  doi          = {10.1007/s00500-025-10608-w},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {3795-3809},
  shortjournal = {Soft Comput.},
  title        = {Environmental impact assessment using bipolar complex intuitionistic fuzzy sets},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deductive systems and R-congruences of pre-hilbert algebras. <em>SOCO</em>, <em>29</em>(8), 3785-3794. (<a href='https://doi.org/10.1007/s00500-025-10601-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-Hilbert algebras belong to a wide class of algebras of logic, they are a generalization of well-known Hilbert algebras. Deductive systems of algebras of logic are an important algebraic notion. In the paper, the properties and characterizations of deductive systems of pre-Hilbert algebras are investigated. It is proven that the deductive systems of a pre-Hilbert algebra (with respect to ⊆) form a relatively pseudocomplemented algebraic lattice. Moreover, R-congruences are introduced and studied. It is shown that the lattice of deductive systems of a pre-Hilbert algebra A is isomorphic to the lattice of R-congruences on A. The construction of the quotient algebra A/D of a pre-Hilbert algebra A via a deductive system D of A is given and the fundamental homomorphism theorem is obtained. Furthermore, maximal deductive systems are investigated. The homomorphic properties of maximal deductive systems of a pre-Hilbert algebra are provided. Finally, some characterizations of maximal deductive systems are given.},
  archive      = {J_SOCO},
  author       = {Walendziak, Andrzej},
  doi          = {10.1007/s00500-025-10601-3},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {3785-3794},
  shortjournal = {Soft Comput.},
  title        = {Deductive systems and R-congruences of pre-hilbert algebras},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partial metric spaces on effect algebras. <em>SOCO</em>, <em>29</em>(8), 3775-3784. (<a href='https://doi.org/10.1007/s00500-025-10593-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the concept of partial metric spaces on effect algebras considering the axiom of “nonzero self-distances”. Partial metric spaces for every state defined on effect algebras are obtained and their properties are investigated. It is also proved that each partial metric space gives rise to a metric space on effect algebras. Further, it is proved that the partial metric spaces on effect algebras are complete. 0-completeness characterization of partial metric spaces is also discussed. Convexity and completeness of the obtained metric space are also discussed.},
  archive      = {J_SOCO},
  author       = {Mishra, Sarvesh Kumar and Shukla, Mukesh Kumar and Singh, Akhilesh Kumar},
  doi          = {10.1007/s00500-025-10593-0},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {3775-3784},
  shortjournal = {Soft Comput.},
  title        = {Partial metric spaces on effect algebras},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of selection noise in genetic algorithms. <em>SOCO</em>, <em>29</em>(8), 3757-3773. (<a href='https://doi.org/10.1007/s00500-025-10652-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selection is often considered as a fundamental force in the evolutionary process. Genetic drift, or selection noise, is an important characteristic of selection methods. It has a direct effect on the performance of genetic algorithms. In this paper, a brief review of methods to analyze genetic drift is given, and known estimations of selection noise of various selection schemes used in genetic algorithms are presented. After that, genetic drift of widely used proportional, ranking, and tournament selection schemes is thoroughly studied. To this end, two new measures for selection noise analysis are proposed, namely the noise takeover time and pure reproduction rate. Using these measures, the effect of population size, chromosome length, and selection scheme parameters on genetic drift is analyzed. Also, selection schemes known as being selection pressure equivalent are tested for selection noise equivalence. Both theoretical and experimental approaches are used for the analysis. The results obtained are presented in tabular form. Wherever possible, it is indicated whether the obtained results are identical or different from the results of previous studies. Since no comprehensive study of selection noise has been conducted previously, this indication concerns only some of the results. Although our results differ at some points from those presented earlier, they are consistent on both measures.},
  archive      = {J_SOCO},
  author       = {Gulayeva, Nataliya M. and Borrego-Díaz, Joaquín and Sancho-Caparrini, Fernando},
  doi          = {10.1007/s00500-025-10652-6},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {3757-3773},
  shortjournal = {Soft Comput.},
  title        = {Analysis of selection noise in genetic algorithms},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Infinite computations and büchi automata using grossone. <em>SOCO</em>, <em>29</em>(8), 3749-3755. (<a href='https://doi.org/10.1007/s00500-025-10648-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional models of computation on finite strings can accept strings or produce a result of a computation. However, when a computation continues for an indefinite (infinite) period a different model of computation is needed. Büchi automata provide such a model of computation. Büchi automata are finite automata operating on infinite strings. A computation is successful (or accepted) by a Büchi automaton if, given a set of favorable states, a favorable state (or states) occur(s) infinitely often. However, there is no accounting for non-favorable states also occurring infinitely often. Hence, the meaning of a successful computation of Büchi automata can have lower than acceptable accuracy. In this paper, the new paradigm of the infinite unit axiom and grossone are applied to extend the computational accuracy of Büchi automata and leads to a more accurate meaning of a successful computation on an infinite string.},
  archive      = {J_SOCO},
  author       = {D’Alotto, Louis},
  doi          = {10.1007/s00500-025-10648-2},
  journal      = {Soft Computing},
  month        = {4},
  number       = {8},
  pages        = {3749-3755},
  shortjournal = {Soft Comput.},
  title        = {Infinite computations and büchi automata using grossone},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive hyperparameter selection in kernel-based partition of unity methods by global optimization techniques. <em>SOCO</em>, <em>29</em>(7), 3733-3748. (<a href='https://doi.org/10.1007/s00500-025-10624-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a new numerical algorithm to detect the kernel shape parameter and the subdomain radius size within a partition of unity method for scattered data interpolation. Since an adaptive search of such hyperparameters is quite expensive from the computational point of view, we propose the use of a leave-one-out cross-validation (LOOCV) technique combined with univariate global optimization tools from the class of Lipschitz derivative-free methods. Conventional LOOCV methods often suffer from ill-conditioning, particularly in high-dimensional settings, leading to computational inefficiencies. To address these issues, we consider efficient global optimization strategies characterized by optimistic and pessimistic improvements. The resulting algorithm allows us to improve the performance of the standard approach in terms of both accuracy and efficiency. Numerical results deriving from the study of some test cases and an application to real-world data support our analysis.},
  archive      = {J_SOCO},
  author       = {Cavoretto, Roberto and De Rossi, Alessandra and Haider, Adeeba and Sergeyev, Yaroslav D.},
  doi          = {10.1007/s00500-025-10624-w},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3733-3748},
  shortjournal = {Soft Comput.},
  title        = {Adaptive hyperparameter selection in kernel-based partition of unity methods by global optimization techniques},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multifactor type-2 fuzzy time series model based on improved fuzzy C-means algorithm and justifiable granularity for stock index forecasting. <em>SOCO</em>, <em>29</em>(7), 3719-3732. (<a href='https://doi.org/10.1007/s00500-025-10651-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy time series (FTS) models are widely used in prediction tasks due to their ability to handle uncertain and nonlinear problems effectively. However, type-1 fuzzy sets have limitations in dealing with data noise and linguistic ambiguity, particularly in multifactor situations. This study proposes a multifactor stock index forecasting model based on type-2 fuzzy sets and a variable size interval partitioning technique. Firstly, information granules are constructed with enhanced effectiveness and interpretability. This is achieved using the fuzzy C-means (FCM) clustering algorithm and the principle of justifiable granularity to partition the universe of discourse. The FCM algorithm in this model attains optimal clustering results by employing an interval type-2 fuzzy approach to adjust the fuzzy parameter m in FCM. Secondly, to more accurately capture the non-determinacy in the time series, three observations of the stock index are modeled as type-2 fuzzy sets, which results in a group of refined first-order fuzzy relationships. To evaluate the performance of this model, experiments were conducted using six benchmark datasets from the Taiwan Stock Exchange Index (TAIEX). The corresponding root mean square error (RMSE) was calculated as the evaluation criterion. Compared with nine representative time series forecasting approaches, the experimental results demonstrate that our model not only guarantees effectiveness and robustness but also achieves enhanced prediction performance.},
  archive      = {J_SOCO},
  author       = {Gong, Zengtai and Feng, Jindong},
  doi          = {10.1007/s00500-025-10651-7},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3719-3732},
  shortjournal = {Soft Comput.},
  title        = {A novel multifactor type-2 fuzzy time series model based on improved fuzzy C-means algorithm and justifiable granularity for stock index forecasting},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Absolute value equations with interval uncertainty. <em>SOCO</em>, <em>29</em>(7), 3705-3718. (<a href='https://doi.org/10.1007/s00500-025-10655-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the (generalized) absolute value equations with uncertain entries. In particular, we assume that the entries come from given intervals. For such interval-valued problem, we study the fundamental properties regarding solutions and solvability. First, we address the issue of the unique solvability of each realization. This is a hard problem, but it can be characterized by means of a regularity of a set of matrices or by a nonlinear system of inequalities; in contrast, the nonnegative unique solvability is polynomially decidable. Second, we focus on the overall solution set. We provide a closed-form characterization and inspect its topological properties such as boundedness. Since the solution set is hard to deal with, we derive a formula for an outer approximation and analyze the situation when the approximation is tight. Eventually, we investigate the convex hull of the solution set; we present an explicit formula that yields the convex hull under mild assumptions.},
  archive      = {J_SOCO},
  author       = {Hladík, Milan and Ptáčková, Lenka},
  doi          = {10.1007/s00500-025-10655-3},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3705-3718},
  shortjournal = {Soft Comput.},
  title        = {Absolute value equations with interval uncertainty},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 0–1 linear programming under interval uncertainty. <em>SOCO</em>, <em>29</em>(7), 3691-3704. (<a href='https://doi.org/10.1007/s00500-025-10625-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the model of an integer linear program with binary variables within the framework of interval programming, which can be used to represent various optimization problems whose input data are affected by interval-valued uncertainty. In the considered model, the inexact or uncertain coefficients of the integer program can be independently perturbed within the given lower and upper bounds. In this paper, we characterize the main properties of 0–1 interval linear programs with respect to feasibility and optimality. Namely, we discuss the feasible and optimal solutions in the weak and in the strong sense, i.e. solutions feasible or optimal for some or for each choice of the interval data. We also address the problem of computing the best and the worst optimal value, as well as the related problem of describing the possibly disconnected set of all optimal values. Due to the dependency problem inherently present in interval programming, we study formulations involving both equations and inequality constraints. Moreover, we prove that for pure 0–1 interval linear programs the standard transformation of splitting an equation constraint into two opposite inequalities preserves the set of (weakly) optimal solutions, which is generally not true for interval linear programs with continuous variables.},
  archive      = {J_SOCO},
  author       = {Garajová, Elif and Hladík, Milan and Rada, Miroslav},
  doi          = {10.1007/s00500-025-10625-9},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3691-3704},
  shortjournal = {Soft Comput.},
  title        = {0–1 linear programming under interval uncertainty},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The force of few: Boosting deviance detection in data scarcity scenarios through self-supervised learning and pattern-based encoding. <em>SOCO</em>, <em>29</em>(7), 3675-3690. (<a href='https://doi.org/10.1007/s00500-025-10646-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern business environments, identifying anomalous or deviant instances in business process executions is a critical concern for enterprises and organizations. Recent advancements show that deep deviance detection models (DDMs), trained on process traces using (semi-)supervised learning techniques, outperform traditional machine learning methods. However, the effectiveness of these deep learning models often depends on large training datasets, which are not always available in practice, particularly in Green AI contexts, where data and computational resources are limited. To address these challenges, this paper presents a novel methodology for discovering deep DDMs that mitigates the impact of limited training data. Our approach incorporates an auxiliary self-supervised learning task that complements the primary deviance classification objective. In addition, we enhance the model with an autoencoder, using its reconstruction error as an additional self-supervisory signal. To promote interpretability, the model adopts a pattern-based encoding mechanism, on top of which two parallel feature-representation layers are efficiently and robustly learned through residual-like skip connections. Our method demonstrates its ability to handle the dual challenges of data efficiency and model explainability, as shown in a case study involving the execution traces of a real-world business process. The results highlight the potential of deep DDMs to achieve high performance in deviance detection, even when faced with limited data availability. Notably, our approach achieves an average performance gain (across all performance metrics) of over 15% while using only 5% of the labelled data, compared to a fully supervised baseline model, when evaluated on two publicly available logs from the current literature.},
  archive      = {J_SOCO},
  author       = {Folino, Francesco and Folino, Gianluigi and Guarascio, Massimo and Pontieri, Luigi},
  doi          = {10.1007/s00500-025-10646-4},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3675-3690},
  shortjournal = {Soft Comput.},
  title        = {The force of few: Boosting deviance detection in data scarcity scenarios through self-supervised learning and pattern-based encoding},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multicombinators as observable presheaves. <em>SOCO</em>, <em>29</em>(7), 3665-3673. (<a href='https://doi.org/10.1007/s00500-025-10636-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we introduce the concept of multicombinators as an alternative Turing-complete model of computation, modally extending the formalism of Combinatory Logic. We present a diagrammatic representation of multicombinators as presheaves defined over a category of generic figures. By adopting Sergeyev’s grossone numeral system, we obtain a sharper characterization of non-halting multicombinators. As a result of our analysis, we show how results for “infinite” combinators using the grossone formalism involving the notion of observability may be extended to the setting of multicombinators. These results formalize the general concept of tractable properties of multicombinators involving sequences of length less than or equal to grossone.},
  archive      = {J_SOCO},
  author       = {Gangle, Rocco and Tohmé, Fernando and Caterina, Gianluca},
  doi          = {10.1007/s00500-025-10636-6},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3665-3673},
  shortjournal = {Soft Comput.},
  title        = {Multicombinators as observable presheaves},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reparable threshold paillier encryption scheme for federated learning. <em>SOCO</em>, <em>29</em>(7), 3659-3664. (<a href='https://doi.org/10.1007/s00500-025-10640-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Threshold Paillier encryption scheme finds extensive application in the context of federated learning. However, the issue of client dropout frequently arises within the context of federated learning, rendering the conventional threshold Paillier encryption scheme ineffective for data decryption. To address this issue, this paper introduces a (N, k, d)-reparable threshold Paillier encryption scheme by combining the reparable Shamir secret-sharing scheme with the Paillier encryption scheme. The proposed scheme has demonstrated several valuable capabilities. Specifically, we initially establish the security of the secret-sharing property of this scheme, namely, any group of k participants can collaboratively recover the private key, while $$k-1$$ or fewer participants cannot recover the private key. Moreover, we demonstrate the scheme’s ability to handle the client dropout problem, namely, any group of d normal participants can collectively repair the private key segments of dropout clients. Ultimately, we substantiate that the (N, k, d)-reparable threshold Paillier encryption scheme consistently upholds the precision of decryption processes.},
  archive      = {J_SOCO},
  author       = {Zhang, Yi and Tian, Kun and Lu, Yunfan and Liu, Fengxia and Li, Cheng and Gong, Zixian and Hu, Zhe and Li, Jia and Xu, Qun},
  doi          = {10.1007/s00500-025-10640-w},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3659-3664},
  shortjournal = {Soft Comput.},
  title        = {Reparable threshold paillier encryption scheme for federated learning},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting leading economic indicators in the US from financial news using multi-task learning. <em>SOCO</em>, <em>29</em>(7), 3641-3657. (<a href='https://doi.org/10.1007/s00500-025-10629-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leading economic indicators are crucial statistics that are based on the economy and have a significant impact on various factors such as policies, stock market trends, etc. However, due to the long release time interval of these indicators, it is challenging to accurately predict their trends in advance. In this paper, we propose an effective framework for forecasting leading economic indicators in the United States by utilizing leading indicators to predict each other and learn their mutual correlation through an attention mechanism. To achieve this, we present a hierarchical, multi-task learning approach that uses textual data to make predictions for four essential leading economic indicators. We first group news articles by topic and then summarize and extract information using a time-series method and attention. Finally, we concatenate news information with historical data to forecast the leading economic indicators. Our experimental results demonstrate that our approach successfully forecasts leading economic indicators, and we are able to predict four indicators one month beforehand. This framework has significant potential for use in the finance industry and can be used to inform important decisions related to investment strategies, policymaking, and other financial aspects.},
  archive      = {J_SOCO},
  author       = {Ying, Josh Jia-Ching and Liu, Chia-Chen and Tseng, Vincent S. and Zhang, Wenbin and Zhang, Ji},
  doi          = {10.1007/s00500-025-10629-5},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3641-3657},
  shortjournal = {Soft Comput.},
  title        = {Forecasting leading economic indicators in the US from financial news using multi-task learning},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced protein complex detection using square clustering coefficient. <em>SOCO</em>, <em>29</em>(7), 3627-3640. (<a href='https://doi.org/10.1007/s00500-025-10615-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying protein complexes from protein-protein interaction networks is one of the crucial tasks in computational biology. Traditional methods, along with their shortcomings in fully understanding protein complex composition, also have inherent limitations and are expensive to implement. In this paper, we introduce a novel method that not only acknowledges but actively tackles these challenges. Our approach, centered around a core-attachment framework, employs a blend of topological metrics, such as square clustering coefficients, in conjunction with traditional clustering coefficients. After establishing the core, we incorporate attachment proteins based on specific conditions employing a depth-first search (DFS) methodology, to form a protein complex. By harnessing multiple metrics, our goal is to elevate the accuracy of protein complex identification beyond what single-metric approaches can achieve. To validate the effectiveness of our approach, we conducted extensive experiments using multiple datasets, including Gavin06, Krogan core, Krogan extend, and DIP datasets, and assessed metrics such as precision, recall, F-measure, and coverage. Our results not only demonstrate the superiority of our method over traditional approaches but also align with findings from related studies. Overall, our study contributes to the ongoing efforts in computational biology by presenting a comprehensive approach to protein complex identification that addresses the shortcomings of previous methods. Through a combination of innovative techniques and insights from recent research, we aim to push the boundaries of accuracy and comprehensiveness in protein complex detection.},
  archive      = {J_SOCO},
  author       = {Mirzaee, Parimah and Moghaddam Charkari, Nasrollah and Roayaei, Mehdy},
  doi          = {10.1007/s00500-025-10615-x},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3627-3640},
  shortjournal = {Soft Comput.},
  title        = {Enhanced protein complex detection using square clustering coefficient},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Impact of artificial intelligence and blockchain on supply chain resilience under influence of change management. <em>SOCO</em>, <em>29</em>(7), 3617-3625. (<a href='https://doi.org/10.1007/s00500-025-10564-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging technologies such as big data analytics, Internet of Things, artificial intelligence and blockchain have revolutionized management in the twenty-first century. However, concepts such as supply chain resilience are still given high importance, especially in the current conditions when the complexity of economic activities and the uncertainties of the environment are increasing. Cyber-attacks, humanitarian crises, pandemics or ecological disasters, all of these put the resilience of companies to the test. Consequently, in this study we empirically analyse artificial intelligence and blockchain to determine their role in the supply chain resilience. After using structural equation modelling to analyse a sample of 197 medium-size enterprises from Romanian manufacturing sector, we found that most of the initial hypotheses are validated and the results are congruent with previous research carried out in the field.},
  archive      = {J_SOCO},
  author       = {Ceptureanu, Eduard Gabriel and Ferraro, Giovanna and Ceptureanu, Sebastian Ion and Lazar, Rodica and Florescu, Mircea and Matei, Alina},
  doi          = {10.1007/s00500-025-10564-5},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3617-3625},
  shortjournal = {Soft Comput.},
  title        = {Impact of artificial intelligence and blockchain on supply chain resilience under influence of change management},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-scale deep neural networks for early fault diagnosis in rolling ball bearings. <em>SOCO</em>, <em>29</em>(7), 3603-3615. (<a href='https://doi.org/10.1007/s00500-025-10658-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling ball bearings are an essential part of rotating machines that can be affected by various faults, increasing maintenance costs and downtime. The paper presents a comparative study of a knowledge-based approach, including Artificial Neural Network (ANN) and multiscale Convolutional Neural Network (CNN) LeNet-5 architecture, including 1D-CNN and 2D-CNN, aimed to detect and diagnose the failures in components of the bearings at an early stage. The models are trained using nonlinear vibration signals that were recorded from a laboratory experimental setup on Machine Fault Simulator (MFS), focusing on ball bearings with defects in inner race (IR), outer race (OR) and ball (B) itself. The classification accuracy of the models is significantly enhanced through the utilisation of deep features extracted by neural networks employing transfer learning models compared to traditional ANN approaches. A comparative analysis, including neighborhood component analysis, evaluates the performance of ANN 1D CNN and 2D CNN models under various fault conditions. Overall, the result of this paper introduces a promising approach for both efficient and accurate fault detection and severity estimation in bearings of induction motors, potentially reducing the need for extensive manpower and sensor usage.},
  archive      = {J_SOCO},
  author       = {Kumar, Rajeev and Anand, R. S.},
  doi          = {10.1007/s00500-025-10658-0},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3603-3615},
  shortjournal = {Soft Comput.},
  title        = {A multi-scale deep neural networks for early fault diagnosis in rolling ball bearings},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cross-scale gaussian wavelet model with decomposition cross-consistency for TAO multifocal region semi-supervised segmentation. <em>SOCO</em>, <em>29</em>(7), 3589-3602. (<a href='https://doi.org/10.1007/s00500-025-10572-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thyroid-associated ophthalmopathy (TAO) is an organ-specific autoimmune disease that severely affects sufferers’ health and life. Clinical activity score (CAS) is one of the significant methods for the early diagnosis of TAO. However, the acquisition of CAS scores relies heavily on the clinician’s subjective experience. Accurate identification of TAO regions segmented by scientific techniques is one of the essential prerequisites for the objective acquisition of the CAS scores. But the currently proposed models have shortcomings of high label annotation costs, etc. Therefore, a cross-scale Gaussian wavelet model with decomposed cross-consistency (CGWM) is proposed for TAO multifocal region semi-supervised segmentation. First, the encoder-decoder dual-tree complex wavelet model is employed for the interpretable extraction of the robust multi-directional features of the diseased region and the resolution recovery. Subsequently, a cross-scale Gaussian hybrid attention mechanism is developed for flexible fine multi-scale contextual feature extraction of unlabeled images by introducing the Gaussian probability model. Finally, a novel and simple decomposition cross-consistency with a decomposition penalty is proposed for further strengthening the consistency between the two segmentation networks and ensuring that the prediction decision boundary is more accurately located in the low-density regions. Compared to other selected benchmark models and fully supervised segmentation techniques, extensive experiments showed that the CGWM achieved state-of-the-art segmentation performance with an accuracy of 84.21% using only 100 tagged images for training, with good prospects for clinical application due to its low annotation cost and strong interpretability.},
  archive      = {J_SOCO},
  author       = {Zhu, Haipeng and He, Hong and Song, Xuefei},
  doi          = {10.1007/s00500-025-10572-5},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3589-3602},
  shortjournal = {Soft Comput.},
  title        = {A cross-scale gaussian wavelet model with decomposition cross-consistency for TAO multifocal region semi-supervised segmentation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shadow learner system: Implementation of CNN with explainable AI model for bone radiology image classification. <em>SOCO</em>, <em>29</em>(7), 3571-3588. (<a href='https://doi.org/10.1007/s00500-025-10644-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancements in deep learning models for medical image classification have greatly improved accuracy, yet the challenge of explainability persists, making it difficult for clinicians to trust and effectively utilize these models in decision-making. This paper presents the Shadow Learner System, a novel approach that combines Convolutional Neural Networks with Explainable AI (XAI) techniques, focusing on the value of misclassified data—both false positives and negatives—by analyzing them to uncover important insights that traditional methods might overlook. We call our framework the Duplex Computer-Aided Diagnosis System. Using the Musculoskeletal Radiographs dataset from Stanford University, which includes images of bone abnormalities that may require surgical intervention, we demonstrate how our system enhances explainability. Our findings show that about 85% of the Regions of Interest identified from misclassified images provided useful insights that clinicians found valuable in their work. Moreover, we observed that the shadow set—comprising important misclassified instances—constituted approximately 4–6% of the original dataset. This research highlights how misclassified data can reveal hidden patterns that improve the overall understanding and trust in AI models used in healthcare. The Shadow Learner System not only serves as a reference for treatment decisions but also has potential applications for other medical conditions that require surgical evaluation, such as osteonecrosis and various tumors. By shifting the focus of XAI from mere model validation to enhancing clinical interpretability, this work contributes to the more effective integration of AI in medical practice.},
  archive      = {J_SOCO},
  author       = {Wu, Yaoyang and Fong, Simon and Liu, Liansheng},
  doi          = {10.1007/s00500-025-10644-6},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3571-3588},
  shortjournal = {Soft Comput.},
  title        = {Shadow learner system: Implementation of CNN with explainable AI model for bone radiology image classification},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Supply chain performance prediction model for make-to-order system using artificial neural network. <em>SOCO</em>, <em>29</em>(7), 3555-3569. (<a href='https://doi.org/10.1007/s00500-025-10553-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a Supply Chain Operations Reference (SCOR®) based performance prediction model for the Make-to-Order job shop facility. The model uses Artificial Neural Network, which is fed with the real data collected from automotive job shop to predict cost and customer response using feed forward back error propagation learning algorithm with nonlinear activation function. The model was implemented using the MATLAB program and the correlation coefficient results demonstrated a high positive correlation between the expected and projected performance values, which supports SCOR® level 1 metrics for all ANN models. The average percentage error and the percentage standard deviation of the best cost model are found to be 0.75 and 1.28 respectively. Similarly, for the response model, they are found to be 0.13 and 0.25 respectively. These results highlight the quality of the developed model and its expected positive impact for improving supply chain performance.},
  archive      = {J_SOCO},
  author       = {Piya, Sujan and Mokhtar, Mahmoud},
  doi          = {10.1007/s00500-025-10553-8},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3555-3569},
  shortjournal = {Soft Comput.},
  title        = {Supply chain performance prediction model for make-to-order system using artificial neural network},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Organising unstructured data using double net self-organising map (DNSOM) model. <em>SOCO</em>, <em>29</em>(7), 3533-3554. (<a href='https://doi.org/10.1007/s00500-025-10607-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface reconstruction is the process of representing surfaces using the data obtained from scanning devices. When the data obtained is unstructured during data collection, it can cause problems in presenting the surface due to the lack of connectivity information for the data. It shows that data collection is a crucial task in surface reconstruction. Previous works have proved that Self-Organising Map (SOM) models can be used to organise unstructured data. However, the 2-D SOM model will generate a surface with holes for the closed surfaces. Besides, the 3-D SOM model will generate an incorrect surface due to the connectivity of the internal neurons. In addition, the Cube Kohonen SOM (CKSOM) model is limited to the same grid size. Hence, a SOM model known as Double Net SOM (DNSOM) is proposed via the merging of two 2-D SOMs to overcome the issues. Three data sets (cube, sphere, and talus bone) with different grid sizes are applied to test the models. When the grid size of all the models increases, the surface becomes smoother. The DNSOM contains a lower quantisation error than the 2-D SOM and the lowest topographic error among the other SOM models. It performs faster than the 3-D SOM and CKSOM. It presents the correct closed surface with a smaller number of neurons and different grid sizes. Microsoft Visual Studio 2022 with the C++ programming language is used to develop the models, while GNUPlot is used to visualise the results.},
  archive      = {J_SOCO},
  author       = {You, Cheng Chun and Lim, Seng Poh and Lee, Chen Kang and Tan, Joi San and Lim, Seng Chee},
  doi          = {10.1007/s00500-025-10607-x},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3533-3554},
  shortjournal = {Soft Comput.},
  title        = {Organising unstructured data using double net self-organising map (DNSOM) model},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving convex multi-objective optimization problems using a projection neural network framework. <em>SOCO</em>, <em>29</em>(7), 3509-3532. (<a href='https://doi.org/10.1007/s00500-025-10550-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a projection neural network model for solving convex multi-objective optimization problem (CMOP) is considered. The CMOP is first converted into an equivalent convex nonlinear single-objective programming problem by the mean of the weighted sum method, where the Pareto optimal solutions (POS) are calculated by diversifying values of weights. A neural network model is then constructed for solving the obtained convex problem. It is shown that the presented neural network model is stable in the sense of Lyapunov and is globally convergent. Simulation results are given to illustrate the global convergence and performance of our proposed model. Both theoretical and numerical approaches are studied. It is illustrated that the numerical results are in good agreement with the theoretical arguments.},
  archive      = {J_SOCO},
  author       = {Jahangiri, Mohammadreza and Nazemi, Alireza},
  doi          = {10.1007/s00500-025-10550-x},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3509-3532},
  shortjournal = {Soft Comput.},
  title        = {Solving convex multi-objective optimization problems using a projection neural network framework},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GWO based energy-efficient workflow scheduling for heterogeneous computing systems. <em>SOCO</em>, <em>29</em>(7), 3469-3508. (<a href='https://doi.org/10.1007/s00500-025-10614-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the critical challenge of energy-efficient task scheduling in heterogeneous computing systems, which are known for their superior performance and complexity management across diverse applications. The research proposes two novel task scheduling algorithms based on the metaheuristic grey wolf optimization technique to optimize energy consumption while minimizing computational time for parallel applications. In the first algorithm, the primary objective is to mitigate static energy consumption while simultaneously enhancing computational efficiency. This is achieved by grouping the most energy-efficient tasks into clusters. While the second algorithm employs a refined approach to minimize dynamic energy consumption. This involves the utilization of a dynamic voltage and frequency scaling-enabled grey wolf optimization model, meticulously crafted for the allocation of these task clusters onto the most suitable processors. The proposed algorithms are rigorously evaluated using real-world applications, including fast Fourier transform, Gaussian elimination, and randomly generated parallel applications. The experimental findings affirm that the proposed approach consistently improves performance across various metrics, including energy consumption, degree of imbalance, resource utilization, sensitivity analysis and task assignment computation time. Specifically, it significantly reduces computational time, achieving a reduction of 30–47% for fast Fourier transform applications and 44–48% for Gaussian elimination applications compared to existing algorithms. Additionally, it improves resource utilization, with enhancements ranging from 12.28 to 45.99% when compared to a variety of existing algorithms. To further validate the effectiveness of the proposed approach, it is applied to 10 real-world optimization problems. The performance is benchmarked against three state-of-the-art algorithms from the 'CEC2020 Competition': SASS, sCMAgES, and COLSHADE. This comprehensive evaluation framework provides a robust assessment of the algorithms' efficacy.},
  archive      = {J_SOCO},
  author       = {Karishma and Kumar, Harendra},
  doi          = {10.1007/s00500-025-10614-y},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3469-3508},
  shortjournal = {Soft Comput.},
  title        = {GWO based energy-efficient workflow scheduling for heterogeneous computing systems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ligand-based and structure-based approaches for the identification of potential SARS-CoV-2 3CLpro inhibitors. <em>SOCO</em>, <em>29</em>(7), 3443-3468. (<a href='https://doi.org/10.1007/s00500-025-10628-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {SARS-CoV-2 is still causing new deaths daily and new variants are appearing. Thus, the a need to identify potential drug-like inhibitors. QSAR and molecular docking were elaborated. The integration of soft computing techniques ensures precise and reliable predictions, accelerating drug discovery significantly. This study delves into soft computing applications in drug design through the use of the dragonfly algorithm, endorsed with ADMET properties and molecular docking studies. Thus, Bayesian Regularization-Backpropagation Neural Network BR-BPNN, Convolutional Neural Network CNN, Support Vector Regression SVR, and Dragonfly Algorithm DA were used because of their advantages over other algorithms. The mechanistic interpretation of the 10 selected descriptors revealed that the spectral diameter of the adjacency matrix and the unsubstituted benzenes had the most positive impact. The nonaromatic conjugated carbons and the number of neighboring atoms at the radius 7 from the chiral center had the most negative effect. The statistical validation of the three models showed an outperformance of the DA-SVR with determination coefficient R2 = 0.92, coefficient of cross-validation Q2 = 0.92, and root mean square error RMSE = 0.21. Henceforth, the present DA-SVR model is mechanistic and correlative and can be used for further computer drug design studies to develop 3CLpro inhibitors. This study also suggests that too complex (DA-CNN) or too simple (BR-BPNN) models are less likely to predict accurately the activity of the considered dataset. Molecules 19 (− 7.8 kcal/mole) and 15 (− 7.5 kcal/mol) were the most affine to the binding site among 24 selected drug-like molecules with 1 kcal/mol difference less than the reference molecule PF-07321332, with conventional Hydrogen bonds HBs, pi-donor HBs, halogen, and alkyl bonds. They share triazole and 1H-isoindole fragments with fluorine in the 1H-isondole in molecule 15. The results of this study pave the way for soft computing techniques enhancement of QSAR-based synthesis and analog generation with respect to molecules 19 and 15 and the structural features indicated and predict their IC50 using the QSAR model to identify de novo potential inhibitors that can undergo wet-lab experiments.},
  archive      = {J_SOCO},
  author       = {Madani, Achouak and Benkortbi, Othmane and Laidi, Maamar and Si-Moussa, Cherif and Salim, Naomie},
  doi          = {10.1007/s00500-025-10628-6},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3443-3468},
  shortjournal = {Soft Comput.},
  title        = {Ligand-based and structure-based approaches for the identification of potential SARS-CoV-2 3CLpro inhibitors},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparative performance of different type-1 tournament based metaheuristic algorithms in solving engineering beam design optimization problems and structural engineering design problems. <em>SOCO</em>, <em>29</em>(7), 3415-3442. (<a href='https://doi.org/10.1007/s00500-025-10611-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tournamenting process is one of the effective approaches for formulating hybrid algorithm in the recent years. In this work, four hybrid algorithms through tournamenting process are developed with the help of four popular and well-known metaheuristic algorithms, viz. teaching learning based optimization (TLBO), embedded cuckoo search (ECS), social group optimization (SGO) and honey badger algorithm (HBA). The resulting algorithms are named as T1-TLBO, T1-ECS, T1-SGO and T1-HBA. These algorithms are applied to solve structural engineering design problems. The results executed by proposed algorithms are compared numerically with a number of recently developed metaheuristic algorithms. Finally, to analyse the statistical significance of the proposed hybrid algorithms, two nonparametric statistical tests are performed and a fruitful conclusion is drawn.},
  archive      = {J_SOCO},
  author       = {Mandal, Goutam and Kumar, Nirmal and Bhunia, Asoke Kumar},
  doi          = {10.1007/s00500-025-10611-1},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3415-3442},
  shortjournal = {Soft Comput.},
  title        = {A comparative performance of different type-1 tournament based metaheuristic algorithms in solving engineering beam design optimization problems and structural engineering design problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-stage multi-objective optimization for robust QFT controller and prefilter synthesis in process control systems. <em>SOCO</em>, <em>29</em>(7), 3383-3414. (<a href='https://doi.org/10.1007/s00500-025-10643-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Engineering problems in the real world are often multi-objective, requiring multiple performance specifications and design constraints to be met for optimal performance. The mathematical model used in the controller synthesis approximates the actual system and is susceptible to measurement noise, disturbances, and parametric uncertainties during operation. To maintain the integrity and safety of processes, control systems must offer robust performance even under the influence of these uncertainties. The proposed work presents a single-stage procedure for the design of quantitative feedback theory (QFT) controllers using a multiple-objective optimization using the genetic algorithm. The proposed methodology is valid for both single-input single-output (SISO) and multi-input multi-output (MIMO) systems. The proposed work also explores the visualization of n-dimensional Pareto fronts using level diagrams to help choose an ideal solution. The approach is demonstrated through its application to the robust control of two process control systems: (a) liquid level control in coupled tanks (SISO) and (b) the level and temperature control in a three-stage evaporator system (MIMO). A comparison has been made with the existing techniques, and it can be observed that the proposed work offers an improvement of 28.4% in rise time, 61.5% and 29.7% in settling time, a 99.92% reduction in overshoot percentage, and 5.6% & 82.43% improvement in gain margin and phase margins when compared to already existing controllers for liquid level control systems. Moreover, in the case of level and temperature control in a three-stage evaporator MIMO system, an improvement of 41.3% can be observed in settling time $${T}_{11}$$ loop, a significant reduction of 99.91% and 99.42% in overshoot percentages for loops $${T}_{11}$$ and $${T}_{22}$$ is observed, a reduction of 73.65% and 37.19% in peak sensitivity function and a reduction of 78.33% and 16.11% can be observed in both the $${T}_{11}$$ and $${T}_{22}$$ loops, respectively when compared to already existing controllers. Thus, the proposed work offers optimal and robust behavior even under the influence of parametric uncertainties.},
  archive      = {J_SOCO},
  author       = {Katal, Nitish and Narayan, Shiv},
  doi          = {10.1007/s00500-025-10643-7},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3383-3414},
  shortjournal = {Soft Comput.},
  title        = {Single-stage multi-objective optimization for robust QFT controller and prefilter synthesis in process control systems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Home energy system: Optimal design via risk-averse stochastic programming. <em>SOCO</em>, <em>29</em>(7), 3367-3381. (<a href='https://doi.org/10.1007/s00500-025-10616-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a risk-averse stochastic programming model for the optimal design of a home energy system that integrates renewable energy generation from photovoltaic panels and a battery energy storage system. Prosumer’s loads are classified into base and programmable loads and the possibility of exploiting the flexibility of these latter is considered in the optimal design. Uncertainties associated with weather-related variables, load demand, and electricity tariffs are considered, through the definition of scenarios representing possible joint evolutions of these factors. The model incorporates a risk measure to control the cost variability and the objective function, by the conditional value-at-risk, aims at minimizing the expected costs that the prosumer may incur in a given percentage of worst-case scenarios. The approach is applied to a real case study in the residential sector calibrated on data of the Italian electricity market. Through numerical experiments and sensitivity analysis, optimal system sizing and operational strategies are derived under different risk preferences. Results demonstrate that the risk-averse stochastic programming approach leads to robust decisions, providing a balance between cost-effectiveness and reliability in the management of the home energy system.},
  archive      = {J_SOCO},
  author       = {Beraldi, Patrizia and Violi, Antonio and Laganá, Demetrio and Carrozzino, Gianluca},
  doi          = {10.1007/s00500-025-10616-w},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3367-3381},
  shortjournal = {Soft Comput.},
  title        = {Home energy system: Optimal design via risk-averse stochastic programming},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FTBAC: Fuzzy trust based access control for healthcare cross-domain environment. <em>SOCO</em>, <em>29</em>(7), 3349-3366. (<a href='https://doi.org/10.1007/s00500-025-10650-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Thing based healthcare ecosystems are extremely popular as they are built on a network of devices that are connected directly to one another in order to collect, share, and use important contextual information. However, in a cross-domain environment, the absence of a delicate, fine-grained access control mechanism may lead to the disruption or leakage of sensitive data. In addition, the plug-and-play nature of the users with wireless healthcare devices may result in disturbances in the accessibility of data. In this article, we propose a Fuzzy Trust-Based Access Control scheme for healthcare environment consisting of dynamically sensitive data. Trust being dynamic in nature has been considered an as attribute along with other static and dynamic attributes for the proposed scheme. The dynamic nature of trust as an attribute prompts us to use fuzzy logic for its calculation. Parameter-based analysis and security analysis exhibits that the proposed scheme is highly scalable in nature and is resilient to reply attack, Distributed-Denial-of-Service attack, and collusion attack. Further, the proposed access control scheme ensures proper delegation, high context awareness, high granularity, and ensures interoperability.},
  archive      = {J_SOCO},
  author       = {Roy, Sujoy and Kumar, Alok and Rao, Udai Pratap},
  doi          = {10.1007/s00500-025-10650-8},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3349-3366},
  shortjournal = {Soft Comput.},
  title        = {FTBAC: Fuzzy trust based access control for healthcare cross-domain environment},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pyranet: A novel architectural approach to reduce the effect of unbalanced classes and analysis on leukemia dataset. <em>SOCO</em>, <em>29</em>(7), 3339-3347. (<a href='https://doi.org/10.1007/s00500-025-10627-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {About 300,000 leukemia cases are diagnosed every year, with the total number of active cases rising to 2.3 million in 2015. Although the number of adults diagnosed with leukemia is pretty high, this is the most common type of cancer found in children in developed countries. Its ability to recur and expensive diagnostic process make patients unable to undergo the diagnosis on a timely basis and consequently can prove fatal for many. The proposed novel model PyraNet aims to tackle the requirement of high-precision machinery and human expertise, as there might not be enough resources for the latter. Proportionate fine-tuning and construction make the model to accurately and precisely detect the presence of leukemic blast cells and classify them into their respective class types. Also, this novel architecture proposed here is a step towards solving the problem of unbalanced classes that often arises when the quantitative distribution of data within different classes is highly biased. As an initiative to tackle it, we have used multi-model-layer training. The analysis of experimental results shows that the proposed model is capable of correctly predicting a higher number of classes with better accuracy.},
  archive      = {J_SOCO},
  author       = {Sharma, Nikhil and Ghumaan, Rajanbir Singh and Sohi, Prateek Jeet Singh and Garg, Bharat and Arya, K. V.},
  doi          = {10.1007/s00500-025-10627-7},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3339-3347},
  shortjournal = {Soft Comput.},
  title        = {Pyranet: A novel architectural approach to reduce the effect of unbalanced classes and analysis on leukemia dataset},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing coordinated target tracking: Innovative particle filters with meta-heuristic integration and advanced model validation. <em>SOCO</em>, <em>29</em>(7), 3307-3338. (<a href='https://doi.org/10.1007/s00500-025-10634-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coordinated target tracking and its augmented variant represent significant challenges in modern surveillance. These tasks are essential for accurately localizing and predicting the movement of dynamic targets. This article introduces an advanced particle filter algorithm with a packet dropout mechanism to enhance tracking accuracy. Additionally, it proposes three meta-heuristic-driven particle filters: the Particle Filter integrated with the Chaotic Gravitational Search Algorithm (PF-CGSA), the Particle Filter integrated with the Improved Grey Wolf Optimizer (PF-IGWO), and the Particle Filter integrated with the Imperialist Competitive Algorithm with Regional Domination Policy (PF-ICARD). These methods are tested using three sophisticated models: the Coordinated Turn Target Tracking Model (CT model), the Augmented Coordinated Turn Target Tracking Model with Cartesian Velocity (ACT1 model), and the Augmented Coordinated Turn Target Tracking Model with Polar Velocity (ACT2 model). Experimental results demonstrate that PF-CGSA, PF-IGWO, and PF-ICARD achieve higher convergence speeds and accuracy. They also effectively mitigate premature convergence phenomena. Comparative analysis based on Root Mean Squared Error (RMSE) metrics underscores their superiority in real-world target tracking challenges, highlighting the potential of these advanced particle filtering techniques in enhancing precision and efficiency in target tracking. Particularly, PF-ICARD achieves the highest accuracy, reducing RMSE by up to 18.64% compared to PF-CGSA and PF-IGWO, making it ideal for high-precision applications. PF-CGSA excels in specific scenarios, notably improving X-coordinate tracking in the ACT2 model by up to 11.39%. Meanwhile, PF-IGWO offers a balanced solution with moderate accuracy and enhanced computational efficiency, suitable for real-time applications.},
  archive      = {J_SOCO},
  author       = {Das, Nitish and Kulkarni, Nilima},
  doi          = {10.1007/s00500-025-10634-8},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3307-3338},
  shortjournal = {Soft Comput.},
  title        = {Enhancing coordinated target tracking: Innovative particle filters with meta-heuristic integration and advanced model validation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance and managerial ability analysis in banking sector: A fuzzy data envelopment analysis approach. <em>SOCO</em>, <em>29</em>(7), 3289-3305. (<a href='https://doi.org/10.1007/s00500-025-10556-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technical efficiency and managerial ability are two key performance indicators in managing business enterprises. Although many attempts have been made to calculate technical efficiency in the data envelopment analysis (DEA) framework, however, few studies have been conducted on calculating managerial ability using DEA. In DEA literature, the estimation of the managerial ability of firms using the deterministic efficiency models may be sensitive to the uncertainty of the input/output data of any production process. In this contribution, we, therefore, introduce a DEA-based procedure to develop a measure of managerial ability. The proposed fuzzy efficiency procedure is applied to sample data on 100 banks in China to compare inferences about their managerial ability. Though the application of our proposed fuzzy managerial ability procedure is illustrative, it can, however, be potentially applied to firms facing fuzzy-type uncertainty in the economy.},
  archive      = {J_SOCO},
  author       = {Amirteimoori, Alireza and Allahviranloo, Tofigh},
  doi          = {10.1007/s00500-025-10556-5},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3289-3305},
  shortjournal = {Soft Comput.},
  title        = {Performance and managerial ability analysis in banking sector: A fuzzy data envelopment analysis approach},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid of particle swarm optimization and fuzzy system for modeling direct current microgrids to improve stability. <em>SOCO</em>, <em>29</em>(7), 3273-3288. (<a href='https://doi.org/10.1007/s00500-025-10543-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population growth increased the need for energy, which led us to use new and clean energy sources. The microgrid is considered one of the best solutions for energy supply, which is one of the main challenges. Here, voltage profile problems in microgrids cause instability in microgrids; PI and phase-proportional-integral controllers stabilize the microgrid's voltage to eliminate the disturbance. Still, the problems with this method are the number of Energy Storage system charges and discharges, which reduces the life of batteries and increases the cost of the system. This article tries to use the optimized FUZZY-PI to control the microgrid voltage by presenting a new solution, which improved the voltage profile with an error of less than one percent. In addition to enhancing the voltage, the proposed method led to stabilizing the microgrid. The practical aspect of this study is the minimum amount of charging and discharging of the battery, leading to increased battery life.},
  archive      = {J_SOCO},
  author       = {Naderi, Hoda and Ghaderi, Neda and Moradi, M. H. and Abedini, Mohammad},
  doi          = {10.1007/s00500-025-10543-w},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3273-3288},
  shortjournal = {Soft Comput.},
  title        = {A hybrid of particle swarm optimization and fuzzy system for modeling direct current microgrids to improve stability},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bi-level programming model for optimal EV charging scheduling and operation in residential communities. <em>SOCO</em>, <em>29</em>(7), 3253-3272. (<a href='https://doi.org/10.1007/s00500-025-10545-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the challenge of disorderly large-scale electric vehicle (EV) charging and its impact on distribution networks by focusing on residential communities as key EV gathering places. We propose a dynamic pricing environment and develop a bi-level programming model capturing the relationship between retailers and EV owners (EVOs). By transforming the bi-level programming into a mixed-integer linear programming problem using the Karush-Kuhn-Tucker conditions and the duality theorem, we obtain an optimal pricing strategy that benefits both parties. We conduct a sensitivity analysis to examine the impact of various factors on the pricing strategy, offering insights for retailers’ scheduling and operational decisions. The efficacy of the proposed algorithm is demonstrated through a case study, highlighting its potential to guide decisions for both retailers and EVOs in residential community EV charging. This work contributes to managing the increasing prevalence of electric vehicles and their impact on power distribution networks, fostering sustainable and efficient energy management strategies in residential communities.},
  archive      = {J_SOCO},
  author       = {Zhu, Gang and Gao, Yan and Dai, Zexing and Sun, Hao},
  doi          = {10.1007/s00500-025-10545-8},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3253-3272},
  shortjournal = {Soft Comput.},
  title        = {A bi-level programming model for optimal EV charging scheduling and operation in residential communities},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive iterated local search algorithm for dynamic patient admission scheduling problems. <em>SOCO</em>, <em>29</em>(7), 3241-3251. (<a href='https://doi.org/10.1007/s00500-025-10631-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare resource management is essential for ensuring the quality of patient care. However, it can be a complex and costly task. This work addresses the patient admission scheduling (PAS) problem, a complex aspect of healthcare resource management. PAS aims to allocate patients to hospital beds within a planning horizon, subject to a variety of healthcare constraints. The goal is to maximize management efficiency and patient comfort to improve medical treatment. In this work, we consider a practical variant of PAS known as dynamic PAS (DPAS). DPAS considers several factors and constraints, such as the daily registration of new patients, urgent patients, uncertainties in stay lengths, operating theatre resources, and the surgery scheduling process. An effective and efficient adaptive iterated local search (AILS) algorithm is proposed to solve DPAS. To enable the search to explore the search space efficiently, the proposed AILS adaptively integrates a number of components. Two adaptive perturbation strategies are devised to locate unexplored areas in the search space. To exploit the newly discovered areas effectively, we propose an adaptive local search mechanism as an intensification strategy to find a high-quality solution. The proposed AILS algorithm is compared to benchmark problems used by existing algorithms. The experimental results demonstrate the effectiveness and efficiency of the proposed approach. Specifically, out of 30 tested instances, AILS obtains 17 of the best-known results using less computational time.},
  archive      = {J_SOCO},
  author       = {Turky, Ayad and Sabar, Nasser R. and Song, Andy and Hussain, Abir and Liatsis, Panos},
  doi          = {10.1007/s00500-025-10631-x},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3241-3251},
  shortjournal = {Soft Comput.},
  title        = {Adaptive iterated local search algorithm for dynamic patient admission scheduling problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization of the rectangle area inside a concave polygon using PSO and tabu search. <em>SOCO</em>, <em>29</em>(7), 3217-3239. (<a href='https://doi.org/10.1007/s00500-025-10568-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimising a figure inside any shape is an important problem with many applications. Several studies tried to find the largest area of the rectangle inside the convex polygon in mathematics, as there are polynomial-time solutions available i.e. there exists an algorithm for finding the solution bounded by a polynomial function, but not for concave polygon as there are no polynomial-time solutions available. This makes this problem an NP (Nondeterministic Polynomial)-complete problem. Generally, the availability of the solution depends upon the length of the input for the problem. However, when solving an NP-complete problem, one method is to apply a polynomial algorithm to estimate the solution; the result will not always be optimal, but it will be close. Therefore, this paper attempts to find the maximum area of the rectangle inside the non-convex polygon by using two heuristic algorithms that are: 1) PSO (Particle Swarm Optimization), and 2) Tabu Search. Where Tabu Search has been utilised for comparative purposes to demonstrate the PSO's exceptional performance. These two algorithms work fast and find the optimal rectangle more efficiently than conventional mathematical approaches. These approximation algorithms have an O(n3) time complexity and O(n2) space complexity for PSO, and O(n4) time complexity and O(n2) space complexity for Tabu Search. In addition to this, the already available literature is also employed for comparative purposes, with PSO displaying competitive results.},
  archive      = {J_SOCO},
  author       = {Kashyap, Gautam Siddharth and Malik, Karan and Wazir, Samar and Brownlee, Alexander E. I.},
  doi          = {10.1007/s00500-025-10568-1},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3217-3239},
  shortjournal = {Soft Comput.},
  title        = {Optimization of the rectangle area inside a concave polygon using PSO and tabu search},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The influence of food bloggers toward consumer’s attitude in restaurant selection: A multi-objective metaheuristic approach. <em>SOCO</em>, <em>29</em>(7), 3189-3215. (<a href='https://doi.org/10.1007/s00500-025-10609-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Restaurant selection by a consumer is a challenging task. The main problem is the proper optimization of ratings by food bloggers and the cost of food in the restaurant. In this paper, we propose an approach for a restaurant recommendation system that uses food blogger ratings and the cost of food items in the restaurant. The aim is to maximize the restaurant rating with minimization of overall cost. For this, we construct a multi-objective optimization problem to get restaurant recommendations that are appropriate for the customer's budget and desired rating. Three evolutionary optimization algorithms, namely Nondominated Sorting Genetic Algorithm II (NSGA II), Strength Pareto Evolutionary Algorithm 2 (SPEA 2), and Indicator-Based Evolution Algorithm (IBEA) have been used to identify approximated Pareto solutions for our proposed model. The effectiveness of the three evolutionary algorithms under consideration is given and evaluated against several performance indicators. Using Zomato restaurant data, we compare the results in terms of convergence and diversity, which confirms our suggestion for standardization. The suggested work contributes to an analytical approach based on evolutionary algorithm solutions to create a multi-objective restaurant recommendation system, which goes beyond the scope of previous works. We also present a comparative result analysis with the existing Zomato rating and proposed approach using statistical tools.},
  archive      = {J_SOCO},
  author       = {Tunga, Harinandan and Pal, Surjendu and Kar, Samarjit and Giri, Debasis and Bausys, Romualdas},
  doi          = {10.1007/s00500-025-10609-9},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3189-3215},
  shortjournal = {Soft Comput.},
  title        = {The influence of food bloggers toward consumer’s attitude in restaurant selection: A multi-objective metaheuristic approach},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A scalable method for extracting features using a complex network from SNP sequences and clustering using the scalable max of min algorithm. <em>SOCO</em>, <em>29</em>(7), 3165-3188. (<a href='https://doi.org/10.1007/s00500-025-10622-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature extraction is pivotal in bioinformatics as it converts variable-length genome sequences into fixed-length mathematical feature vectors, which serve as input for clustering algorithms to cluster similar sequences. One of the types of genome sequences is the Single Nucleotide Polymorphism (SNP), which categorises individuals into risk categories for plant diseases and predicts treatment outcomes more reliably. Extracting features from SNP sequences poses many challenges, including extracting similar features for distinct sequences and lacking context-based features. These approaches also take enormous time to compute features for a huge amount of SNP sequences. Therefore, a scalable approach to extract features is proposed based on a complex network, which converts the genome sequence into a complex network and extracts the proposed relevant features. The time utilised to extract those features has reduced drastically. The efficacy of the proposed scalable feature extraction approach is evaluated by applying K-means and Fuzzy c-means algorithms to assess the performance of this proposed feature vector set and found promising results when compared with the other alignment-free state-of-the-art approaches for feature extraction in terms of the Silhouette index and the Calinski–Harabasz index. Additionally, as most SNP datasets are unlabeled, determining the optimal number of clusters presents another significant challenge. A scalable algorithm called the S-MaxMin algorithm is proposed based on the distance metric to find the optimal number of clusters. The proposed S-MaxMin algorithm is being tested on different datasets, including eight labelled benchmark datasets, giving the same number of clusters as the actual number of classes. Also, the S-MaxMin algorithm is tested on four unlabeled SNP datasets, which yielded approximately the same number of clusters as the clusters with a high Silhouette index score. The two proposed scalable approaches are integrated into a framework consisting of two modules. The first module is dedicated to feature extraction for SNP sequences, while the second module focuses on determining the optimal number of clusters.},
  archive      = {J_SOCO},
  author       = {Kansal, Achint Kumar and Tiwari, Aruna and Ratnaparkhe, Milind and Dwivedi, Rajesh and Jha, Preeti},
  doi          = {10.1007/s00500-025-10622-y},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3165-3188},
  shortjournal = {Soft Comput.},
  title        = {A scalable method for extracting features using a complex network from SNP sequences and clustering using the scalable max of min algorithm},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical treatment of blood nanofluid flow in micro-vessels considering inclined magnetic field, hall and radiation effects. <em>SOCO</em>, <em>29</em>(7), 3151-3164. (<a href='https://doi.org/10.1007/s00500-025-10592-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article primarily intended to investigate the peristalsis of an incompressible couple-stress nanofluid through a symmetric channel. The most important effects that are considered to model the fundamental equations include inclined magnetic field, Hall current, mixed convection, viscous dissipation, radiation effect etc. In this paper, the well-known Buongiorno model is adopted to thoroughly examine the thermophoresis and Brownian motion effects. To simplify the mathematical analysis, we assume extremely small Reynolds number and a long wavelength, thereby reducing the complexity of the system. The resulting mathematical system is handled via built-in numerical technique in Mathematica software. Plots provide a graphical representation of fluid flow characteristics, allowing researchers to examine the effects of various parameters and visualize relationships between variables. The Hall current, generated by blood flow through arteries under an inclined magnetic field, has significant implications for cardiovascular research. By adjusting the magnetic field angle, scientists can regulate blood flow, potentially benefiting conditions like hypertension and vascular stenosis. Moreover, the buoyancy force effects are added to determine the flow pattern in free convection. It is resulted that an increase in thermal buoyancy enhances the blood flow rate. Both $$Nb$$ and $$Nt$$ cause a rise in the fluid's temperature. It is apparent that as the inclination angle is increased, the trapped bolus gradually enlarges. Similar behavior of Hall parameter is observed.},
  archive      = {J_SOCO},
  author       = {Yasin, M. and Hina, S. and Naz, R.},
  doi          = {10.1007/s00500-025-10592-1},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3151-3164},
  shortjournal = {Soft Comput.},
  title        = {Numerical treatment of blood nanofluid flow in micro-vessels considering inclined magnetic field, hall and radiation effects},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Concept lattices of $$\mathbb {C}_{i}$$ -connected contexts and the characterization theorem. <em>SOCO</em>, <em>29</em>(7), 3139-3149. (<a href='https://doi.org/10.1007/s00500-025-10596-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the potential application of formal concept analysis in supporting learning, we attempt to take advantage of the relations between objects to assist in the problem recommendation. This paper is to provide a preliminary preparation for the establishment of a mathematical model and to focus on the theoretical aspects. To achieve this, first, we propose $$\mathbb {C}_{i}$$ -connected relations between objects and introduce the concepts of $$\mathbb {C}_{i}$$ -connected context. Next, we investigate the closedness of $$\mathbb {C}_{i}$$ -connectedness regarding some mapping images, subcontexts and products. Finally, we explore the relationship between some special complete lattices and $$\mathbb {C}_{i}$$ -connected contexts. It is proved that the concept lattices generated by $$\mathbb {C}_{i}$$ -connected contexts can be represented by some atomistic complete lattices.},
  archive      = {J_SOCO},
  author       = {Jia, Zhenhua and Guo, Lankun and Cai, Mingjie and Li, Qingguo},
  doi          = {10.1007/s00500-025-10596-x},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3139-3149},
  shortjournal = {Soft Comput.},
  title        = {Concept lattices of $$\mathbb {C}_{i}$$ -connected contexts and the characterization theorem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quasi-L-algebras. <em>SOCO</em>, <em>29</em>(7), 3125-3137. (<a href='https://doi.org/10.1007/s00500-025-10567-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a generalization of L-algebras motivated by investigations into the structure of quantum logic, termed quasi-L-algebras. After establishing the foundational structure theory for such quasi-L-algebras, we delve into the class of quasi-L-algebras, denoted as $$\mathcal{Q}\mathcal{L}$$ , which forms a quasivariety. Utilizing the fact that every quasi-L-algebra can be embedded into the direct product of an L-algebra and a flat quasi-L-algebra, we determine a generator for $$\mathcal{Q}\mathcal{L}$$ . Lastly, we explore congruence relations on a quasi-L-algebra L and their connections with ideals and weak ideals of L, as well as the ideals of the L-algebra R(L). We also propose a representation for congruence relations on each quasi-L-algebras.},
  archive      = {J_SOCO},
  author       = {Zahiri, Omid and Xin, Xiao Long},
  doi          = {10.1007/s00500-025-10567-2},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3125-3137},
  shortjournal = {Soft Comput.},
  title        = {Quasi-L-algebras},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Operators on complemented lattices. <em>SOCO</em>, <em>29</em>(7), 3115-3123. (<a href='https://doi.org/10.1007/s00500-025-10626-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present paper deals with complemented lattices where, however, a unary operation of complementation is not explicitly assumed. This means that an element can have several complements. The mapping $$^+$$ assigning to each element a the set $$a^+$$ of all its complements is investigated as an operator on the given lattice. We can extend the definition of $$a^+$$ in a natural way from elements to arbitrary subsets. In particular we study the set $$a^+$$ for complemented modular lattices, and we characterize when the set $$a^{++}$$ is a singleton. By means of the operator $$^+$$ we introduce two other operators $$\rightarrow $$ and $$\odot $$ which can be considered as implication and conjunction in a certain propositional calculus, respectively. These two logical connectives are “unsharp” which means that they assign to each pair of elements a non-empty subset. However, also these two derived operators share a lot of properties with the corresponding logical connectives in intuitionistic logic or in the logic of quantum mechanics. In particular, they form an adjoint pair. Finally, we define so-called deductive systems and we show their relationship to the mentioned operators as well as to lattice filters.},
  archive      = {J_SOCO},
  author       = {Chajda, Ivan and Länger, Helmut},
  doi          = {10.1007/s00500-025-10626-8},
  journal      = {Soft Computing},
  month        = {4},
  number       = {7},
  pages        = {3115-3123},
  shortjournal = {Soft Comput.},
  title        = {Operators on complemented lattices},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable grouped deep echo state network for EEG-based emotion recognition. <em>SOCO</em>, <em>29</em>(6), 3097-3114. (<a href='https://doi.org/10.1007/s00500-025-10653-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in deep learning have enabled highly accurate classification and prediction across domains. However, these “black box” models offer limited insight into their decision-making processes. Existing deep models for EEG-based emotion recognition achieve high performance but lack interpretability. This hampers model understanding, trustworthiness and identification of neurophysiological patterns related to emotions. We developed an explainable Grouped Deep Echo State Network (GDESN) for classifying emotions from EEG data. The GDESN leverages the representation power of deep learning while maintaining efficiency. Local and global interpretation techniques were applied to provide model explanations. Local Interpretable Model-Agnostic Explanations (LIME) provided local explanations around predictions by learning an interpretable linear model approximating the GDESN. Eli5 generated global explanations through feature importance weights, uncovering behavior drivers. On the DEAP dataset, the GDESN achieved state-of-the-art arousal accuracy of 89.32% and valence accuracy of 91.21%. Model interpretation identified gamma and theta frequency bands, and electrodes FP1, T8 and Oz as key contributions to emotion recognition. The explainable GDESN demonstrates potential for transparent analysis of emotions from neuroimaging and provides insights into underlying neurophysiological patterns. Overall, the study addresses limitations of non-interpretable “black box” models for this task.},
  archive      = {J_SOCO},
  author       = {Bouazizi, Samar and Ltifi, Hela},
  doi          = {10.1007/s00500-025-10653-5},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {3097-3114},
  shortjournal = {Soft Comput.},
  title        = {Explainable grouped deep echo state network for EEG-based emotion recognition},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling and simulating a startup ecosystem development with a delayed differential equation. <em>SOCO</em>, <em>29</em>(6), 3083-3095. (<a href='https://doi.org/10.1007/s00500-025-10565-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our work, we model the dynamics of a startup ecosystem through a delayed differential equation that considers the system growth’s driving factors. The work presents a theoretical and numerical analysis to study the equilibrium and the stability of the described time delay model. The former ensures the model’s desirable characteristic and the equilibrium solution’s local stability. The latter serves the purpose of studying global stability by varying the equation parameters. This study can devise helpful insights for policymakers, who take action to foster business incentives in their area of operation, and entrepreneurs, who can observe a quantitative assessment of an information spillover in a given startup ecosystem.},
  archive      = {J_SOCO},
  author       = {Brini, Alessio and Fanelli, Viviana},
  doi          = {10.1007/s00500-025-10565-4},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {3083-3095},
  shortjournal = {Soft Comput.},
  title        = {Modeling and simulating a startup ecosystem development with a delayed differential equation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review for finding determinants of some band matrices. <em>SOCO</em>, <em>29</em>(6), 3073-3082. (<a href='https://doi.org/10.1007/s00500-025-10557-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a relationship between the Chebyshev polynomial and the matrix-less method. In this way, it explains the roots of the Chebyshev polynomial and their role in the theory of matrix polynomials. With the help of these techniques, we can evaluate the determinant of some band matrices and pay special attention to the polynomial eigenvalue problem for matrix polynomials expressed in the nonmonomial bases. Numerical results are presented and compared with corresponding theoretical data.},
  archive      = {J_SOCO},
  author       = {Shams Solary, Maryam},
  doi          = {10.1007/s00500-025-10557-4},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {3073-3082},
  shortjournal = {Soft Comput.},
  title        = {A review for finding determinants of some band matrices},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Why does economics need complexity?. <em>SOCO</em>, <em>29</em>(6), 3063-3072. (<a href='https://doi.org/10.1007/s00500-025-10548-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of complexity is gaining popularity in economics, arising from the growing awareness that traditional economics models have several limitations rooted in fixed laws and axioms. Complexity theory offers a promising alternative: it defines the economy as a complex adaptative system, characterized by the interactions of multiple agents who adapt their behavior and learn from past experiences. These interactions give rise to emergent phenomena that cannot be predicted in any way from individual behaviors, highlighting the importance of studying and understanding the system as a whole. In contrast to equilibrium economics, which assumes static states of equilibrium, complexity economics embraces non-equilibrium dynamics as fundamental to economic processes. This perspective represents both an extension and a new departure point from traditional theories, suggesting that complexity is not a refinement, but a paradigm shift in economic thinking.},
  archive      = {J_SOCO},
  author       = {Gallegati, Mauro and Gallegati, Silvia},
  doi          = {10.1007/s00500-025-10548-5},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {3063-3072},
  shortjournal = {Soft Comput.},
  title        = {Why does economics need complexity?},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sustainability, innovation and knowledge: A complex relationship based on an empirical study. <em>SOCO</em>, <em>29</em>(6), 3047-3062. (<a href='https://doi.org/10.1007/s00500-025-10574-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines the impact of sustainability innovation on innovation performance and the mediating effects of knowledge sharing and knowledge application on this relationship. We hypothesize that small and medium-sized enterprises implementing sustainability innovation are able to achieve better innovation outcomes. We tested the hypotheses using structural equation modeling and Smart PLS on a data set of 185 industrial companies. The results support our conceptualization and demonstrate its utility in explaining improvements in achieving innovation performance if sustainability innovation is adopted. Simultaneously, we demonstrate that knowledge sharing and knowledge application mediate the effects of sustainability innovation on innovation performance. Findings have important implications regarding sustainability innovation implementation in industrial companies and its impact on improving innovation outcomes, both direct and mediated by knowledge sharing and knowledge application.},
  archive      = {J_SOCO},
  author       = {Ceptureanu, Sebastian-Ion and Ceptureanu, Eduard-Gabriel and Georgescu, Bogdan and Iancu, Adriana Lavinia},
  doi          = {10.1007/s00500-025-10574-3},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {3047-3062},
  shortjournal = {Soft Comput.},
  title        = {Sustainability, innovation and knowledge: A complex relationship based on an empirical study},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting of exchange rate time series based on event-aware transformer mode. <em>SOCO</em>, <em>29</em>(6), 3035-3045. (<a href='https://doi.org/10.1007/s00500-025-10558-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately forecasting exchange rate time series is crucial for effective risk management. The longer the forecast time window and the higher the frequency, the more valuable it is for managers to make timely decisions. In light of the task characteristics of exchange rate forecasting, this paper proposes an improved transformer-based model for addressing long sequence time series forecasting problems. Specifically, we introduce a position embedding method for events, which integrates the traditional coding context vector to perform joint location representation learning. Additionally, we explore a periodic enhancement method of features to jointly enhance the transformer-like model architecture’s ability to adaptively learn the long-term and hidden correlations of long sequence time series data. Extensive experimental results on the prediction of four exchange rate data for pairs of opening, high, low, and closing prices at a frequency of 5 min show that our model outperforms the prediction of the baseline method.},
  archive      = {J_SOCO},
  author       = {Zhang, Siyi and Che, Tong and Zhu, Zhiliang and Luo, Guoli and Feng, Ping},
  doi          = {10.1007/s00500-025-10558-3},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {3035-3045},
  shortjournal = {Soft Comput.},
  title        = {Forecasting of exchange rate time series based on event-aware transformer mode},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expansive detector via hybrid temporal and transposed convolutional mechanism for weld proximity defects. <em>SOCO</em>, <em>29</em>(6), 3021-3034. (<a href='https://doi.org/10.1007/s00500-025-10562-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection of weld proximity defects aims to recognize and classify different proximity defects in industrial welding. It presents some characteristics such as the small-target, localized diffusion, and dense distribution, which is difficult in steel-sheet welding engineering. Due to small-target size, localized diffusion, the similar and dense distribution, and imbalanced sample numbers, the existing detection models with the fixed receptive field are weak in detecting weld proximity defects. To solve the problem, we propose an expansive you-only-look-once detection model, called DRB-YOLOv5. It integrates a novel dilation causal convolution cross-stage partial network and the improved Focal Loss function. First, we provide a dilation causal transposed-convolution residual block cross-stage partial network to amplify and extract features of weld proximity defects effectively. Further, we reduce the block number of two middle Resblock Bodies in the Backbone of DRB-YOLOv5 to avoid network overfitting. Second, we design a Prediction Head via the Bias Focal Loss to balance positive and negative samples and improve the detection accuracy of various number-imbalanced weld defects. Finally, we compare the proposed model with some related existing models via the real weld proximity defects dataset. Experimental results show that the proposed DRB-YOLOv5 can present superior effects, mainly including mAP: 89.21%, F1: 83.50%, and recall: 80.73%.},
  archive      = {J_SOCO},
  author       = {Chen, Zihua and Zhang, Runmei and Chen, Zhong and Yuan, Bin and Zheng, Yu and Li, Kuan-ching},
  doi          = {10.1007/s00500-025-10562-7},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {3021-3034},
  shortjournal = {Soft Comput.},
  title        = {Expansive detector via hybrid temporal and transposed convolutional mechanism for weld proximity defects},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling of metaheuristic-based dual cluster head selection with routing protocol for energy-efficient wireless sensor networks. <em>SOCO</em>, <em>29</em>(6), 2999-3020. (<a href='https://doi.org/10.1007/s00500-025-10563-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Sensor Networks (WSN) are decentralized networks of spatially distributed sensors that gather and monitor environmental information for various applications, including industrial automation and environmental monitoring. This enables real-time information gathering without relying upon wired connections. In WSN, clustering and routing are essential techniques for improving data transmission. Clustering comprises grouping sensor nodes (SN) into clusters to optimize energy efficacy and extend the network's lifetime. However, selecting suitable and efficient cluster head (CH) components is crucial to harness their benefits. Selecting appropriate CHs and finding optimum coefficients for all the parameters of applicable fitness function (FF) in CH selection is a non-deterministic polynomial-time (NP-hard) problem that needs additional processing. In contrast, routing focuses on defining the most effective path for data to traverse through the network, ensuring timely and reliable data delivery and reducing energy consumption. Therefore, this study proposes a new Metaheuristic-Based Dual Cluster Head Selection with Routing Protocol (MBDCHS-RP) method for energy-efficient WSNs. The MBDCHS-RP method aims to cluster the nodes and select optimum routes for transmitting information in the WSN. To achieve this, the MBDCHS-RP method follows a two-stage clustering process, including tentative CH (TCH) and final CH (FCH) selection. The MBDCHS-RP technique utilizes a cheetah optimization algorithm (COA) with FF comprising residual energy (RE) and average node distance as input parameters for the TCH selection process. In addition, the flower pollination algorithm (FPA) is used to select final CHs with multiple input parameters, namely average intra-cluster distance, RE, and average sink distance. A carnivorous plant algorithm (CPA) is employed for the optimal route selection process with two parameters, RE and distance to the base station, to enable an effective data transmission process. The simulation of the MBDCHS-RP technique is examined using distinct measures. The experimental validation of the MBDCHS-RP technique portrayed superior RNE and NLT values, with an LND of 1270 rounds and an optimum RNE of 24.48 at round 1000.},
  archive      = {J_SOCO},
  author       = {Reddy, Maddikera Krishna and Veluswamy, Anusha Sowbarnika and Selvanayaki, S. and Harini, C. and Kumar, Pavan and Shameem, Syed},
  doi          = {10.1007/s00500-025-10563-6},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2999-3020},
  shortjournal = {Soft Comput.},
  title        = {Modeling of metaheuristic-based dual cluster head selection with routing protocol for energy-efficient wireless sensor networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A synchronous spatiotemporal graph neural network for short-term traffic flow prediction. <em>SOCO</em>, <em>29</em>(6), 2983-2997. (<a href='https://doi.org/10.1007/s00500-025-10555-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is a vital part of an intelligent traffic management system. The critical challenge of the traffic flow prediction task is to fully use observable historical information to extract the hidden spatiotemporal dependence. For this reason, a synchronous spatiotemporal grammar graph attention network is proposed based on multi-dimensional edge information (MDEI-SSTGGAT) to achieve short-term traffic flow prediction tasks. In the designed model, the spatial nodes are first clustered. Then, a local spatiotemporal graph is established for each category for extracting synchronous spatiotemporal features. In the feature extraction module, the graph attention network with multi-dimensional edge information captures the spatiotemporal features dynamically, and the grammar graph structure fuses the hidden features of three observable traffic parameters. The model fully uses observable traffic parameter features to improve the prediction accuracy while keeping the computation time short. Simulation results on real data sets show that the prediction performance of this model is better than the existing prediction methods.},
  archive      = {J_SOCO},
  author       = {Zhang, Zhao and Jiao, Xiaohong},
  doi          = {10.1007/s00500-025-10555-6},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2983-2997},
  shortjournal = {Soft Comput.},
  title        = {A synchronous spatiotemporal graph neural network for short-term traffic flow prediction},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Construction and empirical research of a subjective-and-objective-analysis model of the online learning behavior. <em>SOCO</em>, <em>29</em>(6), 2971-2982. (<a href='https://doi.org/10.1007/s00500-025-10546-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online courses have a large number of learners with large individual differences, which makes it difficult for teachers to accurately analyse their learning, and there are problems such as low course completion rate and low learning outcomes. This paper proposes a subjective and objective two-class analysis method to analyse learners' learning behaviour. The method divides online learning behaviour data into objective factual data and subjective value data. The method first assesses the objective factual data to determine whether the objective facts are learning behaviours, and then evaluates the learners' subjective data to understand their motivations and attitudes, and assesses the learners' subjective value in performing the behaviours. Through empirical analysis, the results show that the method can effectively analyse students' online learning behaviour data and provide a comprehensive and in-depth understanding of students' learning behaviours and needs, thus providing strong support for personalised teaching and learning advice.},
  archive      = {J_SOCO},
  author       = {Wang, Ke and Zheng, Kun and Wang, Ying},
  doi          = {10.1007/s00500-025-10546-7},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2971-2982},
  shortjournal = {Soft Comput.},
  title        = {Construction and empirical research of a subjective-and-objective-analysis model of the online learning behavior},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wind farm layout optimization based on harris hawk optimization algorithm with variable weight coefficients and jansen wake model. <em>SOCO</em>, <em>29</em>(6), 2931-2969. (<a href='https://doi.org/10.1007/s00500-025-10586-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind energy, a pollution-free and renewable new energy, has been widely promoted in recent years and has great development potential. An important stage of wind power generation is to solve the problem of wind farm layout optimization (WFLO), that is, to obtain the optimal location of wind turbines so as to obtain the maximum power output with the minimum energy consumption. Based on the Jansen wake model, a WFLO strategy based on the Harris Hawk Optimization Algorithm with Variable Weight Coefficients (ABHHO) was proposed based on the Jansen’s wake model. Two weight coefficients (Beta and Alpha) are used to improve the HHO algorithm. Beta can reduce the search step size, make the global search faster and more detailed, and improve the search efficiency. The vibration pattern of Alpha interferes with the escape energy of the prey, thus moving away from the local optimal. The combination of these two strategies improves the search performance and convergence speed of HHO algorithm. Then seven algorithms (HHO, WOA, BA, AOA, BOA, SCA and RSA) are selected to perform performance optimization simulation with ABHHO on CEC2017 test functions. The experimental results show that ABHHO performs better than other algorithms. Finally, ABHHO was used to optimize the layout of wind power plants, and the performance of Case 1–Case 4 was tested under two initial wind speeds, including the influence of single wake and multi-wake at the same time, shielding part of the wake area, and not shielding the wake area on the production cost and output energy. For the solutions of Case 1–Case 4, 9 algorithms such as HHO, WOA, SCA, PSO, GOA, DE, CSA, ACOR and TLBO, are selected for comparison with ABHHO. Simulation results show that ABHHO can obtain better results in most test schemes and achieve better wind farm layout than other algorithms under the same experimental conditions, as well as obtain higher output power and lower value cost.},
  archive      = {J_SOCO},
  author       = {Wang, Min and Wang, Jie-Sheng and Zhang, Min and Zheng, Yue and Xing, Yu-Xuan and Song, Hao-Ming and Zhu, Jun-Hua and Wang, Yu-Cai},
  doi          = {10.1007/s00500-025-10586-z},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2931-2969},
  shortjournal = {Soft Comput.},
  title        = {Wind farm layout optimization based on harris hawk optimization algorithm with variable weight coefficients and jansen wake model},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary optimization in VANET services: A comprehensive survey, challenges and futuristic approach. <em>SOCO</em>, <em>29</em>(6), 2905-2929. (<a href='https://doi.org/10.1007/s00500-025-10571-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent vehicles promise the future of developing technology. Vehicular Ad-hoc Network (VANET) allows vehicles to communicate with one another and with the Roadside Units (RSU). VANET typically operates in various situations, such as Dynamic topology, high mobility, and a wide range of communication networks. Specific issues like scalability, packet loss, routing, data dissemination and sharing, energy loss, and security occur during VANET communication. Achieving a high data rate and low latency during transmission is complex. To improve the Quality of Service (QoS) in VANET, the mechanism to identify optimal data rate and optimal latency during the transmission of packets is the utmost importance. This article surveys nature-inspired and evolutionary algorithms that optimize different parameters to improve the VANET services. Evolutionary optimization techniques are proven to be best for finding optimal and near-optimal solutions by formulating single-objective and multi-objective functions based on Mean Routing Load, Packet Delivery Ratio, Throughput, End-to-End Delay, Control Packet Overhead. They allow for investigating an ample solution space, facilitating the identification of effective and flexible VANET communication solutions. The research gap and challenges in the existing scenario are well addressed. Further, some innovative ideas for future research are discussed.},
  archive      = {J_SOCO},
  author       = {Badole, Madhuri and Thakare, Anuradha and Oliva, Diego},
  doi          = {10.1007/s00500-025-10571-6},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2905-2929},
  shortjournal = {Soft Comput.},
  title        = {Evolutionary optimization in VANET services: A comprehensive survey, challenges and futuristic approach},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Innovative image encryption approach based on bitwise XOR high nonlinear S-boxes and random permutation. <em>SOCO</em>, <em>29</em>(6), 2891-2903. (<a href='https://doi.org/10.1007/s00500-025-10547-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With today's developing technologies, the need for new image encryption algorithms to encrypt images is inevitable. In this study, an innovative image encryption algorithm is proposed. The proposed algorithm first XORs each layer of the image with a unique and strong new key. Each layer is then subjected to a random permutation process. Each of the encrypted layers obtained here is finally passed through a new s-box structure with a high nonlinearity value. After these processes, all layers are combined to obtain an encrypted image. Thus, XOR and s-box confusion meet the criteria, while random permutation meets the diffusion criteria. In this study, both key and s-box structures were originally obtained with a chaotic Gaussian map. The outputs of the chaotic map were converted into bit sequences and five different sequences with a length of 1 million were obtained. All these arrays have successfully passed all NIST SP 800-22 tests. On the other hand, the proposed s-box structures surpassed many studies with nonlinearity values of 108, 108.5, and 108.75. The images were successfully encrypted with the proposed algorithm, and the encrypted images successfully completed tests such as NPCR-UACI, information entropy, histogram analysis, and correlation analysis. It is thought that this study will make many contributions to the fields of s-box development, random number generation, and image encryption.},
  archive      = {J_SOCO},
  author       = {Artuğer, Fırat},
  doi          = {10.1007/s00500-025-10547-6},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2891-2903},
  shortjournal = {Soft Comput.},
  title        = {Innovative image encryption approach based on bitwise XOR high nonlinear S-boxes and random permutation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On pure ideals in semilattices. <em>SOCO</em>, <em>29</em>(6), 2885-2889. (<a href='https://doi.org/10.1007/s00500-025-10598-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, $$\mathcal {P}(L)$$ denotes the set of prime ideals, Min(L) denotes the set of minimal prime ideals and Max(L) denotes the set of maximal ideals of a meet semilattice L. The set $$\mathcal {P}(L)$$ can be endowed with the well-known topology called spectral topology. $$\mathcal {P}(L)$$ can also be endowed with another subtopology of the spectral topology called D-topology. In this paper, we prove that if a meet semilattice $$L \in \mathbb {P}_{MIP} \cap \mathbb {P}_{MFP}$$ then the spectral topology and D-topology coincide on $$\mathcal {P}(L)$$ , Min(L) and Max(L) if and only if L is a complemented, Stone and pm-meet semilattice, that is every prime ideal is contained in a unique maximal ideal respectively.},
  archive      = {J_SOCO},
  author       = {Mundlik, Nilesh and Kshirsagar, Mayur},
  doi          = {10.1007/s00500-025-10598-9},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2885-2889},
  shortjournal = {Soft Comput.},
  title        = {On pure ideals in semilattices},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An arithmetic–geometric mean difference based approach to consistency index and priority vector of pairwise comparison matrices. <em>SOCO</em>, <em>29</em>(6), 2867-2884. (<a href='https://doi.org/10.1007/s00500-025-10570-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consistency measure and prioritization elicitation are two important issues for pairwise comparison matrices (PCMs) originating from the analytic hierarchy process (AHP). In this study, a novel consistency index is reported using the difference between arithmetic mean and geometric mean, which is called the arithmetic–geometric mean difference consistency index (AGMD-CI). Some interesting properties of AGMD-CI are investigated and the thresholds of acceptable consistency are determined using the simulation method. Then, a consistency improving method is proposed by constructing an optimization model, which is solved using particle swarm optimization (PSO) algorithm. In addition, based on the idea of minimizing the arithmetic–geometric mean difference, an optimization based method is developed to obtain the priority vector from PCMs. The analytical solution of the proposed model is further derived. It is found that the proposed prioritization method is equivalent to the logarithmic least squares method. Finally, a novel decision algorithm is proposed and the case study is carried out to illustrate the proposed methods.},
  archive      = {J_SOCO},
  author       = {Hu, Yuan-Kai and Liu, Fang and Wang, Shi-Shan},
  doi          = {10.1007/s00500-025-10570-7},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2867-2884},
  shortjournal = {Soft Comput.},
  title        = {An arithmetic–geometric mean difference based approach to consistency index and priority vector of pairwise comparison matrices},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel stochastic machine learning approach for resilient-leagile supplier selection: A circular supply chain in the era of industry 4.0. <em>SOCO</em>, <em>29</em>(6), 2845-2866. (<a href='https://doi.org/10.1007/s00500-025-10578-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to significant changes in supply chain environments and the importance of environmental and economic issues, various supply chain paradigms have been developed to address different challenges. As supplier evaluation and selection is one of the critical issues in supply chain management, in this paper a data-driven model is developed for this purpose. Considering the significance of different components in the case study of the home appliance industry, the leagile, resilience, circular economy, and Industry 4.0 paradigms are simultaneously considered for the first time in supplier evaluation. The key evaluation indicators in this study are recycled product, financial ability, waste management and delivery speed. The methodology used in this paper involves the use of data-driven stochastic model. In this regard, a stochastic VIKOR method has been developed based on scenarios, which improves evaluation effectiveness by considering different scenarios. Additionally, a neural network algorithm with a learning rate optimized using a genetic algorithm has been used to evaluate supplier performance. The findings demonstrate that the developed algorithm surpasses other algorithms, achieving an accuracy rate of 98 percent, and is effective for predicting supplier performance.},
  archive      = {J_SOCO},
  author       = {Molaei, Bahar Javan and Ghanavati-Nejad, Mohssen and Tajally, Amirreza and Sheikhalishahi, Mohammad},
  doi          = {10.1007/s00500-025-10578-z},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2845-2866},
  shortjournal = {Soft Comput.},
  title        = {A novel stochastic machine learning approach for resilient-leagile supplier selection: A circular supply chain in the era of industry 4.0},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new metaheuristic optimization algorithm based on the participation of smart students to increase the class performance. <em>SOCO</em>, <em>29</em>(6), 2829-2844. (<a href='https://doi.org/10.1007/s00500-025-10554-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The learning and teaching power of the students in different courses can be different according to their intelligence and talent. One student can be smart in a single course while he/she is lazy in other courses. After teaching all courses by the class teacher, the lazy students in each course are taught again by the smart student in the course. Inspired by this fact, we present a new metaheuristic optimization algorithm called Participation of Smart Students (PSS) in increasing the class efficiency. The effectiveness of the PSS algorithm has been analyzed by 10 general test functions, 9 test functions from CEC 2019, and 12 test functions from CEC 2022. The results of PSS algorithm are compared with the effectiveness of eight recently developed well-known algorithms, i.e., Teaching and Learning-based Optimization (TLBO) Algorithm, Black Widow Optimization (BWO), Political Optimization (PO), Barnacle Mating Optimizer (BMO),Chimpanzee Optimization Algorithm (CHOA), Aquila Optimizer (AO), Reptile Search Algorithm (RSA), Prairie Dog Optimization (PDO), and Fick’s Law Optimization (FLA). Comparison of the results obtained by the Friedman rank and Wilcoxon signed-rank tests, for all 31 test functions, shows that PSS outperforms TLBO, BMO, BWO, CHOA, AO, RSA, PDO, and FLA algorithms by 38%, 38%, 64%, 74%, 45%, 64%, 58%, and 35%, respectively. Moreover, the PSS algorithm has a higher convergence speed and hit rate (= 35%) than all other compared algorithms. Finally, the reported results of solving two practical optimization problems by the PSS algorithm confirm its higher effectiveness compared to some good algorithms in the literature.},
  archive      = {J_SOCO},
  author       = {Pira, Einollah and Rouhi, Alireza},
  doi          = {10.1007/s00500-025-10554-7},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2829-2844},
  shortjournal = {Soft Comput.},
  title        = {A new metaheuristic optimization algorithm based on the participation of smart students to increase the class performance},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new model for facility bus terminal location problem based on modified kerre’s inequality. <em>SOCO</em>, <em>29</em>(6), 2819-2828. (<a href='https://doi.org/10.1007/s00500-025-10584-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Babaie-Kafaki et al. (AsiaPacific J Operat Res 29:1–25, 2012, Appl Soft Comput 46:220–229, 2016) have suggested a model for the fuzzy bus terminal location problem. Here, we propose a new optimization model by improving Babaie-Kafaki et al.’s model. In our model, we define new structures of neighborhoods. Also, we assume that the number of passengers corresponds to the fuzzy nodes. Using modified Kerre’s inequality, we propose a new variable neighborhood search algorithm for solving a fuzzy bus terminal location problem. In our algorithm, we consider new types of neighborhoods to have a more realistic fuzzy model. The algorithm is tested on a variety of random generated large-scale fuzzy bus terminal location problems with fuzzy coefficients. In contrast of most existing method our proposed algorithm is solved fuzzy bus terminal location problem directly. The parameters of our proposed algorithm are set by irace package to ensure fair space. To demonstrate the performance of our method, we make a comparison between our method and other existing algorithms. We make use of the non-parametric statistical test due to Wilcoxon’s test and the Dolan–Moré performance profiles to assess the performance of the numerical algorithms.},
  archive      = {J_SOCO},
  author       = {Rahdar, Sahar and Ghanbari, Reza and Ghorbani-Moghadam, Khatere and Sadeghi, Sedigheh and Heidari, Donya},
  doi          = {10.1007/s00500-025-10584-1},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2819-2828},
  shortjournal = {Soft Comput.},
  title        = {A new model for facility bus terminal location problem based on modified kerre’s inequality},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-stage optimization replacement policy with multiple spare units. <em>SOCO</em>, <em>29</em>(6), 2807-2817. (<a href='https://doi.org/10.1007/s00500-025-10603-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a two-stage optimization replacement policy considering reliability and economy for a system with N multiple spare units. We assume that the failure time of each unit is stochastic, and the operating system is replaced at failure or at the planned replacement time intervals $$T_{k}$$ ( $$k=1,2,\ldots ,N$$ ) from its installation, whichever occurs first. In stage 1, we maximizes mean time to failure (MTTF) to obtain the optimal replacement time intervals $$T_{1}^{*},T_{2}^{*},\ldots ,T_{N}^{*}$$ . In stage 2, the aim is to find the optimal number of spare units $$N^{*}$$ which minimizes the expected cost rate, and the existing condition of the unique optimal solution is given. Finally, numerical examples and sensitivity analysis are carried out to demonstrate the presented policy.},
  archive      = {J_SOCO},
  author       = {Zhang, Chunxiao and Shen, Hejiao and Bai, Yizhou and Yan, Chao},
  doi          = {10.1007/s00500-025-10603-1},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2807-2817},
  shortjournal = {Soft Comput.},
  title        = {A two-stage optimization replacement policy with multiple spare units},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differentiation or undifferentiation? analysis of car-sharing strategies for the vehicle manufacturer. <em>SOCO</em>, <em>29</em>(6), 2791-2806. (<a href='https://doi.org/10.1007/s00500-025-10587-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on a market consisting of a vehicle manufacturer, a vehicle retailer, and a group of heterogeneous consumers. Three strategies adopted by the vehicle manufacturer are evaluated, i.e., the traditional sales strategy of exclusively selling new-generation vehicles (Strategy TS), the differentiated car-sharing strategy of selling new-generation vehicles and sharing old-generation vehicles (Strategy SO), and the undifferentiated car-sharing strategy of both selling and sharing new-generation vehicles (Strategy SN). For these strategies, we investigate the optimal pricing decisions of the vehicle manufacturer and the retailer, as well as the timing for a vehicle manufacturer to implement car-sharing services and differentiated car-sharing strategies. We obtain several important findings. The vehicle manufacturer’s wholesale prices remain consistent across all three strategies, and the rental price under Strategy SO is lower than that under Strategy SN. When the marginal production cost of new-generation vehicles is low, the vehicle manufacturer should engage in the car-sharing business, which can increase purchasing demand. In the case of operating car-sharing business, Strategy SO will dominate Strategy SN if the incremental value of new-generation vehicles is low; otherwise, Strategy SN is the optimal one. The analysis shows the manufacturer and the retailer possess differing preferences regarding car-sharing strategies.},
  archive      = {J_SOCO},
  author       = {Yu, Xin and Chen, Zhongwei and Fan, Zhi-Ping},
  doi          = {10.1007/s00500-025-10587-y},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2791-2806},
  shortjournal = {Soft Comput.},
  title        = {Differentiation or undifferentiation? analysis of car-sharing strategies for the vehicle manufacturer},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing energy harvesting in web of things services: A metaheuristic approach with retrial queue under working vacation. <em>SOCO</em>, <em>29</em>(6), 2769-2790. (<a href='https://doi.org/10.1007/s00500-025-10583-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the contemporary context, harnessing energy from the environment poses a ubiquitous and formidable challenge. Optimal energy conservation practices dictate the powering down of inactive devices, even when they consume approximately 60% of their peak power. Subsequently, these devices are reactivated when needed. This study addresses this challenge by conceptualizing the Web of Things (WoT) as an M/M/1 retrial queue operating under a working vacation policy, aiming to curtail average power consumption and foster energy conservation within WoT networks. Furthermore, the study delves into the strategic interactions between WoT devices and their users, facilitating mutually beneficial connections to achieve respective objectives. During idle periods, incoming customers are promptly served, whereas the server enters an energy-saving mode until a new client activates it. The study explores numerical examples to assess the impact of various system factors and formulates a cost function, subsequently minimized using particle swarm optimization, artificial bee colony and genetic algorithm techniques. Convergence analysis of these optimization methods is conducted, supported by visual representations. Finally, neuro-fuzzy results generated through the adaptive neuro-fuzzy inference system are compared against validation outcomes.},
  archive      = {J_SOCO},
  author       = {Mathavavisakan, N. Micheal and Indhira, K. and Ammar, Sherif I.},
  doi          = {10.1007/s00500-025-10583-2},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2769-2790},
  shortjournal = {Soft Comput.},
  title        = {Optimizing energy harvesting in web of things services: A metaheuristic approach with retrial queue under working vacation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neutrosophic multi-choice 4D-transportation problem for different quality items. <em>SOCO</em>, <em>29</em>(6), 2743-2767. (<a href='https://doi.org/10.1007/s00500-025-10581-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a transportation problem, where the transportation costs may vary with multiple options. It also explores four-dimensional transportation problem (4D-TP), which is beneficial because it includes the ideas of choosing the best route and the most appropriate conveyance option. Another new feature of this model is that it includes two different selling prices based on product quality, with premium prices for superior items and lower prices for poor quality items. Moreover, due to lack of necessary information, the problem may include some parameters which are not accurately described. Therefore, many parameters in this model are assumed as single-valued neutrosophic numbers to make it more realistic. The multi-choice 4D-TP is transformed into a single-choice 4D-TP using a ranking function that considers weighted value and weighted ambiguity. A new idea of possibility measures is introduced to solve the 4D-TP model for different quality items under neutrosophic environment. The model is illustrated with numerical data and solved using the generalized reduced gradient method with the help of LINGO-17.0 solver. Sensitivity assessments are performed to evaluate the model’s robustness against varying parameters. The research’s credibility is established by comparing the outcomes with existing methods, demonstrating the effectiveness of the proposed methodology. Additionally, the usefulness of the model is illustrated by analyzing the results of various 4-dimensional, 3-dimensional, and 2-dimensional transportation problems as special cases of the proposed model.},
  archive      = {J_SOCO},
  author       = {Chakraborty, Dipankar and Samanta, Sarbari and Kumar Jana, Dipak},
  doi          = {10.1007/s00500-025-10581-4},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2743-2767},
  shortjournal = {Soft Comput.},
  title        = {Neutrosophic multi-choice 4D-transportation problem for different quality items},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A model-free feature extraction procedure for interval-valued time series prediction. <em>SOCO</em>, <em>29</em>(6), 2727-2741. (<a href='https://doi.org/10.1007/s00500-025-10597-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel feature extraction procedure to predict interval-valued time series by combing transfer learning and imaging approaches. Initially, we represent interval-valued time series as a bivariate point-valued time series, and then transform each time series into images by employing imaging approaches such as recurrence plot, gramian angular summation/difference field, and Markov transition field, thereby obtaining an image dataset containing four classes. Based on this dataset, we train multiple candidate feature extraction networks, specifically ResNet with varying layers. Then we choose the penultimate layer of the feature extraction networks to extract the most relevant features from the images. To formulate prediction, we integrate the extracted features into a traditional prediction model. The proposed method are evaluated on three data-generating processes as well as the S&P 500 index, and the experimental results demonstrate a notable improvement in prediction performance compared to existing methods.},
  archive      = {J_SOCO},
  author       = {Tian, Wan and Qin, Zhongfeng and Hu, Tao},
  doi          = {10.1007/s00500-025-10597-w},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2727-2741},
  shortjournal = {Soft Comput.},
  title        = {A model-free feature extraction procedure for interval-valued time series prediction},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fc-gcn: A formal concept-enhanced graph convolution network model. <em>SOCO</em>, <em>29</em>(6), 2715-2725. (<a href='https://doi.org/10.1007/s00500-025-10569-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolution network (GCN) is a promising deep learning method, mainly used to process graph data, such as social network, knowledge graph, etc. The basic idea of GCN is to use local information to update the node feature vectors, so as to obtain global information and realize graph-level tasks. When dealing with large-scale graphs, the computational and storage overhead of GCN are expensive, which may lead to a decline in generalization performance. Fortunately, formal concept analysis (FCA) as a data mining method based on lattice theory, is mainly used to extract the conceptual relationship between data. By classifying and clustering the data, a complete concept hierarchy can be established to help people better understand the internal relationship between data and provide strong support for subsequent data analysis. To this end, this paper proposes a formal concept-enhanced graph convolution network (FC-GCN), which uses the FCA methodology to preprocess large-scale graphs, extract graph data information and deploy the graph-related services. Technically, the maximal cliques and concept stability are used for feature update to implement downstream tasks such as node classification, link prediction, and community detection thereby overcoming the problems of graph convolution methods on large-scale graphs. The FC-GCN model is trained with Cora dataset, and the performance of model accuracy with different parameters is analyzed using node classification. Compared with baselines on real-world datasets, FC-GCN has better performance on vertice classification, accuracy improvements range from 4.2 to 6.1%.},
  archive      = {J_SOCO},
  author       = {Wu, Kai and Zhang, Chao and Hao, Fei and Li, Jinhai and Wan, Qing and Park, Kyuwon and Qin, Xueyang and Loia, Vincenzo},
  doi          = {10.1007/s00500-025-10569-0},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2715-2725},
  shortjournal = {Soft Comput.},
  title        = {Fc-gcn: A formal concept-enhanced graph convolution network model},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal stress levels and inference procedures for constant stress accelerated life test under bathtub-shaped lifetime model. <em>SOCO</em>, <em>29</em>(6), 2687-2714. (<a href='https://doi.org/10.1007/s00500-025-10590-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the case of operating conditions in a much shorter time, the accelerated life test models are commonly used method since these models let the experimenters control the higher stress levels to be used for components or items in the life tests. Among different accelerated life test methods, constant stress accelerated life test models have a relationship between “failure time” and “stress” and these models are quite popular since they help the experimenters save time and cost. In this study, we evaluate the performances of the parameter estimations of the two-parameter bathtub-shaped lifetime distribution introduced by Chen (Stat Probab Lett 49(2):155–161, 2000) under the constant stress accelerated life test model using the well-known eight different inference methods. Then, we investigate the optimal stress levels using some popular criteria. Then, the performances of the estimations are compared with simulation schemes. Simulation results showed that the maximum likelihood method provides better estimation performances than others. The estimation performances of the other methods can be changed according to the stress level of the accelerated life test model. Further, it is observed that increasing stress levels provide optimal accelerated life test schemes under fixed first stress levels. Finally, we use a real data example to illustrate the theoretical outcomes.},
  archive      = {J_SOCO},
  author       = {Çetinkaya, Çağatay},
  doi          = {10.1007/s00500-025-10590-3},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2687-2714},
  shortjournal = {Soft Comput.},
  title        = {Optimal stress levels and inference procedures for constant stress accelerated life test under bathtub-shaped lifetime model},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A modified slacks-based measure of efficiency and super-efficiency under zero and negative data. <em>SOCO</em>, <em>29</em>(6), 2669-2686. (<a href='https://doi.org/10.1007/s00500-025-10566-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional Data Envelopment Analysis (DEA) model assumes non-negative resources and outputs, but in real-world business scenarios, negative data can often arise. This paper introduces modified slack-based measure (SBM) and super-efficiency SBM (SupSBM) models designed to handle negative data under variable returns to scale. These models are consistent with the standard SBM and SupSBM frameworks. The developed models preserve the nature of the data, allowing for direct evaluation of negative values. They are feasible, unit-invariant, and capable of generating efficient projections. Notably, the simplicity and ease of use of these models are significant advantages. Additionally, the modified SBM and SupSBM models are extended to address nonpositive data, which includes both zero and negative values. A criterion for ranking units is also presented, offering more logical and realistic ratings compared to existing methods. The analysis demonstrates that the modified models not only effectively accommodate negative data but also enhance the robustness of efficiency evaluation in complex scenarios. Four numerical examples are provided, with a complete ranking presented to showcase the performance of the developed models and their comparison with other methods.},
  archive      = {J_SOCO},
  author       = {Zanboori, Ehsan},
  doi          = {10.1007/s00500-025-10566-3},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2669-2686},
  shortjournal = {Soft Comput.},
  title        = {A modified slacks-based measure of efficiency and super-efficiency under zero and negative data},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Applications of integrals and extreme value of solution of uncertain age-dependent population equation with migration source. <em>SOCO</em>, <em>29</em>(6), 2653-2668. (<a href='https://doi.org/10.1007/s00500-025-10560-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertain age-dependent population equation with migration source is a kind of partial differential equation depicting population density changes with time and age, while the strength of migration source is affected by the interference of noise. This paper employs uncertain age-dependent population equation with migration source in some practical problems, including average population density, maximum population density and minimum population density. By using real population data in China as an empirical example, this paper applies the parameter estimation called the method of moments and uncertain hypothesis test to illustrate the fitness of the estimated parameters. In addition, average population density, maximum population density and minimum population density are recast with these actual data of China. As a byproduct, this paper also indicates that stochastic age-dependent population equation with migration source cannot model China’s population density by analyzing the characteristics of the corresponding residuals.},
  archive      = {J_SOCO},
  author       = {Yang, Lu},
  doi          = {10.1007/s00500-025-10560-9},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2653-2668},
  shortjournal = {Soft Comput.},
  title        = {Applications of integrals and extreme value of solution of uncertain age-dependent population equation with migration source},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Choquet integral in ranking data: On the construction of a measure of importance and interaction. <em>SOCO</em>, <em>29</em>(6), 2639-2651. (<a href='https://doi.org/10.1007/s00500-025-10585-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The focus of this paper is on a new method for the prioritization of data based on the Choquet integral. Since this method incorporates integral aggregation operators with a fuzzy measure in their core, the main topic is the construction of an appropriate fuzzy measure. The choice of fuzzy measure represents the significance and interaction of different criteria of the investigated data. An illustration of the proposed model on a small part of the Bilbao crime data set is given.},
  archive      = {J_SOCO},
  author       = {Cornejo, M. Eugenia and Medina, Jesús and Štajner-Papuga, Ivana and Tepavčević, Andreja},
  doi          = {10.1007/s00500-025-10585-0},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2639-2651},
  shortjournal = {Soft Comput.},
  title        = {Choquet integral in ranking data: On the construction of a measure of importance and interaction},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The impact of hydrogen energy storage aqua electrolyzer fuels cell on automatic generation control of power system using optimal FGS PID controller. <em>SOCO</em>, <em>29</em>(6), 2619-2638. (<a href='https://doi.org/10.1007/s00500-025-10552-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our rapidly advancing modern society, automatic generation control (AGC) plays a crucial and essential role in enhancing a country’s standard of living by ensuring a high quality of electrical power. Due to practical restrictions and challenges, researchers worldwide need effective and computationally economical control methods. Therefore, this article presents the implementation of a new fuzzy gain scheduling (FGS) PID controller. The PI controller’s frequency and tie-line power deviation serve as feedback signals. To achieve the most positive outcomes, the input scaling factors (SFs) and output SFs of the FGS-PID controller are simultaneously adjusted using Class topper optimization. To validate the proposed method, we first examine a two-area hydrothermal power plant that may or may not have energy storage units that combine hydrogen aqua electrolyzers (HAEs) with fuel cells (FCs). We investigate hydro, thermal, gas, and wind power plants in the second scenario. When compared to other well-known studies, our proposal’s results show that the CTO-based FGS-PI strategy is the best option because it is simple to implement, yields smaller values for the chosen objective function, and has faster response times with less frequency and tie-line power deviation after a step load disturbance, and multi-step load disturbance.},
  archive      = {J_SOCO},
  author       = {Rai, Ankur and Das, Dushmanta Kumar},
  doi          = {10.1007/s00500-025-10552-9},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2619-2638},
  shortjournal = {Soft Comput.},
  title        = {The impact of hydrogen energy storage aqua electrolyzer fuels cell on automatic generation control of power system using optimal FGS PID controller},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A golden section-based group decision-making approach to software trustworthiness evaluation. <em>SOCO</em>, <em>29</em>(6), 2595-2618. (<a href='https://doi.org/10.1007/s00500-025-10559-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software trustworthiness evaluation is a multi-dimensional evaluation problem, which can be accurately evaluated according to decision science. Group decision-making method is a comprehensive method for handing the multi-dimensional evaluation problems. VlseKriterijumska Optimizacija I Kompromisno Resenje technique has been widely used in decision science. In this work, a novel group decision-making method for software trustworthiness evaluation is provided. An ideal data center is established according to golden section in order to quantify the quality of decision data. A golden section-entropy-based method is introduced in order to determine the weight of decision-maker. A new normalization-projection measure is developed in order to test the closeness between evaluation matrix and reference matrix in software evaluation process. Two specific regret matrices are provided in new VlseKriterijumska Optimizacija I Kompromisno Resenje method. A comprehensive group decision-making method is provided and applied to software trustworthiness evaluation. A new ranking method under a static environment and a new ranking method in a dynamic environment are provided in this work. The feasibility and practicability developed method are illustrated by an experimental analysis. The experimental results confirm that the proposed method produces a stable ranking of alternatives, with over 85% agreement in the dynamic experimental cases.},
  archive      = {J_SOCO},
  author       = {Yue, Chuan},
  doi          = {10.1007/s00500-025-10559-2},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2595-2618},
  shortjournal = {Soft Comput.},
  title        = {A golden section-based group decision-making approach to software trustworthiness evaluation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). $${\textsf{L}}$$ -fuzzy transforms: An operator-oriented approach. <em>SOCO</em>, <em>29</em>(6), 2581-2593. (<a href='https://doi.org/10.1007/s00500-024-09650-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the paper, we analyze spaces with fuzzy sets through the perspective of the theory of operators over these sets. We consider spaces with pretopological, topological, and partition structures, and we show that they are images of Čech and Kuratowski interior operators. In particular, the Kuratowski interior operators can be expressed using an $${\textsf{L}}$$ -fuzzy relation, which is reflexive. We focus particularly on the weakest $${\textsf{L}}$$ -fuzzy partitioned space. Subsequently, we prove that an $${\textsf{L}}$$ -fuzzy lower $${\textsf{F}}^{\downarrow }$$ -transform (resp. upper $${\textsf{F}}^{\uparrow }$$ -transform) is a strong Čech–Alexandroff $${\textsf{L}}$$ -fuzzy interior operator ( $${\textsf{L}}$$ -FIO) (resp. $${\textsf{L}}$$ -fuzzy closure operator ( $${\textsf{L}}$$ -FCO)). Conversely, we discovered circumstances which ensure that every strong Alexandroff $${\textsf{L}}$$ -fuzzy pretopology (resp. co-pretopology) can be generated by an $${\textsf{L}}$$ -valued lower $${\textsf{F}}^{\downarrow }$$ -transform (resp. upper $${\textsf{F}}^{\uparrow }$$ -transform). As a new methodological tool, we use the theory of $${\textsf{L}}$$ -fuzzy relation equations ( $${\textsf{L}}$$ -FREs) and especially conditions for their solvability.},
  archive      = {J_SOCO},
  author       = {Singh, A. P. and Tiwari, S. P. and Perfilieva, I.},
  doi          = {10.1007/s00500-024-09650-x},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2581-2593},
  shortjournal = {Soft Comput.},
  title        = {$${\textsf{L}}$$ -fuzzy transforms: An operator-oriented approach},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical algorithm for solving third-order Emden–Fowler type pantograph differential equations: Taylor operational matrix method. <em>SOCO</em>, <em>29</em>(6), 2563-2579. (<a href='https://doi.org/10.1007/s00500-025-10599-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes two different Taylor polynomial-based numerical algorithms, one using uniform collocation points and the other using non-uniform collocation points for the numerical solution of a class of third-order Emden–Fowler type pantograph differential equations. The sufficient conditions for a unique solution to the problem are also derived for the first time. In the literature, only the weakly nonlinear IVP of the concerned model is tackled. In the present work, BVPs and strongly nonlinear IVPs are also considered. Both algorithms are designed by employing the operational matrices of the delayed-derivative terms appearing in the model, accelerating computation. The collocation schemes are appropriately designed to handle singularity effectively without removing it. This also reduces the considered problems into a nonlinear system of equations, which can be solved by the Newton–Raphson iterative method. The accuracy of the algorithms is further analyzed by some theoretical error bounds for the uniform and non-uniform collocation approaches. Several numerical illustrations are provided to support our investigation. In addition, two singularly perturbed problems are also solved to check the flexibility of the proposed algorithms. The fast Taylor operational matrix algorithms tackle several singular differential problems, including perturbed ones, effectively. Also, the numerical outcomes of both the proposed algorithms are compared to decide which is more efficient for the respective problems.},
  archive      = {J_SOCO},
  author       = {Saha, Nikita and Singh, Randhir},
  doi          = {10.1007/s00500-025-10599-8},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2563-2579},
  shortjournal = {Soft Comput.},
  title        = {Numerical algorithm for solving third-order Emden–Fowler type pantograph differential equations: Taylor operational matrix method},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relationships between various ideals in L-algebra. <em>SOCO</em>, <em>29</em>(6), 2551-2562. (<a href='https://doi.org/10.1007/s00500-025-10549-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Ciungu (2021), the relationship between some algebraic structures and L-algebras has been researched. In this paper, according to the theory of ideals in algebraic structures, such as BCK-algebras, we study ideals in L-algebras. We present definitions of positive implicative (implicative, associative, ultra, involution) ideals of L-algebras, and examine the relationship between them. Specially, we present conditions where they coincide.},
  archive      = {J_SOCO},
  author       = {Goraghani, S. Saidi and Borzooei, R. A.},
  doi          = {10.1007/s00500-025-10549-4},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2551-2562},
  shortjournal = {Soft Comput.},
  title        = {Relationships between various ideals in L-algebra},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic updating approximations of local multigranulation neighborhood covering rough sets. <em>SOCO</em>, <em>29</em>(6), 2531-2550. (<a href='https://doi.org/10.1007/s00500-025-10579-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lower and upper approximations in rough set theory are important for dealing with uncertain knowledge. The covering rough set is an important part of the rough set theory and is suitable for dealing with numerical data. With the development of information technology, the information is constantly updated and changed in various information systems, and it is crucial to efficiently obtain the lower and upper approximations in dynamic environments. In this paper, the matrix-based methods for updating the approximate operators of local multigranulation neighborhood covering rough sets when objects are added or deleted are mainly investigated. Firstly, the local multigranulation neighborhood covering rough set model is introduced. Then, we analyze the relationships between the prior matrices and the updating matrices when objects change. Meanwhile, the dynamic updating processes for lower and upper approximations are proposed. The time complexity analyses of algorithms theoretically prove the efficiency of dynamic algorithms compared with static ones. To illustrate the effectiveness of the proposed dynamic algorithms, six datasets from the UCI are employed for comparative experiments.},
  archive      = {J_SOCO},
  author       = {Shi, Qi and Zhang, Yan-Lan},
  doi          = {10.1007/s00500-025-10579-y},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2531-2550},
  shortjournal = {Soft Comput.},
  title        = {Dynamic updating approximations of local multigranulation neighborhood covering rough sets},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On subresiduated lattice ordered commutative monoids and some of its subvarieties. <em>SOCO</em>, <em>29</em>(6), 2517-2529. (<a href='https://doi.org/10.1007/s00500-025-10594-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A subresiduated lattice ordered commutative monoid (srl-monoid for short) is a pair $$({\textbf {A}},Q)$$ where $${\textbf {A}}=(A,\wedge ,\vee ,\cdot ,e)$$ is a lattice ordered monoid and Q is a subalgebra of A such that for each $$a,b\in A$$ the set $$\{q \in Q: a \cdot q \le b\}$$ has maximum, which will be denoted by $$a\rightarrow b$$ . The srl-monoids can be regarded as algebras $$(A,\wedge ,\vee ,\cdot ,\rightarrow ,e)$$ of type (2, 2, 2, 2, 0). This class of algebras is a variety which properly contains the varieties of commutative residuated lattices and subresiduated lattices respectively. In this paper, we study some aspects of the lattice of congruences of any srl-monoid, which is order isomorphic to the lattice of its strongly convex subalgebras. As application of this study we characterize simple and subdirectly irreducible algebras, we prove that every srl-monoid has the congruence extension property and we describe compatible functions. Then we focus our attention on a family of compatible functions, which will be called monotone modal operators, and considering as monotone modal operator the identity map, we introduce and study the variety of strong srl-monoids and some of its subvarieties.},
  archive      = {J_SOCO},
  author       = {Cornejo, Juan Manuel and San Martín, Hernán Javier and Sígal, Valeria Anahí},
  doi          = {10.1007/s00500-025-10594-z},
  journal      = {Soft Computing},
  month        = {3},
  number       = {6},
  pages        = {2517-2529},
  shortjournal = {Soft Comput.},
  title        = {On subresiduated lattice ordered commutative monoids and some of its subvarieties},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Deployment method of wireless sensor networks based on MaOEA/P-GM algorithm. <em>SOCO</em>, <em>29</em>(5), 2515. (<a href='https://doi.org/10.1007/s00500-024-10392-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Wang, Jun and Luo, Dongxu and Chen, Weiru and Peng, Funan and Li, Zhiwu},
  doi          = {10.1007/s00500-024-10392-z},
  journal      = {Soft Computing},
  month        = {3},
  number       = {5},
  pages        = {2515},
  shortjournal = {Soft Comput.},
  title        = {Correction to: Deployment method of wireless sensor networks based on MaOEA/P-GM algorithm},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monkeypox data enhancement and diagnosis using improved DCGAN. <em>SOCO</em>, <em>29</em>(5), 2497-2513. (<a href='https://doi.org/10.1007/s00500-025-10509-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent emergence of the monkeypox virus has attracted significant attention due to its serious effects, including pneumonia, retinal problems, secondary skin infections, and rectal swelling, leading to discomfort and urinary issues. Therefore, accurate identification is crucial, but the lack of comprehensive databases for each condition presents a challenge. Although Generative Adversarial Networks (GANs) show promise for improving data through augmentation, their training is hindered by differences between random noise and image structures. Because GAN-based models take random noise as input for the generators, they must acquire an adaptive function to translate this noise from randomness to meaningful visuals, leads to difficulty in training and converging. To tackle this issue, a new technique is proposed for data augmentation using a Densely Connected Decoder Encoder Generative Adversarial Network (D3EGAN). This approach combines adversarial training with variational Bayesian inference to enhance image production performance. D3EGAN uses a reversed encoder–decoder decoder–encoder framework which is pre-trained to transform random noise into more informative vectors, improving the generator’s learning ability. With this enhanced dataset, advanced deep learning models are employed such as VGG-19, ResNet50, InceptionV3, and EfficientNet to distinguish monkeypox from other diseases. Our study’s results demonstrate significant improvements in image clarity and detection accuracy, surpassing current techniques’ performance. This study highlights the effectiveness of our methodology in improving timely identification and intervention for monkeypox and related diseases, addressing a significant global health issue.},
  archive      = {J_SOCO},
  author       = {Tulasiram, Jinaga and Banothu, Balaji and Nickolas, S.},
  doi          = {10.1007/s00500-025-10509-y},
  journal      = {Soft Computing},
  month        = {3},
  number       = {5},
  pages        = {2497-2513},
  shortjournal = {Soft Comput.},
  title        = {Monkeypox data enhancement and diagnosis using improved DCGAN},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Photovoltaic power one-day and multistep-hourly AI predictions using node-by-node evolved binomial tree structures to form L-transformed PDE modules. <em>SOCO</em>, <em>29</em>(5), 2483-2495. (<a href='https://doi.org/10.1007/s00500-024-10394-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photovoltaic (PV) power is generated by two common types of solar components that are primarily affected by fluctuations and development in cloud structures as a result of uncertain and chaotic processes. Local PV forecasting is unavoidable in supply and load planning necessary in integration of smart systems into electrical grids. Intra- or day-ahead modelling of weather patterns based on Artificial Intelligence (AI) allows one to refine available 24 h. cloudiness forecast or predict PV production at a particular plant location during the day. AI usually gets an adequate prediction quality in shorter-level horizons, using the historical meteo- and PV record series as compared to Numerical Weather Prediction (NWP) systems. NWP models are produced every 6 h to simulate grid motion of local cloudiness, which is additionally delayed and usually scaled in a rough less operational applicability. Differential Neural Network (DNN) is based on a newly developed neurocomputing strategy that allows the representation of complex weather patterns analogous to NWP. DNN parses the n-variable linear Partial Differential Equation (PDE), which describes the ground-level patterns, into sub-PDE modules of a determined order at each node. Their derivatives are substituted by the Laplace transforms and solved using adapted inverse operations of Operation Calculus (OC). DNN fuses OC mathematics with neural computing in evolution 2-input node structures to form sum modules of selected PDEs added step-by-step to the expanded composite model. The AI multi- 1…9-h and one-stage 24-h models were evolved using spatio-temporal data in the preidentified daily learning sequences according to the applied input–output data delay to predict the Clear Sky Index (CSI). The prediction results of both statistical schemes were evaluated to assess the performance of the AI models. Intraday models obtain slightly better prediction accuracy in average errors compared to those applied in the second-day-ahead evening approach. However, the first-morning strategy application includes a much more complicated and time-consuming procedure, so in conclusion, the second one-mode series processing could be recommended. Model statistics are generally more successful than NWP data processing due to limitations, delays, and unavailability of free radiation or cloudiness forecasts in the systems. An all-day model enables the prediction of complete PVP periods in sequenced computing with acceptable operational quality in the late afternoon, which is inevitable in day-ahead management and load scheduling in smart grids based on PV energy.},
  archive      = {J_SOCO},
  author       = {Zjavka, Ladislav},
  doi          = {10.1007/s00500-024-10394-x},
  journal      = {Soft Computing},
  month        = {3},
  number       = {5},
  pages        = {2483-2495},
  shortjournal = {Soft Comput.},
  title        = {Photovoltaic power one-day and multistep-hourly AI predictions using node-by-node evolved binomial tree structures to form L-transformed PDE modules},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Genetic algorithm based data controlling method using IoT enabled WSNs. <em>SOCO</em>, <em>29</em>(5), 2465-2482. (<a href='https://doi.org/10.1007/s00500-024-10396-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) enabled Wireless Sensor Networks (WSNs) is not only constitute an encouraging research domain but also represent a promising industrial trend that permits the development of various IoT-based applications. These applications span a wide range from industry to education, and from military to agriculture. The IoT device plays a significant role in various IoT-based networks, and the functioning of such network depends upon the battery power. Once the devices are deployed in the hostile environments, replacing batteries becomes impractical. Despite a plethora of research addressing this challenge, IoT networks still face issues. In this paper, a genetic algorithm based data monitoring and controlling method using IoT enabled WSNs is proposed by using movable sinks in IoT enabled HWSNs (OptiGeA). The OptiGeA protocol is designed for the election of cluster heads (CHs) by incorporating factors such as density, distance, energy and heterogeneous node capacity into its fitness function. The investigation of OptiGeA is conducted with single sink, multiple static sinks and multiple movable sinks provide an unbiased comparative assessment. The novel deployment technique and multiple mobile sinks approaches are proposed to reduce the transmission distance between the sink and CH during system operation and address hotspot issue. It is evident that the OptiGeA protocol shows an increment of 10.44% compared to the GAOC, whereas with the inclusion of DDC process the OptiGeA-DDC protocol demonstrates a remarkable increase of 48.33% compared to MS-GAOC.},
  archive      = {J_SOCO},
  author       = {Singh, Samayveer and Nandan, Aridaman Singh and Sikka, Geeta and Malik, Aruna and Singh, Pradeep Kumar},
  doi          = {10.1007/s00500-024-10396-9},
  journal      = {Soft Computing},
  month        = {3},
  number       = {5},
  pages        = {2465-2482},
  shortjournal = {Soft Comput.},
  title        = {Genetic algorithm based data controlling method using IoT enabled WSNs},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Multi-objective DOA estimation in automotive radar using a sailfish optimizer with latin hypercube sampling. <em>SOCO</em>, <em>29</em>(5), 2463. (<a href='https://doi.org/10.1007/s00500-025-10542-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {P, Geetha and Nanda, Satyasai Jagannath and Yadav, Rajendra Prasad},
  doi          = {10.1007/s00500-025-10542-x},
  journal      = {Soft Computing},
  month        = {3},
  number       = {5},
  pages        = {2463},
  shortjournal = {Soft Comput.},
  title        = {Correction to: Multi-objective DOA estimation in automotive radar using a sailfish optimizer with latin hypercube sampling},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective DOA estimation in automotive radar using a sailfish optimizer with latin hypercube sampling. <em>SOCO</em>, <em>29</em>(5), 2433-2461. (<a href='https://doi.org/10.1007/s00500-024-10343-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Direction of arrival (DOA) estimation is a challenging problem in automotive radar for target detection and finds potential applications in the design of driver assistance system (DAS). Accurate DOA estimation in automotive radar becomes more difficult in the presence of noise. To address this issue, in this paper, the DOA estimation problem in automotive radar is formulated as a multi-objective optimization problem by simultaneous minimization of two operators: (1) reciprocal of Maximum Likelihood function; and (2) noise variance. Accurate angle estimation can be carried out in the absence of noise, and vice-versa, thus making these two functions contradictory in nature. In this article, a multi-objective Sailfish optimizer algorithm is proposed with Latin hypercube sampling and double archive mechanism termed as MOSFO-LH. The Latin hypercube generates evenly distributed samples and thus provides potential diversification of the search agents in the objective space. Further, a double archive method is incorporated to keep the good solutions that are responsible for maintaining diversity in the Pareto Front. Superior performance of the proposed MOSFO-LH algorithm is reported over five more comparative algorithms, on ten benchmark multi-objective test functions selected from the ZDT and DTLZ test suite. Case studies are reported for DOA estimation in automotive radar under six noise conditions. Effective performance is demonstrated with estimated DOA angles, box plots of root mean square error values, Pareto optimal fronts, heat map of inverse generalized distance, maximum spread and hyper volume metric.},
  archive      = {J_SOCO},
  author       = {P, Geetha and Nanda, Satyasai Jagannath and Yadav, Rajendra Prasad},
  doi          = {10.1007/s00500-024-10343-8},
  journal      = {Soft Computing},
  month        = {3},
  number       = {5},
  pages        = {2433-2461},
  shortjournal = {Soft Comput.},
  title        = {Multi-objective DOA estimation in automotive radar using a sailfish optimizer with latin hypercube sampling},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving learning material repositories using student profiles. <em>SOCO</em>, <em>29</em>(5), 2417-2431. (<a href='https://doi.org/10.1007/s00500-025-10450-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {aaaa The adaptive learning community seeks to provide solutions to customize and enhance students’ learning experiences when accessing web-based learning systems. The adaptation usually occurs from the use of learning materials and user information data, which turns the adaptation process highly dependent on the quality of the repositories. Then, the best adaptation a system may offer might still not satisfy the users’ needs. In this work, we propose an approach to assist teachers and stakeholders in understanding repositories’ characteristics and their gaps according to students’ needs. Our approach, first, selects the best sequence of learning materials for each student, which is a well-known problem called Adaptive Curriculum Sequencing. Then, based on the selected sequences, we use optimization approaches, such as GRASP and Simulated Annealing, to generate new learning materials possibilities that can improve ACS recommendations. This way, our new approach assists teachers in assembling their learning materials. We have evaluated our approach by comparing it to a traditional approach using a real dataset, and the results are promising. In fact, it is possible to design customized materials using a combination of GRASP and brute force algorithms on the characteristics of the learning materials.},
  archive      = {J_SOCO},
  author       = {Silva Bravo, Natalie Ferraz and Martins, André Ferreira and de Souza Fonseca Rodrigues, Thales Brito and Machado, Marcelo and Bernardino, Heder Soares and Vieira, Alex Borges and Barbosa, Hélio José Corrêa and de Souza, Jairo Francisco},
  doi          = {10.1007/s00500-025-10450-0},
  journal      = {Soft Computing},
  month        = {3},
  number       = {5},
  pages        = {2417-2431},
  shortjournal = {Soft Comput.},
  title        = {Improving learning material repositories using student profiles},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Channel boosted convolutional neural network with segnet based segmentation for an automatic prediction of thyroid cancer. <em>SOCO</em>, <em>29</em>(5), 2399-2415. (<a href='https://doi.org/10.1007/s00500-025-10482-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Endocrine cancer is thyroid cancer, and its prevalence has been steadily rising worldwide. A nodule near the thyroid gland in the neck is the earliest sign of thyroid cancer. One of the most reliable and popular approaches for finding thyroid nodules is ultrasonography. However, it takes time and creates difficulties for the professionals to evaluate all of the slide pictures. The most commonly used automated prediction model for detecting thyroid cancer is a different machine learning algorithm. However, attaining accurate prediction with lesser error probability is quite difficult using the existing prediction model. To address this issue, Channel boosted-Convolutional Neural Network (CB-CNN) is developed to identify thyroid cancer. Pre-processing of source ultrasound image is done using adaptive median filter and dualistic sub image histogram equalization for improving the resolution of input image. The adaptive median filter is employed to remove the noise from the original image. Dualistic sub image histogram equalization is used to enhance the image’s contrast level for further processing. The pre-processed image is segmented by using SegNet in order to identify the region of the tumour. After that, the segmented image is classified using CBCNN for predicting thyroid cancer. Simulation analysis reported, the proposed model reached 96% of accuracy, 4% error, 94% precision and 93% specificity. As a result, the proposed strategy performs better than other current strategies, such as Deep Convolutional Neural Network (DCNN), ResNet101, InceptionV3 and VGG19. Through this study it is preferred that proposed model is the best option for identifying thyroid cancer with better accuracy.},
  archive      = {J_SOCO},
  author       = {Arepalli, Leelavathi and Kasukiurthi, Venkata Rao and Dabbiru, Madhavi},
  doi          = {10.1007/s00500-025-10482-6},
  journal      = {Soft Computing},
  month        = {3},
  number       = {5},
  pages        = {2399-2415},
  shortjournal = {Soft Comput.},
  title        = {Channel boosted convolutional neural network with segnet based segmentation for an automatic prediction of thyroid cancer},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: IADF security: Insider attack detection using fuzzy logic in wireless multimedia sensor networks. <em>SOCO</em>, <em>29</em>(4), 2397. (<a href='https://doi.org/10.1007/s00500-024-10397-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Janarthanan, Ashwinth and Kumar, Dhananjay and Antony, R. Remo and Parvathe, C. B. Divya},
  doi          = {10.1007/s00500-024-10397-8},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2397},
  shortjournal = {Soft Comput.},
  title        = {Retraction note: IADF security: Insider attack detection using fuzzy logic in wireless multimedia sensor networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: Enhancing performance of cell formation problem using hybrid efficient swarm optimization. <em>SOCO</em>, <em>29</em>(4), 2395. (<a href='https://doi.org/10.1007/s00500-024-10393-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Nagaraj, G. and Arunachalam, Manimaran and Vinayagar, K. and Paramasamy, S.},
  doi          = {10.1007/s00500-024-10393-y},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2395},
  shortjournal = {Soft Comput.},
  title        = {Retraction note: Enhancing performance of cell formation problem using hybrid efficient swarm optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: Classification of noiseless corneal image using capsule networks. <em>SOCO</em>, <em>29</em>(4), 2393. (<a href='https://doi.org/10.1007/s00500-024-10391-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Koresh, H. James Deva and Chacko, Shanty},
  doi          = {10.1007/s00500-024-10391-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2393},
  shortjournal = {Soft Comput.},
  title        = {Retraction note: Classification of noiseless corneal image using capsule networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RETRACTED ARTICLE: Near-infrared and visible light face recognition: A comprehensive survey. <em>SOCO</em>, <em>29</em>(4), 2391. (<a href='https://doi.org/10.1007/s00500-023-08366-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Huang, Fangzheng and Tang, Xikai and Li, Chao and Ban, Dayan},
  doi          = {10.1007/s00500-023-08366-8},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2391},
  shortjournal = {Soft Comput.},
  title        = {RETRACTED ARTICLE: Near-infrared and visible light face recognition: A comprehensive survey},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gender opposition recognition method fusing emojis and multi-features in chinese speech. <em>SOCO</em>, <em>29</em>(4), 2379-2390. (<a href='https://doi.org/10.1007/s00500-025-10492-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech with gender opposition on the internet have been causing antagonism, gamophobia, and pregnancy phobia among young groups. Recognizing gender opposition speech contributes to maintaining a healthy online environment and security in cyberspace. Traditional recognition model ignores the Chinese-owned features and emojis, which inevitably affects the recognition accuracy of gender opposition. To tackle this issue, a gender opposition recognition method fusing emojis and multi-features in Chinese speech(GOR-CS) is proposed. Firstly, the exBERT method is employed to expand the encoding of emojis into the BERT vocabulary, which can ensure BERT to extract the basis vectors containing characters and emojis information. Then, the feature vectors containing Wubi, Zhengma, and Pinyin information are extracted by Word2Vec to obtain the Chinese-owned features of gender opposition text. Further, the proposed basis vector and feature vectors are fused and then fed into the Bi-GRU network to extract deeper semantics from input sentences. Finally, to determine whether the speech are related to gender opposition, the sentiment polarities are calculated with the fully connected layer and SoftMax function. Experimental results show that the proposed method can effectively improve the accuracy of gender opposition recognition.},
  archive      = {J_SOCO},
  author       = {Zhang, Shunxiang and Ma, Zichen and Li, Hanchen and Liu, Yunduo and Chen, Lei and Li, Kuan-Ching},
  doi          = {10.1007/s00500-025-10492-4},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2379-2390},
  shortjournal = {Soft Comput.},
  title        = {Gender opposition recognition method fusing emojis and multi-features in chinese speech},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight CNN model for UAV-based image classification. <em>SOCO</em>, <em>29</em>(4), 2363-2378. (<a href='https://doi.org/10.1007/s00500-025-10512-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For many unmanned aerial vehicle (UAV)-based applications, especially those that need to operate with resource-limited edge networked devices in real-time, it is crucial to have a lightweight computing model for data processing and analysis. In this study, we focus on UAV-based forest fire imagery detection using a lightweight convolution neural network (CNN). The task is challenging owing to complex image backgrounds and insufficient training samples. Specifically, we enhance the MobileNetV2 model with an attention mechanism for UAV-based image classification. The proposed model first employs a transfer learning strategy that leverages the pre-trained weights from ImageNet to expedite learning. Then, the model incorporates randomly initialised weights and dropout mechanisms to mitigate over-fitting during training. In addition, an ensemble framework with a majority voting scheme is adopted to improve the classification performance. A case study on forest fire scenes classification with benchmark and real-world images is demonstrated. The results on a publicly available UAV-based image data set reveal the competitiveness of our proposed model as compared with those from existing methods. In addition, based on a set of self-collected images with complex backgrounds, the proposed model illustrates its generalisation capability to undertake forest fire classification tasks with aerial images.},
  archive      = {J_SOCO},
  author       = {Deng, Xinjie and Shi, Michael and Khan, Burhan and Choo, Yit Hong and Ghaffar, Fazal and Lim, Chee Peng},
  doi          = {10.1007/s00500-025-10512-3},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2363-2378},
  shortjournal = {Soft Comput.},
  title        = {A lightweight CNN model for UAV-based image classification},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning-based model for automated STN localization using local field potentials in parkinson’s disease. <em>SOCO</em>, <em>29</em>(4), 2343-2362. (<a href='https://doi.org/10.1007/s00500-025-10497-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of the subthalamic nucleus (STN) borders is time-consuming, relying heavily on the neurosurgeon expertise in manually interpreting the electrophysiological signals. Local field potentials (LFPs) have garnered imperative attention due to their strong correlation with the STN. However, existing detection models often face challenges with high computational complexity, hyperparameter optimization and lack of explainability, making them unreliable for clinicians. Therefore, this study introduces an explanatory framework using convolutional neural networks (CNN) for detecting the STN region from LFPs. Continuous wavelet transform is employed to convert LFPs signals into scalogram images, which are then processed by sixteen CNN models. We evaluated our framework by examining the impact of various limiting factors on the classification performance, including model size, learning rate (LR), optimizers and data scaling. Deep features are extracted from the top-performing CNN architectures to capture rich representations of the scalograms. These features are then fused and classified using k-nearest neighbour algorithm. Gradient-weighted class activation mapping is used to explain the decisions made by the proposed model. Our approach achieved an accuracy of 99.61%, outperforming individual CNN models for STN localization. The experimental results revealed that CNN models, embedded with additional hyperparameters and layers, generally outperformed smaller models. Besides, low LR significantly enhanced the performance compared to high LR. Moreover, features extracted from untuned networks produced lower performance than tuned networks. The proposed system could revolutionize deep brain stimulation surgery by increasing efficiency and reducing reliance on clinician expertise for STN detection.},
  archive      = {J_SOCO},
  author       = {Hosny, Mohamed and Naeem, Mohamed A. and Zhu, Minwei and Gao, Wenpeng and Elshenhab, Ahmed M. and Fu, Yili},
  doi          = {10.1007/s00500-025-10497-z},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2343-2362},
  shortjournal = {Soft Comput.},
  title        = {A deep learning-based model for automated STN localization using local field potentials in parkinson’s disease},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced single shot detector for small object detection in drone-capture scenarios. <em>SOCO</em>, <em>29</em>(4), 2331-2341. (<a href='https://doi.org/10.1007/s00500-025-10539-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in deep learning have significantly improved object detection performance. However, detecting small objects in drone-captured imagery remains challenging due to their low resolution and noisy appearance. This paper presents the Enhanced Single Shot Detector (ESSD), designed for accurate small object detection. The ESSD incorporates a scale-confusion erasing module to reduce noise from larger objects, enhancing the detection of smaller ones. It also features a neighbor fusion module that integrates semantic information across layers. Our experiments on the VisDrone2019-DET benchmark dataset show that the ESSD achieves state-of-the-art performance in small object detection.},
  archive      = {J_SOCO},
  author       = {Shi, Yanxia and Liu, Yanrong and Liu, Yaru},
  doi          = {10.1007/s00500-025-10539-6},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2331-2341},
  shortjournal = {Soft Comput.},
  title        = {Enhanced single shot detector for small object detection in drone-capture scenarios},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secure transmission of medical image using a wavelet interval type-2 TSK fuzzy brain-imitated neural network. <em>SOCO</em>, <em>29</em>(4), 2311-2329. (<a href='https://doi.org/10.1007/s00500-025-10449-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this research is to develop a new design of a wavelet interval type-2 takagi–Sugeno-Kang fuzzy brain-imitated neural network (WIT2TFBINN), which is a combination of the mathematical models of a Takagi–Sugeno-Kang (TSK) fuzzy system based on wavelet interval type-2 function (WIT2) and a wavelet interval type-2 fuzzy brain imitated neural network (FBINN). The proposed WIT2TFBINN is used for synchronization control of a 4D Lorentz chaotic system and has the benefits of wavelet interval type-2 membership function, TSK fuzzy inference system, decision making, and emotional activity. To provide fast training, the proposed method's parameter update laws are derived using the gradient descent method. The proposed WIT2TFBINN synchronization technique is then applied to the transmission of medical images in a secure manner. As a cipher image, a medical image is encrypted into a chaotic trajectory. After transmission, the image can be decrypted using chaotic trajectory synchronization on the received signal. The simulation results show that the proposed neural network and the encryption/decryption method are powerful and effective. The results of the static test analysis (histogram, attack analysis, image with noise, image with cropping) show that the encryption/decryption method provides high security.},
  archive      = {J_SOCO},
  author       = {Pham, Duc-Hung and Huynh, Tuan-Tu and Lin, Chih-Min and Giap, Van Nam and Vu, Van-Phong},
  doi          = {10.1007/s00500-025-10449-7},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2311-2329},
  shortjournal = {Soft Comput.},
  title        = {Secure transmission of medical image using a wavelet interval type-2 TSK fuzzy brain-imitated neural network},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliability analysis of discrete-time multi-state star configuration power grid systems with performance sharing. <em>SOCO</em>, <em>29</em>(4), 2297-2310. (<a href='https://doi.org/10.1007/s00500-025-10478-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by practical engineering systems, this paper studies an assessment method for dynamic reliability of a discrete time multi-state star configuration power grid system with performance sharing. The proposed star configuration power grid system consists of n power generation subsystems fixed in star-terminal and one central collection and redistribution subsystem. The star-terminal subsystems with sufficient electric power can first transmit the surplus electric power to the central subsystem, and then the collected electric power in central subsystem is further redistributed to the star-terminal subsystems which are experiencing electric power deficiency through the corresponded transmission links. An algorithm based on the universal generating function (UGF) technique is presented to evaluate the dynamic reliability of the proposed power grid system with performance sharing. Finally, a numerical example and a case study are used to illustrate the accuracy of the proposed model and method. Studies indicate that the steady reliability of the proposed power grid system is improved by 9.41% and 37.28% for the numerical example when comparing the calculation results between performance sharing, unlimited performance sharing and no performance sharing. In the case study, the dynamic reliability of the proposed power grid system increased by 11.5% when comparing the calculation results between with performance sharing and no performance sharing when $$k\to \infty $$ .},
  archive      = {J_SOCO},
  author       = {Su, Peng and Zhang, Keyong and Shi, Honghua},
  doi          = {10.1007/s00500-025-10478-2},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2297-2310},
  shortjournal = {Soft Comput.},
  title        = {Reliability analysis of discrete-time multi-state star configuration power grid systems with performance sharing},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deteriorating inventory model with advance-cash-credit payment schemes and partial backlogging. <em>SOCO</em>, <em>29</em>(4), 2279-2295. (<a href='https://doi.org/10.1007/s00500-025-10532-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In business transactions, suppliers often ask retailers for advance-cash-credit (ACC) payments, and retailers offer customers a cash-credit (CC) payment plan. An advance payment is generally requested to avoid order cancellation, while a credit payment serves as an efficient approach to stimulate sales. With supply chains being usually subject to inventory shortages in view of various uncertainties, this study explores an optimal inventory policy for perishable goods with partial backlogging considerations when suppliers adopt an ACC payment plan for retailers and retailers offer customers a CC payment plan. For this purpose, we establish a model based on two theorems and provide an easy-to-use method to derive the optimal ordering policy to maximize retailers’ total profits. This solution is illustrated using numerical examples. Finally, we conduct a sensitivity analysis to examine the influence of changes in the values of key parameters on the optimal solution.},
  archive      = {J_SOCO},
  author       = {Chang, Chun-Tao and Cheng, Mei-Chuan and Ouyang, Liang-Yuh},
  doi          = {10.1007/s00500-025-10532-z},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2279-2295},
  shortjournal = {Soft Comput.},
  title        = {Deteriorating inventory model with advance-cash-credit payment schemes and partial backlogging},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging feature fusion ensemble of VGG16 and ResNet-50 for automated potato leaf abnormality detection in precision agriculture. <em>SOCO</em>, <em>29</em>(4), 2263-2277. (<a href='https://doi.org/10.1007/s00500-025-10523-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of advancement in technology and modern agriculture, early disease detection of potato leaves will improve crop yield. Various researchers have focussed on disease due to different types of microbial infection in potato leaves using computer vision and machine learning approaches. In this paper, a data science approach for multiclass classification of potato normal and abnormal leaves due to fungal infection like early blight and late blight is performed using the ensembling of deep learning (DL) CNN models. Firstly, the performance of classification on potato disease is verified separately on VGG16 and ResNet-50 CNN models after pre-processing of the leaf dataset. The pre-processing includes noise removal and normalization. Further improvement in classification accuracy is achieved by the ensembling of VGG16 and ResNet-50 CNN models. The ensembling of CNN models is performed on the feature level by fusing features extracted using VGG16 and ResNet-50. From the experimental results, performed on publicly available datasets consisting of 2152 number of normal and abnormal images it is observed that the average classification accuracy of 98.22%, 96.16% and 95.68% is achieved using the proposed ensemble, VGG16 and ResNet-50 models respectively. The efficacy of the proposed approach (ensemble technique at feature level fusion) is verified in comparison with recently reported DL model-based approaches.},
  archive      = {J_SOCO},
  author       = {Trivedi, Amit Kumar and Mahajan, Tripti and Maheshwari, Tanmay and Mehta, Rajesh and Tiwari, Shailendra},
  doi          = {10.1007/s00500-025-10523-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2263-2277},
  shortjournal = {Soft Comput.},
  title        = {Leveraging feature fusion ensemble of VGG16 and ResNet-50 for automated potato leaf abnormality detection in precision agriculture},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adopting fuzzy multi-criteria decision-making ranking approach ensuring connected topology in industrial wireless sensor networks. <em>SOCO</em>, <em>29</em>(4), 2247-2261. (<a href='https://doi.org/10.1007/s00500-025-10448-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In wireless sensor networks (WSNs), topology control aims to optimize the network structure to improve its performance and is a significant issue especially in mesh connected networks. As Industrial Wireless sensor networks (IWSNs) adopt a mesh-based strategy for communication, a connected topology and its maintenance is necessary. Therefore, identifying candidate nodes and reconfiguration under congestion and failure for reliable connection becomes important. A rank-based mechanism appears a viable solution to identify next best candidates to establish the connections among the nodes in the event of network disruption. As a solution, we propose adoption of MCDM (Multi-Criteria Decision-Making) based approach to compute the ranks among the sensor nodes when subject to varied constraints. Our paper compares and analyses the ranking of a node by using two methods, Analytical hierarchy Process (AHP) Weighted TOPSIS (Technique for Order Performance by Similarity to Ideal Solution) and FUZZY TOPSIS. A novel application of the rank-based strategy to determine the connection between the nodes for achieving a network with lower energy consumption and better connectivity for IWSNs is presented. On comparison with standard topology control algorithms, like connected dominating set (CDS) and articulation point strategy our results confirm that the topology formed through our ranking method achieves lower energy consumption in communication and better connectivity probability among the nodes. Further, we also observe performance of the network when subject to obstacles in the line-of-sight communication typical of IWSNs and our approach performs better in this case too.},
  archive      = {J_SOCO},
  author       = {Nandan, Anvita and Snigdh, Itu},
  doi          = {10.1007/s00500-025-10448-8},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2247-2261},
  shortjournal = {Soft Comput.},
  title        = {Adopting fuzzy multi-criteria decision-making ranking approach ensuring connected topology in industrial wireless sensor networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New vigenere method with pseudo-random affine functions for color image encryption. <em>SOCO</em>, <em>29</em>(4), 2229-2245. (<a href='https://doi.org/10.1007/s00500-025-10477-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this document, we propose an enhanced technique for encrypting color images, building upon a substantial refinement of the traditional Vigenere method, guaranteed by two strong pseudo-random replacement tables built from the utilization of dynamic linear functions and the most frequently utilized chaotic maps in cryptography domain. After original image vectorization and initialization value calculation, which serve to modify the initial pixel value, thereby triggering the ciphering procedure, our technique integrates a novel Vigenere circuit using dynamic pseudorandom functions to change pixel values. Finally, a positional shift of each pixel is applied to maximize the temporal complexity of our technology. Experiments carried out on a wide range of images spanning various formats and dimensions confirm the robustness of our method against established attack techniques.},
  archive      = {J_SOCO},
  author       = {El Bourakkadi, Hamid and Chemlal, Abdelhakim and Tabti, Hassan and Kattass, Mourad and Jarjar, Abdellatif and Benazzi, Abdelhamid},
  doi          = {10.1007/s00500-025-10477-3},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2229-2245},
  shortjournal = {Soft Comput.},
  title        = {New vigenere method with pseudo-random affine functions for color image encryption},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced TODIM-TOPSIS framework for design quality evaluation for college smart sports venues under hesitant fuzzy sets. <em>SOCO</em>, <em>29</em>(4), 2215-2227. (<a href='https://doi.org/10.1007/s00500-025-10414-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the gradual development and application of modern intelligent technology in our country, it has become a key factor influencing the nation's overall competitive strength. The state has explicitly proposed the establishment of efficient and high-quality engineering projects in the current sports industry. By applying innovative technologies, smart sports venues will be created to support the future development of the nation and the sports sector, thereby comprehensively enhancing the country's overall competitive strength. Among these, university gyms, as important venues for modern school physical education, must keep pace with the nation's development. By establishing smart sports venues and utilizing Internet of Things (IoT) technology, cloud computing technology, and artificial intelligence technology, the comprehensive operation of sports venues can be promoted, leading to the stable development of the school sports industry. The design quality evaluation for college smart sports venues is a multiple-attribute decision-making (MADM) problem. Recently, the TODIM and TOPSIS methods have been demonstrated to address MAGDM issues. Hesitant fuzzy sets (HFSs) have been introduced as a means to characterize uncertain data during the design quality evaluation for college smart sports venues. In this study, the hesitant fuzzy TODIM-TOPSIS (HF-TODIM-TOPSIS) approach is proposed to solve MADM problems under HFSs. Finally, a numerical study for the design quality evaluation of college smart sports venues is presented to validate the proposed approach. The major contributions of this study are as follows: (1) The TODIM and TOPSIS methods are extended to HFSs; (2) Entropy is used to determine the weight values under HFSs; (3) The HF-TODIM-TOPSIS approach is established to handle MADM problems under HFSs; (4) Algorithm analysis and comparison for the design quality evaluation of college smart sports venues are conducted based on a numerical example to verify the feasibility and effectiveness of the HF-TODIM-TOPSIS approach.},
  archive      = {J_SOCO},
  author       = {Yang, Feng and Wu, Yuefang and Li, Yi},
  doi          = {10.1007/s00500-025-10414-4},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2215-2227},
  shortjournal = {Soft Comput.},
  title        = {Enhanced TODIM-TOPSIS framework for design quality evaluation for college smart sports venues under hesitant fuzzy sets},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling and analysis of data corruption attacks and energy consumption effects on edge servers using concurrent stochastic games. <em>SOCO</em>, <em>29</em>(4), 2189-2214. (<a href='https://doi.org/10.1007/s00500-025-10467-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intricate nature of modern edge architectures, relying on a vast array of computational logic and lightweight communication protocols, creates vulnerabilities that expose them to a broad spectrum of security threats. Moreover, security vulnerabilities can significantly impact the energy footprint of edge servers in these architectures. Our approach utilizes the concurrent stochastic game (CSG) formalism to model the behavior of IoT communication entities (players) while accounting for potential attacks at the communication edge and the resulting energy consumption caused by such attacks. We rely on the PRISM-games language for automated analysis where the game goals modeling functional and security requirements are expressed using reward probabilistic alternating temporal logic (rPATL). To validate our approach, we examine a data corruption attack applied to dam water flow control and study its side effect on energy consumption associated with SensiNact gateways. Our key innovation lies in using formal models at the architectural level to explore potential attacks. These models capture synchronous and asynchronous communication styles, along with their associated energy consumption. The methodology and the implemented formalism offer a significant advancement over traditional game equation models while still achieving the desired security and energy evaluation. Numerical results show that compared to synchronous communication, asynchronous styles suffer from significantly larger infected buffers and higher energy consumption due to attacks ranging from 66 to 91%.},
  archive      = {J_SOCO},
  author       = {Baouya, Abdelhakim and Hamid, Brahim and Gürgen, Levent and Bensalem, Saddek},
  doi          = {10.1007/s00500-025-10467-5},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2189-2214},
  shortjournal = {Soft Comput.},
  title        = {Modeling and analysis of data corruption attacks and energy consumption effects on edge servers using concurrent stochastic games},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel attention based deep learning model for software defect prediction with bidirectional word embedding system. <em>SOCO</em>, <em>29</em>(4), 2171-2188. (<a href='https://doi.org/10.1007/s00500-025-10475-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software defect prediction (SDP) is considered a dynamic research problem and is beneficial during the testing stage of the software development life cycle. Several artificial intelligence-based methods were available to predict these software defects. However, the detection accuracy is still low due to imbalanced datasets, poor feature learning, and tuning of the model's parameters. This paper proposes a novel attention-included Deep Learning (DL) model for SDP with effective feature learning and dimensionality reduction mechanisms. The system mainly comprises ‘6’ phases: dataset balancing, source code parsing, word embedding, feature extraction, dimensionality reduction, and classification. First, dataset balancing was performed using the density peak based k-means clustering (DPKMC) algorithm, which prevents the model from having biased outcomes. Then, the system parses the source code into abstract syntax trees (ASTs) that capture the structure and relationship between different elements of the code to enable type checking and the representative nodes on ASTs are selected to form token vectors. Then, we use bidirectional encoder representations from transformers (BERT), which converts the token vectors into numerical vectors and extracts semantic features from the data. We then input the embedded vectors to multi-head attention incorporated bidirectional gated recurrent unit (MHBGRU) for contextual feature learning. After that, the dimensionality reduction is performed using kernel principal component analysis (KPCA), which transforms the higher dimensional data into lower dimensions and removes irrelevant features. Finally, the system used a deep, fully connected network-based SoftMax layer for defect prediction, in which the cross-entropy loss is utilized to minimize the prediction loss. The experiments on the National Aeronautics and Space Administration (NASA) and AEEEM show that the system achieves better outcomes than the existing state-of-the-art models for SDP.},
  archive      = {J_SOCO},
  author       = {Devi, M. Chitra and Rajkumar, T. Dhiliphan},
  doi          = {10.1007/s00500-025-10475-5},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2171-2188},
  shortjournal = {Soft Comput.},
  title        = {A novel attention based deep learning model for software defect prediction with bidirectional word embedding system},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Review of quantum algorithms for medicine, finance and logistics. <em>SOCO</em>, <em>29</em>(4), 2129-2170. (<a href='https://doi.org/10.1007/s00500-025-10540-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing represents an emerging technology, that leverages the fundamental principles of quantum mechanics to solve highly complex problems that are beyond the capabilities of classical computers. Due to the unique characteristics of quantum computers, optimisation algorithms can be significantly improved, offering performance that surpasses classical methods, especially for computationally intractable problems. This study aims to provide a comprehensive overview of recent scientific research focused on the development of effective quantum algorithms in specific application contexts, with particular emphasis on the healthcare, finance, production planning and logistics sectors. Additionally, we present a comprehensive classification of methodologies and approaches employed in the design and implementation of quantum algorithms.},
  archive      = {J_SOCO},
  author       = {Ciacco, Alessia and Guerriero, Francesca and Macrina, Giusy},
  doi          = {10.1007/s00500-025-10540-z},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2129-2170},
  shortjournal = {Soft Comput.},
  title        = {Review of quantum algorithms for medicine, finance and logistics},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-ant colony algorithm based on the stackelberg game and incremental learning. <em>SOCO</em>, <em>29</em>(4), 2107-2128. (<a href='https://doi.org/10.1007/s00500-025-10469-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the difficulties of slow convergence and inadequate accuracy of traditional ant colony algorithms in solving the traveling salesman problem (TSP), we propose a multi-ant colony algorithm based on the Stackelberg game and incremental learning (SGIACO). We incorporate the Stackelberg game strategy across multiple colonies, where the leader guides the follower to optimize population co-evolution, ensuring a balance between convergence and diversity of the algorithm. Furthermore, we propose an incremental learning strategy that enhances efficient paths on the public routes and ignores inefficient ones, thus accelerating the convergence speed of the algorithm. Finally, when the algorithm stagnates, a pheromone balance mechanism is implemented to help the ants escape from local optima. We conducted experiments on 23 TSP instances to validate the algorithm's performance and compare it to ACS, MMAS, as well as other recent algorithms. In addition, non-parametric tests were conducted for comprehensive performance analysis. Moreover, we verified the feasibility of SGIACO through simulations in robot path planning scenarios. The experimental results show that SGIACO has good convergence and accuracy, which is competitive with other algorithms. Future research aims to scale SGIACO for larger real-world applications, enhancing its adaptability and scalability.},
  archive      = {J_SOCO},
  author       = {Wu, Qihuan and You, Xiaoming and Liu, Sheng},
  doi          = {10.1007/s00500-025-10469-3},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2107-2128},
  shortjournal = {Soft Comput.},
  title        = {Multi-ant colony algorithm based on the stackelberg game and incremental learning},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-population artificial tree algorithm based on adaptive updating strategy for dominant populations. <em>SOCO</em>, <em>29</em>(4), 2075-2106. (<a href='https://doi.org/10.1007/s00500-025-10445-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An artificial tree (AT) algorithm has been proposed recently, and the performance of AT has been enhanced because of the introduction of improved AT algorithm with two-population (IATTP). However, the branch update operators of IATTP cannot effectively balance exploration and exploitation, which limits the optimization accuracy and efficiency of IATTP. To further improve the performance of IATTP, this work proposes a two-population artificial tree algorithm based on adaptive updating strategy for dominant populations (TATAD). In TATAD, six operators named self-evolution operator 2, crossover operator 2, improved self-evolution operator, gradient descent update operator, Gauss and Cauchy variational operator, and random traceless Sigma variational operator are applied to form an operator library. A dominant operator dynamic following mechanism is proposed to assign these six operators to the two populations in an optimal pairing scheme. Both populations and operators compete with each other, and the advantages of all operators are fully utilized. Moreover, the combination of diverse operators and dominant operator dynamic following mechanism can effectively balance the exploration and exploitation of TATAD. The performance of TATAD is compared with four AT algorithms and six efficient algorithms through typical test functions, and their results are bested by Wilcoxon rank sum test (WRST) and Friedman ranking test. It is found that TATAD is the most competitive algorithm among these algorithms for solving these optimization problems.},
  archive      = {J_SOCO},
  author       = {Xiao, Yaping and Niu, Linfeng and Li, Qiqi},
  doi          = {10.1007/s00500-025-10445-x},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2075-2106},
  shortjournal = {Soft Comput.},
  title        = {A two-population artificial tree algorithm based on adaptive updating strategy for dominant populations},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bi-objective multi-warehouse multi-period order picking system under uncertainty: A benders decomposition approach. <em>SOCO</em>, <em>29</em>(4), 2047-2074. (<a href='https://doi.org/10.1007/s00500-025-10495-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In warehouse management order picking is one of the key operations that incur high costs as well as one of the most complex tasks. It comprises the construction of order batches, batch assignment, picker routes, and scheduling of pickers. Therefore, the development of an efficient order picking system and the optimization of these operations have significant effects on the overall efficiency of the warehouse. This paper focuses on studying and modeling the order batching, batch assignment, and picker routing problems in a multi-warehouse, multi-period, multi-picker order picking system. We propose a multi-objective mathematical model for minimizing the delivery times of batches and the total cost of order picking operations. Also, for the first time, a possibilistic approach is applied to overcome uncertain conditions in the order picking problem. Given the complexity of the problem, Benders decomposition is implemented to solve the proposed model. The applicability of the proposed method is evaluated through a range of small to large test problems and an actual case study. The results indicate that the proposed exact method is capable of finding high-quality solutions within a reasonable computational time and number of iterations, which serves as evidence of its suitability for large-scale, complex real-world industrial contexts.},
  archive      = {J_SOCO},
  author       = {Nikkhoo, Fatemeh and Husseinzadeh Kashan, Ali and Nikbakhsh, Ehsan and Ostadi, Bakhtiar},
  doi          = {10.1007/s00500-025-10495-1},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2047-2074},
  shortjournal = {Soft Comput.},
  title        = {A bi-objective multi-warehouse multi-period order picking system under uncertainty: A benders decomposition approach},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel instance density-based hybrid resampling for imbalanced classification problems. <em>SOCO</em>, <em>29</em>(4), 2031-2045. (<a href='https://doi.org/10.1007/s00500-025-10499-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class imbalance problem is one of the challenging issues in various machine learning applications. This problem occurs when the number of instances of a class is much smaller (or larger) than those of the other classes. To handle the imbalanced classification problems, many useful approaches have been developed, for example, synthetic minority oversampling technique (SMOTE). However, the SMOTE is often sensitive to the predetermined $$k$$ value, i.e., the number of nearest neighbors used to generate the synthetic instances. For example, if the $$k$$ value is moderately large, some of the synthetic instances generated by the SMOTE would be located near a decision boundary or even within the majority class area and thus these can be treated as unnecessary noisy instances. Thus, in this study, we propose an efficient hybrid resampling method based on instance density called IDHR (Instance Density-based Hybrid Resampling) to improve the classification performance by generating instances that are closer to the minority class than the majority class while avoiding generation of noisy instances. For this, we first apply the instance density-based oversampling (IDO) technique to generate new synthetic instances. And then, we eliminate some of the synthetic instances that are close to the decision boundary and determine the number of the synthetic instances among the retained synthetic ones which can be eliminated based on maximum of the distances from all the synthetic instances to the minority class instances and minimum of the distances from all the synthetic instances to the majority class instances as well as classification performances. To demonstrate the effectiveness of the proposed resampling method, comprehensive experiments are conducted on sixteen imbalanced datasets with considering three classifiers, i.e., C4.5 decision tree algorithm, support vector machine (SVM), and multi-layer perceptron neural network (MLP-NN). Through the experimental analysis, it is shown that the proposed resampling method outperforms the traditional oversampling methods with respect to AUC and F-measure for most of the imbalanced datasets regardless of classifiers.},
  archive      = {J_SOCO},
  author       = {Park, You-Jin and Ma, Chung-Kang},
  doi          = {10.1007/s00500-025-10499-x},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2031-2045},
  shortjournal = {Soft Comput.},
  title        = {A novel instance density-based hybrid resampling for imbalanced classification problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cyber-attack detection based on a deep chaotic invasive weed kernel optimized machine learning classifier in cloud computing. <em>SOCO</em>, <em>29</em>(4), 2015-2030. (<a href='https://doi.org/10.1007/s00500-025-10521-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, Cloud Computing has attracted a lot of interest from both individual users and organization. However, cloud computing applications face certain security issues, such as data integrity, user privacy, and service availability. The only better solution to such issues is to identify and prevent cyber threats before they can cause seriously harm the cloud computing system. Several methods have been suggested so far to detect the attack in cloud computing (CC), but no one method attains satisfactory results. To overwhelm these drawbacks, a Cyber Security Attack Detection using Deep Kernel Machine Learning optimized with Chaotic Invasive Weed Optimization algorithm is proposed in this paper for Cloud Computing. Here, the data is amassed from CSE-CIC-IDS2018 and Bot-IoT datasets. Subsequently, a pre-processing step involving redundancy reduction and missing value replacement for uncertainty removal is achieved through the Developed Random Forest with Local Least Squares (DRFLLS) method. By utilizing Entropy-Kurtosis based feature selection approach, the pre-processing data is given to the feature selection to identify the optimal features. The selected features are supplied to the Deep Kernel Machine Learning classifier (DK-ML), which is optimized using the Chaotic Invasive Weed Optimization algorithm (Chaotic-IWOA) for classification. This classification process classifies the data as normal or anomalous categories with anomalies encompassing, like DoS, DDoS, Theft attacks, and normal attacks. The proposed technique is activated in MATLAB. The proposed technique achieves 24.88%, 17.98%, 45.65%, 35.95% better accuracy for CSE-CIC-IDS2018 dataset, and 23.93%, 13.94%, 32.94%, and 29.04% better accuracy for Bot-IoT dataset.},
  archive      = {J_SOCO},
  author       = {Indrasena Reddy, M. and Siva Kumar, A. P. and Subba Reddy, K.},
  doi          = {10.1007/s00500-025-10521-2},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2015-2030},
  shortjournal = {Soft Comput.},
  title        = {Cyber-attack detection based on a deep chaotic invasive weed kernel optimized machine learning classifier in cloud computing},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring diversity and time-aware recommendations: An LSTM-DNN model with novel bidirectional dynamic time warping algorithm. <em>SOCO</em>, <em>29</em>(4), 2003-2013. (<a href='https://doi.org/10.1007/s00500-025-10534-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of the Web 3.0 era, the amount and types of data in the network have sharply increased, and the application scenarios of recommendation algorithms are continuously expanding. Location recommendation has gradually become one of the popular application scenarios in recommendation algorithms. Traditional recommendation algorithms not only ignore the temporal attribute of data when recommending information to users, but also blindly pursue the recommendation accuracy, which will cause certain “information cocoon room” problems. Therefore, this article treats user historical data as a time series and proposes an LSTM-DNN model based on the novel bidirectional Dynamic Time Warping (DTW) algorithm. Firstly, in response to the issue of different users consuming different amounts of information, this article proposes a novel bidirectional DTW algorithm to calculate the similarity between different users. Secondly, this article supplements the user dataset from three perspectives: “utilization” and “exploration” of information, and spatiotemporal attributes of data, which alleviates the problem of data sparsity and cold start in the dataset to a certain extent. Moreover, it effectively enhances the diversity of recommendation results. Finally, this paper constructs an Long Short-Term Memory-Deep Neural Networks (LSTM-DNN) to dynamically obtain user interests and preferences, and proposes a new metric Cumulative Self-System Diversity (CSSD) to measure the diversity of algorithm recommendation results. Experiments have shown that the model effectively enhances the diversity of recommendation results while ensuring recommendation accuracy.},
  archive      = {J_SOCO},
  author       = {Li, Te and Chen, Liqiong and Sun, Huaiying and Hou, Mengxia and Lei, Yunjie and Zhi, Kaiwen},
  doi          = {10.1007/s00500-025-10534-x},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2003-2013},
  shortjournal = {Soft Comput.},
  title        = {Exploring diversity and time-aware recommendations: An LSTM-DNN model with novel bidirectional dynamic time warping algorithm},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted rank aggregation based on ranker accuracies for feature selection. <em>SOCO</em>, <em>29</em>(4), 1981-2001. (<a href='https://doi.org/10.1007/s00500-025-10530-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rank aggregation is the combination of several ranked lists from a set of candidates to achieve a better ranking by combining information from different sources. In feature selection problem, due to the heterogeneity of methods, there are some base rankers (Filter-based methods) that are of diverse quality and usually the ground truth of ratings is not available. Existing rank aggregation methods that take the diverse quality of base rankers into account do not have any explicit approach for appropriate weighting, require prior assumptions, and suffers from high computational complexity. In this paper, to overcome these challenges, an efficient unsupervised method is introduced for estimating the base rankers’ qualities and aggregating the rankers based on the estimated weights. We first compute the ratio of disagreement between base rankers in ordering different element pairs and then estimate the accuracies in a way that to minimize the discrepancy between these computed ratios and their analytical counterparts. We use the weighted majority voting method for obtaining the aggregated results. To resolve the probable inconsistencies in the final aggregation, the result is formed as a graph, and a greedy algorithm is used to find an acyclic subgraph with the highest weigh. To demonstrate the performance of the proposed method, nine standard UCI datasets are used. The obtained results by the proposed method have higher values of classifier measures than the existing baseline Feature Selection methods and rank aggregation-based multi-filter methods in the most datasets. The experiments show that rank aggregation-based Feature Selection methods outperform individual methods. The proposed method also shows the weight of each Filter-based Feature Selection method, in which the MRMR method has a higher weight than other methods.},
  archive      = {J_SOCO},
  author       = {Abdolrazzagh-Nezhad, Majid and Kherad, Mahdi},
  doi          = {10.1007/s00500-025-10530-1},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {1981-2001},
  shortjournal = {Soft Comput.},
  title        = {Weighted rank aggregation based on ranker accuracies for feature selection},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complex preference analysis: A score-based evaluation strategy for ranking and comparison of the evolutionary algorithms. <em>SOCO</em>, <em>29</em>(4), 1967-1980. (<a href='https://doi.org/10.1007/s00500-025-10525-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an evaluation strategy is proposed for evaluation of optimization algorithms, called the Complex Preference Analysis, that assesses the efficiency of different evolutionary algorithms by considering multiple performance metrics concurrently across diverse dimensions and generating a single score for ranking. The proposed strategy allows for a thorough evaluation by assigning distinct priorities in the form of weights, to various performance parameters. The algorithm’s performances on each performance parameter are captured and the best and worst performances in each performance category are identified. The deviation of each algorithm from the best and worst performances in the respective performance category is formulated to generate a single score for each of the algorithms for comparison. The flexibility to adjust weights provides a valuable tool for customizing evaluations according to individual needs and preferences. The proposed evaluation strategy is studied by running evaluations on nine evolutionary algorithms based on their performance over five performance indicators on six datasets of the Travelling Salesman Problem. Conducting Complex Preference Analysis on the different evolutionary algorithms reveals distinctive patterns in their performance, with some algorithms such as Simulated Annealing, Tabu Search, Bat Algorithm, Genetic Algorithm, etc. consistently demonstrating superior results across multiple Travelling Salesman Problem instances, while other algorithms such as Ant Colony Optimization, Teaching Learning Based Optimization, etc. rank lower. The algorithms’ performances on individual performance parameters, when reflected on the final rank of the algorithms, generated based on the collective impact of all the parameters, elucidate the efficiency of the proposed evaluation strategy.},
  archive      = {J_SOCO},
  author       = {Sarkar, Debojyoti and Biswas, Anupam},
  doi          = {10.1007/s00500-025-10525-y},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {1967-1980},
  shortjournal = {Soft Comput.},
  title        = {Complex preference analysis: A score-based evaluation strategy for ranking and comparison of the evolutionary algorithms},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A map-reduce algorithm to find strongly connected components of directed graphs. <em>SOCO</em>, <em>29</em>(4), 1947-1966. (<a href='https://doi.org/10.1007/s00500-025-10451-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks have become ubiquitous platforms, comprising intricately linked structures that reflect complex user interactions. Analyzing the interconnected component structure of these large directed graphs is pivotal for critical applications like viral marketing and contagion prediction. This paper presents a parallel algorithm to efficiently discover strongly connected components in massive social graphs by distributing computation across clustered servers. Our proposed distributed approach conducts localized connected component extraction during the Map phase. The merged aggregation in the Reduce phase then uncovers global maximum interconnected sets spanning the fragmented structures. We employ mathematical induction across Map-Reduce stages to demonstrate the algorithm’s correctness for obtaining exhaustive component enumeration across servers. Implementation and complexity analysis on synthetic benchmark graphs highlight significant efficiency gains, with the algorithm demonstrating near-linear speedup for increasing data-set and cluster sizes. The proposed technique advances the state-of-the-art for extracting strongly connected structures from colossal real-world social networks, enabling actionable insights around influence cascades and contagion pathways underlying these intricate linkage patterns.},
  archive      = {J_SOCO},
  author       = {Ji, Fujun and Jin, Jidong},
  doi          = {10.1007/s00500-025-10451-z},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {1947-1966},
  shortjournal = {Soft Comput.},
  title        = {A map-reduce algorithm to find strongly connected components of directed graphs},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving recurrent deterministic policy gradient strategy in autonomous driving. <em>SOCO</em>, <em>29</em>(3), 1931-1946. (<a href='https://doi.org/10.1007/s00500-025-10442-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Even though autonomous driving has emerged as a prominent study topic, the conventional control systems for autonomous driving are often rule-based and need to be more adaptable to the flow and conditions of traffic that change over time. Recurrent deterministic policy gradient (RDPG) is a strategy for building autonomous driving control systems. Its performance has been shown to be better than some other methods. Consequently, in this study, we make use of the RDPG algorithm to implement our control strategies as well and further give more comprehensive considerations to the learning procedure to obtain better control performance in the testing procedure, e.g., various punishments to avoid vehicle collisions, different speed limitations to avoid slow-driving or fast-driving, distinct rewards to encourage the ego-vehicle to reach the destination, and so on. On the other hand, we also improve the training performance by focusing solely on the critical events during the training procedure. Namely, our training architecture is more efficient based on the same training time (training steps). The road scene and vehicular simulator, AirSim, has been selected as the experimental platform. The findings indicate that our design achieves more accurate and steady outcomes in control and faster convergence in learning compared to an existing RDPG control strategy for autonomous driving in the literature.},
  archive      = {J_SOCO},
  author       = {Ooi, Yee-Ming and Chang, Che-Cheng},
  doi          = {10.1007/s00500-025-10442-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1931-1946},
  shortjournal = {Soft Comput.},
  title        = {Improving recurrent deterministic policy gradient strategy in autonomous driving},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of discharge coefficient of submerged gates using a stacking ensemble model. <em>SOCO</em>, <em>29</em>(3), 1911-1929. (<a href='https://doi.org/10.1007/s00500-025-10518-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the precision of discharge coefficient (Cd) prediction is crucial for effective agricultural water management. However, existing methods for Cd calculation are often complex and dependent on specific assumptions. Therefore, there is a critical need for robust and automated models for Cd estimation. This study introduces a dual-stage ensemble model called EnsembleCNN, for Cd prediction using two distinct gate types under submerged flow conditions. The EnsembleCNN framework uniquely integrates machine learning (ML) models with a recurrent convolutional neural network (CNN) model to capture higher-order interactions and non-linearities. Five base ML models are employed to generate initial predictions. These predictions are subsequently processed by a CNN model embedded with long short-term memory (LSTM) layer, residual connection (RC) and an attention mechanism (ATM). This setup effectively manages the complexity of the combined predictions, seamlessly integrating the outputs from the base models. LSTM is exploited to aggregate the best features for prediction. ATM effectively prioritized high-performing base model outputs, while RC improved the gradient flow, collectively reducing the impact of irrelevant features. The proposed approach strategically weights the contributions of each base model, resulting in accurate Cd estimations. The proposed model achieved root mean square errors of 0.0552 and 0.0173 on vertical sluice gates and radial gates datasets, respectively. Additionally, EnsembleCNN outperformed the base and existing models in terms of prediction accuracy. The proposed system provides a robust tool for optimizing water resource management. Moreover, the adaptability to two field datasets further underscores the practical utility of our model in diverse irrigation scenarios.},
  archive      = {J_SOCO},
  author       = {Hosny, Mohamed and Abdelhaleem, Fahmy S. and Elshenhab, Ahmed M. and Ibrahim, Amir},
  doi          = {10.1007/s00500-025-10518-x},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1911-1929},
  shortjournal = {Soft Comput.},
  title        = {Prediction of discharge coefficient of submerged gates using a stacking ensemble model},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label-specific multi-label text classification based on dynamic graph convolutional networks. <em>SOCO</em>, <em>29</em>(3), 1897-1909. (<a href='https://doi.org/10.1007/s00500-025-10446-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label text classification is a key task in natural language processing, aiming to assign each text to multiple predefined categories simultaneously. Existing neural network models usually learn the same text representation for different labels, which limits the effectiveness of the models in capturing deep semantics and distinguishing between similar labels; moreover, these models tend to ignore inter-label correlation, leading to loss of information. To overcome these limitations, we propose a novel label-specific dynamic graph convolutional network (LDGCN). This network combines convolutional operations and BiLSTM to model text sequences and obtains label-specific text representations through a label attention mechanism. In addition, LDGCN improves the dynamic graph convolutional network by utilizing statistical label co-occurrence and label reconstruction maps to effectively capture inter-label dependencies and adaptive interactions between label-specific semantic components. Extensive experiments on the RCV1, AAPD, and EUR-Lex datasets show that our model achieves 96.92%, 86.30%, and 81.42% on the P@1 metrics, respectively, and demonstrates a significant advantage in dealing with tail labels.},
  archive      = {J_SOCO},
  author       = {Yan, Yaoyao and Liu, Fang‘ai and Liu, Kenan and Xu, Weizhi and Zhuang, Xuqiang},
  doi          = {10.1007/s00500-025-10446-w},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1897-1909},
  shortjournal = {Soft Comput.},
  title        = {Label-specific multi-label text classification based on dynamic graph convolutional networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Threats to medical diagnosis systems: Analyzing targeted adversarial attacks in deep learning-based COVID-19 diagnosis. <em>SOCO</em>, <em>29</em>(3), 1879-1896. (<a href='https://doi.org/10.1007/s00500-025-10516-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep and machine learning models have become pivotal in medical image analysis, especially for diagnosing COVID-19 using X-rays and CT scans. While these models, including transfer learning-based approaches, have achieved high accuracy, they remain highly vulnerable to adversarial attacks, which can manipulate input data and cause misclassification, posing critical risks in clinical applications. This study introduces a novel approach to addressing this issue by systematically evaluating the impact of adversarial attacks on COVID-19 diagnosis models built with two leading architectures, VGG-16 and DenseNet-121, using the Fast Gradient Sign Method (FGSM). The FGSM attack causes a dramatic drop in accuracy, reducing VGG-16’s accuracy from 95.12 to 9.97% and DenseNet-121’s from 96.51 to 10.13%. To counter these vulnerabilities, we propose a novel defense mechanism that combines adversarial training with Gaussian noise data augmentation, a dynamic approach that generates perturbations across various epsilon values during the training phase. This innovative method significantly enhances model robustness, restoring accuracy to over 92% on adversarial examples. These findings emphasize the need for strong defense mechanisms in deep learning models for COVID-19 diagnosis, ensuring reliability and security against adversarial threats in clinical environments.},
  archive      = {J_SOCO},
  author       = {Haque, Sheikh Burhan Ul and Zafar, Aasim and Haq, Sheikh Riyaz Ul and Haque, Sheikh Moeen Ul and Ahmad, Mohassin and Roshan, Khushnaseeb},
  doi          = {10.1007/s00500-025-10516-z},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1879-1896},
  shortjournal = {Soft Comput.},
  title        = {Threats to medical diagnosis systems: Analyzing targeted adversarial attacks in deep learning-based COVID-19 diagnosis},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive multimodal approach for parkinson’s disease classification using artificial intelligence: Insights and model explainability. <em>SOCO</em>, <em>29</em>(3), 1845-1877. (<a href='https://doi.org/10.1007/s00500-025-10463-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD) is a debilitating neurodegenerative disorder affecting millions worldwide. Early detection is vital for effective management, yet remains challenging. In this study, we investigated four distinct datasets for PD detection. Through comprehensive experimentation employing ensemble methods and feature selection, we achieved high classification accuracies across the datasets. For the Oxford Parkinson’s Disease Detection Dataset, an accuracy of 95.67%, precision of 97.59%, recall of 84.5%, specificity of 99.32%, and F1-score of 90.57% were achieved. For the Alzheimer Parkinson Diseases 3 Class Dataset, the “Stacking” approach surpasses individual models, reaching an accuracy of 99.85%, precision of 99.81%, recall of 99.81%, specificity of 99.86%, and F1 of 99.81%. For the NewHandPD dataset, Regarding the Spiral category, The “Base-P32-384” model surpasses others with an accuracy of 97.35%, precision of 96.50%, recall of 98.57%, and F1-score of 97.53%. The collective “Stacking” approach proves highly effective regarding the Circle category, achieving 100% across all performance metrics. Regarding the Meander category, the “Base-P16-224” model achieves an accuracy of 97.35%, precision of 99.26%, recall of 95.71%, specificity of 99.19%, and F1 of 97.45%. The Mobile Device Voice Recordings at King’s College London (MDVR-KCL) dataset contains two datasets. Regarding the “SpontaneousDialogue” dataset, accuracy, BAC, precision, recall, specificity, and F1-score were computed, resulting in values of 94.03%, 92.83%, 90.78%, 100.0%, and 85.67%, respectively. Regarding the “ReadText” dataset, accuracy, BAC, precision, recall, specificity, and F1-score were computed, resulting in values of 91.89%, 90.62%, 87.5%, 100.0%, and 81.25%, respectively. Our findings highlight the efficacy of leveraging diverse data sources and advanced machine learning techniques to enhance PD detection accuracy.},
  archive      = {J_SOCO},
  author       = {Balaha, Hossam Magdy and Hassan, Asmaa El-Sayed and Ahmed, Rawan Ayman and Balaha, Magdy Hassan},
  doi          = {10.1007/s00500-025-10463-9},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1845-1877},
  shortjournal = {Soft Comput.},
  title        = {Comprehensive multimodal approach for parkinson’s disease classification using artificial intelligence: Insights and model explainability},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing neural network predictions with finetuned numeric embeddings for stock trend forecasting. <em>SOCO</em>, <em>29</em>(3), 1829-1844. (<a href='https://doi.org/10.1007/s00500-025-10483-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The financial markets, particularly stock trading, offer a variety of profit-generating opportunities based on complex and volatile behaviour. Investors seek strategies to maximise returns, leading to an investigation of inherent market patterns. Converting OHLC (Open, High, Low, Close) data into transformers-based pre-trained language model compatible text is an innovative method for representing numeric data. Extending the language model’s utility to integrate stock market numeric time-series data incorporates its inherent numeracy in embeddings. Raw data are converted into a format compatible with the pre-trained language model through preprocessing and text templates. Using an ensemble of Bidirectional Encoder Representations from Transformers (BERT), FinBERT (BERT finetuned with the financial corpus), FLANG-BERT (BERT finetuned with the financial corpus) and FLANG-ELECTRA (ELECTRA finetuned with the financial corpus) as feature extractor, historical stock market data are utilised to generate an embedding matrix and fused with established neural network architectures, such as Backpropagation Neural Network (BPNN), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU), to predict stock market trends. The simulation results demonstrate that the proposed integrated approach is preferable to previous methodologies. The significance of the findings is confirmed by statistical validation using the Wilcoxon signed-rank test (p value < 0.01). This study offers a promising approach for improving stock market trend prediction by integrating the ensemble of language model-based numeric embeddings with neural networks.},
  archive      = {J_SOCO},
  author       = {Trivedi, Avinash and Sangeetha, S.},
  doi          = {10.1007/s00500-025-10483-5},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1829-1844},
  shortjournal = {Soft Comput.},
  title        = {Enhancing neural network predictions with finetuned numeric embeddings for stock trend forecasting},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A game-theoretic exploration with surplus profit-sharing in a three-channel supply chain, featuring e-commerce dynamics. <em>SOCO</em>, <em>29</em>(3), 1811-1827. (<a href='https://doi.org/10.1007/s00500-025-10453-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a three-channel supply chain, coordination can be challenging especially when a manufacturer has to work with a retailer and an online platform. In such a scenario, sales efforts can be critical to the success of the supply chain. However, there is a risk of free riding behavior by either the retailer or the manufacturer, which can lead to suboptimal sales performance. This article will explore the centralized and the decentralized models by the use of game theory (Nash and Stackelberg) and eventually tries to coordinate the three-channel supply chain with the help of Operational Research (OR) to optimize the decision-making and create a win–win situation. Numerical examples are provided to prove the efficiency of the presented models. Finally, the models are evaluated through sensitivity analysis, and managerial insights are provided to enhance the applicability of the models for coordinating a three-channel supply chain.},
  archive      = {J_SOCO},
  author       = {Vatanara, Maryam and Rabbani, Masoud and Heydari, Jafar},
  doi          = {10.1007/s00500-025-10453-x},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1811-1827},
  shortjournal = {Soft Comput.},
  title        = {A game-theoretic exploration with surplus profit-sharing in a three-channel supply chain, featuring e-commerce dynamics},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forest fire rescue framework to jointly optimize firefighting force configuration and facility layout: A case study of digital-twin simulation optimization. <em>SOCO</em>, <em>29</em>(3), 1789-1810. (<a href='https://doi.org/10.1007/s00500-025-10434-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the pre-prevention stage, firefighting force configuration and facility layout play a critical role in reducing fire extinguishing time (FET) during the early-stage forest fire rescue. It is acknowledged that there is a scarcity of quantitative evaluation research establishing a connection between observed forest fire behaviors and pre-prevention research. Therefore, we propose a forest fire rescue framework to jointly optimize firefighting force configuration and facility layout. As an iterative optimization framework based on fire spread and suppression model (FSSM), firefighting force configuration and facility layout methods use differential-evolution-based algorithm and deep neural network to adjust the configuration funds of various firefighting forces and plan the spatial layout of multiple firefighting facilities. With iterations increasing, the proposed method can continue to find better solutions than before. Moreover, through the offensive and defensive procedures in FSSM, the best configuration and layout solution can mirror multi-rescue-resource interactions and mutual restraints. The performance of the proposed framework is validated through various maps and experiments in terms of FET, forest burned area, and uncontrolled fire rate, even under extreme wind-speed pressure conditions. This implies that the proposed framework demonstrates favorable adaptability. Furthermore, the proposed framework can be introduced into the related dynamic interactions and constraints optimization scenarios (e.g., smart factories, smart construction sites, and more), thereby opening the door of digital-twin simulation optimization.},
  archive      = {J_SOCO},
  author       = {Zhang, HongGuang and Ma, ShengWen and Li, Xiang and You, MingCan and Tao, YuXuan},
  doi          = {10.1007/s00500-025-10434-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1789-1810},
  shortjournal = {Soft Comput.},
  title        = {Forest fire rescue framework to jointly optimize firefighting force configuration and facility layout: A case study of digital-twin simulation optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient collocation algorithm for third order non-linear Emden–Fowler equation. <em>SOCO</em>, <em>29</em>(3), 1767-1788. (<a href='https://doi.org/10.1007/s00500-025-10431-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study presents a novel algorithm for solving third-order non-linear equations (Emden–Fowler type), which can be applied to various physical models. The algorithm uses a quintic trigonometric B-spline collocation method and a quasilinearization technique to avoid the non-linearity term in the equation. The study established a comprehensive error analysis for the proposed algorithm and proved that it has fourth order, i.e., $$(\mathscr {O}(h^4))$$ convergent. The algorithm’s ability to handle singular behavior at the point $$x=0$$ and its faster rate of convergence exhibit a promising approach to solving such problems. The study also validates the theoretical results through numerical experiments and shows that the proposed algorithm has a faster rate of convergence in comparison to the existing methods.},
  archive      = {J_SOCO},
  author       = {Alam, Mohammad Prawesh and Khan, Arshad},
  doi          = {10.1007/s00500-025-10431-3},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1767-1788},
  shortjournal = {Soft Comput.},
  title        = {An efficient collocation algorithm for third order non-linear Emden–Fowler equation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A feature extraction method for rotating machinery fault diagnosis based on a multiscale entropy fusion strategy and GA-RL-LDA model. <em>SOCO</em>, <em>29</em>(3), 1747-1765. (<a href='https://doi.org/10.1007/s00500-025-10484-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problems of information loss, feature redundancy and unsatisfactory diagnosis accuracy when using traditional multiscale entropy methods and feature reduction methods to diagnose rotating machinery faults, a feature extraction method based on a multiscale entropy fusion strategy and a GA-RL-LDA model is proposed in this paper. Firstly, the multiscale fluctuation dispersion entropy (MFDE), the refined composite multiscale dispersion entropy (RCMDE) and the refined composite multiscale fluctuation dispersion entropy (RCMFDE) of the collected vibration signal are calculated to form an original feature set. Then, based on the ReliefF algorithm and Laplacian score (LS), an RL index is constructed for feature sensitivity evaluation. After that, combing the RL with Linear discriminant analysis (LDA) and using genetic algorithm (GA) to optimize the uncertain parameters, a GA-RL-LDA model is proposed for feature reduction. Finally, the reduced feature subset is input into support vector machine (SVM) for fault classification. The experiment utilized data from Unit 3 of the SK Hydropower Station and bearing data from Case Western Reserve University, achieving diagnostic accuracies of 95.2381% and 97.3333%, respectively. In the 105 test samples from Unit 3 of the SK Hydropower Station, only 5 samples were misclassified, while in the 150 test samples from Case Western Reserve University, only 4 samples were misclassified. Compared with different information entropy and optimization strategies, the results show that the proposed method can more effectively extract fault sensitive features and accurately diagnose rotating machinery faults even with a small number of training samples.},
  archive      = {J_SOCO},
  author       = {Lu, Na and Li, Zhongliang and Liu, Dong and Cao, Chaofan and Jiang, Shuangyun and Chen, Xudong and Wang, Peng},
  doi          = {10.1007/s00500-025-10484-4},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1747-1765},
  shortjournal = {Soft Comput.},
  title        = {A feature extraction method for rotating machinery fault diagnosis based on a multiscale entropy fusion strategy and GA-RL-LDA model},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning approach to analyse stress by using voice and body posture. <em>SOCO</em>, <em>29</em>(3), 1719-1745. (<a href='https://doi.org/10.1007/s00500-025-10441-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current scenario, where we can see young people struggling for their careers, they are even fighting a battle with their stress and tension. None of their work is done without stress to complete their task and compete with others. To overcome stress, one should have good emotional intelligence to cope with emotions and any upcoming stress. But at some point, due to lack of guidance, some people don’t know how to analyze the situations and how to handle them without taking the stress and end up with anxiety, depression, disappointment, suicide, heart attack, stroke etc. Due to the advancement of Human–Computer Interaction (HCI), medical science has leveled up to another peak. Machine Learning and Deep Learning played a major role in such interactions and predictions. Many applications have been developed in past years based on machine learning and deep learning. One of those applications is related to psychology and is still in research. These applications can be used for emotion and stress analysis among people, especially youngsters. Research in this field is being conducted using various verbal and non-verbal parameters. This paper addresses the research problem of improving emotion recognition accuracy and robustness to better analyze and manage stress. The primary objective is to develop an advanced Emotion Recognition System (ERS) that leverages deep learning algorithms to analyses both verbal and non-verbal cues—specifically, speech and body posture, including facial expressions. We have further integrated it with the Flask web framework to make an Emotion Recognition System that takes input in the form of video and audio to analyze Emotions and Stress. We have also compared our proposed ERS with existing ones and found that our ERS gives better results.},
  archive      = {J_SOCO},
  author       = {Gupta, Sumita and Gambhir, Sapna and Gambhir, Mohit and Majumdar, Rana and Shrivastava, Avinash K. and Pham, Hoang},
  doi          = {10.1007/s00500-025-10441-1},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1719-1745},
  shortjournal = {Soft Comput.},
  title        = {A deep learning approach to analyse stress by using voice and body posture},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced TOPSIS-CoCoSo framework for multi-attribute decision-making with triangular fuzzy neutrosophic sets: “effect evaluation of intelligent technology empowering physical education teaching” case. <em>SOCO</em>, <em>29</em>(3), 1703-1717. (<a href='https://doi.org/10.1007/s00500-025-10411-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The history of human education development has proven that there is an interactive relationship between technological development and education and teaching. In the process of promoting education modernization and high-quality development, the widespread application of intelligent technology in the field of education is the trend, and intelligence is driving profound transformation and transformation in the field of education. The effect evaluation of intelligent technology empowering Physical Education teaching could be considered as multiple-attribute decision-making (MADM). Recently, the TOPSIS technique and Combined Compromise Solution (CoCoSo) technique was employed to deal with MADM. The triangular fuzzy neutrosophic sets (TFNSs) are employed as a better tool for expressing uncertain information during the effect evaluation of intelligent technology empowering Physical Education teaching. In this paper, the triangular fuzzy neutrosophic number TOPSIS-CoCoSo (TFNN-TOPSIS-CoCoSo) technique based on the TFNN relative closeness coefficient (TFNNRCC) technique is managed to cope with the MADM under TFNSs. The information entropy technique is employed to manage the weight values based on the TFNNRCC under TFNSs. Finally, a numerical example of effect evaluation of intelligent technology empowering Physical Education teaching is managed and some better comparisons are managed to verify the TFNN-TOPSIS-CoCoSo technique. The main contribution of this paper is outlined: (1)TFNN-TOPSIS-CoCoSo technique based on the TFNNRCC is constructed; (2) Entropy technique is employed to manage weight based on the TFNNRCC under TFNSs. (3) TFNN-TOPSIS-CoCoSo technique is founded to manage the MADM based on the TFNNRCC under TFNSs; (4) numerical example for effect evaluation of intelligent technology empowering Physical Education teaching and some comparative analysis is supplied to verify the proposed TFNN-TOPSIS-CoCoSo technique.},
  archive      = {J_SOCO},
  author       = {Xiao, Jie and Zhang, Yu},
  doi          = {10.1007/s00500-025-10411-7},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1703-1717},
  shortjournal = {Soft Comput.},
  title        = {Enhanced TOPSIS-CoCoSo framework for multi-attribute decision-making with triangular fuzzy neutrosophic sets: “effect evaluation of intelligent technology empowering physical education teaching” case},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lacunary statistical soft convergence in soft topology. <em>SOCO</em>, <em>29</em>(3), 1691-1701. (<a href='https://doi.org/10.1007/s00500-025-10479-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical convergence and some related types of convergence are a generalisation of topological convergence. Similarly, soft set theory, introduced by Molodtsov to deal with uncertainty in various scientific fields, is a generalisation of the classical concept of sets. Although both concepts have found extensive applications to various mathematical structures, the investigation of statistical convergence within soft topological spaces has not yet been undertaken. This study examines the lacunary statistical convergence of sequences of soft points in soft topological spaces, employing a density defined by an unbounded modulus function. Basic results and inclusion theorems concerning this convergence are presented.},
  archive      = {J_SOCO},
  author       = {Bayram, Erdal and Dervişoğlu, Melisa},
  doi          = {10.1007/s00500-025-10479-1},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1691-1701},
  shortjournal = {Soft Comput.},
  title        = {Lacunary statistical soft convergence in soft topology},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). K-InfNode: Ranking top-k influential nodes in complex networks with random walk. <em>SOCO</em>, <em>29</em>(3), 1677-1690. (<a href='https://doi.org/10.1007/s00500-025-10471-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A complex network is a symbolic representation of distinct real-world systems where information propagates through nodes. Its goal is to identify communities that represent the network’s structure. However, locating the influential node with the maximal range among various nodes and the ability to disseminate influence to a wide portion of the network is one of the most essential concerns in such a network. Centrality is a traditional metric for understanding the effect of nodes in a network, with numerous variants such as closeness, betweenness, degree centrality, and so on. The centrality metrics either work locally or globally to identify influential nodes. In this study, a proposed algorithm named k-InfNode, based on the characteristics of community structure, captures the dynamics of nodes. k-InfNode uses a random walk and combines local and global properties to figure out which nodes are important in a complex network. It was inspired by the idea of overlapping nodes that show how nodes and communities interact with each other across the network. In the beginning, the fuzzy c-means algorithm finds the overlapping nodes in the network. Next, the algorithm assigns an initial score to each node based on node and community information, and iteratively scores each node using the Random Walk with Restart (RWR) algorithm. Experiments performed using real and artificial networks have shown that the k-InfNode is effective.},
  archive      = {J_SOCO},
  author       = {Hasan, Ahmadi and Kamal, Ahmad and Kumar, Pawan},
  doi          = {10.1007/s00500-025-10471-9},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1677-1690},
  shortjournal = {Soft Comput.},
  title        = {K-InfNode: Ranking top-k influential nodes in complex networks with random walk},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A micro-level approach for modeling rumor propagation in online social networks. <em>SOCO</em>, <em>29</em>(3), 1667-1675. (<a href='https://doi.org/10.1007/s00500-025-10456-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks have become the major platforms for information dissemination in recent years. However, rapid propagation of rumors in these networks as a special form of information can greatly influences social lives. Hence, work on rumor propagation models and analysis is under great attention by the research communities. Previously, researchers have proposed various models to explore the dynamics of rumor propagation and analyze steady-state. However, most of them did not consider people’s behavior differences in the spreading or opposing rumor. To overcome this limitation, we assume that individuals have different probability of spreading rumor, spreading anti-rumor and stifling. In this paper we introduce a new model for rumor propagation in social networks considering these differences at micro-level. The proposed model which considered both types of rumor and anti-rumor messages on people decision is an agent-based model in terms of probabilistic automata network. To evaluate the proposed model, we conduct a number of Monte-Carlo simulation experiments on Barabasi-Albert model of social networks that show the accuracy of the proposed model. We also conduct interesting sensitivity analysis to see the effects of different model parameters on the dynamics of the rumor propagation.},
  archive      = {J_SOCO},
  author       = {Sahafizadeh, Ebrahim and Talatian Azad, Saeed},
  doi          = {10.1007/s00500-025-10456-8},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1667-1675},
  shortjournal = {Soft Comput.},
  title        = {A micro-level approach for modeling rumor propagation in online social networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Paw decompositions of diamond and some edge cycle graphs. <em>SOCO</em>, <em>29</em>(3), 1659-1665. (<a href='https://doi.org/10.1007/s00500-025-10541-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let $${C}_{n}, {K}_{n},{W}_{n},{K}_{r,s}$$ denote a cycle, complete graph, wheel graph, complete bipartite graph respectively. An edge cycle graph of a graph $$G$$ is the graph $$G({C}_{k})$$ formed from one copy of $$G$$ and $$|E(G)|$$ copies of $${P}_{k},$$ where t he ends of the $${i}^{th}$$ edge are identified with the ends of $${i}^{th}$$ copy of $${P}_{k}$$ . In this article, we determine the necessary and sufficient conditions for the existence of paw- decompositions of the diamond graph $${Br}_{n}$$ and some edge cycle graphs like $${K}_{n}\left({C}_{3}\right), { W}_{n}\left({C}_{3}\right),{ K}_{r,s}\left({C}_{3}\right), { C}_{n}\circ \stackrel{\leftharpoonup}{{K}_{m}}({C}_{3})$$ and $${P}_{n}\circ \stackrel{\leftharpoonup}{{K}_{m}}({C}_{3})$$ where $$\circ $$ denotes the corona of graphs.},
  archive      = {J_SOCO},
  author       = {Esakkimuthu, Murugan and Rameshbabu, Sivaprakash Gunniya},
  doi          = {10.1007/s00500-025-10541-y},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1659-1665},
  shortjournal = {Soft Comput.},
  title        = {Paw decompositions of diamond and some edge cycle graphs},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On goal programming approach for interval-valued intuitionistic fuzzy multi-objective transportation problems with an application to tourism industry. <em>SOCO</em>, <em>29</em>(3), 1627-1657. (<a href='https://doi.org/10.1007/s00500-025-10420-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transportation problems are inevitably affected by numerous imprecise factors like weather, fuel expenses, topography, etc. Hence, the use of crisp parameters to model transportation problems appears to be both insufficient and inaccurate. Consequently, transportation problems using fuzzy/ intuitionistic fuzzy (IF) numbers seem more effective. Interval-valued intuitionistic fuzzy (IVIF) numbers are further generalization of IF numbers where membership and non-membership degrees are closed sub-intervals of [0, 1]. This concept of allocating interval values helps in dealing with the hesitancy of decision-maker while assigning fixed values to membership and non-membership degrees. In this article, balanced transportation problems having multiple objectives under the IVIF environment are examined. To overcome inconsistencies in the existing approaches, novel linear as well as non-linear interval-valued membership and non-membership functions have been proposed. Subsequently, an improved IVIF programming approach is developed using these newly defined functions along with theoretical validation. In addition, when goals are associated with objective functions, the proposed approach has been further improvised as IVIF prioritized goal programming. Eventually, a trip planning problem in the tourism industry is exhibited to illustrate the proposed IVIF technique and later, it is amalgamated with prioritized goals to demonstrate the proposed IVIF goal programming approach.},
  archive      = {J_SOCO},
  author       = {Chauhan, Abhishek and Mahajan, Sumati},
  doi          = {10.1007/s00500-025-10420-6},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1627-1657},
  shortjournal = {Soft Comput.},
  title        = {On goal programming approach for interval-valued intuitionistic fuzzy multi-objective transportation problems with an application to tourism industry},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Context-aware coverage path planning for a swarm of UAVs using mobile ground stations for battery-swapping. <em>SOCO</em>, <em>29</em>(3), 1605-1625. (<a href='https://doi.org/10.1007/s00500-025-10537-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The usage of swarms of drones is expected to continue growing in the next years, particularly in dangerous scenarios, such as monitoring and rescue missions in hostile and disaster areas. Small-sized Unmanned Aerial Vehicles (UAVs) are highly suitable for use in such scenarios due to their agility and maneuverability. On the other hand, their limited battery capacity poses significant challenges, especially during missions requiring full coverage of large areas in a short time and extreme weather conditions. This work proposed an energy efficiency approach, which makes use of mobile ground-based battery-swapping stations (BSSes), to speed up the UAV’s battery replacement and reduce energy waste in the round trip to the charging station. Specifically, a Context-Aware Coverage Path Planning (CACPP) problem has been formulated to determine the complete coverage path of a large area by a swarm of UAVs, minimizing the path overlapping and UAV battery swapping. The model takes into account the need to continue re-planning the mission, depending on the weather conditions (i.e., temperature and wind), the presence of obstacles, and the residual energy levels of the drones, as well as the relative positions of the drones and mobile BSSes. To solve the CACPP problem, an iterative approach leveraging two synchronized optimization models for planning UAV paths and BSS routes has been presented. As the CACPP problem is NP-hard, a heuristic procedure for solving it has also been evaluated. Experimental results show that it can be appropriate for large instances of the problem.},
  archive      = {J_SOCO},
  author       = {Porcelli, Lorenzo and Ficco, Massimo and D’Angelo, Gianni and Palmieri, Francesco},
  doi          = {10.1007/s00500-025-10537-8},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1605-1625},
  shortjournal = {Soft Comput.},
  title        = {Context-aware coverage path planning for a swarm of UAVs using mobile ground stations for battery-swapping},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using deep forest regression and multi-layer state transition algorithm to soft measuring modeling with small sample data. <em>SOCO</em>, <em>29</em>(3), 1587-1603. (<a href='https://doi.org/10.1007/s00500-025-10527-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In actual industrial operation process, some key performance indicators (KPIs) are tricky to detect online due to the characteristics of the detection equipment and the nature of the parameters. Moreover, these KPIs usually present small sample attributes. In this article, a stable and efficient soft measuring model for the KPIs of industrial processes is proposed using deep forest regression (DFR) and multi-layer state transition algorithm (STA). First, DFR is used to build soft measuring models for KPIs with random initial hyperparameters. Second, an improved dynamic STA (DSTA) is developed to optimize the DFR’s hyperparameters. Furthermore, the probability parameters of the DSTA structure are optimally selected using a STA. Finally, gradient refinement is utilized to fine-tune the state factor, which achieves a more accurate optimization process during the internal iteration process. The proposed algorithm is evaluated on the benchmark function, dataset, and an actual industrial problem. Results prove that the use of our method in soft measuring modeling can be effective.},
  archive      = {J_SOCO},
  author       = {Xia, Heng and Tang, Jian and Yu, Wen},
  doi          = {10.1007/s00500-025-10527-w},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1587-1603},
  shortjournal = {Soft Comput.},
  title        = {Using deep forest regression and multi-layer state transition algorithm to soft measuring modeling with small sample data},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A community-based simulated annealing approach with a new structure-based neighborhood search to identify influential nodes in social networks. <em>SOCO</em>, <em>29</em>(3), 1567-1585. (<a href='https://doi.org/10.1007/s00500-025-10490-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying influential nodes has attracted the attention of many researchers in recent years. Because of the weak tradeoff between accuracy and running time, and ignoring the community structure by the proposed algorithms in the past research studies, further studies in this area are required. In this paper, we consider communities and also use a novel structure-based neighborhood search to improve exploration strategy of the simulated annealing (SA) algorithm. Moreover, we use the k-shell method for generating a better initial solution instead of random generation. In the proposed algorithm called Ckshell-SA, first, the communities are detected, then the k-shell method is used in each community to find initial candidate nodes locally. Finally, SA algorithm is applied with a neighborhood search that considers the structural properties of the network, and three centralities to find the influential nodes globally. A derivative of the Ckshell-SA method called kshell-SA is also introduced in this paper to examine the impact of considering communities. Unlike the Ckshell-SA, the community structure is neglected, and the k-shell is performed on the whole network in kshell-SA algorithm. Extensive experiments are conducted on eight real-world networks under Independent Cascade Model (IC) and Weighted Independent Cascade Model (WC). The results show that the Ckshell-SA and kshell-SA algorithms outperform the state-of-the-art algorithms concerning influence spread. Furthermore, the results show that Ckshell-SA is more efficient in networks like Facebook with a high Power Law exponent and higher modularity. On the contrary, kshell-SA is more successful in networks like Slashdot or Epinions with lower modularity.},
  archive      = {J_SOCO},
  author       = {Abyaneh, Farzaneh Rajaee and Charkari, Nasrollah Moghadam and Roayaei, Mehdy},
  doi          = {10.1007/s00500-025-10490-6},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1567-1585},
  shortjournal = {Soft Comput.},
  title        = {A community-based simulated annealing approach with a new structure-based neighborhood search to identify influential nodes in social networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid genetic search based approach for the generalized vehicle routing problem. <em>SOCO</em>, <em>29</em>(3), 1553-1566. (<a href='https://doi.org/10.1007/s00500-025-10507-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel meta-heuristic for addressing a variant of the classical Capacitated Vehicle Routing Problem (CVRP) known as the Generalized Vehicle Routing Problem (GVRP). In the GVRP, nodes are organized into clusters, with the constraint that only one node from each cluster must be visited. The proposed meta-heuristic is a Hybrid Genetic Search (HGS) that leverages recent advancements in CVRP methodologies, adapting successful strategies and techniques from CVRP to the GVRP context. To evaluate the performance of the HGS meta-heuristic, we perform an extensive computational analysis on numerous benchmark instances ranging from small to large sizes. To thoroughly analyze the algorithm’s average behavior, convergence profiles over time are reported for the considered instances. Results show that the proposed algorithm achieves 174 new best solutions out of the 498 instances considered. In only six instances out of 498, the algorithm is unable to reach or improve upon the best-known solution in the literature. These results suggest that the proposed meta-heuristic has significant potential in addressing real-world generalized vehicle routing challenges. Code available at: https://github.com/vlatorre847/HGSGVRP .},
  archive      = {J_SOCO},
  author       = {Latorre, Vittorio},
  doi          = {10.1007/s00500-025-10507-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1553-1566},
  shortjournal = {Soft Comput.},
  title        = {A hybrid genetic search based approach for the generalized vehicle routing problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient reconfigurable architecture to extract image features for face recognition using local binary pattern. <em>SOCO</em>, <em>29</em>(3), 1541-1552. (<a href='https://doi.org/10.1007/s00500-025-10415-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognition of the face is a widely used method to detect human features. In various scenarios the face recognition speed becomes significant which necessitates to improve the critical delay of the architecture. In this paper, we propose Efficient FPGA architecture to extract image features using Local Binary pattern (LBP) for Face Recognition. The face image is converted into standard size (256 × 256) as pre-processing and the Gaussian filter is used to remove the high frequency components. These image is then applied to optimized LBP block to obtain the LBP features for both database sample and test sample are further compared to make the decision for face recognition. The proposed LBP architecture is designed using simple counter and comparators which leads to minimum complexity in turn improving the critical delay and hardware utilizations of the entire system. The simulation is performed for Olivetti Research Laboratory (ORL) dataset using MATLAB by showing False Acceptance Rate (FAR), False Rejection Rate (FRR) and Total Success Rate (TSR) values. The thresholding is performed based on Weighted Mean Square Difference and is varied for Total Success Rate (TSR) calculations tested for different combinations of Person in Database (PID) and Person Out of database (POD). Finally, the proposed architecture is synthesized on Spartan 6-xc651 × 4c-3csg432 Digilent FPGA board. It is observed that the recognition time of our architecture in hardware (FPGA) is 1.05 µS which is better compared to existing methods.},
  archive      = {J_SOCO},
  author       = {Bhavikatti, Sumangala and Bhairannawar, Satish},
  doi          = {10.1007/s00500-025-10415-3},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1541-1552},
  shortjournal = {Soft Comput.},
  title        = {Efficient reconfigurable architecture to extract image features for face recognition using local binary pattern},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decomposition matheuristics for last mile delivery using public transportation systems. <em>SOCO</em>, <em>29</em>(3), 1511-1539. (<a href='https://doi.org/10.1007/s00500-025-10513-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the potential of using public transportation systems for freight delivery, where we intend to utilize the spare capacities of public vehicles like buses, trams, metros, and trains, particularly during off-peak hours, to transport packages within the city instead of using dedicated delivery vehicles. The study contributes to the growing literature on innovative strategies for performing sustainable last mile deliveries. We study an operational level problem called the Three-Tier Delivery Problem on Public Transportation, where packages are first transported from the Consolidation and Distribution Center (CDC) to nearby public vehicle stations by delivery trucks, comprising the first tier of the problem. In the second tier, the public vehicles pick them up from the stops and transport them into the city area. The last leg, or the third tier of the delivery, is performed to deliver the packages to their respective customers using green vehicles or eco-friendly systems. We propose mixed-integer linear programming formulations to study the transport of packages from the CDC to the customers and employ decomposition-based matheuristics to solve them. We have three decomposition approaches based on the order of solving the tiers, resulting from the tier we start solving the problem from. We use a heuristic methodology to link the tiers by coordinating the flow of packages between them, and utilize CPLEX to solve the individual tiers. We provide numerical experiments to demonstrate the efficiency and effectiveness of the system. Our results show that this system has the potential to reduce the length of trips performed by traditional delivery trucks by 85.91%, thereby reducing the negative social and environmental impacts of existing last mile delivery systems.},
  archive      = {J_SOCO},
  author       = {Mandal, Minakshi Punam and Archetti, Claudia},
  doi          = {10.1007/s00500-025-10513-2},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1511-1539},
  shortjournal = {Soft Comput.},
  title        = {Decomposition matheuristics for last mile delivery using public transportation systems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A secure quantum homomorphic encryption ciphertext retrieval scheme. <em>SOCO</em>, <em>29</em>(3), 1497-1509. (<a href='https://doi.org/10.1007/s00500-025-10454-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a recent paper (Gong et al. Quantum Inf Process 19:3, 2020), a novel ciphertext retrieval scheme based on the Grover algorithm and quantum homomorphic encryption was presented. In this scheme, when the server performs the operation of marking the solution on the user’s encrypted state in the Grover iteration, it needs to remove many gate-errors generated in the homomorphic evaluation of the T gate. And the server could judge this specific solution from the quantum circuit of marking the solution. It makes this scheme unable to achieve the low-cost and secure ciphertext retrieval. Therefore, we improve the Gong et al.’s scheme and propose a secure quantum homomorphic encryption ciphertext retrieval scheme. In our scheme, the trusted third party is introduced to cooperate with the server to execute the Grover algorithm. In each Grover iteration, the trusted third party can quickly mark the solution on the plaintext state, encrypt the marked state, and transmit it to the server. Then the server performs the remaining operations of this Grover iteration on the encrypted state. The trusted third party finally decrypts the iterated state. This cooperative approach ensures that the number of auxiliary qubits required and extra quantum gates executed in our scheme are lower than the Gong et al.’s scheme. By analyzing the security of our scheme, we confirm that the server and the trusted third party will not be informed of this solution. Thus, our scheme realizes the secure ciphertext retrieval with low computational overhead. We utilize IBM’s Qiskit framework to simulate our scheme, and the experimental result shows that our scheme is correct. It is worth noting that the low-cost and secure ciphertext retrieval will play a crucial role in modern information security and privacy protection.},
  archive      = {J_SOCO},
  author       = {Cheng, Zhen-Wen and Chen, Xiu-Bo and Xu, Gang and Chang, Yan and Miao, Li-Hua and Yang, Yi-Xian and Wang, Ya-Lan},
  doi          = {10.1007/s00500-025-10454-w},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1497-1509},
  shortjournal = {Soft Comput.},
  title        = {A secure quantum homomorphic encryption ciphertext retrieval scheme},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revolutionizing signature scheme: The enhanced edward elgamal extreme performance accumulate signature approach for IoT and blockchain applications. <em>SOCO</em>, <em>29</em>(3), 1473-1496. (<a href='https://doi.org/10.1007/s00500-025-10426-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital signatures, essential for establishing trust in the digital realm, have evolved in their application and importance alongside emerging technologies such as the Internet of Things (IoT), Blockchain, and cryptocurrency. These advancements necessitate improvements in performance, security, and efficiency. This article examines and compares the Elliptic Curve Digital Signature Algorithm with the Hyper Elliptic Curve Digital Signature Algorithm and the Edwards Curve Digital Signature Algorithm. We highlight its superior capabilities for blockchain and IoT applications and advocate for its potential to deliver immediate enhancements in security and performance. Our study introduces a novel digital signature scheme specifically designed to enhance non-repudiation in blockchain ecosystems. Utilizing the Optimized Extreme Performance Edwards Curve Accumulated Signature scheme, our approach significantly reduces signing and verification times by 10% and 13%, respectively, compared to traditional signatures. Additionally, it offers a 10% boost in transaction throughput and block validation efficiency. Experiments conducted within various blockchain-integrated IoT setups demonstrate the scheme's effectiveness, consistently achieving improvements across diverse IoT sensor data. This highlights the innovative contribution of our scheme to the efficiency and security of blockchain technology.},
  archive      = {J_SOCO},
  author       = {Anusha, R. and Saravanan, R.},
  doi          = {10.1007/s00500-025-10426-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1473-1496},
  shortjournal = {Soft Comput.},
  title        = {Revolutionizing signature scheme: The enhanced edward elgamal extreme performance accumulate signature approach for IoT and blockchain applications},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-rank decomposition optimization and its application in fabric defects. <em>SOCO</em>, <em>29</em>(3), 1453-1472. (<a href='https://doi.org/10.1007/s00500-025-10399-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The low-rank decomposition model is frequently employed in defect detection. It separates the target matrix into a low-rank component and a sparse component using the nuclear norm and the $$l_1$$ -norm, which aids in extracting the background and defects. However, the nuclear norm, derived from singular value decomposition, often fails to effectively extract the background of fabrics. This paper introduces a novel matrix norm, defined by integrating several key elementary functions, enhancing the separation of the low-rank and sparse matrices. The Alternating Direction Method of Multipliers (ADMM) typically solves the low-rank decomposition model with a fixed step size penalty factor. This study dynamically adjusts the penalty factor based on defect detection characteristics, thus enhancing the algorithm’s computational efficiency. Additionally, the convergence of the proposed algorithm is validated. Experimental results demonstrate that this new model not only precisely distinguishes the sparse matrix but also achieves higher computational efficiency, surpassing other existing methods in both accuracy and efficiency.},
  archive      = {J_SOCO},
  author       = {Chen, Zhixiang and Shi, Wenya and Liang, Jiuzhen and Liu, Hao},
  doi          = {10.1007/s00500-025-10399-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1453-1472},
  shortjournal = {Soft Comput.},
  title        = {Low-rank decomposition optimization and its application in fabric defects},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient COVID-19 detection using data mining algorithms: A comparison of basic and hybrid approaches. <em>SOCO</em>, <em>29</em>(3), 1437-1451. (<a href='https://doi.org/10.1007/s00500-025-10538-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient diagnosis of COVID-19 remains a significant challenge due to the limitations of current detection methods, such as blood tests and chest scans, which can be time-consuming and error-prone. This study aims to compare the performance of basic and hybrid data mining algorithms in diagnosing COVID-19, using blood test results and clinical information to identify the most effective approach. A dataset of 200 records from suspected and infected COVID-19 patients, with 23 characteristics and one diagnostic class, was analysed. Nine data mining algorithms were tested: four basic algorithms (Naive Bayes, Support Vector Machine, Decision Tree, K-Nearest Neighbor) and five hybrid algorithms (Random Forest, AdaBoost, Majority Voting, XGBoost, Bagging). The study also integrated Response Surface Methodology (RSM) and Adaptive-Network-based Fuzzy Inference System (ANFIS) to enhance model performance. The Bagging algorithm demonstrated superior performance with an accuracy of 88%, sensitivity of 74%, and F-criterion of 78%. The integration of RSM and ANFIS further showed that a smart model could be developed for efficient pandemic crisis management, achieving up to 100% accuracy when considering key factors like AST, Albumin, and CRP. The findings suggest that Bagging and hybrid data mining algorithms can significantly improve COVID-19 detection, reducing time and errors in identifying exposed individuals. The study highlights the potential of combining machine learning techniques with RSM-ANFIS models for effective pandemic management and decision-making in medical settings.},
  archive      = {J_SOCO},
  author       = {Saidi, Mohammad and Gheibi, Mohammad and Ghazikhani, Adel and Lotfata, Aynaz and Chahkandi, Benyamin and Familsamavati, Sajad and Behzadian, Kourosh},
  doi          = {10.1007/s00500-025-10538-7},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1437-1451},
  shortjournal = {Soft Comput.},
  title        = {Efficient COVID-19 detection using data mining algorithms: A comparison of basic and hybrid approaches},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging variant of CAE with sparse convolutional embedding and two-stage application-driven data augmentation for image clustering. <em>SOCO</em>, <em>29</em>(3), 1419-1435. (<a href='https://doi.org/10.1007/s00500-025-10500-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep clustering approaches often struggle with redundant feature learning, which limits their effectiveness. The primary goal of this study is to address these issues by developing a more robust deep clustering method. To achieve this, we propose a variant of the convolutional autoencoder (CAE) called SCDAC, which incorporates sparse convolutional embedding and a two-stage application-driven data augmentation approach. The proposed model operates in two main stages: pretraining and finetuning. In the pretraining stage, we employ application-driven data augmentation to train the CAE variant, focusing on learning robust features and constructing a foundational feature space using sparse convolutional embedding. During the finetuning stage, the model performs joint feature learning and cluster assignment. The feature learning task utilizes an augmented framework to control the input of both original and augmented data, preserving the local structure of images in the feature space. For cluster assignment, the framework controls the input of original data and uses the sparse convolutional embedding layer to obtain low-dimensional representations for soft cluster assignment. Experimental evaluations on six publicly available datasets demonstrate the effectiveness of the proposed model, with significant improvements in accuracy, particularly increases of $$3\%$$ and $$10.3\%$$ on the COIL20 and ORL datasets, respectively. In conclusion, our findings underscore the significance of the SCDAC approach in enhancing deep image clustering performance, offering a viable solution to the limitations of existing methods.},
  archive      = {J_SOCO},
  author       = {Liu, Yanming and Liu, Jinglei},
  doi          = {10.1007/s00500-025-10500-7},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1419-1435},
  shortjournal = {Soft Comput.},
  title        = {Leveraging variant of CAE with sparse convolutional embedding and two-stage application-driven data augmentation for image clustering},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chatgpt and operations research: Evaluation on the shortest path problem. <em>SOCO</em>, <em>29</em>(3), 1407-1418. (<a href='https://doi.org/10.1007/s00500-025-10505-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ChatGPT tool, the large language model developed by OpenAI, is having a great impact among users, experts and scholars for its capabilities of answering questions and retrieving solutions automatically. Despite the short time since its release, it has already been employed in several application domains. However, to the best of our knowledge, it has not been studied in the field of operation research (OR). In this paper, we use ChatGPT to define solution strategies for addressing several variants of the shortest path problem. The results obtained by executing the solution approaches returned by the tool are compared, in terms of correctness and efficiency, to reference codes. They indicate that the proper utilization of this tool could represent a good aid for domain experts. In particular, the outputs provided by ChatGPT could represent not only a good base for more complex implementations, but also they represent a way to facilitate some tasks in order to reduce times to do certain activities, which in any case must involve human control, adaptation and supervision.},
  archive      = {J_SOCO},
  author       = {Luzzi, Martina and Guerriero, Francesca and Maratea, Marco and Greco, Gianluigi and Garofalo, Marco},
  doi          = {10.1007/s00500-025-10505-2},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1407-1418},
  shortjournal = {Soft Comput.},
  title        = {Chatgpt and operations research: Evaluation on the shortest path problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using past sample means in exponential ratio and regression type estimators under a simple random sampling. <em>SOCO</em>, <em>29</em>(3), 1389-1406. (<a href='https://doi.org/10.1007/s00500-025-10408-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical sampling commonly employs auxiliary variables for the selection and estimation phases to improve efficiency of the estimators. However, existing estimators like ratio and product types display limitations under specific conditions. Regression-type estimators, known for their unbiasedness and efficiency, rely solely on current sample information. This highlights the need for more effective estimators capable of leveraging both past and current sample means to improve accuracy and applicability across diverse datasets. In this study, we introduce two novel memory-type estimators, drawing inspiration from Noor-ul-Amin's (2020) approach, which integrates past and current sample information using Hybrid Exponentially Weighted Moving Averages (HEWMA), particularly effective for time-based surveys. Through simulation studies and real data examples, we evaluate the performance of our estimators and identify crucial shortcomings in previous memory-type estimator studies. Furthermore, we highlight significant deficits in previous studies, particularly concerning the impact of sample sizes based on past means, correlation, number of past means, weight parameters and initial values of EWMA and HEWMA algorithms, and the distribution shape of the data on estimator efficiency. Our findings underscore the importance of parameter selection in HEWMA, a greater number of past means, and the significance of past sample sizes for optimizing the performance of the proposed memory-type estimators. By integrating HEWMA, our approach enhances the efficiency and applicability of these estimators, addressing essential gaps in the existing literature and laying the groundwork for more robust and efficient estimation techniques for future studies that use mean.},
  archive      = {J_SOCO},
  author       = {Koçyiğit, Eda Gizem},
  doi          = {10.1007/s00500-025-10408-2},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1389-1406},
  shortjournal = {Soft Comput.},
  title        = {Using past sample means in exponential ratio and regression type estimators under a simple random sampling},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variable selection of multiple types of data: A PLS approach. <em>SOCO</em>, <em>29</em>(3), 1369-1387. (<a href='https://doi.org/10.1007/s00500-025-10531-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of data collection techniques in recent years, multiple types of data have emerged, including scalar data, functional data (curve-like), and compositional data (pie-like). While existing studies propose predictive models for multiple-type of data, few address the issue of variable selection. The challenge lies in the fact that different data types originate from different vector spaces, making it difficult to conduct variable selection at the variable level instead of selection at their sub-component level. This study leverages the group selection ability of gPLS (group Partial Least Squares) and gsPLS (group sparse Partial Least Squares) by regarding the functional and compositional variables as natural groups and proposes two variable selection approaches, named MD-gPLS and MD-gsPLS, after building a vector space for multiple types of data. Numerical studies and real-world examples verify the effectiveness of the proposed approaches. This study broadens the statistical modeling tools of multiple types of data analysis in terms of variable selection and also contributes to the literature by introducing the vector space of multiple types of data.},
  archive      = {J_SOCO},
  author       = {Kong, Boao and Wang, Huiwen and Lu, Shan},
  doi          = {10.1007/s00500-025-10531-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1369-1387},
  shortjournal = {Soft Comput.},
  title        = {Variable selection of multiple types of data: A PLS approach},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predictor–corrector approach for the numerical solution of fuzzy fractional differential equations and linear multiterm fuzzy fractional equations. <em>SOCO</em>, <em>29</em>(3), 1347-1368. (<a href='https://doi.org/10.1007/s00500-025-10401-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the modeling of fuzzy fractional differential equations (FFDEs) has been a very significant issue in many new applications in applied sciences and engineering, while a natural tool for modeling such dynamical systems is to use fuzzy fractional differential equations. We establish the existence and uniqueness of solutions for fuzzy fractional differential equations under sufficient assumptions and contraction principles and study numerical solutions of FFDEs. Our study is based on Caputo’s generalized Hukuhara differentiability. By applying Schauder’s fixed point theorem and a hypothetical condition, we explore the existence of the solutions. In addition, we show the uniqueness of the system's solution by using the contraction mapping theorem. We analyze the predictor–corrector approach (PCA) for FFDEs and multiterm FFDEs. We utilize the PCA to find the approximate solutions to linear multiterm FFDEs under the Caputo fuzzy derivative. After that, we present numerical solutions to initial value problems for solving two families of fuzzy fractional problems: fuzzy fractional differential equations (FFDEs) and multiterm fuzzy fractional differential equations (MFFDEs) utilizing the PCA. The method used in this paper has several advantages; first, it is significant and yields stable results without diverging as well as its ability to solve other mathematical, physical, and engineering problems; second, it is higher accuracy, needs less effort to achieve the results and works to reduces the error between exact and approximate solutions, as depicted in the utilized figures and tables. Finally, the accuracy of our suggested approach is demonstrated by solving some specific examples and analyzing the figures and tables, along with several suggestions for future research directions.},
  archive      = {J_SOCO},
  author       = {Al-Sadi, Wadhah and Wei, Zhouchao and Moroz, Irene and Abu Arqub, Omar and Abdullah, Tariq Q. S.},
  doi          = {10.1007/s00500-025-10401-9},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1347-1368},
  shortjournal = {Soft Comput.},
  title        = {Predictor–corrector approach for the numerical solution of fuzzy fractional differential equations and linear multiterm fuzzy fractional equations},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new approach data processing: Density-based spatial clustering of applications with noise (DBSCAN) clustering using game-theory. <em>SOCO</em>, <em>29</em>(3), 1331-1346. (<a href='https://doi.org/10.1007/s00500-025-10405-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the unpredictable growth of data in various fields, rapid clustering of big data is seriously needed in order to identify the hidden structure of data and discover the relationships between objects. Among clustering methods, density-based clustering methods have an acceptable processing speed for dealing with big data with high dimensions. However, some methods have fixed parameters that are certainly not optimized for all sections. In addition, the complexity of these clustering methods strongly depends on the number of objects. In this paper, a clustering method is presented in order to increase clustering performance and parameter sensitivity according to game-theory and using the concept of Nash equilibrium and dense games, the optimal parameter for clustering is selected and between noise and points clusters make a difference. This method includes (1) searching the grid with several spaces in which there is no cluster, (2) identifying the player through high density data points in order to determine the parameters and (3) combining the clusters to make the game and (4) merging the nearby clusters. The performance of the proposed method was evaluated in four big synthetic datasets, eight real datasets labeled and unlabeled. The obtained results indicate the superiority of the proposed method over SOM, K-means, DBSCAN, SCGPSC methods in terms of accuracy and purity in processing time.},
  archive      = {J_SOCO},
  author       = {Kazemi, Uranus and Soleimani, Seyfollah},
  doi          = {10.1007/s00500-025-10405-5},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1331-1346},
  shortjournal = {Soft Comput.},
  title        = {A new approach data processing: Density-based spatial clustering of applications with noise (DBSCAN) clustering using game-theory},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Arithmetic optimization algorithm with cosine transform-based two-dimensional composite chaotic mapping. <em>SOCO</em>, <em>29</em>(3), 1289-1329. (<a href='https://doi.org/10.1007/s00500-025-10412-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The arithmetic optimization algorithm (AOA) is a newly developed meta-heuristic algorithm that draws inspiration from the combination of arithmetic operations. Since many scholars have widely used traditional one-dimensional chaotic mapping at home and abroad in function optimization, the AOA based on cosine transform two-dimensional composite chaotic mapping is proposed. Firstly, seven two-dimensional chaotic mappings are proposed to be embedded into the MOA and MOP in AOA. Secondly, one-dimensional chaotic systems based on the cosine transform are put forward. Then the proposed chaotic system based on the cosine transform is combined with the two-dimensional chaotic mapping to form the cosine transformed two-dimensional composite chaotic mapping. Finally, six more cosine transformed two-dimensional composite chaotic mappings are embedded into the MOA and MOP of the AOA to balance the algorithm's global and local searching ability and improve the algorithm's performance. The superiority of the improved algorithm is verified by employing 12 benchmark test functions in CEC2022. Then it is compared with the Coati Optimization Algorithm (COA), Prairie Dog Optimization (PDO), Butterfly Optimization Algorithm (BOA), Reptile Search Algorithm (RSA), Bat Algorithm (BAT), and Rat Swarm Optimization (RSO) to verify its convergence. Finally, four engineering design problems (tension/compression spring problem, pressure vessel problem, cantilever beam design problem, and slotted bulkhead design problem) were optimized to validate the efficiency of the improved algorithm. The simulation experiments demonstrate that the improved AOA exhibits superior performance in addressing both function and engineering optimization problems. It showcases remarkable optimization capabilities and improves convergence accuracy.},
  archive      = {J_SOCO},
  author       = {Li, Yi-Xuan and Wang, Jie-Sheng and Zhang, Si-Wen and Zhang, Shi-Hui and Guan, Xin-Yi and Ma, Xin-Ru},
  doi          = {10.1007/s00500-025-10412-6},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1289-1329},
  shortjournal = {Soft Comput.},
  title        = {Arithmetic optimization algorithm with cosine transform-based two-dimensional composite chaotic mapping},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Some new construction methods of similarity measure on picture fuzzy sets. <em>SOCO</em>, <em>29</em>(3), 1273-1287. (<a href='https://doi.org/10.1007/s00500-025-10536-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picture fuzzy sets address problems characterized by ambiguity, instability and inconsistent data. Similarity measures on picture fuzzy sets play an indispensable role in determining the relationships between two such sets. Consequently, the study of similarity measures for picture fuzzy sets has garnered significant attention from scholars, yielding fruitful results. Notably, the existing research on picture fuzzy set similarity has mainly focused on overcoming the limitations of certain existing similarity measures by proposing one or a few new ones, ignoring the construction methods for similarity measures. Therefore, this paper presents two novel construction methods for similarity measures on picture fuzzy sets. The first approach combines the differences among positive membership, neutral membership, negative membership, and refusal membership within picture fuzzy sets using a strictly monotonically decreasing function. Remarkably, this method not only integrates existing similarity measures but also generates novel ones, providing a unified framework for both. The second method employs a strictly decreasing binary function to aggregate the distance measures between two picture fuzzy sets. By varying the binary function and distance measures, we obtain a range of novel similarity measures. Additionally, we apply the newly developed similarity measures to pattern recognition and compare their performance against existing measures. Based on the identification results, it is evident that these novel similarity measures yield reasonable outcomes and exhibit a high degree of reliability.},
  archive      = {J_SOCO},
  author       = {Luo, Minxia and Gao, Jianlei and Li, Wenling},
  doi          = {10.1007/s00500-025-10536-9},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1273-1287},
  shortjournal = {Soft Comput.},
  title        = {Some new construction methods of similarity measure on picture fuzzy sets},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Free-text keystroke authentication using transformers: A comparative study of architectures and loss functions. <em>SOCO</em>, <em>29</em>(2), 1259-1272. (<a href='https://doi.org/10.1007/s00500-025-10524-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keystroke biometrics is a promising approach for user identification and verification, leveraging the unique patterns in individuals’ typing behavior. In this paper, we propose a Transformer-based network that employs self-attention to extract informative features from keystroke sequences, surpassing the performance of traditional Recurrent Neural Networks. We explore two distinct architectures, namely bi-encoder and cross-encoder, and compare their effectiveness in keystroke authentication. Furthermore, we investigate different loss functions, including triplet, batch-all triplet, and WDCL loss, along with various distance metrics such as Euclidean, Manhattan, and cosine distances. These experiments allow us to optimize the training process and enhance the performance of our model. To evaluate our proposed model, we employ the Aalto desktop keystroke dataset. The results demonstrate that the bi-encoder architecture with batch-all triplet loss and cosine distance achieves the best performance, yielding an exceptional Equal Error Rate of 0.0186%. Furthermore, alternative algorithms for calculating similarity scores are explored to enhance accuracy. Notably, the utilization of a one-class Support Vector Machine reduces the Equal Error Rate to an impressive 0.0163%. The outcomes of this study indicate that our model surpasses the previous state-of-the-art in free-text keystroke authentication. These findings contribute to advancing the field of keystroke authentication and offer practical implications for secure user verification systems.},
  archive      = {J_SOCO},
  author       = {Momeni, Saleh and BabaAli, Bagher},
  doi          = {10.1007/s00500-025-10524-z},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {1259-1272},
  shortjournal = {Soft Comput.},
  title        = {Free-text keystroke authentication using transformers: A comparative study of architectures and loss functions},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing demand forecasting through combination of anomaly detection and continuous improvement. <em>SOCO</em>, <em>29</em>(2), 1243-1258. (<a href='https://doi.org/10.1007/s00500-025-10452-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Demand forecasting has emerged as a crucial element in supply chain management. It is essential to identify anomalous data and continuously improve the forecasting model with new data. However, existing literature fails to comprehensively cover both aspects of anomaly detection and continuous improvement in demand forecasting. This study proposes an enhanced model to improve accuracy in the demand forecasting. The proposed model introduces a novel data handling method that incorporates an anomaly detection autoencoder, improved with anomaly correction mechanisms. The data handling approach simultaneously detects data anomalies, distinguishes between expected and unexpected anomalies, and corrects anomalous data, ensuring cleaner input for demand forecasting. Then, the proposed model employs a long short-term memory architecture for demand forecasting, enhanced with a continuous improvement method. Thus, the model not only forecasts demand but also retrains the model when the anomaly data surpasses the predetermined threshold, thereby improving the accuracy of forecasting. The results show that the proposed model outperforms other models in detecting data anomalies, achieving an average precision-recall of 0.922, a receiver operating characteristic value of 0.739, and a significance level of less than 0.05. Finally, the model exhibits superior performance in demand forecasting, with average mean squared error, root mean squared error, and mean absolute error values of 33.167, 4.347, and 1.509, respectively, all with a significance level of less than 0.05.},
  archive      = {J_SOCO},
  author       = {Jahani, Meysam and Zojaji, Zahra and Raji, Fatemeh},
  doi          = {10.1007/s00500-025-10452-y},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {1243-1258},
  shortjournal = {Soft Comput.},
  title        = {Enhancing demand forecasting through combination of anomaly detection and continuous improvement},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving trajectory tracking of robot manipulators via PID control with neural network compensation. <em>SOCO</em>, <em>29</em>(2), 1227-1241. (<a href='https://doi.org/10.1007/s00500-025-10439-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this manuscript, a PID controller based on adaptive neural networks for manipulating robots with n degrees of freedom is presented. The neural network is given by a two-layer perceptron that compensates for the unknown dynamics of the system. The weights of the output layer are estimated online by the proposed adaptation law, while the weights and thresholds in the hidden layer are random constants. A theoretical contribution of this paper is the rigorous analysis of the introduced control scheme. In addition, to demonstrate the effectiveness of the proposed controller, real-time experiments were carried out in a pendulum and a two degrees of freedom manipulator, where the proposed controller outperforms other PID and neural network controllers previously reported in the literature.},
  archive      = {J_SOCO},
  author       = {Moran-Armenta, Marco and Aguilar-Avelar, Carlos and Gandarilla, Isaac and Meza-Sánchez, Marlen and Moreno-Valenzuela, Javier},
  doi          = {10.1007/s00500-025-10439-9},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {1227-1241},
  shortjournal = {Soft Comput.},
  title        = {Solving trajectory tracking of robot manipulators via PID control with neural network compensation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Channel pruning method driven by similarity of feature extraction capability. <em>SOCO</em>, <em>29</em>(2), 1207-1226. (<a href='https://doi.org/10.1007/s00500-025-10470-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Channel pruning is a method to compress convolutional neural networks, which can significantly reduce the number of model parameters and the computational amount. Current methods that focus on the internal parameters of a model and feature mapping information rely on artificially set a priori criteria or reflect filter attributes by partial feature mapping, which lack the ability to analyze and discriminate the channel feature extraction and ignore the basic reasons for the similarity of the channels. This study developed a pruning method based on similar structural features of channels, called SSF. This method focuses on analysing the ability to extract similar features between channels and exploring the characteristics of channels producing similar feature mapping. First, adaptive threshold coding was introduced to numerically transform the channel characteristics into structural features, and channels with similar coding results could generate highly similar feature mapping. Secondly, the spatial distance was calculated for the structural features matrix to obtain the similarity between channels. Moreover, in order to keep rich channel classes in the pruned network, different class cuts were made on the basis of similarity to randomly remove some of the channels. Thirdly, considering the differences in the overall similarity of different layers, this study determined the appropriate pruning ratio for different layers on the basis of the channel dispersion degree reflected by the similarity. Finally, extensive experiments were conducted on image classification tasks, and the experimental results demonstrated the superiority of the SSF method over many existing techniques. On ILSVRC-2012, the SSF method reduced the floating-point operations (FLOPs) of the ResNet-50 model by 57.70% while reducing the Top-1 accuracy only by 1.01%.},
  archive      = {J_SOCO},
  author       = {Sun, Chuanmeng and Chen, Jiaxin and Li, Yong and Wang, Yu and Ma, Tiehua},
  doi          = {10.1007/s00500-025-10470-w},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {1207-1226},
  shortjournal = {Soft Comput.},
  title        = {Channel pruning method driven by similarity of feature extraction capability},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting cervical cancer detection with a multi-stage architecture and complementary information fusion. <em>SOCO</em>, <em>29</em>(2), 1191-1206. (<a href='https://doi.org/10.1007/s00500-025-10491-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cervical cancer is one of the most fatal and prevalent illnesses affecting women globally. Early detection of cervical cancer is crucial for effective treatment. Pap smear tests are commonly used, but population-based screening is time-consuming, expensive, and requires expert physicians. Computer-Aided Diagnosis (CAD) has shown promise in addressing this challenge. However, accurately predicting the disease using a single model can be difficult due to the complex data patterns involved. This research proposes a multi-stage architecture to improve cervical cancer screening. Initially, three pre-trained models are employed for image classification, after which the proposed advanced fusion technique is applied to combine the predictions. Additionally, we introduce a filtering approach in the third stage to refine the predictions. Unlike traditional fusion methods, the proposed architecture considers the confidence score of the base classifiers in making the final predictions on test samples. To enhance the performance of the models, we incorporate advanced augmentation techniques, including CutMix, CutOut, and MixUp. We assessed the performance of the proposed framework using a 5-fold cross-validation technique on two benchmark datasets. We evaluated the performance of the proposed framework through 5-fold cross-validation on two benchmark datasets. Remarkably, our framework achieved a classification accuracy of 97.62% and an F1-score of 97.64% on the SIPaKMeD dataset, demonstrating its effectiveness in accurately categorizing various cell types in the dataset.},
  archive      = {J_SOCO},
  author       = {Sahoo, Pranab and Saha, Sriparna and Sharma, Saksham Kumar and Mondal, Samrat},
  doi          = {10.1007/s00500-025-10491-5},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {1191-1206},
  shortjournal = {Soft Comput.},
  title        = {Boosting cervical cancer detection with a multi-stage architecture and complementary information fusion},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A genetic-based approach for vehicle routing problem with fuzzy alpha-cut constraints. <em>SOCO</em>, <em>29</em>(2), 1169-1189. (<a href='https://doi.org/10.1007/s00500-025-10465-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s business environment, logistics and supply chain management are especially important for the timely delivery of materials and goods. Delivery must not only be fast, it also needs to be performed within a specific time frame. Therefore, this study examines a vehicle routing problem (VRP) that considers multiple goals and allows vehicles to reach their destinations within a time window with a crashed traveling time. Two objectives are considered, the minimization of total cost and the maximization of customer satisfaction. Firstly, a fuzzy multi-objective linear programming (FMOLP) model with alpha-cut technique and epsilon-constraint method is proposed to transform the multi-objective problem into a single-objective mathematical model, and then an improved genetic algorithm (IGA) is constructed to solve large-scale problems. The performances of the proposed methods are evaluated through several case studies. Design of experiments and sensitivity analysis are applied to evaluate the performance and robustness of IGA. The results show that both the FMOLP and IGA are effective, and the IGA can efficiently obtain a near-optimal solution.},
  archive      = {J_SOCO},
  author       = {Kang, He-Yau and Lee, Amy H. I.},
  doi          = {10.1007/s00500-025-10465-7},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {1169-1189},
  shortjournal = {Soft Comput.},
  title        = {A genetic-based approach for vehicle routing problem with fuzzy alpha-cut constraints},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mechanical properties estimation of multi-layer friction stir plug welded aluminium plates using time-series neural network models. <em>SOCO</em>, <em>29</em>(2), 1147-1168. (<a href='https://doi.org/10.1007/s00500-025-10429-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-layer friction stir plug welding can be used to fix the thick aluminium plates. Optical microscopy and tensile tests are utilized to study the microstructural and mechanical characteristics of the welded aluminium plates. However, finding the relation between the indexes of the process and the mechanical properties would be challenging. The present work aims to devise a time-series machine learning model including a recurrent neural network (RNN) and nonlinear autoregressive network with the external state (NARX) to estimate the mechanical properties of the repaired aluminium plate using the force-extension plot. The ultimate tensile strength, yield strength, impact energy and elongation of the repaired aluminium plate can be calculated based on a force-extension plot trained and extracted using the developed networks. In addition, the Bayesian technique is employed to recalculate the optimal hyperparameters of RNN and NARX, targeting the lowest root mean square error (RMSE) between the target and the estimated force during the testing. The investigated methods (RNN and NARX) with the addition of classical estimation methods, including decision tree and support vector regression, are modelled in MATLAB, and the outcomes prove the proposed NARX model efficiency in terms of lower RMSE in comparison with support vector regression, decision tree and RNN.},
  archive      = {J_SOCO},
  author       = {Qazani, Mohammad Reza Chalak and Sajed, Moosa and Pedrammehr, Siamak and Seyedkashi, Seyed Mohammad Hossein},
  doi          = {10.1007/s00500-025-10429-x},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {1147-1168},
  shortjournal = {Soft Comput.},
  title        = {Mechanical properties estimation of multi-layer friction stir plug welded aluminium plates using time-series neural network models},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A GA-FGM-RTA combined model for predicting seawall settlement in under insufficient data volume. <em>SOCO</em>, <em>29</em>(2), 1133-1146. (<a href='https://doi.org/10.1007/s00500-025-10496-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One widely concerned issue in the field of seawall settlement prediction is the difficulty in establishing prediction models in the context of insufficient data volume. Fractional-order grey model (FGM), as an extension of the traditional grey model incorporating fractional calculus, has been used to solve the insufficient data volume problem in temporal prediction. Due to the non-integer nature of the fractional order of FGM, traditional parameter estimation methods often lead to increased instability and uncertainty and are no longer applicable, necessitating the adoption of more complex algorithms for estimating the fractional order. To solve this issue, a novel GA-FGM-RTA combined model was proposed for predicting seawall settlement with insufficient data volume, where a genetic algorithm (GA) with enhanced search capabilities was employed to optimal the fractional order and a real-time tracing algorithm (RTA) was applied to provide a dynamic prediction. A case study of Haiyan seawall in Zhejiang province, China was selected to validate the proposed model. We also compared the proposed GA-FGM-RTA model with the fractional-order GM(1,1), integer-order GM(1,1), and fractal theory model. Results exhibit that the proposed GA-FGM-RTA combined model outperforms other relevant models under the same algorithm frame.},
  archive      = {J_SOCO},
  author       = {Qin, Peng and Cheng, Chunmei and Su, Huaizhi},
  doi          = {10.1007/s00500-025-10496-0},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {1133-1146},
  shortjournal = {Soft Comput.},
  title        = {A GA-FGM-RTA combined model for predicting seawall settlement in under insufficient data volume},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast resistivity imaging of transient electromagnetic using an extreme learning machine. <em>SOCO</em>, <em>29</em>(2), 1121-1131. (<a href='https://doi.org/10.1007/s00500-025-10535-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transient electromagnetic method (TEM) is widely used in geophysical exploration. In TEM data interpretation, nonlinear inversion plays an important role. However, traditional TEM nonlinear inversion adopts the OCCAM imaging method, which merely presents the approximate shape of the stratum model, with poor inversion accuracy and much iteration time. To solve the above problems, a novel nonlinear inversion approach based on extreme learning machine (ELM) is proposed in this paper. The ELM is required to establish the input–output mapping relationship of the inversion network only once through the analytical method, which is different from the traditional neural network method that demands iterative gradient learning and is prone to fall into the local optimum. Moreover, the ELM inversion network by randomly assigning the hidden layer parameters is capable of mapping the observed TEM data and quickly producing resistivity images, which avoids time-consuming iteration and inversion calculations. The presented approach is applied to both synthetic and field examples. The results show that compared with the traditional nonlinear inversion algorithms (BP and OCCAM), the proposed method achieves better inversion accuracy and significantly reduces the calculation time, which verifies the effectiveness of the ELM algorithm for TEM data interpretation. Additionally, the research provides a new method and technology for TEM data inversion.},
  archive      = {J_SOCO},
  author       = {Li, Ruiyou and Zhang, Yong and Li, Guang and Li, Ruiheng and Hu, Jia and Li, Min},
  doi          = {10.1007/s00500-025-10535-w},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {1121-1131},
  shortjournal = {Soft Comput.},
  title        = {Fast resistivity imaging of transient electromagnetic using an extreme learning machine},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A distance based similarity measure on trapezoidal intuitionistic fuzzy numbers and its applications. <em>SOCO</em>, <em>29</em>(2), 1107-1119. (<a href='https://doi.org/10.1007/s00500-025-10427-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are numerous uses for trapezoidal intuitionistic fuzzy sets (TraIFSs), which include membership and non-membership functions in the form of trapezoidal fuzzy sets (TraFSs), for handling data that is ambiguous. The TraIFS distance based similarity metrics are designed to illustrate the similarities among various categories of sensitive fuzzy data. Nonetheless, certain current similarity metrics fail to satisfy the similarity axioms. Moreover, in other circumstances, they could not be utilized effectively. In this article, a novel distance based similarity measure between any two trapezoidal intuitionistic fuzzy numbers (TraIFNs) is defined and some of its important properties are proved and validated by numerical examples. It consists of two interrelated modules. In the first module consists of distance based similarity measure between TraIFNs and it is used for ranking procedure. For the second module, Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) method is used for real life application problems under TraIFN environment. The effectiveness of the proposed distance based similarity measure between TraIFNs is examined by solving the real life applications such as multi-criteria decision making (MCDM) method, pattern recognition problems and also compared over familiar existing methods. Finally, we obtain a general conclusions and future scope of the proposed method.},
  archive      = {J_SOCO},
  author       = {Dhanasekaran, P. and Kalidasan, S.},
  doi          = {10.1007/s00500-025-10427-z},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {1107-1119},
  shortjournal = {Soft Comput.},
  title        = {A distance based similarity measure on trapezoidal intuitionistic fuzzy numbers and its applications},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel cluster based reliable security enhancement in FANET directed by game theory. <em>SOCO</em>, <em>29</em>(2), 1091-1106. (<a href='https://doi.org/10.1007/s00500-025-10502-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of interconnected UAVs has given rise to the creation of flying ad hoc networks (FANETs) aimed at efficiently facilitating network-dependent services. However, FANET encountered considerable challenges in achieving reliability due to security issues influenced by the existence of malicious nodes. These nodes continuously engage in communication and present a significant threat. These issues are precisely addressed in this article by introducing a novel methodology enhancing network security through a game theory-driven decision tree approach. The proposed strategy involves the implementation of a cluster mechanism based on path similarity techniques. Additionally, an optimized strategy put forth to minimize cluster overhead. Comparing with state-of-the-art protocols in identifying malicious nodes within the network, the results indicate a notable enhancement averaging at 52.84%. Moreover, in aspects such as delay reduction, precision rate increase, and message drop minimization, the experimental outcomes exhibit average improvements of 42.17%, 65.24%, and 46.63%, respectively.},
  archive      = {J_SOCO},
  author       = {Gupta, Shikha and Sharma, Neetu},
  doi          = {10.1007/s00500-025-10502-5},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {1091-1106},
  shortjournal = {Soft Comput.},
  title        = {A novel cluster based reliable security enhancement in FANET directed by game theory},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear convergence factor-based manta ray foraging optimization algorithm for combined economic emission dispatch problem. <em>SOCO</em>, <em>29</em>(2), 1053-1089. (<a href='https://doi.org/10.1007/s00500-025-10402-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization objective of Combined Economic Emissions Dispatch (CEED) must simultaneously ensure that full generation costs and pollutant emissions are minimized to meet load demands and constraints. Though the CEED problem itself has multi-objective to be optimized (e.g., fuel cost and emissions), it can be converted into a single objective with a price penalty factor. A nonlinear convergence factor-based manta ray foraging optimization algorithm was proposed for solving the CEED problems. Six nonlinear convergence functions, including the Gaussian function, sine function, cosine function, tangent function, power function and exponential function (named S1MRFO ~ S6MRFO), are introduced in the spiral foraging behavior stage based on the hypotrochoid manta ray foraging optimization algorithm (HYMRFO). These modifications enhance the MRFO algorithm's search capabilities and avoid getting trapped in local minima. The CEC-BC-2017 benchmark functions were used to examine the performance of six revised mathematical spiral feeding strategies for MRFO algorithm, and the S6MRFO algorithm with the best results was chosen. Combining the S6MRFO algorithm with other intelligent optimization algorithms, such as the Grey Wolf Optimizer (GWO), Arithmetic Optimization Algorithm (AOA), Multi-Verse Optimizer (MVO), Harris Hawk Optimization (HHO), Whale Optimization Algorithm (WOA), Sine Cosine Algorithm (SCA) and Ant Lion Optimizer (ALO) are compared together for optimal performance. Finally, the CEED cases with twenty units of 2500 MW and six units with four different loads (150 MW, 175 MW, 200 MW, and 225 MW) were solved by MRFO algorithm based on nonlinear convergence factors. The simulation results show that in all four test cases, the suggested strategy has the lowest fuel cost and the fewest hazardous emissions, where total costs are about 3% less than PSO and emissions are about 5.6% less.},
  archive      = {J_SOCO},
  author       = {Zhang, Xing-Yue and Wang, Jie-Sheng and Zhu, Jun-Hua and Bao, Yin-Yin and Zheng, Yue and Hao, Wen-Kuo},
  doi          = {10.1007/s00500-025-10402-8},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {1053-1089},
  shortjournal = {Soft Comput.},
  title        = {Nonlinear convergence factor-based manta ray foraging optimization algorithm for combined economic emission dispatch problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global vision, local focus: The semantic enhancement transformer network for crowd counting. <em>SOCO</em>, <em>29</em>(2), 1035-1052. (<a href='https://doi.org/10.1007/s00500-025-10506-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic crowd counting has made significant progress in recent years. However, due to the challenge of multi-scale variations, convolutional neural networks (CNNs) with fixed-size kernels cannot effectively address this difficulty, leading to a severe limitation on counting performance. To alleviate this issue, we propose a semantic enhancement Transformer crowd counting network (named SET) to improve the semantic encoding relationships in crowd scenes. The SET integrates global attention from Transformer, learnable local attention, and inductive bias from CNNs into a counting model. Firstly, we introduce an efficient Transformer encoder to extract low-level global features of crowd scenes. Secondly, we propose a hybrid convtrans module to dynamically learn appropriate weights for different regions, aiding in enhancing the model’s global visual understanding. Finally, in order to guide the model to focus better on crowd regions, we jointly employ a segmentation attention module and a feature aggregation module to aggregate semantic and spatial features at multiple levels, thus obtaining finer-grained features. We conduct extensive experiments on four challenging datasets, including ShanghaiTech Part A/B, UCF-QNRF, and JHU-Crowd++, achieving excellent results.},
  archive      = {J_SOCO},
  author       = {Wang, Mingtao and Zhou, Xin and Chen, Yuanyuan},
  doi          = {10.1007/s00500-025-10506-1},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {1035-1052},
  shortjournal = {Soft Comput.},
  title        = {Global vision, local focus: The semantic enhancement transformer network for crowd counting},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A semantic approach for cultural heritage ontology matching and integration based on textual and multimedia information. <em>SOCO</em>, <em>29</em>(2), 1019-1034. (<a href='https://doi.org/10.1007/s00500-025-10517-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the digital era, where more and more complex tasks are demanded by automatic agents, often provided with artificial intelligence, the problem of data management and information extraction has assumed an increasingly central role. In particular, the process of obtaining information from data has to face manifold issues due to the large volume and heterogeneity of data sources. In this context, a domain or a concept of the real world can have several representations in different data sources. Therefore, there is a need for methods and tools for automatically reorganizing and reusing information embedded in data. The main purpose of this work is to describe a framework for ontology matching and merging based on a novel approach that exploits multimedia information as a combination of text and images. We also present and discuss a case study on Cultural Heritage to assess and evaluate the effectiveness of our proposed approach.},
  archive      = {J_SOCO},
  author       = {Rinaldi, Antonio Maria and Russo, Cristiano and Tommasino, Cristian},
  doi          = {10.1007/s00500-025-10517-y},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {1019-1034},
  shortjournal = {Soft Comput.},
  title        = {A semantic approach for cultural heritage ontology matching and integration based on textual and multimedia information},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing the combined compromise solution method for group decision-making under intuitionistic fuzziness: An application to blended english teaching quality evaluation in vocational colleges. <em>SOCO</em>, <em>29</em>(2), 1005-1017. (<a href='https://doi.org/10.1007/s00500-025-10417-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating the quality of blended English teaching in vocational colleges involves a comprehensive approach that considers instructional design, implementation, student engagement, and learning outcomes. By addressing these dimensions and continuously seeking improvement, vocational colleges can enhance the effectiveness of their blended learning programs. The evaluation of blended English teaching quality in vocational colleges involves a multiple-attribute group decision-making (MAGDM) process. Currently, the CoCoSo approach was utilized to address MAGDM challenges. Intuitionistic fuzzy sets (IFSs) serve as tools to represent uncertain data during the evaluation process. This study introduces the intuitionistic fuzzy number CoCoSo (IFN-CoCoSo) approach, designed to handle MAGDM by incorporating Hamming distance, Euclidean distance and logarithmic distance within IFSs. A numerical study on the evaluation of blended English teaching quality in vocational colleges is provided to validate the IFN-CoCoSo approach. The major contributions of this study are assembled: (1) Extension of the CoCoSo approach to IFSs; (2) Use of entropy to derive weights based on three kinds of distance measures within IFSs; (3) Development of the IFN-CoCoSo approach to manage MAGDM using these distances within IFSs; (4) Provision of a numerical study and comparative analysis to validate the proposed approach for evaluating blended English teaching quality in vocational colleges.},
  archive      = {J_SOCO},
  author       = {Xie, Bin and Yuan, Hongmiao},
  doi          = {10.1007/s00500-025-10417-1},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {1005-1017},
  shortjournal = {Soft Comput.},
  title        = {Enhancing the combined compromise solution method for group decision-making under intuitionistic fuzziness: An application to blended english teaching quality evaluation in vocational colleges},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling of the blockchain-empowered cloud 4D printing services collaboration digital twin platform oriented on supply–demand. <em>SOCO</em>, <em>29</em>(2), 977-1004. (<a href='https://doi.org/10.1007/s00500-025-10461-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the widespread adoption of digital twin and blockchain technologies within the frameworks of Industry 4.0 and intelligent manufacturing has intensified the emphasis on globalization and social collaborative manufacturing. This study aims to address the fragmentation of global information and enhance the collaborative utilization and optimal sharing of underutilized manufacturing resources and capabilities through the development of the C4DPSC_DT platform. To meet these demands, our research focuses on the domain of 4D printing and introduces the blockchain-empowered C4DPSC_DT platform, which is based on dynamic supply and demand principles. This platform is meticulously analyzed to unveil its complex nature, characterized by the integration of physical entities, virtual twin representations, and collaborative services, forming five distinct attributes under this triadic fusion. To further enhance the adaptability of the C4DPSC_DT platform, we propose an adaptive collaborative microservice architecture. Additionally, to emphasize the collaborative service attributes of the platform, we introduce the blockchain-empowered C4DPSC framework. This framework incorporates a collaborative multi-chain blockchain structure and the HotStuff consensus algorithm, facilitating the creation of a secure, distributed, traceable, and transparent environment for sharing C4DP resources and collaboration in C4DP services, thereby establishing decentralized and trustworthy collaborative service connections. Moreover, we systematically decompose the collaborative process into five stages, providing a comprehensive lifecycle solution for the systematic analysis and understanding of the 4D Printing Service collaboration process. Finally, through detailed case studies, we empirically validate the exceptional performance of the C4DPSC_DT platform, confirming its superior functionality and robustness.},
  archive      = {J_SOCO},
  author       = {Liu, Jiajia and Zainudin, Edi Syams and As’arry, Azizan Bin and Ismai, Mohd Idris Shah Bin and Zhang, Chenglei},
  doi          = {10.1007/s00500-025-10461-x},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {977-1004},
  shortjournal = {Soft Comput.},
  title        = {Modeling of the blockchain-empowered cloud 4D printing services collaboration digital twin platform oriented on supply–demand},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear complex dynamic system identification based on a novel recurrent neural network. <em>SOCO</em>, <em>29</em>(2), 957-976. (<a href='https://doi.org/10.1007/s00500-025-10457-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposed a novel Modified Jordan Recurrent Neural Network (MJRNN) model to identify complex nonlinear dynamical systems. Due to its capabilities, nonlinear dynamic system identification using artificial neural networks is the most commonly used method in control system engineering. The structure of the proposed model is an extended version of the original Jordan recurrent neural network model. The parameter update equations are obtained using the back-propagation optimization algorithm, the most frequently used method as a learning approach for the training of the proposed model’s parameters. The effectiveness of the proposed neural network model is evaluated in comparison to other neural network models such as the Jordan recurrent neural network (JRNN), Elman recurrent neural network (ERNN), Diagonal recurrent neural network (DRNN), and feed-forward neural network (FFNN) models. The robustness of the proposed model is also tested with parameter variation and disturbance signals. The simulation results have shown that the proposed model performs better than the other neural network models.},
  archive      = {J_SOCO},
  author       = {Saini, Kartik and Kumar, Narendra and Bhushan, Bharat and Kumar, Rajesh},
  doi          = {10.1007/s00500-025-10457-7},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {957-976},
  shortjournal = {Soft Comput.},
  title        = {Nonlinear complex dynamic system identification based on a novel recurrent neural network},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inverse fuzzy graph colouring and its application. <em>SOCO</em>, <em>29</em>(2), 945-956. (<a href='https://doi.org/10.1007/s00500-025-10460-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a novel colouring method called I-fuzzy graph colouring for inverse fuzzy graphs. It defines the chromatic number of inverse fuzzy graphs and explores the relationship between the resultant I-fuzzy graph’s chromatic number and those of individual inverse fuzzy graphs. Various operations, including I-fuzzy union, I-fuzzy intersection, quasi I-fuzzy union, and restricted I-fuzzy union, are employed to establish these relationships. Moreover, we investigate the chromatic number relationship by replacing edge values. The practical application of I-fuzzy graph colouring is demonstrated in determining the simultaneous intake of drugs. Additionally, we observe the MCA problem in inverse fuzzy graphs by considering only I-fuzzy graph colouring functions.},
  archive      = {J_SOCO},
  author       = {Purakkal, Kadeeja Mole Koyalinte and Kalathodi, Sameena},
  doi          = {10.1007/s00500-025-10460-y},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {945-956},
  shortjournal = {Soft Comput.},
  title        = {Inverse fuzzy graph colouring and its application},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fuzzy-bayesian belief network approach to compute efficiency as a metric for IoT systems. <em>SOCO</em>, <em>29</em>(2), 933-944. (<a href='https://doi.org/10.1007/s00500-025-10510-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In IoT applications, a multitude of devices communicate through interconnected networks, collaborating on decision-making tasks. Ensuring the efficiency of such IoT systems is crucial and requires addressing the management of resources. The article primarily focuses on the computation of efficiency in IoT applications, specifically considering metrics such as availability, functional correctness, and throughput. These metrics directly correlate with packet transfer information. Our main objective is to establish the efficiency of an IoT application by employing metrics related to packet transfer rate, utilizing a fuzzy-based Bayesian belief model. Key metrics such as availability, functional correctness, and throughput are commonly utilized to gauge the performance of packet transfer. To achieve this, we propose a Bayesian Belief Network (BBN) model that incorporates these metrics. To calculate efficiency, we have employed a fuzzy-based approach within the Fuzzy Inference System (FIS), which allows for efficient computation when crisp values of availability, functional correctness, and throughput are provided.},
  archive      = {J_SOCO},
  author       = {Pandey, Rishabh Deo and Snigdh, Itu},
  doi          = {10.1007/s00500-025-10510-5},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {933-944},
  shortjournal = {Soft Comput.},
  title        = {A fuzzy-bayesian belief network approach to compute efficiency as a metric for IoT systems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing teaching learning based optimization algorithm through group discussion strategy for CEC 2017 benchmark problems. <em>SOCO</em>, <em>29</em>(2), 895-932. (<a href='https://doi.org/10.1007/s00500-025-10409-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-heuristics are utilized to handle challenging optimization problems, since conventional optimization techniques for such problems often fail or become stuck in the local optimum. Teaching-learning based optimization algorithm (TLBO) is a prominent meta-heuristic that mimics the teaching-learning process. It is initially employed to tackle unconstrained optimization problems. The main obstacle to meta-heuristics is premature convergence. The strategy of forming groups of students is introduced in the teaching-learning process for mutual discussions and joint projects. Along with some advantages, like increased creativity, diversity of ideas, access to new information, and more critical thinking, the group discussion strategy also has few disadvantages, such as disagreements over ideas, group size sensitivity, dependency on others, and lengthened the completion time. If properly implemented, the strategy can be a useful tool in the teaching-learning process. To increase an algorithm local search capabilities and to produce solutions of diverse nature, it is essential to have sufficient knowledge about the optimum solution with enough population diversity. Through group discussion sufficient information with diverse views about the solution of the problem is obtained. Therefore, in this work, the group discussion strategy is embedded to the learner phase of TLBO to enhance it. In the strategy, the group of randomly selected individuals correspond to each candidate solution is made to minimize the happening of premature convergence. This strategy depends on the group size parameter; for which the sensitivity analysis is also performed to obtain the right/optimal value. The suggested algorithm is known as GTLBO, and the group size parameter sensitivity analysis generates its four versions, referred to as GTLBO2–GTLBO5, where the digits 2–5 represent the group size value. The performance of the proposed algorithms is evaluated by the unconstrained benchmark problems of CEC 2017. The comparison of the obtained simulations’ results of the newly designed and some state-of-the-art algorithms on the tested problems exhibits that the suggested algorithms take the first, third, fourth, and fifth ranks in the top five ranks, which highlights the importance of the introduced strategy in the sense of enhancing TLBO.},
  archive      = {J_SOCO},
  author       = {Sagheer, Muhammad and Asif Jan, Muhammad and Shah, Zahir and Mashwani, Wali Khan and Adeeb Khanum, Rashida and Shutaywi, Meshal},
  doi          = {10.1007/s00500-025-10409-1},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {895-932},
  shortjournal = {Soft Comput.},
  title        = {Enhancing teaching learning based optimization algorithm through group discussion strategy for CEC 2017 benchmark problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-based optimization in epidemics prevention. <em>SOCO</em>, <em>29</em>(2), 875-893. (<a href='https://doi.org/10.1007/s00500-025-10494-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a method for knowledge-based optimization of vaccination assignments is proposed, which combines multiobjective optimization algorithms with counter-epidemic strategies known from epidemiology. In the paper, a model based on real-life illness costs is used, which allows taking into account the age of individuals exposed to a simulated epidemic. Using this model, strategies based on the age and on the graph node degree (the number of contacts each individual has) are studied. The optimization algorithms work on a graph which represents a “known” network of contacts and the solutions are subsequently used for controlling an epidemic spreading on another graph representing an “actual” network of contacts. The optimized solutions are tested on “actual” graphs with a varying degree of overlap with the “known” graph on which the optimization algorithms work. In the experiments, the age-based strategy was found to perform best, and the degree-based strategy turned out to be the second-best approach. Both these strategies outperformed other approaches not using knowledge from epidemiology to improve optimization results.},
  archive      = {J_SOCO},
  author       = {Michalak, Krzysztof},
  doi          = {10.1007/s00500-025-10494-2},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {875-893},
  shortjournal = {Soft Comput.},
  title        = {Knowledge-based optimization in epidemics prevention},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new mathematical optimization-based method for the m-invariance problem. <em>SOCO</em>, <em>29</em>(2), 861-873. (<a href='https://doi.org/10.1007/s00500-025-10514-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy preserving dynamic data publication aims at protecting data while simultaneously preserving its utility when the data is published dynamically. For static data (i.e., data published only once), privacy is based on concepts such as k-anonymity and $$\epsilon $$ -differential privacy. In contrast, for dynamic data, the notions of m-invariance and $$\tau $$ -safety are considered. However, most current approaches focus solely on guaranteeing m-invariance and $$\tau $$ -safety without paying attention to the quality of the solution, such as maximizing utility. We propose a new heuristic approach for the NP-hard combinatorial problem of m-invariance and $$\tau $$ -safety, which is based on a mathematical optimization column generation scheme. The quality of a solution to m-invariance and $$\tau $$ -safety can be measured by the Information Loss (IL), a value in [0, 100], the closer to 0 the better. We show that our approach improves by far current heuristics, reducing IL by more than $$60\%$$ and, in some instances, by more than $$95\%$$ .},
  archive      = {J_SOCO},
  author       = {Tobar Nicolau, Adrián and Castro, Jordi and Gentile, Claudio},
  doi          = {10.1007/s00500-025-10514-1},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {861-873},
  shortjournal = {Soft Comput.},
  title        = {A new mathematical optimization-based method for the m-invariance problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Period regulated particle swarm optimization algorithm. <em>SOCO</em>, <em>29</em>(2), 839-860. (<a href='https://doi.org/10.1007/s00500-025-10428-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population cycles refer to the regular fluctuations in population size over time. Inspired by this phenomenon, we introduce a period-regulating factor into the particle swarm optimization (PSO) algorithm and propose a modified period-regulated particle swarm optimization (PPSO) algorithm. This algorithm allows for dynamic parameter adjustments in each particle, maintaining a balance between exploitation and exploration. To enhance the diversity of the swarm, we introduce a selection mechanism that enables particles to choose between the global optimum and a new learning object called the mean optimum. Additionally, we incorporate a multi-particle mutation mechanism to improve the particles’ ability to escape local optima. A set of benchmark functions and classical engineering problems are used to verify the superiority of the PPSO algorithm. The results show that the PPSO can provide a very competitive performance compared to some popular PSO variants and meta-heuristic algorithms. Furthermore, this algorithm retains the advantages of simplicity of implementation inherent in PSO.},
  archive      = {J_SOCO},
  author       = {Liu, Zhilong and Jiang, Huhai},
  doi          = {10.1007/s00500-025-10428-y},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {839-860},
  shortjournal = {Soft Comput.},
  title        = {Period regulated particle swarm optimization algorithm},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved snake optimizer based on forced switching mechanism and variable spiral search for practical applications problems. <em>SOCO</em>, <em>29</em>(2), 803-838. (<a href='https://doi.org/10.1007/s00500-025-10404-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an improved snake optimizer (ISO) enhances snake optimizer (SO) by introducing novel mechanisms for improving convergence ability and stability. Based on the “No Free Lunch” theory, this paper discusses the development status of swarm intelligence algorithms. ISO introducing a chaotic mapping strategy allows the population to generate uniform and randomly distributed initial values at the beginning of ISO. A forced switching mechanism improving the balance between two different updating phases is introduced to address the slow convergence rate based on SO. A variant strategy of whale optimization algorithm is used to make further improvement for exploration of SO. The optimal domain perturbation strategy is used to find a better value near the result after above process. These enhancements result a more robust and effective optimization framework suiting to solve complex continuous optimization problems across various domains. The convergence ability and stability are validated by comparing ISO with SO and eight other classical or latest algorithms with dimensionality setting as Dim = 10 and Dim = 20 in the test functions from CEC-2021. The convergence efficiency achieves 94/160 and the convergence stability achieves 77/160. The ratio of convergence efficiency achieves $$100\%$$ and the ratio of convergence stability achieves $$96.25\%$$ in the applicable functions which are half of CEC-2021 functions. They represent the problems which ISO performs well. The practicality of ISO is further illustrated using three continuous optimization problems. Based on the simulation results, the discretization of ISO is prospected to solve combinatorial optimization problems.},
  archive      = {J_SOCO},
  author       = {Wang, Yanfeng and Xin, Bingqing and Wang, Zicheng and Sun, Junwei},
  doi          = {10.1007/s00500-025-10404-6},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {803-838},
  shortjournal = {Soft Comput.},
  title        = {Improved snake optimizer based on forced switching mechanism and variable spiral search for practical applications problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spark workflow task scheduling with deadline and privacy constraints in hybrid cloud networks. <em>SOCO</em>, <em>29</em>(2), 783-801. (<a href='https://doi.org/10.1007/s00500-025-10486-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing adoption of hybrid clouds in organizations stems from their ability to bolster private cloud resources with additional public cloud capacity when required. However, scheduling distributed applications, such as workflow tasks, on hybrid cloud resources presents new and intricate challenges. A significant concern revolves around the potential exposure of private data and tasks within third-party, public cloud infrastructures, especially within sensitive domains like healthcare applications. The complexity escalates when considering the selection of resources from multiple cloud providers due to the fluctuating resource computation prices and data transmission costs. This paper presents the Spark Workflow Task Scheduling to Hybrid Cloud (SWSHC) framework, designed to schedule Spark workflows precisely while adhering to deadline and task privacy constraints within a hybrid cloud setting. Our innovative approach encompasses developing and implementing three pivotal components: deadline division, stage order optimization, and task scheduling mechanisms. We segregate the workflow deadline for each stage to bridge the gaps between stages effectively. Additionally, job prioritization is achieved using the maximum rank rule. The proposed solution considers diverse factors, including interval pricing variations, utilization of heterogeneous VM instances, intra- and inter-bandwidth considerations, and the efficient utilization of private cloud resources. Through meticulous calibration of our algorithm and comprehensive experimentation with various realistic workflows, our findings unequivocally demonstrate that SWSHC surpasses existing solutions in the current literature the cost by up to 40–70% in terms of cost efficiency and resource utilization.},
  archive      = {J_SOCO},
  author       = {Rajput, Kamran Yaseen and Xiaoping, Li and Lakhan, Abdullah},
  doi          = {10.1007/s00500-025-10486-2},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {783-801},
  shortjournal = {Soft Comput.},
  title        = {Spark workflow task scheduling with deadline and privacy constraints in hybrid cloud networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fault-tolerant scheduling strategy through proactive and clustering techniques for scientific workflows in cloud computing. <em>SOCO</em>, <em>29</em>(2), 755-781. (<a href='https://doi.org/10.1007/s00500-025-10485-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing offers solutions for various scientific and business applications. Large-scale scientific applications, which are organized as scientific workflows, are carried out using cloud computing. However, the higher failure rates in cloud computing can be attributed to the numerous servers and components dealing with intense workloads. This study presents a fault-tolerant scheduling approach using proactive and clustering methods for scientific workflows in cloud computing. Initially, the task clustering issue is addressed by consolidating multiple short-duration tasks into a single job to improve the runtime performance of workflow executions. Subsequently, an automated workflow scheduling strategy is outlined with four key stages: monitoring, analysis, planning, and execution. During monitoring, clustered jobs and the capacities of available cloud resources are observed. In the analysis phase, the accuracy of failure prediction is enhanced by employing the Group Method of Data Handling (GMDH) neural network prior to any faults or failures. The planning stage introduces a novel hybrid multi-objective algorithm, MOPSO-aSA, based on MOPSO and adaptive simulated annealing (SA), to streamline workflow scheduling in error-prone execution environments. Moreover, the reliability of application execution is maintained through re-clustering and migration techniques following any faults or failures. Finally, based on the experimental findings, it is evident that the proposed strategy surpasses other methods in terms of makespan, total cost, energy consumption, and failure rate.},
  archive      = {J_SOCO},
  author       = {Farhood, Suha Mubdir and Khorsand, Reihaneh and Hussein, Nashwan Jasim and Ramezanpour, Mohammadreza},
  doi          = {10.1007/s00500-025-10485-3},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {755-781},
  shortjournal = {Soft Comput.},
  title        = {A fault-tolerant scheduling strategy through proactive and clustering techniques for scientific workflows in cloud computing},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A surrogate archive assisted multi-objective evolutionary algorithm under limited computational budget. <em>SOCO</em>, <em>29</em>(2), 723-753. (<a href='https://doi.org/10.1007/s00500-025-10432-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of archives has received significant attention within the realm of multi-objective optimization. However, there exists a substantial gap in exploring archives within surrogate-assisted multi-objective evolutionary algorithms (SAMOEAs). In this paper, a novel framework called surrogate archive assisted multi-objective evolutionary algorithm (SAAMOEA) is introduced. The framework uses a surrogate archive to guide the evolution of the algorithm. This archive serves as an external database to store individuals that perform better during evolution, reducing the randomness of the individuals. Firstly, the surrogate archive is initialized using multiple MOEAs, and the surrogate constructed by the individuals in this initialization archive are used to approximate the exact function. Secondly, a cluster-based model management strategy is proposed that employs K-means method to fit the Pareto front and identify infilled individuals. Simultaneously, an environment selection method is proposed. The method determines whether infilled individuals are used to update the surrogate by calculating a convergence quality metric. The quality of the individuals in the surrogate archive is maintained inversely through the two strategies described above to provide conditions for accurate model construction. Furthermore, the paper presents three hypotheses about the relationship between the Pareto front of the surrogate model and the Pareto front of the exact function evaluation. The SAAMOEA was compared to ten state-of-the-art (SOTA) algorithms, and simulation experiments were conducted on 12 benchmark functions to obtain non-parametric estimation results and distribution plots of the true PF. Additionally, SAAMOEA was validated on an airfoil design optimization problem. The HV results and optimized parameter results demonstrate the performance advantages of the algorithm.},
  archive      = {J_SOCO},
  author       = {Wang, Le and Fan, Qinqin and Yan, Xuefeng},
  doi          = {10.1007/s00500-025-10432-2},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {723-753},
  shortjournal = {Soft Comput.},
  title        = {A surrogate archive assisted multi-objective evolutionary algorithm under limited computational budget},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing voltage stability and load shedding optimization through a fusion of gravitational search algorithm and particle swarm optimization with deep learning. <em>SOCO</em>, <em>29</em>(2), 701-721. (<a href='https://doi.org/10.1007/s00500-025-10447-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, A novel approach for optimizing load shedding during power system stress conditions is introduced by combining gravitational search and particle swarm optimization (GSA-PSO) with Deep Learning. This approach aims to determine the most effective load-shedding strategy for specific buses, to prevent revenue loss and voltage instability in power systems. The smallest eigenvalue sensitivity of the load flow Jacobian matrix as an indicator is used to identify the buses for load shedding. Furthermore, inequality constraints are calculated for the current operational state and the anticipated load in the next interval. To evaluate the performance of the proposed approach, experiments were conducted on two different power systems: the IEEE 30-bus and 14-bus systems. The GSAPSO-Deep Learning approach was implemented in the Python environment. The results obtained using the proposed method were compared with those of other models, as well as their variants, using statistical inference.},
  archive      = {J_SOCO},
  author       = {Ahmadipour, Masoud and Ali, Zaipatimah and Ridha, Hussein Mohammed},
  doi          = {10.1007/s00500-025-10447-9},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {701-721},
  shortjournal = {Soft Comput.},
  title        = {Enhancing voltage stability and load shedding optimization through a fusion of gravitational search algorithm and particle swarm optimization with deep learning},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning for healthcare 5.0: A comprehensive survey, taxonomy, challenges, and solutions. <em>SOCO</em>, <em>29</em>(2), 673-700. (<a href='https://doi.org/10.1007/s00500-025-10508-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of Healthcare 5.0 heralds a groundbreaking revolution in digital healthcare, superseding the achievements of its predecessor, Healthcare 4.0. Integrating cutting-edge technologies such as the Internet of Medical Things (IoMT), smart wearables, and the extraordinary capabilities of Artificial Intelligence (AI), Healthcare 5.0 envisions a unified framework that grants seamless access to health records, fosters interconnectedness among individuals, resources, and institutions, and empowers intelligent responses to medical concerns. However, the realization of Healthcare 5.0 faces a significant challenge in the form of high-speed data transmission using smart devices. Conventional AI approaches relying on centralized data processing raise compelling concerns surrounding information privacy and scalability within the Healthcare 5.0 context. Amidst this backdrop, federated learning emerges as a beacon of hope, offering a decentralized AI paradigm that facilitates on-device machine learning without compromising end-user privacy through centralized data export. Safeguarding data integrity, federated learning holds the key to unlocking the full potential of Healthcare 5.0. In this pioneering study, we conduct an extensive survey, exploring the transformative implications of federated learning within the realm of Healthcare 5.0. By shedding light on recent advancements tailored to this paradigm, we delve into the fundamental concepts of resource-awareness, privacy preservation, incentivization, and personalization, all within the framework of federated learning. Moreover, we meticulously scrutinize key parameters including security, sparsification, quantization, robustness, scalability, and privacy, providing an authentic evaluation of the current progress in federated learning for Healthcare 5.0. This comprehensive survey serves as an indispensable cornerstone for the evolution of Healthcare 5.0, offering invaluable insights into its unique requirements and untapped potential. By harnessing the capabilities of federated learning in this context, we envisage a transformative era in digital healthcare, fostering a more interconnected, secure, and intelligent healthcare landscape for the betterment of society.},
  archive      = {J_SOCO},
  author       = {Amin, Muhammad Sadiq and Ahmad, Shabir and Loh, Woong-Kee},
  doi          = {10.1007/s00500-025-10508-z},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {673-700},
  shortjournal = {Soft Comput.},
  title        = {Federated learning for healthcare 5.0: A comprehensive survey, taxonomy, challenges, and solutions},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STA-CN-BiGRU: A spatial-temporal attention based ChebNet and BiGRU model for traffic flow prediction. <em>SOCO</em>, <em>29</em>(2), 663-672. (<a href='https://doi.org/10.1007/s00500-025-10464-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is critical to the collaborative decision support function of traffic management. However, it remains a challenging problem because of the inherent nonlinear dynamics, stochasticity, and spatial-temporal correlation of traffic flows. In this paper, a traffic flow prediction model called Spatial-Temporal Attention based ChebNet and BiGRU model (STA-CN-BiGRU), which consists of several layers of ST-Residual Block, is proposed. Firstly, ChebNet is used to learn the spatial dependence of traffic flow caused by the topology of the road network. BiGRU is combined with CNN for capturing the spatial and multi-scale temporal correlation of traffic flows. Then, in order to incorporate the different importance levels of temporal and spatial dependencies for each node, a hybrid spatio-temporal attention module is incorporated into the traffic flow prediction model and then a ST-Residual Block is constructed. Further, the outputs of multiple component traffic flows are weighted fused to obtain the final predictions. Finally, the performance of the proposed model has been extensively evaluated on real-world datasets in terms of one-step ahead prediction, multi-step ahead prediction, and ablation study. The results show that the proposed model can improve the prediction accuracy over the baselines, especially outperforming other models in long-term prediction.},
  archive      = {J_SOCO},
  author       = {Huifang, Feng and Rui, Yang},
  doi          = {10.1007/s00500-025-10464-8},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {663-672},
  shortjournal = {Soft Comput.},
  title        = {STA-CN-BiGRU: A spatial-temporal attention based ChebNet and BiGRU model for traffic flow prediction},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trustworthy deep learning for encrypted traffic classification. <em>SOCO</em>, <em>29</em>(2), 645-662. (<a href='https://doi.org/10.1007/s00500-025-10462-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network traffic classification refers to the identification of collected network traffic data of various applications, which is widely used in research fields such as network resource allocation, traffic scheduling and intrusion detection systems. With the widespread application of encryption technology in the network, encrypted traffic classification has become a hot research topic. At present, most existing methods only focus on the accuracy of network traffic classification. Yet, few work studies the reliability of the classification model, which plays an important role in network regulation and network security. In this paper, we propose a novel traffic classification method based on trustworthy deep learning model, which can effectively improve the reliability of encrypted traffic classification models by correcting the confidence of model output. Specifically, we firstly perform data preprocessing on the original network traffic, and then adopt a ConvNet for feature learning and a ClassifyNet for traffic classification in the initial stage. At the same time, we utilize a trustworthy confidence criterion to design a ConfidNet trained according to the probability of the true class. The ConfidNet can provide a reliable confidence measure for the prediction of the classification model. Finally, we demonstrate the effectiveness of our framework through comprehensive experiments on two benchmark datasets ISCX VPN-nonVPN and USTC-TFC2016, and show that our method can improve the reliability of the classification model and has a good ability to identify misclassified samples compared with state-of-the-art methods.},
  archive      = {J_SOCO},
  author       = {Li, Zheng and Liu, Yanbei and Zhang, Changqing and Shan, Wanjin and Zhang, Haifeng and Zhu, Xiaoming},
  doi          = {10.1007/s00500-025-10462-w},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {645-662},
  shortjournal = {Soft Comput.},
  title        = {Trustworthy deep learning for encrypted traffic classification},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel approach of multi-channel attention mechanism for long-sequential multivariate time-series prediction problem. <em>SOCO</em>, <em>29</em>(2), 629-644. (<a href='https://doi.org/10.1007/s00500-025-10501-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The time-dependent and long sequential time-series is always considered as a challenging problem. It normally demands the robust machine learning (ML) or deep learning (DL)-based techniques to efficiently preserve the long-ranged dependencies within intricate time-series datasets. In recent years, transformer-based architectures have emerged as a powerful tool across various data mining fields, particularly in natural language processing (NLP). These architectures are widely regarded for their ability to effectively handle long-range dependencies in sequence-based data structures, such as text and time-dependent datasets. Consequently, transformers have paved the way for advancements in complex long-sequence time-series forecasting tasks. However, recent studies have highlighted limitations in transformer-based predictive models, particularly in their ability to fully capture the joint spatial and temporal representations within input sequences. To address these challenges, we propose a novel approach in this paper, multi-channel attention transformer for time-series (MAT4TS). Our MAT4TS model enhances the performance of long-sequence time-series forecasting by extending the conventional self-attention mechanism. This enhanced self-attention is complemented by additional multi-channel filtering and embedding processes, leveraging convolutional neural network (CNN)-based architectures. By integrating these processes, our model is able to extract richer spatial–temporal information from long-range sequences, ultimately leading to more accurate prediction outcomes. The comprehensive comparative studies within real-world long-sequential time-series datasets demonstrated the effectiveness as well as superiority of our proposed MAT4TS model for dealing with long-ranged time-series prediction problem in comparing with previous state-of-the-art baselines.},
  archive      = {J_SOCO},
  author       = {Vo, Tham and My, Linh Nguyen Thi},
  doi          = {10.1007/s00500-025-10501-6},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {629-644},
  shortjournal = {Soft Comput.},
  title        = {A novel approach of multi-channel attention mechanism for long-sequential multivariate time-series prediction problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zoom method for association rules in multi-granularity formal context. <em>SOCO</em>, <em>29</em>(2), 613-627. (<a href='https://doi.org/10.1007/s00500-025-10472-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on a granularity tree, this paper investigates the changes in association rules before and after attribute granularity transformation in a formal context. It introduces zoom algorithms to update association rules. The zoom-in algorithm is applied to refine the attribute granularity from coarse to fine, while the zoom-out algorithm achieves the attribute granularity from fine to coarse. These zoom algorithms enable the direct manipulation of association rules in the original formal context, using concepts as a bridge to generate association rules in the new context. This approach eliminates the need for reconstructing the concept lattice when attribute granularity changes. Experimental results demonstrate that the algorithm proposed in this paper significantly reduces computational workload and shortens running time compared to the classical algorithm flow.},
  archive      = {J_SOCO},
  author       = {Niu, Lihui and Mi, Jusheng and Bai, Yuzhang and Li, Zhongling and Li, Meizheng},
  doi          = {10.1007/s00500-025-10472-8},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {613-627},
  shortjournal = {Soft Comput.},
  title        = {Zoom method for association rules in multi-granularity formal context},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust security risk estimation for android apps using nearest neighbor approach and hamming distance. <em>SOCO</em>, <em>29</em>(2), 593-611. (<a href='https://doi.org/10.1007/s00500-025-10489-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, Android-based devices such as smart phones, tablets, smart watches, and virtual reality headsets have found increasing use in our daily lives. Along with the development of various applications for these devices, new malicious apps are released by intruders, which are more difficult to identify and deal with because they exploit more sophisticated techniques. Although methods have been provided to calculate the security risk and identify malicious apps in Android operating system, but with the expansion of the level and depth of the threats, the need for more effective methods in this context is still required. In this paper, we have devised a new algorithm to calculate the security risk of Android apps, which can be used to identify malicious apps from benign ones. In this algorithm, to estimate the security risk of an unknown input app, its nearest neighbors to malicious apps and its nearest neighbors to normal apps are computed separately using Hamming distance. Then, the security risk of the input app can be computed using a simple formulation. After implementing this algorithm, its parameter for the number of neighbors using various real datasets is adjusted. The extensive experiments conducted on these data show the superiority of the proposed method over the previously proposed ones in terms of detection rate. Our additional experimentations show the robustness of the proposed algorithm in adversarial situations.},
  archive      = {J_SOCO},
  author       = {Deypir, Mahmood and Zoughi, Toktam},
  doi          = {10.1007/s00500-025-10489-z},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {593-611},
  shortjournal = {Soft Comput.},
  title        = {Robust security risk estimation for android apps using nearest neighbor approach and hamming distance},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the maximization of the likelihood for the generalized gamma distribution: The modified maximum likelihood approach. <em>SOCO</em>, <em>29</em>(2), 579-591. (<a href='https://doi.org/10.1007/s00500-025-10498-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximum likelihood (ML) estimation of parameters of the generalized gamma (GG) distribution has been considered in several papers, and some of them stated that the ML estimation has some computational difficulties. Therefore, different approaches including numerical methods have been proposed for the ML estimation of parameters of the GG distribution. However, it is known that using numerical methods may have some drawbacks, e.g., non-convergence of iterations, multiple roots, and convergence to the wrong root. In this study, we rehabilitate the ML procedure via the modified ML (MML) methodology and obtain the likelihood equations in which two of them have explicit solutions, and the remaining one should be solved numerically. Since the MML methodology explicitly solves two of three likelihood equations, the mentioned drawbacks are alleviated. We also propose a simple algorithm to obtain the estimates of the parameters of the GG distribution. Then, the GG distribution is used for modeling the real data sets, and the performance of the proposed algorithm is compared with the Broyden–Fletcher–Goldfarby–Shanno (BFGS) and Nelder–Mead (NM) algorithms. The results show that the proposed algorithm is preferable to the BFGS and NM algorithms in terms of computational sense when considering the GG distribution.},
  archive      = {J_SOCO},
  author       = {Arslan, Talha and Acitas, Sukru and Senoglu, Birdal},
  doi          = {10.1007/s00500-025-10498-y},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {579-591},
  shortjournal = {Soft Comput.},
  title        = {On the maximization of the likelihood for the generalized gamma distribution: The modified maximum likelihood approach},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale risk spillover analysis of china’s stock market industry: Evidence supported by a novel hybrid model based on signal decomposition technology. <em>SOCO</em>, <em>29</em>(2), 559-577. (<a href='https://doi.org/10.1007/s00500-025-10438-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There exists a complex interplay between the aggregate risk of the stock market and the risks inherent to various industries. However, existing studies have largely overlooked the disparities in risk contagion effects between different industries and the overall market across diverse time scales, and there remains instability in delineating risk frequency domains. Consequently, it becomes challenging to fully unravel the intricate correlation dynamics between different industries and the broader stock market across varying temporal dimensions. Therefore, this paper takes the China stock market as a representative of emerging markets, selects eleven distinct industry indices along with the Shanghai-Shenzhen 300 Index (CSI 300 Index), and introduces the Variable Mode Decomposition (VMD) algorithm to extract intricate information from time series data. Additionally, the Fuzzy Entropy (FE) algorithm is employed to effectively reconstruct different frequency domains. Furthermore, this paper integrates the strengths of the Generalized Autoregressive Conditional Heteroskedasticity (GARCH) model, the Copula function, and the Conditional Value at Risk (CoVaR) model. By constructing the novel VMD-FE-GARCH-Copula-CoVaR hybrid model, this research aims to explore the risk contagion characteristics of various industries and the Shanghai-Shenzhen 300 Index across different time scales, offering a fresh perspective for the paper of risk contagion within stock market industries.},
  archive      = {J_SOCO},
  author       = {Linjie, Zhan and Zhenpeng, Tang},
  doi          = {10.1007/s00500-025-10438-w},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {559-577},
  shortjournal = {Soft Comput.},
  title        = {Multiscale risk spillover analysis of china’s stock market industry: Evidence supported by a novel hybrid model based on signal decomposition technology},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On hierarchical clustering-based identification of PWA model with model structure selection and application to automotive actuators for HiL simulation. <em>SOCO</em>, <em>29</em>(2), 543-558. (<a href='https://doi.org/10.1007/s00500-025-10458-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of the electronic control unit (ECU) motivates dynamic models with high precision to simulate mechatronic systems for various analysis and design tasks like hardware-in-the-loop (HiL) simulation. Unlike traditional physical models which are established based on the research experience or the mechanics mechanism, in this study, a novel data-driven modeling approach is presented based on the piecewise affine (PWA) identification method. In this work, the highly nonlinear dynamic of automotive actuators is well approximated by the PWA model. To obtain experimental data that can accurately reflect the characteristics of actuators, a test bench was first built. On this basis, the PWA identification of automotive is composed of the data clustering, the model structure selection, and the model parameter estimation. The proposed clustering method improves the widely used balanced iterative reducing and clustering using hierarchies (BIRCH) by introducing a refinement phase for handling clusters with arbitrary shapes. The model structure selection and the parameter estimation are jointly solved by using the optimization method. The presented method is demonstrated with an academic example and an automotive throttle, and the results show that the proposed method can achieve a high model quality, which means that the normalized root mean squared error (NRMSE) is 0.03 and the absolute maximal prediction error can reach 2.43°. Compared to other models like a physical model or a fuzzy model, the improvement using the proposed model can be up to 50%. Thus, the quality of the proposed PWA model is sufficient for HiL simulation.},
  archive      = {J_SOCO},
  author       = {Ren, Zhenxing},
  doi          = {10.1007/s00500-025-10458-6},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {543-558},
  shortjournal = {Soft Comput.},
  title        = {On hierarchical clustering-based identification of PWA model with model structure selection and application to automotive actuators for HiL simulation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unification of methods for new types of fuzzy sets: General approximation spaces with relational morphisms. <em>SOCO</em>, <em>29</em>(2), 521-542. (<a href='https://doi.org/10.1007/s00500-025-10440-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a general method that can be used to unify the theoretical results for several new MV-valued fuzzy sets, such as intuitionistic fuzzy sets, neutrosophic fuzzy sets, fuzzy soft sets, or multivalued fuzzy sets and their mutual combinations. The results created in this way have properties identical to analogous results for classic MV-valued fuzzy sets, and it is not necessary to prove these results separately for each new type of fuzzy sets. To illustrate this general method, we will show how two related fuzzy Chang topologies can be derived in these new types of fuzzy sets from general approximation spaces.},
  archive      = {J_SOCO},
  author       = {Močkoř, Jiří},
  doi          = {10.1007/s00500-025-10440-2},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {521-542},
  shortjournal = {Soft Comput.},
  title        = {Unification of methods for new types of fuzzy sets: General approximation spaces with relational morphisms},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Addition-meet fuzzy relational inequality systems, product-join relational inequality systems and their generalizations. <em>SOCO</em>, <em>29</em>(2), 509-520. (<a href='https://doi.org/10.1007/s00500-025-10473-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real unit interval valued Addition-min FRI systems are generalized to MV-algebra valued Addition-meet and Product-join fuzzy relational inequality systems, and the latter further to residual lattice valued Product-join relational inequality system. MV-algebra valued Addition-meet FRI systems are further generalized in two ways; on the one hand they are defined on involutive residual lattices and on the other hand as Addition-MV-product systems. It is proved that each such FRI system has a minimal solution or, respectively a maximal solution. The number of such solutions is discussed. Several illustrative examples are given. Through residual lattices and MV-algebras, these systems are linked in a profound way to mathematical fuzzy logic.},
  archive      = {J_SOCO},
  author       = {Turunen, Esko},
  doi          = {10.1007/s00500-025-10473-7},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {509-520},
  shortjournal = {Soft Comput.},
  title        = {Addition-meet fuzzy relational inequality systems, product-join relational inequality systems and their generalizations},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bidirectional online sequence extreme learning machine and switching strategy for soft-sensor model of SMB chromatography separation process. <em>SOCO</em>, <em>29</em>(2), 485-507. (<a href='https://doi.org/10.1007/s00500-025-10444-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulated Moving Bed (SMB) chromatography separation is a novel absorptive separation technique with high separation capacity, and it is challenging to make the process run stably at the desired operating point for a long time. Therefore, powerful, and adaptive soft sensor models are important for the overall stability, efficiency, and optimization of the SMB chromatographic separation process. Extreme Learning Machine (ELM), known for its robust generalization capability, can serve as a valuable soft-sensor model for predicting economic and technical indicators such as purity and yield in SMB chromatography separation processes. To improve the prediction accuracy of ELM, avoid stochasticity and learn incrementally, a bidirectional online sequential ELM (BOSELM) is proposed. BOSELM learns data with fixed or varying block sizes on a one-by-one or block-by-block basis (data chunks) without the need to define the size of the network beforehand and determines the output weights based on the analysis of the sequentially arriving data. On the other hand, BOSELM also makes use of the bidirectional ELM's ability to explore the number of hidden nodes to reduce the number of hidden nodes without affecting the learning efficiency, improving the speed and adaptability of model training. The moving window (MW) strategy was adopted to adaptively correct the BOSELM (MW-BOSELM) to address the issue of decreasing model prediction accuracy caused by changes in process conditions. Additionally, the MW strategy kernel-extreme learning machine (MW-KELM) exhibits higher prediction accuracy than MW-BOSELM at certain instances. To enhance the adaptability of the model, an adaptive hybrid soft-sensor model is proposed to intelligently switch between BOSELM and KELM. Comparative analysis with previous models like BELM, OSELM and BOSELM highlights the superiority of the proposed hybrid adaptive soft-sensor model. Thus, these models help to improve the operational efficiency, product quality and economics of the SMB chromatographic separation process.},
  archive      = {J_SOCO},
  author       = {Sun, Yong-Cheng and Wang, Jie-Sheng and Xing, Cheng and Shang-Guan, Yi-Peng and Wang, Xiao-Tian and Zhang, Song-Bo},
  doi          = {10.1007/s00500-025-10444-y},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {485-507},
  shortjournal = {Soft Comput.},
  title        = {Bidirectional online sequence extreme learning machine and switching strategy for soft-sensor model of SMB chromatography separation process},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ring structure of rough sets. <em>SOCO</em>, <em>29</em>(2), 471-483. (<a href='https://doi.org/10.1007/s00500-025-10476-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough set theory has been extensively studied in regard to its lattice structure. However, this article concerns with the (commutative) ring structure of rough set theory. We show that a finite approximation space can be identified by a cube free natural number $$n$$ by providing an isomorphism between lattice of rough sets and lattice of ideals of the ring $$\mathbb {Z}_{n}$$ . We introduce a ring structure on the rough sets via the ring structure on ideals of $$\mathbb {Z}_{n}$$ . Moreover, we also classify all the rings which are isomorphic to the rings formed by the rough sets.},
  archive      = {J_SOCO},
  author       = {Kumar, Arun and Dewan, Bisham},
  doi          = {10.1007/s00500-025-10476-4},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {471-483},
  shortjournal = {Soft Comput.},
  title        = {Ring structure of rough sets},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamical behavior and chaos control of the conflicting information propagation on a homogeneous network system. <em>SOCO</em>, <em>29</em>(2), 457-469. (<a href='https://doi.org/10.1007/s00500-025-10430-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple pieces of information regularly propagate in a social network. Different political party supporters utilize social systems not only for campaigning, publicity but also for opposing the opinions of other parties. They always try to create some agenda against the opposition. It is interesting to recognize the pattern when two conflicting pieces of information interact on social networks. Here, we present a nonlinear model of opposite information spread in a homogeneous network system. We considered two kinds of users, supporting two conflicting news stories at a time with the ability to protect their opinions from others. We obtained fixed points, their existence, and stability conditions. Here, we watch that social network system experience flip bifurcation and hopf bifurcation. We had chaos in the dynamics, which shows the uncertainty in the observation. Moreover, we suggested a strategy for controlling the complex dynamics of information spread on social networks in emergencies.},
  archive      = {J_SOCO},
  author       = {Jain, Ankur and Dhar, Joydip and Gupta, Vijay K.},
  doi          = {10.1007/s00500-025-10430-4},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {457-469},
  shortjournal = {Soft Comput.},
  title        = {Dynamical behavior and chaos control of the conflicting information propagation on a homogeneous network system},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence analysis of a Picard–CR iteration process for nonexpansive mappings. <em>SOCO</em>, <em>29</em>(2), 435-455. (<a href='https://doi.org/10.1007/s00500-025-10515-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel hybrid iteration process, namely the Picard–CR iteration process. We apply the proposed iteration process for the numerical reckoning of fixed points of generalized $$\alpha $$ -nonexpansive mappings. We establish weak and strong convergence results of generalized $$\alpha $$ -nonexpansive mappings. This study demonstrates the superiority of the hybrid approach in terms of convergence speed. Moreover, we numerically compare the proposed iteration process with other well-known ones from the literature. In the comparison, we consider two problems: finding a fixed point of a generalized $$\alpha $$ -nonexpansive mapping and finding roots of a complex polynomial. In the second problem, we use the so-called polynomiography in the analysis. The results showed that the proposed iteration scheme is better than other three-parameter iteration schemes from the literature. Using the proven fixed-point results, we also obtain solutions to fractional differential equations.},
  archive      = {J_SOCO},
  author       = {Nawaz, Bashir and Ullah, Kifayat and Gdawiec, Krzysztof},
  doi          = {10.1007/s00500-025-10515-0},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {435-455},
  shortjournal = {Soft Comput.},
  title        = {Convergence analysis of a Picard–CR iteration process for nonexpansive mappings},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using covering approaches to study concept lattices. <em>SOCO</em>, <em>29</em>(2), 425-434. (<a href='https://doi.org/10.1007/s00500-025-10488-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A covering can be used for problem solving. In this paper, we use covering methods to study isomorphic relationships among various concept lattices. We use the lattices induced by coverings to characterize various concept lattices, and set up isomorphic relationships between the lattices induced by coverings and the various types of concept lattices. Using these isomorphic relationships, we transform attribute and object reductions for these lattices into a covering reduction. We also study the granular reduction for object-induced three-way concept lattices and provide an algorithm for identifying all granular reducts.},
  archive      = {J_SOCO},
  author       = {Liu, Guilong and Gao, Xiuwei},
  doi          = {10.1007/s00500-025-10488-0},
  journal      = {Soft Computing},
  month        = {1},
  number       = {2},
  pages        = {425-434},
  shortjournal = {Soft Comput.},
  title        = {Using covering approaches to study concept lattices},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoverGAN: Cover photo generation from text story using layout guided GAN. <em>SOCO</em>, <em>29</em>(1), 405-423. (<a href='https://doi.org/10.1007/s00500-025-10436-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating cover photos from story text is a non trivial challenge to solve. Existing approaches focus on generating only images from given text prompt. To the best of our knowledge, non of these approaches focus on generating cover photos from a text story. The paper addresses this issue by introducing multi-object image generation with text title from a text story. We split the problem into three steps:- understanding semantics of text story, predicting layout of objects, and generating a cover photo. At start, a semantic relation was encoded between text story objects using a Scene graph, then features from graph neural network were concatenated with single object features from scene graph to create an object layout. All of these features were then passed on to the image generating part. Image generation was further divided into two phases. In the first phase, the image is generated using a scene graph image generation model. While in the second phase, the results of first phase were further enhanced using image translation model conditioned on the object layout. In final phase we generated title of the given story based on generated image. In our experiments, we used custom dataset of text stories with three animal categories along with the COCO dataset. For the image generating part, we evaluated our approach with state of the art models known as scene_gen and sg2im. Our method generated high-resolution informative cover photo with story title by positioning the objects at right locations as specified in the text story.},
  archive      = {J_SOCO},
  author       = {Cheema, Adeel and Naeem, M. Asif},
  doi          = {10.1007/s00500-025-10436-y},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {405-423},
  shortjournal = {Soft Comput.},
  title        = {CoverGAN: Cover photo generation from text story using layout guided GAN},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of machine learning and deep learning techniques on reverse vaccinology – A systematic literature review. <em>SOCO</em>, <em>29</em>(1), 391-403. (<a href='https://doi.org/10.1007/s00500-025-10480-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reverse vaccinology (RV) is recognized as a productive method of vaccine discovery since it may be used to create vaccines for a variety of infectious pathogens. With the potential for machine learning (ML) algorithms to enable quick and precise predictions of vaccine candidates against new infections, RV is of particular relevance. Despite the fact that ML has been used successfully in the past, Deep learning (DL) model-based RV approaches have not been used widely. DL techniques are known to provide more complicated models and better performance for AI applications. This paper supports and reviews the roles of machine learning and Deep Learning in predicting potential vaccine candidates and discovery processes. Our study involved a systematic evaluation of selected publications, identified through a combination of prior knowledge and keyword searches across freely accessible databases. A meticulous screening process, considering contextual relevance, abstract quality, methodology, and full-text content, was employed. The literature review, conducted with a rigorous methodology, encompasses a thorough analysis of articles focusing on machine learning and deep learning techniques.},
  archive      = {J_SOCO},
  author       = {Alashwal, Hany and Kochunni, Nishi Palakkal and Hayawi, Kadhim},
  doi          = {10.1007/s00500-025-10480-8},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {391-403},
  shortjournal = {Soft Comput.},
  title        = {Application of machine learning and deep learning techniques on reverse vaccinology – A systematic literature review},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Short-term time series prediction based on evolutionary interpolation of chebyshev polynomials with internal smoothing. <em>SOCO</em>, <em>29</em>(1), 375-389. (<a href='https://doi.org/10.1007/s00500-025-10424-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel short-term time series forecasting scheme based on evolutionary interpolation of Chebyshev polynomials is presented in this paper. The uniqueness of the proposed scheme lies in the higher density of Chebyshev nodes at the ends of the interpolation interval. Thus, the structural representation of the algebraic interpolant closer to the present moment of time becomes more accurate compared to the older Chebyshev nodes. The internal smoothing scheme is used to find a balance between the ability of the algebraic interpolant to reflect the local dynamics and to suppress the unwanted effects outside the interpolation interval. Evolutionary optimization algorithms are used to define near-optimal corrections of nodal values of the time series. The proposed nonlinear mapping scheme used on the last elements of an equally spaced time series enables a more accurate extrapolation of the soft algebraic interpolant. To our knowledge, this is the first attempt to employ non-uniform Chebyshev nodes for the prediction of an equally spaced time series. Computational experiments with several standard time series are used to demonstrate the efficacy and the accuracy of the proposed one-step-ahead forecasting scheme.},
  archive      = {J_SOCO},
  author       = {Saunoriene, Loreta and Cao, Jinde and Landauskas, Mantas and Ragulskis, Minvydas},
  doi          = {10.1007/s00500-025-10424-2},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {375-389},
  shortjournal = {Soft Comput.},
  title        = {Short-term time series prediction based on evolutionary interpolation of chebyshev polynomials with internal smoothing},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Representations of binary relations and object reduction of attribute-oriented concept lattices. <em>SOCO</em>, <em>29</em>(1), 365-373. (<a href='https://doi.org/10.1007/s00500-025-10418-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, two representations of binary relations by means of Galois adjunctions and the newly introduced complete distributors are constructed. A binary relation can be uniquely determined by a Galois adjunction, a complete distributor respectively. Under a new description of formal contexts, instead of attribute reduction, the object reduction problem of attribute-oriented concept lattice is studied and related algorithm is designed.},
  archive      = {J_SOCO},
  author       = {Yao, Wei and Zhou, Chang-Jie},
  doi          = {10.1007/s00500-025-10418-0},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {365-373},
  shortjournal = {Soft Comput.},
  title        = {Representations of binary relations and object reduction of attribute-oriented concept lattices},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ASAQ—Ant-miner: Optimized rule-based classifier. <em>SOCO</em>, <em>29</em>(1), 355-364. (<a href='https://doi.org/10.1007/s00500-025-10474-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ant-Miner, a rule-based classifier, has been extensively utilized for classification tasks. However, it features numerous controlling parameters that significantly impact its performance. The standard Ant-Miner (AM) often encounters issues such as slow or premature convergence and high selective pressure. Several studies have proposed innovative methods to enhance AM’s performance by examining the quality function, heuristic strategies, and pheromone update mechanisms. Recent research has also focused on ant selection for pheromone updates and term selection strategies. Despite substantial efforts, existing studies are limited by challenges like local optima entrapment, premature or slow convergence, high selective pressure, exhaustive searches, and the generation of specific yet low-quality rules. This paper introduces a novel Ant-Miner algorithm (ASAQ—AM) that implements novel Ant-Selection strategies for pheromone updating and data classification, alongside an Advanced Quality function. This novel quality function employs hierarchical thresholds to evaluate ants based on coverage, rule length, and accuracy. The selected ants contribute to pheromone updates on their respective paths guided by the proposed quality function. The effectiveness of the ASAQ—AM approach is assessed using four publicly available datasets and standard benchmark performance metrics, including accuracy and F1-score. The results demonstrate that the proposed method outperforms the basic Ant-Miner, state-of-the-art variants, and several data mining approaches in terms of accuracy, F1-score, and convergence speed.},
  archive      = {J_SOCO},
  author       = {Ayub, Umair and Almas, Bushra},
  doi          = {10.1007/s00500-025-10474-6},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {355-364},
  shortjournal = {Soft Comput.},
  title        = {ASAQ—Ant-miner: Optimized rule-based classifier},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secure signal and image transmissions using chaotic synchronization scheme under cyber-attack in the communication channel. <em>SOCO</em>, <em>29</em>(1), 339-353. (<a href='https://doi.org/10.1007/s00500-025-10511-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, problem of secure message (signal and image) transmission is studied. The message is encrypted by masking it with a chaotic system state and then transmitted to receiver-side via a communication channel. It is assumed that the communication channel may be prone to a cyber-attack. The transmission system dynamics in presence of the cyber-attack in the communication channel is modeled by a singular dynamical system. Then, at the receiver-side, a novel observer is designed to recover the message together with the cyber-attack signal. Estimation of the cyber-attack is crucial for monitoring the communication channel and enable a network supervisor to mitigate the adverse consequences and make an appropriate strategy. It is assumed neither restrictions on the message nor on the cyber-attack signals. This makes the proposed scheme, the best solution in the real applications. Moreover, comparing to the existing methods which two public and private channels are required, only one communication channel is used in this paper for transmission the encrypted signal which results in a cheaper solution. Solving the optimization problem can be easily performed with the help of the existing toolboxes such as YALMIP and CVX software in MATLAB. Finally, numerical simulations for signal and image transmission are presented to justify the applicability and superior performance of the proposed scheme.},
  archive      = {J_SOCO},
  author       = {Nobakht, Shaghayegh and Ahmadi, Ali-Akbar},
  doi          = {10.1007/s00500-025-10511-4},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {339-353},
  shortjournal = {Soft Comput.},
  title        = {Secure signal and image transmissions using chaotic synchronization scheme under cyber-attack in the communication channel},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A genomic signal processing approach for identification and classification of coronavirus sequences. <em>SOCO</em>, <em>29</em>(1), 321-338. (<a href='https://doi.org/10.1007/s00500-024-10377-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corona disease has caused a variety of problems for people since it was formed and spread around the world. In this study, diagnosis and differentiation of this disease have been investigated in the form of genomic sequences. The proposed approach is based on a combination of several digital signal processing algorithms that include discrete Fourier transform and comb notch filter. More than 100,000 genomic sequences from different geographical locations and different variants have been tested in this research by various machine learning models. The use of KNN and SVM classifier models has resulted in the accurate diagnosis and differentiation of about 99% of coronavirus samples from the influenza virus. The proposed approach provides the possibility to generalize this method and improve machine learning models and get better results.},
  archive      = {J_SOCO},
  author       = {Khodaei, Amin and Mozaffari-Tazehkand, Behzad and Sharifi, Hadi},
  doi          = {10.1007/s00500-024-10377-y},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {321-338},
  shortjournal = {Soft Comput.},
  title        = {A genomic signal processing approach for identification and classification of coronavirus sequences},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the selected strategies and multiple selected paths for digital music subscription services using the DSA-NRM approach consideration of various stakeholders. <em>SOCO</em>, <em>29</em>(1), 299-320. (<a href='https://doi.org/10.1007/s00500-024-10323-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Music has become a part of many people's lives. Early adopters used to buy tapes or CDs to listen to music, which were difficult to preserve and easily damaged. With the digital transfor-mation of the industry, users nowadays can listen to various genres/styles of music online through digital music platforms at any time. As the types and styles of music are numerous, some digital music platforms have begun to consider providing more diverse ways of delivering music listening services. For example, various music classification systems allows users to easily find all albums by the same singer; different styles of music streaming services save users time in searching for songs of the same type; and the ability to share playlists allows users to share their listening playlists with family and friends. This service model increases peer discussion topics and exposure to albums, songs, and singers. The study summarizes the driving factors influencing the adoption of digital music subscription services using expert interviews and literature reviews. The study outlines four adoption-driving dimensions (service benefits, service efficiency, behavioral attribution, and adoption intention) and 16 evaluation criteria. Besides, this study integrates Desire and Satisfaction Analysis (DSA) and Network Relation Map (NRM) to propose a DSA-NRM analysis to evaluate the adoption strategy and optimal development path for digital music subscription services. Based on the four quadrants of music subscription services, this study proposes four selected strategies (attention strategy, sustainment strategy, adjustment strategy, and focus strategy). The research results show that the SB (service benefits) aspect has high desire and low satisfaction and can adopt selected strategy D (focus Strategy). The AI (adoption intention) aspect is an aspect with intense desire and low satisfaction and can use strategy C (adjustment strategy) chosen. The AI (adoption intention) aspect can dominate other aspects, and the SE (service effectiveness) can be dominated by different aspects.},
  archive      = {J_SOCO},
  author       = {Tsai, Kuo-Pao and Yang, Feng-Chao and Lu, Chin-Lung and Lin, Chia-Li},
  doi          = {10.1007/s00500-024-10323-y},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {299-320},
  shortjournal = {Soft Comput.},
  title        = {Exploring the selected strategies and multiple selected paths for digital music subscription services using the DSA-NRM approach consideration of various stakeholders},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RCS: A fast path planning algorithm for unmanned aerial vehicles. <em>SOCO</em>, <em>29</em>(1), 275-298. (<a href='https://doi.org/10.1007/s00500-025-10481-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning is a major problem in autonomous vehicles. In recent years, with the increase in applications of unmanned aerial vehicles (UAVs), one of the main challenges is path planning, particularly in adversarial environments. In this paper, we consider the problem of planning a collision-free path for a UAV in a polygonal domain from a source point to a target point. Based on the characteristics of UAVs, we assume two basic limitations on the generated paths: an upper bound on the turning angle at each turning point (maximum turning angle) and a lower bound on the distance between two consecutive turns (minimum route leg length). We describe an algorithm that runs in $$O(n^2 \log n)$$ time and finds a feasible path in accordance with the above limitations, where n is the number of obstacle vertices. As shown by experiments, the output of the algorithm is much closer to the shortest path with this requirement (always below about 10% of the shortest path), in a much smaller time (up to 10,000 quicker, in our experiments). We further demonstrate how to decompose the algorithm into two phases, a preprocessing and a query phase. In this way, given a fixed start point and a set of obstacles, we can preprocess a data structure of size $$O(n^2)$$ in $$O(n^2 \log n)$$ time, such that for any query target point we can find a path with the given requirements in $$O(n \log n)$$ time. Finally, we modify the algorithm to find a feasible (almost shortest) path that reaches the target point within a given range of directions.},
  archive      = {J_SOCO},
  author       = {Ranjbar Divkoti, Mohammad Reza and Nouri-Baygi, Mostafa},
  doi          = {10.1007/s00500-025-10481-7},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {275-298},
  shortjournal = {Soft Comput.},
  title        = {RCS: A fast path planning algorithm for unmanned aerial vehicles},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The location problem of emergency materials in uncertain environment. <em>SOCO</em>, <em>29</em>(1), 261-273. (<a href='https://doi.org/10.1007/s00500-025-10400-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hazards and unpredictability of emergencies have made people pay more and more attention to emergency response. A reasonable reserve of emergency materials can play an important role in post-disaster rescue. This paper uses the uncertain comprehensive evaluation method to grade the emergency materials, and establishes a location model for the uncertain emergency materials. The location of the reserve point is determined by maximizing the rescue satisfaction, the maximum number of service demand points under the maximum coverage, and pursuing the minimum sum of the distance from the demand point to the reserve point. Based on the uncertainty theory, the uncertain emergency materials location model is converted into an equivalent deterministic emergency materials location model, and the model is solved by a tabu search algorithm. Finally, a numerical experiment is given to illustrate the idea of the uncertain model. Four sites were selected through a tabu search algorithm.},
  archive      = {J_SOCO},
  author       = {Xiao, Jihe and Sheng, Yuhong},
  doi          = {10.1007/s00500-025-10400-w},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {261-273},
  shortjournal = {Soft Comput.},
  title        = {The location problem of emergency materials in uncertain environment},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A game theoretic approach for pricing of red blood cells under supply and demand uncertainty and government role. <em>SOCO</em>, <em>29</em>(1), 237-260. (<a href='https://doi.org/10.1007/s00500-024-10308-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing global population and reduced blood donations due to COVID-19 necessitate efficient management and pricing strategies for red blood cells (RBCs). Pricing mechanisms must address the perishable nature of RBCs and supply–demand uncertainties to minimize wastage. Government intervention in blood donation and healthcare costs further emphasizes their role in addressing these challenges. This paper utilizes mathematical modelling to investigate pricing within the RBC supply chain, involving stakeholders like governments, public hospitals, and blood banks. Employing a government-led Stackelberg game framework, it considers the precedence of government decisions. Objective functions of each participant incorporate economic and social aspects in both centralized and decentralized scenarios. The study starts with optimizing RBC pricing in blood banks and then establishes coordination mechanisms via revenue-sharing contracts to improve supply chain efficiency, cut costs, and minimize waste—an approach novel in the RBC supply chain context. Finally, the effectiveness of the proposed model is evaluated through a numerical example based on real-world data. Furthermore, sensitivity analyses are conducted on key parameters to provide valuable insights for management decision-making.},
  archive      = {J_SOCO},
  author       = {Kamrantabar, Minoo and Yaghoubi, Saeed and Fander, Atieh},
  doi          = {10.1007/s00500-024-10308-x},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {237-260},
  shortjournal = {Soft Comput.},
  title        = {A game theoretic approach for pricing of red blood cells under supply and demand uncertainty and government role},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-objective fuzzy robust optimization model for open-pit mine planning under uncertainty. <em>SOCO</em>, <em>29</em>(1), 213-235. (<a href='https://doi.org/10.1007/s00500-024-10365-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In open-pit mines, transporting ore from the pit to unloading sites is one of the most significant factors driving both cost and environmental impact. However, uncertainty in truck arrival times and ore transport rates due to varying weather conditions, physical limitations, and mental states of the workforce makes efficient allocation a challenge. This study addresses this challenge by proposing a multi-objective mathematical model that optimizes cost, production, and environmental objectives. Fuzzy Robust Optimization (FRO) incorporates uncertainty into the model, and the Linear Programming Metric (LP-Metric) is employed to solve it. A case study using the Chadormalu mine demonstrates the model's effectiveness in planning shift transport. Sensitivity analysis confirms the model's ability to handle uncertainty. Notably, the optimality robustness factor solely influences the objective function's value (representing the sum of relative deviations from optimal function values). Feasibility robustness, however, has no impact on any measurements.},
  archive      = {J_SOCO},
  author       = {Soleimani Bafghi, Sayed Abolghasem and Hosseini Nasab, Hasan and Fakhrzad, Mohammad Bagher and Soltani, Roya and Yarahmadi Bafghi, Ali reza},
  doi          = {10.1007/s00500-024-10365-2},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {213-235},
  shortjournal = {Soft Comput.},
  title        = {A multi-objective fuzzy robust optimization model for open-pit mine planning under uncertainty},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Benders decomposition for the multi-agent location and scheduling problem on unrelated parallel machines. <em>SOCO</em>, <em>29</em>(1), 195-212. (<a href='https://doi.org/10.1007/s00500-024-10395-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The machine location and job scheduling problem is becoming a new and important research topic with a wide range of practical applications. It jointly optimizes the machine location, job assignment, and job sequence decision to yield a globally optimal solution. This paper investigates the multiple-agent scheduling and location problem on unrelated parallel machines with the objective of minimizing the sum of the fixed location cost of the machines, transportation cost of the jobs between the locations of the jobs and machines, and total weighted completion time of the jobs of one agent while keeping the total weighted completion time of each other agent no greater than a given limit. To solve this problem, we develop a tailored Benders decomposition algorithm, which decomposes the problem into a Benders master problem and a Benders subproblem. The Benders master problem determines which locations are chosen to set up machines and which jobs are assigned to each machine. The resulting Benders subproblem finds the optimal job sequence of the jobs assigned to each machine in use, which is solved by an exact dynamic programming algorithm. To speed up the convergence of the developed algorithm, some improvement strategies, including warm start strategy and weak Benders cut generation, are introduced. Computational experiments on randomly generated instances show the effectiveness and efficiency of developed algorithm and improvement strategies. Moreover, management insights are drawn from the sensitivity analyses of some key parameters.},
  archive      = {J_SOCO},
  author       = {Liu, Jun and Yang, Yongjian and Li, Wencan and Jiang, Hua and Guo, Tianwen and Yang, Feng},
  doi          = {10.1007/s00500-024-10395-w},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {195-212},
  shortjournal = {Soft Comput.},
  title        = {Benders decomposition for the multi-agent location and scheduling problem on unrelated parallel machines},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quadratic and lagrange interpolation-based butterfly optimization algorithm for numerical optimization and engineering design problem. <em>SOCO</em>, <em>29</em>(1), 157-194. (<a href='https://doi.org/10.1007/s00500-024-10339-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a novel and improved Butterfly Optimization Algorithm (BOA), known as LQBOA, to solve BOA’s inherent limitations. The LQBOA uses Lagrange interpolation and simple quadratic interpolation techniques with adapted parameter settings to enhance the search strategy of BOA and to achieve a better balance of diversification and intensification. LQBOA’s performance was examined on 45 traditional benchmark issues as well as the IEEE CEC 2017 benchmark suites with 10, 30 and 50 dimensions, and the results were compared against popular state-of-the-art and modified algorithms. It was discovered that in more than 85% of cases, the proposed LQBOA outperformed the compared algorithms. The Friedman rank test and Wilcoxon rank test were used to validate the suggested LQBOA’s rank and significance. Additionally, convergence and diversity analyses were performed to investigate its convergence speed and searching behavior, respectively. Furthermore, LQBOA has been successfully deployed to solve twelve real-world issues including several engineering design problems and two multiple gravity assist spacecraft trajectory problems. The results of these problems were compared to those of a wide range of algorithms, demonstrating the superior performance of the proposed LQBOA. In conclusion, LQBOA makes a significant addition to the optimization area, and its application could greatly improve the performance of numerous optimization jobs.},
  archive      = {J_SOCO},
  author       = {Sharma, Sushmita and Saha, Apu Kumar and Chakraborty, Sanjoy and Deb, Suman and Sahoo, Saroj Kumar},
  doi          = {10.1007/s00500-024-10339-4},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {157-194},
  shortjournal = {Soft Comput.},
  title        = {Quadratic and lagrange interpolation-based butterfly optimization algorithm for numerical optimization and engineering design problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cooperative enhancement method of train operation planning featuring express and local modes for urban rail transit lines. <em>SOCO</em>, <em>29</em>(1), 127-155. (<a href='https://doi.org/10.1007/s00500-024-10364-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An urban rail system’s ability to operate effectively and efficiently depends on its train operation plan. This paper proposes a strategy to optimize the train operation plan in an urban rail line with a single terminal depot by decreasing the travel cost for passengers and increasing resource utilization effectiveness from the operators’ point of view. We put forward a two-stage problem-solving approach that can effectively solve the train operation plan employing express and local type services. A mathematical model is formulated to address multi-level problems including line planning, train scheduling, train circulation planning, and an assignment for passengers’ travel. A two-stage iterative bi-objective algorithm is designed to suggest a targeted optimization for passengers’ traveling expenses and the enterprise’s running expenses. The first phase aims at optimizing the regularity of service to maximize the number of travelers achieved and the bi-objective function. The second phase, however, readjusts the stop plan for express operations to improve the objective until reaching the best possible setting. Finally, a real-world case study with three instances setting different departure ratios for local and express operations demonstrates how the train operation plan created using our approach lowers operational costs while meeting service level requirements with superior performance.},
  archive      = {J_SOCO},
  author       = {Zhou, Wenliang and Oldache, Mehdi and Xu, Guangming},
  doi          = {10.1007/s00500-024-10364-3},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {127-155},
  shortjournal = {Soft Comput.},
  title        = {Cooperative enhancement method of train operation planning featuring express and local modes for urban rail transit lines},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing stock prediction ability through news perspective and deep learning with attention mechanisms. <em>SOCO</em>, <em>29</em>(1), 117-126. (<a href='https://doi.org/10.1007/s00500-025-10437-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {News is reaching investors at an unprecedented rate since pop-up notifications and news recommendations are so common on websites and applications. For investors, these news sources have established themselves as an essential resource for stock market information. To study the impact of news on stock prediction and further enhance its predictive ability, this study innovatively merges the capacity of attention mechanisms to focus crucial information with the ability of temporal convolutional network (TCN) to discern temporal patterns, proposing a new algorithm named “Attention-TCN”. The results indicate that the Attention-TCN model has the smallest prediction error compared to well-known stock prediction algorithms such as Long Short-Term Memory and Gated Recurrent Units. The study demonstrates that incorporating a news perspective and utilizing a TCN model combined with an attention mechanism can hold the promise of helping investors to make more informed decisions and achieving higher returns.},
  archive      = {J_SOCO},
  author       = {Yang, Mei and Fu, Fanjie and Ni, Du and Xiao, Zhi},
  doi          = {10.1007/s00500-025-10437-x},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {117-126},
  shortjournal = {Soft Comput.},
  title        = {Enhancing stock prediction ability through news perspective and deep learning with attention mechanisms},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leader-follower green traffic assignment problem with online supervised machine learning solution approach. <em>SOCO</em>, <em>29</em>(1), 103-116. (<a href='https://doi.org/10.1007/s00500-025-10407-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a bi-level green traffic assignment with network design problem. At the upper level, the objective function evaluates a total traffic Carbon monoxide (CO) gas emissions problem to provide a macroscopic viewpoint of the system manager. At the lower-level, a traffic assignment network design problem is considered to individually optimize users’ travel times, with certain links being potential candidates for network addition. Although the lower-level objective function is convex with linear constraints, the proposed bi-level problem is np-hard, and even finding a near-optimal solution is an np-hard task. To address the solution approach, we applied an online supervised machine learning (SML) algorithm which solves the proposed bi-level problem within a reasonable running time. Additionally, a mat-heuristic algorithm is proposed to compare the results with the online SML algorithm. To validate the online SML algorithm, we conducted experiments using real urban transportation examples in medium and large-sized networks.},
  archive      = {J_SOCO},
  author       = {Sadra, M. and Zaferanieh, M. and Yazdimoghaddam, J.},
  doi          = {10.1007/s00500-025-10407-3},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {103-116},
  shortjournal = {Soft Comput.},
  title        = {Leader-follower green traffic assignment problem with online supervised machine learning solution approach},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight and efficient model for botnet detection in IoT using stacked ensemble learning. <em>SOCO</em>, <em>29</em>(1), 89-101. (<a href='https://doi.org/10.1007/s00500-025-10425-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient botnet detection is of great security importance and has been the focus of researchers in recent years. Botnet detection is also a difficult task due to the difficulty in distinguishing it from normal traffic. At the same time, detecting these botnets require a lot of computation resources using traditional methods and this limitation makes it even more difficult to detect them on Internet of Things (IoT) devices. Considering the massive IoT data, an efficient and lightweight approach for detecting and predicting IoT botnet attacks is required. In this paper, multiple lightweight machine learning methods including a deep Multilayer Perceptron (MLP) method and a Random Forest (RF) method are integrated into a stacked ensemble learning model to detect botnet attacks in IoT devices. This integration is based on applying lasso regression on features and utilizing a logistic regression in ensemble learning, which leads to increasing the accuracy of botnet detection and reducing its computational complexity. The performance evaluation of the proposed model is examined from two perspectives: accuracy and lightweight characteristics; and for this purpose, a real-world UNSW (BoT-IoT) dataset is used. A comparative study with competitive neural network methods demonstrates that our approach delivers a better outcome. Experimental results reveal that this method has a higher efficiency in all metrics than competing methods including accuracy, precision, recall, and F1 score with values of 99.3%, 99.2%, 99%, and 99.1%, respectively. Besides, the results showed that the proposed method requires at least 36% less CPU and 38% less memory compared to the competing methods, which makes the proposed method to be suitable for IoT devises with limited resources.},
  archive      = {J_SOCO},
  author       = {Esmaeilyfard, Rasool and Shoaei, Zohre and Javidan, Reza},
  doi          = {10.1007/s00500-025-10425-1},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {89-101},
  shortjournal = {Soft Comput.},
  title        = {A lightweight and efficient model for botnet detection in IoT using stacked ensemble learning},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). European option pricing under a generalized fractional brownian motion heston exponential Hull–White model with transaction costs by the deep galerkin method. <em>SOCO</em>, <em>29</em>(1), 69-88. (<a href='https://doi.org/10.1007/s00500-025-10433-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new financial model called the generalized fractional Brownian motion Heston exponential Hull–White model, which has stochastic volatility and interest rate, long memory, and heavy tail distribution. Based on the market price of the volatility and delta hedging strategies, we propose a partial differential equation (PDE) to obtain the European option price. To do this, portfolio changes contain long one position of the European call option and shares of the underlying assets (stock, zero coupon bond, volatility), where we use the mentioned model to obtain the price. Due to transaction costs, the resulting equation is a fully nonlinear PDE, which we use the Deep Galerkin Method (DGM) to solve it. Also, we present the proof of the convergence of the method to this class of equations, which includes two parts: the convergence of the loss function to zero and the convergence of the neural network to the exact solution of the equation. We finally present numerical results to show the model and method’s effectiveness.},
  archive      = {J_SOCO},
  author       = {Motameni, Mahsa and Mehrdoust, Farshid and Najafi, Ali Reza},
  doi          = {10.1007/s00500-025-10433-1},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {69-88},
  shortjournal = {Soft Comput.},
  title        = {European option pricing under a generalized fractional brownian motion heston exponential Hull–White model with transaction costs by the deep galerkin method},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Construction of a novel five-dimensional hamiltonian conservative hyperchaotic system and its application in image encryption. <em>SOCO</em>, <em>29</em>(1), 53-67. (<a href='https://doi.org/10.1007/s00500-025-10443-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the theory of Euler’s equations, this paper constructs a novel five-dimensional Hamiltonian conservative hyperchaotic system with the aim of systematically exploring and analyzing its dynamic characteristics, while validating its potential application value in the field of information security. A comprehensive and multi-faceted dynamic analysis of the new system is conducted, encompassing energy variations, equilibrium point distributions, Poincaré section structures, and the computation of Lyapunov exponents. The analysis reveals that the system exhibits excellent chaotic properties and demonstrates remarkable conservative hyperchaotic behavior across a wide range of initial values and parameters. Notably, a significant enhancement in the maximum Lyapunov exponent is observed, further highlighting the system’s potential and promising applications in information security. Additionally, by adjusting the initial values, the coexistence of nested phenomena across multiple energy levels is observed, providing intriguing perspectives for further investigation of the system. Finally, this paper proposes an image encryption scheme based on this system and is successfully applied in the field of image encryption. Experiments show that compared with the information entropy of similar documents in the past four years, the information entropy of this scheme increased by 0.02% on average, and the highest value reached 7.9995, which confirmed that the encryption algorithm has excellent confidentiality performance and provided new ideas and methods for the development of the field of information security.},
  archive      = {J_SOCO},
  author       = {Yan, Minxiu and Li, Shuyan},
  doi          = {10.1007/s00500-025-10443-z},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {53-67},
  shortjournal = {Soft Comput.},
  title        = {Construction of a novel five-dimensional hamiltonian conservative hyperchaotic system and its application in image encryption},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of SaRT–SVM algorithm for leakage pattern recognition of hydraulic check valve. <em>SOCO</em>, <em>29</em>(1), 37-51. (<a href='https://doi.org/10.1007/s00500-024-10371-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Check valves are key components in hydraulic systems. The cross-port leakage in check valves is a common fault that affects their performances. The vibration and pressure fluctuations excited by leaks are weak, therefore leakage is difficult to be identified and classified by intelligent algorithms and non-destructive testing methods. To maximize the performance of leak pattern recognition, we had improved the sequential minimal optimisation algorithm for enhancing the classification performance and tested it with the University of California Irvine Machine Learning Repository. Furthermore, combining with the search and rescue team (SaRT) algorithm, we propose SaRT-SVM algorithm. Two important parameters γ and C of support vector machine (SVM) were optimised and compared with response surface and other algorithms. We analysed the SaRT–SVM method for leakage pattern recognition and validated the robustness of the developed method by applying the method on multiple fault samples of each fault mode, additional different noises, and another independent data collection. The results showed that the SaRT–SVM algorithm exhibited excellent classification performance and robustness when applied to the leakage pattern recognition of hydraulic check valves under the influence of different noises.},
  archive      = {J_SOCO},
  author       = {Tong, Chengbiao and Sepehri, Nariman},
  doi          = {10.1007/s00500-024-10371-4},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {37-51},
  shortjournal = {Soft Comput.},
  title        = {Application of SaRT–SVM algorithm for leakage pattern recognition of hydraulic check valve},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stabilization of impulsive fuzzy dynamic systems involving caputo short-memory fractional derivative. <em>SOCO</em>, <em>29</em>(1), 17-36. (<a href='https://doi.org/10.1007/s00500-024-10353-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main focus of this paper is to investigate the asymptotic stability of impulsive fuzzy fractional dynamic systems (IFFDSs) under the Caputo fractional derivative concept in the short-memory sense. To address the issue of asymptotic instability in IFFDSs, a linear feedback controller is introduced. The paper proposes two methods for achieving this, namely Lyapunov’s direct method (LDM) which is known for its high efficiency in surveying the stability theory of dynamic systems, and the direct evaluation method (DEM), which utilizes the properties of the Laplace transform, the Mittag–Leffler function, and Gronwall–Bellman inequality. The effectiveness of the proposed methods is demonstrated through numerical examples.},
  archive      = {J_SOCO},
  author       = {An, Truong Vinh and Van Hoa, Ngo and Thao, Nguyen Trang},
  doi          = {10.1007/s00500-024-10353-6},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {17-36},
  shortjournal = {Soft Comput.},
  title        = {Stabilization of impulsive fuzzy dynamic systems involving caputo short-memory fractional derivative},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KMSBOT: Enhancing educational institutions with an AI-powered semantic search engine and graph database. <em>SOCO</em>, <em>29</em>(1), 1-15. (<a href='https://doi.org/10.1007/s00500-024-10329-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the rapidly evolving field of education, a semantic search engine is essential to efficiently retrieve knowledge experts’ data. Universities and colleges continuously generate a vast amount of educational and research data. A semantic search engine can assist students and staff in efficiently searching for required information in such a big data pool. The existing systems have limitations in providing personalized recommendations that align with the individual learning objectives of students and scholars, thus hindering their educational experience. To address this, this paper proposed a KMSBOT. This novel recommendation system effectively summarizes academic data and provides tailored information for students, research scholars, and faculty, enhancing educational experiences. This paper meticulously details the development of KMSBOT, which comprises a neo4j-based knowledge graph technique, the NLP method for data structuring, and the KNN machine learning model for classification. The system employs a three-module approach, utilizing data structuring, NLP processing, and semantic search engine integration. By leveraging Neo4j, NLTK, and BERT in Python, this proposed work ensures optimal performance metrics such as time, accuracy, and loss value. The proposed solution addresses traditional recommendation systems’ limitations and contributes to a brighter future, improving user satisfaction and engagement in academic environments.},
  archive      = {J_SOCO},
  author       = {Subramanian, D. Venkata and Chandra, J. and Immanuel, V. Ashok and Rohini, V.},
  doi          = {10.1007/s00500-024-10329-6},
  journal      = {Soft Computing},
  month        = {1},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Soft Comput.},
  title        = {KMSBOT: Enhancing educational institutions with an AI-powered semantic search engine and graph database},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
