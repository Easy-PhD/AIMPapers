<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJMLC</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijmlc">IJMLC - 302</h2>
<ul>
<li><details>
<summary>
(2025). Differential evolution-driven optimized ensemble network for brain tumor detection. <em>IJMLC</em>, <em>16</em>(9), 6447-6472. (<a href='https://doi.org/10.1007/s13042-025-02629-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors are serious and abnormal growth within the brain by posing significant challenges for medical diagnosis and treatment. The varied and complex nature of brain tumors complicates their detection and accurate classification. The need for precise classification of brain tumors from medical imaging is crucial for effective medical intervention. However, traditional methods are reliant on manual diagnosis, which are prone to human errors and inconsistencies. Previous research has struggled to enhance diagnostic precision by combining predictions from multiple models but often result in discrepancies and inconsistent outcomes by leading to complicated diagnostic processes. To address these challenges, researchers have increasingly turned to advanced computational methods to improve diagnostic accuracy. In this context, we propose a robust ensemble approach optimized using a Differential Evolution (DE)-based algorithm. Our method combines three high-performing pre-trained CNN models like MobileNetV1, MobileNetV2, ResNet50V2 and optimizes their contributions by assigning optimal weights through DE. This technique intelligently adjusts the weights allocation of models to maximize ensemble performance. During optimization, the probabilities from each model are extracted and integrated using a weighted average aggregation scheme, enhancing the diagnostic precision and overall predictive accuracy. To validate the effectiveness of our approach, we applied it to two publicly available datasets: a binary classification dataset (BR35H) and a multi-class (4-class) dataset. Through rigorous evaluations, our optimized ensemble approach demonstrated superior accuracy performance of 98% and 97.03%, respectively. We used several performance evaluation metrices and visualization techniques like Grad-CAM to highlight critical areas within the images. Additionally, statistical validation is conducted using the Friedman test followed by the Conover post hoc analysis to rigorously assess and compare the performance differences across models.},
  archive      = {J_IJMLC},
  author       = {Hekmat, Arash and Zuping, Zhang and Bilal, Omair and Khan, Saif Ur Rehman},
  doi          = {10.1007/s13042-025-02629-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {6447-6472},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Differential evolution-driven optimized ensemble network for brain tumor detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-layered security architecture for IoMT systems: Integrating dynamic key management, decentralized storage, and dependable intrusion detection framework. <em>IJMLC</em>, <em>16</em>(9), 6399-6446. (<a href='https://doi.org/10.1007/s13042-025-02628-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing complexity of cyber threats presents significant challenges to the security of Internet of Medical Things (IoMT) systems, where traditional security and intrusion detection methods often prove inadequate. The Key challenges include inefficient key management, fragmented security protocols, and limited scalability. To address these issues, this paper proposes a Dynamic Adaptive Deep Reinforcement Learning (DA-DRL) framework that enhances Advanced Encryption Standard (AES) encryption by dynamically adjusting key generation in response to real-time threats. Additionally, a multi-layered security architecture integrating AES, SHA-512, Non-Interactive Zero Knowledge Proof (NIZKPs), Practical Byzantine Fault Tolerance (PBFT), and Attribute-Based Access Control (ABAC) is introduced, ensuring robust protection against diverse attack vectors. The InterPlanetary File System (IPFS) is employed for decentralized and immutable data storage, enhancing data security and transparency. The proposed DA-DRL-AES-SHA-512 methodology significantly outperforms conventional encryption techniques, achieving an encryption time of 0.0975 s, decryption time of 0.0846 s, and a throughput of 75.63 transactions per second (Tx/s) with a network overhead of just 0.1289%. The Energy consumption and computational overhead are reduced to 0.3664 J and 0.48%, respectively. The Secure and Dependable Bi-LSTM GRU Intrusion Detection Framework (S-BiLSTMGRU-IDF) achieves 99.94% accuracy in binary classification and 99.89% in multiclass classification, improving detection efficiency by 0.6–3.5% over state-of-the-art models. This blockchain-based framework ensures real-time threat mitigation, enhanced data integrity, and superior system performance, establishing a secure, scalable, and efficient solution for IoMT security.},
  archive      = {J_IJMLC},
  author       = {Sharma, Nikhil and Shambharkar, Prashant Giridhar},
  doi          = {10.1007/s13042-025-02628-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {6399-6446},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-layered security architecture for IoMT systems: Integrating dynamic key management, decentralized storage, and dependable intrusion detection framework},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A heterogeneous data fusion mortality prediction model based on time-aware self-attention mechanism. <em>IJMLC</em>, <em>16</em>(9), 6381-6397. (<a href='https://doi.org/10.1007/s13042-025-02627-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting mortality using medical information is a critical task in the healthcare profession. The common method is extracting features from electronic health records and choosing appropriate models to identify patients who may have a higher risk of death. However, the lack of standardization and identifiability in the storage of unstructured data in medical records poses a significant challenge in training models to predict patient mortality. In this paper, we propose a heterogeneous data fusion mortality prediction model called Fusion-transformer to address the above issues. The proposed Fusion-transformer model uses a time-aware self-attention mechanism to combine structured data represented by time signals and static information and unstructured data represented by clinical notes to enhance patient representation learning. Fusion-transformer also uses a time decay module to control the influence of the patient’s hospitalization experience on the current health status at different times. The results of in-hospital mortality prediction experiments on the Medical Information Mart for Intensive Care III dataset show that Fusion-transformer outperforms other machine learning and deep learning baseline models, improving the area under the receiver operating characteristics curve metric from 0.891 to 0.923. In addition, we explore the practical applications value of our method through real ICU patient electronic medical records.},
  archive      = {J_IJMLC},
  author       = {Chen, Shuxu and Wang, Decong and Che, Chao and Wei, Ziqi and Zhong, Zhaoqian},
  doi          = {10.1007/s13042-025-02627-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {6381-6397},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A heterogeneous data fusion mortality prediction model based on time-aware self-attention mechanism},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constructing and learning heterogeneous patient graph representations from structured electronic medical records. <em>IJMLC</em>, <em>16</em>(9), 6367-6380. (<a href='https://doi.org/10.1007/s13042-025-02626-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The graph structure can reveal the relationships between feature nodes and improve the performance of feature-based models. However, more research is needed to construct a patient graph representation using electronic medical record (EMR) to meet modeling requirements. This study aims to propose a heterogeneous patient graph representation (HePGR) framework capable of discovering associations between medical concepts in EMR while simultaneously supporting both clustering and classification tasks. We construct HePGR’s edge connections by evaluating the correlations between medical concepts(e.g., laboratory tests, drugs, surgical codes) using positive pointwise mutual information, directly linking patients with their corresponding medical concepts. Graph attention networks are used to obtain patient node representations, with a supervised training method based on cross-entropy and a semi-supervised method leveraging pseudo-labeling and contrastive learning. To validate the effectiveness of the HePGR model, we design comparison and ablation experiments that are performed on a stroke patient dataset with two prediction tasks and one clustering task. HePGR shows superior performance in all tasks, achieving areas under the receiver operating characteristic curve of 0.990 and 0.806 in the two prediction tasks and a Jaccard coefficient of 0.810 in the clustering task. The proposed HePGR model effectively identifies associations between medical concepts and shows high performance in clinical tasks. This model is expected to be extended to more medical concepts for broad clinical applicability.},
  archive      = {J_IJMLC},
  author       = {Li, Yichen and Wang, Muyu and Gao, Binyu and Zhu, Congmin and Wei, Lan and Fei, Xiaolu and Chen, Hui},
  doi          = {10.1007/s13042-025-02626-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {6367-6380},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Constructing and learning heterogeneous patient graph representations from structured electronic medical records},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal knowledge graph representation learning with temporal feature and complex evolution. <em>IJMLC</em>, <em>16</em>(9), 6347-6365. (<a href='https://doi.org/10.1007/s13042-025-02625-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal knowledge graph (TKG) representation learning is a pivotal task aimed at transforming entities and relations within TKG from a high-dimensional vector space to a lower-dimensional vector space, while preserving the relational features inherent in TKG. TKG comprises a sequence of knowledge graphs (KGs) at various timestamps. Presently, existing methodologies tend to either focus solely on learning historical event characteristics or exclusively model time-dependent relationships. There is a notable dearth of research concerning incomplete data, posing significant challenges to comprehending and capturing the intricate relationship characteristics within TKG. In response to this challenge, a novel method named TFCE is introduced to address the challenges posed by temporal evolution and incomplete data in TKGs. TFCE encompasses three core components: a Temporal Feature Module, a Complex Evolution Module, and a Temporally Embedded Decoder. TFCE incorporates a temporal feature module, enabling the temporal encoding of entities and relations within KGs. This module seamlessly integrates temporal information into the representation learning process. By discerning patterns of entities and relations across time, TFCE facilitates the comprehension and discovery of temporal order relations within KGs. The complex evolution module adeptly learns the evolutionary representation of entities and relationships at each timestamp through recursive modeling of the KG sequence. By systematically analyzing the KG sequence, this module captures the nuanced evolution of entities and relationships over time, enhancing the understanding of temporal dependencies between events. To accommodate incomplete temporal data, TFCE employs a temporally embedded decoder. This decoder effectively processes incomplete temporal data, facilitating the inference of representation learning. Experimental validation conducted across three real-world datasets, namely ICEWS14s, ICEWS 05-15, and ICEWS18, underscores the superiority of TFCE over baseline methods. The TFCE framework demonstrates remarkable efficacy in capturing temporal relationships within TKG, thus showcasing its potential for advancing temporal knowledge graph representation learning methodologies.},
  archive      = {J_IJMLC},
  author       = {Liu, Qian and Feng, Siling and Huang, Mengxing and Bhatti, Uzair Aslam},
  doi          = {10.1007/s13042-025-02625-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {6347-6365},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Temporal knowledge graph representation learning with temporal feature and complex evolution},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augmented harris hawks optimization and for engineering design problems and UAV path planning. <em>IJMLC</em>, <em>16</em>(9), 6295-6345. (<a href='https://doi.org/10.1007/s13042-025-02624-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Harris hawk optimization (HHO) is a popular metaheuristic algorithm recently proposed, but it suffers from slow convergence speed, low accuracy, and the problem of easily getting stuck in local optima when dealing with practical problems. To address these drawbacks, we propose an improved version called augmented Harris hawk optimization (AHHO). In the enhancement, we introduce Logistic chaotic population initialization to enhance AHHO’s global exploration capability; adopt a dynamic Lévy flight strategy to improve the algorithm’s early convergence speed; and propose a new surprise pounce exploitation strategy to enhance the algorithm’s optimization ability. Additionally, we introduce a random centroid dynamic backward learning to improve the algorithm’s search efficiency, convergence speed, and robustness, thereby effectively solving complex optimization problems. To validate the performance of AHHO, we conducted analyses from three aspects: population diversity, exploration and exploitation balance, and convergence behavior. We compared it with HHO and 12 other high-performance algorithms on the CEC2014 and CEC2017 test sets, in two test sets, 15, 17, 23, 14, 18, and 21 first-place rankings were obtained in three dimensions, respectively. The results show that compared to HHO and other algorithms, AHHO demonstrates superior comprehensive performance in all aspects. Finally, we applied AHHO to 5 engineering optimization problems and 1 unmanned aerial vehicle path planning problem, 5 engineering problems and UAVs both achieved first place rankings. The results indicate that AHHO outperforms other benchmark algorithms, demonstrating its strong scalability and outstanding optimization performance.},
  archive      = {J_IJMLC},
  author       = {Zhu, Lindan and Fu, Youfa},
  doi          = {10.1007/s13042-025-02624-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {6295-6345},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Augmented harris hawks optimization and for engineering design problems and UAV path planning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Loepso, local optimum escape particle swarm optimization, an algorithm for traffic forecasting in software-defined networking using deep-learning models. <em>IJMLC</em>, <em>16</em>(9), 6271-6294. (<a href='https://doi.org/10.1007/s13042-025-02623-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of computer networks has led to designing a more flexible and efficient architecture called Software-Defined Networking (SDN). SDN decouples the control plane from the physical networking devices in the data plane. SDN’s global perspective and programmability have inspired researchers to develop ideas that would have been difficult or even impossible in traditional networks. Traffic forecasting is an interesting area that has driven the efforts of this paper. In this study, an optimization of time series parameters is performed to achieve the most suitable time series structure for feeding deep-learning algorithms. Popular deep-learning algorithms, namely Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM), are compared in traffic forecasting. An improved version of Particle Swarm Optimization (PSO), called Local Optimum Escape Particle Swarm Optimization (LOEPSO), is proposed. The algorithm is a variation of PSO inspired by Harmony Search optimization to replace the global worst particle with a randomly created particle. A Ryu controller has been customized to gather the network’s switches’ port statistics and generate a time series from traffic passing through the ports. A traffic generator application, implemented as a Python thread, runs at the SDN network’s hosts simulated in Mininet. For an extensive analysis, traffic is generated in two modes: an idle mode with regular traffic and the worst-case scenario where a chaotic function is used to determine traffic volume. The results show that CNN and LSTM provide reliable forecasting for regular traffic. However, despite having equivalent training results in chaotic traffic, LSTM performs better in forecasting validation data.},
  archive      = {J_IJMLC},
  author       = {Talarposhti, Khadijeh Mirzaei and Jabbehdari, Sam and Rahmani, Amir Masoud},
  doi          = {10.1007/s13042-025-02623-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {6271-6294},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Loepso, local optimum escape particle swarm optimization, an algorithm for traffic forecasting in software-defined networking using deep-learning models},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reward design in multi-agent systems using successor features and multi-information source bayesian optimization. <em>IJMLC</em>, <em>16</em>(9), 6249-6270. (<a href='https://doi.org/10.1007/s13042-025-02622-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coordinating self-interested agents in multi-agent systems to achieve system-level objectives presents significant challenges due to the inherent misalignment between individual and collective goals. Mechanism design offers a solution by employing a bi-level optimization framework, where a designer agent intervenes in the reward structures to incentivize desired behaviors among self-interested agents. However, a major obstacle in reward optimization lies in solving multi-agent reinforcement learning problems given a reward structure. This paper addresses this challenge by introducing a novel algorithm that leverages successor features (SFs) at both levels of the optimization. Specifically, SFs help reduce the number of design iterations at the upper level by using previously learned equilibria as biased information sources and accelerate equilibrium learning at the lower level by transferring equilibria from previously solved Markov games. This innovative approach leads to significant computational savings, making the process up to ten times faster compared to traditional methods.},
  archive      = {J_IJMLC},
  author       = {Park, Kyeonghyeon and Molina Concha, David and Lee, Hyun-Rok and Lee, Taesik and Lee, Chi-Guhn},
  doi          = {10.1007/s13042-025-02622-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {6249-6270},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Reward design in multi-agent systems using successor features and multi-information source bayesian optimization},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FFS-IML: Fusion-based statistical feature selection for machine learning-driven interpretability of chronic kidney disease. <em>IJMLC</em>, <em>16</em>(9), 6215-6248. (<a href='https://doi.org/10.1007/s13042-025-02621-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chronic kidney disease (CKD) is a prevalent and serious global health issue, with a significant impact on individuals globally. Hence, it is imperative to promptly obtain an accurate diagnosis and interpretation for the commencement of appropriate treatment as timely detection and intervention can enhance the probability of long-term survival. Existing projection-based methods for feature selection do not yield desired outcomes due to their different objectives necessitating the need for innovation approaches for a higher predictive performance. This study proposes a novel fusion-based feature selection (FFS) model for the optimization and selection of distinct features to enhance CKD diagnosis. This study utilizes the University of California, Irvine (UCI) CKD dataset and addresses missing data and imbalance issues through Multiple Imputations by Chain Equation (MICE) and Borderline Synthetic Minority Oversampling Technique (Borderline-SMOTE). The proposed model integrates different machine learning (ML) classifiers, conventionally known as black boxes, with SHAP values to provide interpretability and gain transparency in the decision-making process. The proposed FFS model performs better than single feature selection approaches, achieving 100% in all of the evaluation metrics for support vector machine, light gradient boosting, random forest, voting and extreme gradient boosting classifiers compared to other existing literature that also utilized the same dataset. Notably, the SHAP analysis reveals that features such as red blood cell, white blood cell count and the pus cell clumps show model specific interactions. This aids healthcare in understanding and effectively applying the model’s outputs. Empirical evidence demonstrates that our proposed approach exhibits superior performance which has the potential to complement physicians’ diagnosis of kidney diseases. Also, the incorporation of explainability enhances the clarity of outcomes and facilitates the identification of the underlying cause of the diseases, contributing to more transparency and ethically sound AI applications in healthcare.},
  archive      = {J_IJMLC},
  author       = {Nneji, Grace Ugochi and Monday, Happy Nkanta and Pathapati, Venkat Subramanyam Reddy and Nahar, Saifun and Mgbejime, Goodness Temofe and Umana, Edwin Sunday and Hossin, Md Altab},
  doi          = {10.1007/s13042-025-02621-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {6215-6248},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {FFS-IML: Fusion-based statistical feature selection for machine learning-driven interpretability of chronic kidney disease},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel Q-learning-inspired mountain gazelle optimizer for solving global optimization problems. <em>IJMLC</em>, <em>16</em>(9), 6167-6213. (<a href='https://doi.org/10.1007/s13042-025-02620-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Q-learning, an eminent reinforcement learning (RL) approach, has garnered substantial research attention in recent years owing to its effectiveness in solving intricate problems and attain noteworthy results in a range of applications. In this study, the Mountain Gazelle Optimizer (MGO) is explored as a promising metaheuristic algorithm, primarily due to its biologically inspired mechanisms that emulate the adaptive and dynamic behaviors of gazelles in nature. However, despite its strong performance, MGO has inherent limitations, such as a tendency to become trapped in suboptimal search regions during early iterations, making it challenging to escape local optima. Therefore, to circumvent these shortcomings, this paper introduces a novel Q-learning-inspired Mountain Gazelle Optimizer (QLMGO), integrating chaotic and random opposite-based learning (ROBL) strategies to enhance optimization performance. The key innovation of QLMGO lies in its dynamic switching mechanism, enabled by Q-learning, which adaptively selects between ROBL and chaotic strategies to optimize the search process. Initially, Q-learning is utilized to regulate the switching mechanism, ensuring efficient exploitation of the search space. During the update phase, QLMGO dynamically chooses the most effective strategy, either ROBL for intensified local search or chaotic exploration for escaping local optima, to accelerate convergence towards the global optimal solution. The performance of QLMGO was rigorously evaluated against well-established optimization algorithms using 23 CEC2005 functions, 10 advanced CEC2019 functions, 30 CEC2017 test functions, and six real-world engineering problems. To ensure a robust and precise assessment, statistical analyses including the Wilcoxon rank-sum test, Friedman test, and t test were conducted. The empirical results from benchmark functions and engineering applications demonstrate the superiority of QLMGO in solving both constrained and unconstrained optimization problems efficiently, thereby validating its effectiveness as an innovative optimization approach.},
  archive      = {J_IJMLC},
  author       = {Sarangi, Priteesha and Mohapatra, Sarada and Mohapatra, Prabhujit},
  doi          = {10.1007/s13042-025-02620-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {6167-6213},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel Q-learning-inspired mountain gazelle optimizer for solving global optimization problems},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial feature augmentation via transformer-level feature fusion for imbalanced data classification. <em>IJMLC</em>, <em>16</em>(9), 6149-6166. (<a href='https://doi.org/10.1007/s13042-025-02619-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifying high-dimensional imbalanced data, such as images and audio, poses a significant challenge to the machine learning community. One potential solution is to employ generative adversarial networks (GANs) for augmenting the minority class data. However, augmentation in data space shows limited performance improvements due to the intricate relationship between balancing class distribution and enhancing feature representation for the minority class. This paper proposes a novel adversarial feature augmentation network via Transformer-level feature fusion (AFAN-TFF) for imbalanced data classification, which operates in feature space without regard to the modality of input data. AFAN-TFF adopts a modified GAN architecture comprising four key components: a feature generator, a feature discriminator, a feature extractor, and a feature classifier. Additionally, a lightweight vision Transformer (ViT) module is devised to enhance feature extraction. This module integrates a global feature pooling layer and a local feature pooling layer, which are used for capturing long-term dependency and contextual features, respectively. Subsequently, these two types of features are fused by a global–local feature fusion layer. These features can complement each other and overcome their individual limitations, resulting in a more robust and informative feature representation. We conducted extensive experiments on five benchmark datasets to compare AFAN-TFF against several established class-imbalance methods. Results demonstrate that AFAN-TFF has substantial advantages over the comparison methods, with consistently improved weighted accuracy, weighted F1, and weighted MCC scores. The effectiveness of employing AFAN-TFF for feature augmentation to enhance classification performance under class-imbalance conditions is also validated.},
  archive      = {J_IJMLC},
  author       = {Leng, Qiangkui and Yi, Gaocheng and Jiao, Erjie and Wang, Changzhong},
  doi          = {10.1007/s13042-025-02619-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {6149-6166},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adversarial feature augmentation via transformer-level feature fusion for imbalanced data classification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency domain self-attention network with contrastive learning for sequential recommendation. <em>IJMLC</em>, <em>16</em>(9), 6135-6148. (<a href='https://doi.org/10.1007/s13042-025-02618-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation is used to model user preferences by analyzing historical interaction data. However, existing approaches based on self-attention mechanisms usually consider user preferences only from the time-domain perspective, ignoring the inherent periodicity in user behavior. To address this challenge, we introduce an innovative solution called FDSRec, which combines frequency domain self-attention networks with contrastive learning techniques. Specifically, we propose a frequency domain self-attention encoder to capture periodic variations in user behavior data. We convert user representations into frequency domain representations by employing the Fast Fourier Transform technique. Subsequently, the frequency domain self-attention networks are used to learn the correlation and importance among different frequency domain components. In addition, we design time-domain and frequency-domain enhancement methods to address data sparsity and noise issues. Furthermore, we employ a multi-task technique to optimize sequential recommendation and contrastive learning objectives. Finally, extensive experiments are conducted on three publicly available datasets, demonstrating that FDSRec outperforms the state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Ji, Huiqin and Zhang, Jinrui and Wang, Yingqi and Yu, Junyang and Xue, Hui and Zhai, Rui and Li, Han},
  doi          = {10.1007/s13042-025-02618-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {6135-6148},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Frequency domain self-attention network with contrastive learning for sequential recommendation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial immune based intrusion detection and mitigation system using entropy fluctuation method and deep maxout classifier. <em>IJMLC</em>, <em>16</em>(9), 6111-6134. (<a href='https://doi.org/10.1007/s13042-025-02617-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid expansion of wireless communication systems and on-demand computing resources over the internet has created new opportunities and challenges in ensuring the accessibility and security of critical infrastructure. Cyberattacks in various forms like distributed denial-of-service (DDoS), resource exploitation or reconnaissance etc. can significantly reduce the accessibility, performance and security and exposing more and more flaws in these technologies, resulting in regular disruptions, monetary losses and reputational harm. This research study introduces an Artificial Immune System (AIS) based Intrusion detection System (IDS) that monitors, detects and mitigates attacks effectively by combining the entropy fluctuation method and a novel Deep Maxout classifier. By analyzing entropy variations in network traffic, the system identifies deviations indicative of potential attacks. An Improved Activation and Loss Function (IALF)-based Deep Maxout classifier and a Deep Belief Network (DBN) are combined in a hybrid model that is highly effective at detecting complex, nonlinear patterns and adjusting activation and loss functions. These insights are then further processed to distinguish malicious activity from normal behavior, resulting in enhanced detection accuracy. Upon detection, the Entropy-based Mitigation Process (EMP) isolates malicious nodes to ensure secure data transmission using normalized correlation coefficients and quartile deviation metrics. The proposed system is evaluated using diverse datasets, which represent a wide range of cyberattacks on computing resources and communication systems. Experimental findings show that the system outperforms traditional models in terms of detection accuracy and adaptability while minimizing false positives. A dynamic mitigation approach addresses both current and future security needs by enabling continuous, adaptive protection against dynamic threat landscape.},
  archive      = {J_IJMLC},
  author       = {Chitte, Pallavi and Chaudhari, Sangita},
  doi          = {10.1007/s13042-025-02617-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {6111-6134},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Artificial immune based intrusion detection and mitigation system using entropy fluctuation method and deep maxout classifier},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SILTD: Structural information for LLM-generated text detection. <em>IJMLC</em>, <em>16</em>(9), 6095-6110. (<a href='https://doi.org/10.1007/s13042-025-02616-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of large language models (LLMs) has significantly improved the quality and diversity of AI-generated content(AIGC). LLM-Generated text detection plays an important role in preventing the harmful misuse of large language models. Existing approaches primarily analyze texts individually, overlooking the structural relationships between them. This limitation restricts their ability to generalize across diverse LLMs, as they fail to capture the shared statistical patterns inherent in generated texts. To address this, an unsupervised-based structural information for LLM-generated text detection (SILTD) method is proposed. The key insight is that texts from different LLMs exhibit latent similarities in their generative statistical space, which can be modeled to improve cross-model generalization. First, we construct a multi-relational text graph based on the similarity of text features, which aims to model the intricate similarities and correlations between texts. Second, we propose a novel unsupervised graph clustering method. The multi-relational graph is transformed into an encoding tree, which is then optimized based on a two-dimensional structure entropy minimization algorithm to achieve hierarchical clustering of texts. Structural entropy minimization enables achieving high-quality clusters, by measuring the uncertainty of random walks within the graph. Finally, we introduce a new method that measures text similarity and computes the intensity of text aggregation within each cluster, to perform in-cluster label inference. Extensive experiments show that, compared to baseline methods, our approach is more effective and generalizable in detecting six popular LLMs across five datasets.},
  archive      = {J_IJMLC},
  author       = {Yang, Jing and Wang, Shi and Zi, Kangli and Sun, Yanshun and Huang, Yuwei and Luo, Tianyu},
  doi          = {10.1007/s13042-025-02616-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {6095-6110},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {SILTD: Structural information for LLM-generated text detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning distillation of non-target categories for facial expression recognition. <em>IJMLC</em>, <em>16</em>(9), 6081-6093. (<a href='https://doi.org/10.1007/s13042-025-02614-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial Expression Recognition (FER) refers to the automated analysis of human emotional states using computer vision techniques, which are of significant importance in tasks such as fatigued driving detection, learning engagement analysis, and safety monitoring. In recent years, deep learning methods have made remarkable progress in facial expression recognition tasks. However, due to scarce samples, high intra-class variation, and inter-class similarity, current approaches perform poorly in recognizing difficult categories, such as Disgust and Fear. To alleviate the performance degradation resulting from these difficult categories, we propose a training framework called Contrastive Learning Distillation of Non-target Categories (CLDN). The proposed method consists of two stages: In the first stage, the model is jointly trained using contrastive learning and supervised learning to weaken the influence of imbalanced labels on visual representation learning, thereby generating robust soft labels. In the second stage, simple category knowledge is transferred to the difficult categories through self-distillation. During the distillation phase, a Non-target Categories Distillation Loss is introduced, alleviating the inhibition of classic distillation losses on non-target category knowledge and further promoting knowledge transfer during the distillation process. The proposed approach achieves competitive results on the RAF-DB, FERPlus, and AffectNet datasets. Ablation studies demonstrate that the method significantly improves the network’s recognition accuracy for difficult categories. The code is available at https://github.com/Greysahy/CLDN .},
  archive      = {J_IJMLC},
  author       = {An, Heng-Yu and Jia, Rui-Sheng},
  doi          = {10.1007/s13042-025-02614-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {6081-6093},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Contrastive learning distillation of non-target categories for facial expression recognition},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image encoded time series classification of small datasets: An innovative architecture using deep learning ensembles. <em>IJMLC</em>, <em>16</em>(9), 6065-6080. (<a href='https://doi.org/10.1007/s13042-025-02613-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are often favored for their strong learning abilities in tackling automatic intelligent models. The classification of time series data streams spans across many applications of intelligent systems. However, the scarcity of effective Machine Learning architectures to handle limited time-series data adversely affects the realization of some crucial applications. In particular, healthcare-related applications are inherently concerned with limited time series datasets. Indeed, building effective artificial intelligence (AI) models for rare diseases using conventional techniques can pose a significant challenge. Utilizing recent advances in deep learning and signal processing techniques, this study introduces a new ensemble deep learning (DL) approach for time series categorization in the presence of limited datasets. Physiological data, such as ECG and voice, are used to demonstrate the functionality of the proposed DL architecture with data obtained from IoT and non-IoT devices. The proposed framework comprises a self-designed deep CNN-LSTM along with ResNet50 and MobileNet transfer learning approaches. The CNN-LSTM architecture includes an enhanced squeeze and excitation block that improves overall performance.This architecture processes time series data transformed into a 3-Channel image structure via improved recurrence plot (RP), Gramian angular field (GAF), and fuzzy recurrence plot (FRP) methods. The proposed model demonstrated superior classification accuracy on the ECG5000 and TESS datasets compared to other state-of-the-art techniques, validating its efficacy for binary and multiclass classification.},
  archive      = {J_IJMLC},
  author       = {Indrasiri, Pubudu L. and Kashyap, Bipasha and Pathirana, Pubudu N.},
  doi          = {10.1007/s13042-025-02613-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {6065-6080},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Image encoded time series classification of small datasets: An innovative architecture using deep learning ensembles},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining data augmentation and model fine-tuning for learning from limited data. <em>IJMLC</em>, <em>16</em>(9), 6047-6064. (<a href='https://doi.org/10.1007/s13042-025-02611-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obtaining sufficient data is often challenging, costly, or even infeasible in real-world applications. To address this issue, researchers have developed methods for learning from limited data, which involves discovering the underlying pattern using a small amount of available data. Data augmentation and model fine-tuning are two methods commonly used for learning with limited data. However, both methods have limitations: model fine-tuning methods often face difficulties in acquiring relevant data for pre-training in certain fields, such as drug discovery, whereas data augmentation methods have the potential risk of causing bias. To address this challenge, we propose a general learning framework for limited data using a combination of data augmentation and model fine-tuning (DAMFT). This framework comprises data augmentation and model fine-tuning modules. The data augmentation module is responsible for generating relevant data that are utilized to pre-train the target model, and the model fine-tuning module aims to correct the potential bias of the pre-trained model caused by data augmentation. DAMFT not only solves the difficulty in obtaining relevant data needed for model fine-tuning but also alleviates the bias caused by data augmentation. Furthermore, under the DAMFT framework, we provide a supervised learning algorithm, DAMFT_GH, which adopts a generative adversarial network and head fine-tuning to generate the new instances and tune the pre-trained model, respectively. The experimental results demonstrate that the proposed learning algorithm can effectively improve the performance of the classification model in the case of limited data.},
  archive      = {J_IJMLC},
  author       = {Shi, Hongbo and Zhang, Ying and Wan, Bowen},
  doi          = {10.1007/s13042-025-02611-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {6047-6064},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Combining data augmentation and model fine-tuning for learning from limited data},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-lingual sentiment analysis empowered by emotional mutual reinforcement through emojis. <em>IJMLC</em>, <em>16</em>(9), 6031-6045. (<a href='https://doi.org/10.1007/s13042-025-02610-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-lingual sentiment analysis is a challenging task in natural language processing that aims to analyze and understand sentiments expressed in texts across different languages. The motivation behind this task is to address the issue faced by sentiment analysis, where the majority of languages lack sufficient labeled data for training. Nevertheless, cross-lingual sentiment analysis tasks mostly depend on translation tools and corpora. This dependency can prevent these models from capturing the unique sentiment characteristics in the target language due to the accuracy limitations of translation tools and corpora. Driven by the common belief that emojis have consistent associations with sentiments across languages, we introduce a method called emotional mutual reinforcement (EMR). Our EMR approach aims to transfer sentiment knowledge between different languages by using emojis as medium of connection. The central concept of EMR involves employing emojis as the medium to connect different languages, facilitating emotional mutual reinforcement across different linguistic contexts. Sentiment knowledge can effectively cross linguistic boundaries through reinforcing emotion-related features with similar sentiment tendencies. In contrast to existing approaches that utilize emojis as a bridge, EMR can incorporate more fine-grained sentiment knowledge from different languages. Results from a complete evaluation on several publicly available datasets confirm the efficiency of the approach we proposed.},
  archive      = {J_IJMLC},
  author       = {Li, Enping and Li, Tianrui and Liang, Tao and Kang, Azhen and Chen, Kexun and Luo, Haonan},
  doi          = {10.1007/s13042-025-02610-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {6031-6045},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Cross-lingual sentiment analysis empowered by emotional mutual reinforcement through emojis},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-strategy improved electric eel foraging optimization algorithm: Continuous and binary variants for solving optimization problems. <em>IJMLC</em>, <em>16</em>(9), 5985-6030. (<a href='https://doi.org/10.1007/s13042-025-02609-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric Eel Foraging Optimization (EEFO) algorithm is a metaheuristic inspired by the social predation behavior of electric eels. It incorporates interactions, resting, migration, and hunting activities to enhance search efficiency. Although EEFO is effective for optimization tasks, it is characterized by slower convergence rates and a tendency to fall into local optima in certain cases. To overcome these limitations, this paper proposes a Multi-strategy Improved Electric Eel Foraging Optimization (MIEEFO) that integrates three key strategies: adaptive tent chaotic mapping, Differential Evolution (DE) mutation strategy, and an enhanced solution technique based on the Fibonacci search technique (FSM). Firstly, MIEEFO employs an adaptive tent chaotic mapping strategy for initializing a uniformly distributed high-quality population for effective search space exploration. Secondly, a novel DE-based mutation strategy is introduced to balance the exploration and exploitation phases. Additionally, to enhance solution quality and mitigate the risk of local optima, an FSM-based improved solution technique is applied to refine the current optimal solution. To conduct a thorough assessment of MIEEFO’s global optimization capabilities, the established numerical challenge of the CEC’22 test suite is utilized. MIEEFO undergoes a comparative analysis with a range of modern, enhanced algorithms, employing the Wilcoxon signed-rank test and the Friedman test to integrate the results of these comparisons. The findings reveal that MIEEFO stands out for its superior optimization abilities, evidenced by its lowest average Friedman ranking of 1.37. MIEEFO consistently outperforms its rivals in most test scenarios, offering solutions that are both more precise and reliable. In addition, the application of MIEEFO is presented through five real-world constrained engineering design challenges, indicating its practical utility. These results highlight MIEEFO’s robust optimization capabilities and its potential for widespread application. Moreover, the proficiency of MIEEFO in managing discrete feature selection tasks is examined through tests on 17 datasets, in conjunction with ten established classification techniques and two advanced classification methods. The results confirm that MIEEFO achieved an average feature selection reduction of 72.59% across datasets while improving classification accuracy by up to 7.2% compared to competing methods.},
  archive      = {J_IJMLC},
  author       = {Mostafa, Reham R. and Khedr, Ahmed M. and AL Aghbari, Zaher and Afyouni, Imad and Kamel, Ibrahim and Ahmed, Naveed},
  doi          = {10.1007/s13042-025-02609-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5985-6030},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A multi-strategy improved electric eel foraging optimization algorithm: Continuous and binary variants for solving optimization problems},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modulation recognition based on adaptive denoising residual neural network. <em>IJMLC</em>, <em>16</em>(9), 5967-5984. (<a href='https://doi.org/10.1007/s13042-025-02608-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing deep learning methods cannot accurately identify the modulation type of wireless signals in the circumstance of low signal-to-noise ratio (SNR). Therefore, the model based on adaptive denoising residual neural network is designed in this paper. At the input end, the pre-processing of the communication signal is carried out to extract the in-phase, orthogonal, amplitude, phase and frequency components of the complex signal as the recognition features. Then adaptive denoising module combining the soft threshold function and the improved channel attention mechanism removes the noise mixed in the signal. After that, the Inception-ResNet which is composed of Inception and residual structure is used to mine deep features. Finally the modulation recognition is realized by the full connection layer. The simulation results show that under the background of Gaussian white noise, its average recognition accuracy for common signals reaches about 94% and also performs well in the condition of Rician, Rayleigh and even unknown channel. Besides, the proposed model is better than visual geometry group-19 under low SNR, and has certain robustness to frequency offset and phase offset.},
  archive      = {J_IJMLC},
  author       = {Ma, Mingyue and Zhen, Jiaqi},
  doi          = {10.1007/s13042-025-02608-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5967-5984},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Modulation recognition based on adaptive denoising residual neural network},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PRR-TM: Finding equilibria in adversarial team games via perfect-recall refinement and teammate modeling. <em>IJMLC</em>, <em>16</em>(9), 5955-5966. (<a href='https://doi.org/10.1007/s13042-025-02607-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial team games (ATGs) with en ante coordination involve a team competing against an adversary under conditions of incomplete information, where team members can coordinate their strategies before the game starts. Team-maxmin equilibrium with correlation (TMECor) is a core solution concept in this setting. While some existing algorithms leverage game transformation techniques to compute TMECor by converting ATGs into two-player zero-sum games, these methods often encounter scalability issues. The exponential growth in the transformed game tree size impedes computational speed and consumes significant storage resources. In this paper, we propose a novel method based on perfect-recall refinement that achieves game tree transformation while maintaining the original size. Additionally, we introduce an innovative teammate modeling approach, allowing team members to infer private information based on observations of their teammates’ actions. Experimental results on benchmark testbeds show a significant improvement in equilibrium computation efficiency without expanding the game size, indicating the effectiveness of our method. Our work not only addresses the computational complexities associated with ATGs but also provides valuable insights for further research on enhancing strategic decision-making in collaborative adversarial settings.},
  archive      = {J_IJMLC},
  author       = {Qiu, Chen and Huang, Weixin and Xiong, Hongji and Zhang, Jiajia and Wang, Xuan},
  doi          = {10.1007/s13042-025-02607-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5955-5966},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {PRR-TM: Finding equilibria in adversarial team games via perfect-recall refinement and teammate modeling},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Core structure-guided multi-modal classification via monte carlo tree search. <em>IJMLC</em>, <em>16</em>(9), 5943-5953. (<a href='https://doi.org/10.1007/s13042-025-02606-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Modal Classification (MMC) effectively integrates multiple data sources, for which the choice of fusion strategy is crucial for classification performance. Current research includes expertise-based and search-based techniques, among which Neural Architecture Search (NAS) approaches stand out, but face significant time and resource consumption issues. To address this issue, CSG-NAS narrows the search scope by using the core structure-guided search, which greatly improves search performance and efficiency. However, CSG-NAS only considers the complementarity between high-quality views when acquiring the core structures, leading to an incomplete narrowed search space. In this paper, we combine Monte Carlo Tree Search (MCTS) with Core Structure-Guided search to propose an efficient and credible MMC algorithm, MCTS-CSG. It includes the core structures acquisition module composed of learning and searching phases, and the optimal structure search module composed of evolving phase. Specifically, the learning phase partitions and ranks the entire space by learning the node regressor, the search phase is based on the MCTS method to sample the structure in the most promising subspace while avoiding falling into a local optimum. The core structures containing complementarity and optimality are obtained after cyclic execution of the learning and searching phases. In the evolving phase, high-quality search domains are constructed around the core structures, which are defined as areas likely to contain high-performance fusion structures, and the Evolutionary Algorithm (EA) is used to find the optimal model structure. Meanwhile, a knowledge inheritance strategy is introduced to improve search speed. The experimental results show that the MCTS-CSG algorithm performs well in the MMC task with the best known search efficiency and performance.},
  archive      = {J_IJMLC},
  author       = {Liu, Guoqing and Qian, Yuhua and Liang, Xinyan and Fu, Pinhan},
  doi          = {10.1007/s13042-025-02606-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5943-5953},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Core structure-guided multi-modal classification via monte carlo tree search},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active attack and defense on attribute reduction with fuzzy rough sets. <em>IJMLC</em>, <em>16</em>(9), 5923-5941. (<a href='https://doi.org/10.1007/s13042-025-02605-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction based on dynamically updated datasets in fuzzy rough sets plays a significant role in dealing with the uncertainty of time-evolving updated data. However, current research on attribute reduction lacks theoretical mechanisms to actively distinguish and defend against malicious interference in datasets. Aiming at this problem, an attribute reduction update framework with defense is proposed for dynamic datasets with adversarial attack. In this framework, an adversarial attack model is presented to select the optimal attacked attributes and construct the adversarial samples to generate the attack datasets. Based on this, a defense model is designed by constructing defense samples to avoid attacks. Firstly, the key identification sample pairs that determine the discernibility of the minimal element subset are defined, which are then used to define the attack target candidate set and construct adversarial samples. To alter the discernibility attributes of the key discernibility sample pairs, the attribute significance degree with attack preference is defined to select the unimportant attributes to attack. Then, the attack model is designed to select the optimal attacked candidate subset and generate the attack dataset. Targeting the attack strategy, defense samples for both the optimal attacked attribute subset and the useless attribute set are constructed to generate the defense matrix and defense datasets. Finally, a unified update strategy for attribute reduction after attack and defense is proposed to induce the updated reduct. Numerical experiments verify the rationality and effectiveness of the framework proposed in this paper based on the success rate of attack and defense, as well as the classification results.},
  archive      = {J_IJMLC},
  author       = {Gao, Yue and Chen, Degang and Wang, Hui},
  doi          = {10.1007/s13042-025-02605-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5923-5941},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Active attack and defense on attribute reduction with fuzzy rough sets},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on a multi-classification diagnosis method for anemia text medical records in traditional chinese medicine based on improved pre-trained LERT model. <em>IJMLC</em>, <em>16</em>(9), 5907-5921. (<a href='https://doi.org/10.1007/s13042-025-02604-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an innovative NLP hybrid model for diagnosing and predicting common types of anemia in Traditional Chinese Medicine (TCM), addressing challenges of limited medical text data and suitable NLP models. Utilizing the pre-trained LERT model as a foundation, we integrate it with the GRU deep learning model to enhance text feature extraction, improving prediction accuracy and reducing computational complexity. The introduced AGN(Adaptive Gate Network) Module mitigates long-term dependency challenges associated with GRU, offering flexible data attention control and enhancing classification performance. A novel loss function, FCS, is designed to handle unbalanced datasets, focusing on difficult-to-classify samples for improved training stability and reduced misclassifications. Evaluating on a TCM anemia diagnosis dataset, our model outperforms benchmarks with an accuracy of 0.9430, precision(MA/WA) of 0.9517/0.9459, recall(MA/WA) of 0.9326/0.9430, and F1-score(MA/WA) of 0.9408/0.9430, demonstrating its potential to intelligently assist doctors in anemia diagnosis and prediction.},
  archive      = {J_IJMLC},
  author       = {Peng, Chongxiao and Gao, Zhijun and Wang, Jinhuan and Yue, Xin and Sun, Lili and Sun, Yinhuan and Du, Fuquan},
  doi          = {10.1007/s13042-025-02604-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5907-5921},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Research on a multi-classification diagnosis method for anemia text medical records in traditional chinese medicine based on improved pre-trained LERT model},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimum-cost based hidden markov model with speed constraint for intruder trajectory recovery in utility tunnels. <em>IJMLC</em>, <em>16</em>(9), 5893-5905. (<a href='https://doi.org/10.1007/s13042-025-02603-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Utility tunnels represent a critical component of urban infrastructure, often regarded as the city’s lifeline. Ensuring the security of utility tunnels is crucial for protecting urban infrastructure and preventing threats to essential services from intruders. Traditional trajectory recovery methods rely on GPS data, which are not suitable for underground environments with inferior signals. The widely deployed network of surveillance cameras in tunnels presents new opportunities, as it allows us to extract video signals and recover intruders’ trajectories, but this approach encounters several challenges. Firstly, the videos from camera network lacks clear identity labels, leading to ambiguous correspondence between intruders and video records. Secondly, the uneven and incomplete distribution of surveillance cameras results in data sparsity issues. In this paper, we propose a novel two-stage framework, TrajUT, which leverages machine learning algorithms to address these challenges. In the first stage, we introduce the multi-criteria-based trajectory segmentation to segment the raw record sequence into sub-sequences belonging to different groups of intruders, based on the continuity of sequences. For second stage, we design a hidden Markov model-based method that uses the records as observed sequences to infer the hidden sequences with the minimum cost, which correspond to the intruder movement trajectories. The proposed dynamic speed constraints enhance trajectory recovery by incorporating both spatial distances and temporal speed relationships into the cost adjustment mechanism. We conduct experiments using real-world data from the utility tunnels in Suzhou City. The results demonstrate the effectiveness of our framework, achieving a 10.38% improvement in precision compared to the best baseline method.},
  archive      = {J_IJMLC},
  author       = {Song, Wenbin and Yin, Baijian and Li, Xinwei and Wang, Shuai and He, Tian and Xu, Zhao-Dong and Liu, Shenghao},
  doi          = {10.1007/s13042-025-02603-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5893-5905},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Minimum-cost based hidden markov model with speed constraint for intruder trajectory recovery in utility tunnels},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ARTEMIS: Animal recognition through enhanced multimodal integration system. <em>IJMLC</em>, <em>16</em>(9), 5877-5892. (<a href='https://doi.org/10.1007/s13042-025-02602-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces Animal Recognition Through Enhanced Multimodal Integration System (ARTEMIS), a transformer-based framework designed for multilabel animal action recognition by fusing video, image, and textual modalities. ARTEMIS utilizes state-of-the-art captioning and language models, such as BLIP2 and Llama 3, to generate textual descriptions from video frames, which are input to the model, significantly enhancing its performance unlikely previous results that do not consider this modality. Through comprehensive ablation studies, we explore the contribution of various model components and propose optimization strategies, including genetic algorithms and reinforcement learning, to dynamically adjust ensemble weights. Our feature alignment techniques-using contrastive and cosine similarity losses-further improve multimodal integration. Evaluations on the Animal Kingdom dataset, which includes 30,100 clips across 140 action classes, demonstrate that ARTEMIS achieves a new state-of-the-art mAP of 79.82, outperforming existing methods. The combination of multimodal fusion and ensemble strategies makes ARTEMIS a robust solution for complex animal action recognition tasks. The code of our fusion method is available at https://github.com/edofazza/ARTEMIS.},
  archive      = {J_IJMLC},
  author       = {Fazzari, Edoardo and Romano, Donato and Falchi, Fabrizio and Stefanini, Cesare},
  doi          = {10.1007/s13042-025-02602-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5877-5892},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {ARTEMIS: Animal recognition through enhanced multimodal integration system},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gformer: A novel spatio-temporal transformer network for accurate traffic flow prediction. <em>IJMLC</em>, <em>16</em>(9), 5861-5875. (<a href='https://doi.org/10.1007/s13042-025-02601-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting traffic flow on urban road networks is extremely challenging due to complex spatio-temporal correlations. Currently, the most popular method is to stack multiple layers of spatio-temporal graph convolutions, which generally combines the graph convolutional network (GCN) with the temporal convolutional network (TCN) or the recurrent neural network (RNN) for joint spatio-temporal prediction. However, the existing methods for constructing the predefined adjacency matrices of the GCN fail to accurately capture the real world situation. In addition, these methods restrict the potential of GCN since the GCN module is limited to aggregating the features within a relatively limited local spatio-temporal neighborhood. In this paper, we propose a neural network called Gformer for predicting traffic flow based on the time lagged and cross correlation (TLCC) algorithm. Gformer captures the temporal and spatial features using the linear self-attention and TLCC-based GCN. The combination of these two models expands the range of the temporal and spatial neighborhoods where feature aggregation is effective, further unleashing the potential of GCN. Additionally, a novel parametrized skip-connection is used to merge the outputs of multiple layers of the encoder and feed them into the decoder for final prediction. To validate the effectiveness of Gformer, we conduct experiments on the two large-scale urban traffic flow datasets and find that our proposed model exhibits superior overall performance compared to all baseline models. The experiments demonstrate the validity and robustness of the proposed model.},
  archive      = {J_IJMLC},
  author       = {Zhao, Yuan and Li, Mingxin and Lei, Hang and Wen, Shixi and Zhao, Hui and Liu, Lichuan},
  doi          = {10.1007/s13042-025-02601-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5861-5875},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Gformer: A novel spatio-temporal transformer network for accurate traffic flow prediction},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ECODI: A novel evolutionary coreset distillation with LLM-assisted fitness evaluation for encrypted network traffics. <em>IJMLC</em>, <em>16</em>(9), 5841-5859. (<a href='https://doi.org/10.1007/s13042-025-02600-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, machine learning-based methods have become essential for classifying network data flows under encryption, as traditional deep packet inspection is ineffective due to encryption protocols like HTTPS and QUIC, which now cover over 85% of Internet traffic. However, the scale of modern Internet traffic introduces new challenges, particularly the massive size of datasets required for training these models. Handling such large datasets results in excessive computational costs, prompting the need for data condensation techniques that reduce dataset size without sacrificing performance. In this paper, we propose a novel Evolutionary Coreset Distillation method for network traffic classification. Our approach, named ECODI, combines the power of evolutionary algorithms with Large Language Models (LLMs) to condense large datasets into smaller, representative coresets. We employ LLMs to generate high-level embeddings that guide the evolutionary algorithm in selecting coresets, thus preserving the most important information while reducing the dataset size. Additionally, we introduce a gradient-based forgetting mechanism to further refine the coreset by eliminating redundant or low-impact data points. The extensive experiments demonstrate that ECODI outperforms both traditional methods (Random Sampling, K-Center, and Herding) and recent evolutionary approaches (EVA and DEvS) in achieving high classification performance with reduced dataset sizes. Notably, ECODI achieves a fitness score of 0.94 in as few as 10 generations, offering substantial improvements in terms of both convergence speed and final classification accuracy compared to EVA and DEvS.},
  archive      = {J_IJMLC},
  author       = {Tran, Hai-Anh and Tong, Van},
  doi          = {10.1007/s13042-025-02600-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5841-5859},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {ECODI: A novel evolutionary coreset distillation with LLM-assisted fitness evaluation for encrypted network traffics},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving intrusion detection with federated learning: Enhancing privacy and efficiency in IoT networks. <em>IJMLC</em>, <em>16</em>(9), 5821-5839. (<a href='https://doi.org/10.1007/s13042-025-02599-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion detection systems (IDS) are crucial in the identification of unauthorized activities on a digital network, enabling cybersecurity measures to initiate prevention protocols to protect the security of their networks and data. With Internet of Things (IoT) as a ubiquitous phenomenon, IDS has become increasingly important owing to the massive growth of connected devices. Machine learning algorithms can detect anomalies in large datasets, but centralized methods pose security risks by gathering all data in one place. Federated learning (FL) offers a safer alternative, allowing multiple clients to collaborate on a model without sharing data, reducing the risk of data leaks and enhancing privacy. In this paper, we propose a FL-based IDS. Herein, we have applied the FL approach to a number of clients that are grouped in sets where the number of clients in a set varies from 2 to 10. After that, we applied feature ranking via a random forest approach, wherein the features are ranked based on their importance to find the optimal and reduced dataset for reducing the inference time. Further, three models for each of the clients were trained using the refined dataset obtained. Next, the central server aggregates the data from the clients using three methods. We have updated the dataset with two types of scenarios, one with two classes (Benign and Attacks) and the second with a multi-class (Benign, Dodag, Flooding, Rank, Blackhole) for identifying the attack. The experimental results establish that the proposed methodology achieves superior performance as compared to similar existing methodologies.},
  archive      = {J_IJMLC},
  author       = {Sharma, Hemant and Yadav, Gyan Singh},
  doi          = {10.1007/s13042-025-02599-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5821-5839},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Privacy-preserving intrusion detection with federated learning: Enhancing privacy and efficiency in IoT networks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selection based l1alm-DT and MHT-LSTM for human activity recogition via sensor. <em>IJMLC</em>, <em>16</em>(9), 5793-5819. (<a href='https://doi.org/10.1007/s13042-025-02598-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Activity Acknowledgment (HAR) from sensor information assumes a vital part in different fields, for example, medical care, sports examination, and security checking. Notwithstanding, the intricacy of precisely recognizing activity from sensor-created information presents critical difficulties. Challenges incorporate overseeing noise obstruction, tending to missing information, and proficiently choosing significant features while staying away from dimensionality issues. The work presents an exhaustive structure, MHT-LSTM, pointed toward improving the exactitude and unwavering quality of human activity recognition. The framework tends to follow certain coordinating high level techniques, starting with signal handling methods to alleviate commotion impedance. The presentation of the K-Adaptive Butterworth filter fundamentally reduces the noise, followed by regularization-based polynomial interpolation that handles the missing signal. The work involves feature extraction by taking into consideration both statistical features and Spatio temporal features. Then, the highlights enhancement utilizing features using an L1 Regularization Adaptive learning mechanism-based decision tree. This step decreases dimensionality, improving computational proficiency without compromising fundamental data. The last stage includes metaheuristic hyperparameter tuning to Long short-term memory (MHT-LSTM) organizations, catching fleeting conditions for exact activity recognition. The subsequent SRCHBO-LSTM system shows remarkable execution measurements in trial assessments. It accomplishes improved precision, accuracy, and f-score as associated to existing state of art methods. Moreover, its insightful accuracy across different action classes approves its adequacy in assorted genuine applications.},
  archive      = {J_IJMLC},
  author       = {Ram, R. Saravana and Boobalan, S. and Prakash, S. Arun and Sekhar, Velappagari},
  doi          = {10.1007/s13042-025-02598-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5793-5819},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Feature selection based l1alm-DT and MHT-LSTM for human activity recogition via sensor},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MAEL-FER: A multi-aspect enhancement learning framework for robust facial emotion recognition through integrated learning modules. <em>IJMLC</em>, <em>16</em>(9), 5761-5792. (<a href='https://doi.org/10.1007/s13042-025-02597-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition (FER) is an important area in computer vision and Artificial Intelligence focused on identifying emotions from facial movements. However, FER faces challenges such as variability in expressions, occlusions, and changing lighting conditions. Addressing these requires advanced solutions, including improved feature extraction techniques, enhanced model training processes, and comprehensive contextual data analysis. This paper proposes a multi-aspect enhancement learning based facial emotion recognition (MAEL-FER) model that exploits several unique modules to effectively classify facial emotions. This approach consists of one of the most specific features to learn the best details of facial expressions that allow for the classification of similar emotions. A feature enhancement module enhances features in some way and suppress those that may not be accurate or noisy, a region enhancing module enhances regions in face such as the eyes and the mouth to recognize emotions. Also, the model entails feature such as generalization learning for better adaptation with various dataset, Meta-learning to allow efficient learning with limited samples, Adversarial training for robustness against noise and adversarial attacks. The MAEL-FER model offers high accuracy in recognizing facial expressions and effectively extracts features, enabling it to distinguish between similar emotions even in challenging conditions. Simulation results highlight the MAEL-FER model's effectiveness with high accuracy rates of 85.78%, 96.98%, 94.83%, and 69.08% across four FER datasets of FER-2013, CK+, RAF-DB, and AFFECTNET-7, respectively. These results surpass previous state-of-the-art methods, demonstrating the model's superior performance, reliability, and efficiency in diverse FER tasks and conditions.},
  archive      = {J_IJMLC},
  author       = {Balachandran, G. and Ranjith, S. and Jagan, G. C. and Chenthil, T. R.},
  doi          = {10.1007/s13042-025-02597-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5761-5792},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {MAEL-FER: A multi-aspect enhancement learning framework for robust facial emotion recognition through integrated learning modules},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive control of direct-drive wave power generation system based on RBF neural network. <em>IJMLC</em>, <em>16</em>(9), 5747-5760. (<a href='https://doi.org/10.1007/s13042-025-02596-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In view of the problems of time-varying disturbance and model parameter variation in the practical application of direct-driven wave power generation system, an adaptive control strategy based on Radial Basis Function (RBF) neural network is proposed. By analyzing the hydrodynamic model of a direct-drive wave energy converter (WEC), the maximum power capture condition is obtained by using the equivalent circuit method. The nonlinear state-space model of direct-drive wave power generation system is constructed based on the idea of maximum force per ampere (MFPA) control. Through the coordinate transformation and state feedback, the canonical form is achieved. An adaptive state feedback tracking controller is designed, in which RBF neural network is used to approximate the unknown function in the controller. The effects of time-varying disturbance and model parameter variation on the system are suppressed effectively. The system is in the desired operation state, and then maximum power tracking control is achieved. Simulation results show that the proposed control strategy effectively improves the transient and steady-state tracking performance, and has good fault-tolerant and anti-disturbance robustness.},
  archive      = {J_IJMLC},
  author       = {Wu, Zhong-Qiang and Jing, Xin},
  doi          = {10.1007/s13042-025-02596-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5747-5760},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adaptive control of direct-drive wave power generation system based on RBF neural network},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph embedded subspace clustering with entropy-based feature weighting. <em>IJMLC</em>, <em>16</em>(9), 5727-5745. (<a href='https://doi.org/10.1007/s13042-025-02595-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subspace clustering on high-dimensional data usually suffers from correlated and contaminated features, which seriously restrict the subspace distribution and graph embedding procedure in practical applications. Therefore, how to preserve intrinsic structure accurately on robust subspaces still needs to be further explored. In this paper, we propose a robust Graph Embedded Subspace Clustering model with Entropy-based Feature Weighting (GSCEFW) to differentiate feature weights and substantially facilitate manifold preserving during subspace learning. In particular, an optimal graph exploration term guided by pseudo-label learning is introduced to subspace clustering framework, which imposes dual-structural constraint on subspace representation to strengthen its block diagonal contour. Then, an entropy-based feature weighting term is considered to automatically mitigate the adverse effect from noisy or irrelevant features during data reconstruction. Finally, an alternative optimization method is developed to solve the challenging objective function, together with theoretical algorithm analysis. Extensive experiments on benchmark datasets demonstrate the effectiveness and superiority of the proposed GSCEFW model compared with the state-of-the-art models.},
  archive      = {J_IJMLC},
  author       = {Jiang, Kun and Liu, Zhaoli and Zhu, Lei and Cui, Lanlan},
  doi          = {10.1007/s13042-025-02595-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5727-5745},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Graph embedded subspace clustering with entropy-based feature weighting},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust speech recognition method based on dense time–frequency convolution and bispectral refinement enhancement. <em>IJMLC</em>, <em>16</em>(9), 5707-5725. (<a href='https://doi.org/10.1007/s13042-025-02594-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In noisy environments, the accuracy of speech recognition is often affected by noise interference, making it necessary to use speech enhancement techniques to mitigate this impact. Current methods that incorporate enhancement modules through joint training have made some progress in improving the robustness of speech recognition systems. However, these approaches primarily focus on directly modeling the original noisy signal without fully considering the use of potentially valuable information within the noise to support the enhancement modeling process. To address these issues, this work proposes a robust speech recognition method based on dense time–frequency convolution and bispectral refinement enhancement. This method attempts to avoid the problem of excessive suppression by repairing distortions that may be introduced by the speech enhancement module while performing noise reduction. First, a single-channel speech enhancement module based on dense time–frequency convolution is used for initial noise suppression. Then, a bispectral refinement enhancement module is designed to extract beneficial features from the estimated noise to improve speech quality. Finally, a proposed weighted speech distortion loss function is applied through multi-task joint training to further enhance recognition performance. Experimental results show that the proposed method reduces the word error rate in speech recognition by 17.57% compared to baseline methods.},
  archive      = {J_IJMLC},
  author       = {Wang, Wenjun and Dong, Ling and Yu, Zhengtao and Huang, Yuxin and Mo, Shangbin and Wang, Linqing},
  doi          = {10.1007/s13042-025-02594-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5707-5725},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Robust speech recognition method based on dense time–frequency convolution and bispectral refinement enhancement},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-dimensional PLSR with manifold optimization based CNN for image classification. <em>IJMLC</em>, <em>16</em>(9), 5689-5705. (<a href='https://doi.org/10.1007/s13042-025-02593-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional Partial Least Squares Regression (PLSR) aims to establish a linear relationship between independent and dependent variables. It will convert the original data into one-dimensional vectors, thus destroying the structural information of the data and generating dimensional catastrophes. To address these limitations, this paper proposes a novel model CNNM2DPLSR called Two-Dimensional Partial Least Squares Regression (2DPLSR) with Manifold Optimization based Convolutional Neural Network (CNN). Firstly, deep features are extracted from the original data using CNN, which are taken as the new independent variables. To retain the structural information of the data, after performing bilateral dimensionality reduction on the independent variables, the resulting low-dimensional features are multiplied by the dependent variable to maximize the inner product, thereby obtaining the bilateral dimensionality reduction matrix. Finally, an objective function for the model is constructed and undergoes a detailed derivation process. Given that the dimensionality reduction matrix satisfies the column orthogonality constraints, the manifold optimization approach is operated in this model to obtain more accurate numerical solutions. Experimental results on various datasets show that the proposed method has lower classification error rates and better adaptability than other representative methods.},
  archive      = {J_IJMLC},
  author       = {Chen, Haoran and Wu, Kai and Song, Wenjun and Tao, Hongwei and Li, Zuhe and Li, Xiao and Du, Yanan},
  doi          = {10.1007/s13042-025-02593-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5689-5705},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Two-dimensional PLSR with manifold optimization based CNN for image classification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive label modification based on uncertainty learning for facial expression recognition in the wild. <em>IJMLC</em>, <em>16</em>(9), 5673-5688. (<a href='https://doi.org/10.1007/s13042-025-02591-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition (FER) in natural settings is often hampered by label noise due to subjective annotations and ambiguous expressions. While previous studies have attempted to address this through uncertainty estimation and relabeling, they have overlooked the accuracy of uncertainty learning and the adaptability of label correction. We propose Adaptive Label Modification based on Uncertainty Learning (ALM-UL), a novel approach that dynamically adjusts noisy labels based on learned uncertainty without manual sample selection. ALM-UL consists of two key components: (1) an uncertainty learning module that obtains precise uncertainty value by focusing on relatively challenging samples, and (2) an adaptive label modification module that revises noisy labels using the learned uncertainty. This approach allows ALM-UL to concentrate on critical facial samples and implement a parameter-free relabeling mechanism, effectively mitigating the impact of uncertain samples. Our method is easily implementable with minimal additional parameters. Experiments on both synthetic and real-world datasets demonstrate that ALM-UL significantly outperforms state-of-the-art algorithms, achieving an average improvement of 2% in recognition accuracy.},
  archive      = {J_IJMLC},
  author       = {Tang, Hui and Li, Yichang and Jin, Zhong},
  doi          = {10.1007/s13042-025-02591-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5673-5688},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adaptive label modification based on uncertainty learning for facial expression recognition in the wild},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-driven embedded feature selection method based on fuzzy decision consistency and classification reward mechanism. <em>IJMLC</em>, <em>16</em>(9), 5653-5672. (<a href='https://doi.org/10.1007/s13042-025-02590-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is vital in machine learning and data analysis, as it enhances model performance, reduces computational costs, and improves efficiency. However, existing embedded methods, particularly those based on regression, often assume a linear relationship between the feature and decision spaces, which is not suitable for complex and large-scale data. To overcome the limitation, the FDC model is proposed as a novel embedded feature selection approach grounded in granular computing theory. By incorporating a fuzzy consistency metric, the FDC model enables nonlinear mapping from the feature space to the decision space, capturing the intricate relationship between features and decisions. FDC integrates a dual mechanism of fusion fuzzy information decision learning and classification reward, allowing it to simultaneously account for both the fuzzy and explicit aspects of classification. Experimental evaluations on 15 real-world datasets demonstrate that the FDC model effectively improves feature selection accuracy, suggesting its potential and applicability in practical settings.},
  archive      = {J_IJMLC},
  author       = {Huang, Yang and Deng, Tingquan and Wang, Changzhong and Zhang, Yang},
  doi          = {10.1007/s13042-025-02590-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5653-5672},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dual-driven embedded feature selection method based on fuzzy decision consistency and classification reward mechanism},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autoencoder-like non-negative matrix factorization with dual-graph constraints for multi-view clustering. <em>IJMLC</em>, <em>16</em>(9), 5637-5652. (<a href='https://doi.org/10.1007/s13042-025-02589-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-negative matrix factorization (NMF)-based multi-view data clustering has been widely used due to its simple formulation and strong interpretability.However, NMF-based multi-view clustering methods primarily focus on reconstructing the original data while neglecting the learning of low-dimensional representations, and emphasize learning the data manifold within the datasets while ignoring the learning of feature manifolds. To address these limitations, we propose a novel framework that combines autoencoder-like NMF with dual-graph constraints for multi-view clustering (ADGNMF). This approach unifies data representation learning and data reconstruction into a single framework, enhancing the learning of low-dimensional data representations. Additionally, to capture comprehensive information, we apply dual-graph constraints to both the data and feature manifolds. The algorithm employs an iterative updating strategy to optimize the objective function. Compared with several state-of-the-art multi-view clustering algorithms, ADGNMF has demonstrated superior performance across five key metrics on six public datasets.},
  archive      = {J_IJMLC},
  author       = {Ban, Yong and Cai, Yongming and Huang, Zhanpeng},
  doi          = {10.1007/s13042-025-02589-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5637-5652},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Autoencoder-like non-negative matrix factorization with dual-graph constraints for multi-view clustering},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IBBA: An improved binary bat algorithm for solving low and high-dimensional feature selection problems. <em>IJMLC</em>, <em>16</em>(9), 5605-5635. (<a href='https://doi.org/10.1007/s13042-025-02588-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technological advancements have resulted in the accumulation of vast amounts of data across various industries, often containing redundant or irrelevant features. As a result, the development of efficient feature selection methods has become increasingly critical. This paper proposes an Improved Binary Bat Algorithm (IBBA) to overcome the limitations of the original Bat Algorithm (BA), particularly its weak exploration ability and tendency to become trapped in local optima. IBBA enhances both exploration and exploitation through a novel Fitness-based Exploitation Strategy (FES) and an improved Harris Hawks Optimization (HHO). Additionally, random perturbations are introduced during iterations to adjust positions that deviate from the search space, thus preventing ineffective searches. Since the original BA is primarily designed for continuous optimization problems, this study also investigates the effect of four V-shaped transfer functions on the algorithm’s performance. Experimental results on 28 datasets with varying dimensionalities (ranging from nine to 12,600 features) demonstrate that IBBA outperforms 12 state-of-the-art metaheuristic algorithms in terms of fitness, accuracy, feature selection ratio, and runtime. Moreover, an analysis of exploration and exploitation shows that IBBA effectively balances these two processes, addressing BA’s exploration shortcomings. The Wilcoxon signed-rank test, conducted at a significance level of 0.05, validates the algorithm’s effectiveness, revealing that IBBA demonstrates significant advantages in 87.5% of the tests. Finally, comparisons with 14 recently proposed feature selection methods highlight IBBA’s competitive classification accuracy. Therefore, this study is expected to make a valuable contribution to solving feature selection problems across datasets with diverse dimensionalities.},
  archive      = {J_IJMLC},
  author       = {Wang, Tao and Xie, Minzhu},
  doi          = {10.1007/s13042-025-02588-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5605-5635},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {IBBA: An improved binary bat algorithm for solving low and high-dimensional feature selection problems},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coarse-to-fine domain adaptation object detection with feature disentanglement. <em>IJMLC</em>, <em>16</em>(9), 5589-5604. (<a href='https://doi.org/10.1007/s13042-025-02586-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation object detection (DAOD) uses the labeled data of one scene (i.e., the source domain) and the unlabeled data of another unfamiliar scene (i.e., the target domain) to train the cross-domain object detector. Most existing methods align the overall distribution of features by adversarial adaptive methods. Despite their success, these methods are primarily designed for two-stage detectors that are challenging to deploy, resulting in limited practical applications. In addition, owing to the instability of adversarial domain discriminator training, inducing the detector is difficult using only an adversarial adaptive strategy to extract instance-level domain-invariant features to align the overall distribution. To address these issues, we propose a new cross-domain object detection framework based on the You Only Look Once (YOLO) series of algorithms named Disentanglement Representation YOLO (DRY). The developed method achieves feature disentanglement in the channel dimension and spatial dimensions through domain-invariant feature disentanglement (DIFD) and instance-level feature disentanglement (ILFD) modules, respectively, prompting the detector to extract domain-invariant features. Experiments demonstrate that our model outperforms existing methods. It achieved an average accuracy value of 42.7 on the Cityscapes to FoggyCityscapes benchmark and significantly outperformed all other methods on human and car objects. The average accuracy values of 49.0 and 49.5 achieved on the SIM10K to Cityscapes and KITTI to Cityscapes scenarios, respectively, are superior to those of existing methods. Extensive experimental results on various datasets verify that the proposed DRY method is effective and widely applicable. The code is available at https://github.com/BJUTsipl/DRY .},
  archive      = {J_IJMLC},
  author       = {Li, Jiafeng and Zhi, Mengxun and Zheng, Yongyu and Zhuo, Li and Zhang, Jing},
  doi          = {10.1007/s13042-025-02586-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5589-5604},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Coarse-to-fine domain adaptation object detection with feature disentanglement},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-stationary fuzzy time series modeling and forecasting using deep learning with swarm optimization. <em>IJMLC</em>, <em>16</em>(9), 5569-5587. (<a href='https://doi.org/10.1007/s13042-025-02585-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this research is to explore the adaptation of fuzzy time series (FTS) modeling and forecasting for dynamically evolving non-stationary data. It is proposed that fuzzy time series modeling, with fuzzy logical relationships (FLRs) predicted by deep learning, and hyperparameters (fuzzy order and length of intervals) defined by swarm intelligence, can effectively forecast non-stationary time series data. The global outbreak of the COVID-19 pandemic highlights the need for accurate time series forecasting models that can adapt to multiple successive waves of the pandemic caused by dynamically evolving variants of the Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) having distinctive spread patterns. Therefore, in this study, a hybrid time series forecasting model integrating high-order FTS, context-augmented variants of the long short-term memory network (LSTM), and particle swarm optimization (PSO), is proposed for accurate forecasting of COVID-19 cases associated with multiple COVID-19 waves. Attention and convolution mechanisms are explored for context augmentation in LSTM. The proposed hybrid model is evaluated on five different datasets of COVID-19 confirmed cases in USA, UK, India, Russia and Italy, in the duration of June 1, 2020 to April 15, 2022, encompassing multiple COVID-19 waves. The model forecasts are compared with five state-of-the-art time series forecasting models using five different performance metrics. Experimental results prove that the hybrid of FTS, attention-bidirectional-LSTM, and PSO (FTS+PSO+Attention-Bi-LSTM) performs consistently best for all countries. Nemenyi statistical significance test verifies that FTS+PSO+Attention-Bi-LSTM is the leading model for time series forecasting of the COVID-19 pandemic with 95% confidence.},
  archive      = {J_IJMLC},
  author       = {Kumar, Naresh and Susan, Seba},
  doi          = {10.1007/s13042-025-02585-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5569-5587},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Non-stationary fuzzy time series modeling and forecasting using deep learning with swarm optimization},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Profiling users with tag-enhanced spherical metric learning for recommendation. <em>IJMLC</em>, <em>16</em>(9), 5553-5567. (<a href='https://doi.org/10.1007/s13042-025-02584-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity of user-item interactions on the Internet, it is important to profile users and model their preferences in recommender systems. Traditional methods, including metric learning, rely on historical user-item interactions to model preferences but struggle in sparse data scenarios. While item tags offer valuable auxiliary information to enhance representations, their shared nature across items makes it challenging to effectively profile users with tags, which requires preserving user personalization through high-quality tag representations. Moreover, traditional optimization for user/item representations always takes place in Euclidean space, where the unconstrained nature of embedding norms tends to lean toward trivial solutions. This may bias the system towards common or popular preferences, thus suppressing the variety in tag-aware user profiles. To this end, we propose to profile users with tag-enhanced spherical metric learning for recommendation, named UTRec. Specifically, we propose an adaptive tag selection mechanism to ensure the quality of tag representations and learn tag-enhanced representations of users/items, thereby effectively profiling users. Additionally, we introduce a spherical optimization strategy for tag-enhanced recommendations to alleviate the limitations imposed by lazy learning and traditional optimization, ensuring the accuracy and diversity of user and item representations within the spherical space. Numerous experiments have been conducted on four real-world datasets, where our proposed tag-enhanced UTRec framework can bring consistent performance gains and achieve a 13.67% improvement regarding both Recall and NDCG metrics.},
  archive      = {J_IJMLC},
  author       = {Tan, Yanchao and Lv, Hang and Huang, Xinyi and Ma, Guofang and Chen, Chaochao},
  doi          = {10.1007/s13042-025-02584-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5553-5567},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Profiling users with tag-enhanced spherical metric learning for recommendation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy levenberg marquart optimization algorithm with inexact line search technique to solve imprecisely defined nonlinear unconstrained optimization problems. <em>IJMLC</em>, <em>16</em>(9), 5527-5551. (<a href='https://doi.org/10.1007/s13042-025-02583-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a fuzzy inexact Levenberg–Marquardt optimization (FILMO) algorithm with a descent direction to handle the nonlinear systems influenced by the uncertain parameters. The main feature of this proposed inexact algorithm is to use the Armijo-type step size search approach via an uncertain environment. The level of inexactness search direction is controlled through the descent direction of the merit function. We establish the convergence analysis of the FILMO algorithm under the assumption of local error bound. Then, the global convergence of the FILMO algorithm is described. The FILMO algorithm is constructed using fuzzy parameters with an Armijo-type step size approach. Numerical examples are illustrated to investigate the effectiveness and efficiency of the algorithm. Then, the comparison is done with a previously existing conjugate gradient modified Fletcher–Reeves method and fuzzy inner outer direct search (FIODS) method. Furthermore, to quantify the uncertainties and sensitivity of the system, fuzzy and fully fuzzy systems are investigated through a case study.},
  archive      = {J_IJMLC},
  author       = {Panigrahi, Paresh Kumar and Nayak, Sukanta},
  doi          = {10.1007/s13042-025-02583-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5527-5551},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fuzzy levenberg marquart optimization algorithm with inexact line search technique to solve imprecisely defined nonlinear unconstrained optimization problems},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep interactive query design and progressive search for end-to-end detection of tiny object in aerial images. <em>IJMLC</em>, <em>16</em>(9), 5509-5525. (<a href='https://doi.org/10.1007/s13042-025-02582-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting tiny objects in aerial images has always been a perennial challenge in computer vision. The tiny objects contain limited pixel representation and are susceptible to background noise, making accurate detection difficult. This paper proposes a novel framework for the detection of tiny objects, which is guided by an end-to-end query-based approach. There are two inherent drawbacks of previous query-based detectors: first, query-based detectors are inherently insensitive to the detection of tiny objects; second, the performance of the detectors gradually saturates as the network depth increases. This paper proposes a novel approach to solve the above problems by leveraging the property that queries are one-to-one label assignment rules. Specifically, the interactive query prediction selector first selects queries with high confidence scores as acceptable queries. Then, a contrastive learning information extractor is used to progressively assign samples to the accepted and improved noisy queries. Finally, a progressive search is used to generate refined prediction anchor boxes. We conducted extensive experiments on three publicly available aerial image datasets, namely DOTA, VisDrone, and AI-TOD, to demonstrate the usefulness and robustness of our proposed method. The results show that our proposed method yields significant performance improvements in the tiny object detection task, outperforming the existing benchmark models.},
  archive      = {J_IJMLC},
  author       = {Jin, Chuan and Zheng, Anqi and Wu, Zhaoying and Tong, Changqing},
  doi          = {10.1007/s13042-025-02582-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5509-5525},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deep interactive query design and progressive search for end-to-end detection of tiny object in aerial images},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced toolface angle control of stabilized platform using I_DDPG in rotary steerable system. <em>IJMLC</em>, <em>16</em>(9), 5493-5507. (<a href='https://doi.org/10.1007/s13042-025-02581-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An improved deep deterministic policy gradient (I_DDPG) algorithm is developed to enhance the accuracy and robustness of toolface angle control in the stabilized platform of a rotary steerable system. The intrinsic frictional torques of the platform are analyzed, and the stability of the DDPG-controlled system is verified through a Lyapunov function. To address value overestimation and minimize error accumulation, a clipped double Q-learning strategy with a delayed update mechanism is integrated into the DDPG framework. Additionally, the maximum entropy principle is employed to enhance exploration capabilities, leading to the I_DDPG algorithm. Comparative simulation results show that I_DDPG outperforms traditional methods, reducing tracking error by 40.64%, increasing response speed by 78.31%, and significantly reducing overshoot by 97.33% compared to the PID algorithm. Furthermore, the algorithm demonstrates strong robustness and adaptability, effectively mitigating the effects of variations in armature resistance and viscous friction coefficient. This approach provides a reliable solution for precise toolface angle control in complex and dynamic drilling environments.},
  archive      = {J_IJMLC},
  author       = {Huo, Aiqing and Zhang, Kun and Jiang, Xue},
  doi          = {10.1007/s13042-025-02581-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5493-5507},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhanced toolface angle control of stabilized platform using I_DDPG in rotary steerable system},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining adaptive local aggregation average and test-time energy adaptation for federated learning. <em>IJMLC</em>, <em>16</em>(9), 5465-5492. (<a href='https://doi.org/10.1007/s13042-025-02580-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated test-time adaptation (FTTA) aims to adapt knowledge from diverse source models to different but related unlabeled target data in an online and privacy-aware manner. However, existing FTTA methods struggle with decreased adaptation performance caused by data distribution shifts among clients. In this paper, we propose an FTTA method (ALAA-TTEA) called adaptive local aggregation average and test-time energy adaptation. The method consists of two continuous stages. First, in the federated aggregation stage, clients adaptively aggregate the global model and local model through adaptive local aggregation (ALA) to initialize the client model. Then, they obtain the global model through personalized training and model averaging. Second, in the test-time adaptation stage, test-time energy adaptation (TTEA) uses an energy function to transform the global model into an energy-based model. It aligns the model distribution with the test data distribution, thereby enhancing the model’s ability to adapt to the test distribution and improving overall performance. Extensive experiments demonstrate that ALAA-TTEA effectively handles data distribution shifts, including feature shift, label shift, hybrid shift, and domain shift. Moreover, it consistently outperforms existing FTTA methods under most conditions.},
  archive      = {J_IJMLC},
  author       = {Liao, Juxin and Yi, Chang’an and Chen, Kai and Peng, Qiaoyi},
  doi          = {10.1007/s13042-025-02580-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5465-5492},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Combining adaptive local aggregation average and test-time energy adaptation for federated learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical structure analysis of linguistic expressions using concept lattice. <em>IJMLC</em>, <em>16</em>(9), 5441-5464. (<a href='https://doi.org/10.1007/s13042-025-02579-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing with words has proven to be a valuable tool for directly processing linguistic information. However, due to the different states of objects at different times or places, how to dynamically obtain the relations and hierarchical structures of linguistic expressions in different contexts is always a challenge. This paper proposes a computing with linguistic expressions (CWLE) model based on linguistic concept lattices to address this challenge. To handle uncertainty in linguistic expressions, interval type-2 fuzzy sets are first employed to model them, with an initial order established via the centroid mean, enabling flexible adaptation to varied contexts. Second, the linguistic label formal context automates fuzzy set generation, while a fuzzy linguistic-valued lattice is constructed based on the similarity and hierarchical relationships among linguistic expressions. In addition, a hierarchical generation algorithm further captures complex contextual relationships. Finally, comparative analysis demonstrates the CWLE model’s effectiveness in accurately representing the hierarchical structure of linguistic expressions.},
  archive      = {J_IJMLC},
  author       = {Pang, Kuo and Martínez, Luis and Liu, Jun and Zou, Li and Lu, Mingyu},
  doi          = {10.1007/s13042-025-02579-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5441-5464},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hierarchical structure analysis of linguistic expressions using concept lattice},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Periodic frequent subgraph mining in dynamic graphs. <em>IJMLC</em>, <em>16</em>(9), 5419-5439. (<a href='https://doi.org/10.1007/s13042-025-02578-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because most data in the real world can be represented in graph structures, graph mining is essential in many fields. In recent decades, research on algorithms for mining frequent subgraphs in graph databases has matured. In addition to frequent patterns, periodic and closed patterns are important in real life. However, the definition of periodic patterns in the precedent study is rigorous and has certain limitations, so that many approximate periodic patterns cannot be mined. Thus, based on the study of periodic patterns in itemset databases, we define periodic frequent subgraphs (PFSs) in dynamic graphs using the three measures: average periodicity, maximum periodicity, and minimum periodicity. The task of PFS mining is to discover all the PFSs in a given database. We propose the PFS Miner (PFSM) algorithm to realize this task. In addition, we propose closed PFSs (CPFSs) and the corresponding mining algorithm named CPFS Miner (CPFSM) to make the excavated periodic frequent patterns more concise. Finally, we conduct experiments on real datasets to analyze the performance of the algorithms. The experimental results indicate that the PFSM algorithm can mine meaningful periodic frequent patterns and CPFSM can mine closed periodic frequent patterns with good efficiency and performance.},
  archive      = {J_IJMLC},
  author       = {Cai, Jiayu and Chen, Zhaoming and Chen, Guoting and Gan, Wensheng and Broustet, Amaël},
  doi          = {10.1007/s13042-025-02578-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5419-5439},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Periodic frequent subgraph mining in dynamic graphs},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on dynamic flatness feedback control strategy based on IGWO control efficiency identification for cold tandem rolling mill. <em>IJMLC</em>, <em>16</em>(9), 5397-5417. (<a href='https://doi.org/10.1007/s13042-025-02577-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flatness control is an important means to improve the quality of the strip, and modern tandem cold rolling mills are equipped with various control actuators. The existing flatness control efficiency is determined offline and remains constant throughout the manufacturing process. During actual manufacturing, equipment, and process states may change, making it necessary to identify flatness control efficiency online. The main flatness feedback control strategy is a fixed priority sequence in the existing CVC (Continuous Variable Crown) cold tandem rolling mill. The control system does not have the flexibility to adjust the sequence based on real-time flatness. Aiming at the above problems, in order to improve the effect of flatness control, this paper proposes a dynamic flatness feedback control strategy based on control efficiency identification. To address the issue of high cost and difficulty in updating the on-site flatness control efficiency, based on historical actual data, the IGWO (improved grey wolf optimization) algorithm is used to intelligently identify control efficiency. Data post-processing through IF (isolated forests) and CLT (central limit theorem) obtains results on control efficiency. At the same time, a similarity index is proposed to dynamically adjust the priority sequence of feedback control based on the identification results of the control efficiency and the measured flatness deviations. Finally, the field application results show that the flatness control accuracy is improved, the reduction value of the flatness deviations increased by 13.41%, and the reduction rate of the flatness deviations increased by 9.66%.},
  archive      = {J_IJMLC},
  author       = {Zhou, Xiaomin and Li, Liqi and Wang, Shuaikun and Xiong, Qingxia},
  doi          = {10.1007/s13042-025-02577-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5397-5417},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Research on dynamic flatness feedback control strategy based on IGWO control efficiency identification for cold tandem rolling mill},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selections based on fuzzy probability dominance rough sets in interval-valued ordered decision systems. <em>IJMLC</em>, <em>16</em>(9), 5365-5395. (<a href='https://doi.org/10.1007/s13042-025-02562-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selections (FSs) can greatly reduce the dimensionality and complexity of data, improving the efficiency of data mining and classification learning. For interval-valued ordered decision systems (IVODSs), FSs rely on dominance degrees and information measures; however, there are few selection algorithms based on fusion measurements and few semantic analyses of dominance degrees. Around IVODSs, this paper proposes fuzzy probability dominance rough sets (FPDRSs), an information measurement system and a fusion measure, and thus it constructs a systemic FSs framework. Firstly, we utilize a probability density function to propose the fuzzy probability dominance degree (FPD) that can deeply characterize the fuzzy probability dominance relation (FPDR) between any ordered interval values, and define fuzzy probability dominance dual approximations and dependency (FPDD), so FPDRSs are constructed. Then, the fuzzy probability dominance information entropy, conditional entropy (FPDCE), joint entropy and mutual information are obtained to constitute an information measurement system. Furthermore, a fuzzy probability dominance dependency-conditional entropy (FPDDCE) is defined. In addition, the monotonicity and nonmonotonicity of uncertainty measures are studied. Afterwards, three algorithms FPDD-FS, FPDCE-FS and FPDDCE-FS are constructed by using FPDD, FPDCE and FPDDCE, where attribute significance is used for heuristic searches. Finally, the effectiveness of the proposed uncertainty measures is verified through data experiments, and three proposed algorithms achieve better classification performance than six comparative algorithms.},
  archive      = {J_IJMLC},
  author       = {Liu, Xia and Zhang, Xianyong and Chen, Benwei},
  doi          = {10.1007/s13042-025-02562-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {9},
  number       = {9},
  pages        = {5365-5395},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Feature selections based on fuzzy probability dominance rough sets in interval-valued ordered decision systems},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedL_DBNFSpinalNet based malware detection in IoT devices. <em>IJMLC</em>, <em>16</em>(7), 5013-5031. (<a href='https://doi.org/10.1007/s13042-025-02557-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malware detection is the process which identifies, blocks and prevents the harmful effects of malware by using a set of defensive techniques and technologies. Federated Learning (FL) is a sub-field of Machine Learning (ML), wherein training data remains decentralized. Here, the global model learns by utilizing the local update aggregation. However, training data can be manipulated or corrupted by malicious activities, which may affect the locally computed updates. Therefore, detecting malevolent IoT devices is crucial to prevent such issues. Here, Federated learning-based Deep Belief Network Fused SpinalNet (FedL_DBNFSpinalNet) is presented for Malware Detection (MD) in IoT devices using FL. This framework comprises global and local modes, while the designed model contains clients and servers. In the local model, acquisition of data, pre-processing of data, model training and model evaluation are conducted. The pre-processing is done employing Z-score Normalization (ZN) and model training is performed to detect malware using DBNFSpinalNet. Deep Belief Network (DBN) and SpinalNet are combined to form DBNFSpinalNet. In the global model, model aggregation and model initialization are accomplished. The model aggregation is carried out using the Conditional Autoregressive Value at Risk (CAViaR) model. Additionally, FedL_DBNFSpinalNet obtained high accuracy, mean average precision, recall, and F1-score values of about 88.7%, 87.2%, 91.3%, and 91%, as well as minimum False Positive Rate (FPR), loss, Mean Squared Error (MSE), and Root Mean Squared Error (RMSE), values about 0.087, 0.049, 0.068 and 0.026.},
  archive      = {J_IJMLC},
  author       = {Bhavani, R. and Sankaradass, Veeramalai},
  doi          = {10.1007/s13042-025-02557-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {5013-5031},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {FedL_DBNFSpinalNet based malware detection in IoT devices},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved multi-scale convolution and transformer network for EEG-based motor imagery decoding. <em>IJMLC</em>, <em>16</em>(7), 4997-5012. (<a href='https://doi.org/10.1007/s13042-025-02556-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motor imagery (MI) is currently one of the most researched brain‒computer interface (BCI) paradigms, with convolutional neural networks (CNNs) being extensively used for decoding electroencephalogram (EEG) signals. However, numerous studies have demonstrated that the optimal convolution scale varies across subjects and even within different sessions for the same subject. Additionally, EEG signals are time-series data in which temporal dependencies are critical for decoding performance. Consequently, CNN-based models, which are limited by their receptive fields, often struggle to extract highly discriminative features from EEG signals with low signal-to-noise ratios. To address these challenges, an improved multi-scale convolution and Transformer network (IMCTNet) is proposed for decoding MI tasks. In this network, we design a multi-scale temporal convolution block with a channel attention mechanism, enabling adaptive weighting of feature maps across scales. Additionally, we employ Transformer to capture global temporal dependencies, compensating for the limited receptive field of CNNs. The experimental results demonstrate that the IMCTNet outperforms state-of-the-art models, achieving superior classification accuracy (81.83% for Dataset BCI competition IV 2a, 86.47% for Dataset BCI competition IV 2b, and 74.19% for Dataset OpenBMI). The code for IMCTNet is available at https://github.com/ydxswys1/EEG-IMCTNet .},
  archive      = {J_IJMLC},
  author       = {Zhu, Lei and Wang, Yunsheng and Huang, Aiai and Tan, Xufei and Zhang, Jianhai},
  doi          = {10.1007/s13042-025-02556-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4997-5012},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An improved multi-scale convolution and transformer network for EEG-based motor imagery decoding},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Granular ball-based feature subset selection for incomplete generalized double multi-scale decision tables. <em>IJMLC</em>, <em>16</em>(7), 4981-4995. (<a href='https://doi.org/10.1007/s13042-025-02554-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One type of multi-scale data is widely available, where each object has values organized hierarchically across the same scale levels for all attributes and decisions. However, obtaining complete information can be challenging, leading to missing or omitted feature values. To address this issue, we propose a novel granular ball-based feature subset selection method in this paper. Firstly, we introduce a new multi-scale granular ball neighborhood decision table with multi-scale decisions, referred to as incomplete generalized double multi-scale decision tables (IGDMDTs). Secondly, we present an innovative approach to granulating objects into multi-scale granular ball neighborhood granules using the improved granular ball generation strategy. Next, we design a feature subset selection algorithm that optimizes both scale selection and feature selection. Additionally, we provide a concise rule acquisition algorithm. Finally, we verify the feasibility and effectiveness of our algorithm through experimental results.},
  archive      = {J_IJMLC},
  author       = {Deng, Jia and Wei, Ling and Qiu, Chunjuan and Zhang, Lujing},
  doi          = {10.1007/s13042-025-02554-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4981-4995},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Granular ball-based feature subset selection for incomplete generalized double multi-scale decision tables},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy preservation and fairness constraints for few-shot learning based on lagrange duality. <em>IJMLC</em>, <em>16</em>(7), 4961-4979. (<a href='https://doi.org/10.1007/s13042-025-02553-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning focuses on training models that generalize to new classes or tasks with limited training samples. However, the datasets utilized in few-shot learning often contain sensitive information, raising concerns about potential privacy breaches and fairness issues. Rényi differential privacy (RDP) has gained recognition as a promising alternative to standard differential privacy, offering enhanced flexibility in composition rules and providing more precise analytical guarantees. This approach enforces privacy by introducing noise into the data or model. However, the noise introduced to ensure privacy often adversely affects both model utility and fairness. To address these challenges, this paper proposes a novel sample-level adaptive privacy filtering algorithm, individual Rényi differential privacy stochastic gradient descent, which leverages RDP as a privacy filter to achieve more accurate privacy loss estimation. Additionally, the paper proposes a privacy and fairness constraint algorithm based on Lagrange duality. This approach reformulates fairness metrics as optimization constraints, incorporates the RDP filter for precise privacy measurement, and dynamically adjusts clipping bounds by leveraging the gradients of the fairness constraints. Model parameters are optimized via gradient descent to achieve a balanced trade-off among privacy, fairness, and utility. The experimental results demonstrate that the proposed approach enhances model performance while effectively preserving privacy and fairness in few-shot learning tasks, highlighting its practical applicability in real-world scenarios.},
  archive      = {J_IJMLC},
  author       = {Wang, Jinghong and Yang, Hongbo and Li, Wenxin and Mi, Jusheng and Li, Haokang},
  doi          = {10.1007/s13042-025-02553-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4961-4979},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Privacy preservation and fairness constraints for few-shot learning based on lagrange duality},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tripm: A multi-label deep learning SCA model for multi-byte attacks. <em>IJMLC</em>, <em>16</em>(7), 4945-4960. (<a href='https://doi.org/10.1007/s13042-025-02552-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods have significantly impact in the side-channel attack (SCA) community. However, the training and verification phases of deep learning-based side-channel attacks (DL-SCA) typically focus on a single byte, which leads to the requirement of training numerous models to recover all partial key bytes. To resolve the problem, this paper proposes the TripM model, triple-keys attack model, which can attack three bytes in a single training session. First, TripM leverages label groups black to learn multiple bytes of leaked information in a single training session, where the label groups refers to divide labels to different groups according to the different attack bytes. The labels of TripM comprise three label groups, each group containing the point-of-interest information of the corresponding key. Second, the architectural design of TripM features two identical convolutional branches, allowing for the application of weight-sharing techniques. Both branches utilize the same weights, reducing the size of the model parameters and accelerating the training process. Finally, the TripM model employs a multithreading technique in the key recovery phase, where three threads concurrently compute the 3-byte Guessing Entropy (GE) value. Experimental results demonstrate that TripM can efficiently process the public ASCAD and TinyPower datasets, with an average of 80 and 89 traces required to recover a key. Average Layer-wise Correlation (AVE-LWC) visualization techniques also illustrate that TripM possesses excellent feature extraction capabilities.},
  archive      = {J_IJMLC},
  author       = {Deng, Lianrui and Li, Lang and Ou, Yu and Xiang, Jiahao and Xia, Shengcheng},
  doi          = {10.1007/s13042-025-02552-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4945-4960},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Tripm: A multi-label deep learning SCA model for multi-byte attacks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MPKD-DCFI: Multi-path knowledge distillation via dynamic contextual feature interaction. <em>IJMLC</em>, <em>16</em>(7), 4931-4943. (<a href='https://doi.org/10.1007/s13042-025-02551-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most essential problems faced by multi-point distillation are ensuring the accuracy of feature alignment and the flexibility of dynamically adjusting distillation points. However, these problems must be addressed while handling complex features and model fitting capabilities. Therefore, in this article, to address these problems, we propose a novel method called Multi-Path Knowledge Distillation with Dynamic Contextual Feature Interaction (MPKD-DCFI). Firstly, we utilize channel-attention and spatial-attention mechanisms, which perform multi-layer feature extraction on the raw input data to dynamically adjust the weight assignments. This process generates a weight matrix that incorporates the attention mechanisms in the policy network, enhancing the flexibility of feature extraction while increasing the model’s attention to important features. Secondly, we address the limitation of fixed distillation points in existing multipoint distillation by innovatively introducing the Gram matrix, which optimizes the feature alignment process between teacher and student networks. The Gram matrix captures the correlation between feature maps, thus ensuring the comprehensive extraction of key information from both teacher and student networks. Finally, we propose a flexible multi-point distillation method, which not only extracts the current key information between teachers and students but also synthesizes the contextual feature information of the two network models. This method dynamically adjusts the distillation points to ensure that the models needing distillation are judged in real time during the training process. The results show that the approach is feasible, and has satisfactory accuracy and time efficiency.},
  archive      = {J_IJMLC},
  author       = {Liu, Wei and Zhang, Wenju and Wang, Bin and Li, Junfeng and She, Wei and Tian, Zhao},
  doi          = {10.1007/s13042-025-02551-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4931-4943},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {MPKD-DCFI: Multi-path knowledge distillation via dynamic contextual feature interaction},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Daily routines discovery based on weighted spatial-temporal features. <em>IJMLC</em>, <em>16</em>(7), 4913-4929. (<a href='https://doi.org/10.1007/s13042-025-02550-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In healthcare, the term activity of daily living (ADL) refers to the basic activities that humans perform daily to maintain independence and autonomy. A daily routine is an ordered set of ADLs that reflects a person’s lifestyle and wellness. This article proposes a weighted spatial-temporal features method (WSTF) based on fusion adaptive resonance theory (ART) to discover daily routines. WSTF integrates multiple activity attributes, including starting time, end time, and location, to generate spatial-temporal patterns of ADL. A weight assignment scheme is proposed to determine the weight of activity patterns based on the probability of activity transition on the day to distinguish the importance of the activity. Then daily routines are learned from a set of weighted spatial-temporal ADL sequences. Experiments are conducted on data sets collected by two smart home projects, learning 3 and 14 routines from the 20-day Orange4Home and 220-day Aruba continuous activity streams, respectively. The routines we obtain are more consistent, with fewer clusters and fewer errors than the baseline methods. The results of this study provide a basis for the quantification of daily routines and have great potential for the development of real-world applications.},
  archive      = {J_IJMLC},
  author       = {Song, Xinjing and Wang, Yanjiang},
  doi          = {10.1007/s13042-025-02550-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4913-4929},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Daily routines discovery based on weighted spatial-temporal features},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive multimodal prompt-tuning model for few-shot multimodal sentiment analysis. <em>IJMLC</em>, <em>16</em>(7), 4899-4911. (<a href='https://doi.org/10.1007/s13042-025-02549-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Sentiment Analysis (MSA) aims to integrate multiple information sources, such as text and visual modalities, to predict the sentiments expressed in the data. However, the scarcity of multimodal datasets poses a significant challenge for effective vision-language fusion. Prompt learning has recently emerged as a promising solution to this issue. Existing prompting methods either convert image regions into visual tokens that align with textual word dimensions using a visual encoder or directly use image features. However, these methods overlook the inherent differences between the characteristics of a visual encoder and a language model, making it challenging for the language model to directly comprehend the semantic information of the images. To address this, we propose an adaptive multimodal prompt-tuning approach for sentiment analysis. Specifically, in the proposed adaptive multimodal prompt generation module, we extract initial multimodal features using an advanced pre-trained model, ensuring comprehensive integration of information from different modalities. We then introduce and fuse a learnable vector with the initial multimodal features dynamically, creating contextually relevant multimodal prompts. Finally, we integrate these multimodal prompts with the maked text sequence vector and send them to a pre-trained language model to obtain the word probability distribution. This process enhances the language model’s ability to comprehend and utilize semantic information from multimodal inputs, especially images. Extensive experiments and analyses on two aspect-level and two sentence-level datasets demonstrate that our method outperforms existing state-of-the-art approaches, confirming the effectiveness of the proposed adaptive multimodal prompts.},
  archive      = {J_IJMLC},
  author       = {Xiang, Yan and Zhang, Anlan and Guo, Junjun and Huang, Yuxin},
  doi          = {10.1007/s13042-025-02549-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4899-4911},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adaptive multimodal prompt-tuning model for few-shot multimodal sentiment analysis},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MixPro: Simple yet effective data augmentation for prompt-based learning. <em>IJMLC</em>, <em>16</em>(7), 4879-4898. (<a href='https://doi.org/10.1007/s13042-025-02548-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prompt-based learning has shown considerable promise in reformulating various downstream tasks as cloze problems by combining original input with a predetermined template. This approach demonstrates its effectiveness, especially in few-shot learning scenarios, where the model is trained on a scarce amount of data. Despite its successes, the limited templates and text in few-shot prompt-based learning scenarios leave significant room for performance improvement. Moreover, existing methods sometimes resort to model ensembles, which, while effective, could potentially hamper model efficiency due to increased computational demands [1]. To address these issues, we introduce MixPro, an augmentation method designed to augment both the vanilla input text and the templates. We implement this through the token-level, the sentence-level, and the template-level Mixup strategies. We conduct experiments on five few-shot datasets, and the results show that our MixPro achieves an average performance improvement of 5.08% compared to the backbone model before augmentation. Moreover, it outperforms other augmentation baselines, demonstrating its superior effectiveness.},
  archive      = {J_IJMLC},
  author       = {Li, Bohan and Dou, Longxu and Hou, Yutai and Feng, Yunlong and Mu, Honglin and Wang, Enbo and Zhu, Qingfu and Sun, Qinghua and Che, Wanxiang},
  doi          = {10.1007/s13042-025-02548-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4879-4898},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {MixPro: Simple yet effective data augmentation for prompt-based learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Glaucoma detection and severity classification based on glaucoattent net framework. <em>IJMLC</em>, <em>16</em>(7), 4849-4878. (<a href='https://doi.org/10.1007/s13042-025-02547-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global blindness due to glaucoma necessitates advanced diagnostics. Automated glaucoma detection models, while introduced, grapple with discerning subtle optic disc (OD) and optic cup (OC) changes. Challenges arise in intricate segmentation due to structural variations. Moreover, many existing works fixate on binary classification, lacking nuanced assessments, highlighting the need for more sophisticated approaches. To tackle these challenges, we introduce a framework called GlaucoAttent Net for glaucoma detection, aiming to effectively segment the OD and OC while assessing severity. The foundation of robust model training lies in diverse datasets—ORIGA, REFUGE and G1020. Initially, a glaucoma feature enhanced pre-processing stage preserves fundus image details through Non-Local Means (NLM) denoising, Contrast Limited Adaptive Histogram Equalization (CLAHE) and Adaptive Median Filtering. It retains fine structures, texture patterns, OD morphology, intensity gradients and localized features essential for segmentation. Within the core engine GlaucoAttent Net, which is a cascaded U-Net, the encoder path efficiently extracts feature at two levels to create hierarchical feature representations essential for segmenting the OD. The decoder employs a novel attention mechanism to create a probability mask for OD segmentation followed by OC segmentation by refining features. At the last stage of decoder, merging the probability masks for accurate delineation of the OD and OC boundaries in the image. Additionally, a classification system analyses segmentation outputs like cup-to-disc ratio, areas, diameters and other features to categorize eyes as Healthy, Highly Glaucomatous, Less Glaucomatous and Moderately Glaucomatous. Efficacy metrics showcase outstanding performance: 99.67% accuracy, 99.20% precision, 99.50% recall and a 99.35% F-score, solidifying the methodology's potential for transformative impact in advancing clinical diagnostics.},
  archive      = {J_IJMLC},
  author       = {Chavan, Sachin and Choubey, Nitin},
  doi          = {10.1007/s13042-025-02547-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4849-4878},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Glaucoma detection and severity classification based on glaucoattent net framework},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The processing for label noise based on attribute reduction and two-step method. <em>IJMLC</em>, <em>16</em>(7), 4833-4847. (<a href='https://doi.org/10.1007/s13042-025-02546-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is a mainstream task in machine learning. To achieve good classification results, there are many aspects to consider. Among them, label noise is the most direct and fundamental problem. Nowadays research targets the processing of label noise in numerous aspects, including correction, filtering and enhanced robustness methods. All these methods have improved the classification accuracy to some extent. However, the above studies consider only one approach to label noise, such as solely focusing on filtering or exclusively on correction. Label noise is complex and it is singular to consider only one method to deal with it. For example, contaminated data in a certain class and noise belonging to this class, both belong to the label noise problems, but with completely different distributions and treatments. This requires us to discuss the situations separately and to propose different processes. In this paper, we take this into account and propose a noise processing method that combines revision and filtration (RF). The RF method can follow the different distributions of label noise and perform targeted processes, which is more effective and comprehensive. It can maintain the original data distribution and remove noise as much as possible. On the other hand, high-dimensional datasets are encountered when dealing with label noise. The attribute values of the dataset will be abnormal due to the presence of label noise. Therefore, we suggest an attribute reduction method for the case when label noise exists. The advantage is that it not only removes redundant attributes, but also eliminates attributes interfered with by noise, which is suitable for high-dimensional data with label noise. Experiments prove that our proposed RF algorithm is effective among three classifiers with multiple comparison algorithms. Performing attribute reduction also improves classification accuracy significantly.},
  archive      = {J_IJMLC},
  author       = {Wu, Xingyu and Zhu, Ping},
  doi          = {10.1007/s13042-025-02546-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4833-4847},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {The processing for label noise based on attribute reduction and two-step method},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single node adversarial attack via reinforcement learning on non-target node features for graph neural networks. <em>IJMLC</em>, <em>16</em>(7), 4817-4832. (<a href='https://doi.org/10.1007/s13042-025-02545-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have demonstrated exceptional performance across a wide range of graph-related applications. However, GNN models are susceptible to adversarial perturbations that can significantly degrade their performance. Existing studies on graph adversarial attacks predominantly rely on modifications to the graph structure, which disrupt critical topological features and make such attacks easier to detect, limiting their practical applicability. To address these limitations, this paper proposes a Reinforcement Learning-based Single Node Adversarial Attack (RLSNA), which enhances the stealth of graph attacks by perturbing the feature vector of a single non-target node rather than directly modifying the target node or the graph topology. RLSNA leverages the graph’s topology to identify the most effective non-target node for perturbation, thereby improving attack efficiency and effectiveness. Additionally, by employing reinforcement learning, RLSNA minimizes the required perturbation magnitude to achieve successful attacks on target nodes, reducing detectability and enhancing the robustness of graph adversarial attacks. Experimental results on multiple datasets demonstrate that RLSNA delivers strong attack performance across various GNN models while supporting both targeted and untargeted attack scenarios, underscoring its versatility and efficacy.},
  archive      = {J_IJMLC},
  author       = {Zhai, Zhengli and Qu, Chunyu and Li, Penghui and Xu, Shiya and Niu, Niuwangjie},
  doi          = {10.1007/s13042-025-02545-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4817-4832},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Single node adversarial attack via reinforcement learning on non-target node features for graph neural networks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing network security in industrial IoT environments: A DeepCLG hybrid learning model for cyberattack detection. <em>IJMLC</em>, <em>16</em>(7), 4797-4815. (<a href='https://doi.org/10.1007/s13042-025-02544-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Industrial Internet of Things (IIoT) combines sensors, machinery, industrial software, databases, services, and personnel within the computing environment. IIoT enhances cities, agriculture, e-healthcare, and other areas of life. While IIoT and IoT share many characteristics, they deploy different cybersecurity methods for their networks. Unlike consumer IoT solutions, Industrial Internet of Things (IIoT) solutions typically integrate into operational systems instead of operating independently. Previous investigations suffered a major weakness when they failed to use sampling techniques to balance the datasets from real IIoT operations, which comprise multiple attack types. This can result in models performing poorly on minority classes but well on majority classes, limiting the intrusion detection system’s overall effectiveness. Therefore, security solutions for IIoT require extra strategic planning and continuous monitoring to protect system security and privacy. The objective is to identify traffic data irregularities from IIoT networks. This research introduces a deepCLG hybrid learning model designed to improve network intrusion detection systems (NIDSs). The datasets first go through preprocessing and normalization. Following this, we then formulated a hybrid learning model named DeepCLG. It integrates the convolutional neural network (CNN), the long short-term memory (LSTM), and the gated recurrent unit (GRU) with the capsule network (CN). The model’s efficacy is assessed using two widely accessible datasets: the CICIoT 2023 and UNSW_NB15 datasets. The proposed model outperformed existing techniques in detecting attacks and achieved an accuracy of 99.82%, precision of 97.83%, detection rate of 95.91%, Matthew’s correlation coefficient (MCC) of 96.77%, f1-score of 96.86%, and false alarm rate of 00.06% for the CICIoT 2023 dataset and an accuracy of 95.55%, precision of 88.78%, detection rate of 57.77%, Matthew’s correlation coefficient (MCC) of 79.26%, f1-score of 70.06%, and false alarm rate of 00.81% for the UNSW_NB15 dataset. These findings reveal that the proposed model is proficient in identifying cyberattacks and exhibits adaptability in detecting a multitude of cyberattacks within real IIoT environments.},
  archive      = {J_IJMLC},
  author       = {Gulzar, Qawsar and Mustafa, Khuram},
  doi          = {10.1007/s13042-025-02544-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4797-4815},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhancing network security in industrial IoT environments: A DeepCLG hybrid learning model for cyberattack detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving bi-directional recurrent network for video super-resolution with deformable motion alignment structure. <em>IJMLC</em>, <em>16</em>(7), 4783-4795. (<a href='https://doi.org/10.1007/s13042-025-02543-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video super-resolution, which has been widely applied in ultra-high definition display, video surveillance, and robot surgery, is the recovery of high-resolution image frame sequences with distinct details and temporal continuity from low-resolution video. Thanks to advancements in deep learning, deep video super-resolution has achieved promising results. However, frame artifacts and shakiness remain key challenges that need to be addressed for further improvements in video super-resolution. In particular, it is still worthwhile to research how to properly extract the spatiotemporal features from successive video frames and efficiently fuse them in order to achieve video super-resolution with rich intra-frame details and consistent inter-frame variations. In light of this, we propose to improve bi-directional recurrent network for video super-resolution with deformable motion alignment structure in this work to precisely estimate the offsets and provide sharper image frames. Experiments demonstrate that the proposed approach outperforms current state-of-the-art methods by 0.51%. The project code is available at https://github.com/hengliusky/IBRN_VSR .},
  archive      = {J_IJMLC},
  author       = {Liu, Heng and Huang, Xiangchen and Chu, Yuezhong and Ye, Mingquan and Liu, Tao},
  doi          = {10.1007/s13042-025-02543-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4783-4795},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Improving bi-directional recurrent network for video super-resolution with deformable motion alignment structure},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PF-DETR: Instance position and local feature enhancement for DETR. <em>IJMLC</em>, <em>16</em>(7), 4767-4782. (<a href='https://doi.org/10.1007/s13042-025-02541-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recently proposed DEtection TRansformer (DETR) and its variants have achieved good performance in end-to-end object detection. However, these methods do not take into account the positional relationships between instances in the image and the importance of local feature information. To this end, this paper proposes an object detection method based on instance position and local feature enhancement, named PF-DETR. Firstly, a Dual Positional Encoding Attention (DPEA) is designed, which can simultaneously embed the absolute and relative position information of the object queries, thereby enhancing the localization ability of the queries. Secondly, we introduce a Local Feature Enhancement Module (LFEM), which makes full use of local information to enrich and refine object queries, further enhancing the queries’ perception of local features. Finally, a positional relation is established between the queries and the encoded image feature, and a Positional Interaction Cross-Attention (PICA) is proposed to allow the queries to find relevant regions in the encoded image feature more quickly. The experimental results on the MS COCO 2017 dataset show that the proposed method can effectively improve the convergence and performance of the model.},
  archive      = {J_IJMLC},
  author       = {Zhong, Xinfang and Kuang, Wenlan and Li, Zhixin},
  doi          = {10.1007/s13042-025-02541-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4767-4782},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {PF-DETR: Instance position and local feature enhancement for DETR},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-stream framework using spatial–temporal collaboration learning networks for violence and non-violence classification in complex video environments. <em>IJMLC</em>, <em>16</em>(7), 4737-4766. (<a href='https://doi.org/10.1007/s13042-025-02540-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Violence detection (VD) is a critical task in computer vision with applications in security, surveillance, and public safety. The proliferation of surveillance cameras and the increasing need for automated monitoring systems have underscored the importance of accurate and efficient violence detection algorithms. However, existing methods face several challenges, including limited performance in complex real-world scenarios, high false positive rates, and difficulties in capturing subtle violent behaviours. Addressing these challenges requires the development of advanced algorithms that can effectively differentiate between violent and non-violent activities while minimizing false positives. This paper proposes a Spatial–Temporal Context Collaboration Learning Multi-Stream Network (STCCLM-net) to address challenges in violence detection within video data, particularly in scenarios with crowded scenes, rapid motions, and occlusions. This framework leverages a dual-stream architecture comprising a spatial context extractor network (SCENet) and a temporal context extractor network (TCENet), incorporating a Spatial–Temporal Collaboration Unit (STCU) to optimize spatial and temporal features. The pre-processing stage involves frame difference and background suppression for motion capture and clutter removal. Feature extraction utilizes the VGG16 network for spatial and temporal context extraction, enhancing feature recognition. In this, fully connected VGG16 network (FC-VGG16 Net) efficiently handles sequential data with a one-dimensional structure, while convolutional VGG16 network (Conv-VGG16 Net) effectively models spatial–temporal sequences by leveraging convolution operations, enhancing the comprehensive modeling of spatial–temporal dynamics within video clip data. The STCU module explores the complementary nature of spatial and temporal features through an alternating co-attention mechanism, optimizing feature fusion. The classification stage labels video clips as violent or non-violent based on the extracted features. Together, these modules optimize the model's ability to discern complex patterns and salient features across spatial and temporal dimensions in video data. Experimental results showcase enhanced performance metrics, including increased precision and recall rates of overall 99.6%, validating its effectiveness in accurately classifying violent and non-violent actions on four video datasets.},
  archive      = {J_IJMLC},
  author       = {Pandey, Barun and Sinha, Upasana and Nagwanshi, Kapil Kumar},
  doi          = {10.1007/s13042-025-02540-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4737-4766},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A multi-stream framework using spatial–temporal collaboration learning networks for violence and non-violence classification in complex video environments},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new projection neural network for convex nonlinear second-order cone programming with an application in force optimization problems. <em>IJMLC</em>, <em>16</em>(7), 4727-4735. (<a href='https://doi.org/10.1007/s13042-025-02538-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new projection neural network (PNN) is proposed for the convex nonlinear second-order cone programming (CNSOCP) with linear constraints. The KKT system of the CNSOCP with linear constraints is equivalent to the cone projection equation. Based on the natural residual function, a new PNN is proposed by using the descent direction of the Lyapunov function. The new PNN is derived from a projection descent direction of the prediction-correction projection and contraction method. Furthermore, the Lyapunov stability and global convergence of the proposed PNN are proved. The numerical results show the new PNN is efficient for CNSOCP problems with linear constraints and two force optimization problems.},
  archive      = {J_IJMLC},
  author       = {Mu, Xuewen and Zhao, Bingcong and Liu, Yitong},
  doi          = {10.1007/s13042-025-02538-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4727-4735},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A new projection neural network for convex nonlinear second-order cone programming with an application in force optimization problems},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking learning difficulty and uncertainty of samples with a target perturbation-aware bias-variance decomposition. <em>IJMLC</em>, <em>16</em>(7), 4711-4726. (<a href='https://doi.org/10.1007/s13042-025-02537-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning difficulty and uncertainty are two essential properties of samples in machine learning. Treating training samples unequally according to their learning difficulties or uncertainties can improve learning performance in various learning tasks. In previous literature, these two properties are usually independently applied or explored. This study revisits these two learning properties in the learning cases when perturbations exist for the ground-truth target value of each sample. First, we propose a new bias-variance decomposition for generalization errors when target perturbations exist. Second, the learning difficulty and the uncertainty of samples are reformulated in a unified view on the basis of the new decomposition. Learning difficulty is divided into data, model, and coupled difficulties. Uncertainty can be seen as a part of learning difficulty. Third, we take linear regression as an example for the inference of the target perturbation. We design regression experiments to empirically explore the influence of the target perturbation on the learning difficulty. In addition, experiments on linear regression verify the effectiveness of our two proposed perturbation-aware linear regression methods.},
  archive      = {J_IJMLC},
  author       = {Yao, Rujing and Wu, Ou and Wang, Fang},
  doi          = {10.1007/s13042-025-02537-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4711-4726},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Rethinking learning difficulty and uncertainty of samples with a target perturbation-aware bias-variance decomposition},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence in landscape architecture: A survey. <em>IJMLC</em>, <em>16</em>(7), 4685-4710. (<a href='https://doi.org/10.1007/s13042-025-02536-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development history of landscape architecture (LA) reflects the human pursuit of environmental beautification and ecological balance. With the advancement of artificial intelligence (AI) technologies that simulate and extend human intelligence, immense opportunities have been provided for LA, offering scientific and technological support throughout the entire workflow. In this article, we comprehensively review the applications of AI technology in the field of LA. First, we introduce the many potential benefits that AI brings to the design, planning, and management aspects of LA. Secondly, we discuss how AI can assist the LA field in solving its current development problems, including urbanization, environmental degradation and ecological decline, irrational planning, insufficient management and maintenance, and lack of public participation. Furthermore, we summarize the key technologies and practical cases of applying AI in the LA domain, from design assistance to intelligent management, all of which provide innovative solutions for the planning, design, and maintenance of LA. Finally, we look ahead to the problems and opportunities in LA, emphasizing the need to combine human expertise and judgment for rational decision-making. This article provides both theoretical and practical guidance for LA designers, researchers, and technology developers. The successful integration of AI technology into LA holds great promise for enhancing the field’s capabilities and achieving more sustainable, efficient, and user-friendly outcomes.},
  archive      = {J_IJMLC},
  author       = {Xing, Yue and Gan, Wensheng and Chen, Qidi},
  doi          = {10.1007/s13042-025-02536-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4685-4710},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Artificial intelligence in landscape architecture: A survey},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized lao language synthesis via disentangled neural codec language model. <em>IJMLC</em>, <em>16</em>(7), 4673-4683. (<a href='https://doi.org/10.1007/s13042-025-02535-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of personalized speech synthesis aims to generate speech that mimics the voice characteristics of a specific speaker. Recent advancements in large speech models, such as VALL-E, have achieved timbre cloning using a 3-second reference audio. However, current methods are limited by the reverberation and background noise in the reference audio, which can lead to unwanted information leakage into the timbre and make disentangling speaker characteristics challenging. This paper proposes a method—personalized Lao synthesis via a disentangled neural encoder-decoder language model. We present an adversarial speaker classifier and employ a mutual information minimization approach using the variational contrastive log-ratio upper bound to ensure that only the desired information features are retained during training. This approach enables more adaptive personalized Lao speech synthesis. After conducting experiments on approximately 100 h of Lao speech data, the personalized audio synthesized based on this method achieved a MOS score of 4.02, an improvement of 0.18 compared to the baseline model VALL-E, thereby enhancing the ability to model timbre characteristics of unseen speakers.},
  archive      = {J_IJMLC},
  author       = {Mao, Cunli and Tian, Tian and Wang, Linqin and Yu, Zhengtao and Gao, Shengxiang and Dong, Ling},
  doi          = {10.1007/s13042-025-02535-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4673-4683},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Personalized lao language synthesis via disentangled neural codec language model},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-way unsupervised anomaly detection of sequential patterns. <em>IJMLC</em>, <em>16</em>(7), 4655-4672. (<a href='https://doi.org/10.1007/s13042-025-02533-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised anomaly detection of sequential patterns is attractive in various industries. Compared to methods that rely on prior model assumptions, model-free methods are more adaptive to different applications, while are more challenging. Some popular methods quantify the absolute error between the actual and expected frequencies of a pattern. However, they are insensitive to new patterns. In this paper, we propose a three-way anomaly detection of sequential pattern (3WADSP) method to address this issue. First, we define the error between a pattern’s actual frequency relative to the expected one as anomaly metric. The detection performance is effectively improved due to the high sensitivity of the new metric. Second, we construct two trisecting-acting-outcome models for estimating expected frequency, and capturing the symptoms before the occurrence and disappearance of anomalous patterns, respectively. The former provides better interpretability, and the later brings stronger diversity. Finally, we design a smoothing technique by averaging the anomaly degrees of overlapped patterns. The ambiguity caused by the overlapping is eliminated. 3WADSP not only extends the methodology of three-way decisions, but also provides new tools and perspectives for applications such as medical and fault diagnosis.},
  archive      = {J_IJMLC},
  author       = {Chen, Gong-Suo and Chandarasupsang, Tirapot and Zhang, Zhi-Heng and Zhou, Xiang-Bing and Deng, Wu and Tananchana, Annop and Mu, Lei and Min, Fan},
  doi          = {10.1007/s13042-025-02533-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4655-4672},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Three-way unsupervised anomaly detection of sequential patterns},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-way class-specific attribute reducts based on three-way weighted combination-entropies. <em>IJMLC</em>, <em>16</em>(7), 4627-4654. (<a href='https://doi.org/10.1007/s13042-025-02532-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction plays a fundamental role in data analysis, and it mainly resorts to algebraic and informational measures. Class-specific attribute reducts recently emerge for decision class optimization, and their algebraic type is initial while their informational types need developing. In this paper, three-way informational class-specific attribute reducts (including prior, posterior, and likelihood types) are established by introducing three-way weighted combination-entropies, which are hierarchically constructed for uncertainty measurement, and both their mutual relationships with algebraic class-specific reducts and their internal relationships with three-way informational systematicness are revealed. At first, three-way informational class-specific reducts are defined based on prior, posterior, and likelihood weighted combination-entropies, and their basic properties and heuristic algorithms are given. Then, optimization preservation conditions of three-way weighted combination-entropies are deeply mined to describe three-way informational reduction targets; thus, systematic relationships among informational and algebraic class-specific reducts are investigated, and relevant reduction strength and balance are acquired to generate derivation properties and algorithms of class-specific reducts. Finally, theoretical constructions and systematic connections of three-way class-specific reducts are validated via table examples and dataset experiments. This study deepens three-way uncertainty measurement and attribute reduction at the level of decision class, so it enriches three-way decision in terms of granular computing.},
  archive      = {J_IJMLC},
  author       = {Tang, Lingyu and Zhang, Xianyong and Wang, Jun and Zhou, Yanhong and Zhang, Zhixi},
  doi          = {10.1007/s13042-025-02532-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4627-4654},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Three-way class-specific attribute reducts based on three-way weighted combination-entropies},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-scale stream k-means based on product-quantized codes. <em>IJMLC</em>, <em>16</em>(7), 4613-4626. (<a href='https://doi.org/10.1007/s13042-025-02531-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data stream clustering (DSC) is one of the most significant and widely studied research directions in the field of data mining. However, for the processing of large-scale data streams, most existing methods suffer from slow speed, insufficient memory, and lack of detection and response mechanisms for concept drift. In this paper, a novel Large-Scale Stream K-measn method (LS2K-means) is proposed. By first introducing Product-Quantized Codes into the framework of stream clustering methods, memory space consumption is reduced through the dimensionality reduction of data. Additionally, a new similarity measurement method is introduced, greatly improving the efficiency of distance calculation. A concept drift detection and response mechanism is constructed. By comparing the consistency of clustering results, concept drift can be quickly detected, and a backtracking mechanism is utilized to respond to concept drift promptly, effectively improving the algorithm’s performance. The experimental results on six real datasets show that the proposed method can effectively deal with concept drift in data streams. Especially on large-scale datasets, the execution time of the proposed method exceeds that of the comparison methods.},
  archive      = {J_IJMLC},
  author       = {Hang, Yuqing and Yin, Hongwei and Hu, Wenjun and Zhong, Longfei and Ni, Yuzhou},
  doi          = {10.1007/s13042-025-02531-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4613-4626},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Large-scale stream k-means based on product-quantized codes},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-term causal effects estimation across domains: An invariant surrogate representation learning approach. <em>IJMLC</em>, <em>16</em>(7), 4599-4611. (<a href='https://doi.org/10.1007/s13042-025-02528-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating long-term causal effects from long-term observational and short-term experimental data is challenging yet crucial for applications such as marketing and policy-making. Despite the success in certain applications, existing estimators are prone to biased results and cannot be adapted to unseen domains if the data distribution shifts across the domains. To address this problem, first, we propose an invariant surrogate representation learning method to address the distribution shift, in which, the surrogate representation is disentangled into the domain-level latent surrogates, the unit-level latent surrogates, and the invariant latent surrogates. Then, we devise a long-time causal effects estimator based on the learned invariant representation. We further theoretically show that these latent covariates are identifiable under mild assumptions, which ensures the correctness of the learned invariant surrogate representation and the estimated long-term causal effects. Extensive experiments on two real-world datasets demonstrate our method’s effectiveness, and the visualization of the learned representation further verifies the soundness of the invariant surrogate representation learning approach.},
  archive      = {J_IJMLC},
  author       = {Zheng, Jiabi and Chen, Weilin and Lin, Zhiyong and Yang, Aqing and Hao, Zhifeng},
  doi          = {10.1007/s13042-025-02528-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4599-4611},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Long-term causal effects estimation across domains: An invariant surrogate representation learning approach},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ChatHTTPFuzz: Large language model-assisted IoT HTTP fuzzing. <em>IJMLC</em>, <em>16</em>(7), 4577-4598. (<a href='https://doi.org/10.1007/s13042-024-02527-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) devices offer convenience through web interfaces, web VPNs, and other web-based services, all relying on the HTTP protocol. However, these externally exposed HTTP services present significant security risks. Although fuzzing has shown some effectiveness in identifying vulnerabilities in IoT HTTP services, most state-of-the-art tools still rely on random mutation strategies, leading to difficulties in accurately understanding the HTTP protocol’s structure and generating many invalid test cases. Furthermore, These fuzzers rely on a limited set of initial seeds for testing. While this approach initiates testing, the limited number and diversity of seeds hinder comprehensive coverage of complex scenarios in IoT HTTP services. In this paper, we investigate and find that large language models (LLMs) excel in parsing HTTP protocol data and analyzing code logic. Based on these findings, we propose a novel LLM-guided IoT HTTP fuzzing method, ChatHTTPFuzz, which automatically parses protocol fields and analyzes service code logic to generate protocol-compliant test cases. Specifically, we use LLMs to label fields in HTTP protocol data, creating seed templates. Second, The LLM analyzes service code to guide the generation of additional packets aligned with the code logic, enriching the seed templates and their field values. Finally, we design an enhanced Thompson sampling algorithm based on the exploration balance factor and mutation potential factor to schedule seed templates. We evaluate ChatHTTPFuzz on 16 different real-world IoT devices. It finds more vulnerabilities than SNIPUZZ, BOOFUZZ, and MUTINY. ChatHTTPFuzz has discovered 116 vulnerabilities, of which 70 are unique, and 23 have been assigned CVEs.},
  archive      = {J_IJMLC},
  author       = {Yang, Zhe and Peng, Hao and Jiang, Yanling and Li, Xingwei and Du, Haohua and Wang, Shuhai and Liu, Jianwei},
  doi          = {10.1007/s13042-024-02527-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4577-4598},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {ChatHTTPFuzz: Large language model-assisted IoT HTTP fuzzing},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency coordination and economic dispatch of microgrids using fuzzy neural network control. <em>IJMLC</em>, <em>16</em>(7), 4561-4575. (<a href='https://doi.org/10.1007/s13042-024-02526-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-input single-output fuzzy neural network controller is presented for reducing the frequency oscillations of distributed generations, and minimise entire interconnected system production costs. Firstly, to satisfy the constraint of the cost function, the proportional-integral (PI) controller is used for economic dispatch. Secondly, the fuzzy neural network controller is designed to reduce frequency oscillations in the control process and meet cost constraints. At the same time, a genetic algorithm is adopted to amend controller parameters, thus improving the controller performance. The designed controller is distributed and can efficiently regulate the system over the entire range for overall optimization by simply obtaining messages from neighboring generators. The effectiveness of the proposed control strategy is validated through simulations conducted on the Hardware-in-the-Loop platform.},
  archive      = {J_IJMLC},
  author       = {Li, Jian and Cai, Cong and Su, Qingyu},
  doi          = {10.1007/s13042-024-02526-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4561-4575},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Frequency coordination and economic dispatch of microgrids using fuzzy neural network control},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stochastic recursive gradient algorithm with inertial extrapolation for non-convex problems and machine learning. <em>IJMLC</em>, <em>16</em>(7), 4545-4559. (<a href='https://doi.org/10.1007/s13042-024-02524-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the inertial extrapolation step has gained significant attention due to its capacity to expedite algorithm convergence. This technology has found widespread application across various algorithms. However, within the domain of machine learning, the utilization of extrapolation technology has yielded limited results. Therefore, we apply it to stochastic optimization algorithms to address non-convex and machine learning problems. By integrating the inertial extrapolation step and the modified Barzilai-Borwein (BB) technique into the SARAH framework, we propose an inertial stochastic recurrence gradient method. This method incorporates both the inertial extrapolation step and the improved BB technique. Through theoretical analysis presented in this paper, we demonstrate that the algorithm converges to a global optimum and analyze the linear convergence rate of the non-convex ( $$\tilde{\lambda }$$ -gradient-dominated) objective functions. The numerical results obtained from evaluating three widely utilized machine learning problems clearly illustrate the superior performance and practical feasibility of the proposed algorithm.},
  archive      = {J_IJMLC},
  author       = {Mo, Zhongyu and Ouyang, Chen and Pham, Hongtruong and Yuan, Gonglin},
  doi          = {10.1007/s13042-024-02524-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4545-4559},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A stochastic recursive gradient algorithm with inertial extrapolation for non-convex problems and machine learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rough set interpretation to RBF neural network. <em>IJMLC</em>, <em>16</em>(7), 4525-4544. (<a href='https://doi.org/10.1007/s13042-024-02522-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interpretation of neural networks is a hot research topic. An interpretable model for RBF neural networks is proposed from the perspective of rough sets, and it has better interpretation after combining the rules of the neural network with the attribute significance of rough sets. Firstly, the rule integration and extraction algorithm of neurons is proposed on the basis of the RBF hidden layer neuron influence ability. Secondly, the Pearson correlation coefficient is improved and the interpretation factor $$\gamma$$ is defined, so the numerical evaluation of the interpretation of a neuron is carried out. An optimization algorithm for RBF neural networks is proposed. Finally, the feasibility of the interpretation model is analyzed through two sets of experiments, including interpretability experiments and optimization experiments. Experimental results in nine UCI datasets show that the proposed model has effective interpretation and can optimize the performance of RBF neural networks. The results provide heuristic information for research on the combination of rough sets with machine learning and the interpretation of neural networks.},
  archive      = {J_IJMLC},
  author       = {Deng, Dayong and Wang, Jie and Deng, Zhixuan and Liu, Keyu and Zhang, Pengfei},
  doi          = {10.1007/s13042-024-02522-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4525-4544},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Rough set interpretation to RBF neural network},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-proposal collaboration and multi-task training for weakly-supervised video moment retrieval. <em>IJMLC</em>, <em>16</em>(7), 4509-4524. (<a href='https://doi.org/10.1007/s13042-024-02520-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on weakly-supervised Video Moment Retrieval (VMR), aiming to identify a moment semantically similar to the given query within an untrimmed video using only video-level correspondences, without relying on temporal annotations during training. Previous methods either aggregate predictions for all instances in the video, or indirectly address the task by proposing reconstructions for the query. However, these methods often produce low-quality temporal proposals, struggle with distinguishing misaligned moments in the same video, or lack stability due to a reliance on a single auxiliary task. To address these limitations, we present a novel weakly-supervised method called Multi-proposal Collaboration and Multi-task Training (MCMT). Initially, we generate multiple proposals and derive corresponding learnable Gaussian masks from them. These masks are then combined to create a high-quality positive sample mask, highlighting video clips most relevant to the query. Concurrently, we classify other clips in the same video as the easy negative sample and the entire video as the hard negative sample. During training, we introduce forward and inverse masked query reconstruction tasks to impose more substantial constraints on the network, promoting more robust and stable retrieval performance. Extensive experiments on two standard benchmarks affirm the effectiveness of the proposed method in VMR.},
  archive      = {J_IJMLC},
  author       = {Zhang, Bolin and Yang, Chao and Jiang, Bin and Komamizu, Takahiro and Ide, Ichiro},
  doi          = {10.1007/s13042-024-02520-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4509-4524},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-proposal collaboration and multi-task training for weakly-supervised video moment retrieval},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffpvt:information filtering based diffusion model with PVT for medical image segmentation. <em>IJMLC</em>, <em>16</em>(7), 4491-4507. (<a href='https://doi.org/10.1007/s13042-024-02519-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion probabilistic model, as a generative model, has gained wide attention in image processing tasks, and its powerful image generation capability has made it flourish in the field of computer vision. In recent years, it has achieved excellent performance in the field of medical image segmentation, and nowadays denoising diffusion models supported by network architectures such as U-Net and Transformer are all successfully applied in medical image segmentation tasks. In order to explore the potential of pyramid structure in diffusion modelling, we propose a denoising diffusion model, DiffPVT, which uses the PVT as the network architecture. In order to ensure the diffusion model’s compatibility with the pyramid vision transformer (PVT), we use a dual-encoder architecture to convey the spatial information to ensure the effectiveness of the diffusion model in the denoising stage, while proposing a novel decoder structure to further enrich the reconstruction process, in which we retain the information embedding of the time steps in the second layer encoding stage while applying its extension to the decoder part. We combine the denoising task of the diffusion model with the critical need of the edge detection task in the field of medical image segmentation, and propose dual-mode information filtering module (DMIFM) and use it as a holistic structure to process the requirements of multiple types of tasks in parallel, thus enhancing the denoising process of the diffusion model and enriching the edge information of the feature images. We conduct extensive experiments on four public datasets and confirm that DiffPVT has excellent segmentation level in the field of medical image segmentation. https://github.com/cn-xvkong/DiffPVT .},
  archive      = {J_IJMLC},
  author       = {Wang, Chengming and Yuan, Genji and Li, Mengjun and Li, Jinjiang},
  doi          = {10.1007/s13042-024-02519-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4491-4507},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Diffpvt:information filtering based diffusion model with PVT for medical image segmentation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-view multi-label learning with incomplete data and self-adaptive correlations. <em>IJMLC</em>, <em>16</em>(7), 4471-4489. (<a href='https://doi.org/10.1007/s13042-024-02518-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view multi-label (MVML) learning aims to process MVML data sets represented with multiple feature sets (i.e., views) and labeled with multiple class labels. While in current scenes, MVML data sets always encounter two main phenomena. First, for MVML data, there exist some correlations among different features, instances, labels and these correlations usually have diverse representations including within-view, cross-view, and consensus-view representations. Due to there are usually some certain relationships between information exist, thus these correlations always be changed in a self-adaptive way. Second, for some unpredictable reasons, MVML data may be incomplete and lose some information. To address these phenomena, we pay attention to the self-adaptive measurement of those correlations in different representations and the process of incomplete data, then a multi-view multi-label learning with incomplete data and self-adaptive correlations (MVML-IDSaC) is developed. Extensive experiments on 14 MVML data sets show the superiority of MVML-IDSaC and some conclusions are addressed. (1) MVML-IDSaC performs better than some related competitive algorithms in statistical; (2) MVML-IDSaC can process incomplete MVML data much better; (3) considering comprehensive relationships about data and its inferring results with a feasible way, the performances of a multi-view multi-label algorithm is promoted further.},
  archive      = {J_IJMLC},
  author       = {Zhu, Changming and Han, Liju},
  doi          = {10.1007/s13042-024-02518-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4471-4489},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A multi-view multi-label learning with incomplete data and self-adaptive correlations},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-strategy fusion pelican optimization algorithm and logic operation ensemble of transfer functions for high-dimensional feature selection problems. <em>IJMLC</em>, <em>16</em>(7), 4433-4470. (<a href='https://doi.org/10.1007/s13042-024-02517-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In view of the simple structure of transfer function, an integrated strategy of transfer function logic operation is proposed, which combines different transfer functions reasonably and improves the classification accuracy. It is applied to the binary Pelican optimization algorithm (BPOA) to solve the high-dimensional feature selection problem. At the same time, the adaptive retractable strategy and the electric eel hunting strategy are introduced to improve the Pelican optimization algorithm (POA) in order to improve the unbalanced exploration and exploitation ability of the Pelican optimization algorithm itself, which is easy to fall into local optimal problems. The simulation experiment is divided into three parts. Firstly, two different logical operation integration routes are proposed, and four different transfer functions of S-shaped, V-shaped, U-shaped and RZ-shaped are respectively integrated, and the POA variant with the best effect is selected. In the following experiment, the transfer function of the same integration idea is combined in pairs to further improve the integrated transfer function of logical operations. Finally, adaptive scaling strategy and electric eel hunting strategy are introduced to improve the existing problems of POA, and compared with BAOA, BCOA, BEO, BHHO, BPDO and BZOA. Twelve standard high-dimensional UCI datasets were used to perform performance tests, and the results were statistically analyzed by Friedman test and Wilcoxon rank sum test. Simulation results show that the improved method can effectively simplify feature subsets, improve classification accuracy and obtain lower fitness values in solving these data sets.},
  archive      = {J_IJMLC},
  author       = {Song, Hao-Ming and Wang, Jie-Sheng and Hou, Jia-Ning and Wang, Yu-Cai and Song, Yu-Wei and Qi, Yu-Liang},
  doi          = {10.1007/s13042-024-02517-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4433-4470},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-strategy fusion pelican optimization algorithm and logic operation ensemble of transfer functions for high-dimensional feature selection problems},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive survey on GNN-based anomaly detection: Taxonomy, methods, and the role of large language models. <em>IJMLC</em>, <em>16</em>(7), 4407-4432. (<a href='https://doi.org/10.1007/s13042-024-02516-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of data volumes in real-world applications, anomaly detection has become a crucial task across various scenarios. Anomalies are generally defined as data points that constitute a small proportion yet exhibit significantly different patterns. Numerous detection methods have been proposed and applied, ranging from statistical analysis to the recently extensively studied graph representation learning and large language models (LLMs). Existing surveys on the best-performing detection methods based on graph neural networks (GNNs) or graph structures often attempt to classify and summarize these methods based on anomalous structures or categories. However, these studies frequently conflate the data distribution characteristics with detection approaches, failing to clarify the adaptability of detection methods to different data contexts. To address this issue, we propose a more practical taxonomy for GNN-based anomaly detection methods from the perspective of data characteristics and assumptions regarding anomaly distribution. Specifically, we summarize common characteristics and assumptions, discussing the corresponding detection approaches and methods with a focus on their key aspects. We also analyze the attention given to key subspaces of data, clarify the embedding and classification methods that are often conflated in existing surveys, and summarize decision-based detection methods that are frequently overlooked. Additionally, we discuss the application of LLMs in this field, providing insights for future research.},
  archive      = {J_IJMLC},
  author       = {Yuan, Ziqi and Sun, Qingyun and Zhou, Haoyi and Shao, Minglai and Fu, Xingcheng},
  doi          = {10.1007/s13042-024-02516-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4407-4432},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A comprehensive survey on GNN-based anomaly detection: Taxonomy, methods, and the role of large language models},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing ınternet security: A novel ML approach for intrusion detection using RS2FS and cascaded SVM/ANFIS. <em>IJMLC</em>, <em>16</em>(7), 4389-4406. (<a href='https://doi.org/10.1007/s13042-024-02515-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing Internet of Communications provides different services and infrastructures to ensure privacy. However, the ever-evolving nature of security threats, such as Trojans, viruses, and other destructive attacks, necessitates a robust response. Ransomware, one of the deadliest data intrusion viruses that target legitimate network servers, is becoming increasingly difficult to identify due to inadequate feature identification and classification models. This leads to significant inaccuracies in identifying intruders by the IDS system. We proposed a novel and advanced Machine Learning (ML) model for identifying ransomware intrusion detection systems to address these challenges. This research introduces Relative Spectral Scaling Feature Selection (RS2FS) combined with a Cascaded Support Vector Machine (CSVM) and Adaptive Network-Based Fuzzy Inference System (ANFIS), which significantly improves ransomware intrusion detection and accuracy performance. The C-score normalization method is initially applied to eliminate null values, followed by the utilization of the Transmission-Intensive Behavior Rate (TIBR) method to determine the feature marginal rate of intrusion features. Subsequently, the RS2FS method is utilized for feature selection based on the behavioral rate. The proposed ANFIS classifier is implemented to detect Ransomware Intrusion, resulting in a simulation with an impressive detection accuracy of 95.5%, sensitivity performance of 94.9%, and specificity performance of 96.7%, outperforming existing methods.},
  archive      = {J_IJMLC},
  author       = {Gomathi, S. and Anitha Kumari, K.},
  doi          = {10.1007/s13042-024-02515-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4389-4406},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhancing ınternet security: A novel ML approach for intrusion detection using RS2FS and cascaded SVM/ANFIS},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stochastic recursive gradient algorithm integrating momentum and the powerball function with adaptive step sizes. <em>IJMLC</em>, <em>16</em>(7), 4367-4387. (<a href='https://doi.org/10.1007/s13042-024-02514-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Momentum techniques and the Powerball function have been proven effective in stochastic optimization algorithms, widely utilized in large-scale optimization scenarios. Nonetheless, the integration of these methodologies into stochastic optimization algorithms and the determination of their initial learning rates persist as unresolved and pivotal issues. In this study, we integrate momentum techniques and the Powerball function into the SARAH (StochAstic Recursive grAdient algoritHm), culminating in the inception of a novel variance-reduced gradient descent algorithm named PM-SARAH. Moreover, a pair of adaptive step size variants are respectively integrated into the outer and inner loops of PM-SARAH, giving rise to PM-SARAH-AS and PM-SARAH-RAS. Ultimately, through comparative experimentation with state-of-the-art optimization algorithms on standard machine learning tasks and certain non-convex scenarios, the empirical results underscore the superior performance of the algorithms elucidated in this paper.},
  archive      = {J_IJMLC},
  author       = {Qin, Chuandong and Cai, Zilin and Guo, Yuhang},
  doi          = {10.1007/s13042-024-02514-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4367-4387},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A stochastic recursive gradient algorithm integrating momentum and the powerball function with adaptive step sizes},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TFDN: A reliable hybrid time and frequency domain-based model for photovoltaic power generation time series forecasting. <em>IJMLC</em>, <em>16</em>(7), 4347-4365. (<a href='https://doi.org/10.1007/s13042-024-02513-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid expansion of photovoltaic (PV) power generation has highlighted the critical need for accurate PV power forecasting. This paper proposes a novel deep learning-based model for PV power forecasting that effectively integrates time and frequency domain information to achieve more accurate predictions. Within the time-domain module, the input data undergoes an initial decomposition into cycle segments using the Fast Fourier Transform (FFT). These segments are then processed through a mask-based multilayer perceptron and a parameter-efficient inception block, designed to more easily capture both global and local dependencies within the data. In parallel, a distinct module leverages multiscale convolutional kernels of varying sizes to model cross-dimensional dependencies among different variables in the PV data. In the frequency-domain module, a low-pass filter removes high-frequency noise from the frequency components extracted by the FFT. The filtered components are then fed into a complex linear layer to perform linear interpolation, generating the forecasted frequency components. The inverse FFT subsequently converts the frequency components back into the time domain. This process leverages frequency-domain processing to mitigate information loss in the time domain, while also enabling the integration of both time-domain and frequency-domain information for a more comprehensive analysis of the data. Experimental results demonstrate that the proposed model provides accurate PV power forecasts across three sites and outperforms state-of-the-art models.},
  archive      = {J_IJMLC},
  author       = {Hua, Qiang and Chu, HaoRan and Zhang, Feng and Zhang, Yong and Dong, ChunRu},
  doi          = {10.1007/s13042-024-02513-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4347-4365},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {TFDN: A reliable hybrid time and frequency domain-based model for photovoltaic power generation time series forecasting},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-driven frequency-based zero-shot learning with phase augmentation. <em>IJMLC</em>, <em>16</em>(7), 4325-4345. (<a href='https://doi.org/10.1007/s13042-024-02512-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-Shot Learning (ZSL) aims to recognize unseen classes by aligning visual and semantic information. However, existing methods often struggle with noise in the RGB domain, which limits their ability to capture fine-grained semantic attributes, such as a grey bird’s tail blending with the ground. This visual ambiguity in the RGB domain negatively impacts model performance. In contrast, the frequency domain can better capture high-frequency signals that are often overlooked in RGB, making areas that are easily confused in RGB more distinguishable. To address this issue, we propose a novel frequency-based framework that transforms spatial features into the frequency domain, allowing for more robust attribute representation and improved noise suppression. The framework incorporates a Multi-Scale Frequency Fusion Module that integrates multi-scale feature maps with frequency domain attention, and a Phase-based Augmentation Module that enhances key attributes by augmenting phase information. Additionally, we introduce two novel modules: the Masked Residual Aggregation Module for combining global and local features and the Phase High-Frequency Filtering Module for image denoising. The Mean Class Accuracy results of our method on CUB, AWA2, and aPY datasets are 2.8%, 5.0%, and 7.4% higher than other methods, respectively. We establish a new direction in frequency-based zero-shot learning. Source code at https://github.com/Waldeinsamkeit628/AFPA .},
  archive      = {J_IJMLC},
  author       = {Yin, Wanting and Ge, Jiannan and Zhang, Lei and Li, Pandeng and Liu, Yizhi and Xie, Hongtao},
  doi          = {10.1007/s13042-024-02512-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4325-4345},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Attention-driven frequency-based zero-shot learning with phase augmentation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing knowledge tracing with fine-grained session modeling. <em>IJMLC</em>, <em>16</em>(7), 4307-4323. (<a href='https://doi.org/10.1007/s13042-024-02511-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing (KT) aims to dynamically model learners’ evolving knowledge states based on their historical learning records, playing a vital role in online education systems. Most existing KT methods learn the knowledge states as a transition pattern from the previous exercise to the next one, treating learners’ entire learning records as continuous and uniformly distributed. However, we argue that actual learning records can be divided into distinct shorter sessions. To this end, we propose a novel KT model called Fine-grained Session Modeling for Knowledge Tracing (FSM4KT), which is designed to capture learners’ knowledge state changes with finer granularity. In particular, we first divide learners’ extensive historical learning records into shorter sessions from either temporal or knowledge concept-related perspective. Subsequently, a dedicated designed session-based knowledge proficiency modeling component is presented, which figures out intra-session and inter-session fine-grained interaction dependencies and knowledge state changes. Moreover, a global knowledge proficiency modeling component is introduced to holistically model learners’ knowledge states. Extensive experimental results on three real-world datasets demonstrate that FSM4KT outperforms most of the current baseline methods, thus proving the effectiveness of FSM4KT.},
  archive      = {J_IJMLC},
  author       = {Wang, Jing and Ma, Huifang and Zhang, Mengyuan and Li, Zhixin and Chang, Liang},
  doi          = {10.1007/s13042-024-02511-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4307-4323},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhancing knowledge tracing with fine-grained session modeling},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single image deraining via nonlinear recursive conv-transformer. <em>IJMLC</em>, <em>16</em>(7), 4295-4306. (<a href='https://doi.org/10.1007/s13042-024-02510-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image deraining is an important foundation of advanced image processing, aiming to reconstruct high-quality clean images from rainy images. In recent years, image deraining algorithms based on convolutional neural networks have become mainstream, and deep learning models based on Transformer have also made significant progress in the field of image restoration. Compared with convolutional neural networks, the image deraining performance of Transformer is slightly inferior. In addition, although excessive parameterization helps improve the generalization performance of Transformer, it can also lead to the network size to be too large to be trained. To address the aforementioned issues, a lightweight image deraining network called the nonlinear recursive Conv-Transformer network is proposed, which not only outperforms the Transformer model but also the convolutional model in terms of performance. Specifically, a dual-branch based on convolutional and Transformer models is first proposed, which integrates the local features extracted by the convolutional model with the global features extracted by the Transformer model; then, a nonlinear projecting block is proposed to implement the constraint recursion and a channel attention module is utilized to fuse multi-branch residual features, which helps in designing lightweight networks. Experiments on a large number of benchmark datasets have demonstrated that the performance of the proposed method is superior to that of state-of-the-art methods, while the computational complexity and parameter quantity are much lower than those of similar methods based on Transformer.},
  archive      = {J_IJMLC},
  author       = {Liang, Zhenyuan and Chen, Hui and Zhu, Songhao and Liang, Zhiwei},
  doi          = {10.1007/s13042-024-02510-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4295-4306},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Single image deraining via nonlinear recursive conv-transformer},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Precise feature selection using suffix array algorithm of bioinformatics. <em>IJMLC</em>, <em>16</em>(7), 4265-4294. (<a href='https://doi.org/10.1007/s13042-024-02509-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is crucial to select the most relevant and informative features in a dataset to perform data analysis. Machine learning algorithms perform better when features are selected correctly. Feature selection is not solvable in polynomial time. The exact method takes exponential time, so the researchers used approximate algorithms to reach semi-optimal solutions. It is impossible to explore and exploit the search space in a balanced manner when using heuristic algorithms and metaheuristic methods. To solve this problem, the proposed method replaces meta-heuristic algorithms with the linear time SKEW algorithm in bioinformatics. First, each feature is ranked using the Pearson correlation criterion. Each feature is labeled A, C, G, or T according to its rank. The best feature is A, and the worst feature is T. The dataset can now be viewed as Deoxyribonucleic Acid (DNA). In the second step, the SKEW algorithm is used to determine the lexico-graphical order of suffixes. Suffixes are considered and checked as selected features. The third step involves permuting the features, and the first and second steps are repeated. The best suffix with the lowest cost function is selected after multiple iterations (e.g., ten). As compared to Simulated Annealing (SA), Genetic Algorithm (GA), Gray Wolf Optimizer (GWO), Grasshopper Optimization Algorithm (GOA), Ant Colony Optimization (ACO), Greedy, Gravitational Search Algorithm (GSA), and Pyramid Gravitational Search Algorithm (PGSA), the proposed algorithm improves the objective function by 19.3%, 7.6%, 80.6%, 102.2%, 39.7%, 105.6%, 38.1%, and 14.2% respectively.},
  archive      = {J_IJMLC},
  author       = {Zandvakili, Aboozar and Javidi, Mohammad Masoud and Mansouri, Najme},
  doi          = {10.1007/s13042-024-02509-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4265-4294},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Precise feature selection using suffix array algorithm of bioinformatics},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RLGA-FER: Reinforcement learning based on genetic algorithm for facial expression recognition enhancing. <em>IJMLC</em>, <em>16</em>(7), 4251-4264. (<a href='https://doi.org/10.1007/s13042-024-02508-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial Expression Recognition (FER) is currently a very active field of research. It involves a computer’s capability to recognize and interpret human emotional expressions, which change with an individual’s internal emotional state. Several researchers have been working on this topic, using classical methods or Neural Network (NN) approaches. The accuracy and efficiency of classification models are highly dependent on the quality of the training data. The training process becomes much more challenging when there is a lot of redundant, irrelevant, noisy, or unreliable data. Although many techniques have been developed to address data quality problems; however, these have not been entirely effective. To tackle this critical issue, we propose a Reinforcement Learning with a Genetic Algorithm (RLGA-FER) approach to enhance the quality of training data for FER systems. The proposed RLGA-FER system consists of two components: an agent and an environment. The agent uses a genetic algorithm to make a global decision about whether an image should be retained in the dataset or removed. By leveraging reinforcement learning, the agent dynamically learns and adapts to select the most relevant images, while the genetic algorithm robustly explores and evolves the selection process for optimal performance. The environment consists of three parts: a global training dataset, a feature extractor, and a recognition system. The aim of the feature extractor is to generate feature vectors for the dataset by applying a Conventional Neural Network (CNN). The retained feature data are used to train the evaluation system, and a Support Vector Machine (SVM) is used for evaluation. Our RLGA-FER system is evaluated on two popular FER datasets, RAF-DB and ExpW. The experimental results demonstrate that the proposed RLGA-FER system performs well, with recognition rates of 85.20%, and 77.34% for the RAF-DB, and ExpW datasets, respectively.},
  archive      = {J_IJMLC},
  author       = {Altaha, Mohammed A. and Jarraya, Islem and Haddad, Lobna and Hamdani, Tarek M. and Chabchoub, Habib and Alimi, Adel M.},
  doi          = {10.1007/s13042-024-02508-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4251-4264},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {RLGA-FER: Reinforcement learning based on genetic algorithm for facial expression recognition enhancing},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting graph contrastive learning via adaptive graph augmentation and topology-feature-level homophily. <em>IJMLC</em>, <em>16</em>(7), 4235-4249. (<a href='https://doi.org/10.1007/s13042-024-02507-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning, which aims to learn supervised signals from unlabeled graph data, has gained popularity as an effective method for learning node representations. However, most existing methods leverage random edge dropping to obtain the augmented view, which results in many isolated nodes and leads to limited performance. Moreover, how to reasonably and accurately identify important topology-feature-level positive samples with graph homophily is still an interesting and challenging problem. To address these issues, we propose a novel graph contrastive learning method with adaptive graph augmentation and topology-feature-level homophily, named GCL-GATH. Specifically, GCL-GATH assigns different weights to edges during the graph augmentation process, aiming to preserve the global topological structure as much as possible. Moreover, it simultaneously utilizes both structural and feature information to select positive samples from neighboring nodes. Extensive experimental results fully demonstrate that the proposed GCL-GATH outperforms the state-of-the-art methods. The source codes of this work are available at https://github.com/ZZY-GraphMiningLab/GCL-GATH .},
  archive      = {J_IJMLC},
  author       = {Sun, Shuo and Zhao, Zhongying and Liu, Gen and Zhang, Qiqi and Su, Lingtao},
  doi          = {10.1007/s13042-024-02507-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4235-4249},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Boosting graph contrastive learning via adaptive graph augmentation and topology-feature-level homophily},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NIDS-CBAD: Detecting adversarial attacks in network intrusion detection systems using domain constraints. <em>IJMLC</em>, <em>16</em>(7), 4213-4234. (<a href='https://doi.org/10.1007/s13042-024-02506-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has witnessed continuous improvement over the years, which has led to its application with notable results in several areas, including the development of Network intrusion detection systems (NIDS). However, such learning models are susceptible to adversarial attacks, whereby an imperceptible change in an input data sample can cause misclassification. Adversarial attacks in security-critical applications like NIDS can easily compromise network security and, therefore, require effective countermeasure techniques. In this paper, we propose NIDS-CBAD, a constraint based adversarial detection technique for NIDS. We show that it is possible to detect adversarial examples using the inherent constraints of features derived from a network flow. Unlike prevalent detection techniques, NIDS-CBAD relaxes the requirement of generating adversarial examples for training and also does not need an auxiliary classifier. This reduces the computational requirement as we use constraint violations to detect adversarial attacks. NIDS-CBAD even detects practical adversarial examples specifically designed to obey network constraints. The detection method is simple yet effective in its approach and poses difficulty even for a strong adversary in crafting successful attacks. We evaluate the performance of NIDS-CBAD on three prevalent intrusion datasets: NSL-KDD, UNSW-NB15 and CICIDS2017 against five state-of-the-art adversarial attacks. Experimentally, the proposed method yields an adversarial detection rate of upto 100 $$\%$$ with very few false positives.},
  archive      = {J_IJMLC},
  author       = {Kumar, Vivek and Kumar, Kamal and Singh, Maheep},
  doi          = {10.1007/s13042-024-02506-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4213-4234},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {NIDS-CBAD: Detecting adversarial attacks in network intrusion detection systems using domain constraints},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intrusion detection using a hybrid approach based on CatBoost and an enhanced inception v1. <em>IJMLC</em>, <em>16</em>(7), 4189-4211. (<a href='https://doi.org/10.1007/s13042-024-02505-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Amid the intensifying network threats fueled by the swift advancement of information technology, we want to find a new way to ensure network security. The cornerstone of this methodology is the integration of the CatBoost algorithm with a model composed of two Inception V1 modules, each enhanced with three depthwise separable convolutions. The process entails meticulous data preprocessing, judicious feature selection via CatBoost, and exhaustive training and evaluation of the enhanced model. Stringent testing on select datasets has substantiated the exceptional prowess of this approach. The multi-class evaluations conducted on the CICIDS2017 dataset and the latest CICIoT2023 dataset achieved accuracies of 99.85% and 99.13%, and precisions of 99.84% and 99.13%, respectively. Meanwhile, the binary classification experiments on these datasets recorded accuracies and precisions of 99.95%, 99.40% and 99.94%, 99.77%, respectively. These results represent a performance improvement of 1% to 5% in related research contributions using the same datasets, demonstrating the advantages of our method.},
  archive      = {J_IJMLC},
  author       = {Lin, Lieqing and Zhong, Qi and Qiu, Jiasheng and Liang, Zhenyu and Yang, Yuerong and Hu, Suxiang and Chen, Langcheng},
  doi          = {10.1007/s13042-024-02505-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4189-4211},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Intrusion detection using a hybrid approach based on CatBoost and an enhanced inception v1},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural entropy-based scheduler for job planning problems using multi-agent reinforcement learning. <em>IJMLC</em>, <em>16</em>(7), 4171-4188. (<a href='https://doi.org/10.1007/s13042-024-02504-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, various methods have been explored to address the challenges of solving the large-scale flexible Job-shop scheduling problem (FJSP), where operations can be scheduled on multiple machines, posing state representation and decision-making difficulties. However, existing approaches struggle to handle complex scenarios effectively. To tackle these challenges, this paper introduces an innovative end-to-end MARLSIO framework based on multi-agent reinforcement learning (MARL) and structural information optimization. The proposed strategy decomposes the FJSP into two sub-issues: job operation selection and machine selection. To facilitate the allocation of operations to machines, the presented framework employs the multi-agent proximal policy optimization algorithm to train the job agents. Every agent generates actions according to global state and its observed respective state. The decision-making process for each job agent involves combining the machine selection and operation assignment into a composite decision. Furthermore, a novel structural information representation of scheduling states is introduced, enabling the architecture to describe detailed connections between machines and operations. This enhances the agents’ learning efficiency. Experimental results demonstrate that the proposed method outperforms the traditional approaches and exhibits computational efficiency, even when applied to instances of larger scales and distinct characteristics not encountered during training.},
  archive      = {J_IJMLC},
  author       = {Liang, Lixin and Sun, Shuo and Hao, Zhifeng and Yang, Yong},
  doi          = {10.1007/s13042-024-02504-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4171-4188},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Structural entropy-based scheduler for job planning problems using multi-agent reinforcement learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster-based prediction for product sales of E-commerce after COVID-19 pandemic. <em>IJMLC</em>, <em>16</em>(7), 4151-4170. (<a href='https://doi.org/10.1007/s13042-024-02503-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After a public emergency, predicting product sales in e-commerce can help to better understand and respond to market uncertainties and fluctuations. This can be of significant importance for business decision-making and inventory management. Therefore, in this study, we propose a novel sales forecasting model, which combines the dynamic time warping K-means clustering approach with the convolutional neural networks, Long Short-term Memory Networks, and Attention mechanism (called DKCLA) to predict E-commerce sales after the pandemic. Specifically, products with similar sales patterns are clustered. After that, the data within each cluster are used to construct a predictive model. In this case, if a new city experiences an outbreak of COVID-19 and the sales data in the early stage are obtained, the trained predictive model can be employed to predict product sales after lifting the lockdown in the city. Real sales data from a certain E-commerce platform are collected to verify the effectiveness of DKCLA. The results demonstrate that the proposed DKCLA model outperforms the other 36 benchmarks. In addition, the cluster-based prediction algorithm performs better than the non-clustered prediction algorithm in predicting product sales after the pandemic, and the number of clusters directly affects the prediction. And the learning rate and LSTM units exert great influence on the model performance.},
  archive      = {J_IJMLC},
  author       = {Lv, Zhaolin and Kang, Hongyue and Gao, Zhenyu and Zhuang, Xiaotian and Tang, Jun and Wang, Zhongshuai and Jiang, Xintian},
  doi          = {10.1007/s13042-024-02503-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4151-4170},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Cluster-based prediction for product sales of E-commerce after COVID-19 pandemic},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Permutation driven evolutionary ordering with dependency filtering for multi-label classification. <em>IJMLC</em>, <em>16</em>(7), 4115-4150. (<a href='https://doi.org/10.1007/s13042-024-02502-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the key problems in Multi-Label Classification is label interdependence which is a critical factor in determining the performance of a given multi-label classifier. This problem has been attempted through the use of chaining classifiers or Multi-Layered stacking model architectures. However, these approaches neglect the order of labels while incorporating the label inter-dependencies which in itself is a Non-Deterministic Polynomial Time Hard (NP-Hard) problem, neither do they provide space for partial-dependency in a full-dependency architecture. Therefore, this work uses an Evolutionary approach to extract the optimal label order for arranging the labels. Additionally, novel crossover and mutation mechanisms namely Ordered Slicing Crossover and Loop Shift Mutation have also been introduced. Furthermore, a Dependency Filtering Framework is introduced to render partial dependency to avoid redundant labels and forced full dependency. The experiments were conducted on ten benchmark datasets with varying numbers of labels. Different performance metrics were used to evaluate the effectiveness of the proposed method, and it was compared to other state-of-the-art classifier models, showing an improvement of 14.73% on the best-ranked model to date. The experiments also established reduced prediction time for the proposed approach. The code of the proposed method is available here .},
  archive      = {J_IJMLC},
  author       = {Jain, Ankush and Gupta, Daksh and Shukla, Sarthak and Srivastava, Vishal},
  doi          = {10.1007/s13042-024-02502-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4115-4150},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Permutation driven evolutionary ordering with dependency filtering for multi-label classification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint feature modulation mechanism for driving scene image synthesis by instance texture edge and spatial depth priors. <em>IJMLC</em>, <em>16</em>(7), 4097-4114. (<a href='https://doi.org/10.1007/s13042-024-02501-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study Conditional Image Synthesis (CIS) task towards producing photorealistic driving scenes, which plays a significant role in designing perception algorithms of autonomous driving vehicles. However, due to the sparsity of semantic condition representation and the lack of depth correlation, existing CIS methods face great challenges to produce high visual fidelity images with sharp details. To address this problem, this paper proposes a hybrid priors-assisted CIS solution based on the Joint Feature Modulation Mechanism (JFMM), which exploits complementary advantages of the instance texture edge and the spatial depth priors. Firstly, to synthesize rich instance details, JFMM adopts the edge-wise condition enhancement processing by channel-wise concatenating the original semantic layout and an aligned edge map as input of generator’s semantic normalization. It effectively improves the synthesis performance of filling fine appearance content within semantic regions. Second, to construct depth-of-field structure, we design a depth-adaptive normalization module to achieve a fine-grained 3D visual guidance by calculating the depth-wise normalization parameters of feature activations. It adequately supplements the pixel level depth correlations and enhances the generated stereoscopic content. In addition, we propose the driving scene-specific image quality assessment by two measurements of depth and edge similarity to validate the effectiveness. Experiments with quantitative and qualitative comparisons to state-of-the-art approaches demonstrate that the proposed method can achieve a competitive result on complex scene datasets Cityscapes and ADE20K-outdoor.},
  archive      = {J_IJMLC},
  author       = {Xie, Yixiang and Qin, Huabiao and Chen, Guancheng and Yang, Jihong and Feng, Bin},
  doi          = {10.1007/s13042-024-02501-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4097-4114},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Joint feature modulation mechanism for driving scene image synthesis by instance texture edge and spatial depth priors},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid optimized approaches for ball bearing state prognosis for effective decision making. <em>IJMLC</em>, <em>16</em>(7), 4077-4095. (<a href='https://doi.org/10.1007/s13042-024-02498-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manufacturing Industries (MI) has developed in the past years, by including different types of machines such as the Rotating Machines (RM) to deliver High-Quality Products (HQP), however those machines are prone to failure, which effects on the production process and leading to high economic loses, the purpose behind this study is to present a new strategy that support’s the decision-making to avoid any unexpected breakdowns in the MI. A novel hybrid technique that combines the Adaptive Neuro Fuzzy Inference System (ANFIS), the Hybrid Whale Grey Wolf Optimizer (HWGO), and the state space (SS) approach using the Vibration Condition Monitoring (VCM) signals to determine the Remaining Useful Life (RUL) is introduced. The proposed approach was trained using features selected by the Decision Tree (DT) algorithm. A comparative analysis is conducted against the HWGO with 12 metaheuristic algorithms in terms of optimization. The SS model was applied for forecasting the future RUL values depending on the measured values by the ANFIS-HGWO. The overall results confirm the outperforming of the ANFIS-HWGO-SS compared to different contributions available in the literature using the PRONOSTIA database in terms of performance measure, Therefore, the ANFIS-HWGO-SS approach is a reliable tool for determining the RUL before any unexpected breakdown and further supports the decision-making by offering a vital timeframe for making the proper action before a failure occurs which can be applied for other machine-related tasks to ensure stability by decreasing the failure of the machine, reliability of the RM by providing HQP, security by avoiding accidents in MI, marking a significant step towards enhanced operational efficiency and sustainability.},
  archive      = {J_IJMLC},
  author       = {Euldji, Riadh and Boumahdi, Mouloud and Bachene, Mourad and Euldji, Rafik and Colak, Ilhami},
  doi          = {10.1007/s13042-024-02498-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4077-4095},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A hybrid optimized approaches for ball bearing state prognosis for effective decision making},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Star: Semi-supervised tripartite attribute reduction. <em>IJMLC</em>, <em>16</em>(7), 4063-4076. (<a href='https://doi.org/10.1007/s13042-024-02472-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction, also known as feature selection is favored in preprocessing data especially high-dimensional data for learning models. In general, conventional feature selection algorithms including supervised and unsupervised ones yield impressive performances depending on completely labeled and unlabeled data. Nevertheless, they fail for partially labeled data where a very limited portion is annotated with labels. In this work, we therefore propose a novel scheme dubbed as Semi-supervised Tripartite Attribute Reduction (STAR) to handle the paucity of label information. Essentially, STAR is a three-phase framework: (1) divide original partially labeled data into three parts including augmented labeled data, pseudo labeled data and updated unlabeled data; (2) devise three types of fuzzy measurements including fuzzy-rough dependency-based index, fuzzy joint entropy and fuzzy inter-cluster distance to eliminate feature quality on these three parts; (3) derive the qualified feature subset that can maximize the feature importance fusing the three evaluation criteria. STAR is validated in extensive experiments as compared with other nine well-established feature selection algorithms including one unsupervised, two supervised, and six semi-supervised methods. The reported results demonstrate that base classifiers fed by features selected from STAR are more accurate, suggesting its superiority in the presence of partially labeled data.},
  archive      = {J_IJMLC},
  author       = {Liu, Keyu and Qian, Damo and Li, Tianrui and Yang, Xibei and Yin, Tengyu and Yang, Xin and Liu, Dun},
  doi          = {10.1007/s13042-024-02472-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {8},
  number       = {7},
  pages        = {4063-4076},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Star: Semi-supervised tripartite attribute reduction},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: An advanced reinforcement learning control method for quadruped robots in typical urban terrains. <em>IJMLC</em>, <em>16</em>(5), 3759-3760. (<a href='https://doi.org/10.1007/s13042-025-02564-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJMLC},
  author       = {Yan, Chi and Wang, Ning and Gao, Hongbo and Wang, Xinmiao and Tang, Chao and Zhou, Lin and Li, Yuehua and Wang, Yue},
  doi          = {10.1007/s13042-025-02564-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3759-3760},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Correction to: An advanced reinforcement learning control method for quadruped robots in typical urban terrains},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An advanced reinforcement learning control method for quadruped robots in typical urban terrains. <em>IJMLC</em>, <em>16</em>(5), 3747-3757. (<a href='https://doi.org/10.1007/s13042-024-02478-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quadruped robots, with their exceptional flexibility and stable structure, are highly suitable for traversing the complex unstructured terrains in urban environments. However, the current flexibility and stability of quadruped robots based on reinforcement learning are still not ideal in these terrains. To address this limitation, a large-scale parallel technology-based end-to-end teacher-student learning network framework is proposed, where the Gated Recurrent Unit achieves a potential estimation of the heights surrounding the robot. Meanwhile, by introducing an omnidirectional terrain learning curriculum, the robot can move in any commanded direction, achieving smooth output and tracking of motor joint angles. By utilizing state machines, the model trained from the simulation is deployed in the Unitree Go1 robot via zero-shot learning. Simulation and real-world experiments have demonstrated that this approach significantly enhances the robot’s adaptability and mobility across various urban terrains such as gravel, grass, slopes, and steps.},
  archive      = {J_IJMLC},
  author       = {Yan, Chi and Wang, Ning and Gao, Hongbo and Wang, Xinmiao and Tang, Chao and Zhou, Lin and Li, Yuehua and Wang, Yue},
  doi          = {10.1007/s13042-024-02478-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3747-3757},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An advanced reinforcement learning control method for quadruped robots in typical urban terrains},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual variational network for unsupervised cross-modal hashing. <em>IJMLC</em>, <em>16</em>(5), 3729-3746. (<a href='https://doi.org/10.1007/s13042-024-02477-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal retrieval is a natural and highly valuable need in the current multimedia content explosion era. This paper addresses the problem of unsupervised cross-modal hashing retrieval which enables efficient retrieval across different modalities (e.g., image-text) without class labels. Most previous methods try to align visual and text binary representations in the joint Hamming space, by independently learning encoding functions for respective modality domains. However, since the paired training data describes the same object from different modalities, one modality data exactly plays a complementary role in learning encoding function for the other modality data, which has been less explored. This paper presents a novel cross-modal retrieval framework, called deep dual variational hashing (DDVH), by exploring dual variational mappings between modalities to bridge the inherent modality gap. Specifically, DDVH consists of two sub-modules, which are visual variational mapping (VVM) and textual variational mapping (TVM). VVM generates semantic-preserved binary codes for visual modality samples via the Gaussian latent embeddings, and TVM learns visual-guided binary codes for the corresponding text modality data. These two sub-modules can be jointly optimized under the cyclic consistency mechanism. Such a dual variational mapping strategy enables DDVH to generate unified binary representations for two modalities by visual-semantic interaction in the Hamming space. Comprehensive experiments on three benchmarks demonstrate that our proposed DDVH approach yields significant improvements compared to the state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Deng, Xuran and Liu, Zhihang and Li, Pandeng},
  doi          = {10.1007/s13042-024-02477-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3729-3746},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dual variational network for unsupervised cross-modal hashing},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A transformer-based convolutional local attention (ConvLoA) method for temporal action localization. <em>IJMLC</em>, <em>16</em>(5), 3711-3728. (<a href='https://doi.org/10.1007/s13042-024-02476-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of temporal localization in videos, our research introduces a novel framework that achieves significant results in event localization in videos. We depart from conventional approaches that rely heavily only on global context encoding for sequence analysis from video. We propose a novel framework that leverages an encoder-decoder mechanism powered by VidSwin to extract global features, which are subsequently combined with the local context. To achieve this, we designed ConvLoA, a convolutional local attention mechanism dedicated to computing contextual focus within localized areas in video frames. ConvLoA extends beyond localization, providing a pathway for generative models to create novel, unseen instructional videos. Extensive experiments on the YouCook2 and ActivityNet datasets were performed. The results affirm that the proposed approach is on par with other state-of-the-art alternatives, validating its competitiveness. This research not only highlights the importance of local context for precise localization but also sets the stage for enhanced video understanding, offering a versatile solution for event localization within videos.},
  archive      = {J_IJMLC},
  author       = {Artham, Sainithin and Shaikh, Soharab Hossain},
  doi          = {10.1007/s13042-024-02476-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3711-3728},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A transformer-based convolutional local attention (ConvLoA) method for temporal action localization},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quadratic memory-augmented spatio-temporal transformer graph convolutional recurrent network for traffic forecasting. <em>IJMLC</em>, <em>16</em>(5), 3693-3710. (<a href='https://doi.org/10.1007/s13042-024-02474-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic forecasting, a core technology within Intelligent Transportation Systems, holds broad application prospects due to its ability to accurately predict future traffic states through the modeling and analysis of complex spatio-temporal traffic data. Nevertheless, due to the complex temporal and spatial heterogeneity of traffic sequences, existing models are difficult to effectively solve the non-stationary problems caused by emergencies. To this end, this paper proposes a Quadratic Memory-Augmented Spatio-Temporal Transformer Graph Recurrent Network (QMAGRN) model based on an encoder-decoder framework. The model consists of three parts: a spatio-temporal Transformer encoder, a quadratic memory-augmented (QMA) module, and a graph convolutional recurrent neural network (GCRU) decoder. Specifically, the spatio-temporal transformer encoder captures the complex spatio-temporal dependencies in traffic data. We designed the QMA module to dynamically update its memory based on incoming data, enabling it to adapt to changing patterns and trends. The QMA module queries the feature information of the memory module on the time and space axis and uses the attention weighting method to perform feature fusion, thereby enhancing the encoder’s ability to capture complex spatio-temporal information. This allows the model to maintain information from earlier periods and provide context that helps understand long-term trends and changes, thereby addressing the non-stationarity of traffic data. The GCRU decoder utilizes the features generated by the QMA module as input for its recurrent units. The graph convolutional layers amalgamate historical information from neighboring nodes, thereby enhancing the spatial consistency of predictions. We conducted extensive experiments on five real datasets, and the results demonstrate that our model has achieved state-of-the-art performance. Furthermore, visualizing the learned QMA module enhances the interpretability of the model. Our code and data are accessible via this link: https://anonymous.4open.science/r/QMAGRN-08CD},
  archive      = {J_IJMLC},
  author       = {Zhang, Xiaoyan and Zhang, Yongqin and Meng, Xiangfu},
  doi          = {10.1007/s13042-024-02474-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3693-3710},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Quadratic memory-augmented spatio-temporal transformer graph convolutional recurrent network for traffic forecasting},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CataLM: Empowering catalyst design through large language models. <em>IJMLC</em>, <em>16</em>(5), 3681-3691. (<a href='https://doi.org/10.1007/s13042-024-02473-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of catalysis holds paramount importance in shaping the trajectory of sustainable development, prompting intensive research efforts to leverage artificial intelligence (AI) in catalyst design. Presently, the fine-tuning of open-source large language models (LLMs) has yielded significant breakthroughs across various domains such as biology and healthcare. Drawing inspiration from these advancements, we introduce CataLM (Catalytic Language Model), a large language model tailored to the domain of electrocatalytic materials. Our findings demonstrate that CataLM exhibits remarkable potential for facilitating human-AI collaboration in catalyst knowledge exploration and design. To the best of our knowledge, CataLM stands as the pioneering LLM dedicated to the catalyst domain, offering novel avenues for catalyst discovery and development.},
  archive      = {J_IJMLC},
  author       = {Wang, Ludi and Chen, Xueqing and Du, Yi and Zhou, Yuanchun and Gao, Yang and Cui, Wenjuan},
  doi          = {10.1007/s13042-024-02473-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3681-3691},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {CataLM: Empowering catalyst design through large language models},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SDGNN: Structure-aware dual graph neural network for code summarization. <em>IJMLC</em>, <em>16</em>(5), 3663-3679. (<a href='https://doi.org/10.1007/s13042-024-02471-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code summarization aims to convert structured program code into comprehensible natural language descriptions, significantly benefiting software development. The existing approaches mainly employ structure-to-sequence frameworks designed for the Abstract Syntax Tree (AST) format of source code, extensively utilizing architectures such as Tree-based LSTMs, and Graph Neural Networks. From modeling process to encoding architecture can’t effectively learn some of the complex dependencies of the code snippets. In this paper, we propose a Structure-aware Dual Graph Neural Network (SDGNN) for code summarization. Specially, we employ both the grammatical dependency graph and the semantic dependency graph to catch the complex dependency of the program codes in SDGNN. To realize the effective learning of the dual graph, we further devise the hierarchical propagation and the graphical propagation to generate the encoding of the codes, as well as a graph alignment-based dual graph decoder to generate the summarizations from the encoding. Extensive experiments on three programming language datasets show that our framework outperforms state-of-the-art solutions.},
  archive      = {J_IJMLC},
  author       = {Hao, Zhifeng and Lin, Zonghao and Zhang, Shengqiang and Xu, Boyan and Cai, Ruichu},
  doi          = {10.1007/s13042-024-02471-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3663-3679},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {SDGNN: Structure-aware dual graph neural network for code summarization},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new supervised outlier detection method for hybrid data. <em>IJMLC</em>, <em>16</em>(5), 3629-3661. (<a href='https://doi.org/10.1007/s13042-024-02470-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection is an important research topic in data mining. The hybrid data contains numerical features, categorical features and missing information values at the same time, providing a variety of attribute descriptions, which can adapt to more practical application scenarios. However, the existing methods for outlier detection based on rough set theory rely predominantly on unlabeled data, and there are few studies focusing on hybrid data. This article investigates a supervised outlier detection for hybrid data based on conditional information entropy. First, the distance between information values in a hybrid information system (HIS) is introduced, and a variable parameter $$\lambda$$ controlling the distance is provided. Then, conditional information entropy in a HIS is defined to measure the uncertainty of this HIS, and three metrics are constructed to reflect the abnormal degree of each object. Next, an outlier factor based on conditional information entropy is comprehensively established, and a corresponding algorithm (is called CIEOD) is designed. Finally, CIEOD is applied to 18 UCI data sets and compared with other eight outlier detection algorithms. The parameter $$\lambda$$ in CIEOD is analyzed. To evaluate the performance of these algorithms, two criteria are used: AUC value and F1-measure. The experimental results indicate that the designed algorithm has better effectiveness and superiority.},
  archive      = {J_IJMLC},
  author       = {Feng, Danlu and Li, Zhaowen and Li, Jinjin},
  doi          = {10.1007/s13042-024-02470-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3629-3661},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A new supervised outlier detection method for hybrid data},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid-ctunet: A double complementation approach for 3D medical image segmentation. <em>IJMLC</em>, <em>16</em>(5), 3613-3628. (<a href='https://doi.org/10.1007/s13042-024-02469-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical segmentation is a fundamental problem in medical image computing, and it finds wide application in clinical domains such as medical diagnosis and robotic surgery. In this work, we investigate the distinct spatial characteristics of CNNs and Transformers in their representations of local and global features, while also analyzing the differences in preservation of spatial position within their network structures. They provide a comprehensive explanation of the complementarity between CNN and Transformer. To promote effective complementarity, we propose two novel architectures, namely CUNet and TUNet, which individually preserve the spatial characteristics throughout the overall U-Net process of the encoder and decoder. For feature complementation, we incorporate CUNet and TUNet as parallel branches, named CTUNet, which enhances the long-range dependencies of global information in both the deep and shallow locality. Moreover, we design the binary cross-weights for element-wise addition to achieve a more prominent fusion of features with diverse spatial characteristics. For further mask complementation, we construct a Hybrid-CTUNet by integrating the jointly training CTUNet and the independently training TUNet. Extensive empirical analysis conducted on medical datasets confirms the superiority of our proposed method compared to state-of-the-art models. The reproducing code is available at https://github.com/shouwangzhe134/Hybrid-CTUNet.git.},
  archive      = {J_IJMLC},
  author       = {Wang, Dong and Shang, Kun and Liang, Dong and Zhu, Yanjie},
  doi          = {10.1007/s13042-024-02469-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3613-3628},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Hybrid-ctunet: A double complementation approach for 3D medical image segmentation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMMP-net: Diffusion model-based missing part patching network for station air quality data generation completion. <em>IJMLC</em>, <em>16</em>(5), 3601-3612. (<a href='https://doi.org/10.1007/s13042-024-02468-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the missing part of environmental monitoring ground station data is of great significance for environmental monitoring and prediction. However, it is difficult for existing methods to solve the problem of dealing with temporal correlation of station data, spatial correlation, and correlation between pollutant concentration values in missing data completions. Therefore, this paper proposes a diffusion model-based missing part patching network for station air quality data generation completion(DMMP-Net). First, the diffusion model is used to learn the data distribution pattern, and the data with missing values are used as conditional inputs to generate new data without missing values to fill in the data with missing values for the purpose of data enhancement, so that the data can be subsequently applied to the tasks of analyzing the sources of pollution, exploring the components of pollution, and predicting the air quality. Second, we use the attention mechanism to improve the noise estimation network to enhance the feature extraction capability of site air quality data in three dimensions: time, space, and between the concentrations of various pollutants, and to improve the ability of DMMP-Net to learn the features of the data distributions in order to generate accurate complementary data. Experiments are conducted on the data from Beijing regional air quality monitoring stations to prove the effectiveness of DMMP-Net. Compared with the forward substitution method, the mean padding method and the K-nearest neighbor padding algorithm, the evaluation indices of MAE and MRE have better results. In the three cases of random missing, time-continuous missing and space-continuous missing, the evaluation indices of MAE reach 5.532, 10.849 and 12.641, respectively, and the evaluation indices of MRE reach 0.129, 0.243 and 0.342, respectively, and the generation of the replacement effect is better than that of the traditional missing-value filling model.},
  archive      = {J_IJMLC},
  author       = {Li, Zhenying and Li, Weidong and Zhang, Xuehai and Duan, Jinlong and Bai, Linyan},
  doi          = {10.1007/s13042-024-02468-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3601-3612},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {DMMP-net: Diffusion model-based missing part patching network for station air quality data generation completion},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semisupervised action recognition with adaptive correlation learning. <em>IJMLC</em>, <em>16</em>(5), 3587-3600. (<a href='https://doi.org/10.1007/s13042-024-02467-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a huge amount of video image data in the action recognition domain, and it is unreasonable to use expensive manual annotation. Traditional semi-supervised learning applies graph embedding and label propagation to mine local neighborhood relationships between labeled and unlabeled data. However, graph-based modeling methods have limited effectiveness for unstructured action videos. Recently, Graph Convolutional Networks (GCNs) have been used to exploit local neighborhood relationships of samples (action videos). However, existing GCNs methods struggle to extract discriminative high-level features from fixed graph, and suffer from excessive computational complexity when dealing with large-scale data. To address these issues, we propose a new GCN-based semisupervised method with adaptive feature correlation, which enhances local neighborhood by computing its correlation weights and learns global topology from labeled and unlabeled samples to obtain the optimal graph structures, effectively extracting high-level features. Furthermore, owing to the complexity caused by the inevitable redundant computations of GCNs, we apply linear transformations to the features of neighbor graph nodes, then aggregate adjacent nodes’ features for capturing the local neighborhood information. Thus, we mitigate this excess complexity by removing nonlinearity and collapsing weight matrices between consecutive layers, thereby addressing the issue of computational complexity. This linear model is simpler than traditional GCN models and offers superior generalization, robustness, and efficiency. The proposed approach achieves comparable performance on UCF101 using only 0.15 $$\times$$ N labeled training data. On HMDB51 and Something-Something V2, our method improves the recognition accuracy by +1.7% and +2% respectively, using only 0.20 $$\times$$ N labeled training data.},
  archive      = {J_IJMLC},
  author       = {Wang, Fan and Xu, Zengmin and Chen, Jiakun and Hu, Ruimin},
  doi          = {10.1007/s13042-024-02467-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3587-3600},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Semisupervised action recognition with adaptive correlation learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum wavefunction optimization algorithm: Application in solving traveling salesman problem. <em>IJMLC</em>, <em>16</em>(5), 3557-3585. (<a href='https://doi.org/10.1007/s13042-024-02466-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a new optimization algorithm based on the properties of quantum particles represented by their wavefunctions. This algorithm is called the “quantum wavefunction optimization algorithm (QWOA)”. We demonstrate the application of the QWOA to determine the optimal minimum distance for the traveling salesman problem (TSP). Specifically, we address the problem of traversing between cities in different countries using Google Maps, aiming to promote a real-time application of the proposed algorithm. To this end, we select cities from six different countries: Japan, India, Canada, China, Russia, and the United States of America. We use the QWOA to simulate and uncover the optimal shortest paths between these selected cities. The results of the QWOA are compared with those obtained using several well-known optimization algorithms, including the genetic algorithm (GA), simulated annealing (SA), particle swarm optimization (PSO), artificial bee colony (ABC), firefly algorithm (FA), and grey wolf optimizer (GWO). The experimental results, supported by statistical analysis, demonstrate the efficiency of the QWOA relative to these established optimization algorithms.},
  archive      = {J_IJMLC},
  author       = {Singh, Pritpal},
  doi          = {10.1007/s13042-024-02466-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3557-3585},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Quantum wavefunction optimization algorithm: Application in solving traveling salesman problem},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based intrusion detection system for in-vehicle networks with knowledge graph and statistical methods. <em>IJMLC</em>, <em>16</em>(5), 3539-3555. (<a href='https://doi.org/10.1007/s13042-024-02465-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-vehicle networks are increasingly vulnerable to sophisticated cyberattacks, posing significant threats to the safety and security of connected vehicles. Traditional intrusion detection systems (IDS) often fall short in effectively identifying both known and unknown attacks, especially within the complex and dynamic environment of in-vehicle communication systems like the Controller Area Network (CAN). Current IDS approaches struggle with detecting novel attacks, incorporating semantic features, and identifying anomalies in non-periodic messages, highlighting the need for more advanced and robust solutions. To address these challenges, this study introduces HDL-IDS, a hybrid deep learning-based IDS specifically designed for in-vehicle networks. HDL-IDS integrates knowledge graphs, statistical methods, and deep learning techniques—namely Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks—to extract relevant features from raw network data and accurately classify network traffic. By combining the strengths of CNNs and LSTMs, the system captures both spatial and temporal dependencies, while the integration of knowledge graphs enhances semantic analysis. Experimental evaluations demonstrate that HDL-IDS outperforms existing IDS solutions, achieving accuracy levels of up to 99% with a low false-positive rate. The system effectively addresses key research gaps by improving detection of both known and unknown attacks, seamlessly integrating semantic features, and accurately detecting anomalies in non-periodic messages. Although HDL-IDS shows significant promise in enhancing the security of in-vehicle networks, further research is needed to optimize its efficiency, explore transfer learning techniques for detecting unknown attacks, and evaluate its performance across a broader range of datasets. Despite these ongoing challenges, HDL-IDS represents a meaningful advancement in the pursuit of secure and safe connected vehicles.},
  archive      = {J_IJMLC},
  author       = {Alqahtani, Hamed and Kumar, Gulshan},
  doi          = {10.1007/s13042-024-02465-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3539-3555},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deep learning-based intrusion detection system for in-vehicle networks with knowledge graph and statistical methods},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-sensors image fusion method for non-destructive inspection in vertical-cavity surface-emitting lasers. <em>IJMLC</em>, <em>16</em>(5), 3521-3537. (<a href='https://doi.org/10.1007/s13042-024-02464-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection and analysis of defects in vertical cavity surface emitting lasers (VCSELs) have always been critical issues. However, most traditional methods for VCSELs quality inspection are destructive and require the use of both visible and infrared CCDs, which is inefficient and lacks intelligence. In this paper, we propose an innovative deep learning-based image fusion framework that utilizes electroluminescence technology to acquire infrared defect images. These images are then fused with visible defect images, enabling engineers to simultaneously detect surface defects and dark defects at the aperture of VCSELs. We introduce a GradCrossFusion module that effectively enhances the extraction of texture information from surface defects. To highlight the salient features of infrared images, we also design a loss function combination that enhances the perception of weak features in infrared images. Experimental results show that our method outperforms state-of-the-art fusion methods in terms of information entropy, standard deviation, mutual information, and fusion quality, indicating that our framework has great potential for application in the field of VCSELs defect analysis and detection.},
  archive      = {J_IJMLC},
  author       = {Zhang, Minfu and Zhao, Jumin and Guo, Shuai and Li, Dengao and Tang, Bao and Luo, Biao},
  doi          = {10.1007/s13042-024-02464-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3521-3537},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-sensors image fusion method for non-destructive inspection in vertical-cavity surface-emitting lasers},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new adaptive and effective granular ball generation method for classification. <em>IJMLC</em>, <em>16</em>(5), 3501-3520. (<a href='https://doi.org/10.1007/s13042-024-02463-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Granular ball computing is an effective, robust and scalable multi-granularity learning method, which consists of two phases: granular ball (GB) generation and GB-based learning. However, the majority of existing GB generation methods suffer from the limitations of being non-adaptive or generating GBs of inferior quality. Moreover, GB-based classification rule needs to be further optimized as it ignores the possible overlap between GBs. In this paper, a new adaptive and effective GB generation method based on the shortest heterogeneous distance (ADPGBG) is proposed. It can effectively improve the quality of GBs and the GB generation process is completely parameter-free. Subsequently, a corresponding outlier detection method is introduced to weaken the impact of noisy data during the GB generation process. Furthermore, an improved GB k-nearest neighbors classifier (IGBkNN) is developed based on the ADPGBG method, which refines the classification rule and addresses the issue that the queried samples are difficult to be classified correctly in the overlapping region between heterogeneous GBs by introducing the concept of density of the GB. Finally, to evaluate the performance of IGBkNN, extensive experiments are performed and the experimental results demonstrate the superiority of the proposed method compared to the mainstream GB generation methods for classification.},
  archive      = {J_IJMLC},
  author       = {Liao, Wei and Zhang, Qinghua and Xie, Qin and Gao, Man and Jin, Pengren},
  doi          = {10.1007/s13042-024-02463-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3501-3520},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A new adaptive and effective granular ball generation method for classification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing bankruptcy prediction: A study on an improved rime optimization algorithm and its application in feature selection. <em>IJMLC</em>, <em>16</em>(5), 3461-3499. (<a href='https://doi.org/10.1007/s13042-024-02462-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve bankruptcy prediction tasks, we proposed an improved rime optimization technique (RMRIME). The proposed RMRIME algorithm first employs roulette wheel selection step, introducing random individuals into the position updating process to expand the search space and boost the RMRIME’s exploration power. Also, a mutation idea is utilized, which uses info from elite agents to generate mutated individuals. This method aids in increasing population diversity and improving the algorithm’s convergence accuracy. To evaluate RMRIME, it was compared with nine advanced algorithms on the IEEE CEC 2017 benchmark functions. The experimental results show we could significantly improve overall accuracy, with better convergence on the benchmark functions. Finally, a fuzzy k-nearest neighbor-based feature selection, based on the RMRIME, is proposed to tackle the bankruptcy prediction. Experiments performed on three bankruptcy datasets versus the advanced algorithms. The results reveal that the proposed model could achieve an accuracy rate of 91.02%, 97.08% on the dataset, respectively.},
  archive      = {J_IJMLC},
  author       = {Ji, Yaoxian and Lu, Chenglang and Liu, Lei and Heidari, Ali Asghar and Wu, Chengwen and Chen, Huiling},
  doi          = {10.1007/s13042-024-02462-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3461-3499},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Advancing bankruptcy prediction: A study on an improved rime optimization algorithm and its application in feature selection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph contrastive learning with high-order feature interactions and adversarial wasserstein-distance-based alignment. <em>IJMLC</em>, <em>16</em>(5), 3449-3460. (<a href='https://doi.org/10.1007/s13042-024-02461-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning (GCL) has proven to be an effective approach for unsupervised representation learning on graph-structured data. However, existing GCL models face two major limitations. First, existing feature augmentation methods fail to capture the high-order interactions among raw features, which are essential for feature engineering. Second, effective strategies for extracting global information from graphs for contrastive learning remain limited. To address these limitations, we propose a novel GCL model with high-order feature interactions and adversarial Wasserstein-distance-based alignment. Our model employs DNNs to capture complex interactions among raw features and introduce an alignment-based loss function to effectively extract global graph information. While traditional methods for calculating Wasserstein distance between graph views are computationally intensive, we overcome this challenge by training an adversarial Wasserstein-distance discriminator that enables efficient distance computation. We conduct extensive experiments on five benchmark datasets to evaluate the performance of the proposed method. The experimental results demonstrate that our approach achieves superior performance on classification tasks.},
  archive      = {J_IJMLC},
  author       = {Wang, Chenxu and Wan, Zhizhong and Meng, Panpan and Wang, Shihao and Wang, Zhanggong},
  doi          = {10.1007/s13042-024-02461-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3449-3460},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Graph contrastive learning with high-order feature interactions and adversarial wasserstein-distance-based alignment},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing early attack detection: Novel hybrid density-based isolation forest for improved anomaly detection. <em>IJMLC</em>, <em>16</em>(5), 3429-3447. (<a href='https://doi.org/10.1007/s13042-024-02460-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the frequency and complexity of cyber threats have significantly increased, making it imperative to detect such anomalies in their early stages to minimize harm or data loss. Traditional anomaly detection approaches often prove inefficient in addressing modern, sophisticated threats. To mitigate information risks and negative outcomes, it is essential to detect attacks at an early phase. Many existing AD methods struggle to capture the intricate associations in data visualizations or effectively exploit contextual information for improved performance. In this paper, we propose a Hybrid Density-Based Isolation Forest with Coati Optimization (HDBIF-CO) algorithm for effective anomaly detection (AD) classification, using the NSL-KDD, CICIDS2017, and UNSW-NB15 datasets. The primary objective is to develop a more efficient and accurate method for detecting anomalies and potential cyberattacks in cybersecurity systems. The anomalies are detected through six key stages: the data collection phase, the data preprocessing phase (which involves data normalization and outlier elimination), feature selection, cluster discovery using Density-Based Spatial Clustering of Applications with Noise (DBSCAN), detection using the HDBIF-CO algorithm, and finally, the decision phase. The datasets used—NSL-KDD, CICIDS2017, and UNSW-NB15—contain both anomaly and normal data. During the preprocessing phase, duplicate data are eliminated, and features are extracted using a feature reduction technique to minimize data dimensionality. In the cluster formation phase, clusters are identified, and the HDBIF-CO algorithm is applied to segregate anomalies. The evaluation results demonstrated the reliability and effectiveness of the HDBIF-CO method, achieving 98.9% accuracy, 97.9% precision, 98.5% recall, and a 98.6% F1-score.},
  archive      = {J_IJMLC},
  author       = {Nalini, M. and Yamini, B. and Ambhika, C. and Siva Subramanian, R.},
  doi          = {10.1007/s13042-024-02460-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3429-3447},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhancing early attack detection: Novel hybrid density-based isolation forest for improved anomaly detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Faster and lighter surface defect detection model for transparent wine bottle. <em>IJMLC</em>, <em>16</em>(5), 3413-3428. (<a href='https://doi.org/10.1007/s13042-024-02459-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problems of low detection efficiency and high false detection rate due to the small defects on the surface labels of wine bottles and the similarity between patterns and defects, this paper proposes an improved YOLOv5s detection model for wine bottle surface defects. First, this paper introduces the lightweight C3 module and depthwise separable convolution, which greatly reduces the amount of parameters in the model; Secondly, the feature fusion structure of the neck network in the YOLOv5s model is designed, and the weighted bidirectional feature pyramid network is used to further promote the feature fusion of different scales through cross-level multi-scale connections; Finally, the optimized XIOU loss function is used to replace the loss function of the original model, and the detection accuracy of the lightweight model is improved. Experiments show that the model proposed in this paper, with the detection accuracy not weaker than that of the baseline model, reduces the number of parameters to 64.9% of the baseline model, and the mAP value of the model on the wine bottle surface defect dataset in the Tianchi industrial dataset is 79.7%. Compared with the original YOLOv5s and YOLOv7 models, the size of the original model is reduced to 62.6% and 12.7%, respectively, and the lightweight effect is remarkable.},
  archive      = {J_IJMLC},
  author       = {Lv, Zhongliang and Gu, Guojun and Xia, Kewen and Zhao, Zhiqiang and Liu, Kang and Yin, Lei and Xing, Luanfeng and Ying, Lei},
  doi          = {10.1007/s13042-024-02459-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3413-3428},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Faster and lighter surface defect detection model for transparent wine bottle},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Piecewise just-in-time data recovering and fault detection method for time-varying wind power generation process with missing data. <em>IJMLC</em>, <em>16</em>(5), 3399-3412. (<a href='https://doi.org/10.1007/s13042-024-02457-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The presence of missing values in the data poses challenges for fault detection tasks in wind power processes. The conventional data filling methods commonly focus on the process data with a single mode, disregarding the multimodal properties arising from time-varying characteristics in wind power processes. In this paper, to address the challenge of recovering data in time-varying and nonlinear wind power generation processes, a piecewise data recovering method with a just-in-time fault detection strategy is proposed. By utilizing the nonlinear matrix completion method to analyze data recovery ability, the process can be segmented into multiple modes, each exhibiting distinct characteristics. Then, using a just-in-time learning strategy, the missing value of the data can be accurately recovered in the corresponding mode in a short time. Finally, the kernel principal component analysis model is employed to monitor the process based on the recovered data. Compared with the existing methods, the proposed method considers the characteristics of nonlinear and high-rank or even full-rank matrix characteristics and recovers the missing data. In this way, it can achieve an accurate fault detection result for the wind power generation process with missing data. The effectiveness of the proposed method is validated on a real wind power generation process dataset.},
  archive      = {J_IJMLC},
  author       = {Chang, Junyu and Jing, Hua and Chen, Xu and Zhao, Chunhui},
  doi          = {10.1007/s13042-024-02457-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3399-3412},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Piecewise just-in-time data recovering and fault detection method for time-varying wind power generation process with missing data},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling tourists preferences through online reviews: An UPL-PT-MULTIMOORA-EDAS group decision method for wellness scenic spots selection. <em>IJMLC</em>, <em>16</em>(5), 3381-3398. (<a href='https://doi.org/10.1007/s13042-024-02456-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online reviews provide adequate information to aid scenic spots in measuring tourist preferences. Modelling tourist preferences from online reviews has become an increasingly relevant and a practical concern in tourism. However, the massive and ambiguous nature of online reviews increases the difficulty of decision-making, meanwhile, psychological behaviours of tourists have an extensive influence on the decision-making results. In light of these facts, this study proposes an UPL-PT-MULTIMOORA-EDAS method. On the one hand, it enables tourists fully utilize the valuable information of online reviews; on the other hand, integrating psychological preferences can depict the reality of decision-making. Specifically, after crawling the online reviews, latent dirichlet allocation (LDA) and self-organized learning (SOM) are used to mine key attributes and segment the tourists, respectively. Moreover, two novel methods have been proposed for calculating the weight of attributes, which are on the basis of the frequency and position, respectively. Subsequently, prospect theory (PT) is introduced into the decision-making framework to reflect the psychological behaviours of tourists in tourism selection. Finally, we illustrate our proposed method through an example of Chengdu-Chongqing economic circle wellness scenic spots selection, the robustness and effectiveness of the proposed method are substantiated through pertinent experimental investigations and comparative analyses.},
  archive      = {J_IJMLC},
  author       = {Li, Ruochen and Liu, Dun and Chen, Qinxia},
  doi          = {10.1007/s13042-024-02456-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3381-3398},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Modeling tourists preferences through online reviews: An UPL-PT-MULTIMOORA-EDAS group decision method for wellness scenic spots selection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KRAFS-ANet: A novel framework for EEG-based stress classification using channel selection and optimized ensemble stacking. <em>IJMLC</em>, <em>16</em>(5), 3359-3380. (<a href='https://doi.org/10.1007/s13042-024-02455-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mental stress poses a widespread societal challenge, impacting daily routines and contributing to severe health problems. The earlier studies have utilized Electroencephalograms (EEG) for stress classification; however, the computational demands of processing data from numerous channels often hinder the translation of these models to wearable devices. This paper proposes KRAFS-ANet, a novel framework designed for enhanced stress classification using EEG data on wearable devices. KRAFS-ANet framework incorporates two major novel components to achieve high accuracy with a lightweight design: (1) it strategically employs channel selection using Normal Mutual Information and Recursive Feature Elimination (NMI+RFE) to identify the most informative channels and (2) it uses ensemble stacking techniques integrate bagging K-Nearest Neighbour (KNN), bagging Random Forest (RF), and bagging Support Vector Machine (SVM) with an Artificial Neural Network (ANN) meta-classifier. The study conducts comprehensive experiments on the stress-based MAT dataset and further validates the framework on the stress-based SAM40 and anxiety-based DASPS datasets to demonstrate its effectiveness. KRAFS-ANet achieved the highest accuracies and F1-scores of 98.63% and 98.82% on the MAT dataset, 97.25% and 97.24% on the SAM40 dataset, and 94.92% and 95.15% on the DASPS dataset, respectively. This framework advances the practical application of EEG-based stress detection for portable devices such as wearables and smartphones. It enables real-time monitoring and interventions to enhance mental health in daily life, thus proving its efficacy in real-world scenarios.},
  archive      = {J_IJMLC},
  author       = {Shikha, Shikha and Sethia, Divyashikha and Indu, S.},
  doi          = {10.1007/s13042-024-02455-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3359-3380},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {KRAFS-ANet: A novel framework for EEG-based stress classification using channel selection and optimized ensemble stacking},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MCANet: A lightweight action recognition network with multidimensional convolution and attention. <em>IJMLC</em>, <em>16</em>(5), 3345-3358. (<a href='https://doi.org/10.1007/s13042-024-02454-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most lightweight networks used in action recognition tasks are based on convolutional neural networks (CNNs), which have spatial inductive biases that enable action recognition with fewer parameters and faster inference speed. While CNNs are highly effective at extracting local spatiotemporal features, they inherently lack the capability for global spatiotemporal modeling, which is the strength of vision transformers (ViTs). However, ViTs are characterized by a large number of parameters and relatively slower inference times, making them less suitable for lightweight applications. To meet the dual requirements of lightweight design and high recognition accuracy, this paper proposes MCANet, a novel action recognition network optimized for deployment on lightweight devices. MCANet integrates the strengths of both CNNs and ViTs, maintaining low model complexity and rapid inference speed while providing local and global spatiotemporal modeling capabilities. The efficacy of the proposed approach is validated through comprehensive evaluations of several benchmark datasets, including Kinetics400, UCF101, and HMDB51. In terms of accuracy, MCANet matches the performance of the best current action recognition model and shows a 3% improvement over other lightweight networks on Kinetics400. Regarding lightweight performance, MCANet improves inference speed by more than 17% compared to the current best lightweight model.},
  archive      = {J_IJMLC},
  author       = {Tian, Qiuhong and Miao, Weilun and Zhang, Lizao and Yang, Ziyu and Yu, Yang and Zhao, Yanying and Yao, Lan},
  doi          = {10.1007/s13042-024-02454-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3345-3358},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {MCANet: A lightweight action recognition network with multidimensional convolution and attention},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalability and performance evaluation of federated learning frameworks: A comparative analysis. <em>IJMLC</em>, <em>16</em>(5), 3329-3343. (<a href='https://doi.org/10.1007/s13042-024-02453-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a systematic examination and experimental comparison of the prominent Federated Learning (FL) frameworks FedML, Flower, Substra, and OpenFL. The frameworks are evaluated experimentally by implementing Federated Learning over a varying number of clients, emphasizing a thorough analysis of scalability and key performance metrics. The study assesses the impact of increasing client counts on total training time, loss and accuracy values, and CPU and RAM usage. Results indicate distinct performance characteristics among the frameworks, with Flower displaying an unusually high loss, FedML achieving a notably low accuracy range of 66–79%, and Substra demonstrating good resource efficiency, albeit with an exponential growth in total training time. Notably, OpenFL emerges as the most scalable platform, demonstrating consistent accuracy, loss, and training time across different client counts. OpenFL’s stable CPU and RAM underscore its reliability in real-world scenarios. This comprehensive analysis provides valuable insights into the relative performance of FL frameworks, offering good understanding of their capabilities and providing guidance for their effective deployment across diverse user bases.},
  archive      = {J_IJMLC},
  author       = {Soudan, Bassel and Abbas, Sohail and Kubba, Ahmed and Abu Waraga, Omnia and Abu Talib, Manar and Nasir, Qassim},
  doi          = {10.1007/s13042-024-02453-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3329-3343},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Scalability and performance evaluation of federated learning frameworks: A comparative analysis},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Etc-net: A space-adaptive swin transformer-based method for underwater image enhancement integrating edge sharpening and color correction. <em>IJMLC</em>, <em>16</em>(5), 3311-3327. (<a href='https://doi.org/10.1007/s13042-024-02452-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater optical images are important means of conveying information about underwater scenes, contributing significantly to underwater environmental monitoring, terrain surveying, and biological detection. However, the quality of underwater images is often compromised by the absorption and scattering effects of water on light, resulting in challenges such as low contrast, blurriness, and color shifts. Aiming at resolving these challenges, the present study introduces ETC-Net, an underwater image enhancement network utilizing an encoding-decoding architecture. The proposed approach includes an input-side edge information fusion module to enhance initial image informativeness, a spatially adaptive Swin Transformer module serving as a fundamental unit in both the encoder and decoder to mitigate blurriness and an output-side per-channel color correction module to address color shift phenomena. Experimental results on multiple datasets demonstrated the exceptional performance of ETC-Net in both reference and no-reference evaluation metrics, effectively improving the visual perception of underwater images. The code is published at https://github.com/lqjw81/ETC-Net .},
  archive      = {J_IJMLC},
  author       = {Zhou, Liqun and Tao, Yang and Huang, Hongcheng and Zhu, Yanyan},
  doi          = {10.1007/s13042-024-02452-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3311-3327},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Etc-net: A space-adaptive swin transformer-based method for underwater image enhancement integrating edge sharpening and color correction},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new case based reasoning diagnosis approach within a possibilistic framework. <em>IJMLC</em>, <em>16</em>(5), 3297-3310. (<a href='https://doi.org/10.1007/s13042-024-02450-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar exposure behavior has led to a significant increase in melanoma cancer cases in recent years. The mortality rates caused by this disease are the highest among dermatological cancers. This is due to the complexity of diagnosis, doctors use the Case Based Reasoning approach to leverage similarity with previously diagnosed cases. While the CBR approach can effectively address complex cases, its reliance on potentially irrelevant features can limit its accuracy and introduce diagnostic errors. In this study, we introduce a novel approach that integrates CBR within a possibility theory framework to assist experts in melanoma early detection. To address the issue of non-informative features, we introduce a possibilistic selection block within our approach. This block enables the CBR system to focus solely on relevant features, thereby enhancing its accuracy. In this approach, possibility theory is intended to address the problem of ambiguity and uncertainty affecting skin images. Then, the most relevant features are selected based on a possibilistic formalism and used as key features in the similarity measure within the CBR approach. Experimental validation on two sets of optical and dermoscopic lesion image datasets illustrates that our approach can be appropriate for lesion severity classification. It achieves a specificity of 100% and an accuracy of 95% on both databases, surpassing recent existing methods in melanoma diagnosis.},
  archive      = {J_IJMLC},
  author       = {Abbes, Wiem and Frikha Elleuch, Jihen and Sellami, Dorra},
  doi          = {10.1007/s13042-024-02450-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3297-3310},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A new case based reasoning diagnosis approach within a possibilistic framework},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review on handwritten text segmentation in indian languages. <em>IJMLC</em>, <em>16</em>(5), 3269-3295. (<a href='https://doi.org/10.1007/s13042-024-02448-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Word segmentation is a crucial phase for handwritten text recognition. When the input image contains several words written into multiple text lines, it is essential to separate or segment the images of individual words. Although several techniques have been proposed, handwritten text segmentation is still a popular research problem due to significant variations in handwriting styles and script-specific challenges. This paper systematically reviews the literature on handwritten text segmentation in Indian languages. The primary objective of the survey is to accumulate the techniques used for the segmentation of handwritten Indian documents. There, we found that a number of techniques, ranging from traditional image processing techniques to modern deep-learning models, have been used for segmentation from Indian handwritten documents. As there are a number of techniques, a comparative analysis of those techniques is necessary to understand their relative efficiency. Therefore, we implemented those techniques and tested their performance using a common dataset. For the comparison, we have taken handwritten images of three different languages Bengali, Hindi, and Tamil. In our experiments, we found that deep learning-based models often performed better than the non-learning-based techniques.},
  archive      = {J_IJMLC},
  author       = {Moitra, Moumita and Saha, Sujan Kumar},
  doi          = {10.1007/s13042-024-02448-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3269-3295},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A review on handwritten text segmentation in indian languages},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing multi-label disease diagnosis through hypergraph clustering and multi-classification label entropy. <em>IJMLC</em>, <em>16</em>(5), 3253-3268. (<a href='https://doi.org/10.1007/s13042-024-02447-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Syndrome differentiation is a crucial step in the diagnosis and treatment of Traditional Chinese Medicine (TCM). Ascertaining one or multiple disease types based on the patient’s symptoms falls within the research scope of multi-label learning. Previous studies have addressed this issue through problem transformation or algorithm adaptation, often neglecting the semantic connections between patient’s symptoms and specific disease labels. In this paper, we propose a novel multi-label disease diagnosis method that combines Hypergraph Clustering with multi-classification Label Entropy for Multi-Label Classification (HCLE-MLC) to tackle the problem of TCM syndrome differentiation. We construct a symptom hypergraph based on the connections between symptoms and disease labels, leveraging a clustering-optimized hypergraph attention network to obtain node representations that incorporate label information. This enables symptom nodes with similar properties to tend to cluster into the same group during clustering. Additionally, we develop a multi-class classifier to acquire cluster disease labels, determining the optimal number of clusters based on the output label entropy. Evaluation on two TCM datasets demonstrates that HCLE-MLC outperforms mainstream multi-label learning methods, and offers a degree of interpretability by clarifying the relationship between symptoms and specific disease labels.},
  archive      = {J_IJMLC},
  author       = {Jia, Wenyang and Yu, Jianhui and Liu, Yuxin and Liu, Yuliang},
  doi          = {10.1007/s13042-024-02447-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3253-3268},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhancing multi-label disease diagnosis through hypergraph clustering and multi-classification label entropy},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot event argument extraction by disentangling trigger from argument and role. <em>IJMLC</em>, <em>16</em>(5), 3233-3251. (<a href='https://doi.org/10.1007/s13042-024-02446-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event argument extraction (EAE) is an important task in information extraction. Traditional supervised methods are not easy to generalize to new event types. Most zero-shot EAE methods learned event-specific argument representation or event-specific role representation, which makes it difficult to generalize to new event types. We propose Distar, a zero-shot EAE method that disentangles the trigger from the argument and the role by modeling them using a knowledge graph embedding algorithm, i.e., TransE. We treat the argument as the head entity, the role as the relation, and the trigger as the tail entity. To enhance the generalization capacity, we construct two classifiers to relate the new role to the existing ontology. The experimental results show that our method can outperform the baseline by 8% on the ACE-2005 dataset. Our code is open-sourced at https://github.com/ZeroNLP/Distar for reproduction purposes.},
  archive      = {J_IJMLC},
  author       = {Lu, Zhengdong and Zeng, Ziqian and Wang, Jianwei and Wang, Hanlin and Lu, Weikai and Zhuang, Huiping},
  doi          = {10.1007/s13042-024-02446-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3233-3251},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Zero-shot event argument extraction by disentangling trigger from argument and role},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attribute selection methods based on graph theory in updated formal contexts. <em>IJMLC</em>, <em>16</em>(5), 3211-3232. (<a href='https://doi.org/10.1007/s13042-024-02445-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two types of attribute filtering methods for granular reduct of updated formal contexts are considered based on graph theory. In the first type of attribute filtering method, a covering matrix is defined for each attribute. The elements in this matrix are either 0 or 1 according to whether the attribute belongs to the granular discernibility set between two objects. It is proven that the sum of elements in the covering matrix is equal to the degree of the corresponding attribute. This precisely reflects the discernibility of this attribute. A DGRS algorithm for calculating the granular reduct is proposed based on the above principle. Subsequently, the changes in attribute degree are demonstrated when attributes or objects are added, meanwhile, the relationship between the granular reduct of the updated formal context and the original granular reduct is verified. Finally, the ODGRS and ADGRS algorithms are provided to filter out new granular reduct based on the original granular reduct when objects or attributes are added. In the second type of attribute filtering method, the columns corresponding to the attributes in the formal context are employed to study the attributes. The definition of edge label of attribute is provided, and it is verified that the degree of an attribute is equal to the number of elements in the edge label of the attribute. Subsequently, it is determined that the intersection of edge labels can be employed to ascertain whether two attributes are connected. Furthermore, the difference operation of edge labels can be utilized to remove the edges connected to the attribute with the highest degree. Finally, the DGRS, ODGRS and ADGRS algorithms are updated, and the effectiveness of the updated algorithms is verified through experiments.},
  archive      = {J_IJMLC},
  author       = {Li, Zhongling and Mi, Jusheng and Zhang, Tao and Bai, Yuzhang},
  doi          = {10.1007/s13042-024-02445-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3211-3232},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Attribute selection methods based on graph theory in updated formal contexts},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flexible anchor-based multi-view clustering with low-rank decomposition. <em>IJMLC</em>, <em>16</em>(5), 3193-3209. (<a href='https://doi.org/10.1007/s13042-024-02444-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering have attracted more attention recently due to their promising capabilities to reveal the underlying structure between data points. Nonetheless, most current methods endure high time computational complexity, that results in the inapplicability to medium and large-scale datasets. In addition, attributing to the existence of heterogeneous noise, it is tremendously arduous to study an effective low-dimensional subspace structure directly from the raw data points, leading to underperforming clustering results. To tackle these obstacles, we propose Flexible Anchor-based Multi-view Clustering with Low-rank Decomposition (FAMCL) method that combines the anchor learning with the learnable low-rank matrix factorization strategy. Specifically, the anchor point learning and anchor graph construction are fused into a joint optimization framework, which provides a solid foundation to boost the specific representations within different views. To delve deeper into the underlying structure, a low-rank decomposition strategy is applied, decomposing the anchor graph matrix into two components: an orthogonal matrix and a latent representation. Furthermore, an effective alternating direction iterative method with augmented Lagrangian multiplier is introduced to optimize our model. Extensive experiments on seven standard multi-view datasets demonstrate the advantages of FAMCL over other progressive methods.},
  archive      = {J_IJMLC},
  author       = {Zhang, Zheng and Huang, Yufang},
  doi          = {10.1007/s13042-024-02444-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3193-3209},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Flexible anchor-based multi-view clustering with low-rank decomposition},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning dynamic and multi-scale graph structure for traffic demand prediction. <em>IJMLC</em>, <em>16</em>(5), 3177-3191. (<a href='https://doi.org/10.1007/s13042-024-02442-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic demand prediction plays a crucial role in developing modern transport systems, as it can alleviate the dilemma of demand-and-supply imbalances in urban traffic. However, most existing traffic demand prediction works lack the ability to (1) efficiently capture the dynamic and multi-scale spatial dependency and (2) effectively utilize multi-scale and inter-multi-scale temporal features. To address these challenges, this paper develops a Dynamic and Multi-scale Graph Learning method, referred to as DMGL, for traffic demand prediction. In DMGL, a dynamic graph generator module is initially devised to construct different-scale dynamic graphs through temporal feature decomposition and aggregation. Next, a novel multi-scale temporal representation method is introduced that simultaneously captures both multi-scale and inter-multi-scale temporal dependencies. Lastly, a graph convolution module is leveraged to model dynamic and multi-scale spatial dependencies. To showcase the effectiveness of DMGL, we conduct experiments on two datasets, and the results of DMGL surpass the baselines.},
  archive      = {J_IJMLC},
  author       = {Peng, Lilan and Li, Chongshou and Zhang, Wuyang and Yu, Weijie and Li, Tianrui},
  doi          = {10.1007/s13042-024-02442-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3177-3191},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning dynamic and multi-scale graph structure for traffic demand prediction},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extended entropy method for risk inspection and effect analysis in optical cable industry. <em>IJMLC</em>, <em>16</em>(5), 3149-3175. (<a href='https://doi.org/10.1007/s13042-024-02441-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced manufacturing stands as an essential component of the fourth industrial era, where innovative machinery can sense and act autonomously in the production process to give higher and more convenient efficiency. However, there could be certain manufacturing-related possible failures. Identifying the possible failures and assessing their risk are essential. At the same time, global consensus has emerged on the need for assets and environmental defense. To ensure their continued sustainable growth, firms must take measures to mitigate the negative impacts of industrial production on the environment. Failure mode and effects analysis proficiently identifies failures and assesses their risks within a manufacturing process, design and system. Nevertheless, the ecological factors of the identified failure modes are frequently overlooked in failure mode and effects analysis techniques. Additionally, the risk priority number is typically used in conventional failure mode and effects analysis, which has numerous drawbacks in industrial sector, to determine the risk of failures. Considering the two previously mentioned primary issues, this research introduces an extended failure mode and effect analysis that addresses ambiguous information by using an entropy method & Combinative Distance based ASsesment method based on picture fuzzy rough number and adding environmental consequences as one of the risk variables. Firstly, an extended entropy method based on picture fuzzy rough number is utilized for the findings of risk factor’s weights then an extended Combinative Distance based ASsesment method based on picture fuzzy rough number is applied for the risk examination of possible failure modes. Consequently, the combination of the entropy method with the Combinative Distance-based Assessment method effectively manages uncertainty to a significant extent. An industrial case study of robotics optical cable sorting system is implemented to approve the usefulness of the recommended failure source and effect analysis. Upon meticulous implementation and comparison with others decision-making methodologies, this approach exhibits high reliability in providing perceptive conclusions. Sensitivity analysis is also used in the present research to improve the depth of our results.},
  archive      = {J_IJMLC},
  author       = {Akram, Muhammad and Nawaz, Mavera and Deveci, Muhammet},
  doi          = {10.1007/s13042-024-02441-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3149-3175},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Extended entropy method for risk inspection and effect analysis in optical cable industry},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decade’s overview of artificial intelligence in diagnosing: A scoping review. <em>IJMLC</em>, <em>16</em>(5), 3131-3148. (<a href='https://doi.org/10.1007/s13042-024-02440-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The impact of Artificial Intelligence (AI) in healthcare is undeniable, aiding physicians in diagnosing diseases. This study aims to synthesize the literature to examine the progress of AI in diagnosing Tuberculosis (TB), one of the deadliest diseases in the world. The review also provides a taxonomy for AI-based studies for TB diagnosis. A scoping review approach was adopted using the PRISMA-Scoping guidelines, focusing on types of studies, focus area, algorithms/models, and key results. Relevant articles published from 2013 to 2022 were sought using PubMed, Web of Science, and Scopus, resulting in 199 articles included in the review. The use of AI, especially deep learning, has increased since 2016, particularly for diagnosing TB using chest X-Rays (CXR). Most studies focused on diagnosing TB using CXR, Computed Tomography, biomarkers, sputum smear, and drug resistance and recovery. Convolutional Neural Networks (CNNs) and their variants were commonly used in deep learning, while Support Vector Machine (SVM), Decision Trees, and ensemble algorithms performed well in machine learning. CNN outperformed other variants for CXRs (accuracy from 80 to 100%) probably due to their ability to handle high-dimensional data and extract features. In contrast, simpler algorithms like Naive Bayes underperformed compared to other algorithms (accuracy range: 79–89%), showing their limitations in dealing with complex TB diagnostic data. The use of AI approaches, namely machine and deep learning are expected to increase in the future, hence promising a rapid and cost-effective (and potentially sustainable) alternative solution for efficient TB diagnosis.},
  archive      = {J_IJMLC},
  author       = {Balakrishnan, Vimala and Rustamov, Zahiriddin and Ramanathan, Ghayathri and Lim, Jia Leng},
  doi          = {10.1007/s13042-024-02440-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3131-3148},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A decade’s overview of artificial intelligence in diagnosing: A scoping review},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty-based bootstrapped optimization for offline reinforcement learning. <em>IJMLC</em>, <em>16</em>(5), 3113-3130. (<a href='https://doi.org/10.1007/s13042-024-02439-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning (offline RL) promises to learn effective policies from previously-collected, static datasets without offering further possibility for exploration. However, offline RL encounters significant challenges primarily due to algorithmic difficulties arising from function approximation errors caused by extrapolating from out-of-distribution (OOD) data points. In this work, we propose uncertainty-based bootstrapped optimization (UBO), which aims to address the distributional shift induced by the fixed datasets. First, we take advantage of the bootstrapped architecture to implicitly approximate the epistemic uncertainty for the training instances. Then, we apply both the implicit and explicit penalties to the OOD data with high prediction uncertainties. Finally, we introduce a training paradigm based on the upper confidence bound (UCB) strategy for the bootstrapping updates, which enables the algorithm to thoroughly assess the varying performance of each bootstrapped head. We compare UBO with other prevailing offline RL algorithms on D4RL benchmarks. Experiments on various tasks demonstrate that the proposed algorithm can outperform or be competitive with the previous state-of-the-art on most of the tasks.},
  archive      = {J_IJMLC},
  author       = {Li, Tianyi and Yang, Genke and Chu, Jian},
  doi          = {10.1007/s13042-024-02439-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3113-3130},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Uncertainty-based bootstrapped optimization for offline reinforcement learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bicrack: A bilateral network for real-time crack detection. <em>IJMLC</em>, <em>16</em>(5), 3097-3112. (<a href='https://doi.org/10.1007/s13042-024-02438-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crack detection is an important task to ensure structural safety. Traditional manual detection is extremely time-consuming and labor-intensive. However, existing deep learning-based methods also commonly suffer from low inference speed and continuous crack interruption. To solve the above problems, a novel bilateral crack detection network (BiCrack) is proposed for real-time crack detection tasks. Specifically, the network fuses two feature branches to achieve the best trade-off between accuracy and speed. A detail branch with a shallow convolutional layer is first designed. It preserves crack detail to the maximum and generates high-resolution features. Meanwhile, the semantic branch with fast-downsampling strategy is used to obtain enough high-level semantic information. Then, a simple pyramid pooling module (SPPM) is proposed to aggregate multi-scale context information with low computational cost. In addition, to enhance feature representation, an attention-based feature fusion module (FFM) is introduced, which uses space and channel attention to generate weights, and then fuses input fusion features with weights. To demonstrate the effectiveness of the proposed method, it was evaluated on 5 challenging datasets and compared with state-of-the-art crack detection methods. Extensive experiments show that BiCrack achieves the best performance in the crack detection task compared to other methods.},
  archive      = {J_IJMLC},
  author       = {Wang, Sailei and Lu, Rongsheng and Hu, Bingtao and Wan, Dahang and Fang, Mingtao},
  doi          = {10.1007/s13042-024-02438-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3097-3112},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Bicrack: A bilateral network for real-time crack detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-addressing and adaptive-intention-clustering based memory recall for pedestrian trajectory prediction. <em>IJMLC</em>, <em>16</em>(5), 3085-3096. (<a href='https://doi.org/10.1007/s13042-024-02437-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian trajectory prediction is widely applied in autonomous driving, service robots, surveillance systems, etc. The trajectory prediction method using the memory of the retrospective visible examples is more explanatory. But compressing instance information can cause feature loss, which will lead to poor prediction accuracy. Thus, the Attention-addressing and Adaptive-intention-clustering based Memory Recall (AAMR) for intention prediction is proposed in this paper. AAMR introduces a stable attention mechanism to assign weights when addressing similar instances in the attention addressor. It filters out input features that are excessively distant from the corresponding stored instances, thereby compensating for the feature loss caused by sample information compression. AAMR uses a training loss calculation method better suited to training conditions. Additionally, an adaptive-intention-clustering method is proposed to adjust and generate the final predicted intention from multiple addressed intentions. The prediction intention generated by AAMR combines relevant past trajectory information to complete trajectory prediction. AAMR improves ADE and FDE by 4.7 and 8.5% respectively from the previous best method on the ETH/UCY dataset. And ADE and FDE improve by 12.5 and 16.2% respectively on the UNIV dataset.},
  archive      = {J_IJMLC},
  author       = {Lu, Xu and Guo, Xuecai and Liu, Jun},
  doi          = {10.1007/s13042-024-02437-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3085-3096},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Attention-addressing and adaptive-intention-clustering based memory recall for pedestrian trajectory prediction},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage model fusion scheme based on knowledge distillation for stragglers in federated learning. <em>IJMLC</em>, <em>16</em>(5), 3067-3083. (<a href='https://doi.org/10.1007/s13042-024-02436-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning, as an emerging distributed learning paradigm, enables devices (also called clients) storing local data to collaboratively participate in a training task without the data leaving the devices, aiming to achieve the effect of integrating multiparty data while meeting privacy protection requirements. However, the participating clients are autonomous entities in a real-world environment, with heterogeneity and network instability, which leads to FL being plagued by stragglers when intermediate training results are synchronously interacted. To this end, this paper proposes a new FL scheme with a two-stage fusion process based on knowledge distillation, which transfers knowledge of straggler models to the global model without delaying the training speed, thus balancing efficiency and model performance. We have evaluated the proposed algorithm on three popular datasets. The experimental results show that FedTd improves training efficiency and maintains good model accuracy compared to baseline methods under heterogeneous conditions, exhibiting strong robustness against stragglers. By our approach, the running time can be accelerated by 1.97– $$3.32\times$$ under scenarios with higher level of data heterogeneity.},
  archive      = {J_IJMLC},
  author       = {Xu, Jiuyun and Li, Xiaowen and Zhu, Kongshang and Zhou, Liang and Zhao, Yingzhi},
  doi          = {10.1007/s13042-024-02436-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3067-3083},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Two-stage model fusion scheme based on knowledge distillation for stragglers in federated learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tfgcn: A time-varying fuzzy graph convolutional network for multi-sensor traffic flow forecasting. <em>IJMLC</em>, <em>16</em>(5), 3049-3066. (<a href='https://doi.org/10.1007/s13042-024-02435-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic prediction is a pivotal component of intelligent transportation systems (ITS), which can provide effective support for traffic planning and management. Recently, graph convolutional networks (GCNs) have been proposed to model intricate spatio-temporal correlations. However, most GCNs use static graphs, which fail to capture dynamic spatial correlations due to sensor damage. A few studies based on dynamic graph neural networks can model such dynamics but struggle to capture long-term spatio-temporal dependencies because they mainly focus on local and short-term changes in the graph. To overcome these limitations, we propose a time-varying fuzzy graph convolutional network called TFGCN that combines dynamic and static graphs to predict multi-sensor traffic flow. TFGCN uses a gated fuzzy graph to model long-term dynamic spatial correlations adaptively. It also employs a periodic coupled Transformer network that integrates monthly and weekly periodic data to capture global temporal trend information. Extensive experiments conducted on two real-world datasets demonstrate that our proposed model outperforms several state-of-the-art baselines.},
  archive      = {J_IJMLC},
  author       = {Wang, Rui and Zuo, Kaizhong and Zhang, Shaokun and Wang, Chen and Shen, Zhangyi and Hu, Peng and Li, Wenjie},
  doi          = {10.1007/s13042-024-02435-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3049-3066},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Tfgcn: A time-varying fuzzy graph convolutional network for multi-sensor traffic flow forecasting},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relational semantic-enhanced logic rule learning for knowledge graph completion. <em>IJMLC</em>, <em>16</em>(5), 3035-3048. (<a href='https://doi.org/10.1007/s13042-024-02434-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph completion (KGC) aims to automatically infer missing information in a knowledge graph (KG). Logical rule learning-based KGC has garnered significant attention due to its ability to provide logical reasoning and strong interpretability. In these models, the input paths are crucial for training the models to learn logical rules. However, topology-based methods like random walk path sampling often ignore the semantic information of relationships in the KG, which can lead to insufficient sampling, thereby affecting the quality of rules and the performance of KGC. To address this issue, we propose a path sampling method enhanced by relational semantics. First, building on random walk sampling, we prompt a large language model (LLM) to infer additional paths by understanding semantic logical connections between relationships in the KG. Second, to address unreasonable paths that may arise from potential hallucinations of the LLM, we propose a path filtering method based on a statistically analyzed relation set. Through this process, we obtain richer and more reasonable paths for logical rule learning, ultimately generating high-quality logical rules to improve the performance of KGC. Experimental results demonstrate that our model outperforms other baseline methods on three public datasets.},
  archive      = {J_IJMLC},
  author       = {Huang, Yuxin and Zhao, Zhiyong and Xiang, Yan},
  doi          = {10.1007/s13042-024-02434-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3035-3048},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Relational semantic-enhanced logic rule learning for knowledge graph completion},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AM-CFDN: Semi-supervised anomaly measure-based coal flow foreign object detection network. <em>IJMLC</em>, <em>16</em>(5), 3019-3034. (<a href='https://doi.org/10.1007/s13042-024-02433-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In underground coal mine transportation systems, conveyor belts are often affected by foreign objects such as gangue, steel wires, and wooden planks. Foreign objects not only potentially damage the equipment but also reduce the quality of the coal. Addressing the challenges of uneven underground lighting and low model detection accuracy in coal flow foreign object detection, this paper introduces the Anomaly Measure-based Coal Flow Detection Network (AM-CFDN). By introducing the Structural Similarity Index Measure-based Anomaly Evaluation Module (SAE), the AM-CFDN quantitatively assesses the anomaly degree of foreign objects in the coal flow by comparing the feature maps of input samples with selected template samples. Additionally, AM-CFDN employs a multi-task supervised training strategy, integrating both supervised and self-supervised loss functions, where the supervised losses include Cross-Entropy (CE) and mean squared error (L2) loss. The self-supervised loss utilizes Structural Similarity Index Measure (SSIM) loss. The detection performance of the model at both image and pixel levels is effectively enhanced by this approach. Experimental results on the Multi-Class Low-Resolution Foreign Objects in Coal Flow (LFOC) dataset, collected in a real underground coal mine environment, show that AM-CFDN achieves a detection speed of 30.30 frames per second (FPS), with an image-level AUROC of 0.952 and a pixel-level AUROC of 0.693. Compared to existing techniques such as PaDiM and DRAEM, AM-CFDN improves the image-level AUROC by 5.426% and 4.272%, respectively. These results demonstrate that AM-CFDN can effectively detect foreign objects in coal flow while maintaining suitable detection speed, making it suitable for practical coal flow foreign object detection scenarios and effectively ensuring the safety and efficiency of coal mine production.},
  archive      = {J_IJMLC},
  author       = {Li, Weidong and Yu, Yongbo and Wang, Chisheng and Zhang, Xuehai and Duan, Jinlong and Bai, Linyan},
  doi          = {10.1007/s13042-024-02433-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {3019-3034},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {AM-CFDN: Semi-supervised anomaly measure-based coal flow foreign object detection network},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance evaluations of large language models for customer service. <em>IJMLC</em>, <em>16</em>(5), 2997-3017. (<a href='https://doi.org/10.1007/s13042-024-02432-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in large language models (LLMs) show broad promise for a variety of natural language processing (NLP) tasks. There is growing interest in LLMs for domain-specific applications, such as in the telecommunications customer service domain. However, most of the benchmarks are for open-source LLMs, lacking effective exploration of real scenarios. To explore the performance of LLMs for customer service, we propose the first Telecommunications Customer Service Evaluation Benchmark (TeleEval-CS). In our work, we simulate the customer service pre-call, in-call, and post-call using 8.1k examples of 15 subtasks containing 21 datasets. We build 90k domain-specific multi-tasking instruction samples and fine-tune three types of LLMs including basic NLP, knowledge Q&A, and multi-round dialogue to realize industry knowledge injection. We conduct a comprehensive evaluation in multiple scenarios on 34 open-source, 5 closed-source, and 4 fine-tuned LLMs with zero-shot and few-shot approaches on TeleEval-CS. Experimental results show that the open-source LLMs can also perform better than the closed-source LLMs. The performance of the fine-tuned LLM depends on the quality of the fine-tuning dataset rather than its size, and fine-tuning has great potential in customer service scenarios. We provide our data and code at https://github.com/zsjslab/TeleEval-CS .},
  archive      = {J_IJMLC},
  author       = {Li, Fei and Wang, Yanyan and Xu, Yin and Wang, Shiling and Liang, Junli and Chen, Zhengyi and Liu, Wenrui and Feng, Qiangzhong and Duan, Ticheng and Huang, Youzhi and Song, Qi and Li, Xiangyang},
  doi          = {10.1007/s13042-024-02432-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {2997-3017},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Performance evaluations of large language models for customer service},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliable social media framework: Fake news detection using modified feature attention based CNN-BiLSTM. <em>IJMLC</em>, <em>16</em>(5), 2971-2996. (<a href='https://doi.org/10.1007/s13042-024-02431-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The social media platforms leads to proliferation of fake news and spreading of these false information creates high negative impact on the society. To overcome these consequences, it is essential to develop automatic detection of fake news in order to protect the environment. When compared with traditional Machine Learning (ML) techniques, Deep Learning (DL) algorithms showed an encouraging outcomes in Natural Language Processing (NLP). So, the proposed system implements Modified Feature Attention based Convolutional Neural Network-Bidirectional Long Short Term Memory (CNN-BiLSTM) approach for fake news classification. By using these datasets, the fake and real news are classified by using CNN-BiLSTM model along with attention mechanism. CNN already has good learninig skills, when combined with BILSTM, it gets really improved in efficiency and precision. Additionally, modified feature attention mechanism is involved, to concentrate and extract on specific information by using feature and correlation matrix. Further, the efficacy of the proposed model is identified by using performance metrics such as precision, recall, F1-score and accuracy. In order to predict the efficiency of the proposed system, it is compared with other conventional algorithms.},
  archive      = {J_IJMLC},
  author       = {Srikanth, D. and Krishna Prasad, K. and Kannan, M. and Kanchana, D.},
  doi          = {10.1007/s13042-024-02431-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {2971-2996},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Reliable social media framework: Fake news detection using modified feature attention based CNN-BiLSTM},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metric learning with multi-relational data. <em>IJMLC</em>, <em>16</em>(5), 2957-2969. (<a href='https://doi.org/10.1007/s13042-024-02430-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decades, there has been a growing interest in metric learning, a type of representation learning that aims to learn a distance metric that can fit to the data being analyzed. Many metric learning algorithms have been designed for data lying in Euclidean spaces, where a parametric Mahalanobis metric can be learned. However, such algorithms are often unable to handle relational data, that is not independent and identically distributed (i.i.d.), or can only be used at an entity level. In contrast, relational data allows for the discovery of complex interactions between features and entities, which can lead to better models. In this paper, we introduce two novel metric learning algorithms tailored to handle relational data, that preserve the structural information of the graph and use the features of the nodes as well. The first one is supervised and makes full use of both the graph structure and node labels with a carefully designed loss function, while the second is unsupervised and only uses the graph structure. Our experimental results show that both methods outperform state-of-the-art learning algorithms. Interestingly, we also find that the proposed unsupervised method often performs better than traditional supervised metric learning approaches.},
  archive      = {J_IJMLC},
  author       = {Pan, Jiajun and Le Capitaine, Hoel},
  doi          = {10.1007/s13042-024-02430-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {2957-2969},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Metric learning with multi-relational data},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DenseExudatesNet: A novel approach for hard exudates detection in retinal images using deep learning. <em>IJMLC</em>, <em>16</em>(5), 2939-2956. (<a href='https://doi.org/10.1007/s13042-024-02429-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic Retinopathy (DR) affects light sensitive layer that is a prominent reason for visual deterioration. If the patient with Hard Exudates (HE) is not identified promptly, serious irreversible blindness is developed. By employing a computer-aided technique to detect the HE in retinal images early on, an ophthalmologist is able to accurately diagnose the problem of blindness. Recently various HE detection approaches have developed although, they have poor accuracy and high complexity. This research presents a novel DenseExudatesNet model to detect the HE in retinal images to overcome the above challenges and establish an enhanced outcome in the HE detection process. In this research, the data are gathered from the Indian Diabetic Retinopathy Image Dataset (IDRID) and DIARETDB1-Standard Diabetic Retinopathy Database (SDRD). A Dilated Attention ResNet50 is applied for extracting the spatial features. Further, a Channel-Spatial Attention Module (CSAM) is employed to extract the features in the spatial and channel dimensions and the attention is weighted. For detecting the HE, this study applies a DenseExudateNet. This model utilizes an AdaptiveDenseNet (ADN) that enhances the feature reuse capability and mitigates the gradient disappearance issues. To manage the complexity of the model, this research employs an Efficient Channel Attention (ECA). The experimental validation expressed that the proposed DenseExudateNet model accurately and effectively detected the HE in retinal images and achieved a higher accuracy of 98.86% and lower False Alarm rate (FAR) of 0.009%. This research paper concludes that the proposed model achieved better outcomes in the detection of HE when compared to the existing research analyses.},
  archive      = {J_IJMLC},
  author       = {Pratheeba, C. and Rufus, N. Calvin Jeba},
  doi          = {10.1007/s13042-024-02429-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {2939-2956},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {DenseExudatesNet: A novel approach for hard exudates detection in retinal images using deep learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A three-way decision method with probability dominance relation in interval-valued hesitant fuzzy environment for marine steam turbine fault diagnosis. <em>IJMLC</em>, <em>16</em>(5), 2921-2938. (<a href='https://doi.org/10.1007/s13042-024-02428-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important measure to solve the multi-attribute decision-making (MADM) problems, the establishment of three-way decision (3WD) approach has been adopted not only stay at the theoretical level, but also applied to various practical problems. However, there exists a research gap of employing three-way decision (3WD) approach to enrich fault diagnosis based on interval-valued hesitant fuzzy environment (IVHF). To address these challenges, this paper proposes a neighborhood $$(\delta , \eta )$$ three-way decision (3WD) approach to solve fault diagnosis under the IVHF environment. First, the relative loss function (RLF) is considered as a wonderful substitution for the loss function, which usually serves as a conventional tool to consider the losses more comprehensively. Furthermore, an interval-valued hesitant fuzzy weight averaging operator is detected when creating the aggregated loss function. Moreover, a neighborhood $$(\delta , \eta )$$ probability dominance similarity relation is taken instead of the equivalence relation, which is regarded as an effective way to calculate the outranked class. Finally, the proposed method is verified by a marine turbine fault diagnosis case. Results of parameter analysis and comparison analysis show that the proposed approach can diagnose the fault of marine turbine rationality and stability.},
  archive      = {J_IJMLC},
  author       = {Zhan, Qiuyan and Xu, Zeshui and Jin, Lesheng},
  doi          = {10.1007/s13042-024-02428-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {2921-2938},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A three-way decision method with probability dominance relation in interval-valued hesitant fuzzy environment for marine steam turbine fault diagnosis},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Short-text topic modeling with dual reinforcement from internal and external semantics. <em>IJMLC</em>, <em>16</em>(5), 2905-2920. (<a href='https://doi.org/10.1007/s13042-024-02427-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the prevalence of short texts as a popular form of information on the Internet, inferring latent topics from short texts has attracted increasing interest from both academia and industry. To address the data sparsity of short texts in terms of word co-occurrences, existing research efforts either try to extract more information from the given data internally or leverage externally learned semantic information such as pre-trained word embeddings. In this paper, we propose a novel model, called Dual-Reinforced Topic Model (DRTM), to identify topics from short texts by harnessing both internal and external semantic information. Improving existing internal methods that consider only first-order co-occurrence relations between words, our model exploits multi-order relations so that the relevance between words not explicitly appearing together in the given data can be captured. Addressing the limitation of existing external methods that utilize only distributed representations at the word level, we further incorporate document representations into our model to facilitate topic modeling. We have evaluated our model on multiple publicly available datasets. Our experimental results have demonstrated that DRTM clearly outperforms existing internal and external methods in terms of both topic coherence and document classification accuracy.},
  archive      = {J_IJMLC},
  author       = {Wang, Jiamiao and Chen, Ling and Zhang, Zhiheng and He, Jin and Zhou, Xiangbing},
  doi          = {10.1007/s13042-024-02427-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {2905-2920},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Short-text topic modeling with dual reinforcement from internal and external semantics},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weakly supervised multi-label feature selection based on shared subspace. <em>IJMLC</em>, <em>16</em>(5), 2885-2903. (<a href='https://doi.org/10.1007/s13042-024-02426-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection (MLFS) improves classification accuracy and alleviates the curse of dimensionality by retaining relevant features and eliminating redundant and irrelevant features. However, the incompleteness of the label space not only makes the models difficult to learn the latent structure of the label space, but also leads to the unreliability of correlation between the labels and features. Therefore, it is essential and difficult how to discover the credible correlation information between the features and labels, so as to enable the effective selection of the key feature subset by the algorithms learning from multi-label data with missing labels. To more effectively excavate the implicit shared information within the feature matrix and the label matrix, we propose a novel MLFS method named WSMF which combines the feature matrix and the label matrix together to identify vital feature subsets in the absence of a large portion of labeled data. First, we utilize joint matrix factorization to uncover a low-dimensional shared mode between the feature matrix and the label matrix, thereby diminishing the effect of incomplete label information. Second, we employ non-negative matrix factorization (NMF) to enhance the interpretability of the succeeding feature selection process. Additionally, we employ the structural consistency assumption to retrieve the absent labels and incorporate $$l_{2,1}$$ -norm to control the feature redundancy and irrelevant features. In the end, we conduct experiments on 14 datasets to distinctly explain the effectiveness of WSMF against other established algorithms.},
  archive      = {J_IJMLC},
  author       = {Shi, Rongyi and Tan, Anhui and Shi, Suwei and Wang, Jin and Gu, Shenming and Wu, Weizhi},
  doi          = {10.1007/s13042-024-02426-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {2885-2903},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Weakly supervised multi-label feature selection based on shared subspace},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Granular-ball computing guided anomaly detection for hybrid attribute data. <em>IJMLC</em>, <em>16</em>(5), 2869-2884. (<a href='https://doi.org/10.1007/s13042-024-02425-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is one of the important research areas in data mining or data analytics. However, most of the existing anomaly detection methods only consider homogeneous data, such as nominal or numerical attribute data, and fail to effectively deal with hybrid attribute data.  Moreover, these methods also suffer from inefficiency and noise sensitivity due to their single-granularity sample-based input paradigm. In this study, we propose an unsupervised anomaly detection method based on the granular-ball fuzzy set called HGBAD. First, we define a novel granular-ball fuzzy set to deal with the uncertainty information in hybrid attribute data. Based on the novel fuzzy set, multiple granular-ball fuzzy information granules are constructed. The anomaly degrees of granular-ball fuzzy information granules are fused to calculate the anomaly factors. The anomaly factors are used to measure the anomaly degrees of samples. Based on the anomaly factors, anomalies can be detected by an anomaly determination threshold. Experimental results demonstrate the superior performance of HGBAD in detecting anomalies across various data types. The code is publicly available at https://github.com/Mxeron/HGBAD .},
  archive      = {J_IJMLC},
  author       = {Su, Xinyu and Wang, Xiwen and Peng, Dezhong and Chen, Hongmei and Chen, Yingke and Yuan, Zhong},
  doi          = {10.1007/s13042-024-02425-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {2869-2884},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Granular-ball computing guided anomaly detection for hybrid attribute data},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain-adaptive entity recognition: Unveiling the potential of CSER in cybersecurity and beyond. <em>IJMLC</em>, <em>16</em>(5), 2849-2867. (<a href='https://doi.org/10.1007/s13042-024-02424-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the dynamic fields of cybersecurity, precise recognition and identification of cybersecurity-related entities in textual data have become crucial. Existing studies on Named Entity Recognition (NER) in the cybersecurity domain often overlook challenges posed by data sparsity and the substantial presence of Out-of-Vocabulary (OOV) tokens in Cyber Treat Intelligence (CTI) reports. To tackle these challenges, we introduce the Cybersecurity Entity Recognition (CSER) model—a comprehensive approach crafted to handle CTI data complexities and similar intricacies across other domains. The CSER model integrates output from contextual, semantic, and morphological encoders to form a robust feature vector, capturing nuanced patterns, buzzwords, and structural attributes specific to cybersecurity entities. In particular, we employ various deep-learning approaches to capture morphological and contextual features, while pre-trained embeddings are utilized to capture semantic features. Additionally, Conditional Random Field (CRF) is employed as a sequential decoder, enhancing the effectiveness of cybersecurity entity identification. Extensive experiments on genuine cybersecurity datasets reveal that the proposed CSER model surpasses contemporary state-of-the-art methods, demonstrating superior predictive performance. To validate the effectiveness of this model, experiments are extended to datasets from biomedical and material science domains, providing comprehensive insights into the model’s adaptability across diverse domains. Our research demonstrates that the CSER model excels in domains with frequent OOV tokens, particularly cybersecurity, addressing data sparsity effectively. Its capability to manage a substantial volume of OOV tokens enhances performance where traditional models struggle.},
  archive      = {J_IJMLC},
  author       = {Marjan, Md. Abu and Amagasa, Toshiyuki},
  doi          = {10.1007/s13042-024-02424-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {6},
  number       = {5},
  pages        = {2849-2867},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Domain-adaptive entity recognition: Unveiling the potential of CSER in cybersecurity and beyond},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Os-elm based storage strategy for efficient query in blockchain database. <em>IJMLC</em>, <em>16</em>(4), 2835-2847. (<a href='https://doi.org/10.1007/s13042-024-02422-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain is widely used in supply chain systems due to its decentralization and security characteristics. However, with the outbreak of COVID-19, the supply chain systems need to have a more efficient query speed to meet the demand of origin-tracing. This paper proposes a hot block storage strategy to reduce the response time of data queries for blockchain-based supply chain systems. First, the architecture of the hot block storage strategy based on Online Sequential Extreme Learning Machine (OS-ELM) is designed, which includes the sharding-based blockchain module, the feature extraction module and the classifier module. Secondly, the fixed feature of the blocks, the node performance and other three features are considered to comprehensively evaluate the hot blocks for blockchain nodes. Third, the update algorithm for hot blocks is presented to ensure the persistence of efficient query. The experimental results show that the new strategy effectively improves the data query speed. Meanwhile, compared with the existing machine learning methods, the proposed OS-ELM-based strategy can significantly reduce the training time under the premise of ensuring the accuracy of classification when new training data is added. The OS-ELM-based storage strategy can achieve quick origin-tracing for blockchain-based supply chains and is suitable for the systems with rapidly increasing data.},
  archive      = {J_IJMLC},
  author       = {Jia, Dayu and Yang, Guanghong and Huang, Min and Xin, Junchang and Wang, Guoren},
  doi          = {10.1007/s13042-024-02422-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2835-2847},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Os-elm based storage strategy for efficient query in blockchain database},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable evaluation framework for facial expression recognition in web-based learning environments. <em>IJMLC</em>, <em>16</em>(4), 2801-2833. (<a href='https://doi.org/10.1007/s13042-024-02421-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The COVID-19 pandemic necessitated a shift towards remote learning, posing challenges for educators in assessing student impact. While deep learning offers solutions for face expression recognition (FER) in online education, existing evaluation methods often overlook the underlying decision-making processes. This research addresses this gap by proposing a robust, theory-driven, and case-oriented framework for preliminary FER model selection. It prioritizes accuracy, validity, and trustworthiness beyond traditional metrics by uncovering inherent biases and assessing algorithmic interpretability and generalization. A controlled experiment validates these criteria within the Design Science Research framework, facilitating further refinement of the evaluation tool. This novel approach prioritizes reliability and interpretability over mere predictive accuracy, filling a critical gap in existing FER systems. By integrating conformal prediction techniques, the framework enhances uncertainty quantification, allowing educators to understand the confidence levels associated with FER outputs. By advocating for transparency and clarity, it aligns with the evolving legal and societal emphasis on responsible AI development. This framework enables FER models to provide unbiased insights into students’ online learning experiences, encouraging ethical considerations in FER research. The findings serve as a valuable resource for researchers and developers, fostering trust and comprehension among educators in web-based learning environments.},
  archive      = {J_IJMLC},
  author       = {Mouakher, Amira and Kononov, Ruslan},
  doi          = {10.1007/s13042-024-02421-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2801-2833},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Explainable evaluation framework for facial expression recognition in web-based learning environments},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FADSiamNet: Feature affinity drift siamese network for RGB-T target tracking. <em>IJMLC</em>, <em>16</em>(4), 2779-2799. (<a href='https://doi.org/10.1007/s13042-024-02420-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant advancements have been announced in RGB-T tracking based on Siamese-based networks. However, several challenges persist in the majority of Siamese-based frameworks, including the inability to extract deep-level features, weak representation of target features, and the failure to fully exploit cross-modal information. To tackle these issues, a feature affinity drift Siamese network for RGB-T target tracking is proposed. First, the single-mode SiameseRPN++ tracking framework is extended to a multi-mode framework. Furthermore, the integration of ResNet50 as a feature extraction network enables the acquisition of deep-level target features. Subsequently, an affinity feature enhancement module (AFEM) is proposed to enhance the representation of target features by leveraging affinity, while simultaneously reducing noise in thermal infrared (TIR) images and reconstructing multimodal images through a cascade fusion strategy. Following that, a feature space drift module (FSDM) is designed to enhance the edge representation of the heat source target by segmenting the feature maps of the infrared modal branches and shifting them in four different directions. Finally, a multimodal feature-guided interactive learning module (MFIM) is put forward to leverage the discriminative information from one modality while guiding the learning process of target appearance features in the other modality. This module enhances the network’s attention towards foreground information by mining the cross-modal information within the feature space and channels. The validity of the proposed network is thoroughly verified through extensive experiments on three RGB-T datasets, with our method achieving a Precision Rate (PR) of 90.5 $$\%$$ and a Success Rate (SR) of 72.8 $$\%$$ on the GTOT dataset, 78.7 $$\%$$ PR and 56.8 $$\%$$ SR on the RGBT234 dataset, and 76.7 $$\%$$ PR and 53.6 $$\%$$ SR on the RGBT210 dataset. Additionally, the effectiveness of our proposed individual modules is confirmed by ablation experiments.},
  archive      = {J_IJMLC},
  author       = {Li, Haiyan and Cao, Yonghui and Guo, Lei and Chen, Quan and Ding, Zhaisheng and Xie, Shidong},
  doi          = {10.1007/s13042-024-02420-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2779-2799},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {FADSiamNet: Feature affinity drift siamese network for RGB-T target tracking},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sonar image segmentation using a multi-spatial information constraint fuzzy C-means clustering algorithm based on KL divergence. <em>IJMLC</em>, <em>16</em>(4), 2761-2778. (<a href='https://doi.org/10.1007/s13042-024-02419-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sonar image segmentation is an important task in the field of underwater detection, and the realization of accurate segmentation of targets and shadows is the key to subsequent image processing. However, due to the influence of various marine environments, the formation of sonar images is often accompanied by high scattering noise and intensity inhomogeneity. In order to solve the difficulties brought by the above reasons to sonar image segmentation, this paper proposes a multi-spatial information constrained fuzzy c-means clustering algorithm (MSCFCM). Firstly, we incorporate local spatial information into the MSCFCM through morphological reconstruction (MR), and construct the distance metric between the current pixel and its neighboring pixels by combining the mean value information of the image, removing a large amount of noise in the background; secondly, we use the difference in the normalized variance of the processed image and the original image as a weight to constrain the influence of the distance terms, and embed it adaptively into the fuzzy clustering algorithm; finally, the member information of the neighboring pixels is used as the prior information of the current pixel by using the Kullback–Leibler (KL) divergence, and the division of membership degree in each iteration can be optimized to further improve the segmentation performance. We test our method on sonar images and medical images, and the experimental results demonstrate that the algorithm exhibits strong segmentation performance and noise-immunity.},
  archive      = {J_IJMLC},
  author       = {Xu, Huipu and Li, Yongzhi and Zhang, Meixiang and Tong, Pengfei},
  doi          = {10.1007/s13042-024-02419-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2761-2778},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Sonar image segmentation using a multi-spatial information constraint fuzzy C-means clustering algorithm based on KL divergence},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning methods for LSTM-based personalized search: A comparative analysis. <em>IJMLC</em>, <em>16</em>(4), 2747-2759. (<a href='https://doi.org/10.1007/s13042-024-02418-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning techniques have become effective tools for addressing the difficulties associated with personalized search. Long Short-Term Memory (LSTM) models, one of the significant extended models of Recurrent Neural Networks (RNNs), are now widely used to re-rank search results. Thanks to LSTM, the neural network can handle large time-series data and have a memory function. By thoroughly comparing enhanced deep learning-based and especially LSTM-based models, we analyze the literature in the field of personalized search to rank the results in this survey. By focusing on the existence of popular methods, we evaluate the performance of the methods on two datasets in various settings to obtain the best results. The goal is to evaluate the effectiveness of each method and advance the state-of-the-art for deep learning LSTM-based personalized search. We hope to help researchers in choosing the most efficient deep learning algorithm for LSTM-based re-ranking in personalized search using this comparison.},
  archive      = {J_IJMLC},
  author       = {Abri, Sara and Abri, Rayan},
  doi          = {10.1007/s13042-024-02418-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2747-2759},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deep learning methods for LSTM-based personalized search: A comparative analysis},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TiDEFormer—a heterogenous stacking ensemble approach for time series forecasting of COVID-19 prevalence. <em>IJMLC</em>, <em>16</em>(4), 2721-2745. (<a href='https://doi.org/10.1007/s13042-024-02417-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting time series data over extended periods remains a formidable task in practical scenarios, such as the ongoing COVID-19 epidemic. The current variant of concern, JN.1, has increased transmissibility and reduced susceptibility to vaccinations in comparison to previous strains. As a result, there is an urgent requirement to forecast the daily incidence of COVID-19 in the near future. While deep learning models have demonstrated potential in predicting time series, they lack effectiveness in forecasting over long durations. This study seeks to fill the current gap by implementing a novel ensemble-based approach that incorporates two highly promising deep learning models: Time series Dense Encoder (TiDE) and Self attention-based Transformer model. The TiDEFormer, which combines TiDE and Transformer models using a heterogenous stacking ensemble technique, has exhibited greater accuracy in comparison to other proficient algorithms. The work employs the Blocked Time Series Cross validation technique to build distinct accurate models. In addition, the models are subjected to hyper-parameter tuning using the Grid Search Algorithm. The test results of TiDEFormer on the COVID-19 Dataset show a significant improvement in the Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) by around 22% and 17% respectively, compared to the TiDE model. The percentage improvement with respect to the Transformer model is approximately 9% and 6% respectively. Furthermore, an accurate prediction of the COVID-19 situation on daily basis is available for all countries, spanning a period of 200 days forecasting horizon covering approximately these months (From Dec 2023 to July 2024).},
  archive      = {J_IJMLC},
  author       = {Prakash, Satya and Jalal, Anand Singh and Pathak, Pooja},
  doi          = {10.1007/s13042-024-02417-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2721-2745},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {TiDEFormer—a heterogenous stacking ensemble approach for time series forecasting of COVID-19 prevalence},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online streaming feature selection for high-dimensional small-sample data. <em>IJMLC</em>, <em>16</em>(4), 2705-2719. (<a href='https://doi.org/10.1007/s13042-024-02416-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the domain of high-dimensional small-sample data classification tasks, there are several significant challenges. The feature space of samples typically has high dimensionality, and the features may be extracted sequentially. In addition, the distribution of data classes is imbalanced. To address these challenges, a novel online feature selection algorithm specifically designed for this scenario is presented in this paper. First, an adaptive neighborhood relation based on class density is proposed, which fully utilizes the distribution of the target sample’s class. Second, a neighborhood consistency metric is defined based on the proposed neighborhood relation. Moreover, the proposed online feature selection algorithm consists of three main phases: significance analysis, correlation analysis, and redundancy update. Comprehensive experimental studies on 12 datasets illustrate that our method significantly enhances the prediction of minority class samples, compared to several popular online streaming feature selection algorithms.},
  archive      = {J_IJMLC},
  author       = {Gong, Kuangfeng and Li, Guohe and Guo, Lingyun and Lin, Yaojin},
  doi          = {10.1007/s13042-024-02416-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2705-2719},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Online streaming feature selection for high-dimensional small-sample data},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel data credibility-centric multi-model-based complex systems modeling approach for UAV capability evaluation. <em>IJMLC</em>, <em>16</em>(4), 2687-2704. (<a href='https://doi.org/10.1007/s13042-024-02415-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex systems modeling has wide applications in theory and practice. A new approach is proposed by recognizing data credibility (DC) using multiple machine learning (ML) approaches, named DCML. There are two major components and theoretical contributions of the proposed approach: first, identifying less-credible data with a single ML approach, and second, cross-identifying these less-credible data with multiple ML approaches. A practical case of capability evaluation of the Unmanned Aerial Vehicle (UAV) is studied for validating the effectiveness of DCML. Case study results show that (1) The proposed DCML approach demonstrates a proficient ability to identify less credible data, (2) The validations with various ML methods prove effective, but the efficacy of the method is not necessarily proportional to the number of methods employed, (3) The combination of backpropagation neural network (BPNN) and gaussian process regression (GPR) yields the most favorable outcomes.},
  archive      = {J_IJMLC},
  author       = {Yu, Chen-Hao and Zhu, Jun-Yi and Chang, Lei-Lei and Cao, You and Xu, Xiao-Bin and Hao, Zhi-Yong},
  doi          = {10.1007/s13042-024-02415-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2687-2704},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel data credibility-centric multi-model-based complex systems modeling approach for UAV capability evaluation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Higher-order link prediction via light hypergraph neural network and hybrid aggregator. <em>IJMLC</em>, <em>16</em>(4), 2671-2685. (<a href='https://doi.org/10.1007/s13042-024-02414-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction, which aims to predict missing links or possible future links between two nodes, is one of the most important research in social network analysis. Higher-order link prediction, a natural extension of this problem in hypergraphs, focuses on predicting hyperlinks among multiple nodes. The extended problem has a wide range of applications, including predicting chemical reactions and forecasting social communications. Hypergraph neural networks (HGNNs), designed to address the characteristics of higher-order networks (hypergraphs), are variants of graph neural networks (GNNs). Compared with traditional methods, these end-to-end approaches based on HGNNs are effective tools for higher-order link prediction. However, these approaches still have some shortcomings. On the one hand, HGNNs, deriving from traditional GNNs, inevitably inherit unnecessary complexity and redundant computation from deep learning lineage. On the other hand, the existing aggregators do not take into account the similarity among the nodes’ features, resulting in information loss in the embeddings of hyperlinks. To solve the both shortcomings, firstly, we propose a Light HyperGraph Neural Network (LHGNN) by removing some specific linear feature transformation layers and activation function layers to reduce complexity and increase reliability. Secondly, we propose a Hybrid Aggregator (HA) to obtain hyperlinks’ embeddings more comprehensively by concatenating the mean and standard deviation of the nodes’ embeddings. Experimental results on six datasets from four different domains show that our method outperforms state-of-the-art methods with a simpler structure.},
  archive      = {J_IJMLC},
  author       = {Rui, Xiaobin and Zhuang, Jiaxin and Sun, Chengcheng and Wang, Zhixiao},
  doi          = {10.1007/s13042-024-02414-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2671-2685},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Higher-order link prediction via light hypergraph neural network and hybrid aggregator},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic networks link prediction based on continuous gated recurrent graph convolution. <em>IJMLC</em>, <em>16</em>(4), 2653-2669. (<a href='https://doi.org/10.1007/s13042-024-02413-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction, as a fundamental task in dynamic networks, holds great developmental significance. Dynamic networks contain rich spatiotemporal features which are crucial for this task. However, existing deep learning models for learning spatiotemporal information in dynamic networks have shown certain limitations. Notably, they often fail to fully leverage the attributes inherent in dynamic networks and overlook local fine-grained evolutionary features. To address these shortcomings, a dynamic network link prediction method based on Continuous Gated Recurrent Graph Convolution Network is proposed. The method constructs initial node features by combining common neighbor indices with link attributes to better capture the network’s inherent information. Specifically, we integrate Neural Ordinary Differential Equations to enhance the T-GCN model, creating a continuous gated recurrent graph convolution model that excels at capturing fine-grained evolutionary features. Then, a global evolution information extraction module is designed to learn the long and short-term spatiotemporal features comprehensively. Extensive experiments on real dynamic network datasets demonstrate that the proposed method outperforms existing baseline models.},
  archive      = {J_IJMLC},
  author       = {Liao, Yunchun and Shu, Jian and Liu, Linlan},
  doi          = {10.1007/s13042-024-02413-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2653-2669},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dynamic networks link prediction based on continuous gated recurrent graph convolution},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Link prediction for multi-layer and heterogeneous cyber-physical networks. <em>IJMLC</em>, <em>16</em>(4), 2635-2651. (<a href='https://doi.org/10.1007/s13042-024-02412-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-physical networks with tight interactions between the cyber and physical components have gained wide popularity in recent years with the development of cyberspace. Network embeddings, which can generate relatively low-dimensional vectors, are commonly used to reveal the missing or potential patterns in complex cyber-physical networks. Due to the characteristics of heterogeneity and multiple layers, traditional embedding techniques, which focus on the co-occurrence of nodes in homogeneous and single layer networks, fail to represent the similarity between nodes far apart from each other and with distinct attributes. In this paper, a generalized framework termed Info2vec for graph embedding representation is proposed to predict the missing links in cyber-physical networks, where some links are not observed due to the incompletion of data in the mapping of cyberspace. This framework aggregates the identities of heterogeneous nodes in multiple layers from multiple perspectives, including local structure, spatial nearness, and nodal attributes, based on which a context graph is then generated. Numerous sequences of nodes are sampled from the context graph and used as the input of a language model, which will generate embedding vectors used for link prediction. We demonstrate the effectiveness of this approach in the prediction of missing links in a realistic cyber-physical information network, where it significantly outperforms many well-known baselines.},
  archive      = {J_IJMLC},
  author       = {Yang, Guoli and Liu, Yi},
  doi          = {10.1007/s13042-024-02412-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2635-2651},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Link prediction for multi-layer and heterogeneous cyber-physical networks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). See through the noise: Revolutionizing medical image diagnosis with quadratic convolutional neural network (Q-CNN). <em>IJMLC</em>, <em>16</em>(4), 2615-2633. (<a href='https://doi.org/10.1007/s13042-024-02411-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel approach that utilizes quadratic convolutional neural networks (Q-CNN) to enhance the sensitivity of neural network models in analyzing noisy radiographs without the need for training on noisy images. The Q-CNN model is applied for COVID-19 classification in medical image diagnosis. In the presence of noise, the Q-CNN model exhibits superior performance compared to several benchmark models for COVID-19 diagnosis. The Q-CNN model effectively detects and classifies specific indicators, showcasing a unique advantage over existing models. Experimental evaluations conducted on chest radiographs with varying levels of noise demonstrate that the Q-CNN surpasses benchmark models in effectively handling noisy images while maintaining high classification accuracy. The visualization of features and the generation of heatmaps shed light on the essential role played by the non-linear expansion and cross-correlation mechanisms within the Q-CNN in overcoming limitations imposed by noise. Furthermore, a similarity analysis confirms the noise-resistance capabilities of the Q-CNN, providing further validation of its effectiveness in identifying and classifying indicators within noisy radiographs. This research significantly contributes to the field of medical diagnosis by presenting a reliable tool for the detection of specific indicators in noisy radiographic images, thereby enhancing accuracy and improving patient care.},
  archive      = {J_IJMLC},
  author       = {Song, Ki-Young and Tiong, Leslie Ching Ow and Lee, Yunli},
  doi          = {10.1007/s13042-024-02411-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2615-2633},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {See through the noise: Revolutionizing medical image diagnosis with quadratic convolutional neural network (Q-CNN)},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing semi-supervised medical image segmentation with bidirectional copy-paste and masked image reconstruction. <em>IJMLC</em>, <em>16</em>(4), 2603-2613. (<a href='https://doi.org/10.1007/s13042-024-02410-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To avoid the time-consuming and specialized task of medical image annotation, semi-supervised medical image segmentation methods encourage models to leverage large amounts of unlabeled data for training, which plays a crucial role in real-world medical scenarios. However, existing semi-supervised medical image segmentation methods often rely on data augmentation and pseudo-labeling techniques, overlooking the model’s perception of the relatively fixed structural information in medical images. Consequently, the segmentation results remain suboptimal. We propose integrating the Masked Autoencoders (MAE) method into the Bidirectional Copy-Paste (BCP) framework to address this challenge. Specifically, we randomly mask medical images and introduce an additional image reconstruction task in semi-supervised medical image segmentation to enhance the model encoder’s understanding and perception of image structures. We conducted experiments on the LA dataset and ACDC dataset. Experimental results show that our approach significantly outperforms state-of-the-art semi-supervised medical image segmentation methods, achieving notable improvements on various datasets (e.g., over 1.2 $$\%$$ Dice improvement on ACDC dataset).},
  archive      = {J_IJMLC},
  author       = {Yu, Xixuan and Ma, Qinghe and Ling, Tong and Zhu, Jiewen and Shi, Yinghuan},
  doi          = {10.1007/s13042-024-02410-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2603-2613},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhancing semi-supervised medical image segmentation with bidirectional copy-paste and masked image reconstruction},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving the selection of differential evolution through a quartile-based ranked operator. <em>IJMLC</em>, <em>16</em>(4), 2567-2602. (<a href='https://doi.org/10.1007/s13042-024-02409-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Differential Evolution (DE) algorithm is a well-founded and widely popular technique in the field of evolutionary computation. The standard DE algorithm is composed of four stages: initialization, mutation, crossover, and selection. The efficiency of its structure and operators have led to numerous modifications since its inception in 1995. However, the majority of these modifications have focused on the mutation and crossover stages. This paper presents an improved selection mechanism based on the classification of the population using quartiles. This preserves the classical structure of the DE while optimizing its effectiveness and efficiency. The proposed approach is designated as Quartile-based Ranked Differential Evolution (QRDE). It introduces a selection that categorizes the population into four groups to facilitate a comparison of the trial vector against a randomly selected individual from the worst group. Also, a scaling factor defines the exploration and exploitation of the QRDE from the selection part. To demonstrate the efficacy of the QRDE, its performance was evaluated on the set of benchmark functions from the CEC-2017 in 30 and 50 dimensions. The tests were conducted by comparing the QRDE against 9 state-of-the-art algorithms, including DE variants and recent optimization methodologies. The results of statistical tests indicate that the proposed QRDE is more computationally complex than the original DE. However, it outperforms the majority of algorithms in terms of stability and accuracy. Similarly, the QRDE was tested in 5 engineering problems, where the results demonstrate that the QRDE is highly competitive, outperforming other techniques in these domains.},
  archive      = {J_IJMLC},
  author       = {Haro, Eduardo H. and Oliva, Diego and Casas-Ordaz, Angel and Reyes-Davila, Elivier and Avalos, Omar},
  doi          = {10.1007/s13042-024-02409-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2567-2602},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Improving the selection of differential evolution through a quartile-based ranked operator},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency domain adaptive framework for visible-infrared person re-identification. <em>IJMLC</em>, <em>16</em>(4), 2553-2566. (<a href='https://doi.org/10.1007/s13042-024-02408-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The visible-infrared person re-identification task aims to achieve mutual retrieval between infrared images and visible images. The primary challenge is to learn the mapping of these two modalities into a common latent space. Prior works have mainly focused on network feature extraction, but have overlooked the local information of high-frequency channel features, the global information of low-frequency channel features, and the interaction effects between them, all of which are crucial for effectively aligning feature spaces and enhancing cross-modal recognition accuracy, robustness, and overall performance. To address this issue, we propose a frequency domain adaptive framework. Specifically, we designed the frequency domain adaptive encoder to achieve frequency domain adaptation. And the diverse wise embedding was designed to efficiently extract multi-scale features with fewer parameters. Additionally, we proposed the similarity distance clustering strategy, which reduces the large gaps between different modalities by minimizing the KL divergence between visible-infrared similarity distributions images and the normalized label clustering distributions. Our method has been proven superior on two public datasets and achieves state-of-the-art performance on the RegDB dataset.},
  archive      = {J_IJMLC},
  author       = {Wang, Jiangcheng and Li, Yize and Tao, Xuefeng and Kong, Jun},
  doi          = {10.1007/s13042-024-02408-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2553-2566},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Frequency domain adaptive framework for visible-infrared person re-identification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust humanoid robot vehicle ingress with a finite state machine integrated with deep reinforcement learning. <em>IJMLC</em>, <em>16</em>(4), 2537-2551. (<a href='https://doi.org/10.1007/s13042-024-02407-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ingress task is crucial in a humanoid robot’s attempt to drive a land vehicle and reach its destination fast. Previous work is inefficient in granting robots the ability to enter a vehicle from random starting positions and orientations or withstand elasticity in vehicles, which are both hard to model. Deep Reinforcement Learning (DRL) could be introduced to address these issues. Previous applications of DRL in humanoid control tend to use consistent reward terms for the whole control process, which is not suitable for the ingress task with many distinctive states. This letter proposes a novel Finite State Machine control method integrated with Deep Reinforcement Learning for the humanoid ingress task. It collects the robot’s status at the end of each state and immediately adjusts its next move. It has a 97% ingress success rate with random initial displacement and vehicle elasticity in simulation.},
  archive      = {J_IJMLC},
  author       = {Wang, Chenzheng and Chen, Xuechao and Yu, Zhangguo and Dong, Yue and Chen, Kehong and Gergondet, Pierre},
  doi          = {10.1007/s13042-024-02407-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2537-2551},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Robust humanoid robot vehicle ingress with a finite state machine integrated with deep reinforcement learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attribute reduction based on directional semi-neighborhood rough set. <em>IJMLC</em>, <em>16</em>(4), 2523-2535. (<a href='https://doi.org/10.1007/s13042-024-02406-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighborhood rough set has become a mature means of attribute reduction for simplifying modeling and knowledge discovery in continuous and mixed data. It principally generates the neighborhood by condition attribute subset that allows monitoring the local class distribution, thereby evaluating the attribute significance. However, traditional neighborhood formed as a circle with a radius may not inspect some special local distributions correctly, especially near the class boundary. To alleviate such a problem, we present a directional semi-neighborhood formulation approach and redefine the corresponding neighborhood rough set for attribute reduction. Essentially, we attempt to form the neighborhood as a semi-circle directing to the homogeneous samples, which enables to reduce the negative influence of heterogeneous samples. Then, a novel neighborhood rough set using the directional semi-neighborhood is induced. Our feature evaluation criterion, i.e., neighborhood approximation quality established by upper approximation may be more satisfactory in reduct searching. Experiments validated on fifteen public benchmark data sets suggest the superiority of our proposal as it is better at selecting more informative condition attributes for building classification models.},
  archive      = {J_IJMLC},
  author       = {Qian, Damo and Liu, Keyu and Wang, Jie and Zhang, Shiming and Yang, Xibei},
  doi          = {10.1007/s13042-024-02406-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2523-2535},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Attribute reduction based on directional semi-neighborhood rough set},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skin feature point tracking using deep feature encodings. <em>IJMLC</em>, <em>16</em>(4), 2503-2521. (<a href='https://doi.org/10.1007/s13042-024-02405-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial feature tracking is a key component of imaging ballistocardiography (BCG) where accurate quantification of the displacement of facial keypoints is needed for good heart rate estimation. Skin feature tracking enables video-based quantification of motor degradation in Parkinson’s disease. While traditional computer vision algorithms like Scale Invariant Feature Transform (SIFT), Speeded-Up Robust Features (SURF), and Lucas-Kanade method (LK) have been benchmarks due to their efficiency and accuracy, they often struggle with challenges like affine transformations and changes in illumination. In response, we propose a pipeline for feature tracking, that applies a convolutional stacked autoencoder to identify the most similar crop in an image to a reference crop containing the feature of interest. The autoencoder learns to represent image crops into deep feature encodings specific to the object category it is trained upon. We train the autoencoder on facial images and validate its ability to track skin features in general using manually labelled face and hand videos of small and large motion recorded in our lab. Our evaluation protocol is comprehensive, including quantification of errors in human annotation. The tracking errors of distinctive skin features (moles) are so small that we cannot exclude the fact that they stem from the manual labelling based on a $$\chi ^2$$ -test. With a mean error of 0.6–3.3 pixels, our method outperformed the other methods in all but one scenario. More importantly, our method was the only one that did not diverge. We also compare our method with the latest state-of-the-art transformer for feature matching by Google—Omnimotion. Our results indicate that our method is superior at tracking different skin features under large motion conditions and that it creates better feature descriptors for tracking, matching, and image registration compared to both traditional algorithms and the latest Omnimotion.},
  archive      = {J_IJMLC},
  author       = {Chang, Jose Ramon and Nordling, Torbjörn E. M.},
  doi          = {10.1007/s13042-024-02405-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2503-2521},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Skin feature point tracking using deep feature encodings},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An incomplete multi-view clustering approach using subspace alignment constraint. <em>IJMLC</em>, <em>16</em>(4), 2487-2502. (<a href='https://doi.org/10.1007/s13042-024-02403-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For partially missing multi-view data, existing incomplete multi-view clustering approaches suffer from the effects of misplaced neighbour relationships and changes in subspace structure caused by data incompleteness and imbalances in clustering information among views. In this paper, an incomplete multi-view clustering approach is proposed using subspace alignment constraints. Firstly, subspace alignment constraint is proposed among incomplete subspace representations to mitigate the misalignment-related changes in clustering structures. An adaptive weight is proposed to balance clustering information among views. Secondly, an incomplete multi-view clustering model is proposed by integrating subspace alignment constraint and inter-view adaptive representation, and a clustering algorithm is designed using an alternate minimizing optimization strategy. In the end, experimental results on benchmark datasets validate the algorithm’s excellent clustering performance for incomplete multi-view datasets.},
  archive      = {J_IJMLC},
  author       = {Niu, Xueying and Zhao, Xiaojie and Hu, Lihua and Zhang, Jifu},
  doi          = {10.1007/s13042-024-02403-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2487-2502},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An incomplete multi-view clustering approach using subspace alignment constraint},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A smoothing interval neural networks-based caputo fractional-order gradient learning algorithm. <em>IJMLC</em>, <em>16</em>(4), 2469-2485. (<a href='https://doi.org/10.1007/s13042-024-02402-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smoothing interval neural networks (SINNs) are widely recognized for their effectiveness in handling uncertain data across various domains. However, training SINNs using the integer-order gradient method usually leads to lower computational accuracy and instability during parameter updating, which adversely affects the convergence and accuracy of the model. Fractional-order derivatives, in contrast, offer superior non-local memory properties and broader data fitting capabilities, providing more accurate descriptions of complex system dynamics. Therefore, this paper introduces a fractional-order gradient descent (FGD) method that utilizes Caputo fractional-order derivatives to train SINNs. Theoretical validation of the FGD method is achieved by rigorously proving the monotonicity of the error function and the strong convergence theorem of the algorithm. Additionally, various simulations are conducted to assess the enhanced algorithm’s performance on different approximation functions and classification datasets. The experimental results demonstrate that the FGD method significantly accelerates the convergence rate, enhances generalization ability, and improves the overall performance of SINNs.},
  archive      = {J_IJMLC},
  author       = {Shao, Qiang and Liu, Yuanquan and Wang, Rui and Liu, Yan},
  doi          = {10.1007/s13042-024-02402-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2469-2485},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A smoothing interval neural networks-based caputo fractional-order gradient learning algorithm},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging LSTM and GRU-based deep neural coordination in intelligent transportation to strengthen security in the internet of vehicles. <em>IJMLC</em>, <em>16</em>(4), 2431-2467. (<a href='https://doi.org/10.1007/s13042-024-02401-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concerns about security and safety are escalating as additional smart cars become part of the Internet of Vehicles (IoV) and link up to the Internet via Internet of Things (IoT) applications. The rising amount of connected vehicles brings about intricate cybersecurity issues, such as unauthorized entry, data breaches, and potential vehicle misuse. Although research has delved into utilizing Machine Learning (ML) techniques for Intrusion Detection (ID) in IoT networks to avoid vehicle accidents and cyberattacks, there are still major hurdles in accurately detecting unauthorized access and attaining real-time effectiveness. This study tackles these obstacles by suggesting a new Intrusion Detection System (IDS) for the Internet of Vehicles (IoV), utilizing the collective capabilities of Deep Learning (DL). This research addresses existing shortcomings by employing GRU and LSTM models to capture short- and long-term dependencies in attack patterns, improving system detection accuracy and responsiveness. In addition, we present a secure key exchange technique for the IoT network using Artificial Neural Networks (ANNs) to enable mutual learning and enhance key distribution among connected devices, ensuring a strong defense against unauthorized access and data breaches. The proposed strategy’s effectiveness is proven by intense training and testing of DL models on various datasets like CSE-CIC-IDS 2018, CI-CIDS 2017, CIC DoS, and a specialized vehicle exploitation dataset, ensuring generalizability and robustness. The tests demonstrate that the IDS has exceptional precision, detecting 99.9% of network attacks and 95.9% of car hacks. Additional evaluation using recall, F1-score, and accuracy measures affirms the efficiency and trustworthiness of the suggested approach. This study enhances IoT security with a novel ANN-based key exchange method and proposes a comprehensive IDS system for IoV using advanced DL methods. The proposed research makes significant progress in network security and intrusion detection accuracy, greatly improving the safety and security of smart cars and the Internet of Vehicles ecosystem, leading to a safer and more secure future in intelligent transportation systems.},
  archive      = {J_IJMLC},
  author       = {Yanmin, Cai and Sarkar, Arindam and Zain, Jasni Mohamad and Bhar, Arindam and Noorwali, Abdulfattah and Othman, Kamal M.},
  doi          = {10.1007/s13042-024-02401-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2431-2467},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Leveraging LSTM and GRU-based deep neural coordination in intelligent transportation to strengthen security in the internet of vehicles},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Off-policy asymptotic and adaptive maximum entropy deep reinforcement learning. <em>IJMLC</em>, <em>16</em>(4), 2417-2429. (<a href='https://doi.org/10.1007/s13042-024-02399-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximum entropy deep reinforcement learning has shown great promise in tackling various challenging continuous tasks. By incorporating the maximum entropy framework, the goal is to introduce more randomness in action selection and improve the training process. However, there exists a tradeoff between efficiency and stability, especially when dealing with large-scale tasks with high state and action dimensions. In certain situations, it becomes necessary to constrain the temperature hyperparameter of the maximum entropy term to prevent instability, which can hinder convergence. In this study, we propose an algorithm that combines adaptive and asymptotic maximum entropy with actor-critic random policies. ”asymptotic” means the entropy term tends to be stabilized as the learning proceeds. Specifically, we introduce a state-dependent adaptive temperature to accelerate the training process and include an additional term involving asymptotic maximum entropy to ensure stable convergence. These components are combined with the selected critic value to serve as the target Q-value and the surrogate objective in the policy evaluation and improvement steps. The adaptive and asymptotic maximum entropy algorithm demonstrates robust adaptation to the efficiency-stability tradeoff, providing increased exploration and flexibility to address saddle point problems. We evaluate our method on various Gym tasks, and the results indicate that our proposed algorithms outperform several baselines in the domain of continuous control.},
  archive      = {J_IJMLC},
  author       = {Zhang, Huihui and Han, Xu},
  doi          = {10.1007/s13042-024-02399-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2417-2429},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Off-policy asymptotic and adaptive maximum entropy deep reinforcement learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained multimodal named entity recognition with heterogeneous image-text similarity graphs. <em>IJMLC</em>, <em>16</em>(4), 2401-2415. (<a href='https://doi.org/10.1007/s13042-024-02398-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Named Entity Recognition (MNER) leverages semantic information from multiple modalities to enhance the identification and classification of named entities in text. Effective MNER requires a thorough understanding of the intricate semantic correlations across different modalities. However, existing MNER methods often overlook fine-grained correlation information between textual and visual modalities, resulting in a loss of crucial semantic details for accurate entity recognition. We propose a novel Similarity Multimodal Reinforcement Graph (SMRG) framework for MNER to address this issue. SMRG quantifies the relevance between words and grid-level image regions to establish a nuanced heterogeneous image-text similarity graph. By leveraging the feature propagation capabilities of graph convolutional networks, SMRG captures rich semantic relationships across modalities. Moreover, SMRG employs gated aggregation modules to selectively integrate visual semantics with corresponding textual representations, thereby enhancing the expressiveness of text features for MNER. Extensive experiments on two benchmark Twitter datasets demonstrate the superiority of SMRG over state-of-the-art methods in self-domain and cross-domain scenarios.},
  archive      = {J_IJMLC},
  author       = {Wang, YongPeng and Jiang, ChunMao},
  doi          = {10.1007/s13042-024-02398-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2401-2415},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fine-grained multimodal named entity recognition with heterogeneous image-text similarity graphs},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adam energy valley optimization-based routing and RF-spinalnet enabled medical data classification in IoT. <em>IJMLC</em>, <em>16</em>(4), 2377-2399. (<a href='https://doi.org/10.1007/s13042-024-02397-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The progress in big data, especially in Internet of Things (IoT) based healthcare and biomedical categories, attempts to help patients by detecting diseases early by analyzing the medical data. However, the effectiveness of the existing medical data classification schemes needs improvement. Here, a Recurrent Fusion SpinalNet (RF-Spinalnet) is introduced for better classification of medical data in IoT. Initially, IoT is simulated, then, nodes collect the patient’s data, and later, routing is carried out to acquire the medical data at the Base Station (BS) for classification. Here, the routing is done by devised Adam Energy Valley Optimization (AEVO). Afterwards, at BS, input data is subjected to a pre-processing step to remove redundant data using linear normalization. Once the process is completed, feature fusion is done by a Chebyshev distance measure and a Deep Neural Network (DNN). Thereafter, data augmentation is carried out, and finally, classification of medical data is performed using RF-Spinalnet, which is the combination of Deep Recurrent Neural Network (DRNN) and SpinalNet. The efficiency of RF-Spinalnet is evaluated using the COVID-19 Machine Learning Dataset and Covid-19 disease on the Korean dataset based on accuracy, sensitivity, and specificity by Python tool. The RF-Spinalnet demonstrated an accuracy of 91.91%, a sensitivity of 91.89%, and a specificity of 91.45% and the AEVO-routing achieved energy of 0.005 J, distance of 38.516 m, and delay of 0.668 ms.},
  archive      = {J_IJMLC},
  author       = {Purbey, Suniti and Khan, Nariman and Singh, Brijendra Krishna and Balan, Santhosh Kumar},
  doi          = {10.1007/s13042-024-02397-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2377-2399},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adam energy valley optimization-based routing and RF-spinalnet enabled medical data classification in IoT},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SGSM: Semi-generalist sensing model combining handcrafted and deep learning methods. <em>IJMLC</em>, <em>16</em>(4), 2361-2376. (<a href='https://doi.org/10.1007/s13042-024-02396-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significance of intelligent sensing systems is growing in the realm of smart services. These systems extract relevant signal features and generate informative representations for particular tasks. However, building the feature extraction component for such systems requires extensive domain-specific expertise or data. Handcrafted methods focus on general data features rather than specific task characteristics, hence the need for human expertise. Deep learning models place greater emphasis on task-specific labels rather than the underlying data characteristics, necessitating a substantial amount of annotated data. Therefore, it is advantageous to combine the strengths of both approaches by integrating the data handling expertise of existing signal processing methods with the task depicting capabilities of deep learning models. In this paper, we propose SGSM, the first work to link handcrafted and deep learning approaches in the field of sensing. SGSM provides a semi-automated intelligent sensing scheme, which can adaptively and quickly guide the design of particular sensing systems for various given tasks across different sensors. Experimental results on three heterogeneous sensors (acoustic, inertial measurement unit, and Wi-Fi) illustrate that SGSM functions across a wide range of scenarios, thereby establishing its broad applicability. In some cases, SGSM even achieves better performance than sensor-specific specialized solutions.},
  archive      = {J_IJMLC},
  author       = {Yang, Tianjian and Zhou, Hao and Liu, Shuo and Guo, Kaiwen and Hou, Yiwen and Du, Haohua and Li, Xiang-Yang},
  doi          = {10.1007/s13042-024-02396-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2361-2376},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {SGSM: Semi-generalist sensing model combining handcrafted and deep learning methods},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decision making based on AND-logical quantification of uncertainty in pairwise comparisons. <em>IJMLC</em>, <em>16</em>(4), 2335-2359. (<a href='https://doi.org/10.1007/s13042-024-02395-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When pairwisely comparing alternatives of a decision making problem, the decision maker (DM) could provide some discrete values to express her/his opinions. The existing uncertainty in pairwise comparisons should be quantified for establishing a decision making model with applications. In this paper, we propose a novel multi-criteria decision making (MCDM) model called AND-logical analytic hierarchy process (AND-AHP). The AND logic is used to quantify uncertainty such that the preference information of the DM is expressed as an AND-logical number. The concept of AND pairwise comparison matrix (AND-PCM) is developed and used as the mathematical tool of the proposed MCDM model. The consistency of AND-PCM is defined and acceptable consistency is discussed. The priority vector is elicited from an AND-PCM by proposing an AND-weighting (AND-W) model. The observation reveals that the proposed model provides an alternative way to effectively investigate MCDM problems with discrete comparisons of alternatives.},
  archive      = {J_IJMLC},
  author       = {Chen, Ya-Ru and Liu, Fang and Mo, Ji-Ting},
  doi          = {10.1007/s13042-024-02395-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2335-2359},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Decision making based on AND-logical quantification of uncertainty in pairwise comparisons},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved D3QN with graph augmentation for enhanced multi-UAV cooperative path planning in urban environments. <em>IJMLC</em>, <em>16</em>(4), 2315-2333. (<a href='https://doi.org/10.1007/s13042-024-02393-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning of multi-unmanned aerial vehicles (multi-UAVs) in complex urban environments is a challenging task, which suffers from low autonomous decision-making capability and execution efficiency. Traditional methods are struggling to cope with the increasing task demands. Deep reinforcement learning (DRL) offers a more flexible and efficient solution for path planning through offline training and online reasoning, which is expected to better adapt to the complexity of urban environments. Thus, a multi-UAV path planning method based on improved Dueling Double DQN (D3QN) and graph augmentation techniques is proposed in this paper, which effectively addresses the collaborative path planning problem in multi-UAV systems by combining DRL and Graph Neural Networks (GNN). In the proposed method, the D3QN algorithm is adopted to enhance the interaction between UAVs and the environment using a Graph Convolutional Network (GCN) communication model based on historical trajectory information. Furthermore, a task-driven dynamic priority adjustment mechanism is proposed to balance the relationship between UAV paths and energy consumption. Meanwhile, a dynamic incentive adjustment mechanism combining complex real-time environment information and UAV states is proposed to enhance the performance and adaptability of the path planning algorithm. Simulation experiments were conducted to validate the algorithm and compare it with the general DRL methods such as DQN and D3QN, and the results demonstrate the effectiveness and superiority of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Zhao, Yonghao and Ni, Jianjun and Tang, Guangyi and Gu, Yang and Yang, Simon X.},
  doi          = {10.1007/s13042-024-02393-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2315-2333},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Improved D3QN with graph augmentation for enhanced multi-UAV cooperative path planning in urban environments},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GNNRI: Detecting anomalous social network users through heterogeneous information networks and user relevance exploration. <em>IJMLC</em>, <em>16</em>(4), 2297-2314. (<a href='https://doi.org/10.1007/s13042-024-02392-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting anomalous users in social networks is an imperative but challenging task. The increasing complexity of inter-personal behaviors and interactions further complicates the development of effective user anomaly detection techniques. Current state-of-the-art methods heavily rely on static personal features, making it difficult to quantify the hidden relevance of user behaviors through traditional feature engineering. This loss of accuracy is exacerbated by the rise of sophisticated camouflage and disguising techniques, which blur the distinction between anomalous and regular users. In this paper, we present GNNRI, an innovative framework for detecting anomalous users in social networks. Our approach leverages a network representation learning model and a heterogeneous information network (Hin) to explore hidden semantic connections from user metadata, tweets, and interaction information. We extract both user metadata and behavioral features to construct a Hin and introduce two distinct learning layers to explore explicit and implicit user relevance. First, we employ a relation-based self-attention layer to aggregate neighbor node closeness under specific relations and across different relationships. Subsequently, we apply graph convolution network-based convolutional learning layers, which enhance embedding effectiveness by capturing graph-wide node similarity. We evaluate GNNRI using real-world datasets, and our results demonstrate that it outperforms all other comparative baselines, achieving approximately 90% accuracy for user classification, with a 5–15% improvement over other GNN variants. Notably, even when using only 20% of the data for training, GNNRI achieves 87.8%, 86.57%, and 87.1% accuracy for detecting zombies, spammers, and bots, respectively.},
  archive      = {J_IJMLC},
  author       = {Li, Yangyang and Sun, Xinyue and Yang, Renyu and Sun, Xiaoyang and Chen, Shiru and Wang, Shuhai and Bhuiyan, Md Zakirul Alam and Zomaya, Albert Y. and Xu, Jie},
  doi          = {10.1007/s13042-024-02392-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2297-2314},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {GNNRI: Detecting anomalous social network users through heterogeneous information networks and user relevance exploration},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view representation for pathological image classification via contrastive learning. <em>IJMLC</em>, <em>16</em>(4), 2285-2296. (<a href='https://doi.org/10.1007/s13042-024-02391-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pathological images have become indispensable in clinical practice, but their complexity and blurred tissue structures pose challenges for accurate classification. To overcome this, it is crucial to combine the color view and edge view, as the features extracted from the edge view are sensitive for capturing subtle changes in repetitive patterns of cells and tissues. However, existing multi-view methods for pathological images often overlook the consistency among multiple views. Thus, we propose a multi-view method for pathological image classification using contrastive learning. By combining filtering techniques with the deep network, we enhance the interpretability of models and explicit modeling of features. We utilize Sobel filters to obtain the edge view, which complements the color view. To align the multi-view representations, we employ contrastive learning, encouraging the network to learn the intra-sample consistency and distinguish inter-sample differences. The fusion of features from the multi-view representations further enhances the representation. The experimental results on the BreakHist and CRC-100K datasets demonstrate the effectiveness of the proposed method, and we achieve better results on multiple evaluation metrics.},
  archive      = {J_IJMLC},
  author       = {Chen, Kaitao and Sun, Shiliang and Zhao, Jing and Wang, Feng and Zhang, Qingjiu},
  doi          = {10.1007/s13042-024-02391-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2285-2296},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-view representation for pathological image classification via contrastive learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Masked face recognition based on knowledge distillation and convolutional self-attention network. <em>IJMLC</em>, <em>16</em>(4), 2269-2284. (<a href='https://doi.org/10.1007/s13042-024-02390-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face recognition has significantly improved with the development of deep learning technology. However, in the case of a viral epidemic like COVID-19, wearing masks reduces the risk of infection significantly but results in losing crucial face features and increasing intra-class divergence, which decreases the effectiveness and accuracy of face recognition. To deal with this issue, a novel masked face recognition (MFR) method based on knowledge distillation and convolutional self-attention network is proposed. Specifically, a knowledge distillation framework is constructed to transmit knowledge from the teacher network to the student network, which enables the student network to focus on unmasked face areas and generate more effective face embeddings. Moreover, a convolutional self-attention network including the shallow feature extraction module (SFEM) and the convolution-Transformer dual-branch module (CTDM) is proposed to extract local- and global-range features for MFR. Experimental results on multiple public datasets demonstrate that our method has superior MFR performance to state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Wan, Weiguo and Wen, Runlin and Yao, Li and Yang, Yong},
  doi          = {10.1007/s13042-024-02390-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2269-2284},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Masked face recognition based on knowledge distillation and convolutional self-attention network},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial de-overlapping learning machines for supervised and semi-supervised learning. <em>IJMLC</em>, <em>16</em>(4), 2249-2267. (<a href='https://doi.org/10.1007/s13042-024-02389-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While adversarial link information like the commonly used must-link and cannot-link constraints on training data are available, the existing AUC maximization learning frameworks cannot explicitly incorporate them to better guide disentanglements of the overlapping areas. As the first attempt in filling this gap, this study first develops the coupling-based adversarial overlapping concept by means of the coupling of the classical AUC with the modularity caused by adversarial link information. Then the corresponding adversarial de-overlapping maximization learning machine called De-OVL for supervised imbalanced data is developed. Furthermore, by using the proposed two-channel based strategy, De-OVL is extended to its semi-supervised version SDe-OVL with only one tunable hyperparameter for semi-supervised imbalanced data. Based on random Fourier features (RFF), the fast training versions RFF-De-OVL and RFF-SDe-OVL are developed to scale up De-OVL and SDe-OVL, respectively. In contrast to existing imbalanced classification methods, De-OVL has its unified adversarial de-overlapping maximization framework for supervised and semi-supervised imbalanced data, with fewer hyperparameters to be tuned. Extensive experimental results on four groups of benchmarking imbalanced datasets verify the above effectiveness of the proposed machines.},
  archive      = {J_IJMLC},
  author       = {Sun, Yichen and Vong, Chi Man and Wang, Shitong},
  doi          = {10.1007/s13042-024-02389-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2249-2267},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adversarial de-overlapping learning machines for supervised and semi-supervised learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual branch network combining detail information and color feature for remote sensing image dehazing. <em>IJMLC</em>, <em>16</em>(4), 2231-2247. (<a href='https://doi.org/10.1007/s13042-024-02388-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing images are often affected by haze, resulting in problems such as blurriness, loss of details, and color casts. To effectively remove haze and obtain high-quality remote sensing image, a dual branch network, named DICFNet, that effectively combines detail information and color features is proposed. Specifically, a detail information learning branch is designed firstly, which uses the detail feature residual extraction module (DFREM) to capture the detail features and promote feature learning. Secondly, to learn comprehensive color features, a color feature learning branch is designed. It converts the RGB color space into the Lab color space that is very similar to human visual perception, and then puts the color feature extraction module (CFEM) into use to learn brightness and saturation features. Finally, a learnable fusion module is adopted to obtain the optimal fusion scheme for the previous two branches, enhancing the ability of the model to produce clear remote sensing images. A wealth of experimental evidence indicates that the proposed DICFNet outperforms comparison methods in both visual quality and quantitative evaluation while maintaining a lower memory footprint and requiring fewer computational resources. In addition, detailed ablation experiments demonstrate the effectiveness of the core components of the model.},
  archive      = {J_IJMLC},
  author       = {Miao, Mengjun and Huang, Heming and Huang, Kedi and Wang, Shanqin},
  doi          = {10.1007/s13042-024-02388-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2231-2247},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A dual branch network combining detail information and color feature for remote sensing image dehazing},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PLSRP: Prompt learning for send–receive path prediction. <em>IJMLC</em>, <em>16</em>(4), 2219-2230. (<a href='https://doi.org/10.1007/s13042-024-02387-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of the courier industry driven by societal development, efficiently and accurately predicting the send–receive path has become a critical issue. Existing methods suffer from several limitations, including discrepancies between pretraining and downstream data, and inconsistencies between training and testing targets. To address these challenges, this paper introduces a pioneering approach that applies prompt learning to send–receive path prediction. The proposed method employs a “pretraining-prompt-finetuning" paradigm, where a model is pretrained on a large-scale dataset and then finetuned using prompt vectors to adapt to downstream tasks. This novel strategy effectively bridges the gap between pretraining and finetuning data, ensuring better model generalization with minimal additional cost. Furthermore, we incorporate an actor-critic reinforcement learning framework, where the actor network generates paths and the critic network evaluates them. This framework optimizes the model based on rewards calculated from non-differentiable test criteria, effectively addressing the inconsistency between training and testing objectives. This approach is better suited to adapt to various delivery scenarios, enhancing prediction accuracy and efficiency. Experiments conducted on two real-world datasets demonstrate the superiority of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Wei, Qi and Lu, Yi-Hong and Du, Dan and Cai, Huan-Tao and Lai, Pei-Yuan and Wang, Chang-Dong},
  doi          = {10.1007/s13042-024-02387-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2219-2230},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {PLSRP: Prompt learning for send–receive path prediction},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive inertia weights: An effective way to improve parameter estimation of hidden layer in stochastic configuration networks. <em>IJMLC</em>, <em>16</em>(4), 2203-2218. (<a href='https://doi.org/10.1007/s13042-024-02386-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic Configuration Networks (SCNs) is a new incremental neural network model, and its supervised mechanism plays a crucial role in ensuring the universal approximation ability. However, existing studies on SCNs have shown shortcomings, particularly the parameter estimation of the hidden layer during the model construction. To address this issue, many scholars have introduced additional mechanisms, which partially solve the aforementioned problems but increase the computational cost. Therefore, on the premise of maintaining the randomness and low complexity of SCNs, this paper aims to construct the model based on the direction of fastest decline in residuals, so as to obtain better regression performance. To achieve this goal, an input weight and bias configuration method based on adaptive inertia weights is proposed in this paper, named by Adaptive Weighted Stochastic Configuration Networks (AWSCNs). This method adaptively controls the node parameters to obtain smaller residual errors and improve model prediction ability. Additionally, the singular value decomposition algorithm is incorporated to compress the model and enhance the calculation speed. In this paper, the effectiveness and stability of the proposed method are evaluated using one approximation function and seven benchmark regression datasets. Experimental results demonstrate that AWSCNs not only get more ideal node parameters but also exhibit superior performance in terms of fast convergence, generalization capability, and running time.},
  archive      = {J_IJMLC},
  author       = {Han, Ying and Yu, Yuanhao and Li, Kun},
  doi          = {10.1007/s13042-024-02386-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2203-2218},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adaptive inertia weights: An effective way to improve parameter estimation of hidden layer in stochastic configuration networks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weakly-supervised label distribution feature selection via label-specific features and label correlation. <em>IJMLC</em>, <em>16</em>(4), 2181-2201. (<a href='https://doi.org/10.1007/s13042-024-02385-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label Distribution Learning (LDL) stands out as an innovative method to address the challenges posed by label ambiguity. Current LDL algorithms are predominantly designed for datasets with comprehensive supervised information. However, in real-world scenarios, it’s common to encounter partial missing labels within the label space. This phenomenon disrupts the structure and correlation between labels, posing a challenge to the precise design of learning algorithms. Furthermore, in label distribution learning, it also faces the effect of high feature dimensionality. To tackle this, adopting pre-processing methods like feature selection becomes crucial, aiming to trim down the data dimensionality. Motivated by this, a weakly-supervised label distribution feature selection algorithm based on label correlation is proposed in this paper. First, to handle weakly-supervised label distribution data, a two-stage incomplete label distribution learning method (IncomLDLTS) to recover missing labels by exploiting label-independent prediction based on label-specific features is proposed. Second, a minimum correlation label feature selection algorithm (MCLFS) to enhance the performance for complete label distribution data is designed, which employs the interaction information metric to explore the label correlation to obtain a minimum correlation label, then features about each label based on label-specific features and feature redundancy are captured. Finally, based on six representative evaluation metrics, our experiments on 14 datasets affirm the effectiveness of our approach, not only in restoring missing labels but also in choosing essential features, leading to improved classification accuracy.},
  archive      = {J_IJMLC},
  author       = {Shu, Wenhao and Hu, Jiayu and Qian, Wenbin},
  doi          = {10.1007/s13042-024-02385-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {4},
  number       = {4},
  pages        = {2181-2201},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Weakly-supervised label distribution feature selection via label-specific features and label correlation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforced multi-modal cyberbullying detection with subgraph neural networks. <em>IJMLC</em>, <em>16</em>(3), 2161-2180. (<a href='https://doi.org/10.1007/s13042-024-02384-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks have become an indispensable part of contemporary life, and the widespread occurrence of cyberbullying among young people on these sites has sparked serious societal issues. Information on social media often encompasses various heterogeneous elements, such as locations, individuals, organizations, and more. Despite this complexity, text analysis has dominated most studies on cyberbullying detection, ignoring the variety of media data present in social networks. This paper proposes a novel framework for tackling this gap: RSBully is a multi-agent Reinforced Guided Weighted Multi-relational Subgraph Neural Network that is intended to detect cyberbullying effectively. It organizes elements of different types using heterogeneous information networks (HINs) and then transforms them into a weighted multi-relation graph to model the relationship between social media sessions. Second, RSBully uses a reinforced subgraph neural network to eliminate redundant information in social media data by extracting the prominent subgraphs of the graph and capturing intrinsic correlation between modalities and bullying behaviors with interpretability. Comprehensive experimental assessments on real-world social media datasets show that the performance of the RSBully framework outperforms various current state-of-the-art models.},
  archive      = {J_IJMLC},
  author       = {Luo, Kai and Zheng, Ce and Guan, Zhenyu},
  doi          = {10.1007/s13042-024-02384-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2161-2180},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Reinforced multi-modal cyberbullying detection with subgraph neural networks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced and lightweight design of small object detector based on YOLOv5s model. <em>IJMLC</em>, <em>16</em>(3), 2139-2159. (<a href='https://doi.org/10.1007/s13042-024-02383-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the challenges of dense target distribution and complex backgrounds in small detection targets, existing small object detection algorithms suffer from poor performance and high model complexity, which is extremely difficult to deploy on embedded platforms. To address above issues, we optimized the YOLOv5s model structure to enhance detection accuracy. To avoid incurring extra computational expenses, we introduced a local pruning strategy to reduce redundancy, which enables the detection model more suitable for embedded systems. Considering pruning may cause accuracy degradation, we employ knowledge distillation techniques combining feature distillation and output distillation. Specifically, we transfer the knowledge from a high-precision teacher model to a student model, enabling exceptional real-time performance. The experimental results on the VisDrone2019 dataset show that compared to the original algorithm, our model has reduced the parameter count by 50.38%, computation by 51.81%, and model size by 52.94%, totaling just 8 M. The average precision (mAP@0.5) improved to 42.2%. Our proposed model outperforms the current state-of-the-art methods for small object detection in terms of both accuracy and computational efficiency.},
  archive      = {J_IJMLC},
  author       = {Jiang, Hui and Ma, Yongjie and Hong, Tiansong and Gong, Tao},
  doi          = {10.1007/s13042-024-02383-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2139-2159},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhanced and lightweight design of small object detector based on YOLOv5s model},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning based magnet design for arm MRI system. <em>IJMLC</em>, <em>16</em>(3), 2127-2138. (<a href='https://doi.org/10.1007/s13042-024-02382-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Throwing elbow is a common sports injury that can be diagnosed more promptly by portable magnetic resonance imaging (MRI) than by conventional superconducting MRI. The main magnet of portable MRI systems typically consists of permanent magnets. However, the limited length of the main magnet can lead to poor magnetic field homogeneity, resulting in image distortion. Therefore, it is essential to optimize the permanent magnets arrangement. The traditional genetic algorithm (GA) lacks a timely feedback mechanism during the search process, and there is no gradual interaction with the magnetic field map in a single iteration, which has potential for improvement. To address this problem, a deep reinforcement learning (DRL) based magnet design algorithm for an arm MRI system is proposed. Based on the magnetic field map, the method is performed to design a high homogeneity magnet under the weight constraint on the main magnet, significantly better than the multi-objective method NSGA-II. The results indicate that the proposed method achieves a 26.7% gain in homogeneity at a higher average magnetic field strength compared to the GA. In a scenario where the volume of the main magnet is uniform and without weight constraint, an adaptive search mechanism is proposed that enables the method to achieve a 62.90% improvement in homogeneity compared to the GA.},
  archive      = {J_IJMLC},
  author       = {Pang, Yanwei and Guo, Yishun and Liu, Yiming and Song, Zhanjie and Wang, Zhenchang},
  doi          = {10.1007/s13042-024-02382-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2127-2138},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deep reinforcement learning based magnet design for arm MRI system},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual insurance for generalized zero-shot learning. <em>IJMLC</em>, <em>16</em>(3), 2111-2125. (<a href='https://doi.org/10.1007/s13042-024-02381-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional zero-shot learning aims to use the trained model to accurately classify samples from unseen classes, while for the more difficult task of generalized zero-shot learning, the trained model needs to classify samples from both seen and unseen classes into the correct classes. Because only seen class samples are available during training, generalized zero-shot learning meets great challenges in classification. Generative model is one of the good methods to solve this problem. However, the samples generated by the generative model are often of poor quality. In addition, there are semantic redundancies in the generated samples that are not conducive to classification. To solve these problems, we proposed the dual insurance model (DI-GAN) for generalized zero-shot learning in this paper, including a feature generation module and a semantic separation module. They guarantee the high quality of generated features and the good classification performance respectively. Specifically, the first insurance is based on generative adversarial network, whose generator is constrained by a clustering method to make the generated samples close to the real samples. The second insurance is based on variational autoencoder, including semantic separation, instance network and classification network. Semantic separation is designed to extract the semantically related parts which are beneficial to classification, while instance network acting on the semantically related parts is used to ensure the classification performance. Extensive experiments on four benchmark datasets show the competitiveness of the proposed DI-GAN.},
  archive      = {J_IJMLC},
  author       = {Liang, Jiahao and Fang, Xiaozhao and Kang, Peipei and Han, Na and Li, Chuang},
  doi          = {10.1007/s13042-024-02381-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2111-2125},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dual insurance for generalized zero-shot learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ultra-high-definition underwater image enhancement via dual-domain interactive transformer network. <em>IJMLC</em>, <em>16</em>(3), 2093-2109. (<a href='https://doi.org/10.1007/s13042-024-02379-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of ultra-high-definition (UHD) imaging device is increasingly being used for underwater image acquisition. However, due to light scattering and underwater impurities, UHD underwater images often suffer from color deviations and edge blurriness. Many studies have attempted to enhance underwater images by integrating frequency domain and spatial domain information. Nonetheless, these approaches often interactively fuse dual-domain features only in the final fusion module, neglecting the complementary and guiding roles of frequency domain and spatial domain features. Additionally, the extraction of dual-domain features is independent of each other, which leads to the sharp advantages and disadvantages of the dual-domain features extracted by these methods. Consequently, these methods impose high demands on the feature fusion capabilities of the fusion module. But in order to handle UHD underwater images, the fusion modules in these methods often stack only a limited number of convolution and activation function operations. This limitation results in insufficient fusion capability, leading to defects in the restoration of edges and colors in the images. To address these issues, we develop a dual-domain interaction network for enhancing UHD underwater images. The network takes into account both frequency domain and spatial domain features to complement and guide each other’s feature extraction patterns, and fully integrates the dual-domain features in the model to better recover image details and colors. Specifically, the network consists of a U-shaped structure, where each layer is composed of dual-domain interaction transformer blocks containing interactive multi-head attention and interactive simple gate feed-forward networks. The interactive multi-head attention captures local interaction features of frequency domain and spatial domain information using convolution operation, followed by multi-head attention operation to extract global information of the mixed features. The interactive simple gate feed-forward network further enhances the model’s dual-domain interaction capability and cross-dimensional feature extraction ability, resulting in clearer edges and more realistic colors in the images. Experimental results demonstrate that the performance of our proposal in enhancing underwater images is significantly better than existing methods.},
  archive      = {J_IJMLC},
  author       = {Li, Weiwei and Cao, Feiyuan and Wei, Yiwen and Shi, Zhenghao and Jia, Xiuyi},
  doi          = {10.1007/s13042-024-02379-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2093-2109},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Ultra-high-definition underwater image enhancement via dual-domain interactive transformer network},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Triple confidence-aware encoder–decoder model for commonsense knowledge graph completion. <em>IJMLC</em>, <em>16</em>(3), 2073-2091. (<a href='https://doi.org/10.1007/s13042-024-02378-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Commonsense knowledge is essential for performing inference and retrieval in many artificial intelligence applications, including those in natural language processing and expert system. However, a large amount of valuable commonsense knowledge exists implicitly or is missing in commonsense knowledge graphs (KGs). In this case, commonsense knowledge graph completion (CKGC) is proposed to solve this incomplete problem by inferring missing parts of commonsense triples, e.g., (?, HasPrerequisite, turn computer on) or (get onto web, HasPrerequisite, ?). Some existing methods attempt to learn as much entity semantic information as possible by exploiting the structural and semantic context of entities for improving the performance of CKGC. However, we found that the existing models only pay attention to entities and relations of the commonsense triples and ignore the important confidence (weight) information related to the commonsense triples. In this paper we innovatively introduce commonsense triple confidence into CKGC and propose a confidence-aware encoder–decoder CKGC model. In the encoding stage, we propose a method to incorporate the commonsense triple confidence into RGCN (relational graph convolutional network), so that the encoder can learn a more accurate semantic representation of a triple by considering the triple confidence constraints. Moreover, the commonsense KGs are usually sparse, because there are a large number of entities with an in-degree of 1 in the commonsense triples. Therefore, we propose to add a new relation (called similar edge) between two similar entities for compensating the sparsity of commonsense KGs. In the decoding stage, considering that entities in the commonsense triples are sentence-level entities (e.g., the tail entity turn computer on mentioned above), we propose a joint decoding model by fusing effectively the existing InteractE and ConvTransE models. Experiments show that our new model achieves better performance compared to the previous competitive models. In particular, the incorporating of the confidence of triples actually brings significant improvements to CKGC.},
  archive      = {J_IJMLC},
  author       = {Chen, Hongzhi and Zhang, Fu and Li, Qinghui and Li, Xiang and Ding, Yifan and Zhang, Daqing and Cheng, Jingwei and Wang, Xing},
  doi          = {10.1007/s13042-024-02378-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2073-2091},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Triple confidence-aware encoder–decoder model for commonsense knowledge graph completion},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic path planning fusion algorithm with improved a* algorithm and dynamic window approach. <em>IJMLC</em>, <em>16</em>(3), 2057-2071. (<a href='https://doi.org/10.1007/s13042-024-02377-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of robotics, path planning in complex dynamic environments has become a significant research hotspot. Existing methods often suffer from inadequate dynamic obstacle avoidance capabilities and low exploration efficiency. These issues primarily arise from inconsistencies caused by insufficient utilization of environmental maps in actual path planning. To address these challenges, we propose an improved algorithm that integrates the enhanced A* algorithm with the optimized dynamic window approach (DWA). The enhanced A* algorithm improves the robot’s path smoothness and accelerates global exploration efficiency, while the optimized DWA enhances local static and dynamic obstacle avoidance capabilities. We performed simulation experiments using MATLAB and conducted experiments in real dynamic environments simulated with Gazebo. Simulation results indicate that, compared to the traditional A* algorithm, our method optimizes traversed grids by 25% and reduces time by 23% in global planning. In dynamic obstacle avoidance, our approach improves path length by 2.7% and reduces time by 19.2% compared to the traditional DWA, demonstrating significant performance enhancements.},
  archive      = {J_IJMLC},
  author       = {Zhang, Jianfeng and Guo, Jielong and Zhu, Daxin and Xie, Yufang},
  doi          = {10.1007/s13042-024-02377-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2057-2071},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dynamic path planning fusion algorithm with improved a* algorithm and dynamic window approach},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LSSMSD: Defending against black-box DNN model stealing based on localized stochastic sensitivity. <em>IJMLC</em>, <em>16</em>(3), 2041-2056. (<a href='https://doi.org/10.1007/s13042-024-02376-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning as a service (MLaaS) has become a widely adopted approach, allowing customers to access even the most complex machine learning models through a pay-per-query model. Black-box distribution has been widely used to keep models secret in MLaaS. However, even with black-box distribution alleviating certain risks, the functionality of a model can still be compromised when customers gain access to their model’s predictions. To protect the intellectual property of model owners, we propose an effective defense method against model stealing attacks with the localized stochastic sensitivity (LSS), namely LSSMSD. First, suspicious queries are detected by employing an out-of-distribution (OOD) detector. Addressing a critical issue with many existing defense methods that overly rely on OOD detection results, thus affecting the model’s fidelity, we innovatively introduce LSS to solve this problem. By calculating the LSS of suspicious queries, we can selectively output misleading predictions for queries with high LSS using an misinformation mechanism. Extensive experiments demonstrate that LSSMSD offers robust protections for victim models against black-box proxy attacks such as Jacobian-based dataset augmentation and Knockoff Nets. It significantly reduces accuracies of attackers’ substitute models (up to 77.94%) while yields minimal impact to benign user accuracies (average $$-2.72\%$$ ), thereby maintaining the fidelity of the victim model.},
  archive      = {J_IJMLC},
  author       = {Zhang, Xueli and Chen, Jiale and Li, Qihua and Zhang, Jianjun and Ng, Wing W. Y. and Wang, Ting},
  doi          = {10.1007/s13042-024-02376-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2041-2056},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {LSSMSD: Defending against black-box DNN model stealing based on localized stochastic sensitivity},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CHNSCDA: CircRNA-disease association prediction based on strongly correlated heterogeneous neighbor sampling. <em>IJMLC</em>, <em>16</em>(3), 2023-2039. (<a href='https://doi.org/10.1007/s13042-024-02375-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circular RNAs (circRNAs) are a special class of endogenous non-coding RNA molecules with a closed circular structure. Numerous studies have demonstrated that exploring the association between circRNAs and diseases is beneficial in revealing the pathogenesis of diseases. However, traditional biological experimental methods are time-consuming. Although some methods have explored the circRNA associated with diseases from different perspectives, how to effectively integrate the multi-perspective data of circRNAs has not been well studied, and the feature aggregation between heterogeneous nodes has not been fully considered. Based on these considerations, a novel computational framework, called CHNSCDA, is proposed to efficiently forecast unknown circRNA-disease associations(CDAs). Specifically, we calculate the sequence similarity and functional similarity for circRNAs, as well as the semantic similarity for diseases. Then the similarities of circRNAs and diseases are combined with Gaussian interaction profile kernels (GIPs) similarity, respectively. These similarities are fused by taking the maximum values. Moreover, circRNA-circRNA associations and disease-disease associations with strong correlations are selectively combined to construct a heterogeneous network. Subsequently, we predict the potential CDAs based on the multi-head dynamic attention mechanism and multi-layer convolutional neural network. The experimental results show that CHNSCDA outperforms the other four state-of-the-art methods and achieves an area under the ROC curve of 0.9803 in 5-fold cross validation (5-fold CV). In addition, extensive ablation comparison experiments were conducted to confirm the validity of different similarity feature aggregation methods, feature aggregation methods, and dynamic attention. Case studies further demonstrate the outstanding performance of CHNSCDA in predicting potential CDAs.},
  archive      = {J_IJMLC},
  author       = {Lin, Yuanyuan and Wang, Nianrui and Liu, Jiangyan and Zhang, Fangqin and Wei, Zhouchao and Yi, Ming},
  doi          = {10.1007/s13042-024-02375-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2023-2039},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {CHNSCDA: CircRNA-disease association prediction based on strongly correlated heterogeneous neighbor sampling},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-agent collaborative algorithm for task-oriented dialogue systems. <em>IJMLC</em>, <em>16</em>(3), 2009-2022. (<a href='https://doi.org/10.1007/s13042-024-02374-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, reinforcement learning has found successful applications in dialogue systems. However, when confronted with task-oriented dialogue systems, optimizing the strategy becomes challenging due to difficulties in state tracking and the complexity of multitasking. Task-oriented dialogue systems based on reinforcement learning encounter issues such as poor collaboration, non-unique learning goals, and non-staticity arising from the absence of agent cooperation. To address these challenges, this paper introduces a novel multi-agent cooperative dialogue (MACD) algorithm for task-oriented dialogue systems. In MACD, a deep neural network framework is employed to facilitate information exchange among multiple agents within task-oriented dialogue systems. This integration enables the consolidation of observations from individual agents, leading to the derivation of joint observations and fostering information sharing among the agents. Consequently, MACD aims to mitigate the problem of non-stationarity resulting from the lack of shared information among multiple agents. In the context of multi-agent strategy learning within task-oriented dialogue systems, we employ the MADDPG architecture to address the challenge of inadequate joint strategy learning among multiple agents. By integrating single-agent observations and multi-agent strategy learning, we aim to alleviate the collaborative deficiencies inherent in task-oriented dialogue systems involving multiple agents. Through experimentation with reinforcement learning algorithms such as MACD, DQN, OPPA, JOIE, and QMIX on the MultiWOZ 2.0 corpus, our results demonstrate significant enhancements. Specifically, the proposed algorithm effectively elevates the success rate of multi-agent collaboration in accomplishing dialogue tasks in composite task scenarios. Furthermore, it mitigates the occurrence of ineffective dialogues during the dialogue rounds. Comparative analysis reveals that our approach surpasses conventional reinforcement learning algorithms in facilitating agent information interaction and joint strategy learning within the task-oriented dialogue context.},
  archive      = {J_IJMLC},
  author       = {Sun, Jingtao and Kou, Jiayin and Shi, Weipeng and Hou, Wenyan},
  doi          = {10.1007/s13042-024-02374-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2009-2022},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A multi-agent collaborative algorithm for task-oriented dialogue systems},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault-tolerant control design for nonlinear multilateral teleoperation system with unreliable communication channels and actuator constraints. <em>IJMLC</em>, <em>16</em>(3), 1991-2007. (<a href='https://doi.org/10.1007/s13042-024-02373-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For nonlinear multilateral teleoperation systems, unreliable communication channels and actuator constraints are the main challenging issues to achieve the stability condition and satisfy the required performance. In this paper, a novel fault-tolerant control algorithm is proposed for a class of multi-degree-of-freedom nonlinear multilateral teleoperation systems with the aforementioned problems and unknown environmental forces. The time-varying delays and packet dropouts are incorporated in the unreliable communication channels, and the considered systems are modeled as a kind of T-S fuzzy systems with multiple time-varying delays. For actuator constraints, both the actuator failures and the unknown control directions are investigated in such research, by designing a novel fault-tolerant control scheme, the failures and control directions can be estimated simultaneously. Next, the radial basis function neural network (RBFNN) is introduced to estimate the unknown environmental force, and the estimated results are incorporated in the controller design and the mean-square stability of the closed-loop system with disturbance attenuation level is guaranteed. Finally, a numerical simulation example is given to show the effectiveness of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Ke, Huan-Yu and Chen, Yang-Jie and Li, Ming and Li, Jian-Ning},
  doi          = {10.1007/s13042-024-02373-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1991-2007},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fault-tolerant control design for nonlinear multilateral teleoperation system with unreliable communication channels and actuator constraints},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating global semantics and enhanced local subgraph for inductive link prediction. <em>IJMLC</em>, <em>16</em>(3), 1971-1990. (<a href='https://doi.org/10.1007/s13042-024-02372-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inductive link prediction (ILP) predicts missing triplets involving unseen entities in knowledge graphs (KGs). Existing ILP research mainly addresses seen-unseen entities in the original KG (semi-inductive link prediction) and unseen-unseen entities in emerging KGs (fully-inductive link prediction). Bridging-inductive link prediction, which focuses on unseen entities that carry evolutionary information from the original KG to the emerging KG, has not been extensively studied so far. This study introduces a novel model called GSELI (integrating global semantics and enhanced local subgraph for inductive link prediction), which comprises three components. (1) The contrastive learning-based global semantic features (CLSF) module extracts relation-specific semantic features between the original and emerging KGs and employs semantic-aware contrastive learning to optimize these features. (2) The GNN-based enhanced local subgraph (GELS) module employs personalized PageRank (PPR)-based local clustering to sample tightly-related subgraphs and incorporates complete neighboring relations to enhance the topological information of subgraphs. (3) Joint contrastive learning and supervised learning training. Experimental results on various benchmark datasets demonstrate that GSELI outperforms the baseline models in both fully-inductive and bridging-inductive link predictions.},
  archive      = {J_IJMLC},
  author       = {Liang, Xinyu and Si, Guannan and Li, Jianxin and An, Zhaoliang and Tian, Pengxin and Zhou, Fengyu and Wang, Xiaoliang},
  doi          = {10.1007/s13042-024-02372-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1971-1990},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Integrating global semantics and enhanced local subgraph for inductive link prediction},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Iterative filter pruning with combined feature maps and knowledge distillation. <em>IJMLC</em>, <em>16</em>(3), 1955-1969. (<a href='https://doi.org/10.1007/s13042-024-02371-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have been successfully implemented in various computer vision tasks. However, the remarkable achievements are accompanied by high memory and high computation, which hinder the deployment and application of CNNs on resource-constrained mobile devices. Filter pruning is proposed as an effective method to solve the above problems. In this paper, we propose an iterative filter pruning method that combines feature map properties and knowledge distillation. This method can maximize the important feature information (e.g., spatial features) in the feature map by calculating the information capacity and feature relevance of the feature map, and then pruning based on the set criteria. Then, the pruned network learns the complete feature information of the standard CNN architecture in order to quickly and completely recover the lost accuracy before the next pruning operation. The alternating operation of pruning and knowledge distillation can effectively and comprehensively achieve network compression. Experiments on image classification datasets via mainstream CNN architectures indicate the effectiveness of our approach. For example, on CIFAR-10, our method reduces Floating Point Operations (FLOPs) by 71.8% and parameters by 71.0% with an accuracy improvement of 0.24% over the ResNet-110 benchmark. On ImageNet, our method achieves 55.6% reduction in FLOPs and 52.5% reduction in model memory at the cost of losing only 0.17% of Top-5 on ResNet-50.},
  archive      = {J_IJMLC},
  author       = {Liu, Yajun and Fan, Kefeng and Zhou, Wenju},
  doi          = {10.1007/s13042-024-02371-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1955-1969},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Iterative filter pruning with combined feature maps and knowledge distillation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting complex copy-move forgery using KeyPoint-siamese capsule network against adversarial attacks. <em>IJMLC</em>, <em>16</em>(3), 1927-1953. (<a href='https://doi.org/10.1007/s13042-024-02370-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital image forensics, particularly in the realm of detecting Copy-Move Forgery (CMF), is exposed to significant challenges, especially in the face of intricate adversarial attacks. In response to these challenges, this paper presents a robust approach for detecting complex CMFs in digital images using the KeyPoint-Siamese Capsule Network (KP-SCN) and evaluates its resilience against adversarial attacks. The KP-SCN architecture incorporates keypoint detection, a Siamese network for feature extraction, and a capsule network for forgery detection. The method showcases enhanced robustness against adversarial attacks, specifically addressing image perturbation, patch removal, patch replacement, and spatial transformation attacks. By using hierarchical feature representations and dynamic routing in capsule networks, the model effectively handles complex CMF, including rotation, scaling, and non-linear transformations. The proposed KP-SCN approach employs a large dataset for training the KP-SCN, enabling it to identify copy-move forgeries by comparing extracted keypoints and their spatial relationships. KP-SCN demonstrates superior performance compared to the state-of-the-art on the CoMoFoD dataset, achieving precision, recall, and F1-score values of 95.62%, 93.78%, and 94.69%, respectively, and shows strong results on other datasets. For CASIA v2.0, the precision, recall, and F1-score are 90.45%, 88.97%, and 89.70%; for MICC-F2000, they are 91.32%, 90.27%, and 90.79%; for MICC-F600, they are 92.21%, 91.10%, and 91.65%; for MICC-F8multi, they are 89.75%, 87.92%, and 88.83%; and for IMD, they are 93.14%, 92.58%, and 92.86%. The KP-SCN framework maintains high detection rates under various manipulations, including JPEG compression, rotation, scaling, noise, blurring, brightness changes, contrast adjustment, and zoom motion blur compared to the other methods. For instance, it achieves an 80.657% detection rate for CoMoFoD under JPEG compression and 97.883% for IMD under a 10-degree rotation. These findings validate the robustness and adaptability of KP-SCN, making it a reliable solution for real-world forensic applications.},
  archive      = {J_IJMLC},
  author       = {Aiswerya, S. B. and Jawhar, S. Joseph},
  doi          = {10.1007/s13042-024-02370-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1927-1953},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Detecting complex copy-move forgery using KeyPoint-siamese capsule network against adversarial attacks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-low frequency features fusion and integrated classification SCNs for intelligent fault diagnosis of rolling bearing. <em>IJMLC</em>, <em>16</em>(3), 1889-1926. (<a href='https://doi.org/10.1007/s13042-024-02369-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For fault diagnosis of the rolling bearing, it is difficult to accurately extract and recognize fault features of the vibration signal. In this paper, a novel feature extraction method based on optimized Maximum Correlated Kurtosis Deconvolution (MCKD) by an improved Black Widow Optimization Algorithm (IBWOA) and Singular Value Decomposition (SVD) method was proposed, and an integrated classification Stochastic Configuration Networks (ISCNs) model was designed for fault recognition. Firstly, SVD was used to denoise and reconstruct the signal, in which fault features of the reconstructed signal were highlighted by MCKD; however, the filtering effect of MCKD was seriously affected by accurate value of some parameters, so IBWOA was proposed to realize optimized selection of them. Then, Wavelet Packet Decomposition (WPD) was used to deal with the signal after the feature enhancement, and the high-frequency and low-frequency singular values were extracted as the feature vectors. Finally, the ISCNs model was designed to train and classify the low-frequency and high-frequency feature vectors several times, which were then decided by the principle of ”minority obeying majority”. Simulation experiments show that the proposed method can effectively highlight and extract bearing fault features, and the average diagnostic accuracy can maximum reach 99.66% according to multiple experiments.},
  archive      = {J_IJMLC},
  author       = {Li, Kun and Wu, Hao and Han, Ying},
  doi          = {10.1007/s13042-024-02369-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1889-1926},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {High-low frequency features fusion and integrated classification SCNs for intelligent fault diagnosis of rolling bearing},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Video anomaly detection based on multi-scale optical flow spatio-temporal enhancement and normality mining. <em>IJMLC</em>, <em>16</em>(3), 1873-1888. (<a href='https://doi.org/10.1007/s13042-024-02368-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection aims to detect anomaly scores in video frames, and it is a challenging research area since the types of anomalies are limitless. In response to the fact that abnormal behavior is likely to be misidentified as normal and anomalies are typically generated by the fast motion of foreground objects, this paper proposes a novel model called the Multi-scale Optical Flow Spatio-Temporal Enhancement and Normality Mining Network (MOFSTE-NM). It contains the Spatio-temporal Information Attention Enhancement Module (SIAEM) that incorporates reconstructed optical flows at multiple scales and considers spatial and temporal aspects. This strategy reduces the influence of the background and normal objects, enhancing the model’s ability to focus on anomalous fast moving objects in the foreground. Additionally, we propose a Normality Mining Convolution (NMC) module embedded in the decoder to refine the boundary between normality and abnormality. The NMC uses a multihead attention mechanism for dynamic weight adjustment, enabling the precise extraction of normal information. We compute the final anomaly score by fusing two components: (1) the reconstruction error of the optical flows and (2) the peak signal-to-noise ratio between the predicted frame and its ground truth. We evaluate our model on three well-established video anomaly detection datasets. A comparison of different models indicates that the proposed model achieves superior performance compared to state-of-the-art approaches, with area under the receiver operating characteristic curve (AUROC) values of 99.23 $$\%$$ on UCSD Ped2, 88.84 $$\%$$ on CUHK Avenue, and 74.80 $$\%$$ on Shanghaitech.},
  archive      = {J_IJMLC},
  author       = {He, Qiang and Shi, Ruinian and Chen, Linlin and Huo, Lianzhi},
  doi          = {10.1007/s13042-024-02368-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1873-1888},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Video anomaly detection based on multi-scale optical flow spatio-temporal enhancement and normality mining},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PTEKC: Pre-training with event knowledge of ConceptNet for cross-lingual event causality identification. <em>IJMLC</em>, <em>16</em>(3), 1859-1872. (<a href='https://doi.org/10.1007/s13042-024-02367-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event causality identification (ECI) aims to identify causal relations between events in texts. Although existing event causality identification works based on fine-tuning pre-trained language models (PLMs) have achieved promising results, they suffer from prohibitive computation costs, catastrophic forgetting of distributional knowledge, as well as poor interpretability. Particularly in low-resource and cross-linguistic scenarios, existing multi-lingual models are generally confronted with the so-called curse of multilinguality, language bias, and hence result in low accuracy and generalization ability. In this paper, we propose a paradigm, termed Pre-training with Event Knowledge of ConceptNet (PTEKC), to couple Multi-lingual Pre-trained Language Models (mPLMs) with event knowledge for cross-lingual event causality identification. Specifically, we have develop a parameter-sharing adapter plugin that facilitates the integration of event knowledge into the frozen PLMs. This approach significantly diminishes the number of trainable parameters and greatly reduces the risk of catastrophic forgetting. Our Adapter integrates multi-lingual alignment event knowledge into the mPLMs through two designed pre-training tasks, namely event masking and self-supervised link prediction. Extensive experiments on the benchmark dataset MECI show that PTEKC is parameter-efficient and can effectively incorporate multi-lingual alignment event knowledge for improving cross-lingual event causality identification.},
  archive      = {J_IJMLC},
  author       = {Zhu, Enchang and Yu, Zhengtao and Huang, Yuxin and Gao, Shengxiang and Xian, Yantuan},
  doi          = {10.1007/s13042-024-02367-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1859-1872},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {PTEKC: Pre-training with event knowledge of ConceptNet for cross-lingual event causality identification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stock closing price prediction based on ICEEMDAN-FA-BiLSTM–GM combined model. <em>IJMLC</em>, <em>16</em>(3), 1833-1857. (<a href='https://doi.org/10.1007/s13042-024-02366-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracy of stock price forecasting is of great significance in investment decision-making and risk management. However, the complexity and fluctuation of stock prices challenge the traditional forecasting methods to achieve the best accuracy. To improve the accuracy of stock price prediction, a sophisticated combination prediction method based on ICEEMDAN-FA-BiLSTM–GM has been proposed in this article. In this paper, a comprehensive and effective indicator system is constructed, covering 60 indicators such as traditional factors, market sentiment, macroeconomic indicators and company financial data, which affect stock prices. In the data preprocessing stage, in order to eliminate the influence of noise, the stock closing price series is first decomposed by using the ICEEMDAN method, which effectively divides them into high-frequency and low-frequency components according to their respective frequencies. Subsequently, LLE technique is used to narrow down the remaining indicators to obtain 9 narrowed features. Finally, each high-frequency subsequence is combined with all the dimensionality reduction features respectively to construct new indicator sets for input to the model. In the prediction stage, the hyperparameters of the prediction model for each subseries have been determined using the FA algorithm. The prediction has been carried out separately for the high-frequency and low-frequency components, employing the BiLSTM and GM prediction methods. Ultimately, the prediction results of each subseries have been superimposed to obtain the final stock price prediction value. In this paper, an empirical study was conducted using stock price data such as Shanghai composite index. The experimental results show that the established stock price prediction model based on ICEEMDAN-FA-BiLSTM–GM has obvious advantages in terms of prediction accuracy and stability compared with traditional methods and other combined prediction methods. This model can provide more accurate stock price prediction and promote the rationalization of investment decision and the accuracy of risk control.},
  archive      = {J_IJMLC},
  author       = {Xie, Lewei and Wan, Ruibo and Wang, Yuxin and Li, Fangjian},
  doi          = {10.1007/s13042-024-02366-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1833-1857},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Stock closing price prediction based on ICEEMDAN-FA-BiLSTM–GM combined model},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning from high-dimensional cyber-physical data streams: A case of large-scale smart grid. <em>IJMLC</em>, <em>16</em>(3), 1819-1831. (<a href='https://doi.org/10.1007/s13042-024-02365-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality of data and complexity of decision boundaries in high-dimensional data streams that are collected from cyber-physical power systems can greatly influence the process of learning from data and diagnosing faults in such critical systems. These systems generate massive amounts of data that overburden the system with excessive computational costs. Another issue is the presence of noise in recorded measurements that poses a challenge to the learning process, leading to a degradation in the performance of fault diagnosis. Furthermore, the diagnostic model is often provided with a mixture of redundant measurements that may deviate it from learning normal and fault distributions. This paper presents the effect of feature engineering on mitigating the aforementioned challenges in learning from data streams collected from cyber-physical systems. A data-driven fault diagnosis framework for a 118-bus power system is constructed by integrating feature selection, dimensionality reduction methods, and decision models. A comparative study is enabled accordingly to compare several advanced techniques in both domains. Dimensionality reduction and feature selection methods are compared both jointly and separately. Finally, experiments are concluded, and a setting is suggested that enhances data quality for fault diagnosis.},
  archive      = {J_IJMLC},
  author       = {Hassani, Hossein and Hallaji, Ehsan and Razavi-Far, Roozbeh and Saif, Mehrdad},
  doi          = {10.1007/s13042-024-02365-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1819-1831},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning from high-dimensional cyber-physical data streams: A case of large-scale smart grid},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A traffic flow forecasting method based on hybrid spatial–temporal gated convolution. <em>IJMLC</em>, <em>16</em>(3), 1805-1817. (<a href='https://doi.org/10.1007/s13042-024-02364-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influenced by the urban road network, traffic flow has complex temporal and spatial correlation characteristics. Traffic flow forecasting is an important problem in the intelligent transportation system, which is related to the safety and stability of the transportation system. At present, many researchers ignore the research need for traffic flow forecasting beyond one hour. To address the issue of long-term traffic flow prediction, this paper proposes a traffic flow prediction model (HSTGCNN) based on a hybrid spatial–temporal gated convolution. Spatial–temporal attention mechanism and Gated convolution are the main components of HSTGCNN. The spatial–temporal attention mechanism can effectively obtain the spatial–temporal features of traffic flow, and gated convolution plays an important role in extracting longer-term features. The usage of dilated causal convolution effectively improves the long-term prediction ability of the model. HSTGCNN predicts the traffic conditions of 1 h, 1.5 h, and 2 h on two general traffic flow datasets. Experimental results show that the prediction accuracy of HSTGCNN is generally better than that of Temporal Graph Convolutional Network (T-GCN), Graph WaveNet, and other baselines.},
  archive      = {J_IJMLC},
  author       = {Zhang, Ying and Yang, Songhao and Wang, Hongchao and Cheng, Yongqiang and Wang, Jinyu and Cao, Liping and An, Ziying},
  doi          = {10.1007/s13042-024-02364-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1805-1817},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A traffic flow forecasting method based on hybrid spatial–temporal gated convolution},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Backdoor learning curves: Explaining backdoor poisoning beyond influence functions. <em>IJMLC</em>, <em>16</em>(3), 1779-1804. (<a href='https://doi.org/10.1007/s13042-024-02363-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backdoor attacks inject poisoning samples during training, with the goal of forcing a machine learning model to output an attacker-chosen class when presented with a specific trigger at test time. Although backdoor attacks have been demonstrated in a variety of settings and against different models, the factors affecting their effectiveness are still not well understood. In this work, we provide a unifying framework to study the process of backdoor learning under the lens of incremental learning and influence functions. We show that the effectiveness of backdoor attacks depends on (i) the complexity of the learning algorithm, controlled by its hyperparameters; (ii) the fraction of backdoor samples injected into the training set; and (iii) the size and visibility of the backdoor trigger. These factors affect how fast a model learns to correlate the presence of the backdoor trigger with the target class. Our analysis unveils the intriguing existence of a region in the hyperparameter space in which the accuracy of clean test samples is still high while backdoor attacks are ineffective, thereby suggesting novel criteria to improve existing defenses.},
  archive      = {J_IJMLC},
  author       = {Cinà, Antonio Emanuele and Grosse, Kathrin and Vascon, Sebastiano and Demontis, Ambra and Biggio, Battista and Roli, Fabio and Pelillo, Marcello},
  doi          = {10.1007/s13042-024-02363-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1779-1804},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Backdoor learning curves: Explaining backdoor poisoning beyond influence functions},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature correlation fusion and feature selection under adaptive neighborhood group approximation space. <em>IJMLC</em>, <em>16</em>(3), 1761-1778. (<a href='https://doi.org/10.1007/s13042-024-02362-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world scenarios, features often exhibit dynamic interdependence and interaction. While neighborhood rough sets in feature selection have been extensively studied, approaches focusing on searching over feature groups have received less attention. Drawing inspiration from this premise, a feature fusion method grounded in minimum redundancy is proposed to integrate fragmented features. Maximizing Jeffrey divergence constructs a metric function, facilitating the inscription of knowledge granules on the feature groups. This distance function effectively coordinates the importance of feature groups by mapping samples into an adaptive approximation space. Subsequently, traditional uncertainty measures are extended to the neighborhood granules formed by the feature groups. An objective function based on these metrics of neighborhood uncertainty measures is designed to ascertain the importance of feature groups, presenting a novel feature selection algorithm based on this function. Empirical evaluations of the proposed algorithms are conducted using various datasets sourced from the University of California, Irvine (UCI), providing a comprehensive assessment of the efficacy and performance. The experimental results demonstrate the effectiveness of the algorithm.},
  archive      = {J_IJMLC},
  author       = {Li, Gengsen and Sang, Binbin and Cui, Shaoguo and Chen, Hongmei},
  doi          = {10.1007/s13042-024-02362-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1761-1778},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Feature correlation fusion and feature selection under adaptive neighborhood group approximation space},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving numerical and engineering optimization problems using a dynamic dual-population differential evolution algorithm. <em>IJMLC</em>, <em>16</em>(3), 1701-1760. (<a href='https://doi.org/10.1007/s13042-024-02361-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) is a cutting-edge meta-heuristic algorithm known for its simplicity and low computational overhead. But the traditional DE cannot effectively balance between exploration and exploitation. To solve this problem, in this paper, a dynamic dual-population DE variant (ADPDE) is proposed. Firstly, the dynamic population division mechanism based on individual potential value is presented to divide the population into two subgroups, effectively improving the population diversity. Secondly, a nonlinear reduction mechanism is designed to dynamically adjust the size of potential subgroup to allocate computing resources reasonably. Thirdly, two unique mutation strategies are adopted for two subgroups respectively to better utilise the effective information of potential individuals and ensure fast convergence speed. Finally, adaptive parameter setting methods of two subgroups further achieve the balance between exploration and exploitation. The effectiveness of improved strategies is verified on 21 classical benchmark functions. Then, to verify the overall performance of ADPDE, it is compared with three standard DE algorithms, eight excellent DE variants and seven advanced evolutionary algorithms on CEC2013, CEC2017 and CEC2020 test suites, respectively, and the results show that ADPDE has higher accuracy and faster convergence speed. Furthermore, ADPDE is compared with eight well-known optimizers and CEC2020 winner algorithms on nine real-world engineering optimization problems, and the results indicate ADPDE has the development potential for constrained optimization problems as well.},
  archive      = {J_IJMLC},
  author       = {Zuo, Wenlu and Gao, Yuelin},
  doi          = {10.1007/s13042-024-02361-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1701-1760},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Solving numerical and engineering optimization problems using a dynamic dual-population differential evolution algorithm},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image recoloring for multiple types of color vision deficiency. <em>IJMLC</em>, <em>16</em>(3), 1691-1700. (<a href='https://doi.org/10.1007/s13042-024-02360-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many techniques for recoloring images with different effects and improving color discrimination in patients with color vision defects. However, certain issues still persist, such as the unnatural and discordant colors of objects in the converted image. To address these problems, we have explored a comprehensive set of methods to achieve image recoloration. Our approach enables the resulting images to possess three essential characteristics: naturalness, harmonization, and distinguishability, thereby fulfilling the requirements of Color Vision Deficiency individuals. The method comprises two components: recommended palette generation and image recoloring. The former can learn the color distribution of different objects in nature, while the latter can recolor the image in conjunction with the recommended palette. Our experimental findings demonstrate that our approach is feasible and provides a direction for future research.},
  archive      = {J_IJMLC},
  author       = {Jin, Xin and Li, Dandan and Rong, Yiqing and Zou, Dongqing and Zhou, Wu and Zhang, Xiaokun},
  doi          = {10.1007/s13042-024-02360-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1691-1700},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Image recoloring for multiple types of color vision deficiency},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scnet: Shape-aware convolution with KFNN for point clouds completion. <em>IJMLC</em>, <em>16</em>(3), 1671-1690. (<a href='https://doi.org/10.1007/s13042-024-02359-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scanned 3D point cloud data is typically noisy and incomplete. Existing point cloud completion methods tend to learn a mapping of available parts to the complete one but ignore the structural relationships in local regions. They are less competent in learning point distributions and recovering the details of the object. This paper proposes a shape-aware point cloud completion network (SCNet) that employs multi-scale features and a coarse-to-fine strategy to generate detailed, complete point clouds. Firstly, we introduce a K-feature nearest neighbor algorithm to explore local geometric structure and design a novel shape-aware graph convolution that utilizes multiple learnable filters to perceive local shape changes in different directions. Secondly, we adopt non-local feature expansion to generate a coarse point cloud as the rough shape and merge it with the input data to preserve the original structure. Finally, we employ a residual network to fine-tune the point coordinates to smooth the merged point cloud, which is then optimized to a fine point cloud using a refinement module with shape-aware graph convolution and local attention mechanisms. Extensive experiments demonstrate that our SCNet outperforms other methods on the same point cloud completion benchmark and is more stable and robust.},
  archive      = {J_IJMLC},
  author       = {Wu, Xiangyang and Lu, Ziyuan and Qu, Chongchong and Zhou, Haixin and Miao, Yongwei},
  doi          = {10.1007/s13042-024-02359-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1671-1690},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Scnet: Shape-aware convolution with KFNN for point clouds completion},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing ocular diseases recognition with domain adaptive framework: Leveraging domain confusion. <em>IJMLC</em>, <em>16</em>(3), 1661-1669. (<a href='https://doi.org/10.1007/s13042-024-02358-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual health and optimal eyesight hold immense importance in our lives. However, ocular diseases can inflict emotional and financial hardships on patients and families. While various clinical methods exist for diagnosing ocular conditions, early screening of retinal images offers not only a cost-effective approach but also the detection of potential ocular diseases at earlier stages. Simultaneously, many studies have harnessed Convolutional Neural Networks (CNNs) for image recognition, capitalizing on their potential. Nevertheless, the applicability of most networks tends to be limited across different domains. When well-trained models from a domain are applied to another domain, a significant decline in accuracy might occur, thereby constraining the networks’ practical implementation and wider adoption. In this research endeavor, we present a domain adaptive framework, ResNet-50 with Maximum Mean Discrepancy (RMMD). Initially, we employed ResNet-50 architecture as a foundational network, a popular network used for modification and experimenting with whether a module could improve the accuracy. Additionally, we introduce the concept of Maximum Mean Discrepancy (MMD), a metric for quantifying domain differences. Subsequently, we integrate MMD into the loss function, inducing a state of confusion within the network concerning domain disparities. The outcomes derived from the OIA-ODIR dataset substantiate the efficacy of our proposed network. Our framework attains an impressive accuracy of 40.51% (F1) and 81.06% (AUC, Area Under the Receiver Operating Characteristic Curve), marking a notable enhancement of 9.52% and 7.18% respectively when juxtaposed with the fundamental ResNet-50 model, compared with raw ResNet-50 30.99% (F1) and 73.88% (AUC).},
  archive      = {J_IJMLC},
  author       = {Wang, Zayn},
  doi          = {10.1007/s13042-024-02358-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1661-1669},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhancing ocular diseases recognition with domain adaptive framework: Leveraging domain confusion},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLO-SDH: Improved YOLOv5 using scaled decoupled head for object detection. <em>IJMLC</em>, <em>16</em>(3), 1643-1660. (<a href='https://doi.org/10.1007/s13042-024-02357-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a crucial component of computer vision tasks, object detection serves a significant role in a variety of fields, including autonomous driving, defect detection, and remote sensing image recognition. However, the majority of current object detection networks fail to achieve a decent balance between detection accuracy and detection efficiency, and there is room for improvement in terms of detection accuracy. In response, to improve detection accuracy, a more efficient network framework, YOLO-SDH, was proposed in this paper based on You Only Look Once v5 (YOLOv5). In addition, a decoupled head that automatically adjusts the number of channels according to the model size was proposed, which can enhance the network’s detection effect by separating the classification and regression tasks.On the premise of requiring less computation, a lightweight deformable convolution module is proposed so that the convolution can extract ROI over a wider range, thereby enhancing the accuracy of the object detection network. Experiments were run on the datasets of PASCAL VOC2012, NEU-DET, AW, and RSOD. In comparison to the original YOLOv5, the mAP 0.5 of YOLO-SDH improved by 1.29–3.03%, the F1-score improved by 1.2–3.2%, the Precision improved by 0.7–4.2%, demonstrating the algorithm’s efficacy and superiority.},
  archive      = {J_IJMLC},
  author       = {Ren, Zhijie and Yao, Kang and Sheng, Silong and Wang, Beibei and Lang, Xianli and Wan, Dahang and Fu, Weiwei},
  doi          = {10.1007/s13042-024-02357-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1643-1660},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {YOLO-SDH: Improved YOLOv5 using scaled decoupled head for object detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight graph neural network architecture search based on heuristic algorithms. <em>IJMLC</em>, <em>16</em>(3), 1625-1641. (<a href='https://doi.org/10.1007/s13042-024-02356-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A graph neural network is a deep learning model for processing graph data. In recent years, graph neural network architectures have become more and more complex as the research progresses, thus the design of graph neural networks has become an important task. Graph Neural Architecture Search aims to automate the design of graph neural network architectures. However, current methods require large computational resources, cannot be applied in lightweight scenarios, and the search process is not transparent. To address these challenges, this paper proposes a graph neural network architecture search method based on a heuristic algorithm combining tabu search and evolutionary strategies (Gnas-Te). Gnas-Te mainly consists of a tabu search algorithm module and an evolutionary strategy algorithm module. The tabu Search Algorithm Module designs and implements for the first time the tabu Search Algorithm suitable for the search of graph neural network architectures, and uses the maintenance of the tabu table to guide the search process. The evolutionary strategy Algorithm Module implements the evolutionary strategy Algorithm for the search of architectures with the design goal of being light-weight. After the reflection and implementation of Gnas-Te, in order to provide an accurate evaluation of the neural architecture search process, a new metric EASI is proposed. Gnas-Te searched architecture is comparable to the excellent human-designed graph neural network architecture. Experimental results on three real datasets show that Gnas-Te has a 1.37% improvement in search accuracy and a 37.7% reduction in search time to the state-of-the-art graph neural network architecture search method for an graph node classification task and can find high allround-performance architectures which are comparable to the excellent human-designed graph neural network architecture. Gnas-Te implements a lightweight and efficient search method that reduces the need of computational resources for searching graph neural network structures and meets the need for high-accuracy architecture search in the case of insufficient computational resources.},
  archive      = {J_IJMLC},
  author       = {Zhao, ZiHao and Tang, XiangHong and Lu, JianGuang and Huang, Yong},
  doi          = {10.1007/s13042-024-02356-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1625-1641},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Lightweight graph neural network architecture search based on heuristic algorithms},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-refined variational transformer for image-conditioned layout generation. <em>IJMLC</em>, <em>16</em>(3), 1607-1624. (<a href='https://doi.org/10.1007/s13042-024-02355-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Layout generation is an emerging computer vision task that incorporates the challenges of object localization and aesthetic evaluation, widely used in advertisements, posters, and slides design. An ideal layout should consider both the intra-domain relationship within layout elements and the inter-domain relationship between layout elements and the image. However, most previous methods simply focus on image-content-agnostic layout generation without leveraging the complex visual information from the image. To address this limitation, we propose a novel paradigm called image-conditioned layout generation, which aims to add text overlays to an image in a semantically coherent manner. Specifically, we introduce the Image-Conditioned Variational Transformer (ICVT) that autoregressively generates diverse layouts in an image. Firstly, the self-attention mechanism is adopted to model the contextual relationship within layout elements, while the cross-attention mechanism is used to fuse the visual information of conditional images. Subsequently, we take them as building blocks of the conditional variational autoencoder (CVAE), which demonstrates attractive diversity. Secondly, to alleviate the gap between the layout elements domain and the visual domain, we design a Geometry Alignment module, in which the geometric information of the image is aligned with the layout representation. Thirdly, we present a self-refinement mechanism to automatically refine the failure case of generated layout, effectively improving the quality of generation. Experimental results show that our model can adaptively generate layouts in the non-intrusive area of the image, resulting in a harmonious layout design.},
  archive      = {J_IJMLC},
  author       = {Cao, Yunning and Liu, Chuanbin and Ma, Ye and Zhou, Min and Ge, Tiezheng and Jiang, Yuning and Xie, Hongtao},
  doi          = {10.1007/s13042-024-02355-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1607-1624},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Self-refined variational transformer for image-conditioned layout generation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Propagation tree says: Dynamic evolution characteristics learning approach for rumor detection. <em>IJMLC</em>, <em>16</em>(3), 1589-1605. (<a href='https://doi.org/10.1007/s13042-024-02354-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rapid spread of rumors on social media, which has a detrimental effect on our lives, it is becoming increasingly important to detect rumors. It has been proved that the study of dynamic graphs is helpful to capture the temporal change of information transmission and understand the evolution trend and pattern change of events. However, the dynamic learning methods currently studied do not fully consider the interaction characteristics of the evolutionary process. Therefore, it is difficult to fully capture the structural and semantic differences between them. In order to fully exploit the potential correlations of such temporal information, we propose a novel model named dynamic evolution characteristics learning (DECL) method for rumor detection. First, we partition the temporal snapshot sequences based on the propagation structure of rumors. Secondly, a multi-task graph contrastive learning method is adopted to enable the graph encoder to capture the essential features of rumors, and to fully explore the temporal structural differences and semantic similarities between true rumor and false rumor events. Experimental results on three real-world social media datasets confirm the effectiveness of our model for rumor detection tasks.},
  archive      = {J_IJMLC},
  author       = {Zhao, Shouhao and Ji, Shujuan and Lv, Jiandong and Fang, Xianwen},
  doi          = {10.1007/s13042-024-02354-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1589-1605},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Propagation tree says: Dynamic evolution characteristics learning approach for rumor detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised progressive graph neural network for enhanced multi-behavior recommendation. <em>IJMLC</em>, <em>16</em>(3), 1573-1588. (<a href='https://doi.org/10.1007/s13042-024-02353-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-behavior recommendation (MBR) aims to enhance the accuracy of predicting target behavior by considering multiple behaviors simultaneously. Recent researches have attempted to capture the dependencies within behavioral sequences to improve recommendation outcomes, exemplified by the sequential pattern “click $$\rightarrow $$ cart $$\rightarrow $$ buy”. However, their performances are still limited due to the following two problems. Firstly, potential leapfrogging relations among behaviors are underexplored, notably in cases where users purchase directly post-click, bypassing the cart stage. Skipping intermediate behavior allows for better modeling of real-world realities. Secondly, the uneven distribution of user behaviors and item popularity presents a challenge for model training, resulting in prevalence bias and over-reliance issues. To this end, we propose a self-supervised progressive graph neural network model, namely SSPGNN. The model can capture a broader range of behavioral dependencies by using a dual-behavior chain. In addition, we design a self-supervised learning mechanism, including intra- and inter-behavioral self-supervised learning, the former within a single behavior and the latter across multiple behaviors, to address the problems of prevalence bias and overdependence. Extensive experiments on real-world datasets and comparative analyses with state-of-the-art algorithms demonstrate the effectiveness of the proposed SSPGNN. The source codes of this work are available at https://github.com/ZZY-GraphMiningLab/SSPGNN .},
  archive      = {J_IJMLC},
  author       = {Liu, Tianhang and Zhou, Hui and Li, Chao and Zhao, Zhongying},
  doi          = {10.1007/s13042-024-02353-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1573-1588},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Self-supervised progressive graph neural network for enhanced multi-behavior recommendation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GRPIC: An end-to-end image captioning model using three visual features. <em>IJMLC</em>, <em>16</em>(3), 1559-1572. (<a href='https://doi.org/10.1007/s13042-024-02352-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {lmage captioning is a multimodal task involving both computer vision and natural language processing. Recently, there has been a substantial improvement in the performance of image captioning with the introduction of multi-feature extraction methods. However, existing single-feature and multi-feature methods still face challenges such as a low refinement degree, weak feature complementarity, and lack of an end-to-end model. To tackle these issues, we propose an end-to-end image captioning model called GRPIC (Grid-Region-Pixel Image Captioning), which integrates three types of image features: region features, grid features, and pixel features. Our model utilizes the Swin Transformer for extracting grid features, DETR for extracting region features, and Deeplab for extracting pixel features. We merge pixel-level features with region and grid features to extract more refined contextual and detailed information. Additionally, we incorporate absolute position information and pairwise align the three features to fully leverage their complementarity. Qualitative and quantitative experiments conducted on the MSCOCO dataset demonstrate that our model achieved a 2.3% improvement in CIDEr, reaching 136.1 CIDEr compared to traditional dual-feature methods on the Karpathy test split. Furthermore, observation of the actual generated descriptions shows that the model also produced more refined captions.},
  archive      = {J_IJMLC},
  author       = {Peng, Shixin and Xiong, Can and Liu, Leyuan and Yang, Laurence T. and Chen, Jingying},
  doi          = {10.1007/s13042-024-02352-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1559-1572},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {GRPIC: An end-to-end image captioning model using three visual features},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label distribution learning by utilizing common and label-specific feature fusion space. <em>IJMLC</em>, <em>16</em>(3), 1545-1558. (<a href='https://doi.org/10.1007/s13042-024-02351-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label Distribution Learning (LDL) is a novel machine learning paradigm that focuses on the description degrees of labels to a particular instance. Existing LDL algorithms generally learn with the original input space, that is, all features are simply employed in the discrimination processes of all class labels. However, this common-used data representation strategy ignores that each label is supposed to possess some specific characteristics of its own and therefore, may lead to sub-optimal performance. We propose label distribution learning by utilizing common and label-specific feature fusion space (LDL-CLSFS) in this paper. It first partitions all instances by label-value rankings. Second, it constructs label-specific features of each label by conducting clustering analysis on different instance categories. Third, it performs training and testing by querying the clustering results. Comprehensive experiments on several real-world label distribution data sets validate the superiority of our method against other LDL algorithms as well as the effectiveness of label-specific features.},
  archive      = {J_IJMLC},
  author       = {Zhang, Ziyun and Wang, Jing and Geng, Xin},
  doi          = {10.1007/s13042-024-02351-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1545-1558},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Label distribution learning by utilizing common and label-specific feature fusion space},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An ordered subsets orthogonal nonnegative matrix factorization framework with application to image clustering. <em>IJMLC</em>, <em>16</em>(3), 1531-1543. (<a href='https://doi.org/10.1007/s13042-024-02350-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonnegative matrix factorization (NMF) for image clustering attains impressive machine learning performances. However, the current iterative methods for optimizing NMF problems involve numerous matrix calculations and suffer from high computational costs in large-scale images. To address this issue, this paper presents an ordered subsets orthogonal NMF framework (OS-ONMF) that divides the data matrix in an orderly manner into several subsets and performs NMF on each subset. It balances clustering performance and computational efficiency. After decomposition, each ordered subset still contains the core information of the original data. That is, blocking does not reduce image resolutions but can greatly shorten running time. This framework is a general model that can be applied to various existing iterative update algorithms. We also provide a subset selection method and a convergence analysis of the algorithm. Finally, we conducted clustering experiments on seven real-world image datasets. The experimental results showed that the proposed method can greatly shorten the running time without reducing clustering accuracy.},
  archive      = {J_IJMLC},
  author       = {Ma, Limin and Tong, Can and Qi, Shouliang and Yao, Yudong and Teng, Yueyang},
  doi          = {10.1007/s13042-024-02350-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1531-1543},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An ordered subsets orthogonal nonnegative matrix factorization framework with application to image clustering},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clustered automated machine learning (CAML) model for clinical coding multi-label classification. <em>IJMLC</em>, <em>16</em>(3), 1507-1529. (<a href='https://doi.org/10.1007/s13042-024-02349-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical coding is a time-consuming task that involves manually identifying and classifying patients’ diseases. This task becomes even more challenging when classifying across multiple diagnoses and performing multi-label classification. Automated Machine Learning (AutoML) techniques can improve this classification process. However, no previous study has developed an AutoML-based approach for multi-label clinical coding. To address this gap, a novel approach, called Clustered Automated Machine Learning (CAML), is introduced in this paper. CAML utilizes the AutoML library Auto-Sklearn and cTAKES feature extraction method. CAML clusters binary diagnosis labels using Hamming distance and employs the AutoML library to select the best algorithm for each cluster. The effectiveness of CAML is evaluated by comparing its performance with that of the Auto-Sklearn model on five different datasets from the Medical Information Mart for Intensive Care (MIMIC III) database of reports. These datasets vary in size, label set, and related diseases. The results demonstrate that CAML outperforms Auto-Sklearn in terms of Micro F1-score and Weighted F1-score, with an overall improvement ratio of 35.15% and 40.56%, respectively. The CAML approach offers the potential to improve healthcare quality by facilitating more accurate diagnoses and treatment decisions, ultimately enhancing patient outcomes.},
  archive      = {J_IJMLC},
  author       = {Mustafa, Akram and Rahimi Azghadi, Mostafa},
  doi          = {10.1007/s13042-024-02349-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1507-1529},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Clustered automated machine learning (CAML) model for clinical coding multi-label classification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contextual feature fusion and refinement network for camouflaged object detection. <em>IJMLC</em>, <em>16</em>(3), 1489-1505. (<a href='https://doi.org/10.1007/s13042-024-02348-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged object detection (COD) is a challenging task due to its irregular shape and color similarity or even blending into the surrounding environment. It is difficult to achieve satisfactory results by directly using salient object detection methods due to the low contrast with the surrounding environment and obscure object boundary in camouflaged object detection. To determine the location of the camouflaged objects and achieve accurate segmentation, the interaction between features is essential. Similarly, an effective feature aggregation method is also very important. In this paper, we propose a contextual fusion and feature refinement network (CFNet). Specifically, we propose a multiple-receptive-fields-based feature extraction module (MFM) that obtains features from multiple scales of receptive fields. Then, the features are input to an attention-based information interaction module (AIM), which establishes the information flow between adjacent layers through an attention mechanism. Finally, the features are fused and optimized layer by layer using a feature fusion module (FFM). We validate the proposed CFNet as an effective COD model on four benchmark datasets, and the generalization ability of our proposed model is verified in the salient object detection task.},
  archive      = {J_IJMLC},
  author       = {Yang, Jinyu and Shi, Yanjiao and Jiang, Ying and Lu, Zixuan and Yi, Yugen},
  doi          = {10.1007/s13042-024-02348-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1489-1505},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Contextual feature fusion and refinement network for camouflaged object detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight skeleton-based action recognition model based on global–local feature extraction and fusion. <em>IJMLC</em>, <em>16</em>(3), 1477-1488. (<a href='https://doi.org/10.1007/s13042-024-02347-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton-based action recognition has become a research hotspot in the field of computer vision because of its lightweight and strong anti-interference. However, there are disadvantages such as single feature extraction, limited expression ability, and low recognition accuracy. To solve these problems, we propose a lightweight Skeleton-based action recognition model based on global–local feature extraction and fusion (GLF-GCN). GLF-GCN includes a Feature extraction of non-connected nodes Module (Global-GCN), a Feature extraction of adjacent nodes Module (Local-GCN), and a Dynamic Fusion module. More specifically, Global-GCN combines one-dimensional convolution and shift operations to capture spatio-temporal dependencies across global nodes, using shift operations as a replacement for spatio-temporal graph convolution to reduce computational complexity. Meanwhile, Local-GCN captures temporal and spatial local information from first-order neighboring nodes. On this basis, Dynamic Fusion integrates global information based on joint hierarchy and local information based on body parts to discern the varying dependency relationships among different body parts and joints, improving the model’s ability to interpret different skeleton action sequences. The experimental results on single stream and multi-stream data show that the proposed model has higher accuracy, which attains the state-of-the-art performance.},
  archive      = {J_IJMLC},
  author       = {Deng, Zhe and Wang, Yulin and Wei, Xing and Yang, Fan and Zhao, Chong and Lu, Yang},
  doi          = {10.1007/s13042-024-02347-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1477-1488},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Lightweight skeleton-based action recognition model based on global–local feature extraction and fusion},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual tracking with screening region enrichment and target validation. <em>IJMLC</em>, <em>16</em>(3), 1461-1475. (<a href='https://doi.org/10.1007/s13042-024-02346-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The introduction of the one-stream one-stage framework has led to remarkable advances in visual object tracking, resulting in exceptional tracking performance. Most existing one-stream one-stage tracking pipelines have achieved a relative balance between accuracy and speed. However, they focus solely on integrating feature learning and relational modelling. In complex scenes, the tracking performance often falls short due to confounding factors such as changes in target scale, occlusion, and fast motion. In these cases, numerous trackers cannot sufficiently exploit the target feature information and face the dilemma of information loss. To address these challenges, we propose a screening enrichment for transformer-based tracking. Our method incorporates a screening enrichment module as an additional processing operation in the integration of feature learning and relational modelling. The module effectively distinguishes target areas within the search regions. It also enriches the associations between tokens of target area information. In addition, we introduce our box validation module. This module uses the target position information from the previous frame to validate and revise the target position in the current frame. This process enables more accurate target localization. Through these innovations, we have developed a powerful and efficient tracker. It achieves state-of-the-art performance on six benchmark datasets, including GOT-10K, LaSOT, TrackingNet, UAV123, TNL2K and VOT2020. On the GOT-10K benchmarks, Specifically, on the GOT-10K benchmarks, our proposed tracker reaches an impressive Success Rate ( $$S{{R}_{0.5}}$$ ) of 85.4 and an Average Overlap (AO) of 75.3. Experimental results show that our proposed tracker outperforms other state-of-the-art trackers in terms of tracking accuracy.},
  archive      = {J_IJMLC},
  author       = {Sun, Yiqiu and Zhou, Dongming and Yan, Kaixiang},
  doi          = {10.1007/s13042-024-02346-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1461-1475},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Visual tracking with screening region enrichment and target validation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond traditional visual object tracking: A survey. <em>IJMLC</em>, <em>16</em>(2), 1435-1460. (<a href='https://doi.org/10.1007/s13042-024-02345-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single object tracking is a vital task of many applications in critical fields. However, it is still considered one of the most challenging vision tasks. In recent years, computer vision, especially object tracking, witnessed the introduction or adoption of many novel techniques, setting new fronts for performance. In this survey, we visit some of the cutting-edge techniques in vision, such as Sequence Models, Generative Models, Self-supervised Learning, Unsupervised Learning, Reinforcement Learning, Meta-Learning, Continual Learning, and Domain Adaptation, focusing on their application in single object tracking. We propose a novel categorization of single object tracking methods based on novel techniques and trends. Also, we conduct a comparative analysis of the performance reported by the methods presented on popular tracking benchmarks. Moreover, we analyze the pros and cons of the presented approaches and present a guide for non-traditional techniques in single object tracking. Finally, we suggest potential avenues for future research in single-object tracking.},
  archive      = {J_IJMLC},
  author       = {Abdelaziz, Omar and Shehata, Mohamed and Mohamed, Mohamed},
  doi          = {10.1007/s13042-024-02345-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1435-1460},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Beyond traditional visual object tracking: A survey},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grouping attributes: An accelerator for attribute reduction based on similarity. <em>IJMLC</em>, <em>16</em>(2), 1417-1433. (<a href='https://doi.org/10.1007/s13042-024-02344-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process of attribute reduction, the method of attribute selection holds significant importance. Different selection methods can significantly impact the efficiency and outcomes of attribute reduction. Presently, the common approach involves constructing a measure to evaluate the significance of attribute and subsequently selecting the optimal attribute to include in the reduction set based on this measure. However, most existing measures predominantly focus on the relationship between attributes and target concepts, overlooking the inter-relationships among attributes themselves. This paper defines the relationships between attributes based on the variation in significance and utilizes this concept to design a general algorithm for accelerating attribute reduction. Firstly, we introduce the concept of the similarity of attributes, where attributes exhibiting greater overlap in their classification abilities for the target set are deemed more similar. Subsequently, utilizing this concept, a cover is constructed over the original set of attributes. Then, an algorithm for accelerating attribute reduction is devised by integrating the constructed cover into a greedy attribute reduction algorithm. Finally, we conduct experiments on 12 UCI datasets. Compared to four benchmark algorithms, the proposed algorithm effectively reduces runtime while maintaining classification accuracy. The effectiveness of the algorithm is further validated using the Wilcoxon signed-rank test.},
  archive      = {J_IJMLC},
  author       = {Jia, Yunlong and Zhu, Ping},
  doi          = {10.1007/s13042-024-02344-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1417-1433},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Grouping attributes: An accelerator for attribute reduction based on similarity},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning cluster-wise label distribution for label enhancement. <em>IJMLC</em>, <em>16</em>(2), 1403-1415. (<a href='https://doi.org/10.1007/s13042-024-02343-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label enhancement (LE) refers to the process of recovering label distributions from logical labels for less ambiguity. Current LE techniques concentrate on learning each instance individually, which ignores the instance correlation. In this paper, we propose to learn a cluster-wise label distribution (CWLD) shared by all instances of the cluster to explore the instance correlation. The softmax-normalized sum of the CWLD and the logical label vector yields the label distribution. CWLD is learned in an iterative manner. Following instance clustering, the label distributions of all instances in each cluster are averaged. The asymmetric label correlation is then mined using heat conduction. This process is repeated until the label distribution has reached a point of convergence. Experiments were undertaken on thirteen real-world datasets compared with six state-of-the-art algorithms. Results demonstrate the effectiveness and superiority of our proposed method.},
  archive      = {J_IJMLC},
  author       = {Fan, Jun and Zhang, Heng-Ru and Min, Fan},
  doi          = {10.1007/s13042-024-02343-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1403-1415},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning cluster-wise label distribution for label enhancement},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relevance-aware visual entity filter network for multimodal aspect-based sentiment analysis. <em>IJMLC</em>, <em>16</em>(2), 1389-1402. (<a href='https://doi.org/10.1007/s13042-024-02342-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal aspect-based sentiment analysis, which aims to identify the sentiment polarities over each aspect mentioned in an image-text pair, has sparked considerable research interest in the field of multimodal analysis. Despite existing approaches have shown remarkable results in incorporating external knowledge to enhance visual entity information, they still suffer from two problems: (1) the image-aspect global relevance. (2) the entity-aspect local alignment. To tackle these issues, we propose a Relevance-Aware Visual Entity Filter Network (REF) for MABSA. Specifically, we utilize the nouns of ANPs extracted from the given image as bridges to facilitate cross-modal feature alignment. Moreover, we introduce an additional “UNRELATED” marker word and utilize Contrastive Content Re-sourcing (CCR) and Contrastive Content Swapping (CCS) constraints to obtain accurate attention weight to identify image-aspect relevance for dynamically controlling the contribution of visual information. We further adopt the accurate reversed attention weight distributions to selectively filter out aspect-unrelated visual entities for better entity-aspect alignment. Comprehensive experimental results demonstrate the consistent superiority of our REF model over state-of-the-art approaches on the Twitter-2015 and Twitter-2017 datasets.},
  archive      = {J_IJMLC},
  author       = {Chen, Yifan and Xiong, Haoliang and Li, Kuntao and Mai, Weixing and Xue, Yun and Cai, Qianhua and Li, Fenghuan},
  doi          = {10.1007/s13042-024-02342-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1389-1402},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Relevance-aware visual entity filter network for multimodal aspect-based sentiment analysis},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncovering hidden patterns: Low-rank label correlations for multi-label weak-label learning. <em>IJMLC</em>, <em>16</em>(2), 1371-1387. (<a href='https://doi.org/10.1007/s13042-024-02341-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label learning has emerged as a prominent research area in machine learning, as each instance can be associated with multiple class labels. However, many multi-label learning algorithms assume that the label space is complete, whereas in real-world applications, we often only have access to partial label information. To address this issue, we propose a novel Multi-label Weak-label learning algorithm via Low-rank Label correlations (MW2L). First, we propagate the structural and semantic information from the feature space to the label space to effectively capture label-related information and recover lost labels. Second, we incorporate global and local low-rank label correlation information to ensure that the label-related matrix is informative. Last, we use label correlations to supplement the original weak-label matrix and form a unified learning framework. We evaluate the performance of our approach on several benchmark datasets and show that it outperforms state-of-the-art methods in terms of accuracy and robustness to weak-label noise. The proposed approach can effectively handle incomplete and noisy weak labels in multi-label learning and outperforms existing methods.},
  archive      = {J_IJMLC},
  author       = {Li, Tianli and Nasrudin, Mohammad Faidzul and Zhao, Dawei and Chen, Fei and Peng, Xing and Sarim, Hafiz Mohd},
  doi          = {10.1007/s13042-024-02341-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1371-1387},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Uncovering hidden patterns: Low-rank label correlations for multi-label weak-label learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new neural network method for solving bratu type equations with rational polynomials. <em>IJMLC</em>, <em>16</em>(2), 1355-1369. (<a href='https://doi.org/10.1007/s13042-024-02340-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Bratu-type equation is a fundamental differential equation with numerous applications in engineering fields, such as radiative heat transfer, thermal reaction, and nanotechnology. This paper introduces a novel approach known as the rational polynomial neural network. In this approach, rational orthogonal polynomials are utilized within the neural network’s hidden layer. To solve the equation, the initial boundary value conditions of both the differential equation and the rational polynomial neural network are integrated into the construction of the numerical solution. This construction transforms the Bratu-type equation into a set of nonlinear equations, which are subsequently solved using an appropriate optimization technique. Finally, three sets of numerical examples are presented to validate the efficacy and versatility of the proposed rational orthogonal neural network method, with comparisons made across different hyperparameters. Furthermore, the experimental results are juxtaposed against traditional methods such as the Adomian decomposition method, genetic algorithm, Laplace transform method, spectral method, and multilayer perceptron, our method exhibits consistently optimal performance.},
  archive      = {J_IJMLC},
  author       = {He, Jilong and Cao, Cong},
  doi          = {10.1007/s13042-024-02340-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1355-1369},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A new neural network method for solving bratu type equations with rational polynomials},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pixel-patch combination loss for refined edge detection. <em>IJMLC</em>, <em>16</em>(2), 1341-1354. (<a href='https://doi.org/10.1007/s13042-024-02338-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a fundamental image characteristic, edge features encapsulate a wealth of information, serving as a crucial foundation in image segmentation networks for accurately delineating and partitioning object edges. Convolutional neural networks (CNNs) have gained prominence recently, finding extensive utility in edge detection. Previous methods primarily emphasized edge prediction accuracy, ignoring edge refinement. In this work, we introduce a novel encoder-decoder architecture that effectively harnesses hierarchical features. By extending the decoder horizontally, we progressively enhance resolution to preserve intricate details from the original image, thereby producing sharp edges. Additionally, we propose a novel loss function named the Pixel-Patch Combination Loss (P2CL), which employs distinct detection strategies in edge and non-edge regions to bolster network accuracy and yield crisp edges. Furthermore, considering the practicality of the algorithm, our method strikes a fine balance between accuracy and model size. It delivers precise and sharp edges while ensuring efficient model operation, thereby laying a robust foundation for advancements deployed on mobile devices or embedded systems. Our method was evaluated on three publicly available datasets, including BSDS500, Multicue, and BIPED. The experimental results show the superiority of our approach, achieving a competitive ODS F-score of 0.832 on the BSDS500 benchmark and significantly enhancing edge detection accuracy.},
  archive      = {J_IJMLC},
  author       = {Li, Wenlin and Zhang, Wei and Liu, Yanyan and Liu, Changsong and Jing, Rudong},
  doi          = {10.1007/s13042-024-02338-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1341-1354},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Pixel-patch combination loss for refined edge detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal 6-DoF object pose tracking: Integrating spatial cues with monocular RGB imagery. <em>IJMLC</em>, <em>16</em>(2), 1327-1340. (<a href='https://doi.org/10.1007/s13042-024-02336-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate six degrees of freedom (6-DoF) pose estimation is crucial for robust visual perception in fields such as smart manufacturing. Traditional RGB-based methods, though widely used, often face difficulties in adapting to dynamic scenes, understanding contextual information, and capturing temporal variations effectively. To address these challenges, we introduce a novel multi-modal 6-DoF pose estimation framework. This framework uses RGB images as the primary input and integrates spatial cues, including keypoint heatmaps and affinity fields, through a spatially aligned approach inspired by the Trans-UNet architecture. Our multi-modal method enhances both contextual understanding and temporal consistency. Experimental results on the Objectron dataset demonstrate that our approach surpasses existing algorithms across most categories. Furthermore, real-world tests confirm the accuracy and practical applicability of our method for robotic tasks, such as precision grasping, highlighting its effectiveness for real-world applications.},
  archive      = {J_IJMLC},
  author       = {Mei, Yunpeng and Wang, Shuze and Li, Zhuo and Sun, Jian and Wang, Gang},
  doi          = {10.1007/s13042-024-02336-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1327-1340},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-modal 6-DoF object pose tracking: Integrating spatial cues with monocular RGB imagery},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LWTD: A novel light-weight transformer-like CNN architecture for driving scene dehazing. <em>IJMLC</em>, <em>16</em>(2), 1303-1326. (<a href='https://doi.org/10.1007/s13042-024-02335-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of artificial intelligence and automation technology, interest in autonomous driving research is also growing. However, under heavy rain, fog, and other adverse weather conditions, the visual quality of the images is reduced due to suspended atmospheric particles that affect the vehicle’s visual perception system, which is not conducive to the autonomous driving system’s accurate perception of the road environment. To address these challenges, this article presents a computationally efficient end-to-end light-weight Transformer-like neural network called LWTD (Light-Weight Transformer-like DehazeNet) to reconstruct haze-free images for driving tasks, which based on the reformulated ASM theory without prior knowledge. First, a strategy for simplifying the atmospheric light and transmission map into a feature map is adopted, a CMT (Convolutional Mapping Transformer) module for the extraction of global features is developed, and the hazy image is decomposed into a base layer (global features) and a detail layer (local features) for Low-Level, Medium-Level, and High-Level stages. Meanwhile, a channel attention module is introduced to weigh and assign the weights of each feature, and to fuse them with the reformulated ASM (Atmospheric Scattering Model) model to restore the haze-free image. Second, a joint loss function of the graphical features is formulated to further direct the network to converge in the direction of abundant features. In addition, a dataset of real-world fog driving is constructed. Extensive experiments with synthetic and natural hazy images confirmed the superiority of the proposed method through quantitative and qualitative evaluations on various datasets. Furthermore, additional experiments validated the applicability of the proposed method for traffic participant detection and semantic segmentation tasks. The source code has been made publicly available on https://github.com/ZebGH/LWTD-Net.},
  archive      = {J_IJMLC},
  author       = {Zhang, Zhenbo and Feng, Zhiguo and Long, Aiqi and Wang, Zhiyu},
  doi          = {10.1007/s13042-024-02335-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1303-1326},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {LWTD: A novel light-weight transformer-like CNN architecture for driving scene dehazing},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relation extraction method based on pre-trained model and bidirectional semantic union. <em>IJMLC</em>, <em>16</em>(2), 1291-1302. (<a href='https://doi.org/10.1007/s13042-024-02334-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation extraction is an important task in natural language processing, which aims to extract the semantic relationships between entities from unstructured text. In traditional relation extraction methods, semantic, contextual and deep representation extraction are not sufficient. In this paper, we propose a relation extraction model (RoBBS, RoBERTa + Bi-GRU + Self Attention) based on pre-training and bi-directional semantic union. Firstly, the RoBERTa pre-training model is used to extracting the contextual features of distant sentences. Then Bi-GRU is leveraged to realize bidirectional semantic union, comprehensively extracting bidirectional semantic information. Combining this network with the attention mechanism allows for assigning greater weights to the semantic information that has a more significant role in determining the relationship classes of sentences. This, in turn, makes feature selection more efficient. Finally, the relationship is classified using the Softmax function. The experimental results show that the model achieves F-score of 89.02% on the SemEval2010 task8 dataset outperforming state-of-the-art models.},
  archive      = {J_IJMLC},
  author       = {He, Xinyu and Yan, Ge and Han, Xue and Kan, Manfei and Ren, Yonggong},
  doi          = {10.1007/s13042-024-02334-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1291-1302},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Relation extraction method based on pre-trained model and bidirectional semantic union},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A three-way decision method based on COPRAS in the weak probabilistic linguistic term set information systems. <em>IJMLC</em>, <em>16</em>(2), 1265-1290. (<a href='https://doi.org/10.1007/s13042-024-02333-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development and progress of technology, information becomes increasingly diverse, which poses higher demands on decision-making methods. Probabilistic linguistic term set (PLTS) is a tool that can more intuitively express the evaluations of decision makers (DMs). As a specialized form of PLTS with ignored probabilities, weak probabilistic linguistic term set (WPLTS) can describe incomplete or inaccurate evaluation information. Three-way decision (3WD) is an efficient decision-making method that reduces decision cost by adopting delayed decisions on the boundary domain. In this paper, we propose a novel 3WD method by combining 3WD with the complex proportional assessment (COPRAS) method under the WPLTS environment, named the WPLTS-3WD method. Firstly, we introduce the notion of the WPLTS information system. For a WPLTS information system, we propose a method of complementing the ignored probabilities and a new score function. Secondly, the objects are ranked by the COPRAS method. According to the ranking result, we define the dominance relation and dominance sets. Based on the dominance sets, the conditional probabilities can be estimated. By combining the conditional probabilities with relative loss functions, the expected losses will be obtained and the objects can be classified. Moreover, we propose two conversion functions that can convert real-valued and linguistic term evaluation information into PLTS evaluation information. Finally, we use the proposed WPLTS-3WD method to analyze the air quality of four cities. The rationality and advantages of our method are verified through experimental comparisons with other methods and parameter analysis.},
  archive      = {J_IJMLC},
  author       = {Yang, Hai-Long and Liu, Xu and Guo, Zhi-Lian},
  doi          = {10.1007/s13042-024-02333-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1265-1290},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A three-way decision method based on COPRAS in the weak probabilistic linguistic term set information systems},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 5G-SIID: An intelligent hybrid DDoS intrusion detector for 5G IoT networks. <em>IJMLC</em>, <em>16</em>(2), 1243-1263. (<a href='https://doi.org/10.1007/s13042-024-02332-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The constrained resources of Internet of Things (IoT) devices make them susceptible to Distributed Denial-of-Service (DDoS) attacks that disrupt service availability by overwhelming systems. Thus, effective intrusion detection is critical to ensuring uninterrupted IoT activities. This research presents a scalable system that combines machine and deep learning models with optimized data processing to secure IoT devices against DDoS attacks. A real-world 5G-IoT network simulation dataset was used to evaluate performance. Robust feature selection identified the 10 most informative features from the high-dimensional data. These features were used to train eight classifiers, namely: k-Nearest Neighbors (KNN), Naive Bayes (NB), Decision Tree (DT), Random Forest (RF), Multi-Layer Perceptron (MLP), Convolutional Neural Network (CNN), Long-Short-Term Memory (LSTM) and hybrid CNN-LSTM models for DDoS attack detection. Experiments demonstrated 99.99% and 99.98% accuracy for multiclass and binary classification using the proposed hybrid CNN-LSTM model. Crucially, time- and space-complexity analysis validates real-world feasibility. Unlike prior works, this system optimally balances accuracy, efficiency, and adaptability through a precisely engineered model architecture, outperforming existing models. In general, this accurate, efficient, and adaptable system addresses critical IoT security challenges, improving cyber resilience in smart cities and autonomous vehicles.},
  archive      = {J_IJMLC},
  author       = {Sadhwani, Sapna and Mathur, Aakar and Muthalagu, Raja and Pawar, Pranav M.},
  doi          = {10.1007/s13042-024-02332-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1243-1263},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {5G-SIID: An intelligent hybrid DDoS intrusion detector for 5G IoT networks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive consensus model for managing non-cooperative behaviors in portfolio optimization for large companies. <em>IJMLC</em>, <em>16</em>(2), 1219-1242. (<a href='https://doi.org/10.1007/s13042-024-02331-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mean–variance (MV) model provides numerous optimal portfolios for managing a firm's asset portfolio. Portfolio decisions in large corporations involve many interest groups, such as shareholders, bondholders, and employees, and require the assistance of large experts. However, experts from different departments with different cognitive levels and interests can differ or even conflict in their assessments of portfolios. To guarantee their interests, some experts may exhibit non-cooperative behavior, thus reducing the efficiency of reaching a consensus. To tackle this issue, the research aims to develop a large-scale group interactive portfolio optimization method that incorporates non-cooperative behaviors and leverages social network analysis (SN-LSGDM-NC-PO). First, various consensus feedback strategies based on minimum adjustment are formulated to provide advice during the negotiation process according to the global and local levels. Then, considering the acceptance of advice and the effect of expert adjustment on consensus, a new measure of non-cooperative behavior is designed. Non-cooperative behavior by experts can affect trust relations in a social network. Therefore, trust reward and penalty mechanisms, preference penalty mechanisms, and an exit mechanism are developed to manage different types of non-cooperative behavior. Experimental and comparison results demonstrate that the proposed SN-LSGDM-NC-PO algorithm can effectively manage the non-cooperative behaviors and reduce interaction consensus costs.},
  archive      = {J_IJMLC},
  author       = {Li, Danping and Hu, Shicheng},
  doi          = {10.1007/s13042-024-02331-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1219-1242},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An adaptive consensus model for managing non-cooperative behaviors in portfolio optimization for large companies},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight self-ensemble feedback recurrent network for fast MRI reconstruction. <em>IJMLC</em>, <em>16</em>(2), 1201-1218. (<a href='https://doi.org/10.1007/s13042-024-02330-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the speed of MRI acquisition is a key issue in modern medical practice. However, existing deep learning-based methods are often accompanied by a large number of parameters and ignore the use of deep features. In this work, we propose a novel Self-Ensemble Feedback Recurrent Network (SEFRN) for fast MRI reconstruction inspired by recursive learning and ensemble learning strategies. Specifically, a lightweight but powerful Data Consistency Residual Group (DCRG) is proposed for feature extraction and data stabilization. Meanwhile, an efficient Wide Activation Module (WAM) is introduced between different DCRGs to encourage more activated features to pass through the model. In addition, a Feedback Enhancement Recurrent Architecture (FERA) is designed to reuse the model parameters and deep features. Moreover, combined with the specially designed Automatic Selection and Integration Module (ASIM), different stages of the recurrent model can elegantly implement self-ensemble learning and synergize the sub-networks to improve the overall performance. Extensive experiments demonstrate that our model achieves competitive results and strikes a good balance between the size, complexity, and performance of the model.},
  archive      = {J_IJMLC},
  author       = {Li, Juncheng and Yang, Hanhui and Lui, Lok Ming and Zhang, Guixu and Shi, Jun and Zeng, Tieyong},
  doi          = {10.1007/s13042-024-02330-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1201-1218},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A lightweight self-ensemble feedback recurrent network for fast MRI reconstruction},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extended random forest for multivariate air quality forecasting. <em>IJMLC</em>, <em>16</em>(2), 1175-1199. (<a href='https://doi.org/10.1007/s13042-024-02329-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, an extended random forest algorithm for multivariate time series several steps forecasting is proposed. Peoposed method consists input layer and hidden layers involves random forest. In addition, a new algorithm is proposed in the third step to an ensemble of the tree’s outputs with the concept of correlation with the final results to reduce redundancy. In the output layer, a new algorithm is proposed to learn the weight of each random forest tree to calculate the result. Beijing PM25 and Italian air quality, were used to evaluate the proposed method. The results of the proposed method in this research were compared with the other state-of-the-art methods like deep learning and deep forest. We evaluated our proposed model based on evaluation metrics RMSE, MAE and MAPE and achieved good results. According to the results, the proposed method on the Beijing PM2.5 dataset’s RMSE and MAE value respectively are 40.97 and 24.81 for the average forecast for the next 1–6 h, 2.51 and 0.48 less than the best of the others. The average forecast for the next 1–3 h are 2.71 and 1.42 less than the best value of the others and are equal to 31.64 and 18.09. On the Italian air quality dataset, the RMSE, MAE and MAPE value for the next 1-h forecast are 0.6109, 0.4224 and 33.80 and better than the others.},
  archive      = {J_IJMLC},
  author       = {mirzadeh, Hossein and omranpour, Hesam},
  doi          = {10.1007/s13042-024-02329-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1175-1199},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Extended random forest for multivariate air quality forecasting},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced side information fusion framework for sequential recommendation. <em>IJMLC</em>, <em>16</em>(2), 1157-1173. (<a href='https://doi.org/10.1007/s13042-024-02328-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion of side information in sequential recommendation (SR) is a recommendation system technique that combines a user’s historical behavior sequence with additional side information to provide more accurate personalized recommendations. Recent methods are based on self-attention mechanisms, incorporating side information as part of the attention matrix to update item representations. We believe that the integration method via self-attention mechanisms does not fully utilize side information. Therefore, we designed a new Enhanced Side Information Fusion framework (ESIF) for sequential recommendations. Specifically, we have altered the fusion strategy by using an attention matrix to simultaneously update the representations of items and side information, thereby increasing the use of side information. The attention matrix serves to balance various features, ensuring effective utilization of side information throughout the fusion process. We designed a Gated Linear Representation Fusion Module, comprising linear transformations and gated units. The linear transformation processes the input data, while the gated unit dynamically adjusts the degree of information flow based on the input. This module then combines the updated item representation with the side information representation for more efficient use of side information. Additionally, user interaction behavior data inevitably contains noise. The presence of noise can disrupt the model’s performance, affecting the accuracy and reliability of the results. Therefore, we introduced a denoising module in ESIF to enhance recommendation accuracy by reducing noise. Our experimental results demonstrate that ESIF achieves superior performance across five real-world datasets, surpassing the current state-of-the-art side information fusion SR models.},
  archive      = {J_IJMLC},
  author       = {Su, Zheng-Ang and Zhang, Juan and Fang, Zhijun and Gao, Yongbin},
  doi          = {10.1007/s13042-024-02328-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1157-1173},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhanced side information fusion framework for sequential recommendation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph neural network based time estimator for SAT solver. <em>IJMLC</em>, <em>16</em>(2), 1145-1156. (<a href='https://doi.org/10.1007/s13042-024-02327-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {SAT-based formal verification is a systematic process to prove the correctness of computer hardware design based on formal specifications, providing an alternative to time-consuming simulations and ensuring design reliability and accuracy. Predicting the runtime of SAT solvers is important to effectively allocate verification resources and determine if the verification can be completed within time limits. Predicting SAT solver runtime is challenging due to variations in solving time across different solvers and dependence on problem complexity and solver mechanisms. Existing approaches rely on feature engineering and machine learning, but they have drawbacks in terms of expert knowledge requirements and time-consuming feature extraction. To address this, using graph neural networks (GNNs) for runtime prediction is considered, as they excel in capturing graph topology and relationships. However, directly applying existing GNNs to predict SAT solver runtime does not yield satisfactory results, as SAT solvers’ proving procedure is crucial. In this paper, we propose a novel model, TESS, that integrates the working mechanism of SAT solvers with graph neural networks (GNNs) for predicting solving time. The model incorporates a graph representation inspired by the CDCL paradigm, proposes adaptive aggregation for multilayer information and separate modules for conflict learning. Experimental results on multiple datasets validate the effectiveness, scalability, and robustness of our model, outperforming baselines in SAT solver runtime prediction.},
  archive      = {J_IJMLC},
  author       = {Liu, Jiawei and Xiao, Wenyi and Cheng, Hongtao and Shi, Chuan},
  doi          = {10.1007/s13042-024-02327-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1145-1156},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Graph neural network based time estimator for SAT solver},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design your own universe: A physics-informed agnostic method for enhancing graph neural networks. <em>IJMLC</em>, <em>16</em>(2), 1129-1144. (<a href='https://doi.org/10.1007/s13042-024-02326-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-informed Graph Neural Networks have achieved remarkable performance in learning through graph-structured data by mitigating common GNN challenges such as over-smoothing, over-squashing, and heterophily adaption. Despite these advancements, the development of a simple yet effective paradigm that appropriately integrates previous methods for handling all these challenges is still underway. In this paper, we draw an analogy between the propagation of GNNs and particle systems in physics, proposing a model-agnostic enhancement framework. This framework enriches the graph structure by introducing additional nodes and rewiring connections with both positive and negative weights, guided by node labeling information. We theoretically verify that GNNs enhanced through our approach can effectively circumvent the over-smoothing issue and exhibit robustness against over-squashing. Moreover, we conduct a spectral analysis on the rewired graph to demonstrate that the corresponding GNNs can fit both homophilic and heterophilic graphs. Empirical validations on benchmarks for homophilic, heterophilic graphs, and long-term graph datasets show that GNNs enhanced by our method significantly outperform their original counterparts.},
  archive      = {J_IJMLC},
  author       = {Shi, Dai and Han, Andi and Lin, Lequan and Guo, Yi and Wang, Zhiyong and Gao, Junbin},
  doi          = {10.1007/s13042-024-02326-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1129-1144},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Design your own universe: A physics-informed agnostic method for enhancing graph neural networks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A data-driven mixed integer programming approach for joint chance-constrained optimal power flow under uncertainty. <em>IJMLC</em>, <em>16</em>(2), 1111-1127. (<a href='https://doi.org/10.1007/s13042-024-02325-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel mixed integer programming (MIP) reformulation for the joint chance-constrained optimal power flow problem under uncertain load and renewable energy generation. Unlike traditional models, our approach incorporates a comprehensive evaluation of system-wide risk without decomposing joint chance constraints into individual constraints, thus preventing overly conservative solutions and ensuring robust system security. A significant innovation in our method is the use of historical data to form a sample average approximation that directly informs the MIP model, bypassing the need for distributional assumptions to enhance solution robustness. Additionally, we implement a model improvement strategy to reduce the computational burden, making our method more scalable for large-scale power systems. Our approach is validated against benchmark systems, i.e., IEEE 14-, 57- and 118-bus systems, demonstrating superior performance in terms of cost-efficiency and robustness, with lower computational demand compared to existing methods.},
  archive      = {J_IJMLC},
  author       = {Qin, James Ciyu and Jiang, Rujun and Mo, Huadong and Dong, Daoyi},
  doi          = {10.1007/s13042-024-02325-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1111-1127},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A data-driven mixed integer programming approach for joint chance-constrained optimal power flow under uncertainty},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dap-SiMT: Divergence-based adaptive policy for simultaneous machine translation. <em>IJMLC</em>, <em>16</em>(2), 1091-1110. (<a href='https://doi.org/10.1007/s13042-024-02323-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of Simultaneous Machine Translation (SiMT), a robust read/write (R/W) policy is essential alongside a high-quality translation model. Traditional methods typically employ either a fixed wait-k policy in sync with a wait-k translation model or an adaptive policy that is co-developed with a dedicated translation model. This study introduces a more versatile approach by decoupling the adaptive policy from the translation model. Our rationale is based on the finding that an independent multi-path wait-k model, when combined with adaptive policies utilized in advanced SiMT systems, can perform competitively. Specifically, we present DaP, a divergence-based adaptive policy, which dynamically adjusts read/write decisions for any translation model, taking into account potential divergence in translation distributions resulting from future information. Extensive experiments across multiple benchmarks reveal that our method significantly enhances the balance between translation accuracy and latency, surpassing strong baselines.},
  archive      = {J_IJMLC},
  author       = {Zhao, Libo and Zeng, Ziqian},
  doi          = {10.1007/s13042-024-02323-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1091-1110},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dap-SiMT: Divergence-based adaptive policy for simultaneous machine translation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hierarchical dual-view model for fake news detection guided by discriminative lexicons. <em>IJMLC</em>, <em>16</em>(2), 1071-1090. (<a href='https://doi.org/10.1007/s13042-024-02322-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news detection aims to automatically identify the credibility of source posts, mitigating potential societal harm and conserving human resources. Textual fake news detection methods can be categorized into pattern- and fact-based. Pattern-based models focus on identifying shared writing patterns in source posts, while fact-based models leverage auxiliary external knowledge. Researchers have recently attempted to merge these two views into a comprehensive detection system, achieving superior performance to single-view methods. However, existing dual-view methods often prioritize integrating single-view methods over exploring nuanced characteristics of both perspectives. To address this, we propose a novel hierarchical dual-view model for fake news detection guided by discriminative lexicons. First, we construct two lexicons based on distinct word usage tendencies in fake and real news and further augment them with synonyms sourced from large language models. We then devise a hierarchical attention network to derive semantic representations for the source post, incorporating a lexicon attention loss to guide the prioritization of words from the two lexicons. Subsequently, a lexicon-guided interaction network is employed to model the relations between the source post and its relevant articles, assigning authenticity-aware weights to each article. Finally, the representations of source post and relevant articles are concatenated for joint detection. According to experimental results, our model outperforms many competitive baselines in terms of the macro F1 score ranging from 1.1% to 10.5% on Weibo and from 3.2% to 10.8% on Twitter.},
  archive      = {J_IJMLC},
  author       = {Yang, Sijia and Li, Xianyong and Du, Yajun and Huang, Dong and Chen, Xiaoliang and Fan, Yongquan and Wang, Shumin},
  doi          = {10.1007/s13042-024-02322-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1071-1090},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A hierarchical dual-view model for fake news detection guided by discriminative lexicons},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-stage zero-shot object detection network based on CLIP and pseudo-labeling. <em>IJMLC</em>, <em>16</em>(2), 1055-1070. (<a href='https://doi.org/10.1007/s13042-024-02321-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of unknown objects is a challenging task in computer vision because, although there are diverse real-world detection object categories, existing object-detection training sets cover a limited number of object categories . Most existing approaches use two-stage networks to improve a model’s ability to characterize objects of unknown classes, which leads to slow inference. To address this issue, we proposed a single-stage unknown object detection method based on the contrastive language-image pre-training (CLIP) model and pseudo-labelling, called CLIP-YOLO. First, a visual language embedding alignment method is introduced and a channel-grouped enhanced coordinate attention module is embedded into a YOLO-series detection head and feature-enhancing component, to improve the model’s ability to characterize and detect unknown category objects. Second, the pseudo-labelling generation is optimized based on the CLIP model to expand the diversity of the training set and enhance the ability to cover unknown object categories. We validated this method on four challenging datasets: MSCOCO, ILSVRC, Visual Genome, and PASCAL VOC. The results show that our method can achieve higher accuracy and faster speed, so as to obtain better performance of unknown object detection. The source code is available at https://github.com/BJUTsipl/CLIP-YOLO .},
  archive      = {J_IJMLC},
  author       = {Li, Jiafeng and Sun, Shengyao and Zhang, Kang and Zhang, Jing and Zhuo, Li},
  doi          = {10.1007/s13042-024-02321-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1055-1070},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Single-stage zero-shot object detection network based on CLIP and pseudo-labeling},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic configuration network modeling method based on information superposition and mixture correntropy. <em>IJMLC</em>, <em>16</em>(2), 1041-1054. (<a href='https://doi.org/10.1007/s13042-024-02320-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the generalizability and robustness of stochastic configuration networks (SCNs), this paper proposes a robust modeling method based on information superposition and mixture correntropy. First, the mapping information of the (sigmoid) activation function and its derivative function is superimposed, and the hidden layer parameters are randomly assigned through a supervisory mechanism to improve the diversity of the hidden layer mapping. Second, mixture correntropy is used to construct a robust loss function, and different Gaussian kernels are used to measure the contribution of training samples to suppress the negative impact of data noise on the accuracy of the model. Finally, the performance of the proposed modeling method is tested on functional approximation, four benchmark datasets, and historical data from the municipal solid waste incineration process. The experimental results show that the modeling method proposed in this paper has advantages in terms of generalizability and robustness.},
  archive      = {J_IJMLC},
  author       = {Yan, Aijun and Hu, Kaicheng and Wang, Dianhui},
  doi          = {10.1007/s13042-024-02320-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1041-1054},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Stochastic configuration network modeling method based on information superposition and mixture correntropy},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models for medicine: A survey. <em>IJMLC</em>, <em>16</em>(2), 1015-1040. (<a href='https://doi.org/10.1007/s13042-024-02318-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address challenges in the digital economy’s landscape of digital intelligence, large language models (LLMs) have been developed. Improvements in computational power and available resources have significantly advanced LLMs, allowing their integration into diverse domains for human life. Medical LLMs are essential application tools with potential across various medical scenarios. In this paper, we review LLM developments, focusing on the requirements and applications of medical LLMs. We provide a concise overview of existing models, aiming to explore advanced research directions and benefit researchers for future medical applications. We emphasize the advantages of medical LLMs in applications, as well as the challenges encountered during their development. Finally, we suggest directions for technical integration to mitigate challenges and potential research directions for the future of medical LLMs, aiming to meet the demands of the medical field better.},
  archive      = {J_IJMLC},
  author       = {Zheng, Yanxin and Gan, Wensheng and Chen, Zefeng and Qi, Zhenlian and Liang, Qian and Yu, Philip S.},
  doi          = {10.1007/s13042-024-02318-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {1015-1040},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Large language models for medicine: A survey},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-term time series forecasting based on siamese network: A perspective on few-shot learning. <em>IJMLC</em>, <em>16</em>(2), 999-1014. (<a href='https://doi.org/10.1007/s13042-024-02317-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The long-term time series forecasting (LTSF) plays a crucial role in various domains, utilizing a large amount of historical data to forecast trends over an extended future time range. However, in real-life scenarios, the performance of LTSF is often hindered by missing data. Few-shot learning aims to address the issue of data scarcity, but there is relatively little research on using few-shot learning to tackle sample scarcity in long-term time series forecasting tasks, and most few-shot learning methods rely on transfer learning. To address this problem, this paper proposes a Siamese network-based time series Transformer (SiaTST) for the task of LTSF in a few-shot setting. To increase the diversity of input scales and better capture local features in time series, we adopt a dual-level hierarchical input strategy. Additionally, we introduce a learnable prediction token (LPT) to capture global features of the time series. Furthermore, a feature fusion layer is utilized to capture dependencies among multiple variables and integrate information from different levels. Experimental results on 7 popular LSTF datasets demonstrate that our proposed model achieves state-of-the-art performance.},
  archive      = {J_IJMLC},
  author       = {Fan, Jin and Xiang, Jiaqian and Liu, Jie and Wang, Zheyu and Wu, Huifeng},
  doi          = {10.1007/s13042-024-02317-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {999-1014},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Long-term time series forecasting based on siamese network: A perspective on few-shot learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Color attention tracking with score matching. <em>IJMLC</em>, <em>16</em>(2), 983-997. (<a href='https://doi.org/10.1007/s13042-024-02316-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is an ordinary practice that deep networks are utilized to extract deep features from RGB images. Typically, the popular trackers adopt pre-trained ResNet as a backbone to extract target features, achieving excellent performance. Moreover, Staple has shown that color statistics have complementary cues, while the combination of color statistics and deep features in a unified deep framework has rarely been reported. Therefore, we employ color statistics to construct color attention maps, which are encoded into the deep network to guide the generation of target-aware feature maps. Additionally, DCF-based trackers have an online update module to dynamically update the tracking model, it is particularly necessary to collect reliable target samples. Hence, we refer to the template matching thought to design a score matching method, which is intended to score the tracked targets, this method has the advantage of considering the target extent. In this paper, we conduct sufficient ablation analyses on the color attention module and score matching method to verify their effectiveness. Furthermore, our approaches are combined into the DCF frameworks to construct two brand-new trackers, and both quantitative and qualitative results demonstrate that our trackers can perform favorably against recent and far more sophisticated trackers on multiple public benchmarks.},
  archive      = {J_IJMLC},
  author       = {He, Xuedong and Huang, Jiehui},
  doi          = {10.1007/s13042-024-02316-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {983-997},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Color attention tracking with score matching},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing automated street crime detection: A drone-based system integrating CNN models and enhanced feature selection techniques. <em>IJMLC</em>, <em>16</em>(2), 959-981. (<a href='https://doi.org/10.1007/s13042-024-02315-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a pioneering solution to the growing challenge of escalating global crime rates through the introduction of an automated drone-based street crime detection system. Leveraging advanced Convolutional Neural Network (CNN) models, the system integrates several key components for analyzing images captured by drones. Initially, the Embedding Bilateral Filter (EBF) technique divides images into base and detail layers to enhance detection accuracy. The fusion model, IR with attention-based Conv-ViT, combines Inception-V3, ResNet-50, and Convolution Vision Transformer (Conv-ViT) to capture both shape and texture details efficiently. Further enhancement is achieved through the Improved Shark Smell Optimization Algorithm (ISSOA), which optimizes feature selection and minimizes redundancy in image extraction. Additionally, a Multi-scale Contextual Semantic Guidance Network (MCS-GNet) ensures robust image classification by integrating features from multiple layers to prevent data loss. Evaluation on the UCF-Crime and UCSD Ped2 datasets demonstrates superior accuracy, with remarkable results of 0.783 and 0.974, respectively. This innovative approach offers a promising solution to the arduous and continuous task of monitoring security camera feeds for suspicious activities, thereby addressing the pressing need for automated crime detection systems on a global scale.},
  archive      = {J_IJMLC},
  author       = {Vuyyuru, Lakshma Reddy and Purimetla, NagaMalleswara Rao and Reddy, Kancharakunt Yakub and Vellela, Sai Srinivas and Basha, Sk Khader and Vatambeti, Ramesh},
  doi          = {10.1007/s13042-024-02315-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {959-981},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Advancing automated street crime detection: A drone-based system integrating CNN models and enhanced feature selection techniques},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale frequency domain learning for texture classification. <em>IJMLC</em>, <em>16</em>(2), 947-958. (<a href='https://doi.org/10.1007/s13042-024-02314-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, methods for modeling images in frequency domain have attracted widespread attention. Frequency methods transform image into spectrum as model input by defining a set of basis functions, where each point in frequency domain represents image’s projection at the corresponding frequency, which helps to understand structure, texture, and other basic features of the image. Studies have shown that frequency learning methods based on fixed small-scale Discrete Cosine Transform (DCT) basis functions outperform spatial domain methods. However, frequency learning also faces the challenge of feature saturation bottleneck, particularly fixed DCT basis functions makes the frequency learning model more prone to reaching saturation. Therefore, we propose a multi-scale frequency domain learning approach that utilizes multi-scale DCT basis functions to extract diversified frequency features. Our method employs sampling and cropping techniques to extend the frequency features from a single-scale DCT basis functions mapping to a multi-scale mapping. This ensures that the image projection exists at as many frequencies as possible so that advanced features can be extracted over multiple frequency ranges to overcome the saturation bottleneck of network models. Experimental results demonstrate the superior performance of our approach in texture classification tasks.},
  archive      = {J_IJMLC},
  author       = {Zang, Liguang and Li, Yuancheng},
  doi          = {10.1007/s13042-024-02314-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {947-958},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-scale frequency domain learning for texture classification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient federated learning with cross-resource client collaboration. <em>IJMLC</em>, <em>16</em>(2), 931-945. (<a href='https://doi.org/10.1007/s13042-024-02313-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a distributed machine learning paradigm. Traditional federated learning performs well on the premise that all clients have the same learning ability or similar learning tasks. However, resource and data heterogeneity are inevitable among clients in real-world scenarios, leading to the situation that existing federated learning mechanisms cannot achieve high accuracy in short response time. In this study, an effective federated learning framework with cross-resource client collaboration, termed CEFL, is proposed to coordinate clients with different capacities to help each other, efficiently and adequately reflecting collective intelligence. Clients are categorized into different clusters based on their computational resources in the hierarchical framework. Resource-rich clusters use their knowledge to assist resource-limited clusters converge rapidly. Once resource-limited clusters have the ability to mentor others, resource-rich clusters learn from the resource-limited clusters in their favor to improve their own effectiveness. A cloud server provides tailored assistance to each cluster with a personalized model through an adaptive multi-similarity metric, in order for each cluster to learn the most useful knowledge. The experiments fully demonstrate that the proposed method not only has superior accuracy with significantly reduced latency but also improves the convergence rate compared to other state-of-the-art federated learning methods in addressing the problem of resource and data heterogeneity.},
  archive      = {J_IJMLC},
  author       = {Shen, Qi and Yang, Liu},
  doi          = {10.1007/s13042-024-02313-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {931-945},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Efficient federated learning with cross-resource client collaboration},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-enhanced recommendation via dynamic co-attention and high-order connectivity. <em>IJMLC</em>, <em>16</em>(2), 919-930. (<a href='https://doi.org/10.1007/s13042-024-02312-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph (KG) based recommender systems have shown promise in improving accuracy and interpretability. They reveal the intrinsic relationships of knowledge through the associations and paths between entities for personalized recommendations. However, existing approaches do not adequately consider the high-order connections between neighboring nodes in the relational graph, resulting in a lack of sufficient capture of structured information. In this paper, we propose a knowledge-enhanced recommendation model via dynamic co-attention and high-order connectivity (DCHC) to address this issue. First, we construct a hybrid graph by aligning users and items in the user-item bipartite graph with entities in the KG. As a result, we are able to simultaneously consider the interaction between users and items as well as the entity information in the KG, thereby gaining a more comprehensive understanding of user behavior and interests. Second, we explicitly model the high-order connections between entities through the hybrid structured graphs in an end-to-end manner. Therefore, we not only explored the complex interactive relationships between entities but also ensured the accurate capture of structural information in the graph. Third, we employ a dynamic co-attention mechanism to enhance the representation of users and items, effectively exploiting the potential correlation between them. We therefore effectively exploited the potential correlation between users and items and successfully integrating these relationships into their representations. Extensive experiments conducted on three benchmarks demonstrate that DCHC outperforms state-of-the-art KG-based recommendation methods.},
  archive      = {J_IJMLC},
  author       = {Wang, Dan-Dong and Min, Fan},
  doi          = {10.1007/s13042-024-02312-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {919-930},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Knowledge-enhanced recommendation via dynamic co-attention and high-order connectivity},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial recurrent neural network coordinated secured transmission towards safeguarding confidentiality in smart industrial internet of things. <em>IJMLC</em>, <em>16</em>(2), 891-917. (<a href='https://doi.org/10.1007/s13042-024-02310-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research introduces a new method to tackle the issue of exchanging cryptographic keys in the Industrial Internet of Things (IIoT). This study focuses on the inefficiency and lengthy evaluation procedures of conventional cryptographic key exchange algorithms, which are not appropriate for the rapid and constantly changing IIoT device environment. In the solution domain, the proposed approach uses synchronization of neural networks with vector valued and Recurrent Neural Networks (RNNs), merging drive-response mechanisms to enhance speed and efficiency in crucial operations. The research examines the influence of postponements on the generating arbitrary inputs and coordination challenges in RNNs that incorporate drive-response mechanisms for synchronized input vector creation. This article explains an elementary evaluation of coordination in Artificial Neural Networks (ANNs) by utilizing an RNN framework to structure ANNs for sharing session keys. The study provides multiple contributions: (1) employing the polynomial coordination technique to generate coordinated inputs for the ANN synchronization process using RNNs, (2) using Lyapunov formulas and inequality assessment methods to identify required control parameters and time-varying conditions for achieving synchronization in the drive-response systems proposed with polynomial and non-polynomial functions, (3) demonstrating the connection between polynomial and non-polynomial synchronization with numerical illustrations, and (4) designing symmetric layouts of ANNs to create a session keys in the IIoT network. The suggested technique outperforms existing methods in the literature by offering a quicker, more dependable solution for cryptographic key exchange, paving the way for improved and secure industrial applications. This new method not only fixes current inefficiencies but also paves the way for future improvements in secure communication in the IIoT environment.},
  archive      = {J_IJMLC},
  author       = {Sarkar, Arindam and Singh, Moirangthem Marjit and Sharma, Hanjabam Saratchandra},
  doi          = {10.1007/s13042-024-02310-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {891-917},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Artificial recurrent neural network coordinated secured transmission towards safeguarding confidentiality in smart industrial internet of things},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-dynamic residual graph convolutional network with global feature enhancement for traffic flow prediction. <em>IJMLC</em>, <em>16</em>(2), 873-889. (<a href='https://doi.org/10.1007/s13042-024-02307-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key to achieving an accurate and reliable traffic flow prediction lies in modeling the complex and dynamic correlations among sensors. However, existing studies ignore the fact that such correlations are influenced by multiple dynamic factors and the original sequence features of the traffic data, which limits the deep modeling of such correlations and leads to a biased understanding of such correlations. The extraction strategies for global features are less developed, which has degraded the reliability of the predictions. In this study, a novel multi-dynamic residual graph convolutional network with global feature enhancement is proposed to solve these problems and achieve an accurate and reliable traffic flow prediction. First, multiple graph generators are proposed, which fully preserve the original sequence features of the traffic data and enable layered depth-wise modeling of the dynamic correlations among sensors through a residual mechanism. Second, an output module is proposed to explore extraction strategies for global features, by employing a residual mechanism and parameter sharing strategy to maintain the consistency of the global features. Finally, a new layered network architecture is proposed, which not only leverages the advantages of both static and dynamic graphs, but also captures the spatiotemporal dependencies among sensors. The superiority of the proposed model has been verified through extensive experiments on two real-world datasets.},
  archive      = {J_IJMLC},
  author       = {Li, Xiangdong and Yin, Xiang and Huang, Xiaoling and Liu, Weishu and Zhang, Shuai and Zhang, Dongping},
  doi          = {10.1007/s13042-024-02307-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {873-889},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-dynamic residual graph convolutional network with global feature enhancement for traffic flow prediction},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RHGNN: Imposing relational inductive bias for heterogeneous graph neural network. <em>IJMLC</em>, <em>16</em>(2), 855-871. (<a href='https://doi.org/10.1007/s13042-024-02305-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous graph data are ubiquitous and extracting information from them is increasingly crucial. Existing approaches for modeling heterogeneous graphs often rely on the splitting strategy guided by meta-paths or relations. However, the splitting strategy falls short in capturing the rich semantic information and topological structure of heterogeneous graphs comprehensively, as well as the hidden semantic associations between various edge types. Moreover, establishing meta-paths for heterogeneous graphs requires substantial expert experience and domain knowledge, making the process time-consuming, laborious, and often inaccurate. To address these challenges, we propose a novel heterogeneous graph neural network called RHGNN, which overcomes the reliance on meta-paths by modeling the heterogeneous graph as a whole instead of splitting it, and jointly obtains personalized feature representations for nodes and edges. Specifically, we first introduce the pre-training strategy Type2vec to learn feature representations of edge types and extract the semantic and structural information of the entire heterogeneous graph. Then we view the heterogeneous graph as a homogeneous one, and design a new information propagation and aggregation mechanism for both nodes and edges to learn their representations. Based on the assumption that edges with the same type have similar representations, we introduce an explicit regularization method based on the relational inductive bias to impose smoothness constraints on the model. Experimental results demonstrate that RHGNN significantly outperforms state-of-the-art models on both node-level and edge-level tasks.},
  archive      = {J_IJMLC},
  author       = {Zhu, Shichao and Zhang, Shuai and Liu, Yang and Zhou, Chuan and Pan, Shirui and Li, Zhao and Chen, Hongyang},
  doi          = {10.1007/s13042-024-02305-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {855-871},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {RHGNN: Imposing relational inductive bias for heterogeneous graph neural network},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection and analysis of android malwares using hybrid dual path bi-LSTM kepler dynamic graph convolutional network. <em>IJMLC</em>, <em>16</em>(2), 835-853. (<a href='https://doi.org/10.1007/s13042-024-02303-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In past decade, the android malware threats have been rapidly increasing with the widespread usage of internet applications. In respect of security purpose, there are several machine learning techniques attempted to detect the malwares effectively, but failed to achieve the accurate detection due to increasing number of features, more time consumption decreases in detection efficiency. To overcome these limitations, in this research work an innovative Hybrid dual path Bidirectional long short-term memory Kepler dynamic graph Convolutional Network (HBKCN) is proposed to analyze and detect android malwares effectively. First, the augmented abstract syntax tree is applied for pre-processing and extracts the string function from each malware. Second, the adaptive aphid ant optimization is utilized to choose the most appropriate features and remove irrelevant features. Finally, the proposed HBKCN classifies benign and malware apps based on their specifications. Four benchmark datasets, namely Drebin, VirusShare, Malgenome -215, and MaMaDroid datasets, are employed to estimate the effectiveness of the technique. The result demonstrates that the HBKCN technique achieved excellent performance with respect to a few important metrics compared to existing methods. Moreover, detection accuracies of 99.2%, 99.1%,99.8% and 99.8% are achieved for the considered datasets, respectively. Also, the computation time is greatly reduced, illustrating the efficiency of the proposed model in identifying android malwares.},
  archive      = {J_IJMLC},
  author       = {Lingayya, Sadananda and Kulkarni, Praveen and Salins, Rohan Don and Uppoor, Shruthi and Gurudas, V. R.},
  doi          = {10.1007/s13042-024-02303-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {835-853},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Detection and analysis of android malwares using hybrid dual path bi-LSTM kepler dynamic graph convolutional network},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reciprocal interlayer-temporal discriminative target model for robust visual tracking. <em>IJMLC</em>, <em>16</em>(2), 819-834. (<a href='https://doi.org/10.1007/s13042-024-02296-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most Siamese algorithms take little account of the information interaction between the target and search region, leading to tracking results that are often disturbed by the cumulative effect of target-like distractors between layers. In this paper, we propose a reciprocal interlayer-temporal discriminative target model for robust visual tracking. Firstly, an interlayer target-aware enhancement model is constructed, which establishes pixel-by-pixel correlation between the template and search region to achieve interlayer feature information interaction. This alleviates the cumulative error caused by the blindness of the target to search region during feature extraction, enhancing target perception. Secondly, to weaken the impact of interference, a temporal interference evaluation strategy is designed. It utilizes the interframe candidate propagation module to build associations among multi-candidates in the current frame and the previous frame. Then, the similar distractors are eliminated by using object inference constraint, so as to obtain a more accurate target location. Finally, we integrate the interlayer target-aware enhancement model and temporal interference evaluation strategy into the Siamese framework to achieve reciprocity for robust target tracking. Experimental results show that our tracking approach performs well, especially on seven benchmark datasets, including OTB-100, TC-128, DTB, UAV-123, VOT-2016, VOT-2018 and GOT-10k.},
  archive      = {J_IJMLC},
  author       = {Zhang, Huanlong and Ma, Zonghao and Zhao, Yanchun and Wang, Yong and Jiang, Bin},
  doi          = {10.1007/s13042-024-02296-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {819-834},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Reciprocal interlayer-temporal discriminative target model for robust visual tracking},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-graph aggregated graph neural network for heterogeneous graph representation learning. <em>IJMLC</em>, <em>16</em>(2), 803-818. (<a href='https://doi.org/10.1007/s13042-024-02294-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous graph neural networks have attracted considerable attention for their proficiency in handling intricate heterogeneous structures. However, most existing methods model semantic relationships in heterogeneous graphs by manually defining meta-paths, inadvertently overlooking the inherent incompleteness of such graphs. To address this issue, we propose a multi-graph aggregated graph neural network (MGAGNN) for heterogeneous graph representation learning, which simultaneously leverages attribute similarity and high-order semantic information between nodes. Specifically, MGAGNN first employs the feature graph generator to generate a feature graph for completing the original graph structure. A semantic graph is then generated using a semantic graph generator, capturing higher-order semantic information through automatic meta-path learning. Finally, we aggregate the two candidate graphs to reconstruct a new heterogeneous graph and learn node embedding by graph convolutional networks. Extensive experiments on real-world datasets demonstrate the superior performance of the proposed method over state-of-the-art approaches.},
  archive      = {J_IJMLC},
  author       = {Zhu, Shuailei and Wang, Xiaofeng and Lai, Shuaiming and Chen, Yuntao and Zhai, Wenchao and Quan, Daying and Qi, Yuanyuan and Lv, Laishui},
  doi          = {10.1007/s13042-024-02294-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {803-818},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-graph aggregated graph neural network for heterogeneous graph representation learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial attack method based on enhanced spatial momentum. <em>IJMLC</em>, <em>16</em>(2), 789-802. (<a href='https://doi.org/10.1007/s13042-024-02290-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have been widely applied in many fields, but it is found that they are vulnerable to adversarial examples, which can mislead the DNN-based models with imperceptible perturbations. Many adversarial attack methods can achieve great success rates when attacking white-box models, but they usually exhibit poor transferability when attacking black-box models. Momentum iterative gradient-based methods can effectively improve the transferability of adversarial examples. Still, the momentum update mechanism of existing methods may lead to a problem of unstable gradient update direction and result in poor local optima. In this paper, we propose an enhanced spatial momentum iterative gradient-based adversarial attack method. Specifically, we introduce the spatial domain momentum accumulation mechanism. Instead of only accumulating the gradients of data points on the optimization path in the gradient update process, we additionally accumulate the average gradients of multiple sampling points within the neighborhood of data points. This mechanism fully utilizes the contextual gradient information of different regions within the image to smooth the accumulated gradients and find a more stable gradient update direction, thus escaping from poor local optima. Empirical results on the standard ImageNet dataset demonstrate that our method can significantly improve the attack success rate of momentum iterative gradient-based methods and shows excellent attack performance not only against normally trained models but also against adversarial training and defense models, outperforming the state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Hu, Jun and Wei, Guanghao and Xia, Shuyin and Wang, Guoyin},
  doi          = {10.1007/s13042-024-02290-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {789-802},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Adversarial attack method based on enhanced spatial momentum},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SPERM: Sequential pairwise embedding recommendation with MI-FGSM. <em>IJMLC</em>, <em>16</em>(2), 771-787. (<a href='https://doi.org/10.1007/s13042-024-02288-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual recommendation systems have shown remarkable performance by leveraging consumer feedback and the visual attributes of products. However, recent concerns have arisen regarding the decline in recommendation quality when these systems are subjected to attacks that compromise the model parameters. While the fast gradient sign method (FGSM) and iterative FGSM (I-FGSM) are well-studied attack strategies, the momentum iterative FGSM (MI-FGSM), known for its superiority in the computer vision (CV) domain, has been overlooked. This oversight raises the possibility that visual recommender systems may be vulnerable to MI-FGSM, leading to significant vulnerabilities. Adversarial training, a regularization technique designed to withstand MI-FGSM attacks, could be a promising solution to bolster model resilience. In this research, we introduce MI-FGSM for visual recommendation. We propose the Sequential Pairwise Embedding Recommender with MI-FGSM (SPERM), a model that incorporates visual, temporal, and sequential information for visual recommendations through adversarial training. Specifically, we employ higher-order Markov chains to capture consumers’ sequential behaviors and utilize visual pairwise ranking to discern their visual preferences. To optimize the SPERM model, we employ a learning method based on AdaGrad. Moreover, we fortify the SPERM approach with adversarial training, where the primary objective is to train the model to withstand adversarial inputs introduced by MI-FGSM. Finally, we evaluate the effectiveness of our approach by conducting experiments on three Amazon datasets, comparing it with existing visual and adversarial recommendation algorithms. Our results demonstrate the efficacy of the proposed SPERM model in addressing adversarial attacks while enhancing visual recommendation performance.},
  archive      = {J_IJMLC},
  author       = {Paul, Agyemang and Wan, Yuxuan and Chen, Boyu and Wu, Zhefu},
  doi          = {10.1007/s13042-024-02288-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {771-787},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {SPERM: Sequential pairwise embedding recommendation with MI-FGSM},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quasi-framelets: Robust graph neural networks via adaptive framelet convolution. <em>IJMLC</em>, <em>16</em>(2), 755-770. (<a href='https://doi.org/10.1007/s13042-024-02286-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to provide a novel design of a multiscale framelet convolution for spectral graph neural networks (GNNs). While current spectral methods excel in various graph learning tasks, they often lack the flexibility to adapt to noisy, incomplete, or perturbed graph signals, making them fragile in such conditions. Our newly proposed framelet convolution addresses these limitations by decomposing graph data into low-pass and high-pass spectra through a finely-tuned multiscale approach. Our approach directly designs filtering functions within the spectral domain, allowing for precise control over the spectral components. The proposed design excels in filtering out unwanted spectral information and significantly reduces the adverse effects of noisy graph signals. Our approach not only enhances the robustness of GNNs but also preserves crucial graph features and structures. Through extensive experiments on diverse, real-world graph datasets, we demonstrate that our framelet convolution achieves superior performance in node classification tasks. It exhibits remarkable resilience to noisy data and adversarial attacks, highlighting its potential as a robust solution for real-world graph applications. This advancement opens new avenues for more adaptive and reliable spectral GNN architectures.},
  archive      = {J_IJMLC},
  author       = {Yang, Mengxi and Shi, Dai and Zheng, Xuebin and Yin, Jie and Gao, Junbin},
  doi          = {10.1007/s13042-024-02286-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {2},
  number       = {2},
  pages        = {755-770},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Quasi-framelets: Robust graph neural networks via adaptive framelet convolution},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Text semantic matching algorithm based on the introduction of external knowledge under contrastive learning. <em>IJMLC</em>, <em>16</em>(1), 741-753. (<a href='https://doi.org/10.1007/s13042-024-02285-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring the semantic similarity between two texts is a fundamental aspect of text semantic matching. Each word in the texts holds a weighted meaning, and it is essential for the model to effectively capture the most crucial knowledge. However, current text matching methods based on BERT have limitations in acquiring professional domain knowledge. BERT requires extensive domain-specific training data to perform well in specialized fields such as medicine, where obtaining labeled data is challenging. In addition, current text matching models that inject domain knowledge often rely on creating new training tasks to fine-tune the model, which is time-consuming. Although existing works have directly injected domain knowledge into BERT through similarity matrices, they struggle to handle the challenge of small sample sizes in professional fields. Contrastive learning trains a representation learning model by generating instances that exhibit either similarity or dissimilarity, so that a more general representation can be learned with a small number of samples. In this paper, we propose to directly integrate the word similarity matrix into BERT’s multi-head attention mechanism under a contrastive learning framework to align similar words during training. Furthermore, in the context of Chinese medical applications, we propose an entity MASK approach to enhance the understanding of medical terms by pre-trained models. The proposed method helps BERT acquire domain knowledge to better learn text representations in professional fields. Extensive experimental results have shown that the algorithm significantly improves the performance of the text matching model, especially when training data is limited.},
  archive      = {J_IJMLC},
  author       = {Hu, Jie and Zhu, Yinglian and Wu, Lishan and Luo, Qilei and Teng, Fei and Li, Tianrui},
  doi          = {10.1007/s13042-024-02285-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {741-753},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Text semantic matching algorithm based on the introduction of external knowledge under contrastive learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bgman: Boundary-prior-guided multi-scale aggregation network for skin lesion segmentation. <em>IJMLC</em>, <em>16</em>(1), 721-740. (<a href='https://doi.org/10.1007/s13042-024-02284-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin lesion segmentation is a fundamental task in the field of medical image analysis. Deep learning approaches have become essential tools for segmenting medical images, as their accuracy in effectively analyzing abnormalities plays a critical role in determining the ultimate diagnostic results. Because of the inherent difficulties presented by medical images, including variations in shapes and sizes, along with the indistinct boundaries between lesions and the surrounding backgrounds, certain conventional algorithms face difficulties in fulfilling the growing requirements for elevated accuracy in processing medical images. To enhance the performance in capturing edge features and fine details of lesion processing, this paper presents the Boundary-Prior-Guided Multi-Scale Aggregation Network for skin lesion segmentation (BGMAN). The proposed BGMAN follows a basic Encoder–Decoder structure, wherein the encoder network employs prevalent CNN-based architectures to capture semantic information. We propose the Transformer Bridge Block (TBB) and employ it to enhance multi-scale features captured by the encoder. The TBB strengthens the intensity of weak feature information, establishing long-distance relationships between feature information. In order to augment BGMAN’s capability to identify boundaries, a boundary-guided decoder is designed, utilizing the Boundary Aware Block (BAB) and Cross Scale Fusion Block (CSFB) to guide the decoding learning process. BAB can acquire features embedded with explicit boundary information under the supervision of a boundary mask, while CSFB aggregates boundary features from different scales using learnable embeddings. The proposed method has been validated on the ISIC2016, ISIC2017, and $$PH^2$$ datasets. It outperforms current mainstream networks with the following results: F1 92.99 and IoU 87.71 on ISIC2016, F1 86.42 and IoU 78.34 on ISIC2017, and F1 94.83 and IoU 90.26 on $$PH^2$$ .},
  archive      = {J_IJMLC},
  author       = {Huang, Zhenyang and Zhao, Yixing and Li, Jinjiang and Liu, Yepeng},
  doi          = {10.1007/s13042-024-02284-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {721-740},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Bgman: Boundary-prior-guided multi-scale aggregation network for skin lesion segmentation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visible-infrared person re-identification with complementary feature fusion and identity consistency learning. <em>IJMLC</em>, <em>16</em>(1), 703-719. (<a href='https://doi.org/10.1007/s13042-024-02282-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dual-mode 24/7 monitoring systems continuously obtain visible and infrared images in a real scene. However, differences such as color and texture between these cross-modality images pose challenges for visible-infrared person re-identification (ReID). Currently, the general method is modality-shared feature learning or modal-specific information compensation based on style transfer, but the modality differences often result in the inevitable loss of valuable feature information in the training process. To address this issue, A complementary feature fusion and identity consistency learning (CFF-ICL) method is proposed. On the one hand, the multiple feature fusion mechanism based on cross attention is used to promote the features extracted by the two groups of networks in the same modality image to show a more obvious complementary relationship to improve the comprehensiveness of feature information. On the other hand, the designed collaborative adversarial mechanism between dual discriminators and feature extraction network is designed to remove the modality differences, and then construct the identity consistency between visible and infrared images. Experimental results by testing on SYSU-MM01 and RegDB datasets verify the method’s effectiveness and superiority.},
  archive      = {J_IJMLC},
  author       = {Wang, Yiming and Chen, Xiaolong and Chai, Yi and Xu, Kaixiong and Jiang, Yutao and Liu, Bowen},
  doi          = {10.1007/s13042-024-02282-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {703-719},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Visible-infrared person re-identification with complementary feature fusion and identity consistency learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Condensed-gradient boosting. <em>IJMLC</em>, <em>16</em>(1), 687-701. (<a href='https://doi.org/10.1007/s13042-024-02279-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a computationally efficient variant of Gradient Boosting (GB) for multi-class classification and multi-output regression tasks. Standard GB uses a 1-vs-all strategy for classification tasks with more than two classes. This strategy entails that one tree per class and iteration has to be trained. In this work, we propose the use of multi-output regressors as base models to handle the multi-class problem as a single task. In addition, the proposed modification allows the model to learn multi-output regression problems. An extensive comparison with other multi-output based Gradient Boosting methods is carried out in terms of generalization and computational efficiency. The proposed method showed the best trade-off between generalization ability and training and prediction speeds. Furthermore, an analysis of space and time complexity was undertaken.},
  archive      = {J_IJMLC},
  author       = {Emami, Seyedsaman and Martínez-Muñoz, Gonzalo},
  doi          = {10.1007/s13042-024-02279-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {687-701},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Condensed-gradient boosting},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-representation with adaptive loss minimization via doubly stochastic graph regularization for robust unsupervised feature selection. <em>IJMLC</em>, <em>16</em>(1), 661-685. (<a href='https://doi.org/10.1007/s13042-024-02275-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature selection (UFS), which involves selecting representative features from unlabeled high-dimensional data, has attracted much attention. Numerous self-representation-based models have been recently developed successfully for UFS. However, these models have two main problems. First, existing self-representation-based UFS models cannot effectively handle noise and outliers. Second, many graph-regularized self-representation-based UFS models typically construct a fixed graph to maintain the local structure of data. To overcome the above shortcomings, we propose a novel robust UFS model called self-representation with adaptive loss minimization via doubly stochastic graph regularization (SRALDS). Specifically, SRALDS uses an adaptive loss function to minimize the representation residual term, which may enhance the robustness of the model and diminish the effect of noise and outliers. Besides, rather than utilizing a fixed graph, SRALDS learns a high-quality doubly stochastic graph that more accurately captures the local structure of data. Finally, an efficient optimization algorithm is designed to obtain the optimal solution for SRALDS. Extensive experiments demonstrate the superior performance of SRALDS over several well-known UFS methods.},
  archive      = {J_IJMLC},
  author       = {Song, Xiangfa},
  doi          = {10.1007/s13042-024-02275-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {661-685},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Self-representation with adaptive loss minimization via doubly stochastic graph regularization for robust unsupervised feature selection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class-structure preserving multi-view correlated discriminant analysis for multiblock data. <em>IJMLC</em>, <em>16</em>(1), 639-660. (<a href='https://doi.org/10.1007/s13042-024-02270-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development in data acquisition methods, multiple data sources are now becoming available to explain different views of an object. This consequently introduces several new challenges in integrating the high dimensional, distinct, and heterogeneous views under multi-view learning (MVL) framework. The multiset canonical correlation analysis (MCCA) is a popular subspace learning technique in MVL, which forms a common latent space by maximizing the pairwise correlation across all the views. However, MCCA does not utilize the class label information of the objects and is unable to handle the data non-linearity. Although there exist a few supervised extensions of MCCA, they lack productive use of intra-view and inter-view consistency and/or inconsistency information while using the class label. In this regard, a supervised subspace learning method, termed as class-structure preserving multi-view correlated discriminant analysis (CSP-MvCDA), is proposed by judiciously integrating the merits of MCCA, linear discriminant analysis (LDA), and a locality preserving norm. The proposed method jointly optimizes the inter-set correlation across all the views and intra-set discrimination in each view to obtain a common discriminative latent space, where the shared and complementary information across multiple views is exploited. The locality preserving norm with prior class labels helps to preserve the local class-structure of the data, while the LDA maintains its global class-structure. To show the effectiveness of the proposed method, several cancer and benchmark data sets are used. The experimental results establish that the proposed CSP-MvCDA method is superior to several state-of-the-art algorithms in terms of classification performance.},
  archive      = {J_IJMLC},
  author       = {Mondal, Sankar and Maji, Pradipta},
  doi          = {10.1007/s13042-024-02270-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {639-660},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Class-structure preserving multi-view correlated discriminant analysis for multiblock data},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint recognition for location and activity based on multidimensional features of CSI images. <em>IJMLC</em>, <em>16</em>(1), 625-638. (<a href='https://doi.org/10.1007/s13042-024-02266-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The joint recognition technology of location and activity, leveraging CSI (Channel State Information), finds widespread applications in domains such as human-computer interaction and smart homes, owing to the pervasive deployment of wireless networks. While single-dimensional recognition algorithms have achieved notable accuracy, there remains room for improvement in multidimensional recognition algorithms. To address this gap, a joint recognition algorithm for location and activity, termed the JRLA-MFCI algorithm, is proposed based on multidimensional features extracted from CSI images. This algorithm utilizes fine-grained CSI information to construct anti-interference CSI amplitude difference and phase difference images. Texture and color features are subsequently extracted to form feature vectors, and the SVM algorithm employing a quadratic polynomial kernel function with optimized parameters is employed for the joint recognition of location and activity. Extensive experimentation validates the efficacy of the JRLA-MFCI algorithm, yielding recognition accuracies of 95.86% and 93.86% in two distinct experimental scenarios, respectively.},
  archive      = {J_IJMLC},
  author       = {Tian, Yong and Gao, Fangting and Yan, Shuyu and Tong, Xin and Zhang, Qiyue and Ding, Xuejun},
  doi          = {10.1007/s13042-024-02266-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {625-638},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Joint recognition for location and activity based on multidimensional features of CSI images},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised image categorization based on deep generative models with disentangled representations and von mises-fisher distributions. <em>IJMLC</em>, <em>16</em>(1), 611-623. (<a href='https://doi.org/10.1007/s13042-024-02265-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational autoencoders (VAEs) have emerged as powerful deep generative models for learning abstract representations in the latent space, making them highly applicable across diverse domains. This paper presents a novel image categorization approach that leverages VAEs with disentangled representations. In VAE-based clustering models, the latent representations learned by encoders often combine both generation and clustering information. To address this concern, our proposed model disentangles the acquired latent representations into dedicated clustering and generation modules, thereby enhancing the performance and efficiency of clustering tasks. Specifically, we introduce an extension of the Kullback–Leibler (KL) divergence to promote independence between these two modules. Additionally, we incorporate the von Mises-Fisher (vMF) distribution to improve the clustering model’s ability to capture cluster characteristics within the generation module. Extensive experimental evaluations confirm the effectiveness of our model in clustering tasks, notably without the requirement for pre-training. Furthermore, when compared to various deep generative clustering models requiring pre-training, our model is able to achieve either comparable or superior performance across multiple datasets.},
  archive      = {J_IJMLC},
  author       = {Fan, Wentao and Xu, Kunxiong},
  doi          = {10.1007/s13042-024-02265-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {611-623},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Unsupervised image categorization based on deep generative models with disentangled representations and von mises-fisher distributions},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HOGFormer: High-order graph convolution transformer for 3D human pose estimation. <em>IJMLC</em>, <em>16</em>(1), 599-610. (<a href='https://doi.org/10.1007/s13042-024-02262-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The combination of graph convolution network (GCN) and Transformer has shown promising results in 3D human pose estimation (HPE) tasks when lifting the 2D to 3D poses. However, recent approaches to 3D HPE still face difficulties such as depth ambiguity and occlusion. To address these issues, we suggest a novel 3D HPE architecture, termed High-Order Graph Convolution Transformer (HOGFormer). HOGFormer consists of three core components: the Chebyshev Graph Convolution (CGConv) module, the Graph-based Dynamic Adjacency Matrix Transformer (GDAMFormer) module, and the High-Order Graph Convolution (HOGConv) module. In more detail, the CGConv module can further increase the estimation accuracy by approximating the graph convolution with Chebyshev polynomials. The GDAMFormer module efficiently addresses issues like self-occlusion and depth blur by using a dynamic adjacency matrix to represent the dynamic relationships among joints. The HOGConv module can effectively extract local features by capturing the local physical dependencies of skeleton connections. With the integration of these modules, the proposed architecture can effectively capture global and local information. We evaluate our architecture quantitatively and qualitatively on the popular benchmark dataset Human3.6M. Our experiments demonstrate that HOGFormer achieves state-of-the-art performance.},
  archive      = {J_IJMLC},
  author       = {Xie, Yuhong and Hong, Chaoqun and Zhuang, Weiwei and Liu, Lijuan and Li, Jie},
  doi          = {10.1007/s13042-024-02262-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {599-610},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {HOGFormer: High-order graph convolution transformer for 3D human pose estimation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A knowledge-enhanced model with syntactic-aware attentive graph convolutional network for biomedical entity and relation extraction. <em>IJMLC</em>, <em>16</em>(1), 583-598. (<a href='https://doi.org/10.1007/s13042-024-02259-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biomedical entity and relation extraction has recently gained increasing interest. Nevertheless, it continues to pose a significant challenge due to the unique domain-specific characteristics of the biomedical corpus. Biomedical documents often include many highly specialized terms, acronyms, and abbreviations. This presents a significant challenge for those entity and relation extraction models that neglect biomedical domain-specific knowledge, as they may show biases in interpreting biomedical texts and may fail to accurately associate these specialized terms with the appropriate biomedical entities. Moreover, most existing models struggle to process lengthy sentences in the biomedical corpus, which hinders their performance. To address these limitations, this paper proposes a Knowledge-Enhanced Model with Syntactic-Aware Attentive Graph Convolutional Network (KESAAGCN) for biomedical entity and relation extraction. Given an input text, KESAAGCN first constructs an initial span graph representing its initial understanding of the text. Specially, a syntactic-aware attentive graph convolutional network based on the dependency trees of the sentences is utilized to capture relations between long-distance entities in lengthy sentences. Then, a domain knowledge graph is constructed based on an external knowledge base to incorporate useful domain-specific information into the model. Finally, the initial span graph and the domain knowledge graph are fused to obtain a more refined graph for final prediction. Extensive experimental results on three benchmark datasets demonstrate the effectiveness and superiority of our methods.},
  archive      = {J_IJMLC},
  author       = {Liu, Xiaoyong and Qin, Xin and Xu, Chunlin and Li, Huihui},
  doi          = {10.1007/s13042-024-02259-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {583-598},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A knowledge-enhanced model with syntactic-aware attentive graph convolutional network for biomedical entity and relation extraction},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSLID-TCN: Multi-stage linear-index dilated temporal convolutional network for temporal action segmentation. <em>IJMLC</em>, <em>16</em>(1), 567-581. (<a href='https://doi.org/10.1007/s13042-024-02251-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal Convolutional Network (TCN) has received extensive attention in the field of speech synthesis. Many researchers use TCN-based models for action segmentation since both tasks focus on contextual connections. However, TCN can only capture the long-term dependencies of information and ignores the short-term dependencies, which can lead to over-segmentation by dividing a single action interval into multiple action categories. This paper proposes Multi-Stage Linear-Index Dilated TCN (MSLID-TCN) model each of whic layer has an appropriate receptive field, allowing the video’s short-term and long-term dependencies to be passed to the next layer, thereby optimizing the over-segmentation problem. MSLID-TCN has a four-stage structure. The first stage is a LID-TCN, while the remaining stages are Single Stage TCNs (SS-TCNs). The I3D feature of the video is used as the input for MSLID-TCN. In the first stage, LID-TCN makes initial predictions on frame features to obtain predicted probability values. In the last three stages, these probability features are used as input to the network where SS-TCN corrects the predicted probability values from the previous stage, ultimately yielding action segmentation results. Comparative experiments show that our model performs excellently on the three datasets: 50salads, Georgia Tech Egocentric Activities (GTEA), and Breakfast.},
  archive      = {J_IJMLC},
  author       = {Gao, Suo and Wu, Rui and Liu, Songbo and Erkan, Uğur and Toktas, Abdurrahim and Liu, Jiafeng and Tang, Xianglong},
  doi          = {10.1007/s13042-024-02251-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {567-581},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {MSLID-TCN: Multi-stage linear-index dilated temporal convolutional network for temporal action segmentation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse low-redundancy multi-label feature selection with constrained laplacian rank. <em>IJMLC</em>, <em>16</em>(1), 549-566. (<a href='https://doi.org/10.1007/s13042-024-02250-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the crucial methods for data dimensionality reduction, multi-label feature selection aims to eliminate irrelevant and redundant features from the data and retain only the most representative subset of features. Although many advanced multi-label feature selection methods have been proposed with state-of-the-art performance, it remains a long-standing challenge for multi-label feature selection to remove irrelevant and redundant features from the data. Besides, the existing graph-based multi-label feature selection methods are limited by the single way of learning similar graphs, leading to a considerable model limitation. To address these issues, we use the $$L_{1}$$ norm sparsity constraint to eliminate irrelevant features and introduce the Laplace rank constraint to construct dynamic graphs to improve the sparsity of the model and overcome the model limitation problem. Next, we build a penalty term for eliminating redundant features by combining $$L_{1}$$ norm and $$L_{2,1}$$ norm to constrain the learning of the feature weight matrix. Then, we combine it with the linear mapping of instances to ground-true labels. We propose sparse, low-redundancy multi-label feature selection with constrained Laplacian rank (SLCLR). Finally, SLCLR was compared with nine advanced existing methods on thirteen benchmark multi-label datasets, and the experiment results on seven commonly used evaluation metrics all validated the good feature selection performance of SLCLR.},
  archive      = {J_IJMLC},
  author       = {Wu, Yanhong and Bai, Jianxia},
  doi          = {10.1007/s13042-024-02250-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {549-566},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Sparse low-redundancy multi-label feature selection with constrained laplacian rank},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DmADs-net: Dense multiscale attention and depth-supervised network for medical image segmentation. <em>IJMLC</em>, <em>16</em>(1), 523-548. (<a href='https://doi.org/10.1007/s13042-024-02248-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has made important contributions to the development of medical image segmentation. Convolutional neural networks, as a crucial branch, have attracted strong attention from researchers. Through the tireless efforts of numerous researchers, convolutional neural networks have yielded numerous outstanding algorithms for processing medical images. The ideas and architectures of these algorithms have also provided important inspiration for the development of later technologies.Through extensive experimentation, we have found that currently mainstream deep learning algorithms are not always able to achieve ideal results when processing complex datasets and different types of datasets. These networks still have room for improvement in lesion localization and feature extraction. Therefore, we have created the dense multiscale attention and depth-supervised network (DmADs-Net).We use ResNet for feature extraction at different depths and create a Multi-scale Convolutional Feature Attention Block to improve the network’s attention to weak feature information. The Local Feature Attention Block is created to enable enhanced local feature attention for high-level semantic information. In addition, in the feature fusion phase, a Feature Refinement and Fusion Block is created to enhance the fusion of different semantic information.We validated the performance of the network using five datasets of varying sizes and types. Results from comparative experiments show that DmADs-Net outperformed mainstream networks. Ablation experiments further demonstrated the effectiveness of the created modules and the rationality of the network architecture.},
  archive      = {J_IJMLC},
  author       = {Fu, Zhaojin and Li, Jinjiang and Chen, Zheng and Ren, Lu},
  doi          = {10.1007/s13042-024-02248-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {523-548},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {DmADs-net: Dense multiscale attention and depth-supervised network for medical image segmentation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective two-stage training scheme for boundary decision of imbalanced samples. <em>IJMLC</em>, <em>16</em>(1), 507-521. (<a href='https://doi.org/10.1007/s13042-024-02241-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to categorize imbalanced data is an active research direction in data mining and machine learning research areas. In order to dynamically reduce the negative influence of imbalanced samples on the loss in the phase of training, the existing cost-sensitive re-weighing methods assign different weights to imbalanced samples. However, it will be overfitted for deep neural networks (DNNs) to process hard samples, because the existing cost-sensitive re-weighting methods cannot effectively guide DNNs to reasonably partition the decision boundaries of the samples. In this study, we propose a new self-balanced loss function, called SBLoss, which can adaptively assign different weights to the samples according to the influence of the samples on the decision boundary in order to reduce the overfitting phenomena caused by hard samples. Extensive experiments are conducted on multiple real imbalanced datasets, and the experimental results show that the imbalanced data classification method based on a two-stage training scheme have high accuracy and robustness, which outperforms the state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Xue, Qi and Qiao, Shaojie and Yang, Guoping and Liao, Hai and Han, Nan and Peng, Yuhan and Wu, Tao and Yuan, Guan and Li, He},
  doi          = {10.1007/s13042-024-02241-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {507-521},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An effective two-stage training scheme for boundary decision of imbalanced samples},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A semantic features-enhanced dispensation network for retrieving remote sensing images. <em>IJMLC</em>, <em>16</em>(1), 493-505. (<a href='https://doi.org/10.1007/s13042-024-02239-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing (RS) images contain useful information about the numerous elements captured from space or satellites. These elements may include multispectral super-resolution features that are helpful in various fields such as geological analysis, weather prediction, urban planning, and others. To proceed with these features without considering learnable parameters usually provide unsatisfactory retrieval results. To overcome this, in this article, we propose a semantic features-based dispensation network for learning local and global hybrid features to retrieve RS images. Firstly, we improve the RS images using the proposed pixel-wise feature enhancement technique to expose hidden elements and achieve the finest query image. Secondly, we learn the local and global semantic features using the proposed dispensation network. The dispensation network encodes the local and global semantic features to learn the most critical and improved multispectral features. Finally, with improved learning competence, the proposed method reduces the semantic gap to index and retrieves the top similar RS images. The experiments are conducted on two benchmark datasets to show the improved efficiency and accuracy of the proposed method for retrieving RS images.},
  archive      = {J_IJMLC},
  author       = {Unar, Salahuddin and Unar, Saifullah and Su, Yining and Liu, Pengbo and Fu, Xianping},
  doi          = {10.1007/s13042-024-02239-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {493-505},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A semantic features-enhanced dispensation network for retrieving remote sensing images},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Action recognition method based on a novel keyframe extraction method and enhanced 3D convolutional neural network. <em>IJMLC</em>, <em>16</em>(1), 475-491. (<a href='https://doi.org/10.1007/s13042-024-02235-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, action recognition is a challenging task in the field of computer vision. Traditional action recognition methods cannot fully extract the spatiotemporal features of actions in video. To address the problem, an action recognition method based on keyframe extraction and DAMR_3DNet (D3DNet+3D Attention Mechanism module+3D Residual module) is proposed. Firstly, we explore a keyframe extraction method based on image information entropy and hog_ssim similarity algorithm, which selects keyframes from the input video to represent video content. And we take the selected keyframes as the model input to reduce the computational complexity of network model. Afterward, we design a DAMR_3DNet model to recognize action and reduce the parameters of network. The D3DNet module improves the C3D network by using the 3D decoupled convolution substituting the 3D convolution and introducing a feature fusion layer. And a 3D attention mechanism is designed to strengthen the action features and reduce the influence of background features. Finally, a 3D residual structure is explored to avoid gradient disappearance while fusing the high-level and low-level spatiotemporal features. Experiments consistently show the superiority of the proposed method on UCF101, Chinese sign language (CSL) and HMDB51 datasets. And the results demonstrate that the proposed method is effective, which improves the performance of action recognition and outperforms the most state-of-the-art methods.},
  archive      = {J_IJMLC},
  author       = {Tian, Qiuhong and Li, Saiwei and Zhang, Yuankui and Lu, Hongyi and Pan, Hao},
  doi          = {10.1007/s13042-024-02235-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {475-491},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Action recognition method based on a novel keyframe extraction method and enhanced 3D convolutional neural network},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proportional periodic sampling for cross-load bearing fault diagnosis. <em>IJMLC</em>, <em>16</em>(1), 461-473. (<a href='https://doi.org/10.1007/s13042-024-02233-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearing vibration data under various loads shows different distributions, which leads to the poor performance of existing deep learning methods in performing cross-load fault diagnosis tasks. As a result, cross-load deep transfer learning methods that can reduce the impact of distribution differences have become the current research priority. However, existing transfer learning methods fall short in fully leveraging the bearing data characteristics, resulting in unreasonable sampling strategy, complex or inefficient network structure. These limitations hamper the performance improvement of cross-load fault diagnosis methods. To address the above drawbacks, a transductive convolution transfer learning (TCTL) method based on proportional periodic sampling is proposed. First, according to the periodic characteristic of bearing vibration data, the proportional periodic sampling is conducted on all vibration data to construct high-quality sample sets, which can greatly reduce the number of model parameters and ensure the excellent diagnostic accuracy of the model. Second, considering the short length of vibration samples and minor distribution differences between various loads, the cross-load convolutional neural network (CL-CNN) model is proposed to extract fault features from the constructed samples efficiently. Third, utilizing the characteristic that the vibration data under each load satisfies the clustering assumption, the cross-load multi-objective loss is used to effectively supervise the CL-CNN model to extract more domain-invariant features. Finally, compared to ablation and latest methods, TCTL boasts higher average value and lower standard deviation of accuracy on both datasets, proving the effectiveness of TCTL.},
  archive      = {J_IJMLC},
  author       = {Zheng, Jianbo and Jiang, Bin and Yang, Chao},
  doi          = {10.1007/s13042-024-02233-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {461-473},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Proportional periodic sampling for cross-load bearing fault diagnosis},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clean-label attack based on negative afterimage on neural networks. <em>IJMLC</em>, <em>16</em>(1), 449-460. (<a href='https://doi.org/10.1007/s13042-024-02230-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attacks can fool machine learning models by adding small but carefully designed perturbations to an image, resulting in the model to misclassify it into another class. In general, an attacker chooses a target class as a pollution source to generate a perturbed image and tricks the classifier into classifying it as the target class. However, the effectiveness of adversarial attacks suffers from some limitations, including the need for specific control over the labeling of the target class and challenges in generating effective adversarial samples in real-world scenarios. To overcome these limitations, we propose a novel clean-label attack based on negative afterimage. Negative afterimage is a visual phenomenon whereby, after gazing at a bright image for some time, one perceives the inverse color image of the previously observed bright region when shifting focus to a darker area. We explore the afterimage phenomenon and use negative afterimages as pollution sources to generate adversarial samples, which can avoid any dependency on the labeling of pollution sources. Subsequently, we generate adversarial samples using an optimization-based approach to ensure that adversarial samples are visually undetectable. We conducted experiments on two widely used datasets, CIFAR-10 and ImageNet. The results show that our proposed method can effectively generate adversarial samples with high stealthiness.},
  archive      = {J_IJMLC},
  author       = {Zang, Liguang and Li, Yuancheng},
  doi          = {10.1007/s13042-024-02230-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {449-460},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Clean-label attack based on negative afterimage on neural networks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting data reduction for boolean matrix factorization algorithms based on formal concept analysis. <em>IJMLC</em>, <em>16</em>(1), 419-447. (<a href='https://doi.org/10.1007/s13042-024-02226-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Boolean Matrix Factorization (BMF) helps unveil hidden patterns in boolean datasets and is a powerful tool in machine learning. However, when dealing with large datasets, reducing data size becomes crucial for BMF algorithms. In this paper, we revisit and propose novel data reduction approaches for BMF algorithms based on Formal Concept Analysis (FCA), aiming to minimize the impact of data reduction on factor quality. Specifically, we introduce the concept of intent vectors , and present incremental algorithms along with their associated theorems for capturing and quantifying these vectors, thereby facilitating a reduction in data size. More importantly, we propose two innovative approaches based on FCA principles that effectively identify and eliminate redundant rows in datasets through distinct deletion strategies. The first approach incrementally deletes rows while preserving the intent vectors of attribute concepts, thus maintaining the quality of factors. The second approach progressively removes rows from the reduced dataset by the first approach, by gradually adjusting the amount of concept loss to minimize any degradation in factor quality. Experiments demonstrate that our first reduction algorithm significantly decreases data size without degrading factor quality, consistently outperforming current leading algorithms with a $$100\%$$ success rate. Our second algorithm outperformed the existing algorithm in 72 out of 96 comparisons, greatly reducing data size with minimal loss in factor quality.},
  archive      = {J_IJMLC},
  author       = {Yang, Lanzhen and Tsang, Eric C. C. and Mao, Hua and Zhang, Chengling and Wu, Jiaming},
  doi          = {10.1007/s13042-024-02226-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {419-447},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Revisiting data reduction for boolean matrix factorization algorithms based on formal concept analysis},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel framework for concept drift detection using autoencoders for classification problems in data streams. <em>IJMLC</em>, <em>16</em>(1), 397-418. (<a href='https://doi.org/10.1007/s13042-024-02223-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In streaming data environments, data characteristics and probability distributions are likely to change over time, causing a phenomenon called concept drift, which poses challenges for machine learning models to predict accurately. In such non-stationary environments, there is a need to detect concept drift and update the model to maintain an acceptable predictive performance. Existing approaches to drift detection have inherent problems like requirements of truth labels in supervised detection methods and high false positive rate in case of unsupervised drift detection. In this paper, we propose a semi-supervised Autoencoder based Drift Detection Method (AEDDM) aimed at detecting drift without the need of truth labels, yet with a high confidence that the detected drift is real. In a binary classification setting, AEDDM uses two autoencoders in a layered architecture, trained on labelled data and uses a thresholding mechanism based on reconstruction error to signal the presence of drift. The proposed method has been evaluated on four synthetic and four real world datasets with different drifting scenarios. In case of real-world datasets, the induced and detected drifts have been evaluated from classifier’s performance viewpoint using seven mostly used batch classifiers as well as from adaptation perspective in an online learning environment using Hoeffding Tree classifier. The results show that AEDDM affectively detects the distributional changes in data which are most likely to impact the classifier’s performance (real drift) while ignoring the virtual drift thus considerably reducing the false alarms with an ability to adapt in terms of classification performance.},
  archive      = {J_IJMLC},
  author       = {Ali, Usman and Mahmood, Tariq},
  doi          = {10.1007/s13042-024-02223-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {397-418},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A novel framework for concept drift detection using autoencoders for classification problems in data streams},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Enhanced coati optimization algorithm using elite opposition-based learning and adaptive search mechanism for feature selection. <em>IJMLC</em>, <em>16</em>(1), 395. (<a href='https://doi.org/10.1007/s13042-024-02271-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJMLC},
  author       = {Qtaish, Amjad and Braik, Malik and Albashish, Dheeb and Alshammari, Mohammad T. and Alreshidi, Abdulrahman and Alreshidi, Eissa Jaber},
  doi          = {10.1007/s13042-024-02271-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {395},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Correction: Enhanced coati optimization algorithm using elite opposition-based learning and adaptive search mechanism for feature selection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced coati optimization algorithm using elite opposition-based learning and adaptive search mechanism for feature selection. <em>IJMLC</em>, <em>16</em>(1), 361-394. (<a href='https://doi.org/10.1007/s13042-024-02222-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid rise in volume and feature dimensions is negatively impacting machine learning and many other areas, leading to worse classification accuracy and higher computational costs. Feature Selection (FS) methods are crucial to lessen feature dimensionality, which act by removing attributes like irrelevant and less informative information which may have a detrimental impact on the performance of classifiers. This paper presents an Enhanced variant of the Coati Optimization Algorithm (ECOA) that features a better search ability than the basic COA. The COA algorithm was newly evolved to imitate the behavior of coatis when they hunt and attack iguanas as well as when they try to flee from predators. Although the authors of this algorithm state that it is promising, it occasionally exhibits poor search performance and early convergence. To mitigate these issues, the ECOA algorithm was proposed that makes use of elite opposite-based learning in addition to some adaptive search mechanisms. ECOA is expected to have an improved search mechanism and can prevent trapping at local optimum, depending on the mutation, mutation neighborhood search, and rollback procedures. Moreover, it enhances population variety and convergence rate. The COA and ECOA algorithms were used to solve FS problems by selecting optimal feature subsets based on a binary version of each adopted algorithm and the k-Nearest Neighbor (k-NN) classifier. To assess the performance of the Binary ECOA (BECOA), a number of experiments was performed on 24 datasets collected from many sources. Further, six criteria-sensitivity, specificity, classification accuracy, fitness value, number of chosen features, and run time-were used to assess the performance of BECOA. Experimental findings show the excellence of BECOA over other k-NN based FS methods, including Binary COA (BCOA) and other binary optimization methods, in a number of assessment aspects. In particular, among the 24 datasets deemed, BECOA, which yielded the best overall results among all other competing binary algorithms, was able to exclusively outperform the others in 7 datasets in terms of classification accuracy, 11 datasets in terms of specificity, 5 datasets in terms of sensitivity, 10 datasets in terms of number of selected features, 4 in terms of run-time, and 14 datasets in terms of fitness values.},
  archive      = {J_IJMLC},
  author       = {Qtaish, Amjad and Braik, Malik and Albashish, Dheeb and Alshammari, Mohammad T. and Alreshidi, Abdulrahman and Alreshidi, Eissa Jaber},
  doi          = {10.1007/s13042-024-02222-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {361-394},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhanced coati optimization algorithm using elite opposition-based learning and adaptive search mechanism for feature selection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decision-making model with similarity measurement for case selection in public health treatment. <em>IJMLC</em>, <em>16</em>(1), 337-360. (<a href='https://doi.org/10.1007/s13042-024-02217-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The outbreak of a new major infectious disease often has a severe impact on human health and society. Developing appropriate treatments is a societal concern. A case-based decision making model can potentially generate therapy alternatives, but has also revealed two challenges, specifically, ensuring precise case similarity measurement and reasonable selection of the most suitable historical cases. Hence, a decision-making model with similarity measurement for case selection is introduced to generate treatments. First, case information is extended to probabilistic hesitant fuzzy sets with uncertainty, and case similarity measurement based on an interval evidential reasoning approach is developed, which not only handles heterogeneous information effectively but also guarantees accurate retrieval results. Then, an attribute determination model is constructed from many factors to improve the rationality of the results and enable interpretability. Furthermore, an improved gained and lost dominance score method is used to determine the most suitable historical case and an alternative target case is produced, which ensures the fairness and rationality of the decision results. Finally, a case study involving generation of therapy alternatives for patients with mild COVID-19 is provided to demonstrate the procedure employed in the proposed method and comparative analysis is conducted to verify its advantages.},
  archive      = {J_IJMLC},
  author       = {Zheng, Jing and Wang, Ying-Ming and Zhang, Kai},
  doi          = {10.1007/s13042-024-02217-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {337-360},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A decision-making model with similarity measurement for case selection in public health treatment},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-strategy spider wasp optimizer based on grouping and dimensional symmetry method with a time-varying weight. <em>IJMLC</em>, <em>16</em>(1), 301-335. (<a href='https://doi.org/10.1007/s13042-024-02216-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristic algorithms offer numerous advantages, such as their ability to address a wide range of problems without the need for specific problem formulations or gradient information. They have demonstrated effectiveness in solving complex real-world problems. The Spider Wasp Optimizer (SWO) is an innovative metaheuristic algorithm inspired by the hunting, nesting, and mating behaviors of female spider wasps. In order to improve its overall efficiency and enhance the exploitation performance of SWO, this paper introduces three strategies for the enhancement of SWO. The modified algorithm resulting from these enhancements is referred to as ADNSWO. Through the application of the Adaptive Group-Based Strategy Application (AGSA), individuals within the population not involved in exploitation are grouped, and the population’s exploitation strategy is enhanced using the Dimensional Symmetric Distance Optimization Strategy (DSD). AGSA and DSD strategies enhance the exploitation performance of the population. The third strategy aims to enhance the equilibrium between exploration and exploitation in the population by employing the Time-varying Weight (TW). To evaluate ADNSWO’s performance, numerical optimization experiments were conducted using the CEC2017 test set. ADNSWO was compared with SWO and eight other state-of-the-art algorithms. Statistical analysis, including the Wilcoxon Signed-Rank Test and the Friedman test, revealed that ADNSWO outperformed other algorithms comprehensively. Furthermore, an analysis of the computational complexity of ADNSWO showed that its performance improvement did not come at the cost of increased complexity. The effectiveness analysis of the strategies demonstrated that the three proposed strategies significantly contributed to the overall performance enhancement of ADNSWO.},
  archive      = {J_IJMLC},
  author       = {Feng, Zhiyu and Zhu, Donglin and Guo, Huaiyu and Sun, Gaoji and Zhou, Changjun},
  doi          = {10.1007/s13042-024-02216-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {301-335},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A multi-strategy spider wasp optimizer based on grouping and dimensional symmetry method with a time-varying weight},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-way concept lattices triggered by pythagorean fuzzy set and interval set. <em>IJMLC</em>, <em>16</em>(1), 285-299. (<a href='https://doi.org/10.1007/s13042-024-02215-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way concept lattices offer a robust and flexible framework for analyzing complex data and understanding relationships and patterns within datasets. Their ability to handle uncertainty and ambiguity makes them a valuable tool in various applications involving data analysis and knowledge extraction. However, objects values, attributes values and the relationships between objects and attributes in information system, may lack specificity or even be missing. Managing imprecise and ambiguous data is crucial as it mirrors real-world complexities and aligns with realistic decision-making. To address this, we use Pythagorean fuzzy set to accurately depict the uncertain relations between objects and attributes in an information system, and interval set to describe the values of objects and attributes. Additionally, we construct Pythagorean fuzzy three-way interval set concept lattices model to acquire important knowledge. The investigation into the properties of the proposed model reveals that the extension set and the intension set of the Pythagorean fuzzy interval set concept lattices encompass those of existing Pythagorean fuzzy concept lattices, and the proposed model offers finer concept lattices with richer information compared to other existing concept lattices. Finally, a real-life example is provided to showcase the effectiveness and advantages of our proposed model.},
  archive      = {J_IJMLC},
  author       = {Zhao, Jie and Wan, Renxia and Miao, Duoqian},
  doi          = {10.1007/s13042-024-02215-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {285-299},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Three-way concept lattices triggered by pythagorean fuzzy set and interval set},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uni-directional graph structure learning-based multivariate time series anomaly detection with dynamic prior knowledge. <em>IJMLC</em>, <em>16</em>(1), 267-283. (<a href='https://doi.org/10.1007/s13042-024-02212-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Internet of Things (IoT) system, sensors generate a vast amount of multivariate time series data and transmit it to the data center for aggregation and analysis. However, due to equipment failure or attacks, the collected data may contain anomalies, which in turn affect the overall performance and reliability of IoT services. Therefore, an effective multivariate time series anomaly detection (MTSAD) method is a crucial issue to ensure the quality of service. Graph structure learning (GSL)-based methods become a promising technology in MTSAD, which learns an optimal graph structure joint with the anomaly detection task. However, most existing methods disregard the causal and dynamic relationships between sensors during the processing of IoT and assume that the data is devoid of any missing values. Therefore, we propose a uni-direction graph structure learning-based multivariate time-series anomaly detection with dynamic prior knowledge (DPGLAD), which learns the uni-directional relationships between sensors under the constraint of the dynamic prior graph and utilizes diffusion convolutional recurrent neural networks (DCRNN) based on timestamp mask to extract temporal and spatial features. Extensive experiments show that our method has better detection performance and shorter training times than state-of-the-art techniques on four real-world datasets. Compared with the best GSL-based method GTA, DPGLAD achieves 4.16–7.29% more F1-score.},
  archive      = {J_IJMLC},
  author       = {He, Shiming and Li, Genxin and Wang, Jin and Xie, Kun and Sharma, Pradip Kumar},
  doi          = {10.1007/s13042-024-02212-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {267-283},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Uni-directional graph structure learning-based multivariate time series anomaly detection with dynamic prior knowledge},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A chinese named entity recognition model: Integrating label knowledge and lexicon information. <em>IJMLC</em>, <em>16</em>(1), 253-266. (<a href='https://doi.org/10.1007/s13042-024-02207-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chinese named entity recognition (CNER) is one of the important tasks in the field of information extraction. And different divisions of CNER for text processing units can be generally classified into character granularity and word granularity. These two approaches are not only limited by the applicable scenarios, but also susceptible to ambiguity, errors or out of vocabulary. In addition, the direct formalization of entity identification into question answering questions does not take full advantage of the knowledge information of the labels. Therefore, a CNER model incorporating label knowledge and lexicon information (LkLi-CNER) is proposed in this paper. The model first integrates lexical enhancement information directly into the BERT layer for full interaction by matching sentences with lexicons on a character-based basis. And then a priori knowledge is introduced to fuse the representation of label description text into the enhanced text representation, so that the model can be further enhanced by learning semantic information from the entity labels themselves. Finally, the probability of being the start and end of each category is calculated for each token, and the start-end group with the highest probability is selected as the output. The experimental results show that the LkLi-CNER model is significantly better than baseline, and good results are achieved simultaneously on four CNER datasets in different fields, which proves the effectiveness of the proposed model.},
  archive      = {J_IJMLC},
  author       = {Yuan, Yihan and Zhang, Qinghua and Zhou, Xiong and Gao, Man},
  doi          = {10.1007/s13042-024-02207-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {253-266},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A chinese named entity recognition model: Integrating label knowledge and lexicon information},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated simplicial neural network with neuro-fuzzy network for graph embedding. <em>IJMLC</em>, <em>16</em>(1), 233-251. (<a href='https://doi.org/10.1007/s13042-024-02201-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, graph neural network (GNN) has become the main stream for most of recent researches due to its powers in dealing with complex graph data learning problems. However, as most of the recent GNN-based architectures have been mainly designed to only evaluate direct relational structures between nodes. As the results, these techniques are unable to capture the sophisticated multi-way relationships in graph. The multi-way relationships can be represented by both explicit graph-based and complex topological structures. In general, the multi-way relationships in graph can be modelled as simplicial complexes, hyper-graphs, e.g., and can be efficiently preserved under the simplicial neural networks (SNN). There are several notable SNN-based architectures have been proposed recently, such as the well-known simplicial convolutional neural network (SCNN). The SNN-based techniques have shown the competitive performances in handling graph learning. However, most of recent proposed SNN-based architectures are designed upon the deep neural learning paradigm. Therefore, they still encountered several challenges with regard to the feature noise and data uncertainty. To overcome these limitations, in this paper, we proposed a novel integrated SNN and neuro-fuzzy network (NFN) graph embedding technique, called as: SFGE. Our SFGE model is designed to better capture the multi-way structural representation of graph by taking advances of different advanced graph-based and fuzzy-based neural learning techniques. By taking advances of neuro-fuzzy learning approach, our model can efficiently support to eliminate the feature uncertainty/ambiguity during the task-driven fine-tuning process. In addition, it also supports to better capture the rich multi-way relational structures of the input graphs under the topology-enhanced graph analysis approach. Extensive empirical studies within a real-world molecular graph dataset have effectiveness of our SFGE in dealing with graph classification task.},
  archive      = {J_IJMLC},
  author       = {Pham, Phu},
  doi          = {10.1007/s13042-024-02201-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {233-251},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An integrated simplicial neural network with neuro-fuzzy network for graph embedding},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-strategy dung beetle optimizer for global optimization and feature selection. <em>IJMLC</em>, <em>16</em>(1), 189-231. (<a href='https://doi.org/10.1007/s13042-024-02197-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dung beetle optimizer (DBO) is a novel meta-heuristic algorithm proposed to imitate the habits of dung beetles. However, the parameter changes in the DBO affect the stability of the results. As the boundary shrunk is likely to cause overlap solutions, the algorithm eventually traps in local solutions. To overcome the weaknesses of DBO, the proposed version presents an integrated variant of DBO with the adaptive strategy, the dynamic boundaries individual position micro-adjustment strategy, and the mutation strategy, called BGADBO. First, an adaptive strategy is applied to overcome the instability caused by parameter changes. Then, introducing the linear scaling method to adjust the position of individuals within the dynamic boundary enriches the population diversity. The dynamic learning mechanism is introduced to enhance the adaptive capability of individuals when adjusting their positions. Finally, a Gaussian mutation mechanism is introduced to enhance the performance of the algorithm to escape the local optimum. In the experiment, we take the CEC2005 and CEC2019 benchmark functions to verify the performance of the proposed algorithm. In addition, the BGADBO is applied to several engineering optimization problems and feature selection (FS) problems to evaluate the application value. The experimental results indicate the proposed algorithm superior performance compared with the DBO and other well-established algorithms.},
  archive      = {J_IJMLC},
  author       = {Xia, Huangzhi and Chen, Limin and Xu, Hongwen},
  doi          = {10.1007/s13042-024-02197-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {189-231},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-strategy dung beetle optimizer for global optimization and feature selection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guaranteed performance control for delayed markov jump neural networks with output quantization and data-injection attacks. <em>IJMLC</em>, <em>16</em>(1), 173-188. (<a href='https://doi.org/10.1007/s13042-024-02195-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers guaranteed performance control for delayed Markov jump neural networks (DMJNNs) under output quantization and data-injection attacks. The objective is to design an asynchronous output-feedback controller (OFC) that takes into account both quantization and attacks to achieve stochastic stability and ensure the boundedness of a predefined performance index. An exponential hidden Markov model is employed to represent the asynchrony between the modes of the OFC and the DMJNN. A sufficient condition for the desired performance is presented using free-weight matrix and Lyapunov–Krasovskii functional methods, integral inequalities, and Dynkin’s formula. Two distinct controller design approaches are proposed, depending on whether the coefficient matrix of the control input is a unit matrix while considering factors related to attacks and quantization. Optimization algorithms are developed based on the proposed controller design approaches, allowing for the determination of the minimum upper bound of the predefined performance index and the accompanying controller gains. Finally, a simulation example is provided to illustrate the applicability and effectiveness of the optimization algorithms developed.},
  archive      = {J_IJMLC},
  author       = {He, Lanlan and Zhang, Xiaoqing and Jiang, Taiping and Tang, Chaoying},
  doi          = {10.1007/s13042-024-02195-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {173-188},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Guaranteed performance control for delayed markov jump neural networks with output quantization and data-injection attacks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-class feature selection via sparse softmax with a discriminative regularization. <em>IJMLC</em>, <em>16</em>(1), 159-172. (<a href='https://doi.org/10.1007/s13042-024-02185-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection plays a critical role in many machine learning applications as it effectively addresses the challenges posed by “the curse of dimensionality” and enhances the generalization capability of trained models. However, existing approaches for multi-class feature selection (MFS) often combine sparse regularization with a simple classification model, such as least squares regression, which can result in suboptimal performance. To address this limitation, this paper introduces a novel MFS method called Sparse Softmax Feature Selection ( $$S^2FS$$ ). $$S^2FS$$ combines a $$l_{2,0}$$ -norm regularization with the Softmax model to perform feature selection. By utilizing the $$l_{2,0}$$ -norm, $$S^2FS$$ produces a more precise sparsity solution for the feature selection matrix. Additionally, the Softmax model improves the interpretability of the model’s outputs, thereby enhancing the classification performance. To further enhance discriminative feature selection, a discriminative regularization, derived based on linear discriminate analysis (LDA), is incorporated into the learning model. Furthermore, an efficient optimization algorithm, based on the alternating direction method of multipliers (ADMM), is designed to solve the objective function of $$S^2FS$$ . Extensive experiments conducted on various datasets demonstrate that $$S^2FS$$ achieves higher accuracy in classification tasks compared to several contemporary MFS methods.},
  archive      = {J_IJMLC},
  author       = {Sun, Zhenzhen and Chen, Zexiang and Liu, Jinghua and Yu, Yuanlong},
  doi          = {10.1007/s13042-024-02185-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {159-172},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Multi-class feature selection via sparse softmax with a discriminative regularization},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Igtracker: Task and instance information gaps in multiple object tracking. <em>IJMLC</em>, <em>16</em>(1), 143-158. (<a href='https://doi.org/10.1007/s13042-024-02182-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian multiple object tracking targets to track multiple pedestrian instances in real-time. Recently, the methods based on joint detection and embedding have improved performance by sharing task features. However, it has two obvious shortcomings: inconsistent task information and ambiguous neighbor instance overlap. Hence, the branch tasks information gap and instances information gap need to be carefully addressed. In this paper, IGTracker is proposed as a novel online tracking framework, which bridges different branch task optimization requirements from the perspective of task-specific information gaps and nearest instance information gaps. Firstly, to alleviate the competitive conflict between subtasks, we propose a shuffle involution decoupling (SID) module, which constructs task-specific features by focusing on local interaction information and global long-range dependencies of key points. Secondly, the nearest neighbor information enhancement (NNIE) strategy is proposed to reduce the ambiguity between similar instances by leveraging the adjacency key point information gap. As a bonus, our proposed IGTracker achieves competitive performance compared to various existing methods on the MOTChallenge benchmarks.},
  archive      = {J_IJMLC},
  author       = {Liu, Jialin and Kong, Jun and Jiang, Min and Zhuang, Danfeng},
  doi          = {10.1007/s13042-024-02182-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {143-158},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Igtracker: Task and instance information gaps in multiple object tracking},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prompt-based data labeling method for aspect based sentiment analysis. <em>IJMLC</em>, <em>16</em>(1), 127-142. (<a href='https://doi.org/10.1007/s13042-024-02180-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ABSA aims to extract aspect terms and corresponding sentiment from unstructured texts. Supervised approaches are widely used in existing ABSA models because of their model maturity, and most of them usually need large-scale training data to deal with over-fitting. However, in real scenarios, the labeled data is difficult to obtain, thus the performance is adversely influenced. To address these issues, this paper proposes a prompt-based data augmentation method, enabling it to overcome small data problems by expanding the sample size in the training corpus. Our approach computes the relationship between the prompt templates and unlabeled data and then assigns labels to expand the training data. To achieve this, we formulate it as a data filtering problem and implement it with Natural Language Inference models. The experimental results on four well-studied datasets demonstrate that our model not only achieves results on par with existing state-of-the-art data augmentation methods on a few occasions but also significantly improves the effectiveness of existing ABSA models on most occasions, indicating its strong robustness in various base ABSA models. Further discussion shows that prompt learning can help the model mark data from unlabeled datasets, which explains its effectiveness in data augmentation.},
  archive      = {J_IJMLC},
  author       = {Bu, Kun and Liu, Yuanchao},
  doi          = {10.1007/s13042-024-02180-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {127-142},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Prompt-based data labeling method for aspect based sentiment analysis},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain adaptation with optimized feature distribution for streamer action recognition in live video. <em>IJMLC</em>, <em>16</em>(1), 107-125. (<a href='https://doi.org/10.1007/s13042-024-02174-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the large-scale annotation of streamer actions is expensive, training with generic action data is a practical approach. Nevertheless, the spatiotemporal differences between generic actions and streamer actions decrease the recognition accuracy. Domain adaptation utilizes labeled data from both the source domain and target domain to mitigate the performance degradation of target domain data, but it relies on (1) the feature distribution of each category that satisfies the clustering assumption and (2) the distribution of features of the same category in different domains having minimal discrepancy. Considering that streamer action recognition in live video does not meet the above assumptions, we propose a domain adaptation method with optimized feature distribution for streamer action recognition in live video. The method generates diverse features for each sample through the style transfer module and then uses the proposed metric learning loss to constrain the features in a similar feature space to satisfy the above assumptions. The experimental results show that our method has an accuracy of 86.35%, which exceeds the SOTA by 4.71% and an inference speed of 1500 FPS, which is capable of performing the task of streamer action recognition in live video.},
  archive      = {J_IJMLC},
  author       = {He, Chen and Zhang, Jing and Chen, Lin and Zhang, Hui and Zhuo, Li},
  doi          = {10.1007/s13042-024-02174-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {107-125},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Domain adaptation with optimized feature distribution for streamer action recognition in live video},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image retrieval by aggregating deep orientation structure features. <em>IJMLC</em>, <em>16</em>(1), 93-106. (<a href='https://doi.org/10.1007/s13042-024-02172-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aggregating deep features for image retrieval has shown excellent performance in terms of accuracy. However, exploring visual perception properties to activate the dormant discriminative cues of deep convolutional feature maps has received little attention. To address this issue, we present a novel representation, namely the deep orientation aggregation histogram, to image retrieval via aggregating deep orientation structure features. Its main highlights are: (1) A statistical orientation computation model is proposed to detect candidate directions. It will help to use the feature maps to exploit various orientation to provide robust representation. (2) A computed module is proposed to active the discriminative orientation cues hidden in the deep convolutional feature maps. It can boost the representation of deep features with aid of the statistical orientation and their orientation structures. (3) The proposed method can stimulate orientation-selectivity mechanism to provide a strong discriminative yet compact representation. Experimental results on five popular benchmark datasets demonstrated that the proposed method could improve retrieval performance in terms of mAP scores. Furthermore, it outperforms some existing state-of-the-art methods without complex fine-tuning. The proposed method benefits to retrieve the scene images with various color and direction details.},
  archive      = {J_IJMLC},
  author       = {Lu, Fen and Liu, Guang-Hai},
  doi          = {10.1007/s13042-024-02172-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {93-106},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Image retrieval by aggregating deep orientation structure features},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning for multi-agent with asynchronous missing information fusion method. <em>IJMLC</em>, <em>16</em>(1), 75-91. (<a href='https://doi.org/10.1007/s13042-024-02170-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most current research on multi-agent reinforcement learning assumes a reliable environment where agents have globally accurate observations. However, this assumption places high demands on communication between agents and has hindered the large-scale application of reinforcement learning algorithms in realistic scenarios. This paper presents, for the first time, a state estimation method that addresses the problem of training failure caused by asynchronous missing information. Our approach addresses the training dispersion problem caused by information asynchrony, noise, measurement errors, and missing information during multi-agent interaction. We use neural networks to construct recursive state models for the agent environment with limited state information and fill in the missing and asynchronous information with state estimates for reinforcement learning training. In the simulation validation stage, we combine the designed asynchronous missing information fusion algorithm with multi-agent reinforcement learning algorithms for validation. Our results demonstrate that our algorithm overcomes the problem of unsuccessful training due to asynchronous information when the information missing rate does not exceed 30%.},
  archive      = {J_IJMLC},
  author       = {Gao, Jiashan and Wang, Shaoping and Wang, Xingjian and Zhang, Yuwei and Yang, Xinyu},
  doi          = {10.1007/s13042-024-02170-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {75-91},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Reinforcement learning for multi-agent with asynchronous missing information fusion method},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning enhancing modality-invariant features for visible-infrared person re-identification. <em>IJMLC</em>, <em>16</em>(1), 55-73. (<a href='https://doi.org/10.1007/s13042-024-02168-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the task of visible-infrared person re-identification, most existing methods embed all images into a unified feature space through shared parameters, and then use a metric learning loss function to learn modality-invariant features. However, they may encounter the following two problems: For one thing, they mostly focus on modality-invariant features. In reality, some unique features within each modality can enhance feature discriminability but are often overlooked; For another, current metric learning loss functions mainly focus on feature discriminability and only align modality distributions implicitly, which leads to that the feature distributions from different modalities are still inconsistent in this unified feature space. Taking the foregoing into consideration, in this paper, we propose a novel end-to-end framework composed of two modules: the intra-modality enhancing module and the modality-invariant module. The former fully leverages modality-specific characteristics by establishing independent branches for each modality. It improves feature discriminability by further enhancing the intra-class compactness and inter-class discrepancy within each modality. The latter is designed with a cross-modality feature distribution consistency loss based on the Gaussian distribution assumption. It significantly alleviates the modality discrepancies by effectively and directly aligning the feature distribution in the unified feature space. As a result, the proposed framework can learn modality-invariant features with enhancing discriminability in each modality. Extensive experimental results on SYSU-MM01 and RegDB demonstrate the effectiveness of our method.},
  archive      = {J_IJMLC},
  author       = {Zhang, La and Zhao, Xu and Du, Haohua and Sun, Jian and Wang, Jinqiao},
  doi          = {10.1007/s13042-024-02168-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {55-73},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning enhancing modality-invariant features for visible-infrared person re-identification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy K-means clustering with reconstructed information. <em>IJMLC</em>, <em>16</em>(1), 43-53. (<a href='https://doi.org/10.1007/s13042-024-02167-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering techniques play a pivotal role in unveiling the inherent structure of unlabeled data. When dealing with overlapping clusters, traditional hard clustering methods encounter challenges. As a representative of soft clustering methods, Fuzzy K-Means (FKM) enables data points to be assigned different degrees of membership to multiple clusters, offering a solution to this problem. However, when dealing with high-dimensional data, the performance of FKM is often affected by redundant features and noise. To address this limitation, this paper introduces a Fuzzy K-Means Clustering with Reconstructed Information (FKMRI) method. This method combines the reconstruction term with a cluster weight variable to effectively capture the true nature of data structure, thereby enhancing the clustering capability of FKM in high-dimensional spaces. We theoretically analyze the convergence of the FKMRI algorithm and prove its time complexity to be $$O\left( (c+P(c)) n d^2+c n d\right)$$ . Finally, we evaluate the performance of FKMRI on standard benchmark datasets including Yale-32x32, Yale-64x64, ORL-32x32, and ORL-64x64. The results demonstrate that, in comparison to five current state-of-the-art algorithms (K-Means, FKM, Kernel-km, RSFKM, DFKM), FKMRI exhibits an average improvement of over 18% in terms of accuracy rate (ACC) and normalized mutual information (NMI). These findings convincingly validate the effectiveness and efficiency of the proposed algorithm in handling high-dimensional data clustering, providing valuable support for related research fields.},
  archive      = {J_IJMLC},
  author       = {Huang, Honglan and Shi, Wei and Yang, Fangjie and Feng, Yanghe and Zhang, Longfei and Liang, Xingxing and Shi, Jun and Cheng, Guangquan and Huang, Jincai and Liu, Zhong},
  doi          = {10.1007/s13042-024-02167-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {43-53},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fuzzy K-means clustering with reconstructed information},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-rank tensor learning with projection distance metric for multi-view clustering. <em>IJMLC</em>, <em>16</em>(1), 25-41. (<a href='https://doi.org/10.1007/s13042-024-02166-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace approaches have been extensively studied for their ability to project data onto a low-dimensional space, which is in favour of the clustering task. However, most existing models mainly concentrate on reconstructing data from the sample space, neglecting crucial information from the feature space, and failing to learn an optimal representation. For addressing this issue, we present a new joint framework, dubbed low-rank tensor learning with projection distance metric. This model recovers the original data by learning two low-rank factors, which thoroughly exploits the essential data information. Specifically, a low-rank constraint is introduced on a tensor that integrates subspace representations of all view data, enabling it to capture high-order relationships among views while recovering data from the sample space. Meanwhile, a low-rank projection matrix calculated by decomposing the original features is utilized to enhance data structures via exploring relationships among feature dimensions. Additionally, a distance metric learned by the projection matrix is introduced to leverage the local structure embedded in samples, thereby encouraging the learned representation to be more discriminative. Extensive experimental results on six datasets indicate the superiority of the proposed model.},
  archive      = {J_IJMLC},
  author       = {Huang, Sujia and Fu, Lele and Du, Shide and Wu, Zhihao and Vasilakos, Athanasios V. and Wang, Shiping},
  doi          = {10.1007/s13042-024-02166-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {25-41},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Low-rank tensor learning with projection distance metric for multi-view clustering},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double-quantitative multi-granularity kernel fuzzy rough sets model and its application in rheumatoid arthritis risk assessment. <em>IJMLC</em>, <em>16</em>(1), 1-23. (<a href='https://doi.org/10.1007/s13042-024-02144-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The medical big data of combined Chinese and western medicine diagnosis and treatment (CCWMDT) is difficult to be used effectively in clinical medical decision-making because of its complex structure and multi-source storage. In this paper, we discuss the problem of multi-attribute group decision making (MAGDM) in complex information systems with multi-source, diversified and hybrid attribute information. With the help of traditional information systems, a hybrid diversified attribute information system (HDAIS) is first defined. Further, with the involvement of kernel functions, a binary relation over HDAISs is then presented. At the same time, in response to the problem of inaccurate information, a double-quantitative model is introduced to extract effective information from the perspective of absolute and relative metrics, and the rough approximations of a decision target concept under the multi-granularity framework are given, namely, a double-quantitative multi-granularity kernel fuzzy rough set (DQ-MGKFRS). Based on the above, a group decision method is established on DQ-MGKFRS to realize the information fusion of HDAIS. Finally, the proposed method used in the medical decision problem of rheumatoid arthritis (RA) diagnosis. The results of comparative analysis and sensitivity analysis illustrate the feasibility, effectiveness and robustness of our method.},
  archive      = {J_IJMLC},
  author       = {Dai, Xianjun and Sun, Bingzhen and Bai, Juncheng and Ye, Jin and Chu, Xiaoli},
  doi          = {10.1007/s13042-024-02144-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {1},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Double-quantitative multi-granularity kernel fuzzy rough sets model and its application in rheumatoid arthritis risk assessment},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
