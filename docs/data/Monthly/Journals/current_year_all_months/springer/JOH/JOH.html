<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JOH</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="joh">JOH - 31</h2>
<ul>
<li><details>
<summary>
(2025). A new, efficient approach to speed up local search by estimating the solution quality: An application to stochastic, parallel machine scheduling. <em>JOH</em>, <em>31</em>(3), 1-31. (<a href='https://doi.org/10.1007/s10732-025-09562-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local search has become a very powerful tool to solve hard optimization problems. One of the key parts here is that you must decide to accept or reject a new solution, for which we compare the objective values of the incumbent and the new solution. Since in general very many iterations are involved, it is important that this comparison can be done efficiently. In case of a stochastic problem, where we want to optimize the expected value, it is often impossible to do the comparison analytically. We can resolve this by simulating a solution, but to find an accurate estimate we need many simulations, which may take a lot of time. In this paper we present an alternative method to estimate the expected value for problems involving waiting relations. To apply this method we must iteratively compute the maximum of several stochastic variables. Thereto, we pretend that all stochastic variables are normally distributed, after which we iteratively estimate the expected value and standard deviation of the maximum of two variables; in the further analysis we pretend this maximum to be normally distributed again. We test the efficiency of this method on a specific scheduling problem with precedence relations. In our experiments we find that this approximation method in many cases produces better solutions than estimating the expected makespan using 1000 independent simulations per iteration, and it always dominates using 300 simulations per iteration, while using only a fraction of the time. Moreover, this method of estimating the distribution of the maximum seems to be widely applicable. For example, we can use it for all kinds of planning problems in which a person/task must wait until at least two other events have been completed, which is a typical situation in which a direct computation of the expected value is intractable.},
  archive      = {J_JOH},
  author       = {Passage, Guido and van den Akker, Marjan and Hoogeveen, Han},
  doi          = {10.1007/s10732-025-09562-5},
  journal      = {Journal of Heuristics},
  month        = {9},
  number       = {3},
  pages        = {1-31},
  shortjournal = {J. Heuristics},
  title        = {A new, efficient approach to speed up local search by estimating the solution quality: An application to stochastic, parallel machine scheduling},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A tabu-bi-label hybridized branch and price algorithm for just-in-time material handling scheduling problems of mixed-model assembly lines with electric vehicle recharging requirements. <em>JOH</em>, <em>31</em>(3), 1-34. (<a href='https://doi.org/10.1007/s10732-025-09563-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the highly-diversified customer demand, mixed-model automobile assembly lines (MMAALs) have been widely applied to enable the mass production of customized automobiles. Meanwhile, an inexorable trend in the green and sustainable production has promoted the optimization of material handling scheduling, which constitutes a large proportion of the energy consumption in the automobile production. Therefore, to deal with both manufacturing and energy issues, this article employed electric vehicles (EVs) and proposed a supermarket integrated MMAAL material handling scheduling problem under JIT settings with EV recharging requirements. A mixed integer linear programming model is consequently established, aiming to minimize the number of EVs for reducing cost as well as saving energy. In order to obtain the global optimal solution, a Tabu-Bi-Label Hybridized Branch and Price Algorithm (TBHBP) algorithm is developed, a heuristic Tabu Search algorithm is combined with a modified Bidirectional Labeling for achieving much faster speed while maintaining a high solution quality. Computational experiments on TBHBP along with a case study are carried out and compared with benchmark algorithms, the results of which verified the efficiency and effectiveness of TBHBP in dealing with the proposed problem.},
  archive      = {J_JOH},
  author       = {Huang, Yufan and Zhou, Binghai},
  doi          = {10.1007/s10732-025-09563-4},
  journal      = {Journal of Heuristics},
  month        = {9},
  number       = {3},
  pages        = {1-34},
  shortjournal = {J. Heuristics},
  title        = {A tabu-bi-label hybridized branch and price algorithm for just-in-time material handling scheduling problems of mixed-model assembly lines with electric vehicle recharging requirements},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selector: Ensemble-based automated algorithm configuration. <em>JOH</em>, <em>31</em>(3), 1-31. (<a href='https://doi.org/10.1007/s10732-025-09561-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solvers contain parameters that influence their performance and these must be set by the user to ensure that high-quality solutions are generated, or optimal solutions are found quickly. Manually setting these parameters is tedious and error-prone, since search spaces may be large or even infinite. Existing approaches to automate the task of algorithm configuration (AC) make use of a single machine learning model that is trained on previous runtime data and used to create or evaluate promising new configurations. We combine a variety of successful models from different AC approaches into an ensemble that proposes new configurations. To this end, each model in the ensemble suggests configurations and a hyper-configurable selection algorithm chooses a subset of configurations to match the amount of computational resources available. We call this approach Selector, and we examine its performance against the state-of-the-art AC methods PyDGGA and SMAC, respectively. The new configurator will be made available as an open source software package.},
  archive      = {J_JOH},
  author       = {Wei√ü, Dimitri and Schede, Elias and Tierney, Kevin},
  doi          = {10.1007/s10732-025-09561-6},
  journal      = {Journal of Heuristics},
  month        = {9},
  number       = {3},
  pages        = {1-31},
  shortjournal = {J. Heuristics},
  title        = {Selector: Ensemble-based automated algorithm configuration},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient hybridization of quantum annealing and ant colony optimization for coloring DIMACS graph instances. <em>JOH</em>, <em>31</em>(3), 1-44. (<a href='https://doi.org/10.1007/s10732-025-09565-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph coloring problem is a well-known NP-complete combinatorial optimization problem where the goal is to assign colors to the vertices of a graph such that no adjacent vertices share the same color. Despite extensive research, no known polynomial-time algorithm exists for finding the optimal coloring for all the benchmark graph instances. This paper presents a time-efficient effective hybridization of ant colony optimization and quantum annealing algorithms in a single framework to solve graph coloring. The algorithm has been tested on 100 standard DIMACS benchmark graph instances of varying size and complexity. The experimental result shows that quantum annealing outperforms the performances of ant colony optimization in terms of obtaining the optimal/best-known chromatic number. However, the runtime of quantum annealing is too high for some simple graph instances of larger size. On the other hand, ant colony optimization gives faster result than quantum annealing for the simple graphs, but the performance is not satisfactory for some complex benchmark instances. The hybridization approach gives optimal/best-known results for the complex graphs and takes less time for the large-sized instances. By conducting a performance comparison among the individual algorithms with the hybridization using Friedman Test and Nemenyi Post-hoc analysis, the worthiness of the proposed hybrid algorithm is explained, establishing its promising nature.},
  archive      = {J_JOH},
  author       = {Kole, Arnab and Pal, Anindya Jyoti},
  doi          = {10.1007/s10732-025-09565-2},
  journal      = {Journal of Heuristics},
  month        = {9},
  number       = {3},
  pages        = {1-44},
  shortjournal = {J. Heuristics},
  title        = {Efficient hybridization of quantum annealing and ant colony optimization for coloring DIMACS graph instances},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SolQHealer: Quantum procedures for rendering infeasible solutions feasible: A proof of concept with the maximum independent set problem and 3-SAT. <em>JOH</em>, <em>31</em>(3), 1-28. (<a href='https://doi.org/10.1007/s10732-025-09564-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, the usefulness of quantum annealing hardware for combinatorial optimization has been the subject of active debate. Although current analog quantum machines do not guarantee optimality, operating instead as heuristic solvers, the technology is evolving rapidly. Beyond performance alone, this emerging technologies offers fundamentally new approaches to problem-solving that are not readily accessible to classical exact methods particularly in dynamic environments or online optimization settings. This paper focuses on one such approaches: Reverse Quantum Annealing (RQA). Unlike classical exact methods, RQA allows the optimization process to begin from an initial infeasible solution by embedding it directly into the qubits‚Äô initial state. We leverage this capability by formulating problem constraints as penalty terms within Quadratic Unconstrained Binary Optimization (QUBO) models, thereby preserving infeasible solutions within the quantum search space. We propose iterative strategies that apply RQA in three distinct modes to rapidly repair infeasible solutions. These methods are evaluated on two well-known NP-hard problems: the Maximum Independent Set (MIS) and the 3-SAT problem. Our results demonstrate the effectiveness of RQA in steering infeasible configurations toward feasibility, offering promising potential for real-time applications where problem data may change suddenly and solutions must be repaired swiftly.},
  archive      = {J_JOH},
  author       = {Deleplanque, Samuel and P√©rez Armas, Luis Fernando and Creemers, Stefan},
  doi          = {10.1007/s10732-025-09564-3},
  journal      = {Journal of Heuristics},
  month        = {9},
  number       = {3},
  pages        = {1-28},
  shortjournal = {J. Heuristics},
  title        = {SolQHealer: Quantum procedures for rendering infeasible solutions feasible: A proof of concept with the maximum independent set problem and 3-SAT},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic capacitated dispersion problems in disaster preparedness for mass casualty incident. <em>JOH</em>, <em>31</em>(3), 1-30. (<a href='https://doi.org/10.1007/s10732-025-09566-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent disasters that cause mass casualty incidents ‚Äìsuch as the 2020 Beirut explosion or the 2023 Turkey-Syria earthquake‚Äì have shown that critical facilities, which are meant to help the casualties, could be damaged by them. Therefore, it is critical to increase the resiliency of critical facilities by dispersing their locations. This paper proposes a stochastic capacitated dispersion model that considers a scenario in which a disaster can cause mass casualty incidents and damage critical facilities. The extent of damage is modeled as a function of the distance between the site locations of the facility and the epicenter of the disaster, as well as the level of severity of the disaster. The model incorporates a chance constraint to account for supply uncertainty. To solve this stochastic optimisation problem, we propose a new simheuristic algorithm that combines simulation and heuristic optimisation. Experiments show that our algorithm produces solutions that match the quality of the best deterministic solutions reported in the literature. In the stochastic disaster scenario, our algorithm produces solutions that can meet demand 90% of the time, while deterministic solutions fail to meet this demand.},
  archive      = {J_JOH},
  author       = {Onggo, B. Stephan and Martin, Xabier A. and Corlu, Canan G. and Panadero, Javier and Juan, Angel A.},
  doi          = {10.1007/s10732-025-09566-1},
  journal      = {Journal of Heuristics},
  month        = {9},
  number       = {3},
  pages        = {1-30},
  shortjournal = {J. Heuristics},
  title        = {Stochastic capacitated dispersion problems in disaster preparedness for mass casualty incident},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive variable neighborhood search for the traveling salesman problem with job-times. <em>JOH</em>, <em>31</em>(2), 1-65. (<a href='https://doi.org/10.1007/s10732-025-09553-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Traveling Salesman Problem with Job-times (TSPJ) is an extension problem that integrates the Traveling Salesman Problem and the Job Scheduling Problem. TSPJ refers to finding the optimal route for a salesman to visit each location exactly once while assigning one job to each location. Each job can only be assigned once, and its completion time depends on the assigned location. The objective of the TSPJ is to minimize the maximum completion time of all jobs. This paper studies the problem from a new perspective and illustrates the realistic application scenarios of TSPJ. To solve the problem efficiently, we propose a Variable Neighborhood Search algorithm embedded in an adaptive shaking strategy and an intensive local search procedure. The adaptive shaking strategy invokes the small-perturbation or large-perturbation strategy according to the searching states and results during the searching procedure. In the proposed local search procedure, the first improvement strategy is adopted and the parameter of perturbation strength is updated for the following procedures. Experimental results on 310 benchmark instances demonstrate that the proposed algorithm outperforms the state-of-the-art heuristic methods. In particular, the best-known solutions are improved in 241 instances and the proposed algorithm can obtain the same results as the best-known solutions in 60 instances. Two statistical tests show that the results obtained by the proposed algorithm have significant differences from those of the compared methods and therefore verify the superiority of our method.},
  archive      = {J_JOH},
  author       = {Lan, Shaowen and Lu, Yongliang and Fan, Wenjuan},
  doi          = {10.1007/s10732-025-09553-6},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {2},
  pages        = {1-65},
  shortjournal = {J. Heuristics},
  title        = {An adaptive variable neighborhood search for the traveling salesman problem with job-times},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reliability-extended simheuristic for the sustainable vehicle routing problem with stochastic travel times and demands. <em>JOH</em>, <em>31</em>(2), 1-39. (<a href='https://doi.org/10.1007/s10732-025-09555-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-life transport operations are often subject to uncertainties in travel time or customers‚Äô demands. Additionally, these uncertainties greatly impact the economic, environmental, and social costs of vehicle routing plans. Thus, analysing the sustainability costs of transportation activities and reliability in the presence of uncertainties is essential for decision makers. Accordingly, this paper addresses the Sustainable Vehicle Routing Problem with Stochastic Travel times and Demands. This paper proposes a novel weighted stochastic recourse model that models travel time and demand uncertainties. To solve this challenging problem, we propose an extended simheuristic that integrates reliability analysis to evaluate the reliability of the generated solutions in the presence of uncertainties. An extensive set of computational experiments is carried out to illustrate the potential of the proposed approach and analyse the influence of stochastic components on the different sustainability dimensions.},
  archive      = {J_JOH},
  author       = {Abdullahi, Hassana and Reyes-Rubiano, Lorena and Ouelhadj, Djamila and Faulin, Javier and Juan, Angel A.},
  doi          = {10.1007/s10732-025-09555-4},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {2},
  pages        = {1-39},
  shortjournal = {J. Heuristics},
  title        = {A reliability-extended simheuristic for the sustainable vehicle routing problem with stochastic travel times and demands},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid algorithms for enhanced efficiency and scalability of network-based tri-level interdiction models. <em>JOH</em>, <em>31</em>(2), 1-43. (<a href='https://doi.org/10.1007/s10732-025-09554-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on optimizing resilience strategies for interdependent infrastructure networks (e.g., electric power, water supply, transportation system) against intelligent attacks. We formulate this problem as a tri-level defender-attacker-defender (DAD) model, which is known for its computational complexity. To address this challenge, we propose two novel hybrid decomposition-based algorithms: the hybrid Benders decomposition-based (HBD) algorithm and the hybrid set covering-based (HSC) algorithm. These algorithms efficiently solve the nested subproblems (master problem and subproblem) of the tri-level DAD formulation, incorporating metaheuristic algorithms for improved performance. The proposed algorithms are applied to a tri-level protection-interdiction-restoration model to optimize network resilience. Two case studies are used to evaluate the effectiveness of the solution techniques: (i) An interdependent system of water, gas, and power networks with 125 nodes and 164 links, and (ii) A simulated system of two networks with 252 nodes and 507 links. Our results demonstrate that both hybrid algorithms offer high-quality solutions with significantly improved computational efficiency compared to the existing exact solution method based on the set covering approach. In our comparison across different case studies and budget scenarios, we find that for higher budget scenarios, the HBD algorithm outperforms the HSC algorithm and is more computationally efficient. For lower budget scenarios, the performance of both algorithms is similar, with the HSC algorithm showing slightly better performance in terms of computational speed. Both algorithms show clear advantages over the set covering (CD) approach, particularly when available budget grows. This study highlights that the choice between the HBD and HSC algorithms depends on both the case study size and available budget, with the HBD algorithm being preferable in higher budget scenarios and the HSC algorithm being slightly more efficient in lower budget scenarios.},
  archive      = {J_JOH},
  author       = {Ghorbani-Renani, Nafiseh and Gonz√°lez, Andr√©s D. and Barker, Kash},
  doi          = {10.1007/s10732-025-09554-5},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {2},
  pages        = {1-43},
  shortjournal = {J. Heuristics},
  title        = {Hybrid algorithms for enhanced efficiency and scalability of network-based tri-level interdiction models},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient solution of the number partitioning problem on a quantum annealer: A hybrid quantum-classical decomposition approach. <em>JOH</em>, <em>31</em>(2), 1-20. (<a href='https://doi.org/10.1007/s10732-025-09556-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current quantum computers can only solve optimization problems of a very limited size. For larger problems, decomposition methods are required in which the original problem is broken down into several smaller sub-problems. These are then solved on the quantum computer and their solutions are recombined into a final solution for the original problem. Often, these decomposition methods do not take the specific problem structure into account. In this paper, we present a tailored method using a divide-and-conquer strategy to solve the 2-way Number partitioning problem (NPP) with a large number of variables. The idea is to perform a specialized decomposition into smaller NPPs, which are solved on a quantum computer, and then recombine the results into another small auxiliary NPP. Solving this auxiliary problem yields an approximate solution of the original larger problem. We experimentally verify that our method allows to solve NPPs with over a thousand variables using the D-Wave Advantage quantum annealer (Advantage_system6.4).},
  archive      = {J_JOH},
  author       = {Li, Zongji and Seidel, Tobias and Leib, Dominik and Bortz, Michael and Heese, Raoul},
  doi          = {10.1007/s10732-025-09556-3},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {2},
  pages        = {1-20},
  shortjournal = {J. Heuristics},
  title        = {Efficient solution of the number partitioning problem on a quantum annealer: A hybrid quantum-classical decomposition approach},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid iterated local search algorithm for the vehicle routing problem with lockers. <em>JOH</em>, <em>31</em>(2), 1-25. (<a href='https://doi.org/10.1007/s10732-025-09557-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Vehicle Routing Problem (VRP) with Lockers, the vertices in a graph are divided into two key subsets: a customer set and a locker set, with lockers serving as alternative delivery points for the customer‚Äôs parcel. This paper presents a generic VRP with lockers, where a customer‚Äôs parcel can be delivered either to its home within a time windows or to a nearby locker, where they can pick it up at any time. The objective is to design a set of routes for a fleet of homogeneous vehicles in order to minimize the total travel, vehicle and assignment costs in a such manner that each locker can be visited at most once, the capacities of the vehicles and lockers are not exceeded and the time windows constraints are ensured. To solve this problem. we propose a hybrid metaheuristic that combines Iterated Local Search with a Set Partitioning-like model. Our algorithm uses several classical and specific neighborhood operators. We demonstrate the effectiveness of the proposed methodology by evaluating it on benchmark literature instances from three problems that we show that are encompassed by the generic problem defined in this paper. The results show that we found or improved 432 out of 490 best known solutions.},
  archive      = {J_JOH},
  author       = {Oliveira, Bruno and Pessoa, Artur and Roboredo, Marcos},
  doi          = {10.1007/s10732-025-09557-2},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {2},
  pages        = {1-25},
  shortjournal = {J. Heuristics},
  title        = {Hybrid iterated local search algorithm for the vehicle routing problem with lockers},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast constructive heuristics for the uncapacitated inventory routing problem. <em>JOH</em>, <em>31</em>(2), 1-31. (<a href='https://doi.org/10.1007/s10732-025-09558-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inventory routing problem (IRP) poses a significant optimization challenge across various industries. This paper focuses on the uncapacitated IRP, by introducing fast constructive heuristics integrating insights from approximation algorithms, particularly rounding techniques in linear programming¬†(LP). The proposed heuristics efficiently deliver effective solutions, providing advantages over methods such as branch-and-cut and metaheuristics. Methodologically, we emphasize scalability, subjecting our algorithms to rigorous stress tests with larger instances. Computational experiments, utilizing 420 instances, demonstrate the effectiveness and scalability of our heuristics, notably those tailored to specific problem variants, achieving an average gap of 2.2%. Our work underscores the effectiveness of leveraging approximation algorithms for the uncapacitated IRP, with future directions aimed at enhancing heuristics for broader real-world applicability, including the capacitated version of the IRP.},
  archive      = {J_JOH},
  author       = {Alarc√≥n, Miguel √Ångel Marfurt and Pedrosa, Lehilton Lelis Chaves and Usberti, F√°bio Luiz},
  doi          = {10.1007/s10732-025-09558-1},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {2},
  pages        = {1-31},
  shortjournal = {J. Heuristics},
  title        = {Fast constructive heuristics for the uncapacitated inventory routing problem},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A biased-randomised iterated local search for the team orienteering arc routing problem allowing different origin and destination. <em>JOH</em>, <em>31</em>(2), 1-27. (<a href='https://doi.org/10.1007/s10732-025-09559-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the hybridisation of the team orienteering problem and the arc routing problem, the so-called team orienteering arc routing problem (TOARP). This problem has recently raised interest among researchers and practitioners as it can model new routing problems involving unmanned aerial vehicles or other types of electric vehicles. In the TOARP, a fixed fleet of vehicles, initially located at a depot, has to collect as much reward as possible from visiting a set of arcs, while they must visit a set of required arcs. At the same time, they must return to the depot on or before a given deadline (which can be time-based or distance-based). In this paper, we explore an extension of the TOARP in which the origin depot and the destination depot may be different nodes in a network. To solve this version of the problem, we propose a novel biased-randomised iterated local search algorithm. Computational results show the capability, efficiency and robustness of our approach, which provides competitive solutions to the TOARP in short computing times and outperforms some of the best-known solution approaches in the literature.},
  archive      = {J_JOH},
  author       = {Martin, Xabier A. and Keenan, Peter and Panadero, Javier and McGarraghy, Sean and Juan, Angel A.},
  doi          = {10.1007/s10732-025-09559-0},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {2},
  pages        = {1-27},
  shortjournal = {J. Heuristics},
  title        = {A biased-randomised iterated local search for the team orienteering arc routing problem allowing different origin and destination},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tree search hyper-heuristic with application to combinatorial optimization. <em>JOH</em>, <em>31</em>(2), 1-42. (<a href='https://doi.org/10.1007/s10732-025-09560-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we investigate using the state space search paradigm to construct heuristics in the form of Priority Rules for combinatorial optimisation problems. This is an alternative to Genetic Programming (GP) and other hyper‚Äìheuristics, which represent the most common approach currently used. To do that, we define the problem of designing heuristics as a Constraint Satisfaction Problem and then exploit Any-Time Depth-First Search to solve it. To limit the effective size of the search space, we introduced a set of powerful pruning mechanisms, some embedded into the problem definition as constraints, while others by means of constraint propagation procedures. To further reduce the search space, we propose a heuristic procedure that allows the algorithm to discard some non-promising PRs, at low computational cost. The proposed approach, termed Systematic Search and Heuristic Evaluation (SSHE), was evaluated on two hard combinatorial optimisation problems, namely the One Machine Scheduling Problem with time-varying capacity (denoted by $$(1,Cap(t)||\sum T_j)$$ ) and the classic Travelling Salesman Problem. The results of the experimental study show that SSHE is quite competitive with GP in building PRs; in particular, the PRs obtained by SSHE and GP showcase similar performance, but the ones produced by SSHE have generally lower size and so better readability than the PRs produced by GP.},
  archive      = {J_JOH},
  author       = {Gil-Gala, Francisco Javier and ∆âurasevic, Marko and Sierra, Maria R. and Varela, Ramiro},
  doi          = {10.1007/s10732-025-09560-7},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {2},
  pages        = {1-42},
  shortjournal = {J. Heuristics},
  title        = {Tree search hyper-heuristic with application to combinatorial optimization},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lagrangian-based heuristics for production planning with perishable products, scarce resources, and sequence-dependent setup times. <em>JOH</em>, <em>31</em>(1), 1-35. (<a href='https://doi.org/10.1007/s10732-024-09539-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a lot-sizing and scheduling problem apparent in the food industry that stemmed originally from the Brazilian meat production sector. More specifically, we consider a production environment in which various production lines share a set of scarce production resources. Therefore, only a subset of the existing production lines can simultaneously operate in each period under the limitations of the availability of resources. Moreover, we consider sequence-dependent setup times and costs, significant inventory holding costs, backlogging, and perishable products. The problem is formulated as a mixed integer programming model, and we propose four Lagrangian-based heuristics to find high-quality solutions for challenging instances. A computational study shows that proposed approaches are very competitive in solving the problem, outperforming methods already established in the literature.},
  archive      = {J_JOH},
  author       = {Soler, Willy A. Oliveira and Santos, Maristela O. and Akartunalƒ±, Kerem},
  doi          = {10.1007/s10732-024-09539-w},
  journal      = {Journal of Heuristics},
  month        = {3},
  number       = {1},
  pages        = {1-35},
  shortjournal = {J. Heuristics},
  title        = {Lagrangian-based heuristics for production planning with perishable products, scarce resources, and sequence-dependent setup times},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybridizing constraint programming and meta-heuristics for multi-mode resource-constrained multiple projects scheduling problem. <em>JOH</em>, <em>31</em>(1), 1-37. (<a href='https://doi.org/10.1007/s10732-024-09540-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Multi-Mode Resource-Constrained Multiple Projects Scheduling Problem (MMRCMPSP) is an important combinatorial optimization problem for both real-world situations in industry and academic research. Its objective is to find the best schedule for activities across multiple projects that can be executed in different modes. The schedule must consider shared resource availability and satisfy precedence and time constraints. To tackle this problem, we propose a hybrid approach that combines constraint programming (CP) with meta-heuristic algorithms. We introduce and assess a CP model that incorporates all MMRCMPSP constraints. By leveraging the strengths of CP and meta-heuristics, our approach yields new upper bounds for various MMRCMPSP benchmark instances. Additionally, we evaluate our method using existing benchmark instances for single-project scheduling problems with multiple modes and provide improved solutions for many of them.},
  archive      = {J_JOH},
  author       = {Ahmeti, Arben and Musliu, Nysret},
  doi          = {10.1007/s10732-024-09540-3},
  journal      = {Journal of Heuristics},
  month        = {3},
  number       = {1},
  pages        = {1-37},
  shortjournal = {J. Heuristics},
  title        = {Hybridizing constraint programming and meta-heuristics for multi-mode resource-constrained multiple projects scheduling problem},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-echelon van-robot routing problem with sharing-curbside satellites. <em>JOH</em>, <em>31</em>(1), 1-35. (<a href='https://doi.org/10.1007/s10732-024-09541-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High population density and commercial-activity density in urban areas make land use for urban logistics systems even more challenging. Herein, a concept named sharing-curbside satellite (SS) is involved in two-echelon city logistics systems. Traditional vans are deployed in the 1st-echelon network, whereas ground-based robots are employed in the 2nd-echelon network. As a type of nondedicated satellites, the SS shares curbside spaces with the local traffic flow, and each SS can have multiple time windows for direct transshipment between vans and robots. The SS can provide a new mode for urban deliveries through temporary and nondedicated satellites at the neighborhood level. In this study, the two-echelon van-robot routing problem with SSs (2ERP-SS) is defined. The SS synchronization involves vans being used as part of SSs, each SS has multiple time windows, cargoes are transshipped directly between vans and robots, and the available transshipment capacity decreases over time. We develop a mixed-integer linear programming model. We provide a large neighborhood search (LNS) combined with a beam search algorithm, and employ an adaptive LNS (ALNS) for comparison. The effectiveness of the mathematical formulation and heuristics are evaluated through computational experiments, and practical management insights are elucidated.},
  archive      = {J_JOH},
  author       = {Li, Hongqi and Wang, Feilong and Xiong, Hanxi and Wang, Zhiqi},
  doi          = {10.1007/s10732-024-09541-2},
  journal      = {Journal of Heuristics},
  month        = {3},
  number       = {1},
  pages        = {1-35},
  shortjournal = {J. Heuristics},
  title        = {Two-echelon van-robot routing problem with sharing-curbside satellites},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptative multi-objective scatter search for solving the dynamic bin packing problem. <em>JOH</em>, <em>31</em>(1), 1-69. (<a href='https://doi.org/10.1007/s10732-024-09537-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the dynamic multi-objective bin packing problem, a combinatorial optimization problem within the cutting/packing problems family. A solution to this problem involves packing cooling cookies into boxes while following a specific production process. In such a case, items, each with its own capacity, arrive in batches at racks. The objective is to optimize (i) the number of boxes used, (ii) the average initial heat associated with each box, and (iii) the maximum time taken to move all boxes to the storefront. This problem is addressed through an adaptive multi-objective scatter search applied to a special dynamic bin packing problem. The method begins by constructing an initial Pareto front set, specifically, the initial reference set containing diversified solutions based on the three objective functions related to the studied problem. The subsequent stages of the method operate in three collaborative phases: (i) improving the reference set by optimizing a highlighted objective function, (ii) refining the final reference set by prioritizing the optimization of average initial heat, and (iii) addressing the objective related to the maximum time to establish the final solution. Hence, to facilitate the transition between the aforementioned three phases, a hybridization between the solution combination method and the reference update method is introduced. Finally, the proposed method‚Äôs performance is evaluated using benchmark and newly generated instances and compared with recent methods. The study includes both qualitative and quantitative analyses. To identify the best-performing method among those tested, three statistical tests are conducted: the Student‚Äôs t-test, the Sign test, and the Wilcoxon signed-rank test. Additionally, performance metrics such as the $$\varepsilon $$ -test, the binary coverage measure, and the net front contribution indicator are used for evaluation. The results achieved by the proposed method surpass those published in the literature, highlighting the method‚Äôs strength and effectiveness, and establishing it as a competitive solution for the dynamic multi-objective bin-packing problem.},
  archive      = {J_JOH},
  author       = {A√Øder, M√©ziane and Boulebene, Sabrin and Hifi, Mhand},
  doi          = {10.1007/s10732-024-09537-y},
  journal      = {Journal of Heuristics},
  month        = {3},
  number       = {1},
  pages        = {1-69},
  shortjournal = {J. Heuristics},
  title        = {An adaptative multi-objective scatter search for solving the dynamic bin packing problem},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient backtracking heuristic for the resource allocation problem with compatibility and exclusivity constraints. <em>JOH</em>, <em>31</em>(1), 1-29. (<a href='https://doi.org/10.1007/s10732-024-09538-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a resource allocation problem featuring specific constraints, called exclusivity constraints, in addition to regular compatibility constraints. Resources are to be allocated to independent modules, each having a list of compatible resources. A resource can be allocated to several modules. However, some modules exhibit exclusivity constraints, requiring each of them to be allocated to one dedicated compatible resource, not shared with any other module. Such a resource allocation problem arises in the deployment of simulation modules on computational resources in a distributed simulation platform, where the simulation requester may require some modules to be allocated to dedicated resources for a better soft real-time execution, or for instrumentation purposes. In this paper, we introduce the problem of resource allocation with compatibility and exclusivity constraints and show it reduces to the list-coloring problem in a threshold graph. We deduce that our problem is NP-complete in the general case, while it can be solved in polynomial time, in two special cases. We propose a heuristic backtracking algorithm enhanced by pruning rules and exploiting the subproblems‚Äô special structure. Compared to four list coloring heuristics adapted to our problem, our heuristic algorithm can be considered as the method of choice to find high-quality solutions in short computing times.},
  archive      = {J_JOH},
  author       = {Khassiba, Ahmed},
  doi          = {10.1007/s10732-024-09538-x},
  journal      = {Journal of Heuristics},
  month        = {3},
  number       = {1},
  pages        = {1-29},
  shortjournal = {J. Heuristics},
  title        = {An efficient backtracking heuristic for the resource allocation problem with compatibility and exclusivity constraints},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 30 years of the journal of heuristics: A bibliometric analysis. <em>JOH</em>, <em>31</em>(1), 1-55. (<a href='https://doi.org/10.1007/s10732-024-09542-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Journal of Heuristics is an international journal that provides a forum to solve complex problems using heuristic solution tools. The journal was created in 1995, and in 2025, celebrates its 30th anniversary. Motivated by this special event, this article presents a bibliometric analysis of the journal. The article examines the journal publication and citation structure using the Scopus database, considering a wide range of issues including the most cited documents, productive authors, institutions, and countries. The work also develops a graphical visualization of the bibliographic data by using the VOS viewer software. This approach is studied with different bibliometric measures such as bibliographic coupling, co-citation, and co-occurrence of keywords. The results show that the Journal of Heuristics has maintained a solid quality of its publications over the years. Currently, the most popular topics are connected to heuristics, metaheuristics, local search, and tabu search. Researchers from the USA are the most productive. But countries such as France, the UK, Spain and Canada, have also a significant productivity in the journal.},
  archive      = {J_JOH},
  author       = {Flores-Sosa, Martha and Merig√≥, Jos√© M. and Sanchez-Valenzuela, Kenia},
  doi          = {10.1007/s10732-024-09542-1},
  journal      = {Journal of Heuristics},
  month        = {3},
  number       = {1},
  pages        = {1-55},
  shortjournal = {J. Heuristics},
  title        = {30 years of the journal of heuristics: A bibliometric analysis},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A memetic algorithm for the flexible periodic vehicle routing problem. <em>JOH</em>, <em>31</em>(1), 1-26. (<a href='https://doi.org/10.1007/s10732-024-09536-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flexible periodic vehicle routing problem (FPVRP) is an extension of the classic VRP in which customers are visited periodically in the course of a given time horizon. Periodicity and flexibility in providing services are two main features of the FPVRP, which introduce new challenges in solving this problem. To the best of our knowledge, there is only one single-solution-based algorithm in the literature for solving the FPVRP. In this paper, another technique called the MA-FPVRP is proposed for tackling this problem. Our population-based approach is a memetic algorithm made up of two main components: a genetic procedure that aims to find a suitable sequence of visits for each route, and a local search procedure consisting of four moves whose prime goal is to guide the search toward the promising areas. Considering 45 standard benchmark instances with unknown optimal solutions, the MA-FPVRP outperforms the preceding method in terms of both the solution quality and execution time. Using this evolutionary scheme, the average relative percent deviation (RPD) to the best-known solution values decreases from 0.52% to 0.15%, and the average execution time improves by approximately 31%. For all 10 large instances of the FPVRP, new best results are found using our algorithm. Considering the remaining 35 small and medium-size instances, our approach is superior to the previous method in terms of the solution quality, and it is more than two times faster. Besides, using the MA-FPVRP, new best solutions are obtained for 5 out of these 35 instances.},
  archive      = {J_JOH},
  author       = {Amiri, Banafsheh and Ziarati, Koorush and Sohrabi, Somayeh},
  doi          = {10.1007/s10732-024-09536-z},
  journal      = {Journal of Heuristics},
  month        = {3},
  number       = {1},
  pages        = {1-26},
  shortjournal = {J. Heuristics},
  title        = {A memetic algorithm for the flexible periodic vehicle routing problem},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transforming last mile delivery with heterogeneous assistants: Drones and delivery robots. <em>JOH</em>, <em>31</em>(1), 1-42. (<a href='https://doi.org/10.1007/s10732-024-09543-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid global expansion of e-commerce and the increasing number of online shoppers, logistics service providers (LSPs) are exploring sustainable solutions to meet the rising demand. Thanks to developments in automation and robotic technologies, LSPs have now the opportunity to enhance their operations through the deployment of autonomous delivery solutions like drones and delivery robots. This paper investigates a practical delivery system to integrate these emerging technologies simultaneously into conventional van-only delivery system. Additionally, the effects of various assistant characteristics on operations are examined through broader assumptions. We introduce a mathematical model aiming to minimize delivery makespan and explore various valid inequalities to mitigate its complexity. A new hybrid metaheuristic algorithm combining genetic algorithm and large neighborhood search algorithm is also proposed for large scale instances. A three-layer coding and encoding method is also introduced for genetic algorithm to manage the complex structure of the problem. Finally, extensive numerical experiments are conducted to show the effectiveness of valid inequalities and the algorithm. The sensitivity analyses provide comparisons of various delivery configurations and offer valuable insights for the logistics industry to integrate these innovative delivery solutions into their daily operations. In our experiments, using a single drone reduces total delivery times by up to 23.57%, while a single robot contributes to a 37.19% improvement in the objective. The heterogeneous configuration offers a substantial 49.71% improvement compared to using only vans for deliveries.},
  archive      = {J_JOH},
  author       = {Chen, Cheng and Demir, Emrah and Hu, Xisheng and Huang, Hainan},
  doi          = {10.1007/s10732-024-09543-0},
  journal      = {Journal of Heuristics},
  month        = {3},
  number       = {1},
  pages        = {1-42},
  shortjournal = {J. Heuristics},
  title        = {Transforming last mile delivery with heterogeneous assistants: Drones and delivery robots},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary optimization of the area under precision-recall curve for classifying imbalanced multi-class data. <em>JOH</em>, <em>31</em>(1), 1-66. (<a href='https://doi.org/10.1007/s10732-024-09544-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of imbalanced multi-class data is still so far one of the most challenging issues in machine learning and data mining. This task becomes more serious when classes containing fewer instances are located in overlapping regions. Several approaches have been proposed through the literature to deal with these two issues such as the use of decomposition, the design of ensembles, the employment of misclassification costs, and the development of ad-hoc strategies. Despite these efforts, the number of existing works dealing with the imbalance in multi-class data is much reduced compared to the case of binary classification. Moreover, existing approaches still suffer from many limits. These limitations include difficulties in handling imbalances across multiple classes, challenges in adapting sampling techniques, limitations of certain classifiers, the need for specialized evaluation metrics, the complexity of data representation, and increased computational costs. Motivated by these observations, we propose a multi-objective evolutionary induction approach that evolves a population of NLM-DTs (Non-Linear Multivariate Decision Trees) using the $$\theta $$ -NSGA-III ( $$\theta $$ -Non-dominated Sorting Genetic Algorithm-III) as a search engine. The resulting algorithm is termed EMO-NLM-DT (Evolutionary Multi-objective Optimization of NLM-DTs) and is designed to optimize the construction of NLM-DTs for imbalanced multi-class data classification by simultaneously maximizing both the Macro-Average-Precision and the Macro-Average-Recall as two possibly conflicting objectives. The choice of these two measures as objective functions is motivated by a recent study on the appropriateness of performance metrics for imbalanced data classification, which suggests that the mAURPC (mean Area Under Recall Precision Curve) satisfies all necessary conditions for imbalanced multi-class classification. Moreover, the NLM-DT adoption as a baseline classifier to be optimized allows the generation non-linear hyperplanes that are well-adapted to the classes ‚Äòboundaries‚Äô geometrical shapes. The statistical analysis of the comparative experimental results on more than twenty imbalanced multi-class data sets reveals the outperformance of EMO-NLM-DT in building NLM-DTs that are highly effective in classifying imbalanced multi-class data compared to seven relevant and recent state-of-the-art methods.},
  archive      = {J_JOH},
  author       = {Chabbouh, Marwa and Bechikh, Slim and Mezura-Montes, Efr√©n and Ben Said, Lamjed},
  doi          = {10.1007/s10732-024-09544-z},
  journal      = {Journal of Heuristics},
  month        = {3},
  number       = {1},
  pages        = {1-66},
  shortjournal = {J. Heuristics},
  title        = {Evolutionary optimization of the area under precision-recall curve for classifying imbalanced multi-class data},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A Q-learning-based algorithm for the block relocation problem. <em>JOH</em>, <em>31</em>(1), 1-41. (<a href='https://doi.org/10.1007/s10732-024-09545-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Block Relocation Problem (BRP), also known as the Container Relocation Problem, is a challenging combinatorial optimization problem in block stacking systems and has many applications in real-world scenarios such as logistics and manufacturing industry. The BRP is about finding the optimal way to retrieve blocks from a storage area with the objective of minimizing the number of relocations. The BRPs have been studied for a long time, and have been solved primarily using conventional optimization techniques, including mathematical programming models, as well as both exact and heuristic algorithms. For the first time, this paper tackles the problem using a reinforcement learning method. We focus on one of the major variants of the BRP‚Äîthe restricted BRP with duplicate priorities (RBRP-dup). We first model the RBRP-dup as a Markov decision process and then propose a Q-learning-based algorithm to solve the problem. The Q-learning-based algorithm contains two phases. In the learning phase, two innovative mechanisms: an optimal rule-integrated behaviour policy and a heuristic-based dynamic initialization method, are incorporated into the Q-learning model to reduce the size of the state-action space and accelerate convergence. In the optimization phase, the insights obtained in the learning phase are combined with a heuristic algorithm to improve decision-making. The performance of our proposed method is evaluated against the state-of-the-art exact algorithm and a commonly used heuristic algorithm based on benchmark instances from the literature. The computational experiments demonstrate the superiority of our proposed method regarding solution quality in large and complex instances.},
  archive      = {J_JOH},
  author       = {Liu, Liqun and Feng, Yuanjun and Zeng, Qingcheng and Chen, Zhijun and Li, Yaqiu},
  doi          = {10.1007/s10732-024-09545-y},
  journal      = {Journal of Heuristics},
  month        = {3},
  number       = {1},
  pages        = {1-41},
  shortjournal = {J. Heuristics},
  title        = {A Q-learning-based algorithm for the block relocation problem},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A heuristic algorithm to improving the coil slitting process in the steel industry. <em>JOH</em>, <em>31</em>(1), 1-38. (<a href='https://doi.org/10.1007/s10732-024-09546-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The steel industry is constantly facing problems and challenges that require optimisation to improve the production process. We present an algorithm to address a major challenge, the slitting problem, for a specific Spanish company. This problem arises when large steel coils need to be cut into smaller strips. Given the highly heterogeneous stock (coils come from previous operations), selecting the most suitable coils and defining the cutting patterns become very complicated due to operational and customer constraints. The company aims to reduce the leftovers and increase the service level (the difference between the weight requested by the customer and the weight supplied). The algorithm is currently in production and was validated using the company‚Äôs data and compared with an exact model. Results significantly improved the company‚Äôs operations, achieving a 50% reduction in leftovers and a much better service level in minutes, as opposed to the hours the company previously required. Although there are Mixed Integer Linear Optimization models that provide an optimal solution in small cases, they are not a viable alternative for the company because they require excessive computational time (even, in some cases, to obtain feasible solutions) and use overly expensive commercial solvers.},
  archive      = {J_JOH},
  author       = {Soto-S√°nchez, √ìscar and Sierra-Paradinas, Mar√≠a and Gallego, Micael and Alonso-Ayuso, Antonio and Gort√°zar, Francisco},
  doi          = {10.1007/s10732-024-09546-x},
  journal      = {Journal of Heuristics},
  month        = {3},
  number       = {1},
  pages        = {1-38},
  shortjournal = {J. Heuristics},
  title        = {A heuristic algorithm to improving the coil slitting process in the steel industry},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A local branching-based solution for the multi-period cutting stock problem with tardiness, earliness, and setup costs. <em>JOH</em>, <em>31</em>(1), 1-57. (<a href='https://doi.org/10.1007/s10732-025-09547-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the Multi-Period Cutting Stock Problem with Due Dates and Setups (MPCSPDDS), an extension of the classical one-dimensional Cutting Stock Problem (CSP). The MPCSPDDS considers the due dates specified in cutting orders‚Äô requests and setups required for transitioning between different cutting patterns. The challenge lies in minimizing tardiness and earliness during production, considering these as detrimental factors. Additionally, the proposed model assumes that a setup is necessary for the cutting machine when switching patterns. The contribution of this paper includes the proposition of an integer mathematical programming model and a matheuristic solution approach for two variants of the MPCSPDDS, employing column generation, a round-up heuristic, and the local branching matheuristic. Computational experiments show that our proposed solution method consistently yields, on average, high-quality feasible solutions compared to employing column generation and solving the problem with the generated columns using the CPLEX solver while maintaining a low computational cost.},
  archive      = {J_JOH},
  author       = {de Ara√∫jo Silva Oliveira, Elisama and Wanner, Elizabeth and de S√°, Elisangela Martins and de Souza, S√©rgio Ricardo},
  doi          = {10.1007/s10732-025-09547-4},
  journal      = {Journal of Heuristics},
  month        = {3},
  number       = {1},
  pages        = {1-57},
  shortjournal = {J. Heuristics},
  title        = {A local branching-based solution for the multi-period cutting stock problem with tardiness, earliness, and setup costs},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heuristics for the run-length encoded Burrows‚ÄìWheeler transform alphabet ordering problem. <em>JOH</em>, <em>31</em>(1), 1-29. (<a href='https://doi.org/10.1007/s10732-025-09548-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Burrows‚ÄìWheeler Transform (BWT) is a string transformation technique widely used in areas such as bioinformatics and file compression. Many applications combine a run-length encoding (RLE) with the BWT in a way which preserves the ability to query the compressed data efficiently. However, these methods may not take full advantage of the compressibility of the BWT as they do not modify the alphabet ordering for the sorting step embedded in computing the BWT. Indeed, any such alteration of the alphabet ordering can have a considerable impact on the output of the BWT, in particular on the number of runs. For an alphabet $$\Sigma $$ containing $$\sigma $$ characters, the space of all alphabet orderings is of size $$\sigma !$$ . While for small alphabets an exhaustive investigation is possible, finding the optimal ordering for larger alphabets is not feasible. Therefore, there is a need for a more informed search strategy than brute-force sampling the entire space, which motivates a new heuristic approach. In this paper, we explore the non-trivial cases for the problem of minimizing the size of a run-length encoded BWT (RLBWT) via selecting a new ordering for the alphabet. We show that random sampling of the space of alphabet orderings usually gives sub-optimal orderings for compression and that a local search strategy can provide a large improvement in relatively few steps. We also inspect a selection of initial alphabet orderings, including ASCII, letter appearance, and letter frequency. While this alphabet ordering problem is computationally hard we demonstrate gain in compressibility.},
  archive      = {J_JOH},
  author       = {Major, Lily and Clare, Amanda and Daykin, Jacqueline W. and Mora, Benjamin and Zarges, Christine},
  doi          = {10.1007/s10732-025-09548-3},
  journal      = {Journal of Heuristics},
  month        = {3},
  number       = {1},
  pages        = {1-29},
  shortjournal = {J. Heuristics},
  title        = {Heuristics for the run-length encoded Burrows‚ÄìWheeler transform alphabet ordering problem},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Measuring the effectiveness and efficiency of simulation optimization metaheuristic algorithms. <em>JOH</em>, <em>31</em>(1), 1-21. (<a href='https://doi.org/10.1007/s10732-025-09549-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristic algorithms have proven capable as general-purpose algorithms for solving simulation optimization problems. Researchers and practitioners often compare different metaheuristic algorithms by examining one or more measures that are derived through empirical analysis. This paper presents a single measure that can be used to empirically compare different metaheuristic algorithms for optimization problems. This measure incorporates both the effectiveness and efficiency of the metaheuristic algorithm, which is especially important in simulation optimization applications because the number of simulation runs available to the analyst (i.e., the run budget) can vary significantly with each simulation study. Therefore, the trade-off between the effectiveness and efficiency of a metaheuristic algorithm must be examined. This single measure is especially useful for multi-objective optimization problems; however, determining this measure is non-trivial for two or more objective functions. Additional details for calculating this measure for multi-objective optimization problems are provided as well as a procedure for comparing two or more metaheuristic algorithms. Finally, computational results are presented and analyzed to compare the performance of metaheuristic algorithms using knapsack problems, pure binary integer programs, traveling salesman problems, and the average results obtained across a diverse set of optimization problems that include simulation and multi-objective optimization problems.},
  archive      = {J_JOH},
  author       = {Thengvall, Benjamin G. and Hall, Shane N. and Deskevich, Michael P.},
  doi          = {10.1007/s10732-025-09549-2},
  journal      = {Journal of Heuristics},
  month        = {3},
  number       = {1},
  pages        = {1-21},
  shortjournal = {J. Heuristics},
  title        = {Measuring the effectiveness and efficiency of simulation optimization metaheuristic algorithms},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selection for high-dimensional data using a multivariate search space reduction strategy based scatter search. <em>JOH</em>, <em>31</em>(1), 1-33. (<a href='https://doi.org/10.1007/s10732-025-09550-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In feature selection, the increasing of the dimensionality and the complexity of feature interactions make the problem challenging. Furthermore, searching for an optimal subset of features from a high-dimensional feature space is known to be an $$\mathcal{N}\mathcal{P}$$ -hard problem. To improve the efficiency and effectiveness of the search algorithm, feature grouping has emerged as a way to reduce the search space by clustering features according to a measure. In this work we propose to reduce the search space by applying a greedy algorithm, called Multivariate Greedy Predominant Groups Generator (MGPGG). MGPGG extends the idea of the Greedy Predominant Groups Generator (GPGG) algorithm by taking into account feature interaction among three or more features. For this purpose, MGPGG uses the Multivariate Symmetrical Uncertainty (MSU) to group features that share information about the class label. We also propose a Scatter Search strategy that integrates MGPGG to find small subsets of features with high predictive power. The proposed algorithm, called Multivariate Predominant Group-based Scatter Search (MPGSS), is tested on high-dimensional data from biomedical and text-mining fields. The proposal is compared with state-of-the-art feature selection strategies. Results show that MPGSS is competitive since it is capable of finding small subsets of features while keeping high predictive classification models.},
  archive      = {J_JOH},
  author       = {Garcia-Torres, Miguel},
  doi          = {10.1007/s10732-025-09550-9},
  journal      = {Journal of Heuristics},
  month        = {3},
  number       = {1},
  pages        = {1-33},
  shortjournal = {J. Heuristics},
  title        = {Feature selection for high-dimensional data using a multivariate search space reduction strategy based scatter search},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heuristic algorithm for integrated ship scheduling, routing and stowage problem in multi-vessel roll-on/roll-off shipping. <em>JOH</em>, <em>31</em>(1), 1-40. (<a href='https://doi.org/10.1007/s10732-025-09551-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Roll-on/roll-off (RoRo) ships offer distinct advantages in the maritime industry when it comes to transporting wheeled cargos and super-large vehicles. As the scale of RoRo fleets continues to grow, RoRo shipping companies face the challenge of efficiently organizing multiple ships to meet transportation demands across various regions, ensuring order fulfillment, and minimizing costs. In light of these challenges, we introduced and explored the multi-vessel RoRo ship scheduling, routing and stowage problem (m-RSRSSP), and proposed a mixed-integer linear programming (MILP) model to address this problem. Compared with previous studies, this paper enriches fleet's decision-making and address scenarios where multiple cargos are considered at one port on the basis of integrating ship scheduling, routing and stowage problem of ro-ro ship, which is better aligned with the requirements of certain practical scenarios. Given the intricate nature of this model, we developed a heuristic algorithm rooted in tabu search, incorporating a nested greedy approach. Furthermore, we presented a case study involving deep-sea RoRo transportation between Northeast Asia and Europe. The experimental results validate the efficiency and reliability of the proposed heuristic algorithm in solving large-scale problems, and provide valuable strategies for the formulation of the RoRo fleet operation schemes.},
  archive      = {J_JOH},
  author       = {Zhao, Yuzhe and Peng, Peiyun and Zhou, Jingmiao and Wang, Yadong},
  doi          = {10.1007/s10732-025-09551-8},
  journal      = {Journal of Heuristics},
  month        = {3},
  number       = {1},
  pages        = {1-40},
  shortjournal = {J. Heuristics},
  title        = {Heuristic algorithm for integrated ship scheduling, routing and stowage problem in multi-vessel roll-on/roll-off shipping},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective population-based approach for the partial set covering problem. <em>JOH</em>, <em>31</em>(1), 1-32. (<a href='https://doi.org/10.1007/s10732-025-09552-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The partial set covering problem (PSCP) is a significant combinatorial optimization problem that finds applications in numerous real-world scenarios. The objective of PSCP is to encompass a minimum number of subsets while ensuring the coverage of at least n elements. Due to its NP-hard nature, solving large-scale PSCP efficiently remains a critical issue in computational intelligence. To effectively tackle this challenge, we delve into a population-based approach that incorporates a modified tabu search, thereby striking a delicate balance between exploration and exploitation. To further enhance its efficacy, we employ the multiple path-relinking strategy and the fix-and-optimize process. Finally, the dynamic resource allocation scheme is utilized to save computing efforts. Comparative experiments of the proposed algorithm were conducted against three state-of-the-art competitors, across two distinct categories, encompassing 150 instances. The results significantly underscore the profound effectiveness of our proposed algorithm, as evidenced by the updating of 67 best-known solutions. Moreover, we conduct an in-depth analysis of the key components inherent to the algorithm, shedding light on their respective influences on the whole performance.},
  archive      = {J_JOH},
  author       = {Zhang, Ye and He, Jinlong and Zhou, Yupeng and Hu, Shuli and Cai, Dunbo and Tian, Naiyu and Yin, Minghao},
  doi          = {10.1007/s10732-025-09552-7},
  journal      = {Journal of Heuristics},
  month        = {3},
  number       = {1},
  pages        = {1-32},
  shortjournal = {J. Heuristics},
  title        = {An effective population-based approach for the partial set covering problem},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
