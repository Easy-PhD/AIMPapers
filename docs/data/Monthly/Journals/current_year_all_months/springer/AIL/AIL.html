<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIL</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ail">AIL - 30</h2>
<ul>
<li><details>
<summary>
(2025). Correction to: Code is law: How COMPAS affects the way the judiciary handles the risk of recidivism. <em>AIL</em>, <em>33</em>(3), 873-874. (<a href='https://doi.org/10.1007/s10506-024-09400-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIL},
  author       = {Engel, Christopher and Linhardt, Lorenz and Schubert, Marcel},
  doi          = {10.1007/s10506-024-09400-2},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {873-874},
  shortjournal = {Artif. Intell. Law},
  title        = {Correction to: Code is law: How COMPAS affects the way the judiciary handles the risk of recidivism},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The digital transformation of jurisprudence: An evaluation of ChatGPT-4’s applicability to solve cases in business law. <em>AIL</em>, <em>33</em>(3), 847-871. (<a href='https://doi.org/10.1007/s10506-024-09406-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the evolving landscape of legal information systems, ChatGPT-4 and other advanced conversational agents (CAs) offer the potential to disruptively transform the law industry. This study evaluates commercially available CAs within the German legal context, thereby assessing the generalizability of previous U.S.-based findings. Employing a unique corpus of 200 distinct legal tasks, ChatGPT-4 was benchmarked against Google Bard, Google Gemini, and its predecessor, ChatGPT-3.5. Human-expert and automated assessments of 4000 CA-generated responses reveal ChatGPT-4 to be the first CA to surpass the threshold of solving realistic legal tasks and passing a German business law exam. While ChatGPT-4 outperforms ChatGPT-3.5, Google Bard, and Google Gemini in both consistency and quality, the results demonstrate a considerable degree of variability, especially in complex cases with no predefined response options. Based on these findings, legal professionals should manually verify all texts produced by CAs before use. Novices must exercise caution with CA-generated legal advice, given the expertise needed for its assessment.},
  archive      = {J_AIL},
  author       = {Schweitzer, Sascha and Conrads, Markus},
  doi          = {10.1007/s10506-024-09406-w},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {847-871},
  shortjournal = {Artif. Intell. Law},
  title        = {The digital transformation of jurisprudence: An evaluation of ChatGPT-4’s applicability to solve cases in business law},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intermediate factors and precedential constraint. <em>AIL</em>, <em>33</em>(3), 827-846. (<a href='https://doi.org/10.1007/s10506-024-09405-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the extension of formal accounts of precedential constraint to make use of a factor hierarchy with intermediate factors. A problem arises, however, because constraints expressed in terms of intermediate factors may give different outcomes from those expressed only using base level factors. We argue that constraints that use only base level factors yield the correct outcomes, but that intermediate factors play an important role in the justification and explanation of those outcomes. The discussion is illustrated with a running example.},
  archive      = {J_AIL},
  author       = {Bench-Capon, Trevor},
  doi          = {10.1007/s10506-024-09405-x},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {827-846},
  shortjournal = {Artif. Intell. Law},
  title        = {Intermediate factors and precedential constraint},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-training improves few-shot learning in legal artificial intelligence tasks. <em>AIL</em>, <em>33</em>(3), 809-825. (<a href='https://doi.org/10.1007/s10506-024-09403-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the labeling costs in legal artificial intelligence tasks are expensive. Therefore, it becomes a challenge to utilize low cost to train a robust model. In this paper, we propose a LAIAugment approach, which aims to enhance the few-shot learning capability in legal artificial intelligence tasks. Specifically, we first use the self-training approach to label the amount of unlabelled data to enhance the feature learning capability of the model. Moreover, we also search for datasets that are similar to the training set by improving the text similarity function. We conducted experimental analyses for three legal artificial intelligence tasks, including evidence extraction, legal element extraction, and case multi-label prediction, which composed of 3500 judgement documents. The experimental results show that the proposed LAIAugment method has an average F1-score of 72.3% on the three legal AI tasks, which is 1.93% higher than the baseline model. At the same time, it shows a huge improvement in few-shot learning.},
  archive      = {J_AIL},
  author       = {Zhou, Yulin and Qin, Yongbin and Huang, Ruizhang and Chen, Yanping and Lin, Chuan and Zhou, Yuan},
  doi          = {10.1007/s10506-024-09403-z},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {809-825},
  shortjournal = {Artif. Intell. Law},
  title        = {Self-training improves few-shot learning in legal artificial intelligence tasks},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Japanese tort-case dataset for rationale-supported legal judgment prediction. <em>AIL</em>, <em>33</em>(3), 783-807. (<a href='https://doi.org/10.1007/s10506-024-09402-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the first dataset for Japanese Legal Judgment Prediction (LJP), the Japanese Tort-case Dataset (JTD), which features two tasks: tort prediction and its rationale extraction. The rationale extraction task identifies the court’s accepting arguments from alleged arguments by plaintiffs and defendants, which is a novel task in the field. JTD is constructed based on annotated 3477 Japanese Civil Code judgments by 41 legal experts, resulting in 7978 instances with 59,697 of their alleged arguments from the involved parties. Our baseline experiments show the feasibility of the proposed two tasks, and our error analysis by legal experts identifies sources of errors and suggests future directions of the LJP research.},
  archive      = {J_AIL},
  author       = {Yamada, Hiroaki and Tokunaga, Takenobu and Ohara, Ryutaro and Tokutsu, Akira and Takeshita, Keisuke and Sumida, Mihoko},
  doi          = {10.1007/s10506-024-09402-0},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {783-807},
  shortjournal = {Artif. Intell. Law},
  title        = {Japanese tort-case dataset for rationale-supported legal judgment prediction},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). InstructPatentGPT: Training patent language models to follow instructions with human feedback. <em>AIL</em>, <em>33</em>(3), 739-782. (<a href='https://doi.org/10.1007/s10506-024-09401-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, patent prosecution is conceptualized as a system of reinforcement learning from human feedback. The objective of the system is to increase the likelihood for a language model to generate patent claims that have a higher chance of being granted. To showcase the controllability of the language model, the system learns from granted patents and pre-grant applications with different rewards. The status of “granted” and “pre-grant” are perceived as labeled human feedback implicitly. In addition, specific to patent drafting, the experiments in this research demonstrate the model’s capability to learn from adjusting claim length and inclusion of limiting terms for narrowing claim scope. As proof of concept, the experiments focus on claim ones only and the training data originates from a patent dataset tailored specifically for artificial intelligence. Although the available human feedback in patent prosecution are limited and the quality of generated patent text requires improvement, the experiments following the 3-stage reinforcement learning from human feedback have demonstrated that generative language models are capable of reflecting the human feedback or intent in patent prosecution. To enhance the usability of language models, the implementation in this research utilizes modern techniques that enable execution on a single consumer-grade GPU. The demonstrated proof of concept, which reduces hardware requirements, will prove valuable in the future as more human feedback in patent prosecution become available for broader use, either within patent offices or in the public domain.},
  archive      = {J_AIL},
  author       = {Lee, Jieh-Sheng},
  doi          = {10.1007/s10506-024-09401-1},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {739-782},
  shortjournal = {Artif. Intell. Law},
  title        = {InstructPatentGPT: Training patent language models to follow instructions with human feedback},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models in cryptocurrency securities cases: Can a GPT model meaningfully assist lawyers?. <em>AIL</em>, <em>33</em>(3), 691-737. (<a href='https://doi.org/10.1007/s10506-024-09399-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) could be a useful tool for lawyers. However, empirical research on their effectiveness in conducting legal tasks is scant. We study securities cases involving cryptocurrencies as one of numerous contexts where AI could support the legal process, studying GPT-3.5’s legal reasoning and ChatGPT’s legal drafting capabilities. We examine whether a) GPT-3.5 can accurately determine which laws are potentially being violated from a fact pattern, and b) whether there is a difference in juror decision-making based on complaints written by a lawyer compared to ChatGPT. We feed fact patterns from real-life cases to GPT-3.5 and evaluate its ability to determine correct potential violations from the scenario and exclude spurious violations. Second, we had mock jurors assess complaints written by ChatGPT and lawyers. GPT-3.5’s legal reasoning skills proved weak, though we expect improvement in future models, particularly given the violations it suggested tended to be correct (it merely missed additional, correct violations). ChatGPT performed better at legal drafting, and jurors’ decisions were not statistically significantly associated with the author of the document upon which they based their decisions. Because GPT-3.5 cannot satisfactorily conduct legal reasoning tasks, it would be unlikely to be able to help lawyers in a meaningful way at this stage. However, ChatGPT’s drafting skills (though, perhaps, still inferior to lawyers) could assist lawyers in providing legal services. Our research is the first to systematically study an LLM’s legal drafting and reasoning capabilities in litigation, as well as in securities law and cryptocurrency-related misconduct.},
  archive      = {J_AIL},
  author       = {Trozze, Arianna and Davies, Toby and Kleinberg, Bennett},
  doi          = {10.1007/s10506-024-09399-6},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {691-737},
  shortjournal = {Artif. Intell. Law},
  title        = {Large language models in cryptocurrency securities cases: Can a GPT model meaningfully assist lawyers?},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unfair clause detection in terms of service across multiple languages. <em>AIL</em>, <em>33</em>(3), 641-689. (<a href='https://doi.org/10.1007/s10506-024-09398-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the existing natural language processing systems for legal texts are developed for the English language. Nevertheless, there are several application domains where multiple versions of the same documents are provided in different languages, especially inside the European Union. One notable example is given by Terms of Service (ToS). In this paper, we compare different approaches to the task of detecting potential unfair clauses in ToS across multiple languages. In particular, after developing an annotated corpus and a machine learning classifier for English, we consider and compare several strategies to extend the system to other languages: building a novel corpus and training a novel machine learning system for each language, from scratch; projecting annotations across documents in different languages, to avoid the creation of novel corpora; translating training documents while keeping the original annotations; translating queries at prediction time and relying on the English system only. An extended experimental evaluation conducted on a large, original dataset indicates that the time-consuming task of re-building a novel annotated corpus for each language can often be avoided with no significant degradation in terms of performance.},
  archive      = {J_AIL},
  author       = {Galassi, Andrea and Lagioia, Francesca and Jabłonowska, Agnieszka and Lippi, Marco},
  doi          = {10.1007/s10506-024-09398-7},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {641-689},
  shortjournal = {Artif. Intell. Law},
  title        = {Unfair clause detection in terms of service across multiple languages},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting court judgment prediction and explanation using legal entities. <em>AIL</em>, <em>33</em>(3), 605-640. (<a href='https://doi.org/10.1007/s10506-024-09397-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic prediction of court case judgments using Deep Learning and Natural Language Processing is challenged by the variety of norms and regulations, the inherent complexity of the forensic language, and the length of legal judgments. Although state-of-the-art transformer-based architectures and Large Language Models (LLMs) are pre-trained on large-scale datasets, the underlying model reasoning is not transparent to the legal expert. This paper jointly addresses court judgment prediction and explanation by not only predicting the judgment but also providing legal experts with sentence-based explanations. To boost the performance of both tasks we leverage a legal named entity recognition step, which automatically annotates documents with meaningful domain-specific entity tags and masks the corresponding fine-grained descriptions. In such a way, transformer-based architectures and Large Language Models can attend to in-domain entity-related information in the inference process while neglecting irrelevant details. Furthermore, the explainer can boost the relevance of entity-enriched sentences while limiting the diffusion of potentially sensitive information. We also explore the use of in-context learning and lightweight fine-tuning to tailor LLMs to the legal language style and the downstream prediction and explanation tasks. The results obtained on a benchmark dataset from the Indian judicial system show the superior performance of entity-aware approaches to both judgment prediction and explanation.},
  archive      = {J_AIL},
  author       = {Benedetto, Irene and Koudounas, Alkis and Vaiani, Lorenzo and Pastor, Eliana and Cagliero, Luca and Tarasconi, Francesco and Baralis, Elena},
  doi          = {10.1007/s10506-024-09397-8},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {605-640},
  shortjournal = {Artif. Intell. Law},
  title        = {Boosting court judgment prediction and explanation using legal entities},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Re-evaluating GPT-4’s bar exam performance. <em>AIL</em>, <em>33</em>(3), 581-604. (<a href='https://doi.org/10.1007/s10506-024-09396-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Perhaps the most widely touted of GPT-4’s at-launch, zero-shot capabilities has been its reported 90th-percentile performance on the Uniform Bar Exam. This paper begins by investigating the methodological challenges in documenting and verifying the 90th-percentile claim, presenting four sets of findings that indicate that OpenAI’s estimates of GPT-4’s UBE percentile are overinflated. First, although GPT-4’s UBE score nears the 90th percentile when examining approximate conversions from February administrations of the Illinois Bar Exam, these estimates are heavily skewed towards repeat test-takers who failed the July administration and score significantly lower than the general test-taking population. Second, data from a recent July administration of the same exam suggests GPT-4’s overall UBE percentile was below the 69th percentile, and $$\sim$$ 48th percentile on essays. Third, examining official NCBE data and using several conservative statistical assumptions, GPT-4’s performance against first-time test takers is estimated to be $$\sim$$ 62nd percentile, including $$\sim$$ 42nd percentile on essays. Fourth, when examining only those who passed the exam (i.e. licensed or license-pending attorneys), GPT-4’s performance is estimated to drop to $$\sim$$ 48th percentile overall, and $$\sim$$ 15th percentile on essays. In addition to investigating the validity of the percentile claim, the paper also investigates the validity of GPT-4’s reported scaled UBE score of 298. The paper successfully replicates the MBE score, but highlights several methodological issues in the grading of the MPT + MEE components of the exam, which call into question the validity of the reported essay score. Finally, the paper investigates the effect of different hyperparameter combinations on GPT-4’s MBE performance, finding no significant effect of adjusting temperature settings, and a significant effect of few-shot chain-of-thought prompting over basic zero-shot prompting. Taken together, these findings carry timely insights for the desirability and feasibility of outsourcing legally relevant tasks to AI models, as well as for the importance for AI developers to implement rigorous and transparent capabilities evaluations to help secure safe and trustworthy AI.},
  archive      = {J_AIL},
  author       = {Martínez, Eric},
  doi          = {10.1007/s10506-024-09396-9},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {581-604},
  shortjournal = {Artif. Intell. Law},
  title        = {Re-evaluating GPT-4’s bar exam performance},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring explainable AI in the tax domain. <em>AIL</em>, <em>33</em>(3), 551-579. (<a href='https://doi.org/10.1007/s10506-024-09395-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyses whether current explainable AI (XAI) techniques can help to address taxpayer concerns about the use of AI in taxation. As tax authorities around the world increase their use of AI-based techniques, taxpayers are increasingly at a loss about whether and how the ensuing decisions follow the procedures required by law and respect their substantive rights. The use of XAI has been proposed as a response to this issue, but it is still an open question whether current XAI techniques are enough to meet existing legal requirements. The paper approaches this question in the context of a case study: a prototype tax fraud detector trained on an anonymized dataset of real-world cases handled by the Buenos Aires (Argentina) tax authority. The decisions produced by this detector are explained through the use of various classification methods, and the outputs of these explanation models are evaluated on their explanatory power and on their compliance with the legal obligation that tax authorities provide the rationale behind their decision-making. We conclude the paper by suggesting technical and legal approaches for designing explanation mechanisms that meet the needs of legal explanation in the tax domain.},
  archive      = {J_AIL},
  author       = {Górski, Łukasz and Kuźniacki, Błażej and Almada, Marco and Tyliński, Kamil and Calvo, Madalena and Asnaghi, Pablo Matias and Almada, Luciano and Iñiguez, Hilario and Rubianes, Fernando and Pera, Octavio and Nigrelli, Juan Ignacio},
  doi          = {10.1007/s10506-024-09395-w},
  journal      = {Artificial Intelligence and Law},
  month        = {9},
  number       = {3},
  pages        = {551-579},
  shortjournal = {Artif. Intell. Law},
  title        = {Exploring explainable AI in the tax domain},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Legal sentence boundary detection using hybrid deep learning and statistical models. <em>AIL</em>, <em>33</em>(2), 519-549. (<a href='https://doi.org/10.1007/s10506-024-09394-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentence boundary detection (SBD) represents an important first step in natural language processing since accurately identifying sentence boundaries significantly impacts downstream applications. Nevertheless, detecting sentence boundaries within legal texts poses a unique and challenging problem due to their distinct structural and linguistic features. Our approach utilizes deep learning models to leverage delimiter and surrounding context information as input, enabling precise detection of sentence boundaries in English legal texts. We evaluate various deep learning models, including domain-specific transformer models like LegalBERT and CaseLawBERT. To assess the efficacy of our deep learning models, we compare them with a state-of-the-art domain-specific statistical conditional random field (CRF) model. After considering model size, F1-score, and inference time, we identify the Convolutional Neural Network Model (CNN) as the top-performing deep learning model. To further enhance performance, we integrate the features of the CNN model into the subsequent CRF model, creating a hybrid architecture that combines the strengths of both models. Our experiments demonstrate that the hybrid model outperforms the baseline model, achieving a 4% improvement in the F1-score. Additional experiments showcase the superiority of the hybrid model over SBD open-source libraries when confronted with an out-of-domain test set. These findings underscore the importance of efficient SBD in legal texts and emphasize the advantages of employing deep learning models and hybrid architectures to achieve optimal performance.},
  archive      = {J_AIL},
  author       = {Sheik, Reshma and Ganta, Sneha Rao and Nirmala, S. Jaya},
  doi          = {10.1007/s10506-024-09394-x},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {519-549},
  shortjournal = {Artif. Intell. Law},
  title        = {Legal sentence boundary detection using hybrid deep learning and statistical models},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparative user study of human predictions in algorithm-supported recidivism risk assessment. <em>AIL</em>, <em>33</em>(2), 471-517. (<a href='https://doi.org/10.1007/s10506-024-09393-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the effects of using an algorithm-based risk assessment instrument (RAI) to support the prediction of risk of violent recidivism upon release. The instrument we used is a machine learning version of RiskCanvi used by the Justice Department of Catalonia, Spain. It was hypothesized that people can improve their performance on defining the risk of recidivism when assisted with a RAI. Also, that professionals can perform better than non-experts on the domain. Participants had to predict whether a person who has been released from prison will commit a new crime leading to re-incarceration, within the next two years. This user study is done with (1) general participants from diverse backgrounds recruited through a crowdsourcing platform, (2) targeted participants who are students and practitioners of data science, criminology, or social work and professionals who work with RisCanvi. We also run focus groups with participants of the targeted study, including people who use RisCanvi in a professional capacity, to interpret the quantitative results. Among other findings, we observe that algorithmic support systematically leads to more accurate predictions from all participants, but that statistically significant gains are only seen in the performance of targeted participants with respect to that of crowdsourced participants. Among other comments, professional participants indicate that they would not foresee using a fully-automated system in criminal risk assessment, but do consider it valuable for training, standardization, and to fine-tune or double-check their predictions on particularly difficult cases. We found that the revised prediction by using a RAI increases the performance of all groups, while professionals show a better performance in general. And, a RAI can be considered for extending professional capacities and skills along their careers.},
  archive      = {J_AIL},
  author       = {Portela, Manuel and Castillo, Carlos and Tolan, Songül and Karimi-Haghighi, Marzieh and Pueyo, Antonio Andres},
  doi          = {10.1007/s10506-024-09393-y},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {471-517},
  shortjournal = {Artif. Intell. Law},
  title        = {A comparative user study of human predictions in algorithm-supported recidivism risk assessment},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Agents preserving privacy on intelligent transportation systems according to EU law. <em>AIL</em>, <em>33</em>(2), 437-470. (<a href='https://doi.org/10.1007/s10506-024-09391-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent Transportation Systems are expected to automate how parking slots are booked by trucks. The intrinsic dynamic nature of this problem, the need of explanations and the inclusion of private data justify an agent-based solution. Agents solving this problem act with a Believe Desire Intentions reasoning, and are implemented with JASON. Privacy of trucks becomes protected sharing a list of parkings ordered by preference. Furthermore, the process of assigning parking slots takes into account legal requirements on breaks and driving time limits. Finally, the agent simulations use the distances, the number of trucks and parkings corresponding to the proportions of the current European Union data. The performance of the proposed solution is tested in these simulations with three different distances against an alternative with complete knowledge. The difference in efficiency, the number of illegal breaks and the traveled distances are measured in them. Comparing the results, we can conclude that the nonprivate alternative is slightly better in performance while both alternatives do not produce illegal breaks. In this way the simulations show that the proposed privacy protection does not impose a relevant handicap in efficiency.},
  archive      = {J_AIL},
  author       = {Carbo, Javier and Pedraza, Juanita and Molina, Jose M.},
  doi          = {10.1007/s10506-024-09391-0},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {437-470},
  shortjournal = {Artif. Intell. Law},
  title        = {Agents preserving privacy on intelligent transportation systems according to EU law},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The challenge of open-texture in law. <em>AIL</em>, <em>33</em>(2), 405-435. (<a href='https://doi.org/10.1007/s10506-024-09390-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important challenge when creating automatically processable laws concerns open-textured terms. The ability to measure open-texture can assist in determining the feasibility of encoding regulation and where additional legal information is required to properly assess a legal issue or dispute. In this article, we propose a novel conceptualisation of open-texture with the aim of determining the extent of open-textured terms in legal documents. We conceptualise open-texture as a lever whose state is impacted by three types of forces: internal forces (the words within the text themselves), external forces (the resources brought to challenge the definition of words), and lateral forces (the merit of such challenges). We tested part of this conceptualisation with 26 participants by investigating agreement in paired annotators. Five key findings emerged. First, agreement on which words are open-texture within a legal text is possible and statistically significant. Second, agreement is even high at an average inter-rater reliability of 0.7 (Cohen’s kappa). Third, when there is agreement on the words, agreement on the Open-Texture Value is high. Fourth, there is a dependence between the Open-Texture Value and reasons invoked behind open-texture. Fifth, involving only four annotators can yield similar results compared to involving twenty more when it comes to only flagging clauses containing open-texture. We conclude the article by discussing limitations of our experiment and which remaining questions in real life cases are still outstanding.},
  archive      = {J_AIL},
  author       = {Guitton, Clement and Tamò-Larrieux, Aurelia and Mayer, Simon and van Dijck, Gijs},
  doi          = {10.1007/s10506-024-09390-1},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {405-435},
  shortjournal = {Artif. Intell. Law},
  title        = {The challenge of open-texture in law},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Code is law: How COMPAS affects the way the judiciary handles the risk of recidivism. <em>AIL</em>, <em>33</em>(2), 383-404. (<a href='https://doi.org/10.1007/s10506-024-09389-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Judges in multiple US states, such as New York, Pennsylvania, Wisconsin, California, and Florida, receive a prediction of defendants’ recidivism risk, generated by the COMPAS algorithm. If judges act on these predictions, they implicitly delegate normative decisions to proprietary software, even beyond the previously documented race and age biases. Using the ProPublica dataset, we demonstrate that COMPAS predictions favor jailing over release. COMPAS is biased against defendants. We show that this bias can largely be removed. Our proposed correction increases overall accuracy, and attenuates anti-black and anti-young bias. However, it also slightly increases the risk that defendants are released who commit a new crime before tried. We argue that this normative decision should not be buried in the code. The tradeoff between the interests of innocent defendants and of future victims should not only be made transparent. The algorithm should be changed such that the legislator and the courts do make this choice.},
  archive      = {J_AIL},
  author       = {Engel, Christoph and Linhardt, Lorenz and Schubert, Marcel},
  doi          = {10.1007/s10506-024-09389-8},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {383-404},
  shortjournal = {Artif. Intell. Law},
  title        = {Code is law: How COMPAS affects the way the judiciary handles the risk of recidivism},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining prompt-based language models and weak supervision for labeling named entity recognition on legal documents. <em>AIL</em>, <em>33</em>(2), 361-381. (<a href='https://doi.org/10.1007/s10506-023-09388-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition (NER) is a very relevant task for text information retrieval in natural language processing (NLP) problems. Most recent state-of-the-art NER methods require humans to annotate and provide useful data for model training. However, using human power to identify, circumscribe and label entities manually can be very expensive in terms of time, money, and effort. This paper investigates the use of prompt-based language models (OpenAI’s GPT-3) and weak supervision in the legal domain. We apply both strategies as alternative approaches to the traditional human-based annotation method, relying on computer power instead human effort for labeling, and subsequently compare model performance between computer and human-generated data. We also introduce combinations of all three mentioned methods (prompt-based, weak supervision, and human annotation), aiming to find ways to maintain high model efficiency and low annotation costs. We showed that, despite human labeling still maintaining better overall performance results, the alternative strategies and their combinations presented themselves as valid options, displaying positive results and similar model scores at lower costs. Final results demonstrate preservation of human-trained models scores averaging 74.0% for GPT-3, 95.6% for weak supervision, 90.7% for GPT + weak supervision combination, and 83.9% for GPT + 30% human-labeling combination.},
  archive      = {J_AIL},
  author       = {Oliveira, Vitor and Nogueira, Gabriel and Faleiros, Thiago and Marcacini, Ricardo},
  doi          = {10.1007/s10506-023-09388-1},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {361-381},
  shortjournal = {Artif. Intell. Law},
  title        = {Combining prompt-based language models and weak supervision for labeling named entity recognition on legal documents},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiscoLQA: Zero-shot discourse-based legal question answering on european legislation. <em>AIL</em>, <em>33</em>(2), 323-359. (<a href='https://doi.org/10.1007/s10506-023-09387-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The structures of discourse used by legal and ordinary languages share differences that foster technical issues when applying or fine-tuning general-purpose language models for open-domain question answering on legal resources. For example, longer sentences may be preferred in European laws (i.e., Brussels I bis Regulation EU 1215/2012) to reduce potential ambiguities and improve comprehensibility, distracting a language model trained on ordinary English. In this article, we investigate some mechanisms to isolate and capture the discursive patterns of legalese in order to perform zero-shot question answering, i.e., without training on legal documents. Specifically, we use pre-trained open-domain answer retrieval systems and study what happens when changing the type of information to consider for retrieval. Indeed, by selecting only the important parts of discourse (e.g., elementary units of discourse, EDU for short, or abstract representations of meaning, AMR for short), we should be able to help the answer retriever identify the elements of interest. Hence, with this paper, we publish Q4EU, a new evaluation dataset that includes more than 70 questions and 200 answers on 6 different European norms, and study what happens to a baseline system when only EDUs or AMRs are used during information retrieval. Our results show that the versions using EDUs are overall the best, leading to state-of-the-art F1, precision, NDCG and MRR scores.},
  archive      = {J_AIL},
  author       = {Sovrano, Francesco and Palmirani, Monica and Sapienza, Salvatore and Pistone, Vittoria},
  doi          = {10.1007/s10506-023-09387-2},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {323-359},
  shortjournal = {Artif. Intell. Law},
  title        = {DiscoLQA: Zero-shot discourse-based legal question answering on european legislation},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). To test or not to test? a question of rational decision making in forensic biology. <em>AIL</em>, <em>33</em>(2), 293-322. (<a href='https://doi.org/10.1007/s10506-023-09386-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How can the forensic scientist rationally justify performing a sequence of tests and analyses in a particular case? When is it worth performing a test or analysis on an item? Currently, there is a large void in logical frameworks for making rational decisions in forensic science. The aim of this paper is to fill this void by presenting a step-by-step guide on how to apply Bayesian decision theory to routine decision problems encountered by forensic scientists on performing or not performing a particular laboratory test or analysis. A decision-theoretic framework, composed of actions, states of nature, and utilities, models this problem, and an influence diagram translates its notions into a probabilistic graphical network. Within this framework, the expected value of information (EVOI) for the submission of an item to a particular test or analysis addresses the above questions. The development of a classical case example on whether to perform presumptive tests for blood before submitting the item for a DNA analysis illustrates the use of this model for source level questions in forensic biology (i.e., questions that ask whether a crime stain consisting of a particular body fluid comes from a particular person). We show how to construct an influence diagram for this example, and how sensitivity analyses lead to an optimal analytical sequence. The key idea is to show that such a Bayesian decisional approach provides a coherent framework for justifying the optimal analytical sequence for a particular case in forensic science.},
  archive      = {J_AIL},
  author       = {Gittelson, Simone and Taroni, Franco},
  doi          = {10.1007/s10506-023-09386-3},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {293-322},
  shortjournal = {Artif. Intell. Law},
  title        = {To test or not to test? a question of rational decision making in forensic biology},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing legal judgment summarization with integrated semantic and structural information. <em>AIL</em>, <em>33</em>(2), 271-292. (<a href='https://doi.org/10.1007/s10506-023-09381-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Legal Judgment Summarization (LJS) can highly summarize legal judgment documents, improving judicial work efficiency in case retrieval and other occasions. Legal judgment documents are usually lengthy; however, most existing LJS methods are directly based on general text summarization models, which cannot handle long texts effectively. Additionally, due to the complex structural characteristics of legal judgment documents, some information may be lost by applying only one single kind of summarization model. To address these issues, we propose an integrated summarization method which leverages both semantic and structural information to improve the quality of LJS. Specifically, legal judgment documents are firstly segmented into three relatively short parts according to their specific structure. We propose an extractive summarization model named BSLT and an abstractive summarization model named LPGN by adopting Lawformer as the encoder. Lawformer is a new pre-trained language model for long legal documents, which specializes in capturing long-distance dependency and modeling legal semantic features. Then, we adopt different models to summarize the corresponding part regarding its structural characteristics. Finally, the obtained summaries are integrated to generate a high-quality summary involving semantic and structural information. We conduct comparative experiments to evaluate the performance of our model. The results show that our model outperforms the baseline model LEAD-3 by 14.78% on the mean ROUGE score, which demonstrates our method is effective in LJS and is prospected to be applied to assist other tasks in legal artificial intelligence.},
  archive      = {J_AIL},
  author       = {Dan, Jingpei and Hu, Weixuan and Wang, Yuming},
  doi          = {10.1007/s10506-023-09381-8},
  journal      = {Artificial Intelligence and Law},
  month        = {6},
  number       = {2},
  pages        = {271-292},
  shortjournal = {Artif. Intell. Law},
  title        = {Enhancing legal judgment summarization with integrated semantic and structural information},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI, law and beyond. a transdisciplinary ecosystem for the future of AI & law. <em>AIL</em>, <em>33</em>(1), 253-270. (<a href='https://doi.org/10.1007/s10506-024-09404-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We live in exciting times for AI and Law: technical developments are moving at a breakneck pace, and at the same time, the call for more robust AI governance and regulation grows stronger. How should we as an AI & Law community navigate these dramatic developments and claims? In this Presidential Address, I present my ideas for a way forward: researching, developing and evaluating real AI systems for the legal field with researchers from AI, Law and beyond. I will demonstrate how we at the Netherlands National Police Lab AI are developing responsible AI by combining insights from different disciplines, and how this connects to the future of our field.},
  archive      = {J_AIL},
  author       = {Bex, Floris J.},
  doi          = {10.1007/s10506-024-09404-y},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {253-270},
  shortjournal = {Artif. Intell. Law},
  title        = {AI, law and beyond. a transdisciplinary ecosystem for the future of AI & law},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automating petition classification in brazil’s legal system: A two-step deep learning approach. <em>AIL</em>, <em>33</em>(1), 227-251. (<a href='https://doi.org/10.1007/s10506-023-09385-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated classification of legal documents has been the subject of extensive research in recent years. However, this is still a challenging task for long documents, since it is difficult for a model to identify the most relevant information for classification. In this paper, we propose a two-stage supervised learning approach for the classification of petitions, a type of legal document that requests a court order. The proposed approach is based on a word-level encoder–decoder Seq2Seq deep neural network, such as a Bidirectional Long Short-Term Memory (BiLSTM) or a Bidirectional Encoder Representations from Transformers (BERT) model, and a document-level Support Vector Machine classifier. To address the challenges posed by the lengthy legal documents, the approach introduces a human-in-the-loop approach, whose task is to localize and tag relevant segments of text in the word-level training part, which dramatically reduces the dimension of the document classifier input vector. We performed experiments to validate our approach using a real-world dataset comprised of 270 intermediate petitions, which were carefully annotated by specialists from the 15th civil unit of the State of Alagoas, Brazil. Our results revealed that both BiLSTM and BERT-Convolutional Neural Networks variants achieved an accuracy of up to 95.49%, and also outperformed baseline classifiers based on the Term Frequency–Inverse Document Frequency test vectorizer. The proposed approach is currently being utilized to automate the aforementioned justice unit, thereby increasing its efficiency in handling repetitive tasks.},
  archive      = {J_AIL},
  author       = {Costa, Yuri D. R. and Oliveira, Hugo and Nogueira, Valério and Massa, Lucas and Yang, Xu and Barbosa, Adriano and Oliveira, Krerley and Vieira, Thales},
  doi          = {10.1007/s10506-023-09385-4},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {227-251},
  shortjournal = {Artif. Intell. Law},
  title        = {Automating petition classification in brazil’s legal system: A two-step deep learning approach},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward representing interpretation in factor-based models of precedent. <em>AIL</em>, <em>33</em>(1), 199-226. (<a href='https://doi.org/10.1007/s10506-023-09384-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses the desirability and feasibility of modeling precedents with multiple interpretations within factor-based models of precedential constraint. The main idea is that allowing multiple reasonable interpretations of cases and modeling precedential constraint as a function of what all reasonable interpretations compel may be advantageous. The article explains the potential benefits of extending the models in this way with a focus on incorporating a theory of vertical precedent in U.S. federal appellate courts. It also considers the costs of extending the models in this way, such as the significant increase in the functional size of the case base and the need to provide some kind of ordering on interpretations to select a “best” interpretation. Finally, the article suggests partially incorporating multiple interpretations of dimensions as a realistic starting point for incorporating interpretations generally, and shows how doing so can help address difficulties with dimensions. The conclusion remarks on the use of interpretations to deal with inconsistent precedents.},
  archive      = {J_AIL},
  author       = {Rigoni, Adam},
  doi          = {10.1007/s10506-023-09384-5},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {199-226},
  shortjournal = {Artif. Intell. Law},
  title        = {Toward representing interpretation in factor-based models of precedent},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decision support for detecting sensitive text in government records. <em>AIL</em>, <em>33</em>(1), 171-197. (<a href='https://doi.org/10.1007/s10506-023-09383-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Freedom of information laws promote transparency by permitting individuals and organizations to obtain government documents. However, exemptions from disclosure are necessary to protect privacy and to permit government officials to deliberate freely. Deliberative language is often the most challenging and burdensome exemption to detect, leading to high processing costs and delays in responding to open-records requests. This paper describes a novel deliberative-language detection model trained on a new annotated training set. The deliberative-language detection model is a component of a decision-support system for open-records requests under the US Freedom of Information Act, the FOIA Assistant, that ingests documents responsive to an open-records requests, suggests passages likely to be subject to deliberative language, privacy, or other exemptions, and assists analysts in rapidly redacting suggested passages. The tool’s interface is based on extensive human-factors and usability studies with analysts and is currently in operational testing by multiple US federal agencies.},
  archive      = {J_AIL},
  author       = {Branting, Karl and Brown, Bradford and Giannella, Chris and Guilder, James Van and Harrold, Jeff and Howell, Sarah and Baron, Jason R.},
  doi          = {10.1007/s10506-023-09383-6},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {171-197},
  shortjournal = {Artif. Intell. Law},
  title        = {Decision support for detecting sensitive text in government records},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Reasoning with inconsistent precedents. <em>AIL</em>, <em>33</em>(1), 167-170. (<a href='https://doi.org/10.1007/s10506-024-09392-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIL},
  author       = {Canavotto, Ilaria},
  doi          = {10.1007/s10506-024-09392-z},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {167-170},
  shortjournal = {Artif. Intell. Law},
  title        = {Correction to: Reasoning with inconsistent precedents},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reasoning with inconsistent precedents. <em>AIL</em>, <em>33</em>(1), 137-166. (<a href='https://doi.org/10.1007/s10506-023-09382-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational models of legal precedent-based reasoning developed in AI and Law are typically based on the simplifying assumption that the background set of precedent cases is consistent. Besides being unrealistic in the legal domain, this assumption is problematic for recent promising applications of these models to the development of explainable AI methods. In this paper I explore a model of legal precedent-based reasoning that, unlike existing models, does not rely on the assumption that the background set of precedent cases is consistent. The model is a generalization of the reason model of precedential constraint. I first show that the model supports an interesting deontic logic, where consistent obligations can be derived from inconsistent case bases. I then provide an explanation of this surprising result by proposing a reformulation of the model in terms of cases that support a new potential decision and cases that conflict with it. Finally, I show that the reformulation of the model allows us to verify that inconsistent case bases do not make verification that a decision is permissible substantially more complex than consistent case bases and to introduce intuitive criteria to compare different permissible decisions.},
  archive      = {J_AIL},
  author       = {Canavotto, Ilaria},
  doi          = {10.1007/s10506-023-09382-7},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {137-166},
  shortjournal = {Artif. Intell. Law},
  title        = {Reasoning with inconsistent precedents},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network to identify requests, decisions, and arguments in court rulings on custody. <em>AIL</em>, <em>33</em>(1), 101-135. (<a href='https://doi.org/10.1007/s10506-023-09380-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Court rulings are among the most important documents in all legal systems. This article describes a study in which natural language processing is used for the automatic characterization of Spanish judgments that deal with the physical custody (joint or individual) of minors. The model was trained to identify a set of elements: the type of custody requested by the plaintiff, the type of custody decided on by the court, and eight of the most commonly used arguments in this type of judgment. Two jurists independently annotated more than 3000 judgments, which were used to train a model based on transformers. The main difficulties encountered in this task were the complexity of the judicial language and the need to work with appellate court rulings that have a more complicated structure than decisions at first instance. For the complete court rulings, the F1 score of the inter-annotator agreement ranged from 0.60 to 0.86 and the Kappa index from 0.33 to 0.73. The F1 score of the agreement between the model and the annotators ranged from 0.66 to 0.93 and the Kappa index from 0.57 to 0.80. These results in which the model performance exceeds even the inter-annotator agreement show the high ability of transformers to identify abstract entities in legal texts.},
  archive      = {J_AIL},
  author       = {Muñoz-Soro, José Félix and del Hoyo Alonso, Rafael and Montañes, Rosa and Lacueva, Francisco},
  doi          = {10.1007/s10506-023-09380-9},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {101-135},
  shortjournal = {Artif. Intell. Law},
  title        = {A neural network to identify requests, decisions, and arguments in court rulings on custody},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Natural language processing for legal document review: Categorising deontic modalities in contracts. <em>AIL</em>, <em>33</em>(1), 79-100. (<a href='https://doi.org/10.1007/s10506-023-09379-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contract review process can be a costly and time-consuming task for lawyers and clients alike, requiring significant effort to identify and evaluate the legal implications of individual clauses. To address this challenge, we propose the use of natural language processing techniques, specifically text classification based on deontic tags, to streamline the process. Our research question is whether natural language processing techniques, specifically dense vector embeddings, can help semi-automate the contract review process and reduce time and costs for legal professionals reviewing deontic modalities in contracts. In this study, we create a domain-specific dataset and train both baseline and neural network models for contract sentence classification. This approach offers a more efficient and cost-effective solution for contract review, mimicking the work of a lawyer. Our approach achieves an accuracy of 0.90, showcasing its effectiveness in identifying and evaluating individual contract sentences.},
  archive      = {J_AIL},
  author       = {Graham, S. Georgette and Soltani, Hamidreza and Isiaq, Olufemi},
  doi          = {10.1007/s10506-023-09379-2},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {79-100},
  shortjournal = {Artif. Intell. Law},
  title        = {Natural language processing for legal document review: Categorising deontic modalities in contracts},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A large scale benchmark for session-based recommendations on the legal domain. <em>AIL</em>, <em>33</em>(1), 43-78. (<a href='https://doi.org/10.1007/s10506-023-09378-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of legal documents in various formats and their dispersion across multiple courts present a significant challenge for users seeking precise matches to their information requirements. Despite notable advancements in legal information retrieval systems, research into legal recommender systems remains limited. A plausible factor contributing to this scarcity could be the absence of extensive publicly accessible datasets or benchmarks. While a few studies have emerged in this field, a comprehensive analysis of the distinct attributes of legal data that influence the design of effective legal recommenders is notably absent in the current literature. This paper addresses this gap by initially amassing a comprehensive session-based dataset from Jusbrasil, one of Brazil’s largest online legal platforms. Subsequently, we scrutinize and discourse key facets of legal session-based recommendation data, including session duration, types of recommendable legal artifacts, coverage, and popularity. Furthermore, we introduce the first session-based recommendation benchmark tailored to the legal domain, shedding light on the performance and constraints of several renowned session-based recommendation approaches. These evaluations are based on real-world data sourced from Jusbrasil.},
  archive      = {J_AIL},
  author       = {Domingues, Marcos Aurélio and de Moura, Edleno Silva and Marinho, Leandro Balby and da Silva, Altigran},
  doi          = {10.1007/s10506-023-09378-3},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {43-78},
  shortjournal = {Artif. Intell. Law},
  title        = {A large scale benchmark for session-based recommendations on the legal domain},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating legal event and context information for chinese similar case analysis. <em>AIL</em>, <em>33</em>(1), 1-42. (<a href='https://doi.org/10.1007/s10506-023-09377-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similar case analysis (SCA) is an essential topic in legal artificial intelligence, serving as a reference for legal professionals. Most existing works treat SCA as a traditional text classification task and ignore some important legal elements that affect the verdict and case similarity, like legal events, and thus are easily misled by semantic structure. To address this issue, we propose a Legal Event-Context Model named LECM to improve the accuracy and interpretability of SCA based on Chinese legal corpus. The event-context integration mechanism, which is an essential component of the LECM, is proposed to integrate the legal event and context information based on the attention mechanism, enabling legal events to be associated with their corresponding relevant contexts. We introduce an event detection module to obtain the legal event information, which is pre-trained on a legal event detection dataset to avoid labeling events manually. We conduct extensive experiments on two SCA tasks, i.e., similar case matching (SCM) and similar case retrieval (SCR). Compared with baseline models, LECM is validated by about 13% and 11% average improvement in terms of mean average precision and accuracy respectively, for SCR and SCM tasks. These results indicate that LECM effectively utilizes event-context knowledge to enhance SCA performance and its potential application in various legal document analysis tasks.},
  archive      = {J_AIL},
  author       = {Dan, Jingpei and Xu, Lanlin and Wang, Yuming},
  doi          = {10.1007/s10506-023-09377-4},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {1-42},
  shortjournal = {Artif. Intell. Law},
  title        = {Integrating legal event and context information for chinese similar case analysis},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
