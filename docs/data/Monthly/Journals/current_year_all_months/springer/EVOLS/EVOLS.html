<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EVOLS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="evols">EVOLS - 124</h2>
<ul>
<li><details>
<summary>
(2025). Continual learning approaches for anomaly detection. <em>EVOLS</em>, <em>16</em>(4), 1-20. (<a href='https://doi.org/10.1007/s12530-025-09732-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection (AD) is a relevant problem in numerous real-world applications, especially when dealing with images. However, in real-world applications, it is common that the input data distribution can change over time, decreasing performance significantly. Therefore, in this study, we investigate the problem of Visual Anomaly Detection at Pixel-Level in the Continual Learning setting, where the model adapts to the new data while maintaining the knowledge of old data. We implement and test several AD techniques and adapt them to work in the CL setting using the Replay approach. We evaluate them using the well-known MVTec AD Dataset, where each object corresponds to a new learning task. Moreover, a significant challenge when dealing with the Replay approach is the memory occupied to store a portion of past images, which could be too heavy for many resource-constrained systems. Therefore, we propose a novel approach called SCALE, which performs high compression levels while preserving image quality through Super-Resolution techniques. Using the SCALE method to compress replay memory, in conjunction with the AD technique Inpaint, allows for obtaining the best AD results while significantly reducing memory consumption.},
  archive      = {J_EVOLS},
  author       = {Pezze, Davide Dalle and Anello, Eugenia and Masiero, Chiara and Susto, Gian Antonio},
  doi          = {10.1007/s12530-025-09732-7},
  journal      = {Evolving Systems},
  month        = {12},
  number       = {4},
  pages        = {1-20},
  shortjournal = {Evol. Syst.},
  title        = {Continual learning approaches for anomaly detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pixelated disparity network for hepatocellular carcinoma recognition from ultrasound images. <em>EVOLS</em>, <em>16</em>(4), 1-16. (<a href='https://doi.org/10.1007/s12530-025-09737-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The overgrowth of tumor cells in the liver results in Hepatocellular Carcinoma with unfamiliar symptoms in its earlier stages. Though the treatments facilitate transplantation, freezing, etc. the recognition of such tumors is to be made early using ultrasound images. This article proposes a Disparity Learning Network for Pixel Differentiation to recognize Hepatocellular Carcinoma from ultrasound image inputs. First, the conventional textural features are extracted from the input image from which the disparity for differential pixel distribution is estimated. This disparity is computed based on pixel absence in a well-distributed region and the corresponding error occurrence. In this case, the disparity network is constructed using one conditional and one training layer for disparity classification and new distribution training. In the classification process, the absence and high-density factors are differentiated for region-wise disparity estimation. Such estimation is used for training further classifications, for differentiating non-disparity regions. The maximum disparity pixel distributed region is recognized as the infected region from the given input.},
  archive      = {J_EVOLS},
  author       = {Usha, S. and Bala, Saroj and Saranya, M. D. and Suganyadevi, S.},
  doi          = {10.1007/s12530-025-09737-2},
  journal      = {Evolving Systems},
  month        = {12},
  number       = {4},
  pages        = {1-16},
  shortjournal = {Evol. Syst.},
  title        = {Pixelated disparity network for hepatocellular carcinoma recognition from ultrasound images},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved ear recognition system based on efficient feature extraction and fusion techniques. <em>EVOLS</em>, <em>16</em>(4), 1-11. (<a href='https://doi.org/10.1007/s12530-025-09739-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometric identification through ear image analysis and recognition has emerged as a promising biometric system due ear uniqueness and stability in varying environmental conditions. In this study, a novel approach for ear recognition using a fusion of two powerful feature extraction techniques such as Histogram of Oriented Gradients (HOG) and an improved Local Optimal Oriented Pattern (LOOP) based on Spatial Pyramid Decomposition (SPD) is proposed. An efficient scheme based on Discriminant Correlation Analysis (DCA) is adopted as a feature level fusion and dimensionality reduction technique where the performance of the recognition system is evaluated using a K-Nearest Neighbors (K-NN) classifier. Extensive experiments on six well known benchmarks ear datasets are conducted to assess the effectiveness of the proposed approach. Experimental results clearly indicate the superiority of the proposed method in terms of performance and complexity in comparison with the state-of-the-art ear recognition techniques.},
  archive      = {J_EVOLS},
  author       = {Lebed, Toufik and Boukharouba, Abdelhak},
  doi          = {10.1007/s12530-025-09739-0},
  journal      = {Evolving Systems},
  month        = {12},
  number       = {4},
  pages        = {1-11},
  shortjournal = {Evol. Syst.},
  title        = {An improved ear recognition system based on efficient feature extraction and fusion techniques},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Healthcare fraud detection using adaptive learning and deep learning techniques. <em>EVOLS</em>, <em>16</em>(4), 1. (<a href='https://doi.org/10.1007/s12530-025-09741-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EVOLS},
  author       = {Matloob, Irum and Khan, Shoab and Rukaiya, Rukaiya and Alfraihi, Hessa and Khan, Javed Ali},
  doi          = {10.1007/s12530-025-09741-6},
  journal      = {Evolving Systems},
  month        = {12},
  number       = {4},
  pages        = {1},
  shortjournal = {Evol. Syst.},
  title        = {Correction: Healthcare fraud detection using adaptive learning and deep learning techniques},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-stage shadow removal method with multi-channel multi-scale feature fusion and stripe pooling attention. <em>EVOLS</em>, <em>16</em>(4), 1-16. (<a href='https://doi.org/10.1007/s12530-025-09740-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shadows in images, caused by objects blocking light, degrade image quality and complicate various computer vision tasks. This paper presents a novel two-stage shadow removal method that addresses this challenge through separate shadow detection and recovery stages. In the first stage, the GLFFNet model leverages global and local channel fusion modules to precisely detect shadow regions. In the second stage, the USFNet model employs shadow localization, boundary enhancement, and frequency band extraction modules to recover shadow areas while minimizing impact on non-shadowed regions. Extensive experiments on multiple datasets demonstrate the superior performance of our method, achieving state-of-the-art results in shadow detection and recovery. This work contributes to advancing shadow removal techniques for practical computer vision applications. The code and models used in this paper are available at: https://github.com/Valsemia/GLFFNet-and-USFNet.git .},
  archive      = {J_EVOLS},
  author       = {Li, Zhidan and Chen, Zhou and Xu, Jiayue and Cheng, Jixiang},
  doi          = {10.1007/s12530-025-09740-7},
  journal      = {Evolving Systems},
  month        = {12},
  number       = {4},
  pages        = {1-16},
  shortjournal = {Evol. Syst.},
  title        = {A two-stage shadow removal method with multi-channel multi-scale feature fusion and stripe pooling attention},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recurrent neural network with contextual attention for prognostics. <em>EVOLS</em>, <em>16</em>(4), 1-19. (<a href='https://doi.org/10.1007/s12530-025-09744-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fundamental goal of prognostics is to predict a system or component’s remaining useful life (RUL), or the span of time until it fails to operate as intended, which is crucial for reducing downtime. Recently, various deep learning approaches have been used for machine prognostics. The sequential models like RNN, LSTM, GRU, and Transformer models can effectively manage implicit contexts defined within the data, such as temporal contexts. Further, the attention mechanism enables the model to focus on different parts of the input sequence. However, such models may struggle with explicitly incorporating external contextual information such as machine operating conditions. In this paper, a novel recurrent neural network (RNN)-based architecture is proposed for RUL prediction that explicitly embeds contextual information into the model. Context influences both the input feature weighting and the computation of the attention vector, resulting in a context-aware attention mechanism. This not only improves prediction performance but also provides interpretability by highlighting the most influential features and parts of input sequences. The proposed architecture is evaluated using two widely adopted benchmark datasets: the NASA C-MPASS Turbofan Engine Degradation Simulation dataset and the Bearing dataset (IEEE PHM 2012 Challenge). Results show that incorporating context significantly improves performance over baseline and state-of-the-art methods. The model achieves up to 18.90% and 59.10% reductions in RMSE and Score on FD002, and 6.86% and 53.88% on FD004 (C-MPASS). On the Bearings dataset, it yields an 84.54% improvement in RMSE and 54.98% in Score over the best existing model. Notably, these gains are achieved using a lightweight model architecture with minimal parameters, demonstrating both effectiveness and efficiency.},
  archive      = {J_EVOLS},
  author       = {Dutta Baruah, Rashmi and Munoz-Organero, Mario},
  doi          = {10.1007/s12530-025-09744-3},
  journal      = {Evolving Systems},
  month        = {12},
  number       = {4},
  pages        = {1-19},
  shortjournal = {Evol. Syst.},
  title        = {Recurrent neural network with contextual attention for prognostics},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolving online clustering for real-time driver behavior analysis in IoT-enabled vehicles. <em>EVOLS</em>, <em>16</em>(4), 1-32. (<a href='https://doi.org/10.1007/s12530-025-09745-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing integration of Internet of Things (IoT) technologies into modern vehicles has enabled real-time access to driving data. However, analyzing this information in embedded environments remains challenging due to the continuous nature of the data streams and the limited computational resources available. This study addresses these constraints by proposing an evolving online clustering approach for real-time monitoring of driver behavior. The proposed method integrates Tiny Machine Learning (TinyML) techniques with soft sensors derived from physical data captured via on-board diagnostics (OBD-II). Central to the system is the MMCloud algorithm, which incrementally updates clusters without requiring retraining, enabling adaptation to concept drift and evolving driving conditions. The methodology involves the real-time acquisition of vehicle signals, including speed, RPM, engine load, and throttle position, followed by the calculation of a soft-sensor metric known as radar area. The algorithm was deployed on a Freematics One+ device and validated through case studies conducted in varied urban driving conditions. The results indicate that the system can classify driver behavior into cautious, normal, and aggressive categories, achieving Silhouette Scores up to 0.83 and maintaining execution times between 600–700 $$\mu s$$ in most cases. These findings suggest that the approach is suitable for embedded applications requiring adaptive, real-time behavior analysis.},
  archive      = {J_EVOLS},
  author       = {Medeiros, Morsinaldo and Silva, Marianne and Silva, Ivanovitch},
  doi          = {10.1007/s12530-025-09745-2},
  journal      = {Evolving Systems},
  month        = {12},
  number       = {4},
  pages        = {1-32},
  shortjournal = {Evol. Syst.},
  title        = {Evolving online clustering for real-time driver behavior analysis in IoT-enabled vehicles},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Key influencing factors in vehicle platoons: A systematic study and review. <em>EVOLS</em>, <em>16</em>(4), 1-13. (<a href='https://doi.org/10.1007/s12530-025-09746-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle platooning presents a promising approach to enhancing traffic efficiency in autonomous driving. This technique offers numerous benefits, including reduced travel time, lower emissions, improved fuel efficiency, and the potential to mitigate traffic congestion. Despite the aforementioned advantages, the technology is still in its developmental stages, facing several significant technical issues. Key challenges arise from the evolving nature of the vehicle platoon, including vehicle heterogeneity, external disturbances like wind affecting longitudinal dynamics, and delays or interruptions in communication networks. For these reasons, this paper conducts a simulation-based research into the impact of various factors, such as communication delays, network disconnections, external disturbances, among others, on the string stability of vehicle platoons. The simulation results reveal that network disconnections have the most detrimental effect, as they can lead to severe string instability. Other factors, such as external disturbances, do not compromise string stability but may result in steady-state tracking errors.},
  archive      = {J_EVOLS},
  author       = {Viadero-Monasterio, Fernando and Meléndez-Useros, Miguel and Jiménez-Salas, Manuel and López Boada, Beatriz and Jesús López Boada, María},
  doi          = {10.1007/s12530-025-09746-1},
  journal      = {Evolving Systems},
  month        = {12},
  number       = {4},
  pages        = {1-13},
  shortjournal = {Evol. Syst.},
  title        = {Key influencing factors in vehicle platoons: A systematic study and review},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolving fuzzy classification for human-centered explainable learning analytics in virtual environments. <em>EVOLS</em>, <em>16</em>(4), 1-17. (<a href='https://doi.org/10.1007/s12530-025-09747-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the use of explainable artificial intelligence in education, with a focus on its relevance for Learning Analytics. The research introduces a prototype-based dynamic incremental classification algorithm, Dynamic Incremental Semi-Supervised Fuzzy C-Means (DISSFCM), which leverages fuzzy logic to analyze student interaction data from virtual learning platforms, even when the data are only partially labeled. The proposed methodology generates human-centered explanations by extracting IF-THEN fuzzy rules from the evolving prototypes produced by DISSFCM over successive time intervals. These explanations, expressed in linguistic terms, remain accessible to non-expert stakeholders and are particularly suitable for educational contexts. The Open University Learning Analytics Dataset (OULAD) is utilized for experimentation and validation, providing a realistic scenario for semi-supervised data collection. Visual summaries of the evolving fuzzy rules support the identification of temporal patterns in streaming data. Results show that the model effectively adapts to concept drift while maintaining interpretability. Most notably, it proves robust in handling partially labeled data and variable time granularities, two challenges frequently encountered in real-world Learning Analytics scenarios. The ability to both predict student outcomes and provide intelligible explanations under such constraints highlights the practical value of the approach. To evaluate the quality and relevance of the generated explanations, an expert-based evaluation was conducted. Domain experts evaluated the clarity, usefulness, and accuracy of the explanations in terms of their support for human understanding and decision-making. The results suggest that the explanations were perceived as generally informative and useful, supporting the method’s relevance for human-centered educational applications.},
  archive      = {J_EVOLS},
  author       = {Casalino , Gabriella and Castellano, Giovanna and Kaczmarek-Majer, Katarzyna and Schicchi, Daniele and Taibi, Davide and Zaza, Gianluca},
  doi          = {10.1007/s12530-025-09747-0},
  journal      = {Evolving Systems},
  month        = {12},
  number       = {4},
  pages        = {1-17},
  shortjournal = {Evol. Syst.},
  title        = {Evolving fuzzy classification for human-centered explainable learning analytics in virtual environments},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scale-invariant object detection by adaptive convolution with unified global-local context. <em>EVOLS</em>, <em>16</em>(4), 1-15. (<a href='https://doi.org/10.1007/s12530-025-09749-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense features are important for detecting differnet scale objects in images. Unfortunately, despite the remarkable efficacy of the CNN models in multi-scale object detection, CNN models often fail to detect different scale objects in images due to using similar type of CNN features. Atrous convolution addresses this issue by applying sparse kernels. However, sparse kernels often can lose the multi-scale detection efficacy of the CNN model. In this paper, we propose an object detection model using a Switchable Atrous Convolutional Network (SAC-Net) based on the efficientDet model.A fixed atrous rate limits the performance of the CNN models in the convolutional layers. To overcome this limitation, we introduce a switchable mechanism that allows dynamically adjusting the atrous rate during the forward pass. The proposed SAC-Net encapsulates the benefits of both low-level and high-level features to achieve improved performance on multi-scale object detection tasks, without losing the dense features. Further, we apply a depth-wise switchable atrous rate to the proposed network, to improve the scale-invariant features. Finally, we apply the global context to the proposed model. Our extensive experiments on benchmark datasets demonstrate that the proposed SAC-Net outperforms the state-of-the-art models by a significant margin in terms of accuracy. The code will be released after acceptance.},
  archive      = {J_EVOLS},
  author       = {Singh, Amrita and Mukherjee, Snehasis},
  doi          = {10.1007/s12530-025-09749-y},
  journal      = {Evolving Systems},
  month        = {12},
  number       = {4},
  pages        = {1-15},
  shortjournal = {Evol. Syst.},
  title        = {Scale-invariant object detection by adaptive convolution with unified global-local context},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coal blocking detection method for underground transfer point conveyor based on MR-CAE. <em>EVOLS</em>, <em>16</em>(4), 1-15. (<a href='https://doi.org/10.1007/s12530-025-09751-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coal mine transportation safety is of vital importance. Traditional coal flow prediction methods have problems such as low accuracy and susceptibility to environmental factors. To address these pro blems, this paper proposes a multi-scale residual convolutional autoencoder (MR-CAE) for coal blockage detection in transfer stations. The model introduces a multi-layer residual convolutional block to improve the decoder, combined with a multi-scale enhanced fusion convolutional block (MEFCB), and uses a dynamic attention mechanism to adaptively fuse coal flow features to obtain higher detection accuracy. Finally, skip connections are used to enhance the model's adaptability to the environment. Indicators such as MAE and MSE are used to evaluate the prediction performance, and the robustness of the model is ensured by testing in more scenarios. Compared with Swin Transformer and ViT, the prediction accuracy of the model is improved by 3.6% and 3.3%, respectively, and the detection success rate reaches 93.5%. This demonstrates its advanced capabilities in coal flow prediction and provides a reliable framework for coal flow monitoring in transfer stations.},
  archive      = {J_EVOLS},
  author       = {Yu, Yuanhang and Zhou, Huaping and Sun, Kelei},
  doi          = {10.1007/s12530-025-09751-4},
  journal      = {Evolving Systems},
  month        = {12},
  number       = {4},
  pages        = {1-15},
  shortjournal = {Evol. Syst.},
  title        = {Coal blocking detection method for underground transfer point conveyor based on MR-CAE},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving MCI classification with multimodal hyper-connectivity and deep neural networks for early detection of alzheimer’s disease. <em>EVOLS</em>, <em>16</em>(4), 1-21. (<a href='https://doi.org/10.1007/s12530-025-09748-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early symptoms of Alzheimer’s disease often manifest as Mild Cognitive Impairment making timely and crucial accurate classification for prompt diagnosis and therapeutic strategy development. However, mild cognitive impairment classification is hindered by challenges such as data heterogeneity, overfitting, and decreased learning efficiency, especially when handling complex, multimodal neuroimaging data. To tackle these issues, this research introduces a novel multimodal deep learning method for accurate mild cognitive impairment classification subtypes employing structural and functional MRI as well as demographic and cognitive features from Alzheimer’s disease Neuroimaging Initiative Dataset. This technique uses a graph convolutional network based multimodal hyper-connectivity network to capture complex intermodal relationships among extracted features. The structural MRI data undergo standardized processing including intensity normalization, skull stripping, spatial normalization and tissue segmentation while functional MRI data are processed into functional connectivity matrices and Pearson correlation. A hyper-connectivity graph is constructed employing mutual information and cross-correlation to quantify relationship between multimodal features. The graph convolutional network propagates and aggregates context-aware features which are further processed through customized deep neural network classifier employing ReLU activation, dropout and softmax output for multiclass classification. The simulation outcomes on the dataset demonstrate that the proposed multimodal deep learning technique significantly outperforms existing methods. It achieves accuracy (98.79%), precision (98.02%), recall (98.77%), specificity (98.76%), and F1-score (98.39%). These outcomes reflect the technique’s robust potential to support early detection and MCI monitoring which contributes to more efficient and accessible Alzheimer’s disease management.},
  archive      = {J_EVOLS},
  author       = {Julaiha, Noorul and Vasudevan, B.},
  doi          = {10.1007/s12530-025-09748-z},
  journal      = {Evolving Systems},
  month        = {12},
  number       = {4},
  pages        = {1-21},
  shortjournal = {Evol. Syst.},
  title        = {Improving MCI classification with multimodal hyper-connectivity and deep neural networks for early detection of alzheimer’s disease},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid fox optimization algorithm with chaotic maps and polynomial mutation for clustering applications. <em>EVOLS</em>, <em>16</em>(4), 1-27. (<a href='https://doi.org/10.1007/s12530-025-09750-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering of unlabeled data is a critical task for extracting meaningful patterns from large and complex datasets. In this context, metaheuristic optimization-based clustering methods have gained popularity due to their ability to handle nonlinear and high-dimensional search spaces. This study introduces the Hybrid Fox Optimization Algorithm (ECFOX), an improved optimization and clustering method that builds upon the standard FOX algorithm. ECFOX integrates chaotic maps for population initialization and adaptive control, as well as a polynomial mutation operator to enhance solution diversity and local refinement. The Singer chaotic map generates a well-distributed initial population, while the Iterative chaotic map adaptively balances exploration and exploitation. A polynomial mutation operator is periodically applied to refine candidate solutions and maintain diversity. The effectiveness of ECFOX was evaluated in two experimental stages. First, clustering performance was tested on 17 real-world datasets from the UCI Machine Learning Repository, comparing ECFOX with traditional clustering methods (K-means, K-medoids, Fuzzy C-means) and popular metaheuristic algorithms (ChOA, GWO, WOA, PSO, FOX). ECFOX achieved superior results on most datasets. In the second stage, ECFOX was tested on 23 classical benchmark functions to assess its global and local search performance. The results were compared with those of well-known metaheuristic algorithms, including GWO, CHIMP, PSO, ALO, IALO, and the standard FOX algorithm. ECFOX demonstrated superior convergence speed, solution quality, and robustness. Statistical validation using Wilcoxon signed-rank and Friedman tests confirmed the significance of ECFOX’s improvements. These findings suggest that ECFOX is a reliable and competitive approach for clustering and general optimization problems.},
  archive      = {J_EVOLS},
  author       = {Dağlı, İlker and İnan, Onur and Başçi̇ftçi̇, Fatih},
  doi          = {10.1007/s12530-025-09750-5},
  journal      = {Evolving Systems},
  month        = {12},
  number       = {4},
  pages        = {1-27},
  shortjournal = {Evol. Syst.},
  title        = {A hybrid fox optimization algorithm with chaotic maps and polynomial mutation for clustering applications},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incorporating manifold regularization into adaptive label thresholding algorithm for online semi-supervised multi-label classification. <em>EVOLS</em>, <em>16</em>(4), 1-15. (<a href='https://doi.org/10.1007/s12530-025-09752-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online multi-label classification aims to assign multiple appropriate categories to arriving instances. Currently, most approaches focus on supervised scenarios where instances are all labeled. The adaptive label thresholding approach, for example, can dynamically adjust the label threshold for labeled instances to distinguish relevant and irrelevant labels. However, in reality, labeling every instance is time-consuming and resource-intensive, and typically only a small fraction of instances are labeled. To address this challenge, we propose an innovative online semi-supervised multi-label classification algorithm. We design a novel online manifold regularization term that can leverage the similarity between labeled and unlabeled instances for prediction, and integrate it with the optimization objective of the adaptive label thresholding algorithm. The Online Gradient Descent method is employed to solve the improved optimization problem. We further extend the model to handle nonlinear classification problems using Mercer kernels, and derive detailed coefficient update formulas for support vectors. Experiments are conducted on eight open datasets spanning text, image, music, and biology domains. Performance is evaluated using seven common multi-label classification metrics. Paired t-tests on F1-measure results show that our proposed algorithm achieves statistically significant improvements over the second-best method on six datasets, confirming its effectiveness in semi-supervised multi-label classification tasks.},
  archive      = {J_EVOLS},
  author       = {Fang, Nannan and Zhai, Tingting},
  doi          = {10.1007/s12530-025-09752-3},
  journal      = {Evolving Systems},
  month        = {12},
  number       = {4},
  pages        = {1-15},
  shortjournal = {Evol. Syst.},
  title        = {Incorporating manifold regularization into adaptive label thresholding algorithm for online semi-supervised multi-label classification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information diffusion prediction using hybrid GCNN–LSTM and stock market based sentiment analysis in social media. <em>EVOLS</em>, <em>16</em>(3), 1-23. (<a href='https://doi.org/10.1007/s12530-025-09694-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of social media, the information diffusion popularity prediction has attracted wide attention in many applications. However, due to the real-time changes in networks and the complexity of social interactions, analyzing the exact mechanism of the information dissemination process remains extremely difficult. However, conventional popularity prediction methods rely heavily on human expertise to create features and define the generative model, or completely depend on the underlying user relation network for embedding learning. To address these concerns, this proposed work designed an information diffusion prediction model using a Hybrid Graph Convolutional Neural Network–Long Short Term Memory (GCNN–LSTM). The sentiment of the diffused information is analyzed through a hybrid Long Short Term Memory–Support Vector Machine (LSTM–SVM) in social media applications. The proposed work comprises two phases: the first phase is for effective popularity prediction of information diffusion, and the second phase is for analyzing the users' sentiment based on the influence of diffused information. In the detection of the information diffusion phase, the user data from social media is gathered to make a graphical representation based on the comment node attributes, and the effective features are extracted with the assistance of the graph convolutional neural network. After that, the features are given in the LSTM model for the detection of popularity. The diffused information in social media is considered in the sentimental analysis phase; initially, the data is subjected to preprocessing, and features are extracted with Term Frequency Inverse Document Frequency (TFIDF). Finally, with the help of a hybrid LSTM–SVM, the sentiment of the social media data is detected. The proposed model is implemented in MATLAB software and achieved 96% accuracy for phase 1 and 96% for phase 2. Thus, the proposed model effectively detects the spread of information in social media, which can assist various applications.},
  archive      = {J_EVOLS},
  author       = {Sabharwal, Shweta Mayor and Aggrawal, Niyati},
  doi          = {10.1007/s12530-025-09694-w},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-23},
  shortjournal = {Evol. Syst.},
  title        = {Information diffusion prediction using hybrid GCNN–LSTM and stock market based sentiment analysis in social media},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Carbon price volatility prediction using a hybrid CEEMDAN-attention-LSTM approach. <em>EVOLS</em>, <em>16</em>(3), 1-15. (<a href='https://doi.org/10.1007/s12530-025-09704-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carbon price volatility is a critical indicator of the carbon trading market, characterized by its phase-wise variation. However, conventional forecasting methods frequently struggle to address the substantial noise and non-linear dynamics inherent in these sequences. To address these challenges, this study proposes a novel hybrid model, CEEMDAN-At-LSTM, which combines complete ensemble empirical mode decomposition with adaptive noise (CEEMDAN) and an attention-enhanced long short-term memory network (LSTM). The model decomposes complex volatility sequences and captures hidden temporal features within each subsequence. Forecasting performance was evaluated using metrics including MAE, MSE, HMAE, and HMSE, and further validated through the model confidence set (MCS) test to ensure robustness. Experiments were conducted on datasets from the Hubei Carbon Emissions Trading Center and the EU ETS, representing emerging and developed markets, respectively. CEEMDAN-At-LSTM achieved at least a 38.87% reduction in forecasting error compared to baseline models, demonstrating its effectiveness in managing nonlinearity and noise. This approach provides a reliable framework for carbon market volatility forecasting, supporting informed policymaking and the advancement of a low-carbon economy.},
  archive      = {J_EVOLS},
  author       = {Yao, Junxuan and Wang, Heping and Mao, Suzhen},
  doi          = {10.1007/s12530-025-09704-x},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-15},
  shortjournal = {Evol. Syst.},
  title        = {Carbon price volatility prediction using a hybrid CEEMDAN-attention-LSTM approach},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HC-DMAformer: Hybrid convolutional-dynamic multi-level attention transformer for efficient and accurate EEG-based autism detection. <em>EVOLS</em>, <em>16</em>(3), 1-16. (<a href='https://doi.org/10.1007/s12530-025-09705-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorder is a neurological condition that significantly impacts communication and social interactions. Psychological tests and neuroimaging are frequently used in traditional autism spectrum disorder detection techniques. However, electroencephalogram is an effective tool for identifying neurological disorders like autism spectrum disorder because it has the ability to capture real-time brain activity. Therefore, this paper introduces a novel framework called a hybrid convolutional-dynamic multi-level attention transformer model. The proposed framework integrates convolutional neural networks with a dynamic multi-level attention mechanism, which replaces the traditional self-attention layer in transformers, significantly reducing computational complexity while maintaining high detection accuracy. The electroencephalogram data recordings are initially preprocessed through re-referencing, filtering, and normalization procedures. The pre-processed data signals are segmented and transformed into spectrograms using the short-time Fourier transform technique. These spectrograms are used as model input for the training approach. The proposed model used VGG-16 and ResNet-50 to extract features, while attention-based transformer captures complex temporal patterns in the electroencephalogram spectrograms. Following feature extraction, the model refines the representation before classification by applying a dense layer to refine the combined feature set. The feature maps obtained from triple-stream modules are fused to form hybrid features and are classified into two distinct classes: non-autistic and autistic cases using the softmax classifier. The evaluation of the HC-DMAformer model attained a higher accuracy of 99.23%, across various Electroencephalogram datasets. Furthermore, the model is computationally efficient, with a training duration of 1 h 29 min, and a computation time of 13.18 s. The result demonstrates that the proposed method outperforms than other methods.},
  archive      = {J_EVOLS},
  author       = {Kavitha, V. and Vidhya, R. and Swathi Mirthika, G. L. and Suresh, K. and Hemavathi, S},
  doi          = {10.1007/s12530-025-09705-w},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-16},
  shortjournal = {Evol. Syst.},
  title        = {HC-DMAformer: Hybrid convolutional-dynamic multi-level attention transformer for efficient and accurate EEG-based autism detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolving security measures for IoT medical data in cloud environments. <em>EVOLS</em>, <em>16</em>(3), 1-17. (<a href='https://doi.org/10.1007/s12530-025-09706-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Medical Things (IoMT) consists of interconnected devices such as wearable sensors, medical monitors, and diagnostic tools that collect and transmit real-time health data. These networks play a crucial role in modern healthcare by enabling continuous patient monitoring and data-driven decision-making. However, the increasing reliance on medical IoT devices exposes them to various cybersecurity threats, such as data breaches, unauthorized access, and denial-of-service attacks. The sensitive nature of healthcare data makes these networks attractive targets for malicious actors, which compromise patient safety and privacy. Existing approaches to attack detection in medical IoT networks often struggle to provide accurate and timely detection of cyber-attacks due to the uncertainty and dynamic nature of IoT data. This paper addresses these limitations by introducing a novel Fuzzy Adaptive Support Vector Machine (F-ASVM) that combines fuzzy logic with adaptive SVM to detect attacks accurately. The integration of fuzzy logic allows the model to handle uncertainty in sensor data, providing a more accurate classification of normal behavior and potential attacks. Meanwhile, the adaptive SVM ensures that the model adjusts to new attack patterns over time, making it adaptable to emerging threats. The study also incorporates the Seagull Optimization Algorithm (SOA) with a local strategy to fine-tune the hyperparameters of the SVM, improving the model’s performance and ensuring efficient convergence. The effectiveness of the proposed approach is evaluated using a diabetic patient dataset, with simulation results showing its ability to detect attacks with high accuracy, enhancing the security and reliability of critical medical IoT infrastructure.},
  archive      = {J_EVOLS},
  author       = {Dhaya, C. and Niranjana, G. and Prakash, B.},
  doi          = {10.1007/s12530-025-09706-9},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-17},
  shortjournal = {Evol. Syst.},
  title        = {Evolving security measures for IoT medical data in cloud environments},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid jumping swarm optimization based local search approach for minimum weighted dominating set problem. <em>EVOLS</em>, <em>16</em>(3), 1-15. (<a href='https://doi.org/10.1007/s12530-025-09707-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Minimum Weighted Dominating Set (MWDS) problem is a challenging hard graph optimization problem and it has various real-world applications, particularly in network design and communications. In this paper, a novel, discrete swarm optimization-based local search algorithm is developed for MWDS. This approach integrates the jumping particle swarm optimization approach with two new local search strategies based on cost ratio and neighbourhood search, with this, the proposed JPSWD efficiently identifies the solution space by avoiding local optimum. Simulation results carried out on extensive datasets suggest that the performance of JPSWD is better than that of the existing algorithms. This notable improvement is particularly evident in the context of execution time and computational cost, which are critical factors we have considered over other algorithms. A statistical analysis based on algorithms’ ranking further substantiates the better performance of JPSWD, and marking it as a better alternative for tackling the MWDS problem.},
  archive      = {J_EVOLS},
  author       = {Maheswari, G. and Balaji, S.},
  doi          = {10.1007/s12530-025-09707-8},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-15},
  shortjournal = {Evol. Syst.},
  title        = {A hybrid jumping swarm optimization based local search approach for minimum weighted dominating set problem},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient lung disease classification using dove swarm optimization based multi-scale faster-RCNN model. <em>EVOLS</em>, <em>16</em>(3), 1-22. (<a href='https://doi.org/10.1007/s12530-025-09708-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Respiratory illness remains a significant cause of increased morbidity and mortality rates, particularly in developing countries. To conduct an in-depth analysis an efficient machine-learning technique is essential. Various approaches including computed tomography (CT) have evolved in this domain to detect lung diseases but have several disadvantages such as the usage of ionization and inevitable radiation exposure by which the overall results get diminished. In response to this limitation, this paper proposes a novel approach called “Enhanced Multi-Scale Faster Recurrent Convolutional Neural Network based on Dove Swarm Optimization” (EMFRCNN-DSO). The DSO is an effective and time-efficient algorithm for solving several optimization problems. The proposed EMFRCNN-DSO algorithm addresses the demerits of several existing methods and demonstrates enhanced accuracy in classifying the classes of lung disease. The proposed EMFRCNN-DSO algorithm follows a structured process. It begins by preprocessing raw chest X-ray images through enhancement and normalization tasks. Subsequently, a set of significant features, including texture-based, shape-based, and histograms of oriented gradient features, are extracted from the preprocessed data. Based on these extracted feature vectors, the EMFRCNN-DSO classifier accurately categorizes multiple lung disease classes, including healthy, pneumonia, COPD, COVID-19, tuberculosis, and lung opacity. To enhance the classification performance further, the loss functions of the enhanced multi-scale Faster RCNN are normalized and weighted by tuning optimal values for the balancing parameter using the dove swarm optimization algorithm. This step significantly improves the accuracy of classifying lung disease classes. Experimental investigations validate the superiority of the proposed EMFRCNN-DSO algorithm, demonstrating an enhanced classification accuracy of approximately 97.5%. This achievement marks a notable improvement thus paving the way for more effective and timely interventions to combat respiratory illnesses.},
  archive      = {J_EVOLS},
  author       = {Varadharajan, Indumathi and Rathinavelayutham, Siva},
  doi          = {10.1007/s12530-025-09708-7},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-22},
  shortjournal = {Evol. Syst.},
  title        = {An efficient lung disease classification using dove swarm optimization based multi-scale faster-RCNN model},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive algorithms for YouTube channel analysis and revenue enhancement. <em>EVOLS</em>, <em>16</em>(3), 1-23. (<a href='https://doi.org/10.1007/s12530-025-09709-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to increasing competition and evolving viewer preferences, content creators on YouTube face challenges in optimizing revenue generation. To address these challenges, this study proposes a novel framework comprising three algorithms namely, Similar Channels algorithm, Rank Score algorithm, and Video Analysis algorithm with Long Short-Term Memory. The Similar Channels algorithm introduces a multidimensional similarity assessment that integrates content features, video tags, and engagement metrics such as likes, views, and subscribers for accurately identifying the channels with comparable performance and audience engagement. In addition, the Similar Channel algorithm dynamically adjusts weightage for different metrics based on content type. The Rank Score algorithm enhances competitor analysis by implementing a weighted ranking system that assigns adaptive weights to engagement metrics, providing creators with actionable insights into their competitive landscape. The Video Analysis algorithm employs a Long Short-Term Memory-based Recurrent Neural Network to capture temporal trends in engagement metrics and effectively identify the top-performing videos that drive audience engagement and revenue. Further, the Video Analysis algorithm leverages sequential engagement data to predict video success with greater accuracy. Experimental evaluations demonstrate the effectiveness of the proposed algorithms, achieving a high ranking accuracy of 0.98 for competitor channel analysis and precisely identifying top-performing videos based on engagement scores. By leveraging big data analysis and novel algorithmic improvements, content creators optimize revenue generation on YouTube channels by making data-driven decisions. The Similar Channel and Rank Score algorithms provide insights into competitor performance, while the Video Analysis algorithm with Long Short-Term Memory enables the identification of top-performing videos.},
  archive      = {J_EVOLS},
  author       = {Subha, K. and Bharathi, N.},
  doi          = {10.1007/s12530-025-09709-6},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-23},
  shortjournal = {Evol. Syst.},
  title        = {Adaptive algorithms for YouTube channel analysis and revenue enhancement},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel approach for classifying LEV motor bearing faults using a PSO-optimized CNN model and parameters based on transfer learning. <em>EVOLS</em>, <em>16</em>(3), 1-23. (<a href='https://doi.org/10.1007/s12530-025-09710-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Light Electric Vehicles (LEVs) have recently become a popular choice for transportation due to their environmental and economic benefits. This growing interest necessitates LEV motors to operate with higher performance and reliability. In recent years, Brushless Direct Current (BLDC) electric motors have been preferred as LEV motors to meet this need. Failures occur over time in LEV motors operating in outdoor environments. In this study, a new novel method based on CEEMDAN (Complete Ensemble Empirical Mode Decomposition with Adaptive Noise)—STFT (Short Time Fourier Transform) and hybrid PSO (Particle Swarm Optimization)—CNN (Convolutional Neural Networks)—TL (Transfer Learning) is proposed to diagnose LEV bearing failure. In this new method, the IMFs (Intrinsic Mode Function) of one-dimensional time series vibration signals are obtained with CEEMDAN. Each IMF matrix was converted into spectrograms using STFT. Data augmentation methods enhanced these spectrograms. Using this data set, CNN model design was performed with the PSO algorithm. Parameters were optimized with the CNN model that gave the highest accuracy. Using the fine-tuning method, which is part of the transfer learning process, the performance of the obtained hyperparameters was measured with a five-fold cross-validation on GoogleNet, ResNet-50, DarkNet-53, MobileNet-v2 and Xception deep learning architectures. These architectures were evaluated with metrics such as accuracy, precision, recall and F1 score and the DarkNet-53 model gave the highest classification accuracy of 99.53%. The results show that the proposed new method is robust for diagnosing bearing failures in LEVs with limited data.},
  archive      = {J_EVOLS},
  author       = {Esmeray, Hadi and Dogan, Zafer and İşeri, İsmail},
  doi          = {10.1007/s12530-025-09710-z},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-23},
  shortjournal = {Evol. Syst.},
  title        = {A novel approach for classifying LEV motor bearing faults using a PSO-optimized CNN model and parameters based on transfer learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recursive methods for updating consequent parameters in evolving fuzzy systems: A comprehensive review with computational experiments. <em>EVOLS</em>, <em>16</em>(3), 1-30. (<a href='https://doi.org/10.1007/s12530-025-09711-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolving (Fuzzy and Neuro-Fuzzy) Systems are known for expanding or contracting their structure and updating their parameters on the fly in a single pass, eventually in real-time, to react to process drifts while obtaining the output. The system’s structure can be adjusted by creating, merging, splitting, deleting, or updating its structural components, such as rules, clusters, neurons, granules, leaves, or clouds. On the other hand, the consequent (output weight) parameters can be updated using modeling and optimization methods. Typically, in an Evolving System, the consequent parameters are updated using the recursive least square algorithm or its variations. This paper provides a comprehensive analysis of recursive learning methods used to update the consequent parameters in Evolving Systems. Seven methods are detailed and revisited, namely Recursive Least Squares (RLS), Weighted Recursive Least Squares (WRLS), Recursive Weighted Total Least Squares (RWTLS), Multi-Innovations Recursive Weighted Least Squares (MI), Kernel Recursive Least Squares (KRLS), Recursive Maximum Correntropy (RMC), and Gradient Descent (GD). These seven approaches were implemented in three distinct Evolving Systems and compared in ten data stream regression tasks. The experimental results suggest that the WRLS achieved the average best performance, followed by RMC and RLS. The study also indicates that there is no one-size-fits-all or universally optimal method for updating consequent parameters across all Evolving Systems and datasets. Future work should prioritize developing methods focusing on accuracy and computational efficiency, especially in high-dimensional data streams. Additionally, research should explore robust approaches to handle noise and context changes, ensuring consistent performance across various conditions.},
  archive      = {J_EVOLS},
  author       = {Rodrigues, Fernanda P. S. and Silva, Alisson Marques},
  doi          = {10.1007/s12530-025-09711-y},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-30},
  shortjournal = {Evol. Syst.},
  title        = {Recursive methods for updating consequent parameters in evolving fuzzy systems: A comprehensive review with computational experiments},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual attention-based CNN-LSTM framework for session-based recommendations. <em>EVOLS</em>, <em>16</em>(3), 1-17. (<a href='https://doi.org/10.1007/s12530-025-09712-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation systems (SRS) are essential in dynamic environments where user preferences evolve over time. This paper proposes a Hybrid session-based recommendation (HSRec) model that integrates "Convolutional Neural Networks" (CNN) with "Long Short-Term Memory" (LSTM) networks to enhance recommendations within session contexts. The CNN is employed to capture local interaction patterns between items within the session, whereas the LSTM component captures the sequential flow of user behaviour across items. In addition, the model introduces a dual attention mechanism, comprising item-level attention to focus on key interactions within the session and session-level attention to capture long-term preferences by weighting past sessions based on relevance. The proposed hybrid model utilizes item embeddings to represent items in dense vectors and applies CNN filters to capture short-term patterns in sessions, such as frequent item co-occurrences. The LSTM processes the output of the CNN to model long-term dependencies across the entire session. A final prediction layer with softmax activation predicts the next item in the session. The results indicate that HSRec outperforms traditional models by effectively learning both local and global dependencies in session data. The model’s effectiveness is assessed on different datasets, and the findings indicate that HSRec surpasses traditional methods, delivering greater efficiency in offering personalized recommendations to users.},
  archive      = {J_EVOLS},
  author       = {Jangid, Manisha and Kumar, Rakesh},
  doi          = {10.1007/s12530-025-09712-x},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-17},
  shortjournal = {Evol. Syst.},
  title        = {Dual attention-based CNN-LSTM framework for session-based recommendations},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolving interval-based time series clustering for streaming industrial data. <em>EVOLS</em>, <em>16</em>(3), 1-17. (<a href='https://doi.org/10.1007/s12530-025-09713-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate clustering of time series data is crucial for extracting meaningful insights from streaming sensor data in industrial applications. To address the challenges of dynamic and unlabeled data streams, we introduce Interval ERAL (iERAL), an enhancement of the Error in Aligned Series (ERAL) framework. iERAL is a time series alignment and averaging method designed for online analysis, incorporating an interval band to represent variance in the underlying data. We pair iERAL with an evolving time series clustering algorithm, capable of automatically detecting, adapting to, and merging clusters in real-time. This evolving approach enables the algorithm to dynamically adjust to new patterns, promote or demote clusters based on their relevance, and handle data variability with interval-based analysis. Unlike previous methods, our approach not only computes the time series prototype for each cluster but also provides a variance band for interval-based analysis. We demonstrate the effectiveness of our method by applying it to line pressure measurements in a real-world industrial setting. The algorithm achieves promising results in clustering unlabeled data streams, highlighting its potential for anomaly detection and adaptive monitoring of industrial processes in evolving operating conditions.},
  archive      = {J_EVOLS},
  author       = {Stržinar, Žiga and Škrjanc, Igor and Pregelj, Boštjan},
  doi          = {10.1007/s12530-025-09713-w},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-17},
  shortjournal = {Evol. Syst.},
  title        = {Evolving interval-based time series clustering for streaming industrial data},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On resolving the out of vocabulary problem in DisCoCat-based quantum natural language processing. <em>EVOLS</em>, <em>16</em>(3), 1-15. (<a href='https://doi.org/10.1007/s12530-025-09714-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of quantum computing has evolved a lot in the past few years with doors opening for novel applications in a variety of fields. Consequently, natural language processing (NLP) has also been affected due to this disruption, leading to various proposals for doing NLP on a quantum computer. One such promising framework is DisCoCat, a linguistics-oriented model designed to capture the meaning of language without compromising its structural information. Recently, DisCoCat models have been run on real quantum hardware. However, a few issues in the current formulation have led to problems like the out-of-vocabulary (OOV) problem. In this work, our aim is to tackle this OOV problem with respect to DisCoCat-based quantum natural language processing. We first design a novel functor mapping from string diagrams, a primary construction in DisCoCat, to quantum circuits. Later, we test the correctness and validity of this new technique on state-of-the-art datasets for tasks such as sentence similarity and paraphrase identification. We present clear empirical evidence that this novel functor mapping not only performs better than the pre-existing technique in most cases, but also it does so with relatively fewer parameters, thus ensuring better scalability with improved performance.},
  archive      = {J_EVOLS},
  author       = {Bhatuse, Amey and Khandelwal, Ankit and Udmale, Sandeep S. and Chandra, M Girish and Kolte, Sopan},
  doi          = {10.1007/s12530-025-09714-9},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-15},
  shortjournal = {Evol. Syst.},
  title        = {On resolving the out of vocabulary problem in DisCoCat-based quantum natural language processing},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization of bound-constrained and constrained optimization problems with interval coefficients via extended tournament differential evolution. <em>EVOLS</em>, <em>16</em>(3), 1-43. (<a href='https://doi.org/10.1007/s12530-025-09715-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this work is to develop a hybrid algorithm for solving bound constrained and constrained optimization problems with interval coefficients. The proposed algorithm is based on tournamenting process and differential evolution algorithm popularly known as tournament differential evolution. In this work, the said algorithm is extended using interval mathematics and interval ranking in order to make this algorithm compatible of solving optimization problems in interval environment. In this connection, ten bound constrained optimization problems with interval coefficients and ten constrained optimization problems with interval coefficients are considered and solved by the proposed algorithm. The results obtained from different variants of this algorithm are compared with each other. Also, to test the efficiency, two different variants of tournamenting adaptive Gaussian quantum particle swarm optimization algorithm, are used to compare the results obtained from different variants of tournament differential evolution algorithm. Finally, analysis of variance test is performed.},
  archive      = {J_EVOLS},
  author       = {Akhtar, Md and Mandal, Goutam and Bhunia, Asoke Kumar},
  doi          = {10.1007/s12530-025-09715-8},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-43},
  shortjournal = {Evol. Syst.},
  title        = {Optimization of bound-constrained and constrained optimization problems with interval coefficients via extended tournament differential evolution},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CRCNet: Convolutional multi-layer perceptron encoder with attention module for colorectal cancer segmentation. <em>EVOLS</em>, <em>16</em>(3), 1-13. (<a href='https://doi.org/10.1007/s12530-025-09716-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal cancer (CRC) segmentation is a difficult task because of the structural complexity of polyps in colonoscopy and endoscopy imaging. This paper proposes CRCNet, a novel deep learning (DL) framework to address these challenges using specifically designed components that improve feature learning and localization precision. CRCNet combines a convolutional multi-layer perceptron (MLP) encoder that preserves both spatial and contextual representations; a synchronized feature boost (SFB) module to maintain fine-grained low-level features usually lost during downsampling. A convolutional block attention module (CBAM) to focus on diagnostically relevant areas using spatial and channel-wise attention. Further, a semantic-local feature aggregation (SLFA) block merges semantic context with localized information to enhance boundary clarity in the decoder. CRCNet is evaluated on four benchmark datasets: CVC-ClinicDB, ETIS, CVC-ColonDB, and CVC-300. It achieves dice coefficient of 0.9519, 0.9139, 0.8677, and 0.9421 intersection over union scores of 0.9083, 0.8438, 0.7692, and 0.8909, respectively. The model also demonstrates exceptional boundary accuracy and lowers mean absolute error ( $$\le 0.0180$$ ) with a structure measure (Sm) above 0.93 and an enhanced measure above 0.95 across all datasets. The lightweight architecture (1.18 M parameters) of CRCNet ensures computational efficiency by preserving detailed anatomy details in low-contrast areas. These experimental results show the superior performance of CRCNet over existing techniques by focusing on its adaptability in managing various polyp shapes, scale modifications, and imaging artefacts. CRCNet improves the accuracy of CRC diagnosis by fusing attention systems and advanced feature enhancement.},
  archive      = {J_EVOLS},
  author       = {Singh, Manoj Kumar and Chand, Satish and Kumar, Devender},
  doi          = {10.1007/s12530-025-09716-7},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-13},
  shortjournal = {Evol. Syst.},
  title        = {CRCNet: Convolutional multi-layer perceptron encoder with attention module for colorectal cancer segmentation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLOv8n-EggplantDiseases: An enhanced model for accurate disease detection in eggplants. <em>EVOLS</em>, <em>16</em>(3), 1-18. (<a href='https://doi.org/10.1007/s12530-025-09717-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address issues such as rot, disease, and low detection accuracy in eggplant production, this paper proposes an improved detection model based on YOLOv8n, named YOLOv8n-EggplantDiseases (YOLOv8n-ED). The model enhances target detection by redesigning the feature extraction network and optimizing the detection architecture. Specifically, it integrates C2f_CGA and Swin Transformer into the backbone to improve semantic representation and small-object recognition in complex backgrounds. Additionally, the SimAM attention-free mechanism is incorporated to further enhance contextual understanding. The original convolution layers are replaced with the ADown module, and BoTNet is introduced to strengthen target identification. In the Neck, ODConv (omni-dimensional dynamic convolution) and C2f_SimAM modules are employed to improve feature expressiveness. Moreover, the WIoU loss function is adopted to address class imbalance and scale variation, accelerate convergence, and enhance regression accuracy. The proposed YOLOv8n-ED achieves 73.2% Precision, 66.5% Recall, 70.4% mAP@.5, and 39.5% mAP@.5-.95, outperforming baseline models by + 2.5% Recall, + 1.9% mAP@.5, and + 1% mAP@.5-.95.},
  archive      = {J_EVOLS},
  author       = {Yao, Qingan and Zhang, Congmin and Feng, Yuncong and Wang, Xuexiao},
  doi          = {10.1007/s12530-025-09717-6},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-18},
  shortjournal = {Evol. Syst.},
  title        = {YOLOv8n-EggplantDiseases: An enhanced model for accurate disease detection in eggplants},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A method for predicting key bogie component status under limited and non-stationary data conditions. <em>EVOLS</em>, <em>16</em>(3), 1-21. (<a href='https://doi.org/10.1007/s12530-025-09718-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The normal operation of the bogie is essential for ensuring the safety and stability of high-speed trains. Due to the insufficiency and non-stationarity of operational data from key bogie components, this study proposes a state prediction method that integrates a diffusion model, variational autoencoder (VAE), and attention mechanism. Firstly, the DM-VAE data augmentation method is employed, leveraging the generative capability of the VAE and the data enhancement strength of the diffusion model to mitigate data scarcity. Secondly, an improved Transformer algorithm is designed to adaptively capture non-stationary features, improving prediction accuracy. Finally, the proposed method is validated through a case study on the bogie's air spring. The results demonstrate that the proposed approach achieves improved predictive performance and accuracy.},
  archive      = {J_EVOLS},
  author       = {Zhang, Kai and Wei, Zhe and Wang, Lei and Xu, Duo and Huang, Guotian},
  doi          = {10.1007/s12530-025-09718-5},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-21},
  shortjournal = {Evol. Syst.},
  title        = {A method for predicting key bogie component status under limited and non-stationary data conditions},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A blockchain–enabled quaternion evolutionary gravitational neocognitron neural network for securing IoT healthcare data in cloud environment. <em>EVOLS</em>, <em>16</em>(3), 1-21. (<a href='https://doi.org/10.1007/s12530-025-09719-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combining traditional healthcare systems with the Internet of Things (IoT) has significantly improved healthcare service quality. However, continuous monitoring and data transmission by wearable devices and sensors in such environments often occur over unsecured open channels, making the system vulnerable to cyberattacks, especially in critical care situations. To address these concerns, a novel solution leveraging Deep Learning (DL) and Blockchain technologies is proposed for secure data sharing in IoT-enabled medical facilities. The model combines an Encoder-Elliptic Curve Deep Neural Network (EECDNN) with blockchain technology and a Quaternion Evolutionary Gravitational Neocognitron Neural Network (QEGNNnet) for intrusion detection and secure cloud-based healthcare data. The system encrypts medical information using EECDNN, with the encryption key managed securely within a blockchain system where it is segmented into blocks for increased security. Authorized users, such as patients and healthcare providers, can retrieve and decrypt data using the secret key. The model’s efficiency was tested on public datasets like ToN-IoT, CIC-IDS 2017, and CIC-IDS 2018, and was compared to other DL models. Results demonstrated substantial improvements, achieving an impressive 99.9% accuracy and a reduced error rate of 2%. The model also exhibited reduced execution time and block access time, significantly enhancing intrusion detection performance.},
  archive      = {J_EVOLS},
  author       = {Taluja, Anuradha and Kumar, Harish and Thangarasu, Jackulin and Pingle, Yogesh Prabhakar},
  doi          = {10.1007/s12530-025-09719-4},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-21},
  shortjournal = {Evol. Syst.},
  title        = {A blockchain–enabled quaternion evolutionary gravitational neocognitron neural network for securing IoT healthcare data in cloud environment},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TransDense121-UNet: A multi-scale transformer-based approach for accurate liver tumor segmentation. <em>EVOLS</em>, <em>16</em>(3), 1-21. (<a href='https://doi.org/10.1007/s12530-025-09720-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liver tumor segmentation and diagnosis from medical images play an important role in treatment planning. However, the conventional process of detecting and segmenting liver tumors is a time-consuming and highly observer-dependent task. Therefore this study develops a multi-scale transformer-based neural network method called TransDense121-UNet for accurate detection and segmentation of liver tumors. This method includes data preprocessing, detection, and segmentation phases. The proposed method is evaluated on various datasets such as 3DIRCADb, LiTS2017, and liver tumor segmentation dataset. Multi-scale Axis Attention is used to extract various features of different scales including intensity, size, shape, and location during liver tumor segmentation. This model applies a multi-path framework that combines multi-scale atrous convolutions in parallel with an axis attention layer. It increases effectiveness as retains a broad receptive field at various dilation rates and provides enhanced features without compromising resolution, resulting in the accurate detection of small tumors. In contrast, the axis attention mechanism is used to capture long-range dependencies for better integration of contextual information which is useful in segmenting complex liver images. In the detection and segmentation phase, TransDense121-UNet is employed which encompasses utilized UNet, DenseNet121, and Enhanced Transformer. By leveraging the unique capabilities of dense block relevant features are extracted, while robust enhanced transformer systems address issues of computational complexity. Through the experimental validation, the proposed approach achieved an accuracy of 98.78% and a Dice coefficient of 0.989, demonstrating its effectiveness in precisely detecting and segmenting liver tumors.},
  archive      = {J_EVOLS},
  author       = {Mayuri, A. V. R. and Maniraj, S. P. and Duraisamy, M. and Murthy, G. L. N. and Garg, Kanika and Sangeetha, M.},
  doi          = {10.1007/s12530-025-09720-x},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-21},
  shortjournal = {Evol. Syst.},
  title        = {TransDense121-UNet: A multi-scale transformer-based approach for accurate liver tumor segmentation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D NoC-enabled spiking neural networks: A high-performance computing paradigm. <em>EVOLS</em>, <em>16</em>(3), 1-18. (<a href='https://doi.org/10.1007/s12530-025-09721-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs), best known for their complex spatial–temporal dynamics, event-driven features, and compatibility with neuromorphic hardware, are gaining popularity in brain-inspired intelligence. As a developing paradigm for artificial general intelligence (AGI), SNNs can potentially create more biologically plausible neural computation models. However, current artificial neural network circuit topologies struggle to accurately replicate the brain's sparse global and dense local connection patterns, also known as a small-world network. A new 3D Network-on-Chip (NoC) architecture and a hybrid wired-wireless NoC router are presented in this study to address this problem and facilitate effective on-chip connectivity in large-scale SNN simulations. The 3D NoC architecture is intended to deliver an accessible and high-performance architecture for mimicking brain-like connectivity inside a reconfigurable hardware environment. The system uses a Neural Tile (NT), which contains a 64:64 fully connected feed-forward SNN framework and incorporates a 3D mesh topology NoC connectivity framework. The hybrid NoC router, which combines wired and wireless routing paradigms, is developed to achieve high speed, reduced area, and increased reliability over standard wired or wireless-only systems. This design provides a viable method for effectively simulating large-scale SNNs and is demonstrated to be a more stable platform for high-performance neuromorphic computing. It addresses the challenge of delivering highly dynamic neural connectivity while maintaining efficient hardware usage. The paper offers a scalable platform for advancing the field of brain-inspired intelligence and neuro-engineering, which is essential for simulating and optimizing Spiking Neural Networks on neuromorphic hardware. The suggested framework has been assessed on a Xilinx Virtex-4 FPGA and synthesized using 90 nm low-power CMOS technology. The presented hybrid NoC router and 3D NoC-enabled architecture are thoroughly evaluated through simulation and synthesis. The proposed design with 64 neurons per chip achieves a silicon area of 3.072 mm2 on a Virtex-4 FPGA, compared to the 3.18 mm2 occupied by the 2D EMBRACE monolithic SNN architecture. This represents a 3.4% reduction in chip area, highlighting the space efficiency of the 3D NoC-based MCNT design, which is particularly impactful given the added scalability and vertical integration benefits of 3D architectures. The findings demonstrate that, compared to previous designs, the suggested architecture offers better performance, including lower latency, reduced chip area, and lower power consumption.},
  archive      = {J_EVOLS},
  author       = {Karthikeyan, V. and Subbulakshmi, K.},
  doi          = {10.1007/s12530-025-09721-w},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-18},
  shortjournal = {Evol. Syst.},
  title        = {3D NoC-enabled spiking neural networks: A high-performance computing paradigm},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi kernel polar code using nut cracker optimization based GAN for successive cancellation decoder to attain low latency and high efficiency. <em>EVOLS</em>, <em>16</em>(3), 1-17. (<a href='https://doi.org/10.1007/s12530-025-09722-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Kernel Polar Code is a type of polar code that utilizes multiple kernels for information encoding and decoding. The selection and optimization of multiple kernels can be challenging. Previous research has demonstrated that existing deep learning models may achieve high decoding accuracy and speed for polar code when the block length can be very tiny. Its speed, however, dramatically drops with longer codes because of the huge network structure. A successful Generative Artificial Intelligence (GEN AI) is developed in this work for decoding polar codes. The input sequence has been encoded using multiple kernel polar codes, giving a polar encoded output. After encoding the message using the multi-kernel polar encoder, the resulting bits are mapped to binary phase-shift keying (BPSK) symbols prior to transmission. The Gaussian noise term with zero mean and variance in additive white Gaussian noise (AWGN) is used to receive the signal. The improved Generative Adversarial Network (GAN) improves the decoder performance under different channel conditions after the signals have been transmitted via the channel. Computation is employed to determine the approximate reliability of the bit channel. The proposed approach achieves 95.30% of accuracy, 4.70% error, 91.70% precision and 96.80% specificity. Thus, the designed optimized GAN model is the best option for successive cancellation in the decoder.},
  archive      = {J_EVOLS},
  author       = {Pushpa, B. Yamini and Panda, Sunita},
  doi          = {10.1007/s12530-025-09722-9},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-17},
  shortjournal = {Evol. Syst.},
  title        = {Multi kernel polar code using nut cracker optimization based GAN for successive cancellation decoder to attain low latency and high efficiency},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolving fault-tolerant control models for optimized big data transmission in power systems using crossover-based chimp optimization. <em>EVOLS</em>, <em>16</em>(3), 1-23. (<a href='https://doi.org/10.1007/s12530-025-09723-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current parallel data transmission method faces challenges such as low data transfer rates and compromised data integrity, leading to node congestion, instability, prolonged processing times, and inefficient data switching during big data scheduling processes. To address these issues, this paper proposes a Cluster Scheduling Fault-Tolerant Control method tailored for transmitting big data within new power systems. The method integrates a crossover-based Chimp optimization to enhance fault control performance in power system operations. The approach analyzes the integrity control principles of Parallel Data Transmission and employs a hybrid queuing model combining a single service window and raster analysis method to regulate Parallel Data Transmission rates. Additionally, a 3 + 1 integration framework adjusts the signal intensity fluctuations to optimize data clustering computations and stabilize nonlinear switched systems within large data clusters. In a closed-loop system configuration, data switching operations are orchestrated to achieve Fault-Tolerant Control in the scheduling of big data clusters. Experimental findings demonstrate the proposed model significantly improves data transmission rates, integrity, and network resource utilization. The developed method enhances efficiency as evidenced by improvements in precision, accuracy, recall, and throughput metrics, validating its effectiveness in real-world applications.},
  archive      = {J_EVOLS},
  author       = {Zhu, Chenfeng and Babu, B. Ravindra and Ramaiah, Gurumurthy B.},
  doi          = {10.1007/s12530-025-09723-8},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-23},
  shortjournal = {Evol. Syst.},
  title        = {Evolving fault-tolerant control models for optimized big data transmission in power systems using crossover-based chimp optimization},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on the application of an improved autoformer model integrating CNN-attention-BiGRU in short-term power load forecasting. <em>EVOLS</em>, <em>16</em>(3), 1-17. (<a href='https://doi.org/10.1007/s12530-025-09724-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate short-term load forecasting is essential for power system reliability and the integration of renewable energy. However, existing models often fail to simultaneously capture long-term dependencies and local fluctuations in load data. This study proposes CA-BiGRU+Autoformer, a hybrid model that combines Convolutional Neural Networks (CNN), Multi-Head Attention, Bidirectional Gated Recurrent Units (BiGRU), and the Autoformer framework. The model is designed to enhance multi-scale feature extraction by integrating local detail perception, bidirectional temporal modeling, and trend-seasonal decomposition. Experiments were conducted on two public datasets—GEFCom2014-E and the Australian Electricity Load and Price Forecasting dataset—to validate the model’s performance across different time resolutions and regional patterns. Compared with state-of-the-art baselines such as Autoformer, Informer, and LSTM, the proposed model achieves superior accuracy. On the GEFCom2014-E dataset, it reduces MSE by 11.4% in 96-step forecasting, while on the Australian dataset, it lowers MSE by 13.6% in 24-step tasks. Ablation studies confirm the effectiveness of each component. The results demonstrate that CA-BiGRU+Autoformer effectively captures complex temporal patterns and offers a robust solution for real-world short-term load forecasting.},
  archive      = {J_EVOLS},
  author       = {Tie, Ruijun and Li, Ming and Zhou, Cong and Ding, Nanwei},
  doi          = {10.1007/s12530-025-09724-7},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-17},
  shortjournal = {Evol. Syst.},
  title        = {Research on the application of an improved autoformer model integrating CNN-attention-BiGRU in short-term power load forecasting},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing security in cloud computing systems using hybrid feature selection and ensemble-based machine learning for intrusion detection. <em>EVOLS</em>, <em>16</em>(3), 1-27. (<a href='https://doi.org/10.1007/s12530-025-09725-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing has become essential for organizations to efficiently store, process, and share data while accessing diverse services. However, the increasing volume of data stored and processed in the cloud exposes it to significant security risks, including unauthorized access and cyber threats. Therefore, this study introduces a novel Hybrid Red Panda Simulated Feature Selection with a Machine Learning-Based Intrusion Detection method for enhancing security in cloud infrastructure. The model collects network traffic data from diverse datasets, including UNSW-NB15, Edge IIoT, TON-IoT, NSL-KDD, Cryptojacking attack time series, and BoT-IoT. To address class imbalance, these datasets are balanced using the Synthetic Minority Over-sampling Technique. The steps taken during preprocessing, such as cleaning the data, applying one-hot encoding, and performing Z-score normalization, is crucial for providing high-quality data. The proposed hybrid optimization method combines Red Panda Optimizer and Simulated Annealing to select optimal features, reducing computational complexity and improving detection efficiency. An Ensemble-based Gradient Boosting Regression Tree is employed for anomaly detection, fine-tuned through grid search to achieve robust performance. To enhance decision-making transparency, Shapley Additive Explanations and Local Interpretable Model-Agnostic Explanations are utilized, offering feature-level and instance-specific insights. A comprehensive evaluation of the proposed framework significantly outperforms existing methods, achieving an accuracy of 99.6% and a precision of 99.35%, demonstrating superior reliability. This work provides a robust and interpretable approach to enhancing cloud security and offers a scalable solution for mitigating cyber threats in diverse cloud environments.},
  archive      = {J_EVOLS},
  author       = {Aswini, J. and Rekha, K. Sashi and Rosaline, R. Anto Arockia and Sivaneshkumar, A.},
  doi          = {10.1007/s12530-025-09725-6},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-27},
  shortjournal = {Evol. Syst.},
  title        = {Enhancing security in cloud computing systems using hybrid feature selection and ensemble-based machine learning for intrusion detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Biometric fingerprint identification in low-quality samples using a hybrid features extraction method with deep learning. <em>EVOLS</em>, <em>16</em>(3), 1-19. (<a href='https://doi.org/10.1007/s12530-025-09726-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fingerprint recognition is essential element of biometric security, yet it faces challenges related to accuracy, robustness, and latency. One significant issue is that the performance of fingerprint authentication systems significantly decreases when faced with low-quality fingerprints. In this paper, two new hybrid approaches are suggested to enhance the accuracy of fingerprint verification and create a reliable identification system. The first approach, SIFT-Descriptor-SCNN, combines the scale-invariant feature transform (SIFT) method with the proposed Siamese convolutional neural network model. First, we compute the SIFT feature descriptors and then pass them to the SCNN for further feature extraction and matching. This increases the system’s ability to distinguish between various patterns for accurate identification. The second novel approach combines oriented FAST with a dense grid, the SIFT algorithm, and the SCNN, named oriented FAST-Dense-SIFT-Descriptor-SCNN. In this work oriented FAST with a dense method is implemented for the detection of keypoints and then the detected keypoints are fed into SIFT algorithm to compute the descriptors. The integration of these algorithms with the SCNN model enhances the performance of the fingerprint identification system. We test the performance of the two hybridization models, the SOCOFing dataset, which includes 6000 real fingerprint and 49,270 synthetically altered versions organized into easy, medium and hard was used. The first model provides an accuracy of 97.57, 96.72, and 95.61 for the easy, medium, and hard datasets, while the validation accuracy is 97.49, 96.14, and 96.07. The second model has a faster prediction time and a higher training and validation accuracy for all three sets. The training accuracy is 98.37, 98.08, and 97.86 and the validation accuracy is 98.55, 97.40, and 98.31.},
  archive      = {J_EVOLS},
  author       = {Haleem, Alyaa and Ben Jabra, Saoussen and Chainbi, Walid},
  doi          = {10.1007/s12530-025-09726-5},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-19},
  shortjournal = {Evol. Syst.},
  title        = {Biometric fingerprint identification in low-quality samples using a hybrid features extraction method with deep learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A physical dynamical evolution learning model for human pose estimation network. <em>EVOLS</em>, <em>16</em>(3), 1-11. (<a href='https://doi.org/10.1007/s12530-025-09727-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human pose estimation can accurately identify and locate the key points and motion of each joint on the human body from images or videos, and abstract an arbitrary human pose skeleton, which has important application prospects in computer vision tasks. Currently, human pose estimation mainly relies on data-driven deep learning models, usually facing problems such as difficulty in training, inefficient learning, and limited generalization ability. Thereby, a physical dynamic evolution learning model for human posture estimation network is proposed to optimize the nonlinear learning property of the deep learning model using physical dynamics. The core of physical dynamic evolution learning model lies in the construction of Hamiltonian dynamical neural network evolution model (HDNE), which mainly consists of alignment network and Hamiltonian neural network (HNN). The alignment network can adapt to the output heads of any different human pose estimation models. HNN learns the Hamilton function that approximates the dynamical system to simulate and predict the evolutionary behavior of high-dimensional features for deep learning based on Hamiltonian canonical equations. Experimental results demonstrate a significant improvement in human pose detection accuracy and training efficiency under the evolutionary learning of HDNE.},
  archive      = {J_EVOLS},
  author       = {Qian, Kui and Deng, Yue and Li, Zhengyan and Wen, Xiulan},
  doi          = {10.1007/s12530-025-09727-4},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-11},
  shortjournal = {Evol. Syst.},
  title        = {A physical dynamical evolution learning model for human pose estimation network},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design of an iterative method for enhanced disease detection and feature selection using particle swarm optimization, genetic algorithms, and convolutional neural networks. <em>EVOLS</em>, <em>16</em>(3), 1-16. (<a href='https://doi.org/10.1007/s12530-025-09728-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The necessity for advanced methodologies in fruit grading and disease detection is underscored by the increasing demand for food safety and quality in the agricultural sector. Traditional methods often fail to accurately identify and classify diseases due to their inability to handle high-dimensional data and complex feature interactions. This work addresses these limitations by proposing an innovative framework that integrates multiple optimization techniques for enhanced feature selection and disease detection in fruits. The proposed model combines Particle Swarm Optimization (PSO), Genetic Algorithms (GA), Simulated Annealing (SA), and Coot Optimization (CO) for superior feature selection. This amalgamation leverages the unique exploration capabilities of each algorithm, thus facilitating a more comprehensive evaluation of the feature space and enabling the model to overcome local optima and navigate complex feature landscapes more effectively. The integration improves feature selection accuracy by 5–10% and reduce computational time by 10–20% compared to utilizing CO alone. Furthermore, the framework enhances deep learning algorithms for disease detection by integrating Convolutional Neural Networks (CNNs) with attention mechanisms and Quad Long Short-Term Memory networks (QLSTMs) with a Graph-based Generative Adversarial Network (Graph GAN). This integration allows for the effective capture of spatial relationships and temporal dependencies within thermal image datasets, leading to significant improvements in disease detection accuracy and a reduction in false-negative rates. To enhance the robustness and generalizability of the model, an extensive dataset comprising diverse fruit types, disease severities, and environmental conditions has been curated, including thermal sample images that depict various disease stages. This comprehensive dataset ensures that the model is well-equipped to detect both external and internal symptoms of diseases, resulting in an anticipated increase of 10–15% in model accuracy and a reduction of 20–30% in false-positive rates. The impacts of this work are multifaceted, offering significant advancements in the accuracy, efficiency, and applicability of fruit grading and disease detection methodologies. By addressing the limitations of existing techniques and introducing a robust, integrated framework, this research paves the way for safer and more reliable agricultural practices, ultimately contributing to enhanced food safety and quality.},
  archive      = {J_EVOLS},
  author       = {Said, Archana Ganesh and Jawale, Deepali},
  doi          = {10.1007/s12530-025-09728-3},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-16},
  shortjournal = {Evol. Syst.},
  title        = {Design of an iterative method for enhanced disease detection and feature selection using particle swarm optimization, genetic algorithms, and convolutional neural networks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep autoencoder-driven feature learning and meta-heuristic optimized machine learning modelling for crop water stress identification. <em>EVOLS</em>, <em>16</em>(3), 1-19. (<a href='https://doi.org/10.1007/s12530-025-09729-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of water stress in crops is essential for maintaining sustainable, high-quality crop production and minimizing the risk of severe crop losses. The erroneous and subjective nature of human expert-based crop stress identification can be effectively replaced by machine learning (ML) and deep learning models (DL) due to their remarkable ability to perform complex data analysis. The objective of the present study is to develop a framework for the accurate identification of crop water stress using a hybrid DL-ML approach. The study proposes a novel method utilizing the feature representation capabilities of a sparse autoencoder (SAE) to extract latent space features and optimize the ML models (XGB, RF, LGB) using the Bat Algorithm to create a strong predictive model through a soft voting ensemble (SAE-BAT-ENS). The performance of optimized models viz., SAE-BAT-XGB, SAE-BAT-RF, and SAE-BAT-LGB were compared with the state-of-the-art (SOTA) models. Although the SAE-BAT-XGB model showed strong predictive power with an accuracy 97.08%, the soft voting ensemble model, SAE-BAT-ENS, enhanced the performance, by taking the prediction probabilities into account, thus balancing out the weaknesses of individual models. Additionally, the proposed approach was compared with the standard majority voting ensemble (MAJ_VOTE_ENS), and the SAE-BAT-ENS achieved superior results. The proposed approach outperformed the SOTA ML models with an accuracy of 97.81%, precision 98.50%, recall 97.05%, and F1-score 97.77%. The approach employed in the study has shown an increment of 3.94% compared to RF, 3.01% compared to model XGB, and 4.71% compared to LGB model. The study finds applications in developing precision crop water stress management, decision support systems, and mobile applications for automating field crop management.},
  archive      = {J_EVOLS},
  author       = {Subeesh, A. and Chauhan, Naveen and Chandel, Narendra Singh and Rajwade, Yogesh},
  doi          = {10.1007/s12530-025-09729-2},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-19},
  shortjournal = {Evol. Syst.},
  title        = {Deep autoencoder-driven feature learning and meta-heuristic optimized machine learning modelling for crop water stress identification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parameter estimation based IIR system identification using improved arithmetic optimization algorithm. <em>EVOLS</em>, <em>16</em>(3), 1-13. (<a href='https://doi.org/10.1007/s12530-025-09730-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {System identification plays a crucial role in various fields like control systems, communication networks, biomedical signal processing, and many more. Among the different system identification techniques, infinite impulse response (IIR) system offer flexibility in capturing complex dynamics. However, accurately estimating the parameters of an IIR model can be challenging due to its inherent nonlinearity and potential instability. This paper presents a novel method for IIR system identification utilizing an enhanced arithmetic optimization algorithm (IAOA) in order to overcome this problem. The IAOA leverage the strengths of evolutionary computation and numerical optimization techniques to improve the precision and efficacy of the parameter estimation process. By combining concepts from genetic algorithms, particle swarm optimization, and simulated annealing, the proposed algorithm aims to overcome the limitations of traditional optimization methods and provide a more robust and effective solution. The performance of the IAOA is evaluated through comprehensive comparisons and simulations with existing optimization methods on various benchmark IIR system identification problems. The results demonstrate its superiority in terms of parameter estimation and convergence.},
  archive      = {J_EVOLS},
  author       = {Goyal, Deepak and Khanna, Puneet and Singh, Sandeep},
  doi          = {10.1007/s12530-025-09730-9},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-13},
  shortjournal = {Evol. Syst.},
  title        = {Parameter estimation based IIR system identification using improved arithmetic optimization algorithm},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic segmentation and detection of renal cyst using AMS-PAN and RFN-PINN approach based on ultrasound image. <em>EVOLS</em>, <em>16</em>(3), 1-21. (<a href='https://doi.org/10.1007/s12530-025-09731-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cysts are the most common structural injury observed in adult kidneys. Rarely, these are the result of hereditary conditions such as von Hippel Lindau disease, autosomal dominant polycystic kidney disease, and tuberous sclerosis; however, most of the time, cysts are isolated or limited in number and have no known cause. The development of cysts, stones, and tumors causes chronic kidney disorders, which frequently impede renal function. At first, kidney disorders don't exhibit any noticeable signs and are asymptomatic. To avoid renal failure and the loss of kidney function, kidney illnesses must be diagnosed at an earlier stage. In this paper, renal cyst segmentation and classification is performed using AMS-PAN and hybrid RFN-PINN approaches. Renal ultrasound image is provided as a source for this proposed approach. These raw pictures entered are blurred and poor calibre. The supplied image is pre-processed to improve image quality and eliminate noise. Pre-processing techniques such as Dualistic Sub-Image Histogram Equalization and Logical-Pool Recurrent Neural Network are used to improve and reduce noise in images. After processing, the images are input into the Pyramid Attention Network, which uses a combination of attention mechanisms and a segmentation technique based on Multi-Scale features (AMS-PAN) to identify the affected areas of the image. Finally, this segmented images are given to Hybrid ReducedFireNet and Physics Informed Neural Network algorithm based classifier to predict the renal cyst. The proposed algorithm achieves 97% accuracy, 96.7% specificity, and 91.8% NPV. Consequently, our suggested model is the most effective way to divide and categorize renal cyst sickness.},
  archive      = {J_EVOLS},
  author       = {Reddy, Viswanathan Ramasamy and Jasti, V. Durga Prasad and Rajkumar, K. and Kuchipudi, Ramu and Muthukumaran, N.},
  doi          = {10.1007/s12530-025-09731-8},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-21},
  shortjournal = {Evol. Syst.},
  title        = {Automatic segmentation and detection of renal cyst using AMS-PAN and RFN-PINN approach based on ultrasound image},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An overview of tensor and matrix decomposition methods, applied to deep neural networks. <em>EVOLS</em>, <em>16</em>(3), 1-18. (<a href='https://doi.org/10.1007/s12530-025-09733-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are indispensable for feature extraction in various Artificial Intelligence tasks. However, their computational complexity and memory requirements pose significant challenges. To address these issues, there is a growing need for CNN simplification techniques. One promising approach involves compressing the weight matrices of fully connected layers and the tensors of convolutional layers using several decompositions into matrix products. To this end we investigate the effectiveness of several relevant techniques and their impact on the achieved accuracy, applying the techniques on already trained networks, or during their training, when applicable.},
  archive      = {J_EVOLS},
  author       = {Vorgiazidou, Eleftheria and Delibasis, Konstantinos and Maglogiannis, Ilias},
  doi          = {10.1007/s12530-025-09733-6},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-18},
  shortjournal = {Evol. Syst.},
  title        = {An overview of tensor and matrix decomposition methods, applied to deep neural networks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Indoor fire danger tracking method with fusion of image difference and smart optimization. <em>EVOLS</em>, <em>16</em>(3), 1-15. (<a href='https://doi.org/10.1007/s12530-025-09734-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To realize accurate and fast fire danger tracking in complex application scenes, a fusion method with aid of image gray value difference technique and Moth-flame optimization algorithm is developed. The method has two advantages. First, with this method, the critical image gray value difference can be employed to capture the dynamic characteristics of flames, thereby enhancing accuracy. It can overcome the interferences of complex fire scenes with many similar flame colors and provide a stable video-based fire tracking result. The method can successfully predict all our test cases with 100% prediction precision. Second, the method does not need prior data training. It can achieve fire danger tracking solely by relying on the currently monitored frame image within 11 s. These advantages make the method significantly superior to traditional data-driven methods in terms of calculation accuracy and efficiency, especially for small flames whose area occupies less than 0.1% of the image. Traditional data-driven methods usually require hours of training and exhibit a low detection rate in such scenarios. Three numerical cases are implemented to validate the method. The results indicate that the method can successfully distinguish the fire danger zone from areas with similar flame colors in the monitored video, and even small flames in the early stage of a fire can also be tracked based on the method. Moreover, when compared with previous fire detection methods, the proposed method demonstrates significantly higher fire tracking accuracy. This advancement offers a critical technical solution for achieving fast and precise fire tracking in real-world applications.},
  archive      = {J_EVOLS},
  author       = {Sun, Bin},
  doi          = {10.1007/s12530-025-09734-5},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-15},
  shortjournal = {Evol. Syst.},
  title        = {Indoor fire danger tracking method with fusion of image difference and smart optimization},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual attention-based hybrid deep learning framework for short text classification. <em>EVOLS</em>, <em>16</em>(3), 1-12. (<a href='https://doi.org/10.1007/s12530-025-09735-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In digital communication, persistent spam poses significant risks to user privacy and security. Classifying short texts (e.g., SMS, tweets) is challenging due to their brevity, ambiguity, and lack of contextual depth. To address this, we propose a novel dual-attention-based hybrid deep learning framework that synergistically integrates Convolutional Neural Networks (CNN) and Bidirectional Long Short-Term Memory Networks (BiLSTM). The CNN branch employs location-based attention to highlight spatially significant features. In contrast, the BiLSTM branch uses co-attention to model sequential relationships, enabling comprehensive feature extraction from sparse, noisy short texts. The fused features are classified through an optimized, fully connected layer, achieving state-of-the-art accuracy of 99.74% (SMS) and 99.36% (Twitter) while maintaining computational efficiency (12ms latency, 8.5G FLOPs). Our model’s parallel architecture and attention mechanisms uniquely balance accuracy and deployability, outperforming transformers (e.g., BERT) with 10 × fewer computational resources. This work advances spam detection by addressing feature sparsity and real-time processing constraints, offering a robust solution for practical applications.},
  archive      = {J_EVOLS},
  author       = {Alkaabi, Hussein Ala’a and Abed, Russul Hazim},
  doi          = {10.1007/s12530-025-09735-4},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-12},
  shortjournal = {Evol. Syst.},
  title        = {Dual attention-based hybrid deep learning framework for short text classification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating U-net variants for satellite image object detection: Towards an ensemble method and performance evaluation. <em>EVOLS</em>, <em>16</em>(3), 1-20. (<a href='https://doi.org/10.1007/s12530-025-09736-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current era, object detection from satellite images has become essential in various applications, from environmental surveillance to urban development. U-Net, one of the popular encoder-decoder architectures, has proven to be a strong performer in segmentation tasks. Different U-Net variants, such as the baseline U-Net, Attention U-Net, and Attention Res-UNet (Attention Deep Residual U-Net), offer architectural innovations that yield higher segmentation accuracy in specific contexts. This research presents an ensemble approach that combines the benefits of various U-Net models to refine overall segmentation quality. U-Net variants are comprehensively explored for segmentation on satellite images, emphasising how they perform in the semantic segmentation of an aerial images dataset. Interestingly, the ensemble model outperforms single models considering IoU and dice score, delivering a staggering IoU of 93.2 percent, 90 percent pixel accuracy, and a dice score of 94.1 percent, accentuating its outstanding performance. The findings indicate the potential of the suggested ensemble method, that integrates complementary U-Net architectures to deliver state-of-the-art results in satellite image analysis.},
  archive      = {J_EVOLS},
  author       = {Malik, Sunesh and Nandal, Priyanka and Pahal, Sudesh and Parikh, Jolly and Jain, Rachna},
  doi          = {10.1007/s12530-025-09736-3},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-20},
  shortjournal = {Evol. Syst.},
  title        = {Investigating U-net variants for satellite image object detection: Towards an ensemble method and performance evaluation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic design of CNN architecture based on genetic algorithm and particle swarm optimization. <em>EVOLS</em>, <em>16</em>(3), 1-19. (<a href='https://doi.org/10.1007/s12530-025-09738-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are indispensable in computer vision, especially for image classification, but designing optimal CNN architectures is challenging and often requires extensive domain-specific knowledge. This paper presents a novel method that combines genetic algorithms (GAs) and particle swarm optimization (PSO) to automate CNN architecture design. The proposed algorithm integrates the global search capability of GAs with the local optimization efficiency of PSO, effectively addressing the limitations of each. Tested on the CIFAR-10 benchmark dataset, the algorithm achieved a classification accuracy of 94.47%, outperforming most existing manually designed and evolutionary algorithm-designed architectures. Statistical analysis confirmed the significance of the improvements. This approach not only enhances the accuracy of CNN architectures but also demonstrates the potential of hybrid metaheuristic algorithms in automated design, making it more accessible for researchers across various fields.},
  archive      = {J_EVOLS},
  author       = {Lin, Shuaifei and Zhang, Wei and Xu, Nannan and Liu, Xueli and Wu, Jianfeng},
  doi          = {10.1007/s12530-025-09738-1},
  journal      = {Evolving Systems},
  month        = {9},
  number       = {3},
  pages        = {1-19},
  shortjournal = {Evol. Syst.},
  title        = {Automatic design of CNN architecture based on genetic algorithm and particle swarm optimization},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-overlapping spectrum resources: Enhancing video quality transmission with FDR-CK algorithm. <em>EVOLS</em>, <em>16</em>(2), 1-14. (<a href='https://doi.org/10.1007/s12530-024-09653-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to advancement of technology the multimedia is determined as a better progressive development that is applied in various domains. However, the video communication through network is enhanced in the modern world and the main purpose is to enhance the quality. But while transmitting video in network it distracted the network due to over fitting as well as congestion problem. In order to perform the video quality transmission in a network the effective resources are allocated individually to overcome the overlapping issues. Therefore, this article proposes a novel Federated Deep Reinforcement based Crossover Kepler (FDR-CK) Algorithm to enhance the video transmission quality in communication network. The implementation of time-frequency resources helps in solving the requirements of a single-frequency network. In the proposed FDR-CK, the allocated transmitted data uses spectrum resources that exhibit the non-overlapping in which they are determined in the same frequency. The effectiveness of the allocated resources is highlighted by enhancing the efficiency of FDR-CK algorithm and minimizing the co-frequency interference. This enhancement in resource allocation using proposed FDR-CK approach attained optimal solutions in video quality transmission. The effectiveness of the proposed FDR-CK is analyzed by evaluating various metrics such as diversity Gain, throughput, Bit error rate, Signal-to-noise ratio, End-to-end-delay, Packet Delivery ratio, and channel Capacity for the proposed approach with various state of art techniques. The maximum transmission rate with better quality and this is satisfied by the proposed FDR-CK method by achieving 3.2 bits/Htz.},
  archive      = {J_EVOLS},
  author       = {Srinivasan, Karthik and Matheswaran, Saravanan and Sengodan, Prabaharan and Pichamuthu, Rajaram},
  doi          = {10.1007/s12530-024-09653-x},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Evol. Syst.},
  title        = {Non-overlapping spectrum resources: Enhancing video quality transmission with FDR-CK algorithm},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing object detection performance: Random replacement one–one optimized convolutional LeNet algorithm with novel strategies for improved efficiency. <em>EVOLS</em>, <em>16</em>(2), 1-26. (<a href='https://doi.org/10.1007/s12530-025-09655-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, computer vision has become indispensable, particularly in advancing object detection and recognition capabilities. Identifying specific objects amidst a complex scene remains a critical challenge. To address this, computer vision methodologies must optimize detection and recognition while managing trade-offs effectively. This study introduces the random replacement one–one optimized convolutional LeNet algorithm (ConvLeNet-RROO) to improve the efficiency and overall performance of object detection systems. ConvLeNet-RROO innovatively incorporates a random replacement strategy during training, selectively replacing weights or neurons to mitigate local minima and accelerate convergence. Moreover, the algorithm integrates one-to-one optimized convolutional layers, which significantly reduce computational complexity without compromising accuracy. Extensive experiments conducted on diverse object detection datasets, including the Indian vehicle dataset, cars detection dataset, vehicle detection dataset, BIT-vehicle dataset, and urban vehicle dataset, illustrate that ConvLeNet-RROO surpasses traditional LeNet and other existing models in detection performance. The integration of optimal curves and a novel random substitution strategy improves performance in object detection by enhancing the ability of a model to accurately detect objects in various conditions. Performance evaluation of ConvLeNet-RROO involves comprehensive analysis using several major performance metrics including accuracy, precision, false positive rate, and false negative rate, demonstrating its superior performance compared to all other existing methods. Experimental results validate the model's exceptional accuracy (99.5%), recall (96.9%), precision (98.4%), F1-measure (97.7%), low false positive rate (0.147), and false negative rate (0.028), highlighting its efficacy in advancing object detection capabilities.},
  archive      = {J_EVOLS},
  author       = {Alsowail, Rakan A. and Al-Shehari, Taher},
  doi          = {10.1007/s12530-025-09655-3},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-26},
  shortjournal = {Evol. Syst.},
  title        = {Advancing object detection performance: Random replacement one–one optimized convolutional LeNet algorithm with novel strategies for improved efficiency},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cyberbullying detection and classification on social media images using convolution neural networks and CB-YOLO model. <em>EVOLS</em>, <em>16</em>(2), 1-19. (<a href='https://doi.org/10.1007/s12530-025-09656-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many positives to using social media like Facebook, Instagram, and Twitter, but there are also many drawbacks. Cyberbullying (CB) is a problem that has arisen on these networks. The effects of cyberbullying on victims are difficult to quantify because responses vary widely depending on the individual. It is extremely difficult to identify bullying content in cyber messaging due to the vague nature of these communications. Reports of studies that use textual posts to tackle this problem have surfaced. However, less focus has been placed on detecting cyberbullying based on images. In this research, we discuss the findings of a comprehensive investigation of the dense region objects of cyberbullying images. Finding a well-suited model for the detection and classification of Cyberbullying images is a challenging problem. The primary objective of this work is to create a lightweight deep-learning model to combat the problem of cyberbullying using images on social media. In this work, initially, we designed a deep learning-based system trained on the 2-Dimensional Convolutional Neural Network (CB-2DCNN) to identify instances of cyberbullying images. Thereafter, we proposed and built Cyberbullying model based on You Only Look Once (CB-YOLO) is a soft prediction residual network model to effectively identify and detect cyberbullying in social media images with high accuracy, precision, recall, and f-score.},
  archive      = {J_EVOLS},
  author       = {Pericherla, Subbaraju and Ilavarasan, E.},
  doi          = {10.1007/s12530-025-09656-2},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Evol. Syst.},
  title        = {Cyberbullying detection and classification on social media images using convolution neural networks and CB-YOLO model},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized deep learning approach for automated fault diagnosis in mobile robot used for fire-fighting application. <em>EVOLS</em>, <em>16</em>(2), 1-17. (<a href='https://doi.org/10.1007/s12530-025-09658-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots are mechanical devices with human-like appearances that carry out difficult jobs. Mobile platforms can expand the workspace compared to fixed-based robots, whose capacity is constrained, and it is used in various applications. Firefighting robots are essential for switching off fire without human presence, and it is mostly placed in ruthless environments where they are consistently vulnerable to many faults. If a fault is not diagnosed in time, it can cause unexpected downtime and even catastrophic damage to the machinery. However, some existing algorithms, such as You Only Look Once, Version 3 (Yolov3), STMicroelectronics32 (STM32), and Haar Cascade Classifier, are used for fault detection, but their accuracy is limited when detecting multiple faults. In order to solve this problem, a deep learning-based LSTM model was used to improve fault detection accuracy in mobile robots. Initially, a fire detection system for a mobile robot platform was developed using smoke, flame, and temperature sensors. The system used relays, 1n5822 diodes, an IRF3205 power Metal Oxide Semiconductor Field Effect Transistor (MOSFET), capacitance, and ULN 2003 type relay drivers for defect detection. During simulations, the fault detection model collects data from the sensors. Then, the acquired data is sent for pre-processing using Min–Max normalization to normalize the data within the particular range. Then, the pre-processed data is fed into Optimized Long Short-Term Memory (O-LSTM) to diagnose fault in robotic sensors. Bald eagle search (BES) optimization is utilized in the created sources to determine the learning rate, number of hidden layers, and node in order to reduce error for enhancing deep learning prediction accuracy. Performance indicators for proposed and existing models are compared in order to assess the planned model’s performance. Performance metrics such as accuracy, recall, specificity, and precision attained for the proposed model is 97%, 90%, 95%, and 97%. Through this proposed O-LSTM model occurrence of fault in firefighting mobile robots can be detected more effectively.},
  archive      = {J_EVOLS},
  author       = {Pandian, D. Satheesh},
  doi          = {10.1007/s12530-025-09658-0},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Evol. Syst.},
  title        = {Optimized deep learning approach for automated fault diagnosis in mobile robot used for fire-fighting application},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gradual task complexity scaling (GTCS-DRL): A deep reinforcement learning approach for training automated guided vehicle system. <em>EVOLS</em>, <em>16</em>(2), 1-14. (<a href='https://doi.org/10.1007/s12530-025-09660-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of Automated Guided Vehicle (AGV) systems, training Deep Reinforcement Learning (DRL) models presents significant challenges due to the complexity of tasks and environments, as well as the large state and action spaces involved. This paper introduces the Gradual Task Complexity Scaling (GTCS) approach, a novel learning procedure for DRL that effectively addresses these challenges. Unlike existing methods, which focus on directly achieving the final objective, GTCS incrementally upgrades the agent’s objectives while maintaining the same environmental context, enabling a more efficient balance between exploration and exploitation during training. The GTCS procedure features four key components: gradually expanding the reduced effective space size within the warehouse, increasing the number of products the agent must deliver, enhancing the capabilities of AGVs represented as DRL agents, and reducing the maximum number of steps allowed for task completion. GTCS outperforms previous approaches by improving the stability of the learning process, optimizing the delivery workflow, and achieving more efficient learning outcomes.},
  archive      = {J_EVOLS},
  author       = {Rhazzaf, Mohamed and Masrour, Tawfik},
  doi          = {10.1007/s12530-025-09660-6},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Evol. Syst.},
  title        = {Gradual task complexity scaling (GTCS-DRL): A deep reinforcement learning approach for training automated guided vehicle system},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image restoration based on SimAM attention mechanism and constraint adversarial network. <em>EVOLS</em>, <em>16</em>(2), 1-20. (<a href='https://doi.org/10.1007/s12530-025-09663-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration has important application value in the fields of old photo recovery, object removal, video editing, etc. Traditional image restoration methods The existing image restoration methods use the single resolution image as the network input for image feature extraction, and cannot fully use of the different features of images with different resolution rates for image restoration, resulting in poor restoration of image texture details and even artifacts. In order to improve the restoration effect, an image restoration algorithm based on the SimAM attention mechanism and constrained adversarial network is proposed. Firstly, a low-resolution image generation module is designed, which uses the encoding and decoding structure to generate the global structure information of multiple low-resolution input images. Then, a SimAM attention feature fusion module is constructed, and the low-resolution image generation results are fused with the fine-grained features contained in the high-resolution input missing images to help complete the high-resolution images. A parameter-free SimAM attention mechanism is introduced to infer the three-dimensional attention weight of feature maps by considering the correlation between spatial and channel dimensions, to characterize locally significant features and suppress useless features, and to improve the effectiveness of target region information. Finally, an improved multi-scale adversarial loss function is proposed. The function guarantees the quality and authenticity of the discriminator image at different scales by constraining the local fineness of the generated image and the consistency of the repaired image on the high-level structure. The experimental results show that on the Paris StreetView, CelebA and Places2 data sets, aiming at three different image damage rates, the experiment is conducted based on three quantitative evaluation indexes including SSIM, PSNR and L1. The results show that the proposed method can generate more reliable local details and improve the effect of image restoration.},
  archive      = {J_EVOLS},
  author       = {Bao, Hang and Qi, Xin},
  doi          = {10.1007/s12530-025-09663-3},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-20},
  shortjournal = {Evol. Syst.},
  title        = {Image restoration based on SimAM attention mechanism and constraint adversarial network},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EdmABC: An improved artificial bee colony algorithm on detecting breast cancer for mammography images. <em>EVOLS</em>, <em>16</em>(2), 1-31. (<a href='https://doi.org/10.1007/s12530-025-09666-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in computer vision and machine learning have continually driven the evolution of image processing technologies, providing opportunities to enhance our ability to analyze and interpret digital images. This paper presents a specialized approach named “Edge Detection of Mammography using improved Artificial Bee Colony” (edmABC), for edge detection and analysis of mammography images for the detection of breast cancer inspired by the foraging behavior of honeybees. This study has harnessed the Artificial Bee Colony (ABC) algorithm to identify and emphasize boundaries within mammography images. The primary goal is to enhance image edge detection of mammography images, which is crucial in facilitating clinical analysis and subsequent diagnosis by healthcare professionals. The proposed approach combines local search, information sharing, and exploration–exploitation of the ABC algorithm to identify potential edge points based on fitness values and improve edge accuracy. For this aim, this study has introduced opposition-based learning and chaotic systems into the population initialization stage, extracted grayscale values, and applied statistical estimation to further improve the final solutions of the proposed algorithm. The findings demonstrate that the edmABC method outperforms several standard edge detection techniques such as Canny, Prewitt, and Sobel. Combining the ABC algorithm alongside grayscale values and statistical estimation has impacted the results significantly. Therefore, this study positions edmABC as a promising solution for enhancing mammography image analysis.},
  archive      = {J_EVOLS},
  author       = {Tawil, Mohamed Al and Dakkak, Omar},
  doi          = {10.1007/s12530-025-09666-0},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-31},
  shortjournal = {Evol. Syst.},
  title        = {EdmABC: An improved artificial bee colony algorithm on detecting breast cancer for mammography images},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FTN-ResNet50: Flexible transformer network model with ResNet50 for road crack detection. <em>EVOLS</em>, <em>16</em>(2), 1-15. (<a href='https://doi.org/10.1007/s12530-025-09667-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crack detection is an important prerequisite for evaluating the degree of road damage. Accurate and efficient extraction of pavement crack information from pavement images is the key to the assessment of road technical condition and maintenance condition. The traditional methods (edge detection, morphological method etc.,) are not effective in pavement crack segmentation, the precision of crack contour segmentation is not enough, it is difficult to identify narrow cracks, and the segmentation accuracy is low. Therefore, this paper proposes a novel flexible Transformer network model with ResNet50 for road crack detection. Firstly, a flexible gate is introduced into the self-attention module to select important areas of concern, and a sparse self-attention mechanism from local to global is designed to reduce the computing load and enhance the multi-scale generalization ability of the model. ResNet50 is used as the backbone network to extract pavement crack characteristics. A feature fusion module based on attention mechanism is designed to improve jump connection in ResNet50. Finally, a feature thinning head is added to the decoding part to get an improved model. The experimental results on the pavement crack open data set show that the proposed method can effectively improve the recall rate and accuracy, and has good adaptability to different pavement crack image detection. The accuracy of the proposed method is more than 69%, which is a great improvement compared with most other algorithms. However, very few experimental parameters are required, which aids the computational efficiency.},
  archive      = {J_EVOLS},
  author       = {Lin, Yadang and Yu, Tao and Lin, Zhenzhen},
  doi          = {10.1007/s12530-025-09667-z},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Evol. Syst.},
  title        = {FTN-ResNet50: Flexible transformer network model with ResNet50 for road crack detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep neural network parameter tuning using harmony search for a realistic flexible job shop scheduling. <em>EVOLS</em>, <em>16</em>(2), 1-17. (<a href='https://doi.org/10.1007/s12530-025-09668-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are a robust and versatile machine learning technique that offers a wide range of applications across various domains. They constitute effective and approximate models that can replace realistic models. However, designing, training, and refining the model poses a significant challenge to achieve the desired outcome. To address this challenge, metaheuristics are employed for DNN structure optimization to improve their accuracy and efficiency. The present work proposes a Harmony Search Optimization (HSO) technique to find the best DNN configuration to approximate a realistic FJSSP by considering makespan as a scheduling objective function. Different DNN hyper-parameters are adjusted according to the accuracy of the solutions, including the number of neurons in each hidden layer, activation functions for both hidden and output layers, and learning rate and momentum. A comparative study is investigated to analyze and evaluate DNN performances, considering three optimization objectives when evaluating validation data: minimizing the occurrence of low-precision solutions (PS), minimizing Mean Absolute Percentage Error (MAPE) value, and minimizing the upper-bound value of Relative Errors (Max REs) between DNN-predicted makespan values and their corresponding real values in the validation set. The results obtained during the application of DNN to a case study representing FJSSP demonstrate the effectiveness, high accuracy, and fast responsiveness of the models. The three metrics evaluations provide DNN models with excellent computation time (more than 99% time saving compared to the simulation model). However, in terms of predicting DNN outcomes for all proposed production runs, the DNN model resulting from the Max REs evaluation presents a relative error of 2.22% or less, outpacing the other two assessments: PS (≤ 3.04%) and MAPE (≤ 4.04%). In addition, it presents compact solutions, and the outliers do not exceed a relative error of 27.24%. This assessment offers a viable solution to attain more accurate DNN predictions, effectively addressing future approximation challenges.},
  archive      = {J_EVOLS},
  author       = {Mihoubi, Bachir},
  doi          = {10.1007/s12530-025-09668-y},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Evol. Syst.},
  title        = {Deep neural network parameter tuning using harmony search for a realistic flexible job shop scheduling},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural temporal code-driven stimulation in real-time using the Victor–Purpura distance. <em>EVOLS</em>, <em>16</em>(2), 1-15. (<a href='https://doi.org/10.1007/s12530-025-09670-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous neural systems encode information through the generation of specific sequences of action potentials, creating temporal activity patterns that form neural codes. These systems produce functionally equivalent activity patterns, albeit with some variability in their temporal structure. In this work, we have implemented a real-time closed-loop stimulation protocol to study temporal coding in neural systems. The protocol identifies codes in neural signals acquired in real-time and delivers a stimulus when a predefined code is identified allowing a degree of variability in the detection through the use of the Victor–Purpura metric. The goal of the stimulation is to induce a new state in the system and to study the equivalence between codes with intrinsic variability. The real-time performance of the protocol was validated in closed-loop experiments with an electronic neuron by characterizing the latencies. Moreover, its functionality was corroborated through two proof of concept scenarios where we modulated the activity of a neural model to induce a new dynamic state. In the first scenario, when tested in a regular bursting model state with Gaussian stochastic inputs to induce temporal variability, our protocol robustly generated short bursts amidst consecutive bursts produced by the model without stimulation. In the second scenario, tested in an operating chaotic model state, the protocol drove the model to show regular bursting activity. The findings indicated that the dynamic state was consistently induced by closed-loop stimulation in contrast to the less effective open-loop stimulation, i.e., without precise activity-dependent stimulation of the system. The reproducibility of these results in both test scenarios is supported by the statistical analysis carried out. This protocol allows inferring of equivalence between different matching patterns when closed-loop stimulation, driven by these patterns, elicits comparable responses. This new real-time protocol implementation is available as open-source software.},
  archive      = {J_EVOLS},
  author       = {Ayala, Alberto and Lareo, Angel and Varona, Pablo and Rodriguez, Francisco B.},
  doi          = {10.1007/s12530-025-09670-4},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Evol. Syst.},
  title        = {Neural temporal code-driven stimulation in real-time using the Victor–Purpura distance},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive data augmentation for salient sentence identification in indian judicial decisions. <em>EVOLS</em>, <em>16</em>(2), 1-13. (<a href='https://doi.org/10.1007/s12530-025-09671-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying salient sentences in long judicial decisions is a major challenge in legal document understanding. This process is time-consuming and difficult even for legal experts. In countries like India, where the common law system is heavily based on past cases, quickly recognizing key sentences is important for rapid resolution of cases. The emergence of deep learning models for language processing tasks can help legal professionals make faster and more informed decisions. However, using these models to automate saliency detection requires annotated data for training and evaluation, which is costly and requires trained legal professionals. Here we introduce the task of saliency detection in Indian judicial decisions, along with the curation of a concise gold standard dataset tailored to this task. An adaptive data augmentation strategy is introduced to address the scarcity of labeled data. This strategy dynamically adjusts the amount of augmentation applied to training samples based on the model’s current classification performance on the validation set. By monitoring performance at different levels, the augmentation process can be fine-tuned, allowing model training to be stopped with the optimal augmented dataset. Legal experts provide a list of protected terms to ensure that specific legal terms remain unchanged during the augmentation process. The methodology focuses on training a deep learning-based Convolutional Bidirectional LSTM model, evaluating the performance with and without augmentation, and conducting a comparative analysis against fine-tuned transformer models used as baselines. The results demonstrate improvements in model performance while preserving protected terms and carefully managing augmentation levels. Additionally, the trained deep learning models on the augmented set proved to be more resource-efficient compared to fine-tuned models.},
  archive      = {J_EVOLS},
  author       = {Sheik, Reshma and Nair, Krishnadas and Krishna, S. K. Manu and Nirmala, S. Jaya},
  doi          = {10.1007/s12530-025-09671-3},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-13},
  shortjournal = {Evol. Syst.},
  title        = {Adaptive data augmentation for salient sentence identification in indian judicial decisions},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The auto-correlation enhanced transformer for information diffusion prediction in social networks. <em>EVOLS</em>, <em>16</em>(2), 1-14. (<a href='https://doi.org/10.1007/s12530-025-09672-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information diffusion prediction aims to analyze the patterns of information propagation in social media to understand and forecast the process of information dissemination. Previous Transformer-based methods are usually limited to dynamic short cascades and do not combine temporal and structural information effectively. Additionally, the self-attention mechanism in Transformers cannot capture the periodic dependencies of sub-sequences, thereby reducing prediction precision. To address the above issues, we propose a dynamic heterogeneous social network information diffusion prediction model called Auto-Correlation Enhanced Transformer (ACET). First, we construct a heterogeneous graph composed of a social network graph and a dynamic diffusion graph to learn users’ structural characteristics. We also construct a user co-occurrence graph based on the information diffusion sequence, leading to more accurate user embeddings. Next, to discover the dependencies at the sub-sequences level and reduce computational complexity, we replace self-attention in Transformer with the auto-correlation mechanism resulting in improved prediction accuracy of the model. Finally, for the effective fusion of user similarity, temporal features, and structural features, a novel residual fusion method is proposed to replace the original one in Transformer. Experimental results show that the performance of ACET on three public datasets is all improved. Specially, the Map@k and Hits@k on Douban dataset are improved by an average of 22.95% and 15.88%, respectively.},
  archive      = {J_EVOLS},
  author       = {Du, Yuxuan and Lu, Jing},
  doi          = {10.1007/s12530-025-09672-2},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Evol. Syst.},
  title        = {The auto-correlation enhanced transformer for information diffusion prediction in social networks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating sparse graph convolution and capsule networks for superior breast cancer diagnosis. <em>EVOLS</em>, <em>16</em>(2), 1-18. (<a href='https://doi.org/10.1007/s12530-025-09673-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer (BC) is a preliminary effect of breast tissues that leads to the premature death of women in worldwide. Accurate and automatic detection is complex in the field of medical image processing. In this paper, a novel deep learning-related approach is proposed named as Deep Residual Caps Network (DRCN) to detect BC. Here, different sources such as the Breast Histopathology Images dataset, Breast Cancer Histopathological (BreakHis) dataset and BACH-ICAR-2018 dataset are used to collect the histopathological (HP) images. The gathered HP images are preprocessed by using different kinds of preprocessing and segmentation approaches for enhancing diversity, reducing overfitting issues and minimizing class imbalance issues. The detection task is performed by combining Sparse Graph Convolution Residual Network (SGCResNet) and Shared Capsule Network (SCapsNet) modules. The SGCResNet module is used to learn the features for generating high-quality features by enhancing the generalization ability of the model. After that, the SCapsNet module is applied to mimic the hierarchical relationships of the model during BC detection. To enhance the operation speed of the model, the Capsule Filter Routing (CFR) is implemented which helps to filter capsules according to its activation values. The experiments are used to find the superior performance of the proposed model through different analyses such as comparison study, visual representation and numerical evaluation with diverse measures. The results showed that the proposed model achieved better performances of 98.82% and 0.94 from detection accuracy and Mathew’s Correlation Coefficient (MCC) compared to other methods.},
  archive      = {J_EVOLS},
  author       = {Bala, P. Manju and Palani, U.},
  doi          = {10.1007/s12530-025-09673-1},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Evol. Syst.},
  title        = {Integrating sparse graph convolution and capsule networks for superior breast cancer diagnosis},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EFCMG: An evolving fuzzy classifier with participatory learning and multivariable gaussian for data stream. <em>EVOLS</em>, <em>16</em>(2), 1-22. (<a href='https://doi.org/10.1007/s12530-025-09674-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel evolving fuzzy classifier that begins with no initial structure and develops incrementally through a participatory learning-based clustering algorithm. It employs multivariable Gaussian membership functions for rule antecedents and class outputs for consequents. The classifier’s learning algorithm is designed to adjust dynamically by creating, merging, deleting, and updating clusters and rules. Uniquely, it features a ‘procrastination’ approach where clusters are initially formed in a disabled state to robustly manage outliers and ensure only representative data influence the model. Clusters are refined based on compatibility measures using the Mahalanobis distance, with adjustments to learning rates influenced by the nature of incoming data-slowing for anomalies and accelerating for typical inputs. This mechanism enhances adaptability and model accuracy, distinguishing it from existing fuzzy classifiers. Comparative analyses on binary and multiclass tasks demonstrate superior or competitive performance, underscoring the classifier’s innovative approach to evolving fuzzy classification.},
  archive      = {J_EVOLS},
  author       = {Rodrigues, Sávio and da Silva, Alisson Marques and Campos Souza, Paulo Vitor},
  doi          = {10.1007/s12530-025-09674-0},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Evol. Syst.},
  title        = {EFCMG: An evolving fuzzy classifier with participatory learning and multivariable gaussian for data stream},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 6G digital twin and CPS system promote the development of rural architectural planning. <em>EVOLS</em>, <em>16</em>(2), 1-19. (<a href='https://doi.org/10.1007/s12530-025-09675-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating digital twins (DT) into 6G networks presents substantial prospects for improving federated learning (FL). Within this framework, we provide Digital Twin-Assisted Semi-Supervised Autoencoder-based Robust Network (DASSARN), a new method specifically developed to tackle the difficulties associated with FL in 6G systems. DASSARN utilizes data transfer-enabled FL to address challenges such as update noise and client selection, ultimately optimizing performance. We evaluate the performance of DASSARN by comparing it to well-known FL benchmarks, such as FL with FedAvg, FL with FedSGD, and several forms of self-supervised FL (SSFL). The evaluation is conducted on the MNIST and CIFAR-10 datasets. Our assessment, which includes independent and non-independent data scenarios, shows that DASSARN competes effectively with the top supervised FL methods and outperforms the most advanced semi-supervised FL techniques. This is especially important considering the difficulties in obtaining extensive labeled datasets in real-world applications. DASSARN accomplishes these outcomes by utilizing data augmentation and pseudo-labeling techniques to improve the diversity of client data. The results emphasize the potential of DASSARN to enhance FL in the developing 6G environment, showcasing its capacity to achieve strong performance with limited dependence on labeled data.},
  archive      = {J_EVOLS},
  author       = {Binqing, Zhai and Yicong, Yao and Khishe, Mohammad},
  doi          = {10.1007/s12530-025-09675-z},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Evol. Syst.},
  title        = {6G digital twin and CPS system promote the development of rural architectural planning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: AFLF: A defensive framework to defeat multi-faceted adversarial attacks via attention feature fusion. <em>EVOLS</em>, <em>16</em>(2), 1. (<a href='https://doi.org/10.1007/s12530-025-09676-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EVOLS},
  author       = {Dhamija, Lovi and Bansal, Urvashi},
  doi          = {10.1007/s12530-025-09676-y},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1},
  shortjournal = {Evol. Syst.},
  title        = {Correction: AFLF: A defensive framework to defeat multi-faceted adversarial attacks via attention feature fusion},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: An explainable AI based new deep learning solution for efficient heart disease prediction at early stages. <em>EVOLS</em>, <em>16</em>(2), 1. (<a href='https://doi.org/10.1007/s12530-025-09677-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EVOLS},
  author       = {Ashfaq, Muhammad Talha and Javaid, Nadeem and Alrajeh, Nabil and Ali, Syed Saqib},
  doi          = {10.1007/s12530-025-09677-x},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1},
  shortjournal = {Evol. Syst.},
  title        = {Correction: An explainable AI based new deep learning solution for efficient heart disease prediction at early stages},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-space interaction enhanced particle swarm optimization for tackling high-dimensional problems. <em>EVOLS</em>, <em>16</em>(2), 1-29. (<a href='https://doi.org/10.1007/s12530-025-09678-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary algorithms (SAEAs) are effective for expensive optimization problems but often encounter inefficiencies in high-dimensional spaces. This paper introduces a surrogate-assisted particle swarm optimization with two-space interaction (TSPSO), designed to enhance performance in such environments. The approach divides individuals into potential and non-potential populations, segmenting the search space based on fitness values and constructing surrogate models tailored to each subspace. Throughout the iterative process, optimal solutions identified in the potential space are transferred to the non-potential space, guiding further exploration. This method helps narrow the search space, enabling quicker identification of promising directions and improving convergence rates. To mitigate premature convergence, a L $$\acute{e}$$ vy flight strategy is applied under specific conditions, ensuring diversity in the search process. Experimental results demonstrate that TSPSO performs competitively in high-dimensional optimization tasks.},
  archive      = {J_EVOLS},
  author       = {Wang, Le and Fan, Qinqin and Yan, Xuefeng},
  doi          = {10.1007/s12530-025-09678-w},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-29},
  shortjournal = {Evol. Syst.},
  title        = {Two-space interaction enhanced particle swarm optimization for tackling high-dimensional problems},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A diagnosis and treatment of liver diseases: Integrating batch processing, rule-based event detection and explainable artificial intelligence. <em>EVOLS</em>, <em>16</em>(2), 1-26. (<a href='https://doi.org/10.1007/s12530-025-09679-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liver diseases pose a significant global health burden, impacting many individuals and having substantial economic and social consequences. Rising liver problems are considered a fatal disease in many countries, such as Egypt and Moldova. This study aims to develop a diagnosis and treatment model for liver disease using Basic Formal Ontology (BFO), Patient Clinical Data (PCD) ontology, and detection rules derived from a decision tree algorithm. For the development of the ontology, the National Viral Hepatitis Control Program (NVHCP) guidelines were used, which made the ontology more accurate and reliable. The Apache Jena framework uses batch processing to detect events based on these rules. Based on the event detected, queries can be directly processed using SPARQL. We convert these Decision Tree (DT) and medical guidelines-based rules into Semantic Web Rule Language (SWRL) to operationalize the ontology. Using this SWRL in the ontology to predict different types of liver disease with the help of the Pellet and Drools inference engines in Protege Tools, a total of 615 records were taken from different liver diseases. After inferring the rules, the result can be generated for the patient according to the rules, and other patient-related details, along with different precautionary suggestions, can be obtained based on these results. These rules can make suggestions more accurate with the help of Explainable Artificial Intelligence (XAI) with open API-based suggestions. When the patient has prescribed a medical test, the model accommodates this result using optical character recognition (OCR), and the same process applies when the patient has prescribed a further medical suggestion according to the test report. These models combine to form a comprehensive Decision Support System (DSS) for the diagnosis of liver disease.},
  archive      = {J_EVOLS},
  author       = {Chandra, Ritesh and Tiwari, Sadhana and Rastogi, Satyam and Agarwal, Sonali},
  doi          = {10.1007/s12530-025-09679-9},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-26},
  shortjournal = {Evol. Syst.},
  title        = {A diagnosis and treatment of liver diseases: Integrating batch processing, rule-based event detection and explainable artificial intelligence},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid multi-strategy SCSO algorithm for robot path planning. <em>EVOLS</em>, <em>16</em>(2), 1-27. (<a href='https://doi.org/10.1007/s12530-025-09680-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the problems of low convergence efficiency and the tendency to fall into local extremes in the sand cat swarm optimization algorithm for solving the path planning problem of mobile robots, a hybrid multi-strategy sand cat swarm optimization (HMSCSO) algorithm is proposed. Firstly, a non-linear adjustment strategy is used to increase the convergence accuracy of the algorithm. Then, the logarithmic weight strategy is introduced into the position update to balance the exploration and exploitation ability of the algorithm. Next, the alternate selection strategy is used to improve the algorithm’s ability to jump out of local extremes. Finally, the Lévy flight position update formula is introduced into the algorithm to alleviate the situation where the algorithm falls into stagnation. To verify the effectiveness of the proposed HMSCSO algorithm, 23 benchmark test functions and CEC2022 test functions are selected for comparison with other advanced optimizers. In addition, the HMSCSO algorithm is subjected to ablation experiments in three groups of environments with different obstacles. The experimental results show that after 30 independent experiments, the average path length of the HMSCSO algorithm in path planning is shortened by 23.30%, 2.32%, and 30.20% compared to the original algorithm in three different environments, respectively, with a maximum shortening of 37.73%, 55.75%, and 85.28% compared to other algorithms in the same environments.},
  archive      = {J_EVOLS},
  author       = {Lou, Tai-shan and Yue, Zhe-peng and Chen, Zhi-wu and Qi, Ren-long and Li, Guang},
  doi          = {10.1007/s12530-025-09680-2},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-27},
  shortjournal = {Evol. Syst.},
  title        = {A hybrid multi-strategy SCSO algorithm for robot path planning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lagrange stability of inertial type neural networks: A lyapunov-krasovskii functional approach. <em>EVOLS</em>, <em>16</em>(2), 1-17. (<a href='https://doi.org/10.1007/s12530-025-09681-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper applies Lagrange sense to solve the global exponential stability problem for a class of inertial neural networks with both time-varying delays. The existence of time-varying delays in discrete and distributed terms is investigated using lower and upper bounds. First, we convert the proposed inertial neural networks into regular ones. Second, new brand Lyapunov-Krasovskii functionals, stability theory, and integral inequality are used to develop a number of novel required conditions for the stability of the neural networks under discussion using linear matrix inequalities. The LMI control toolbox in MATLAB software allows for easy testing in real-world circumstances. Several comparisons are made between the planned study and several current literatures in an attempt to further minimize conservatism. Finally, three numerical examples are shown to demonstrate the advantages and superiority of our theoretical results.},
  archive      = {J_EVOLS},
  author       = {Maharajan, C. and Sowmiya, C. and Xu, Changjin},
  doi          = {10.1007/s12530-025-09681-1},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Evol. Syst.},
  title        = {Lagrange stability of inertial type neural networks: A lyapunov-krasovskii functional approach},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ETC-net: An efficient collaborative transformer and convolutional network combining edge constraints for medical image segmentation. <em>EVOLS</em>, <em>16</em>(2), 1-20. (<a href='https://doi.org/10.1007/s12530-025-09682-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation is a fundamental task in auxiliary diagnostic medical endeavors. In the domain of medical image segmentation, the U-Net network, combined with the Transformer architecture, has emerged as the dominant model. Its strength lies in its ability to effectively integrate both local and global contextual information. This integration significantly improves the overall efficacy of medical image segmentation. However, there are still some challenges in comprehensive modeling of global and local features with the combination of transformer and U-Net: 1) due to the discrete nature of the combination, it is difficult to balance the importance of global and local features; 2) deeper feature encoding leads to the neglect of target edge details, resulting in blurry segmentation boundaries. To solve the above problems, we propose a feature collaborative medical image segmentation network called ETC-Net (Efficient Transformer with Convolutional Network that combines edge constraints). Firstly, the Convolutional Neural Network and Transformer branches are added in parallel to the full convolutional attention-based U-Net model to extract global and local features, respectively. This is beneficial for exploring different features and retain the important information. The significance module is then designed to additionally supervise the prediction of the target edges to compensate for the information lost at the target edges, thus improving the model’s ability to learn detailed features. Experiments conducted on cardiac images, pathological images, and H&E stained tissue image datasets demonstrate the model’s effectiveness, with Dice scores of 93.48, 91.44, and 79.29%, respectively, which are superior to compared models. The source code will be made available at https://github.com/shilong1202/ETC-Net .},
  archive      = {J_EVOLS},
  author       = {Dang, Lanxue and Li, Shilong and Zhang, Wenwen and Hou, Yan-e and Liu, Yang},
  doi          = {10.1007/s12530-025-09682-0},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-20},
  shortjournal = {Evol. Syst.},
  title        = {ETC-net: An efficient collaborative transformer and convolutional network combining edge constraints for medical image segmentation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A boosted sine cosine algorithm with dimension learning-based search and terminal replacement mechanism for optimization and engineering applications. <em>EVOLS</em>, <em>16</em>(2), 1-38. (<a href='https://doi.org/10.1007/s12530-025-09683-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sine cosine algorithm (SCA) is a well-known stochastic optimizer that uses the oscillation characteristic and periodicity of the sine–cosine mathematical model to construct operators to accomplish the search objective iteratively with the merit of a simple structure and easy to understand. However, SCA possesses several limitations, such as low convergence velocity and accuracy, as well as trapping into local stagnation. To overcome these difficulties, this paper combines three mechanisms, namely greedy selection (GS), dimension learning-based hunting (DLH), and terminal replacement mechanism (TRM), to propose a boosted SCA, named GDTSCA. In this research, the GS strategy plays a role in reducing the implementation of invalid position updates by individuals and facilitating individuals to search in a better direction, which enhances the convergence rate and precision of GDTSCA. The DLH strategy uses different methods to build a neighborhood for each searching individual to accomplish information sharing among the individuals. The strategy can mitigate the problem of diversity reduction of searching individuals and boost the global search. The TRM strategy takes the neighbors of the best individual to update the worst individual to keep the individual from falling into local stagnation. To scientifically analyze and verify the performance of GDTSCA, this paper conducts experiments based on the CEC2017 test suite. First, the proposed algorithm is analyzed for the impact of different strategies. Then, this paper studies the search history and balance diversity of GDTSCA utilizing qualitative analysis. Next, to evaluate the ability of GDTSCA, it is compared with nine original meta-heuristics, seven SCA variants, and six other advanced algorithms. The results show that GDTSCA exhibits a stronger optimization effect than the optimizers utilized in most benchmark functions. Finally, the performance of GDTSCA for optimization in real scenarios is explored based on three well-known engineering design tasks. The outcomes show that the optimization ability of GDTSCA is superior to that of many well-known algorithms utilized in the experiment.},
  archive      = {J_EVOLS},
  author       = {Huang, Wei and Chen, Huiling and Heidari, Ali Asghar and Xu, Hupeng and Zhang, Qian and Lin, Yaoyao},
  doi          = {10.1007/s12530-025-09683-z},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-38},
  shortjournal = {Evol. Syst.},
  title        = {A boosted sine cosine algorithm with dimension learning-based search and terminal replacement mechanism for optimization and engineering applications},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal fusion and vision transformers for robust early AMD prediction. <em>EVOLS</em>, <em>16</em>(2), 1-22. (<a href='https://doi.org/10.1007/s12530-025-09684-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Age-related macular degeneration is a chronic disease affecting a central area of the retina. Accurate disease identification aids in slowing down the progression of age-related macular degeneration and preserving vision. Various traditional techniques have been developed for effective age-related macular degeneration detection. However, traditional approaches failed to detect and classify the disease accurately and it consumes more time. However, traditional approaches failed to detect and classify age-related macular degeneration accurately. This research paper proposed an efficient model named as Multi-Modal Vision transformer model for the early and accurate prediction of age-related macular degeneration. This study aims to combine information from the Color Fundus Photography and Optical Coherence Tomography streams for performing efficient age-related macular degeneration diagnosis. The input images are needed to be preprocessed to enhance the image quality and make it suitable for further processing. The proposed framework integrated a Cascaded group attention transformer block which extracts the significant features from these modalities effectively. This block has the ability to solve computational complexity issues and attention head redundancy problems. Further, the multi-modal fusion method based on self-attention is introduced for fusing the features from Color Fundus Photography and Optical Coherence Tomography images. This fusion model is trained by applying both standard backpropagation and random gradient descent algorithms. For multi-class classification tasks, the fused features are classified into different classes based on the decision score. To visualize the single-modal and multi-modal output images in a heat map we applied a Class Activation Mapping model. Furthermore, the proposed technique is conducted on the Python platform and the performance is evaluated on different datasets with significant evaluation measures. This technique achieves a higher accuracy of 98.65% and a lower computational time of 13.14 s. From this experimental finding, it’s clear that this study offers an outstanding contribution to early age-related macular degeneration detection.},
  archive      = {J_EVOLS},
  author       = {Annamalai, Akila and Palani, Durgadevi},
  doi          = {10.1007/s12530-025-09684-y},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Evol. Syst.},
  title        = {Multi-modal fusion and vision transformers for robust early AMD prediction},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PLANT detect net: A hybrid IoT and deep learning framework for secure plant disease detection and classification. <em>EVOLS</em>, <em>16</em>(2), 1-20. (<a href='https://doi.org/10.1007/s12530-025-09685-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things has been increasingly well-known in recent days as a result of its numerous applications. The Internet of Things plays a pivotal role in transforming traditional agricultural practices by enabling smart and precise plant disease detection and classification. Through a network of interconnected sensors and devices, the Internet of Things facilitates real-time monitoring and data collection from agricultural fields. Yet, the traditional detection techniques are limited by poor accuracy, high computational complexity, class imbalance, and overfitting issues. This work introduces a hybrid deep learning methodology known as PlantDetectNet with the IoT to overcome the above difficulties and achieve enhanced outcomes in the plant disease detection and classification process. In this research, the proposed framework employs sensor data and PlantVillage dataset images for accurate disease identification. In the proposed scheme, a gated recurrent unit is applied for extracting the sensor data’s temporal features and Depthcat convolutional neural network is utilized for extracting the spatial features from the input data. The Global Visual Geometry Group 16 framework is employed for mitigating the overfitting, a number of parameters, and refining the intermediate layer features. The Gated ConvNeXt model is utilized for enhancing the classification outcome of the model and effectively gathering the information in the modeling of channel-wise relationships. Additionally, the research introduces a Residual DenseNet approach for eliminating the invalid features and improving the significant features. The experimental results show that the proposed framework attained a high accuracy of 98.8% and a higher recall of 95.9% compared to existing approaches. These simulation findings prove that the proposed methodology enhanced efficiency, accuracy, and scalability in leaf disease detection and improved crop yields.},
  archive      = {J_EVOLS},
  author       = {Gupta, Pradeep and Jadon, Rakesh Singh},
  doi          = {10.1007/s12530-025-09685-x},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-20},
  shortjournal = {Evol. Syst.},
  title        = {PLANT detect net: A hybrid IoT and deep learning framework for secure plant disease detection and classification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized ensemble deep learning approach for accurate breast cancer diagnosis using transfer learning and grey wolf optimization. <em>EVOLS</em>, <em>16</em>(2), 1-17. (<a href='https://doi.org/10.1007/s12530-025-09686-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer (BC) is one of the most significant threats to women’s health worldwide, affecting one in eight women and causing over 42,250 deaths in 2024. Early detection plays a crucial role in improving patient outcomes, with mammography being the primary screening method most health organizations recommend. This paper highlights the potential of deep learning (DL) in enhancing diagnostic Accuracy and speed. However, despite the promising results of DL models, the increasing complexity of breast cancer data presents a significant challenge in selecting the most relevant features. We propose a robust DL model incorporating transfer learning (TL) and grey wolf optimization (GWO) to enhance BC diagnosis. The architecture is developed by leveraging multiple deep neural networks, including ResNet and Inception, based on convolutional neural networks (CNNs). These networks are fine-tuned using a mammographic image dataset to optimize model weights and parameters for higher classification accuracy. Additionally, the Wisconsin Breast Cancer Dataset (WBCD) is utilized with GWO to refine feature selection further. Experimental results demonstrate that the proposed ensemble method improves robustness, generalization, and detection rates while minimizing false positives and negatives. Large-scale dataset evaluation yielded a precision of 0.942, sensitivity of 0.982, Accuracy of 0.965, and an area under the curve (AUC) value of 0.971. These findings suggest that the proposed framework could significantly enhance patient care and improve healthcare service organization and management.},
  archive      = {J_EVOLS},
  author       = {Hassan, Esraa and Saber, Abeer and El-Sappagh, Shaker and El-Rashidy, Nora},
  doi          = {10.1007/s12530-025-09686-w},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Evol. Syst.},
  title        = {Optimized ensemble deep learning approach for accurate breast cancer diagnosis using transfer learning and grey wolf optimization},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Action quality assessment via moment aware network. <em>EVOLS</em>, <em>16</em>(2), 1-10. (<a href='https://doi.org/10.1007/s12530-025-09687-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent action quality assessment methods attempt to decompose the entire video into sub-actions of the same level, which still suffers from information redundancy and lacks certain interpretability. Through studying and analysing the evaluation rules of relevant sports events, we assume that certain critical moments in the actions will significantly impact the assessment of the entire action, if the weight of these critical moments in the evaluation process can be increased, then the results can be more accurate and more persuasive. To validate this idea, we propose a moment-aware approach for action quality assessment, a novel moment-aware module is used to explore the key moments in action globally and locally to obtain more reliable evaluation results. Extensive experiments have shown that our module captures key moments that are close to the focus of human referees, and our method has also achieved favorable results on multiple public AQA benchmarks, the Spearman’s rank correlation reached 0.9360 on FineDiving dataset and 0.8797 on AQA-7 dataset.},
  archive      = {J_EVOLS},
  author       = {Han, Jifeng and Zhang, Yanduo and Lu, Tao and Wang, Jiaming},
  doi          = {10.1007/s12530-025-09687-9},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-10},
  shortjournal = {Evol. Syst.},
  title        = {Action quality assessment via moment aware network},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved employee bee algorithm for team formation. <em>EVOLS</em>, <em>16</em>(2), 1-20. (<a href='https://doi.org/10.1007/s12530-025-09688-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding an appropriate subset of agents (a team) from a larger pool of agents (the source set) so that the team exhibits a desired quality is the essence of the team formation problem. This problem is recognized to have high computational complexity, classified as NP-hard. In order to reduce the state space, this research paper incorporates techniques including vertical and horizontal reductions, which convert data to binary representation. To simplify the data representation for analysis, these methods use vertical and horizontal reductions to convert data to binary format, generating a subgraph. With this, the Honeybee Optimization algorithm’s Employee Bee phase (EBP) swap operation characteristic is used to efficiently optimize team communication costs by making it easier to determine a team with a minimum communication costs (MCC). The proposed approach is assessed using two well-known real-world data sets, the ACM data set and the DBLP data set, demonstrating an improvement of 79% in the ACM dataset and 68% in the DBLP dataset compared to existing literature approaches like Improved Jaya Modified Swap Operation, Improved Grey Wolf Optimization, and State Space Reduction Techniques for Team Formation. This highlights the significant positive impact of state space reduction techniques combined with the IEB on team performance, particularly enhancing communication efficiency and overall team effectiveness, as measured by MCC metrics.},
  archive      = {J_EVOLS},
  author       = {Shingade, Sandip and Niyogi, Rajdeep and Shelke, Sushila},
  doi          = {10.1007/s12530-025-09688-8},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-20},
  shortjournal = {Evol. Syst.},
  title        = {Improved employee bee algorithm for team formation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Microbe-drug association prediction using metapath aggregated node embeddings and self-supervised learning. <em>EVOLS</em>, <em>16</em>(2), 1-20. (<a href='https://doi.org/10.1007/s12530-025-09689-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human microorganisms are closely related to human health by regulating the immune system, producing hormones, and contributing to metabolism. Discovering potential associations between microbes and drugs aid drug research and development. This work proposes a novel computational framework called self-supervised metapath aggregated microbe-drug association prediction network (SMMDA-Net) to predict potential microbe-drug associations. Various biological datasets are leveraged to construct heterogeneous networks using microbe-drug associations and microbe-disease, disease-drug transitive associations. Feature matrices containing information on microbe functional similarity, microbe genome similarity, drug structure similarity and drug side-effect-based similarity are extracted. Then, a novel model called self-supervised metapath-based node embedding generator (SMNEG) is used to generate low-dimensional meaningful embeddings for nodes in the heterogeneous network. A CNN classifier is adopted and trained by the low-dimensional embeddings to predict potential microbe-drug associations. Extensive experiments on three datasets show that the proposed model outperforms six state-of-the-art methods. It achieved an AUC of 98.23% and an AUPR of 95.14% on the MDAD dataset, an AUC of 99.22% and an AUPR of 94.86% on the aBiofilm dataset, and an AUPR of 87.98% on the DrugVirus dataset. Furthermore, ablation and case studies were performed to evaluate the effectiveness of SMMDA-Net in predicting potential microbe-drug associations.},
  archive      = {J_EVOLS},
  author       = {Syama, K. and Jothi, J. Angel Arul and Sivakumar, Anushka},
  doi          = {10.1007/s12530-025-09689-7},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-20},
  shortjournal = {Evol. Syst.},
  title        = {Microbe-drug association prediction using metapath aggregated node embeddings and self-supervised learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting missing links in complex networks using information about common neighbors and a degree of popularity. <em>EVOLS</em>, <em>16</em>(2), 1-16. (<a href='https://doi.org/10.1007/s12530-025-09690-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying missing links in complex networks is particularly challenging due to factors such as noise, intentional perturbations, and incomplete data collection. Addressing missing links in complex networks requires robust prediction models that consider various factors and network attributes for accurate and reliable results. Similarity-based link prediction methods are computationally efficient and scalable, making them practical for real-world applications. However, they typically distort network properties and lack accuracy in preserving network structures. To overcome this problem, this paper presents a new family of measures that results from strengthening existing similarity measures based on local information. Here, existing methods are combined with the Degree of Popularity (DP) of nodes, which is considered the attraction force between the nodes of the network. Nodes with a greater DP feature are more likely to be connected in the future. This research shows that the proposed family of measures improve the link prediction results of existing method without any additional cost in terms of time complexity. To evaluate our proposal, firstly tested our proposed similarity measure is tested using thirteen datasets of real-world networks, comparing the evaluation performances against sixteen basic algorithms based on local information similarity measures. Secondly, our similarity measure is compared with eleven well-known and frequently referenced similarity measures based on global information. The comparison results, in terms of the Area Under the Curve (AUC) measure, clearly demonstrate the superiority of our proposed method, achieving an average AUC of 0.9116 using the DP feature. This outperforms local, quasi-local, and global methods (28 methods in total) and attains the highest performance score across all 13 datasets.},
  archive      = {J_EVOLS},
  author       = {Saifi, Abdelhamid and Nouioua, Farid and Charikhi, Mourad and Belazzoug, Mouhoub},
  doi          = {10.1007/s12530-025-09690-0},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Evol. Syst.},
  title        = {Predicting missing links in complex networks using information about common neighbors and a degree of popularity},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-source information diffusion model for conversation recommender system. <em>EVOLS</em>, <em>16</em>(2), 1-20. (<a href='https://doi.org/10.1007/s12530-025-09692-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational recommender system (CRS) captures user preferences from historical conversations to provide high-quality recommendations. Existing studies introduce external data to compensate for data limitations, improving the model’s ability to predict user preferences. However, CRS still faces several challenges: i) Existing methods only use text features to capture user preferences, ignoring the role of images in entity representation. The fusion mechanism in CRS fails to effectively enable parameter interaction between multiple sources, leading to lower-quality feature fusion results. ii) In the recommendation module, previous methods assign weights to entities in a sequential manner but overlook the influence of contextual semantic information over time. This makes it difficult to update entity weights in real-time. iii) In the dialogue module, the system-generated responses lack diversity. To address these issues, this paper first introduces entity-related image information to enrich entity features, encoding relevant themes and storylines of items. Second, to reduce differences between multiple sources, we propose a Cross Correlation Interaction Mechanism (CCIM) to enable effective interaction and achieve efficient feature fusion. Finally, we incorporate diffusion models into CRS. In the recommendation module, the diffusion model updates entity weights dynamically through iterative learning, capturing the dynamic evolution of user interests. In the dialogue module, we design an entity diffusion module to improve response diversity. Extensive experiments on two public CRS datasets demonstrate the effectiveness of our model. Our code is released on https://github.com/Janns0916/MDCR-main https://github.com/Janns0916/MDCR .},
  archive      = {J_EVOLS},
  author       = {Liu, Fengjin and Huang, Xianying and Liu, Huaiyu},
  doi          = {10.1007/s12530-025-09692-y},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-20},
  shortjournal = {Evol. Syst.},
  title        = {Multi-source information diffusion model for conversation recommender system},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding character recognition using grad-CAM and predicting faithfulness through human evaluation. <em>EVOLS</em>, <em>16</em>(2), 1-18. (<a href='https://doi.org/10.1007/s12530-025-09693-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transparency in the Artificial Intelligence (AI) models represents the future potential that the research community seeks, prompting a strong call for eXplainable Artificial Intelligence (XAI) and significantly transforming the dynamics of trust and risk evaluation. Learning models operate as black-boxes, where users input a sequence of instances for labeling without gaining insight into the model’s learning or behavior. This can be handled by incorporating an explanation along with the prediction, thus evolving from a black-box to a white-box model, making it more transparent and interpretable. XAI has found successful applications across diverse domains, especially in medical and banking. However, its exploration within Optical Character Recognition (OCR) remains relatively unexplored. This paper presents an explainable model that provides a visual understanding of the predictions made by a CNN model to recognize the handwritten Assamese digits. This in turn ensures trust in the black-box model predictions thus making it transparent. A Gradient Class Activation Mapping (Grad-CAM) is incorporated with a CNN model that gives visual explanations against the predictions made. The visual explanations are justified by human evaluation further, where the explanations are validated. Through these visual explanations, users can make judgments regarding their trust in the model and determine the fidelity of its predictions. The visual explanations generated by the Grad-CAM in the present work demonstrate that the model’s predictions align with human understanding, thereby establishing the faithfulness and trustworthiness of the model in predicting the digits.},
  archive      = {J_EVOLS},
  author       = {Dutta, Prarthana and Muppalaneni, Naresh Babu},
  doi          = {10.1007/s12530-025-09693-x},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Evol. Syst.},
  title        = {Understanding character recognition using grad-CAM and predicting faithfulness through human evaluation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep ensembled voting framework for human activity recognition and validation on video sequences. <em>EVOLS</em>, <em>16</em>(2), 1-23. (<a href='https://doi.org/10.1007/s12530-025-09695-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) is concerned with identifying human activities gathered using devices like video cameras. The video datasets are challenging in terms of quality: varying backgrounds, camera viewpoints, and huge volume. Deep learning (DL) paradigms are more suitable for such datasets than traditional machine learning techniques. But sometimes DL HAR models suffer from the misclassification problem when tested in real-time environment or on unseen data. To overcome such issues the DL-based ensembled models have proven beneficial and provide high performance. In the proposed work, a deep ensembled voting algorithm (EnsVoting) framework is introduced where the prediction is based on the output of Conv-Rec base models. In Conv-Rec model, a deep convolutional neural network (CNN) is used to extract deep features from videos that are passed to the bi-directional recurrent neural network (RNN) layer later. Then the base model’s prediction is used by the proposed EnsVoting model which provides more efficient results. To validate the trained models’ performance, two validation sets are made (i) seen video set: from the UCF-101 dataset; (ii) unseen video set: from the Kinetics-700 dataset. The proposed work is well researched, comprehensive, and offers novelties (i) EnsVoting algorithm based HAR framework (ii) implemented fast trained HAR model using ResNetRS-152 with 91.25% accuracy, (iii) scientific validation including seen video set with accuracy 96.25% and unseen video set with accuracy nearly 73% and, (iv) evaluated the overall performance in terms of accuracy, ROC/AUC and performed the statistical test for evaluating the p-value.},
  archive      = {J_EVOLS},
  author       = {Gupta, Neha and Gupta, Suneet K. and Jain, Vanita and Singh, Narpinder and Suri, Jasjit S.},
  doi          = {10.1007/s12530-025-09695-9},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-23},
  shortjournal = {Evol. Syst.},
  title        = {Deep ensembled voting framework for human activity recognition and validation on video sequences},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Motor imagery task classification using spatial–time–frequency features of EEG signals: A deep learning approach for improved performance. <em>EVOLS</em>, <em>16</em>(2), 1-21. (<a href='https://doi.org/10.1007/s12530-025-09696-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of electroencephalogram (EEG) signals according to the user-intended motor imagery (MI) task is crucial for effective brain–computer interfaces (BCIs). Current methods often encounter difficulties in attaining high classification accuracy. This study aims to improve accuracy by utilising spatial and time–frequency characteristics of multichannel EEG data using convolutional neural networks (CNN). EEG signals acquired from the sensory-motor region were subjected to time–frequency analysis, creating three-dimensional spatially informed time–frequency representations (SITFR). The CNN was trained and validated using SITFR matrices corresponding to four motor imagery tasks utilising the BCI Competition IV dataset IIa with a five-fold cross-validation technique. Gaussian noise data augmentation was applied to improve model robustness by increasing variability in EEG signals while preserving their structural integrity. Four time–frequency approaches, namely continuous wavelet transform (CWT), wavelet synchrosqueezed transform (WSST), Fourier synchrosqueezed transform (FSST) and synchroextracting transform (SET) were used for this experiment. The CNN model attained a mean test accuracy of 98.18% and kappa score of 0.98 for CWT-SITFR, outperforming other TFR methods. The accuracies obtained for FSST, WSST and SET were 97.47%, 94.38% and 91.82% with kappa scores of 0.97, 0.93 and 0.89 respectively. This approach enables the CNN to learn both time–frequency and spatial features, resulting in better performance compared with existing state-of-the-art techniques.},
  archive      = {J_EVOLS},
  author       = {Muhamed Jishad, T. K. and Sudeep, P. V. and Sanjay, M.},
  doi          = {10.1007/s12530-025-09696-8},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Evol. Syst.},
  title        = {Motor imagery task classification using spatial–time–frequency features of EEG signals: A deep learning approach for improved performance},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MHWF-CNN: Multiscale horizontal wavelet fusion convolutional neural network with transfer learning for image classification. <em>EVOLS</em>, <em>16</em>(2), 1-13. (<a href='https://doi.org/10.1007/s12530-025-09697-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces an innovative methodology that synergizes wavelet-based feature extraction with multiscale fusion and deep learning, aiming to elevate the image classification task. Initially, the Haar wavelet transform is applied to lung X-ray images, extracting approximation, horizontal, vertical, and diagonal sub-band coefficients. Following this, a multi-scale horizontal fusion technique integrates wavelet-transformed images at different resolutions with the original image. This process creates an enriched feature map with essential contextual information for the subsequent deep-learning model. The resulting image features serve as input for the deep learning models, encompassing conventional Convolutional Neural Networks and transfer learning models such as ResNet50 and VGG19. The Experimental demonstrates the proposed MHWF-CNN method performance in terms of accuracy that using the publicly accessible Chest X-ray dataset. The proposed method attains 99% accuracy with the integration of advanced methodology to ensure the power and potential of this approach in image classification domain.},
  archive      = {J_EVOLS},
  author       = {Kavitha, S. and Inbarani, H. Hannah},
  doi          = {10.1007/s12530-025-09697-7},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-13},
  shortjournal = {Evol. Syst.},
  title        = {MHWF-CNN: Multiscale horizontal wavelet fusion convolutional neural network with transfer learning for image classification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Healthcare fraud detection using adaptive learning and deep learning techniques. <em>EVOLS</em>, <em>16</em>(2), 1-20. (<a href='https://doi.org/10.1007/s12530-025-09698-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The healthcare industry faces huge losses due to the mismanagement of insurance transactions. Due to the development of public and private healthcare programs, many citizens receive better medical care benefits. Still, there is a need for financial transparency in these healthcare transactions, which has become a challenge. To ensure the delivery of more effective and higher-quality healthcare services, introducing healthcare fraudulent transactions prevention and detection tools in hospitals is necessary. In this paper, we propose how to inculcate a healthcare transaction monitoring system within an enterprise or organisation. Using machine and deep learning techniques, this research proposes a novel framework for analyzing health insurance data. Due to the complexity of medical information, detecting fraudulent transactions in the industry requires effort. Typically, patients, services, and providers (doctors, hospitals, pharmacies) are the main key elements of the healthcare ecosystem. As fraudsters continue to evolve their methods of conducting fraudulent transactions over time, an evolving fraud detection framework needs to be developed. Therefore, we proposed a framework that can identify fraud at the actor-level and further analyze the identified element (doctor, patient, and services) using an Anomaly transformer to evaluate the behavior of that particular identified element. Actor-level frauds are detected, 50% are at the patient level, 12% are at the service versus doctor level, 13% are at the service versus patient level, and 25% are at the physician level. Further, sequences of these elements are analyzed by the Anomaly transformer. All patient sequences’ anomaly scores are generated using a data-driven threshold, and fraudulent sequences are identified. Results of the Speciality-based Rule engine and the Anomaly transformers are compared to identify the anomaly finally. Once the frauds are identified, the proposed architecture enables the management to take disciplinary action against each involved element. The Accuracy of the proposed framework is 97%, The experimental results are validated using the insurance data of local hospital employees, and the domain expert has validated the detected fraud cases.},
  archive      = {J_EVOLS},
  author       = {Matloob, Irum and Khan, Shoab and Rukaiya, Rukaiya and Alfrahi, Hessa and Ali Khan, Javed},
  doi          = {10.1007/s12530-025-09698-6},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-20},
  shortjournal = {Evol. Syst.},
  title        = {Healthcare fraud detection using adaptive learning and deep learning techniques},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparing the efficiency of YOLO-M for face recognition in images and videos degraded by compression artifacts. <em>EVOLS</em>, <em>16</em>(2), 1-30. (<a href='https://doi.org/10.1007/s12530-025-09699-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial recognition is essential for public and private security, widely used to identify individuals and manage access with precision. This study evaluates the impact of image compression on the accuracy of facial recognition models, considering three types of codecs: HEVC, H.264, and JPEG2000, which exhibit distinct compression characteristics. Three facial recognition models were analyzed: Local Binary Pattern (LBP), Extreme Learning Machine (ELM), and the proposed YOLO-M model. The YOLO-M, a hybrid architecture developed in this study, combines YOLOv8 for rapid face detection with ResNet-50, which extracts detailed and robust features. The extracted information is integrated and processed through convolutional and dense layers, culminating in a softmax classifier, ensuring efficiency in challenging scenarios. The results showed that LBP has limited performance, achieving 82.41% accuracy on the original dataset but degrading significantly under severe compression due to its reliance on local texture patterns. ELM, on the other hand, demonstrated greater robustness, reaching 96.9% accuracy on the original dataset and maintaining good performance under moderate compression, though with a decline under extreme compression. YOLO-M was the most resilient and accurate among the methods, achieving 98.99% accuracy on the original dataset and maintaining superior performance even under severe compression, such as JPEG2000 with high quantization levels.},
  archive      = {J_EVOLS},
  author       = {Ferreira, Fernando Rodrigues Trindade and do Couto, Loena Marins and de Melo Baptista Domingues, Guilherme},
  doi          = {10.1007/s12530-025-09699-5},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-30},
  shortjournal = {Evol. Syst.},
  title        = {Comparing the efficiency of YOLO-M for face recognition in images and videos degraded by compression artifacts},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PolyNet-FractalNet deep feature fusion framework with modified spider monkey optimization for multi-modal biometric recognition. <em>EVOLS</em>, <em>16</em>(2), 1-35. (<a href='https://doi.org/10.1007/s12530-025-09700-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The biometric recognition plays secure banking identity verification, in border control for efficient and reliable access management, in smartphone authentication user access it with enhanced security in real world. This paper documents a biometric recognition of Multi-Modal Adaptive Biometric Recognition Network (MABRecNet) designed to improve airport security, accurate, and reliable. MABRecNet addresses core challenges in biometric traits, enhanced feature extraction, overfitting prevention, scalability and robustness across datasets. The methodology starts with preprocessing to enhance image quality and increase variability using data augmentation. The Adaptive PolyNet is core model in multi-path dynamic structure capable of capturing low and high-level features from biometric traits, adaptable for changes in lighting conditions, pose, and user behaviour. Its adaptive branch activation and attention mechanisms pay attention on key feature vectors that enhance the recognition accuracy. Besides, Late Score Fusion-based FractalNet Deep CNN mines various feature vectors with different modalities to be fused at late score for better recognition performance. In addition, the MSMO algorithm aims at optimizing feature selection and dimensionality reduction through a balance of relevance and redundancy. This provides computational efficiency for real-time applications. The optimized feature set is processed in the Feature-Wise deep convolution neural network FWDCNN module of MABRecNet, which captures unique characteristics of combined biometric traits. This brings out the correct recognition result, hence improving recognition accuracy and robustness in multi-modal biometric systems. MABRecNet shows high performance with 99% Accuracy, 98.5% Precision, 98.8% mAP, 98.5% Recognition rate and, 97.5% GAR recognition. The framework enhances the biometric identification system on security and efficiency, even at large scales deployments.},
  archive      = {J_EVOLS},
  author       = {Singh, Laxman and Kumar, Ashish and Golash, Richa},
  doi          = {10.1007/s12530-025-09700-1},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-35},
  shortjournal = {Evol. Syst.},
  title        = {PolyNet-FractalNet deep feature fusion framework with modified spider monkey optimization for multi-modal biometric recognition},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new IoT recommendation system based on a dynamic ontology. <em>EVOLS</em>, <em>16</em>(2), 1-20. (<a href='https://doi.org/10.1007/s12530-025-09701-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) has transformed various aspects of daily life by generating vast, heterogeneous data, necessitating efficient data filtering to ensure optimal system performance. Recommender systems are crucial in delivering personalized recommendations based on user preferences and behavioral patterns. However, a significant challenge lies in effectively categorizing and analyzing large-scale, diverse, and complex data to extract meaningful insights for accurate recommendations. This research presents an innovative model that integrates ontology with clustering methods and deep neural networks, significantly enhancing the accuracy of IoT recommender systems by improving the data filtering process. Unlike traditional methods, this model has wide-ranging applications in optimizing services across diverse IoT recommender system environments. By leveraging semantic relationships and structured knowledge representations, our approach surpasses conventional filtering techniques, leading to more refined recommendations. The proposed model not only improves user experience but also optimizes service delivery in dynamic IoT environments. To assess its effectiveness, we conducted extensive experimental evaluations and benchmarked our model against existing state-of-the-art methods. The results demonstrate substantial improvements in recommendation accuracy and a notable reduction in error rates. Specifically, our approach achieves approximately a 50% improvement over traditional collaborative filtering methods, paving the way for more intelligent, adaptive, and personalized IoT-based recommender systems.},
  archive      = {J_EVOLS},
  author       = {Niroomand, Atefeh and Ghafouri, Seyyed Hamid and Bardsiri, Amid Khatibi},
  doi          = {10.1007/s12530-025-09701-0},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-20},
  shortjournal = {Evol. Syst.},
  title        = {A new IoT recommendation system based on a dynamic ontology},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive deep learning approach for identification of crop-types from remote sensing images. <em>EVOLS</em>, <em>16</em>(2), 1-15. (<a href='https://doi.org/10.1007/s12530-025-09702-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate crop-type maps that are updated regularly are necessary for various agricultural monitoring and decision-making purposes. Obtaining crop-type maps early in the current growing season is highly advantageous for agricultural decision-making and management. Due to the abundance of high-resolution remote sensing data with precise spatial and temporal details, the frequency of data collection from various sources is anticipated to rise. The augmentation of data gathering will yield a larger volume of information available in the initial phases of the season. This study proposed an Adaptive Convolutional Neural Network with Incremental Training (ACNN-IT) method based on the CNN model. ACNN-IT is primarily intended to explore the potential of integrating diverse data sources for real-time crop-type identification. Given the periodic production of Sentinel remote sensing data, an adaptive strategy for early crop-type detection is necessary. Consequently, the incremental training-based CNN model is developed for autonomous feature extraction and classification. The proposed model comprises pre-processing, feature extraction, and classification. An iterative training method is utilized to familiarize the network with adaptive sentiment data and ascertain the ideal detection rate for each crop variety throughout the early growth season. An examination of the ACNN-IT model is conducted using remote sensing data collected from Sentinel-1 A and Sentinel-2 satellites. ACNN-IT strategy was validated using support vector machine (SVM), random forest (RF), and SoftMax classifiers. Simulation results revealed that the proposed model has improved the overall crop type detection accuracy by 3.56% with reduced computational burden by 7.23% compared to the state-of-the-art.},
  archive      = {J_EVOLS},
  author       = {Vatkar, Shilpa and Kulkarni, Sujata},
  doi          = {10.1007/s12530-025-09702-z},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Evol. Syst.},
  title        = {An adaptive deep learning approach for identification of crop-types from remote sensing images},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating LSTM-based time series prediction using dynamic systems measures. <em>EVOLS</em>, <em>16</em>(2), 1-18. (<a href='https://doi.org/10.1007/s12530-025-09703-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long Short-Term Memory (LSTM) is widely used in time-series analysis and prediction. Combining LSTM with mathematical transformer models such as Fourier and Wavelet or with statistical methods like Lomb-Scargle, Harmonic Regression, and Seasonal-Trend decomposition can effectively capture time-series behavior and enhance the efficiency and accuracy of prediction models. However, this approach heavily relies on the characteristics of the data. Depending on whether the time series data is periodic, chaotic, or quasi-periodic, the selection of appropriate tools varies—an issue often overlooked in current research that combines LSTM with mathematical transformers or statistical methods. In this study, we aim to demonstrate that using nonlinear dynamic systems techniques, which can capture the characteristics of time series data, leads to the selection of the best transformer. Moreover, this approach explains why LSTM and its combination models may not always perform well. This insight is vital for designing new models based on the dynamic behavior of data. Our experimental findings on two real-world datasets indicate that a combination of LSTM with transformers or decomposition tools does not perform well on highly sensitive and chaotic time series. In other words, we present a model that explains the inefficiencies of LSTM-based models in certain scenarios.},
  archive      = {J_EVOLS},
  author       = {Mahmoudi, Amin},
  doi          = {10.1007/s12530-025-09703-y},
  journal      = {Evolving Systems},
  month        = {6},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Evol. Syst.},
  title        = {Investigating LSTM-based time series prediction using dynamic systems measures},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive genetic algorithm-optimized temporal convolutional networks for high-precision ship traffic flow prediction. <em>EVOLS</em>, <em>16</em>(1), 1-17. (<a href='https://doi.org/10.1007/s12530-024-09624-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timely prediction of Ship Traffic Flow (STF) is essential for managing maritime traffic and preventing congestion. However, existing deep neural network-based STF models often face challenges with hyperparameter selection and limited accuracy improvements. This study introduces a Temporal Convolutional Network (TCN) model optimized by an Adaptive Genetic Algorithm (AGA) to address these issues. The methodology begins with comprehensive data preprocessing, using gate-line-based rules to analyze ship traffic entering and leaving ports, leveraging Automatic Identification System (AIS) data. The AGA-TCN model then employs causally dilated convolutions to capture long-term dependencies and extract frequency domain features, with the AGA dynamically optimizing TCN hyperparameters for specific prediction tasks, resulting in an end-to-end STF prediction framework. AIS data from San Francisco waters, covering the period from June 1, 2022, to December 14, 2022, was used to evaluate the model. The performance of the AGA-TCN model was compared against Particle Swarm Optimization (PSO)-TCN, standard TCN, Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU) models. These models were chosen for comparison due to their widespread use in time-series prediction tasks, representing a variety of approaches in deep learning and optimization. The experiments demonstrate that the AGA-TCN model outperformed all these models, with improvements in RMSE, MSE, and MAPE of 54.37%, 79.18%, and 27.43%, respectively, over the standard TCN. These results underscore the robustness and high accuracy of the AGA-TCN model in STF prediction, establishing it as a superior approach for this application.},
  archive      = {J_EVOLS},
  author       = {LI, Yunfan and Wang, Qian},
  doi          = {10.1007/s12530-024-09624-2},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Evol. Syst.},
  title        = {Adaptive genetic algorithm-optimized temporal convolutional networks for high-precision ship traffic flow prediction},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A domain knowledge infused gated network using integrated sentiment prediction framework for aspect-based sentiment analysis. <em>EVOLS</em>, <em>16</em>(1), 1-26. (<a href='https://doi.org/10.1007/s12530-024-09625-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-Based Sentiment Analysis (ABSA) targets sentiments on specific aspects in reviews, offering more granularity than overall sentiment analysis. Challenges in ABSA include handling implicit sentiments, varying expressions, linguistic nuances, and ensuring robust predictions across domains. Addressing these is crucial for extracting meaningful insights from customer reviews and enhancing products or services. Aiming at these concerns, this paper proposes an Enhanced Knowledge Infused Graph-Gated BERT (EKIG-GBERT) model for ABSA in customer-related program reviews. This innovative approach integrates a Dynamic Sentiment-specific Knowledge Graph (DSSKG) and Knowledge graph-enhanced BERT model with Gated Domain Graph Convolutional Network (KG-BERT-GDGCN) to capture intricate sentiment-aspect relationships. The methodology begins with data pre-processing, including tokenization and noise reduction, followed by domain-specific knowledge infusion via DSSKG. The approach leverages KG-BERT for advanced aspect extraction, enhancing the model's capacity to capture subtle emotional nuances in textual data. Aspect extraction is performed at multiple levels like term, category, implicit, entity, and attribute that leverages the KG-BERT model for comprehensive sentiment representation. Additionally, a structured graph seamlessly integrates affective information from DSSKG and KG-BERT, forming an affective adjacency matrix that encapsulates nuanced emotional connections among words in a sentence. The integrated sentiment prediction framework fuses features from DSSKG and KG-BERT using the GDGCN model. Processing through densely connected layers, dropout, and batch normalization ensures effective regularization, resulting in a robust model that leverages information from multiple sources for improved sentiment analysis. Experimental evaluations using four SemEval datasets (i.e., Rest14 task 4, Lap14 task 4, Res15 task 12, Res16 task 5) demonstrate that the EKIG-GBERT model significantly outperforms existing ABSA methods. The EKIG-GBERT model achieved an accuracy of 97.5% on the Rest14 task 4, 98.5% on Lap14 task 4, 94% on Res15 task 12, and 92% on Res16 task 5. Additionally, the confusion matrix analysis further confirmed its superior performance in distinguishing between various sentiment aspects. These results underscore the model's robustness and reliability in the ABSA prediction tasks.},
  archive      = {J_EVOLS},
  author       = {Dubey, Gaurav and Kaur, Kamaljit and Chadha, Anupama and Raj, Gaurav and Jain, Shikha and Dubey, Anil Kumar},
  doi          = {10.1007/s12530-024-09625-1},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Evol. Syst.},
  title        = {A domain knowledge infused gated network using integrated sentiment prediction framework for aspect-based sentiment analysis},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive model based on ESN for anomaly detection in industrial systems. <em>EVOLS</em>, <em>16</em>(1), 1-16. (<a href='https://doi.org/10.1007/s12530-024-09626-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling real industrial systems is a challenging task due to the complex nature of process data. Data-driven models commonly employ machine learning algorithms, but they often lack the ability to adapt to changes in the system over time. This paper proposes a method that uses Echo State Networks (ESN), a simplified version of Recurrent Neural Networks (RNN), to model an industrial plant. The ESN model incorporates online adaptation to system changes and enables the visualisation of deviations or errors in the operation of the plant. This adaptive model acknowledges acceptable changes within the original system while identifying potential problems or errors. The advantage of this approach is that the same model can be applied to other systems with the same design, eliminating the need for algorithm retraining. Firstly, its successful offline application in visualising anomalies applied to the reference plant is assessed. Secondly, the model is tested for online adaptation to changes in another plant with an identical design but slight differences, while still observing the generated faults. Residual colour maps are used for the visualisation of anomalies.},
  archive      = {J_EVOLS},
  author       = {Rodríguez-Ossorio, José Ramón and Morán, Antonio and Fuertes, Juan J. and Prada, Miguel A. and Díaz, Ignacio and Domínguez, Manuel},
  doi          = {10.1007/s12530-024-09626-0},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Evol. Syst.},
  title        = {Adaptive model based on ESN for anomaly detection in industrial systems},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI in gastrointestinal disease detection: Overcoming segmentation challenges with coati optimization strategy. <em>EVOLS</em>, <em>16</em>(1), 1-19. (<a href='https://doi.org/10.1007/s12530-024-09627-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today AI helps a lot within the healthcare industry in the handling and classification of diseases that affect people. Multiple AI-based computerized methodologies developed in recent years for diagnosing gastrointestinal diseases (GI) including polyps. Diagnosis of these diseases performed by human beings requires much more time is expensive and requires expertise in this field. Thus the comprised methodologies that help the doctors as a second opinion is greatly requested. The prime issues faced by these technologies are segmentation and finding the precise regions where the infected area is there since the affected region has varying locations and shapes. This is due to the segmentation inaccuracy leading the negative impacts on feature learning and further affecting the preciseness in classification. Thus this paper introduced a novel automatic strategy for diagnosing GI disease which is designed with some of the following prime phases, from preprocessing to classification. The input GI images are gained from the Kvasir Dataset contains multiple classes like polyps, ulcerative colitis, etc., and the CVC-ClinicDB dataset which includes a single class of polyps images. For extracting the features a Coati optimization algorithm is employed in the feature learning model which helps in finding and focusing on the relevant features or information and makes the model more robust. A hybrid U-net model is employed for the pixel-level segmenting process, which can minimize the errors and enhance the segmentation process. Along with the Mask region based convolutional neural network (Mask RCNN) is employed to classify the segmented images, which enhances the accuracy of diagnosis and also the affected area's localization. Experimental outputs concluded that the proposed method offered realistic and pragmatic solutions for diagnosing GI diseases with enhanced accuracy of 98.8%, 98.2% recall, 97% F1-score, and 97.5% preciseness value. Further, it improved the prognosis pace by curtailing the training time of the model to 15 s.},
  archive      = {J_EVOLS},
  author       = {Jagarajan, Manikandan and Jayaraman, Ramkumar},
  doi          = {10.1007/s12530-024-09627-z},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Evol. Syst.},
  title        = {AI in gastrointestinal disease detection: Overcoming segmentation challenges with coati optimization strategy},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EPAMeT: Evolving predictive associative memories for time series. <em>EVOLS</em>, <em>16</em>(1), 1-16. (<a href='https://doi.org/10.1007/s12530-024-09628-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Associative memories (AM) are at the core of human intelligence and learning systems. While there have been some neural network AM developed for vector-based data such as images, current machine learning methods, including deep neural networks, do not allow for training a model on time series data and recalling it on a subset of variables measured over a shorter time window. They also do not support further incremental training of the model on new temporal data and new variables. This paper introduces a new framework and method for the creation of evolving predictive associative memories for time series, abbreviated here as ePAMeT. The method is based on spiking neural networks (SNN). ePAMeT introduces significant adaptability in handling time series data with reduced or newly introduced features. This model maintains high accuracy and explainability, offering substantial improvements over traditional methods in dynamic and uncertain environments. First, an SNN model is trained on multiple time series using all available variables measured at a full-time length, and then the model is recalled on subsets of variables at a shorter time measurement without compromising predictive accuracy. Using a shorter time for recall makes early prediction of events possible. The SNN model can be further adapted/evolved on new data without pre-training the model on the old data, even using new variables. This is possible due to the evolving connectivity of the SNN model. A dynamic graph is extracted from the SNN model to capture dynamic interactions between the used temporal variables at any time during the evolution of the model, which constitutes strong explainability and a generation of new knowledge. The method is illustrated on original financial time series data, but it is applicable to many other domain areas as discussed. The proposed method has advantages over traditional machine learning methods in terms of evolvability, explainability, knowledge discovery, and using partial information of both the number of variables and their time length for the recall of the model on new data. The proposed framework opens the field for creating new types of evolvable time series prediction models. Future developments are discussed.},
  archive      = {J_EVOLS},
  author       = {AbouHassan, Iman and Kasabov, Nikola K. and Bankar, Tanmay and Garg, Rishabh and Sen Bhattacharya, Basabdatta},
  doi          = {10.1007/s12530-024-09628-y},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Evol. Syst.},
  title        = {EPAMeT: Evolving predictive associative memories for time series},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Microfluidic droplet detection for bio medical application using YOLO with COA based segmentation. <em>EVOLS</em>, <em>16</em>(1), 1-20. (<a href='https://doi.org/10.1007/s12530-024-09629-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, biological and biochemical analysis using droplet-based microfluidics has become common practice. This process involves precisely locating the interface between miscible flows and dynamically controlling the sizes of oil-infused droplets in the segmented stream. Miniaturization for point-of-care diagnostics is hampered by the existing optical detection technology because it is costly, time-consuming, and requires a lot of processing to detect droplet contents. So, Optimized deep learning approach is developed to detect microfluidic droplets in bio medical research. To improve image quality, this proposed model pre-processes raw input images with Perona Malik Anisotropic Diffusion and range constrained bi-histogram equalization. Perona Malik Anisotropic Diffusion is used to denoise the input image, and range-limited bi-histogram equalization is used to increase the contrast level of the denoised image. The pre-processed image serves as an input for the droplet segmentation procedure. Image segmentation creates masks or contours for each recognized object in an image, as well as bounding boxes around those objects. To segment the pre-processed image, this current research uses the Optimized You Only Look Once (YOLO v7) technique. Anchor boxes are utilized in YOLO to produce candidate regions as well as anticipate bounding box adjustments and objectness ratings. Cheetah Optimization Algorithm (COA) is used for optimal selection of best anchor boxes in YOLOv7 rather than manually mapping the coordinates of anchor boxes. Proposed optimized deep learning model provides 96% accuracy, 93% precision, and 93.3% recall through a simulation study by comparing the actual and predicted droplets. Thus, the YOLO v7 with COA based segmentation improves the droplet prediction and servers as an efficient tool in bio medical research.},
  archive      = {J_EVOLS},
  author       = {Kumar, Kanike Sharan and Juliet, A. Vimala},
  doi          = {10.1007/s12530-024-09629-x},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Evol. Syst.},
  title        = {Microfluidic droplet detection for bio medical application using YOLO with COA based segmentation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NeuDen: A framework for the integration of neuromorphic evolving spiking neural networks with dynamic evolving neuro-fuzzy systems for predictive and explainable modelling of streaming data. <em>EVOLS</em>, <em>16</em>(1), 1-18. (<a href='https://doi.org/10.1007/s12530-024-09630-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel framework, called here 'NeuDen' for the integration of neuromorphic evolving spiking neural networks (eSNN), that learn efficiently multiple time series in their temporal association and interaction as spike based information, with dynamic evolving neuro-fuzzy systems (deNFS), that learn incrementally extracted from the eSNN frequency-based (rate-based) feature vectors, to predict future time-series values and to produce interpretable fuzzy rules. The new framework aims to make the best out of the dominant characteristics of the two types of models. First, spike-time-dependent plasticity (STDP) learning is used in SNN to learn temporal interaction between multiple time series, connected to a dynamic eSNN (deSNN) as a regressor/classifier. Then, frequency-based feature-vectors are extracted from the trained deSNN for further learning, fuzzy inference and rule extraction in a deNFS, here exemplified by a popular DENFIS model, resulting in an accurate prediction results and explainable dynamic fuzzy rules. The NeuDen, framework and model, overcomes both the explainability problems of eSNN and the limitations of deNFS to model multiple streaming time series in their temporal interaction. NeuDen surpasses both deSNN and DENFIS by providing multiple regression models and achieving higher accuracy. NeuDen is demonstrated on benchmark data and on financial and economic time series, achieving from 3 to 100 times smaller RMSE when compared with other evolving systems. The proposed framework opens a new direction for the development of more efficient evolving systems by integrating eSNN with other Explainable Artificial Intelligence (XAI) techniques, such as other neuro-fuzzy systems, deep neural networks, and quantum classifiers for specific applications.},
  archive      = {J_EVOLS},
  author       = {Hassan, Iman Yakzan Abou and Kasabov, Nikola K.},
  doi          = {10.1007/s12530-024-09630-4},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Evol. Syst.},
  title        = {NeuDen: A framework for the integration of neuromorphic evolving spiking neural networks with dynamic evolving neuro-fuzzy systems for predictive and explainable modelling of streaming data},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic adaptation of scan rates for efficient and congestion-aware internet-wide scanning in IoT security. <em>EVOLS</em>, <em>16</em>(1), 1-18. (<a href='https://doi.org/10.1007/s12530-024-09631-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, internet-wide scanning is considered as a countermeasure against the security problems in internet-of-things (IoT). The network congestion problem severely affects the IoT system due to the presenting number of port scanning packets in the network. The network congestion is taken as a major issue so the research paper is proposed for efficient internet-wide scanning in wireless LANs by minimizing network congestion. Adaptive Particle Network Optimization (APNO) is proposed in this paper that adaptively adjusts scan rates based on real-time network conditions and traffic dynamics. To enhance the adaptability and search efficiency, improvements are provided in the initialization of particle positions, velocity computation, and convergence mechanisms. The adaptive approach is implemented to ensure efficient scanning while minimizing network congestion during IoT data communication. The scan rate is adjusted based on the threshold values by defining network congestion limits and IoT data throughput requirements. The simulations are conducted on an NS-3 simulator that covers a wide range of scenarios, including varying scan rate ranges, traffic loads, network densities, and threshold sensitivities. The comparative analysis displayed a better outcome from the proposed APNO algorithm and achieved a scan efficiency of 98.2%, congestion level of 2.1% and IoT data throughput of 240Mbps. The convergence result showed a significant improvement in Internet-wide scanning in IoT environments.},
  archive      = {J_EVOLS},
  author       = {Velayudham, A. and Priya, M. S. Krishna},
  doi          = {10.1007/s12530-024-09631-3},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Evol. Syst.},
  title        = {Dynamic adaptation of scan rates for efficient and congestion-aware internet-wide scanning in IoT security},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of deep reinforcement learning in various image processing tasks: A survey. <em>EVOLS</em>, <em>16</em>(1), 1-20. (<a href='https://doi.org/10.1007/s12530-024-09632-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A subset of machine learning algorithm called Deep Reinforcement Learning (DRL) enables computers or agents to learn behavior by taking actions in a given environment through trial and error while observing the rewards. In this learning paradigm, the agent is given a set of actions to chose and is then rewarded or punished depending on the results of those actions. The agent gradually develops the ability to make the best decisions by maximizing its rewards. DRL blends the learning ability of deep neural networks into the decision making capability of reinforcement learning (RL) frameworks in order to seeks and identify the most favorable set of actions. This survey paper studies DRL applications for diverse image processing tasks. It starts by providing an overview of the latest model-free and model-based RL and DRL algorithms. Then, it looks at how DRL is being used for various image processing tasks including image segmentation and classification, object detection, image registration, image denoising, image restoration, and landmark detection. Lastly, the paper discusses the potential uses and challenges of DRL in the proposed area by addressing the research questions. Survey results have showed that DRL is a promising approach for image processing and that it has the potential to solve complex image processing tasks.},
  archive      = {J_EVOLS},
  author       = {Tadesse, Daniel Moges and Kebede, Samuel Rahimeto and Debele, Taye Girma and Waldamichae, Fraol Gelana},
  doi          = {10.1007/s12530-024-09632-2},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Evol. Syst.},
  title        = {Application of deep reinforcement learning in various image processing tasks: A survey},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Batch-enabled randomized parameter tuning for improved metaheuristic performance. <em>EVOLS</em>, <em>16</em>(1), 1-30. (<a href='https://doi.org/10.1007/s12530-024-09633-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameters are an important part of any metaheuristic algorithm. They play a pivotal role in deciding the results obtained from these algorithms. The problem of parameter tuning has become an optimization problem in itself, termed meta optimization. In the proposed work, a methodology for parameter tuning is proposed, in which the values of parameters vary randomly over an interval; hence, it is called random parameter tuning. It starts with dividing the whole population into sub-populations (called batches), and each batch is assigned a different range of parameter values. During each iteration, the value of a parameter is decided randomly according to the predefined interval of the corresponding batch. This approach is easy to understand and is general. It can be embedded with any of the metaheuristic algorithms. The proposed work has been embedded in the Genetic Algorithm, Particle Swarm Optimization, Firefly Algorithm, and Differential Evolution Algorithm. The approach has been tested over 15 benchmark functions, shifted rotated functions, and classical engineering problems. Moreover, the significance of the proposed approach is established by conducting a sensitivity analysis, a non-parametric Friedman test, and a Wilcoxon Rank Test. The proposed approach has been compared with the two state-of-the-art methods. The results show the superiority of the proposed approach.},
  archive      = {J_EVOLS},
  author       = {Kaushik, Deepika and Nadeem, Mohammad},
  doi          = {10.1007/s12530-024-09633-1},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Evol. Syst.},
  title        = {Batch-enabled randomized parameter tuning for improved metaheuristic performance},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). COVID-19 chest CT scan image segmentation based on chaotic gravitational search algorithm. <em>EVOLS</em>, <em>16</em>(1), 1-33. (<a href='https://doi.org/10.1007/s12530-024-09634-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation is a pivotal phase in the image processing pipeline, offering detailed insights into various image features. Traditional segmentation methods grapple with challenges such as local minima and premature convergence when navigating intricate pixel search spaces. Additionally, these algorithms experience prolonged processing times as the number of threshold levels increases. To mitigate these issues, we implemented the Chaotic Gravitational Search Algorithm (CGSA), a robust optimizer, for the multi-level thresholding of COVID-19 chest CT scan images. CGSA amalgamates the Gravitational Search Algorithm (GSA) for exploration with chaotic maps for exploitation. Kapur’s entropy method was employed to partition the sample images based on optimal pixel values. The segmentation performance of CGSA was rigorously assessed on various COVID-19 chest CT scan imaging datasets from Kaggle, utilizing metrics such as Peak Signal to Noise Ratio (PSNR), Structural Similarity Index Measure (SSIM), and Feature Similarity Index Measure (FSIM). The qualitative analysis encompassed convergence curves, segmented graphs, colormap images, histogram curves, and boxplots. Statistical validation was conducted using the signed Wilcoxon rank sum test, and eight sophisticated heuristic algorithms were enlisted for comparative analysis. The comprehensive evaluation unequivocally demonstrated CGSA's superiority in terms of processing time efficiency and its ability to provide optimal values for image quality metrics, establishing it as a powerful tool for quickly assessing COVID-19 disease severity.},
  archive      = {J_EVOLS},
  author       = {Rather, Sajad Ahmad and Das, Sujit and Çiftçioğlu, Aybike Özyüksel},
  doi          = {10.1007/s12530-024-09634-0},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-33},
  shortjournal = {Evol. Syst.},
  title        = {COVID-19 chest CT scan image segmentation based on chaotic gravitational search algorithm},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A domain adaptation technique through cluster boundary integration. <em>EVOLS</em>, <em>16</em>(1), 1-21. (<a href='https://doi.org/10.1007/s12530-024-09635-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many machine learning models deployed on smart or edge devices experience a phase where there is a drop in their performance due to the arrival of data from new domains. This paper proposes a novel unsupervised domain adaptation algorithm called DIBCA++ to deal with such situations. The algorithm uses only the clusters’ mean, standard deviation, and size, which makes the proposed algorithm modest in terms of the required storage and computation. The study also presents the explainability aspect of the algorithm. DIBCA++ is compared with its predecessor, DIBCA, and its applicability and performance are studied and evaluated in two real-world scenarios. One is coping with the Global Navigation Satellite System activation problem from the smart logistics domain, while the other identifies different activities a person performs and deals with a human activity recognition task. Both scenarios involve time series data phenomena, i.e., DIBCA++ also contributes towards addressing the current gap regarding domain adaptation solutions for time series data. Based on the experimental results, DIBCA++ has improved performance compared to DIBCA. The DIBCA++ has performed better in all human activity recognition task experiments and 82.5% of experimental scenarios on the smart logistics use case. The results also showcase the need and benefit of personalizing the models using DIBCA++, along with the ability to transfer new knowledge between domains, leading to improved performance. The adapted source and target models have performed better in 70% and 80% of cases in an experimental scenario conducted on smart logistics.},
  archive      = {J_EVOLS},
  author       = {Devagiri, Vishnu Manasa and Boeva, Veselka and Abghari, Shahrooz},
  doi          = {10.1007/s12530-024-09635-z},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Evol. Syst.},
  title        = {A domain adaptation technique through cluster boundary integration},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient cluster-based deep anomaly detection based traffic analysis and multi-objective optimization for smarter traffic control. <em>EVOLS</em>, <em>16</em>(1), 1-26. (<a href='https://doi.org/10.1007/s12530-024-09636-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the need for an efficient traffic management system, this paper introduces the Integrated Traffic Analysis and Optimization (ITAO) methodology. This innovative method combines two powerful techniques: Cluster-based Deep Anomaly Detection (CDAD) and the Nelder–Mead Pareto African Vultures Optimization Algorithm (NelPareto AVOA). Together, they tackle the major challenges of urban traffic. Using large amounts of traffic data from various sources, ITAO can identify complex traffic patterns, quickly detect unusual conditions, and make real-time adjustments. This paper details the steps of collecting and processing data, using CDAD for deep analysis and feature extraction. It highlights the use of a time-decay function in DBSCAN clustering and Temporal Deep Belief Networks to better understand traffic patterns and detect anomalies. Furthermore, ITAO employs a multi-objective optimization strategy to achieve several goals: maximizing traffic flow, reducing congestion, improving energy efficiency, and enhancing pedestrian safety. The NelPareto AVOA, inspired by nature, ensures that traffic signals and patterns are analyzed and optimized in real-time, adapting to the changing urban environment. Across various datasets, ITAO achieves superior predictive accuracy, consistently delivering the lowest Root Mean Square Error (RMSE) values. For instance, in PEMS-BAY, the RMSE is approximately 15.5 for a batch size of 10 and rises to 16.0 for larger batches. Similarly, in METR-LA, the RMSE starts at 14.0 for a batch size of 10 and increases to 15.0 at batch size 40. INRIX-SEA follows a similar trend, with an RMSE of 15.0 at a batch size of 10, reaching 16.0 for larger sizes. The RMSE for PeMSD4 begins at 14.5 and rises to 15.5, while for PeMSD8, it starts at 15.0, increasing to 16.0 for larger batches. In addition to its accuracy, ITAO excels in classification tasks, as illustrated by True Positive Rate (TPR) values. At specific False Positive Rate (FPR) levels, ITAO outperforms other methods with TPR ranging from 0.9 to 1.0, while methods like WKNN-FDCN achieve TPR values from 0.7 to 1.0. Other models perform less robustly: STAWnet shows TPR between 0.4 and 0.9, PGCN from 0.3 to 0.8, VDGCNet from 0.2 to 0.7, DSTF from 0.1 to 0.5, and DL from 0.0 to 0.4. These results, combined with ITAO's ability to optimize multiple objectives such as traffic flow, energy efficiency, and pedestrian safety, highlight its effectiveness over existing methods.},
  archive      = {J_EVOLS},
  author       = {Soni, Ravikant and Soni, Sunita and Nagwanshi, Kapil Kumar},
  doi          = {10.1007/s12530-024-09636-y},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Evol. Syst.},
  title        = {Efficient cluster-based deep anomaly detection based traffic analysis and multi-objective optimization for smarter traffic control},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Location metadata extraction from geosocial data of road accident using deep learning models. <em>EVOLS</em>, <em>16</em>(1), 1-13. (<a href='https://doi.org/10.1007/s12530-024-09637-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Road accident detection and prevention is one of the most challenging problems in the research field revolving around a multitude of problems that need to be addressed. In this context, the research includes creating an automated system to extract geosocial data from multiple sources like news articles and leverage the power of deep learning techniques to classify the collected data as road accidents and extract the useful metadata such as time and date of road accident, location of accident, etc. The news articles are classified into three classes namely non-road accident news, particular road accident, and generic road accident using Word2Vec-based and LSTM-based models. For the combination of LSTM model with K(5)-Fold CV, the road accident news classification model obtains the highest accuracy of about 96%. For location metadata extraction, BERT (Bidirectional Encoder Representations from Transformers)-based baseline models (DBBCS, DTRS, DRBS, DRLS, BLUWwmFS, BLCWwmFS, DBUDS, DBCDS) have also been compared based on various performance metrics such as exact match (EM) and F1-scores. The BLCWwmFS (bert-large-cased-whole-word-masking-finetuned-squad) is found to be the best performing model with an EM and F1-scores of 0.645 and 0.673 respectively for location metadata extraction.},
  archive      = {J_EVOLS},
  author       = {Mukherjee, Trishit and Sinhahajari, Soumitra and Mukherjee, Debargha and Mallick, Hrishikesh and Middya, Asif Iqbal and Roy, Sarbani},
  doi          = {10.1007/s12530-024-09637-x},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Evol. Syst.},
  title        = {Location metadata extraction from geosocial data of road accident using deep learning models},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple attribute group decision making based on $$p,q$$ -quasirung orthopair bonferroni mean operators and their applications. <em>EVOLS</em>, <em>16</em>(1), 1-23. (<a href='https://doi.org/10.1007/s12530-024-09638-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Bonferroni mean (BM) operator provides a strategy for justifying the effects of unrealistic aggregation values while simultaneously capturing the interconnections between input arguments. Moreover, $$p,q$$ -quasirung orthopair fuzzy ( $$p,q-$$ -QOF) sets is a new development in fuzzy set (FS) theory that allows for more accurate and nuanced management and representation of uncertain data. In this paper, we integrate the concept of $$p,q$$ -QOF numbers ( $$p,q$$ -QOFNs) and extend the BM operators to accommodate $$p,q$$ -QOF information. To aggregate diverse preferences of decision-makers, we first present some Bonferroni mean and weighted Bonferroni mean averaging operators for $$p,q$$ -QOFNs. Subsequently, we construct a decision-making (DM) framework utilizing the proposed operators within the context of $$p,q$$ -QOF sittings, demonstrated through a numerical illustration. Finally, we compare the presented approach with existing methods to establish the practicality and feasibility of the proposed DM process.},
  archive      = {J_EVOLS},
  author       = {Rahim, Muhammad and Ahmad, Sadique and Younis, B. A. and Egami, Ria H. and Ahmed, Mohammed Mustafa},
  doi          = {10.1007/s12530-024-09638-w},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Evol. Syst.},
  title        = {Multiple attribute group decision making based on $$p,q$$ -quasirung orthopair bonferroni mean operators and their applications},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning models to forecast toxicity in conversation threads by identifying potential toxic users. <em>EVOLS</em>, <em>16</em>(1), 1-16. (<a href='https://doi.org/10.1007/s12530-024-09639-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While most conversations on social media platforms promote freedom of expression, some can take a harmful turn, potentially impacting users’ mental well-being. Therefore, it’s imperative to monitor and moderate these discussions. Significant efforts have been made to classify conversations as either toxic or non-toxic. However, post-detection toxicity methods are insufficient. In the proposed work, our focus lies on predicting the toxicity level of conversations before they cause harm. We aim to preemptively address toxic conversations by forecasting the degree of toxicity in advance. Our approach integrates essential user behavior features to optimize toxicity forecasting. Leveraging various learning models such as State Space, Convolution Neural Network (CNN), Long-short Term Memory (LSTM), Bi-directional Long-short Term Memory (Bi-LSTM), and Ensemble models, we analyze features like the proportion of toxic replies and the similarity of toxicity patterns to those of the most toxic users in the dataset. Our proposed method significantly surpasses state-of-the-art models, demonstrating around six-fold improvement. Additionally, it achieves an 82.31% reduction in mean average error and a 78.3% reduction in root mean squared error compared to the state-of-the-art.},
  archive      = {J_EVOLS},
  author       = {Ranjith, Snigdha and Chowdary, C. Ravindranath and Tiwari, Paras},
  doi          = {10.1007/s12530-024-09639-9},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Evol. Syst.},
  title        = {Learning models to forecast toxicity in conversation threads by identifying potential toxic users},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-heuristic algorithms for influence maximization: A survey. <em>EVOLS</em>, <em>16</em>(1), 1-28. (<a href='https://doi.org/10.1007/s12530-024-09640-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization (IM) is a key problem in social network analysis, which has attracted attention of many scholars due to the wide range of applications, the variety of IM algorithms have been proposed from different perspectives. In this paper, we review IM algorithms from the perspective of meta-heuristic optimization, proposed a two-layer structure taxonomy to organize almost all the meta-heuristic IM algorithms. The initial layer, predicated upon the delineation of problem construction models, stratifies IM algorithms into two categories: single-objective and multi-objective IM algorithms. Subsequently, the secondary layer discerns between evolution-based and population intelligence-based IM algorithms, delineating them according to the underlying conceptual frameworks, a detailed exposition and analysis ensue. Subsequent scrutiny involves an exhaustive evaluation of the merits and demerits inherent in each IM algorithm, juxtaposing considerations such as time complexity and experimental validation methodologies. Furthermore, we distill myriad strategies aimed at enhancing accuracy and mitigating time complexity across the four phases of the algorithmic process. Finally, based on the above analysis, the challenges and future directions of IM problems are outlined from the perspective of algorithms, applications and models.},
  archive      = {J_EVOLS},
  author       = {Fan, Chencheng and Wang, Zhixiao and Zhang, Jian and Zhao, Jiayu and Meng, Xianfeng},
  doi          = {10.1007/s12530-024-09640-2},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Evol. Syst.},
  title        = {Meta-heuristic algorithms for influence maximization: A survey},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel metaheuristic population algorithm for optimising the connection weights of neural networks. <em>EVOLS</em>, <em>16</em>(1), 1-23. (<a href='https://doi.org/10.1007/s12530-024-09641-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficacy of feed-forward multi-layer neural networks relies heavily on their training procedure, where identifying appropriate weights and biases plays a pivotal role. Nonetheless, conventional training algorithms such as backpropagation encounter limitations, including getting trapped in sub-optimal solutions. To rectify these inadequacies, metaheuristic population algorithms are advocated as a dependable alternative. In this paper, we introduce a novel training methodology termed, DDE-OP, which leverages the principles of differential evolution enriched with a division-based scheme and an opposite-direction strategy. Our approach integrates two effective concepts with differential evolution. Initially, the proposed algorithm identifies partitions within the search space through a clustering algorithm and designates the obtained cluster centres to serve as representatives. Subsequently, an updating scheme incorporates these clusters into the current population. Lastly, a quasi-opposite-direction strategy is used to augment search space exploration. Extensive evaluation on diverse classification and approximation tasks demonstrate that DDE-OP surpasses conventional and population-based methodologies.},
  archive      = {J_EVOLS},
  author       = {Mousavirad, Seyed Jalaleddin and Schaefer, Gerald and Rezaee, Khosro and Oliva, Diego and Zabihzadeh, Davood and Chakrabortty, Ripon K. and Mohammadigheymasi, Hamzeh and Pedram, Mehdi},
  doi          = {10.1007/s12530-024-09641-1},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Evol. Syst.},
  title        = {A novel metaheuristic population algorithm for optimising the connection weights of neural networks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AFLF: A defensive framework to defeat multi-faceted adversarial attacks via attention feature fusion. <em>EVOLS</em>, <em>16</em>(1), 1-20. (<a href='https://doi.org/10.1007/s12530-024-09643-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attacks threaten the reliability and security of Deep Neural Networks (DNNs), necessitating the need to develop robust defensive mechanisms beyond traditional defensive approaches. The perceptible and imperceptible input perturbations, when fed to Deep Learning (DL) models, could lead to a distortion of the feature space and can change the predictions. The proposed study designed a novel defensive strategy to enhance the robustness of classification and detection models against a wide range of adversarial attacks. The study introduced a two-stage defensive framework by using a unique integration of extracting robust feature representations, attention feature fusion, and model agnostic adversarial learning of features. The attention mechanism facilitates the effective combination of extracted features from different dimensions based on their relevancy to an adversarial nature using the Z-score method. It can lead to more efficient use of resources. After that, the model agnostic adversarial feature learning trains the model with original features and their adversarial counterparts to learn robust representations invariant to multi-faceted adversarial changes. The proposed work is then extensively evaluated against benchmark datasets of traffic signs and assessed for effectiveness against various adversarial attacking strategies. The improvements in robustness of the proposed defensive mechanism are demonstrated in terms of defense accuracy, fooling rate, and clean data accuracy loss. Ultimately, the proposed approach offers a practical and innovative defensive solution and contributes to advancing the field of adversarial defensive strategies by emphasizing a robust set of features without compromising the loss of clean data accuracy.},
  archive      = {J_EVOLS},
  author       = {Dhamija, Lovi and Bansal, Urvashi},
  doi          = {10.1007/s12530-024-09643-z},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Evol. Syst.},
  title        = {AFLF: A defensive framework to defeat multi-faceted adversarial attacks via attention feature fusion},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A network traffic data generation model based on AOT-DDPM for abnormal traffic detection. <em>EVOLS</em>, <em>16</em>(1), 1-18. (<a href='https://doi.org/10.1007/s12530-024-09644-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the Internet, network security issues have become increasingly prominent, and accurate detection of abnormal traffic has become a research hotspot in this field. However, in the actual detection, the imbalance of traffic data leads to the low accuracy of model detection. The above problems can be effectively solved by generating traffic data. However, the existing data generation models are difficult to reflect the potential sample distribution of the generated objects and the model training is unstable, which leads to the low quality of the generated samples. To solve the above problems, this paper proposes a network traffic generation model based on AOT-DDPM. Firstly, the model proposed an adaptive sampling strategy in the reverse diffusion process, which dynamically updated the number of samples in each class by learning the distribution of the original data and the imbalance of each class to improve the quality of generated samples. Secondly, using the Transformer network as the core structure of the reverse process to effectively capture the feature distribution between data and improve the model’s data generation performance. Finally, the ODE Solver was introduced to generate data, so as to generate high-quality samples in shorter time steps, and finally obtain balanced data. Through verification on three public datasets, the experimental results show that the AOT-DDPM model is superior to other comparison methods in terms of the effectiveness of data generation, and can solve the problems of data generation in the field of network abnormal traffic detection.},
  archive      = {J_EVOLS},
  author       = {Gong, Xingyu and Chen, Siyu and Li, Na},
  doi          = {10.1007/s12530-024-09644-y},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Evol. Syst.},
  title        = {A network traffic data generation model based on AOT-DDPM for abnormal traffic detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple phases modified termite life cycle optimizer for data clustering and engineering optimization. <em>EVOLS</em>, <em>16</em>(1), 1-33. (<a href='https://doi.org/10.1007/s12530-024-09645-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Termite life cycle optimizer (TLCO) is a recently introduced swarm intelligence metaheuristic algorithm inspired by the intricate behaviors exhibited by termite colonies, demonstrating competitive performance compared to other state-of-the-art algorithms. However, the original TLCO encounters challenges related to unbalanced exploration and exploitation, low convergence accuracy, and premature stagnation of iterations in high-dimensional complex applications. To address these issues, this study introduces an enhanced variant of the termite life cycle optimizer, referred to as the modified termite life cycle optimizer (MTLCO). The MTLCO introduces multiple novel phases for optimizing complex computational problems. Key among these are the Best Agent Guide Phase and the transition factor (TF) phase, which aim to steer the optimization in a more directed manner. Additionally, the Control Randomization Value and Direction serve to introduce randomness with precision, ensuring diversity in the solution space. The Phasor Operator Phase, an innovative mechanism, aids in further improving the convergence rate. Taking cues from other meta-heuristic paradigms, a new phase rooted in the Whale optimization algorithm (WOA) strategy has been incorporated, providing a more adaptive search mechanism. To counter stagnation and premature convergence, a Restart Strategy has been devised, facilitating a fresh search whenever required. For comprehensive validation, the enhanced MTLCO has been integrated into the Bonobo Optimizer and evaluated using the CEC’20 benchmark functions. Furthermore, its effectiveness is underscored by promising outcomes in five intricate engineering problems and 15 data clustering challenges. Comparative analyses with conventional methods affirm the superior performance, robustness, and versatility of the proposed MTLCO.},
  archive      = {J_EVOLS},
  author       = {Zebiri, Ibrahim and Abdel Samee, Nagwan and Alkanhel, Reem and Batra, Harshit and Hashim, Fatma A.},
  doi          = {10.1007/s12530-024-09645-x},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-33},
  shortjournal = {Evol. Syst.},
  title        = {Multiple phases modified termite life cycle optimizer for data clustering and engineering optimization},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An evolving approach to the similarity-based modeling for online clustering in non-stationary environments. <em>EVOLS</em>, <em>16</em>(1), 1-30. (<a href='https://doi.org/10.1007/s12530-024-09646-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel evolving approach based on the Similarity-Based Modeling (SBM), a technique widely used in industrial applications of anomaly detection and multiclass classification. The proposed approach, which inherits from SBM, uses a simple model-matrix composed of historical points to represent each cluster. Its inference procedure for a given input instance consists only of generating an estimate, considering each cluster, and then assigning the input to the most similar cluster according to a novel membership function that considers approximation error and data density. The main features of our approach include a simple and intuitive learning scheme, the ability to model clusters of any shape without using micro-cluster-like procedures, robustness to noisy data, and low computational effort. We evaluate the effectiveness of the proposed approach on fifteen datasets widely used in the literature, assessing its ability to deal with overlapping clusters, clusters with arbitrary shape, noisy data, and high dimensionality. Using Adjusted Rand Index (ARI) and Purity metrics, the proposed algorithm was compared with eight recent state-of-the-art algorithms, and the proposed method achieved the highest performance on most of the datasets. On the remaining datasets, it showed similar performance to other methods. Averaging over the fifteen datasets, our approach achieved an ARI value of 0.8872 and a Purity value of 0.9107. The most competitive method, considering ARI, achieved an average value of 0.6988, and considering Purity, achieved an average value of 0.9257. This shows the effectiveness of the proposed approach.},
  archive      = {J_EVOLS},
  author       = {Almeida, Nayron Morais and Camargos, Murilo Osorio and Mariano, Denis G. B. and Bomfim, Carlos H. M. and Palhares, Reinaldo M. and Caminhas, Walmir M.},
  doi          = {10.1007/s12530-024-09646-w},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Evol. Syst.},
  title        = {An evolving approach to the similarity-based modeling for online clustering in non-stationary environments},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolving medical image classification: A three-tiered framework combining MSPLnet and IRNet-VGG19. <em>EVOLS</em>, <em>16</em>(1), 1-27. (<a href='https://doi.org/10.1007/s12530-024-09647-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of images is an important process in the revolution of big data in healthcare. For classification and diagnosis, several developments have considerably improved digital clinical image processing. In many applications of medical imaging, medical image classification is a very essential task. Convolutional Neural Networks (CNNs) have displayed better performance in the classification of images for medical systems. However, CNN and conventional standardized classifiers suffer limitations in their performance due to a few reliability concerns, such as overfitting issues, feature extraction inefficiencies, and computational complexity. Therefore, a novel approach to medical image classification is proposed in this paper employing a three-tiered model that differs from conventional frameworks of multi-class classification to overcome these problems. In the first tier, the preparation of data includes the collection and transformation of five various clinical types of datasets such as Octoscope, Skin Cancer (PAD-UFES-20), The Kvasir dataset, Covid-19 dataset, and Chest X-Ray Images (Pneumonia). The stage of pre-processing guarantees the raw data is cleansed and organized for efficient analysis and training. In the second tier, sophisticated feature extraction utilizes a Multi-head Self-attention Progressive Learning Network on pre-processed data. The mechanism of Multi-head Self-attention and the techniques of Progressive Learning are leveraged to improve feature extraction, providing superior performance than traditional methods. In the third tier, the classification of features that are extracted is performed through Inception Residual Network-VGG19 (IRNet-VGG19), which combines the strengths of both Inception modules and the deep architecture of VGG19 to upgrade the accuracy of classification further. By evaluating all five datasets, the performance of IRNet-VGG19 shows better classification outcomes when compared with other existing approaches. The accuracies of classification on five different datasets are achieved as 0.993, 0.966, 0.994, 0.984, and 0.968 respectively, outperforming other challenging methods.},
  archive      = {J_EVOLS},
  author       = {Annapoorani, G. and Manikandan, P. and Genitha, C. Heltin},
  doi          = {10.1007/s12530-024-09647-9},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Evol. Syst.},
  title        = {Evolving medical image classification: A three-tiered framework combining MSPLnet and IRNet-VGG19},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep adaptive fusion with cross-modality feature transition and modality quaternion learning for medical image fusion. <em>EVOLS</em>, <em>16</em>(1), 1-26. (<a href='https://doi.org/10.1007/s12530-024-09648-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today's rapidly advancing medical landscape, the integration of information from multiple imaging modalities, known as medical fusion, stands at the forefront of diagnostic innovation. This approach combines the strengths of diverse techniques such as magnetic resonance imaging (MRI), computed tomography (CT), positron emission tomography (PET), and single-photon emission computed tomography (SPECT) to offer a more comprehensive view of a patient's condition. Issues such as data heterogeneity, where varied resolutions and contrasts must be harmonized, complicate the seamless integration of imaging data. The complexity of interpreting fused images demands specialized training for clinicians and raises concerns about potential diagnostic errors. This work presents the deep adaptive fusion (Deep-AF) model for image fusion in multimodal biomedical scans includes MRI, CT, PET, and SPECT. This Deep-AF model integrates convolutional neural network (CNN)-based decision maps, deep sparse coding, cross-modality feature transition, and fusion techniques. Three pre-processing steps, including intensity normalization, noise reduction, and spatial registration, are initially applied to enhance alignment and quality in fused images. Non-subsampled contourlet thresholding (NSCTT) is employed to address challenges related to intensity, resolution, and contrast differences among modalities, facilitating multi-scale and multidirectional representation. Despite challenges in spatial alignment, interpretation across modalities, and model generalization, the proposed gradient-weighted class activation mapping with CNN (GradCAM-CNN) enhances interpretability by visualizing crucial regions for CNN predictions. Deep sparse coding fusion (DSCF) overcomes challenges through the adaptive learning of complex features, capturing high-level features while enforcing sparsity. The cross-modality feature transition mechanism (CMFTM) addresses variations in modality characteristics. The attention weighted averaging network (AtWANet) addresses challenges in multimodal feature fusion by dynamically assigning weights based on relevance, providing a flexible approach despite misalignment and scale variations. AtWANet's model training optimizes the fusion process by dynamically assigning attention weights to each modality, ensuring effective integration of varied representations. Simulation results obtains that the proposed Deep-AF model obtains robust fusion results in terms of statistical and accuracy metrics.},
  archive      = {J_EVOLS},
  author       = {Srivastava, Somya and Bhatia, Shaveta and Agrawal, Arun Prakash and Jayswal, Anant Kumar and Godara, Jyoti and Dubey, Gaurav},
  doi          = {10.1007/s12530-024-09648-8},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Evol. Syst.},
  title        = {Deep adaptive fusion with cross-modality feature transition and modality quaternion learning for medical image fusion},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ERDA: Evolving robotic dragonfly algorithm for target search in unknown multi-robot environment. <em>EVOLS</em>, <em>16</em>(1), 1-19. (<a href='https://doi.org/10.1007/s12530-024-09649-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Target search in an unknown environment is a major challenge in disaster relief, hazardous areas, finding leak sources, and surveillance. This paper proposes an Evolving Robotic Dragonfly Algorithm (ERDA) to conduct the target search using a multi-robot team. It works as the distributed control mechanism for the robots. The swarm behaviors of dragonflies in the Dragonfly Algorithm (DA) are improved to solve the multi-robot target search problem. The robot that exhibits the best fitness acts as the leader of the team. The leader robot utilizes the gradient information to evolve the search direction towards the target. ERDA employs an adaptive inertia weight to improve the diversity in the team. The enemy-eluding behavior of DA is adapted to support obstacle avoidance. These factors enhance the performance of the proposed algorithm. The ERDA is rigorously evaluated and compared with existing algorithms. Experiments are conducted in simple and cluttered environments with varying count of obstacles. Also, experiments are carried out with varying number of robots and different environment sizes to study the efficiency and effectiveness of the proposed method. ERDA improved the success rate by 7.41% and reduced the mean iteration count by 53.29% in the cluttered environment. The results obtained indicate that ERDA exhibits better performance than the existing methods.},
  archive      = {J_EVOLS},
  author       = {Joseph, Dani Reagan Vivek and Ramapackiyam, Shantha Selvakumari},
  doi          = {10.1007/s12530-024-09649-7},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Evol. Syst.},
  title        = {ERDA: Evolving robotic dragonfly algorithm for target search in unknown multi-robot environment},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STAC-HNN: A spatio-temporal auto-correlation based location recommendation using hypergraph neural network. <em>EVOLS</em>, <em>16</em>(1), 1-14. (<a href='https://doi.org/10.1007/s12530-024-09650-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location recommendation normally used recurrent neural networks (RNNs), which often overlooked higher-order dependencies and similar subsequences that encapsulate latent user preferences. Meanwhile category information was underutilized. In this paper, we propose STAC-HNN, a spatio-temporal auto-correlation based model using hypergraph neural networks, to address these limitations. STAC-HNN captures both local and global signal representations: the global module leverages hypergraph neural networks to model high-order interactions among user trajectories and POI categories, while the local module employs a spatio-temporal weight matrix and self-attention mechanisms to uncover relations between non-adjacent locations and visits. Additionally, a bi-task network independently and collaboratively learns users’ POI and category preferences, enhancing model performance. Experiments on three real-world datasets show that STAC-HNN significantly outperforms state-of-the-art methods in next POI recommendation. To facilitate future research, we release the codes at https://github.com/chenshone/STAC-HNN.},
  archive      = {J_EVOLS},
  author       = {Zhou, Jianxing and Lu, Jing},
  doi          = {10.1007/s12530-024-09650-0},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Evol. Syst.},
  title        = {STAC-HNN: A spatio-temporal auto-correlation based location recommendation using hypergraph neural network},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emergence of flocking behaviors transferring previously evolved alignment robot controllers. <em>EVOLS</em>, <em>16</em>(1), 1-12. (<a href='https://doi.org/10.1007/s12530-024-09651-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flocking is a crucial collective behavior in swarm robotics. Reynolds introduced the boids model as a means to imitate flocking behaviors in artificial agents. This model relies on three fundamental local rules: separation, cohesion, and alignment. This paper examines the development of flocking behaviors only through the evolution of the alignment rule. Initially, we employ a genetic algorithm to develop the alignment behavior inside a group of stationary robots. The advanced alignment robot controller is a continuous-time recurrent neural network (CTRNN). Afterwards, we include the developed controller into a three-layered subsumption architecture in order to accomplish flocking behavior. Aside from the advanced alignment behavior, the architecture also incorporates a rudimentary manually designed obstacle avoidance behavior and a subroutine for moving forward. The initial experiment centers on the progression of alignment among the robots. Advanced communication techniques result in a scalable and precise alignment, where both the message content and its related context are very pertinent. The second experiment investigates the development of flocking behavior. The results indicate that the suggested subsumption architecture is capable of achieving efficient flocking behaviors. In addition, the robot swarm has the ability to navigate around barriers and continue to exhibit flocking behavior once the impediments have been bypassed. Our research indicates that the formation of a cohesive group can occur by implementing a single developed rule, complemented with well designed actions for avoiding obstacles and navigating the environment.},
  archive      = {J_EVOLS},
  author       = {Sendra-Arranz, Rafael and Gutiérrez, Álvaro},
  doi          = {10.1007/s12530-024-09651-z},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Evol. Syst.},
  title        = {Emergence of flocking behaviors transferring previously evolved alignment robot controllers},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based compression and encryption of CT images for secure telemedicine applications. <em>EVOLS</em>, <em>16</em>(1), 1-20. (<a href='https://doi.org/10.1007/s12530-024-09652-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective management of the enormous volume of medical images for storage and transmission is crucial, particularly in telemedicine applications, where medical image compression and encryption play a significant role. In medical imaging, Computed Tomography is the famed tool for diagnosis. Prior, diverse research work has been conducted in the field of telemedicine for compressing and encrypting Computed Tomography images. However, the schemes have less compression ratio, more encryption time, and poor performance. To address these difficulties, this research proposes a novel DeepTeleNet strategy for effectively compressing and encrypting the Computed Tomography image. The DeepTeleNet framework utilizes a Hybrid Dilated Convolution U-Net for the segmentation of Region of Interest-based computed Tomography image that enables the model to capture more spatial information. The Hybrid Dilated convolution U-Net framework incorporates an Adaptive Attention Fusion Module, which mitigates the irrelevant information and enhances the feature representation in the Region of Interest area by the utilization of the Channel Attention Module and Spatial Attention Module. Additionally, the proposed strategy deployed an Adaptive Arithmetic and Adaptive Huffman encoding for Region of Interest lossless compression, where the Adaptive Arithmetic encoding dynamically adjusts the probability estimates as per the observed frequencies and the Adaptive Huffman encoding dynamically updates the trees as data is processed. Moreover, the enhanced Autoencoder is employed for the lossy compression of non- Region of Interest that integrates the Convolutional Autoencoder network and Principal Component Analysis. Further, the proposed strategy utilizes multiple chaotic maps with Sparse Lifting Wavelet Transform to authenticate Computed Tomography images by embedding an encrypted watermark into the images. The experimental result demonstrates that the DeepTeleNet scheme effectively compressed and encrypted the computed Tomography images and achieved a higher compression ratio, and lower encryption time of 57.8241%, and 0.09 s compared to existing methodologies, underscores its effectiveness in Computed Tomography image compression and encryption, making it a promising solution for telemedicine application.},
  archive      = {J_EVOLS},
  author       = {Rosaline, S. and Paulraj, D.},
  doi          = {10.1007/s12530-024-09652-y},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Evol. Syst.},
  title        = {Deep learning-based compression and encryption of CT images for secure telemedicine applications},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid mountain gazelle particle swarm-based algorithm for constrained optimization problems. <em>EVOLS</em>, <em>16</em>(1), 1-32. (<a href='https://doi.org/10.1007/s12530-024-09654-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nature inspired techniques have been essential in addressing complex, non-linear and non-convex optimization problems. Combining two or more techniques is useful to improve accuracy, adaptability and efficiency in solving complex problems to handle the uncertainties and non-linearity effectively. In this paper, we introduce a hybrid approach called Mountain Gazelle Particle Swarm Optimization (MGPSO) which merges Particle Swarm Optimization (PSO) and Mountain Gazelle optimization (MGO) to improve problem-solving abilities. PSO has certain limitations in exploration but strong exploitation capabilities, while MGO has a strong exploration by enabling a more diverse and extensive search space. Keeping this in mind, we have integrated PSO with the MGO algorithm to strength of both algorithm and hence to improve the performance in solving complex optimization problems. The performance of the proposed hybrid algorithm has been tested against 23 benchmark functions of varying complexity, structural design problems and 12 IEEE CEC22 (IEEE Congress on Evolutionary Computation 2022) functions. The results computed are compared with several of the existing state-of-art literature. Experimental results shows that proposed MGPSO performs significantly better than other existing algorithms. Among the 23 benchmark functions, MGPSO archives superior results in 16 and for 12 CEC22 function, proposed algorithm excels in 10. Additionally, the MGPSO results are validated through the statistical analysis test.},
  archive      = {J_EVOLS},
  author       = {Rani, Rekha and Garg, Vanita and Jain, Sarika and Garg, Harish},
  doi          = {10.1007/s12530-024-09654-w},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-32},
  shortjournal = {Evol. Syst.},
  title        = {A hybrid mountain gazelle particle swarm-based algorithm for constrained optimization problems},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Impact of displayed inventory level in a two-warehouse system for deteriorating item with discount facilities via different metaheuristic algorithms. <em>EVOLS</em>, <em>16</em>(1), 1-25. (<a href='https://doi.org/10.1007/s12530-025-09657-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the balance between exploration and exploitation stages is very crucial for preventing local optima when using metaheuristic algorithms to solve optimization problems. This is made by a number of procedures, including hybridization and search agent improvement. This work deals with the modelling of single deteriorating item based two-warehouse inventory system with variable demand depending on time, frequency of advertisement and displayed inventory level. Customers’ waiting time dependent partially backlogged shortages are allowed. Moreover, price break facilities are available for the retailer. In the proposed model, transportation costs for replenishing the items as well as for transferring the item from rented warehouse to owned warehouse are considered. Based on displayed inventory level and capacity of owned warehouse, different cases are investigated and the corresponding optimization problems are developed. An extended version of hybrid Tournament Differential Algorithm (TDE) is applied to solve the said optimization problem. Then the same problem is solved by differential evolution and teaching learning based optimization algorithm and the obtained results are compared with TDE algorithm. Finally, a numerical example along with sensitivity analysis (graphically) is carried out to illustrate the proposed model and also to explore how the changes in key model parameters effect on optimal policy. To analyze the statistical interpretation of different metaheuristic algorithms, a non-parametric test is performed.},
  archive      = {J_EVOLS},
  author       = {Halder, Partha and Mandal, Goutam and Mondal, Rajan and Bhunia, Asoke Kumar},
  doi          = {10.1007/s12530-025-09657-1},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Evol. Syst.},
  title        = {Impact of displayed inventory level in a two-warehouse system for deteriorating item with discount facilities via different metaheuristic algorithms},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted FedCOM: A communication efficient approach to federated learning. <em>EVOLS</em>, <em>16</em>(1), 1-8. (<a href='https://doi.org/10.1007/s12530-025-09659-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapidly expanding domain of federated learning, characterized by decentralized training across multiple clients, often grapples with challenges tied to client reliability and bandwidth constraints. This paper introduces the Weighted Federated Communication (Weighted FedCOM) paradigm-an innovative enhancement over traditional federated learning approaches. At its core, Weighted FedCOM seamlessly integrates the robustness of weighted aggregation with the efficiency gains from model compression. By assigning weights to client contributions based on the accuracy of their local models, our approach ensures that more reliable models exert a greater influence on the global aggregated model. Concurrently, the incorporation of model compression techniques offers substantial reductions in communication overhead, a typical bottleneck in federated learning. Preliminary evaluations demonstrate that Weighted FedCOM significantly outperforms conventional federated learning methodologies in terms of convergence speed and global model accuracy. This research illuminates a promising avenue for bolstering the efficacy and efficiency of federated learning in diverse, decentralized systems.},
  archive      = {J_EVOLS},
  author       = {Kaushal, Vishal and Sharma, Sangeeta},
  doi          = {10.1007/s12530-025-09659-z},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-8},
  shortjournal = {Evol. Syst.},
  title        = {Weighted FedCOM: A communication efficient approach to federated learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient malware detection based on machine learning for enhanced cloud privacy protection. <em>EVOLS</em>, <em>16</em>(1), 1-17. (<a href='https://doi.org/10.1007/s12530-025-09661-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing environments are increasingly popular due to their flexibility and scalability, but they also present significant security challenges, particularly in the form of malware attacks. These malicious attacks exploit weaknesses within cloud infrastructures, which can result in serious repercussions like data breaches, unauthorized system access, and identity theft. In this paper, we introduce an innovative malware detection classifier specifically designed to overcome the shortcomings of conventional machine learning algorithms, such as K-Nearest Neighbor (KNN) and Support Vector Machine (SVM), in the unique context of cloud environments. Our proposed method relies on Log-spectral distance as a fundamental metric, which enables a more precise and effective approach to detecting malware. Through rigorous and extensive experimentation, our findings demonstrate that this novel classifier achieves an outstanding accuracy rate of 97% without the need for feature selection—surpassing the 95% accuracy attained when employing feature selection through the Mutual Information (MI) method. Additionally, our classifier outperforms both traditional machine learning (ML) and deep learning (DL) techniques, showcasing its robustness and dependability in identifying malware threats within cloud settings. The results of our study underscore the classifier's potential to serve as a crucial tool for enriching security in cloud environments. This advanced solution not only contributes to academic research but also offers practical applications for safeguarding cloud infrastructures against the continuously evolving landscape of malware threats.},
  archive      = {J_EVOLS},
  author       = {Baawi, Salwa Shakir and Oleiwi, Zahraa Ch. and Al-Muqarm, Abbas M. Ali and Al-Shammary, Dhiah and Sufi, Fahim},
  doi          = {10.1007/s12530-025-09661-5},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Evol. Syst.},
  title        = {Efficient malware detection based on machine learning for enhanced cloud privacy protection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature augmentation-based CNN framework for skin-cancer diagnosis. <em>EVOLS</em>, <em>16</em>(1), 1-11. (<a href='https://doi.org/10.1007/s12530-025-09662-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic skin-cancer detection is an area in computer vision in which convolutional neural networks (CNNs) have shown remarkable performance since they have proved to be very efficient image feature extractors. Nevertheless, developing an efficient skin-cancer detection model in real world scenarios is a challenging task, since skin-cancer image datasets are characterized by instances with a large amount of noise and redundant information. Therefore, it is essential to develop an efficient augmentation method in order to create robust and diverse image representations. For this task, we propose a feature augmentation-based method, which enlarges the dimension of skin-cancer image representations. In this approach different types of augmentation functions mainly composed of noise-based injection functions, such as hair and microscope effect, are injected into the initial representation. Subsequently, they are used to extract different types of features based on pre-trained CNN backbones such as ResNet and DenseNet. All these different types of feature embeddings are concatenated together creating an augmented multi-feature representation of the initial image instance. However, in order to remove redundant information and reduce the large multi-dimension of the CNNs’ output feature embeddings, we incorporate U-Map dimensional reduction method. Finally, the compressed feature embedding is used for training an XGBoost model in order to perform the final classification task. The main findings of this work are that the proposed methodology achieved an accuracy of 0.929 (via 10-fold cross-validation), significantly improving CNN performance in skin-cancer diagnosis and outperforming state-of-the-art image classification and skin-cancer detection CNN frameworks.},
  archive      = {J_EVOLS},
  author       = {Pintelas, Emmanuel and Livieris, Ioannis E. and Tampakas, Vasilis and Pintelas, Panagiotis},
  doi          = {10.1007/s12530-025-09662-4},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Evol. Syst.},
  title        = {Feature augmentation-based CNN framework for skin-cancer diagnosis},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An explainable AI based new deep learning solution for efficient heart disease prediction at early stages. <em>EVOLS</em>, <em>16</em>(1), 1-25. (<a href='https://doi.org/10.1007/s12530-025-09664-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate predictive models are crucial for early detection and intervention of Heart Disease (HD), which continues to be a major cause of death worldwide. However, the challenges of high dimensionality and data imbalance affect the precision and generalizability of predictions. We propose a novel deep model, the Fully Connected Wave Network (FCW-Net), for early HD prediction. To mitigate class imbalance, Proximity Weighted Synthetic (ProWSyn) oversampling technique is employed, while Principal Component Analysis (PCA) is used to reduce dimensionality, enhancing model efficiency and prediction accuracy. With an AUC-ROC of 0.9622, an accuracy of 0.9237, a precision of 0.8856, an F1-score of 0.9268, and a recall of 0.9721, our results demonstrate that the FCW-Net deep model achieves superior performance than baseline models when using PCA and ProWSyn. Model transparency is further improved by eXplainable Artificial Intelligence technique, SHapley Additive exPlanations analysis, which provides insights into feature contributions to HD risk.},
  archive      = {J_EVOLS},
  author       = {Ashfaq, Muhammad Talha and Javaid, Nadeem and Alrajeh, Nabil and Ali, Syed Saqib},
  doi          = {10.1007/s12530-025-09664-2},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Evol. Syst.},
  title        = {An explainable AI based new deep learning solution for efficient heart disease prediction at early stages},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HDTN: Hybrid duo-transformer network for liver and hepatic tumor segmentation in CT images. <em>EVOLS</em>, <em>16</em>(1), 1-20. (<a href='https://doi.org/10.1007/s12530-025-09665-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hepatic tumor segmentation from Computed Tomography (CT) images relies on intelligent computer-aided algorithms for early detection and precision diagnosis. Combining multi-level learning concepts improves the precision of segmentation and detection from any image type. In this article, a Hybrid Duo-Transformer Network (HDTN) is designed to improve the precision of hepatic tumor segmentation from any quality of CT input. The proposed network model assimilates a self-attuned transformer and cascaded dilated layer for improving the segmentation accuracy. This hybrid model is designed to eradicate the problem of pixel dissolving issues in low-quality CT images. By extracting the intensity and saturation features, the transformer network identifies the segmentation boundary using a cross pixel present in the dissolving region. For this purpose, this network requires a minimum of 1 × 1 block of the input image. Following this boundary detection, the dilated layer is responsible for verifying the intensity within the least possible block region. The high-intensity outcomes are further extracted to converge the segmentation region. The failing intensities due to saturation are used to train the convolution layer to reduce the transboundary error pixels. Thus, the converged final block is the segmented region from the CT input with high precision. The proposed model improves the segmentation precision by 11.51% and intensity analysis by 8% and reduces the mean error by 9.09% for the different boundaries.},
  archive      = {J_EVOLS},
  author       = {Mohanapriya, D. and Sekar, T. Guna},
  doi          = {10.1007/s12530-025-09665-1},
  journal      = {Evolving Systems},
  month        = {2},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Evol. Syst.},
  title        = {HDTN: Hybrid duo-transformer network for liver and hepatic tumor segmentation in CT images},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
