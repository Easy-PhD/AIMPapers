<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JIIS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jiis">JIIS - 91</h2>
<ul>
<li><details>
<summary>
(2025). DeepVulHunter: Enhancing the code vulnerability detection capability of LLMs through multi-round analysis. <em>JIIS</em>, <em>63</em>(6), 2237--2264. (<a href='https://doi.org/10.1007/s10844-025-00982-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the economic losses caused by software vulnerabilities continue to escalate, automated vulnerability detection has emerged as a crucial demand in software engineering. While current Large Language Model (LLM)-based approaches demonstrate promising capabilities for vulnerability detection, they still face significant challenges including susceptibility to non-vulnerability factors like code length, severe hallucination issues, and unsatisfactory detection accuracy and balance. To overcome these limitations, we propose DeepVulHunter, a novel multi-round detection framework that utilizes Retrieval Augmented Generation (RAG) technique to provide code snippets semantically similar to the target code and their associated vulnerability information. Extensive experiments conducted across five representative models from the Llama and Deepseek series confirm that our method effectively mitigates these challenges while enhancing both accuracy and balance in vulnerability detection tasks for general large models. The best-performing Llama-405B model achieves a detection accuracy of up to 75.3%, surpassing the current state-of-the-art approach that utilizes GPT-4 with Chain-of-Thought (CoT) prompting.},
  archive      = {J_JIIS},
  author       = {Jiao, Yutong and Han, Jiaxuan and Huang, Cheng},
  doi          = {10.1007/s10844-025-00982-0},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {2237--2264},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {DeepVulHunter: Enhancing the code vulnerability detection capability of LLMs through multi-round analysis},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting cognitive process-driven model with sentiment-infused user preference for recommendation. <em>JIIS</em>, <em>63</em>(6), 2203--2235. (<a href='https://doi.org/10.1007/s10844-025-00980-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning leverages textual feedback and contextual cues to improve rating prediction accuracy through simulated cognitive reasoning. User reviews provide critical insights for accurate preference modeling. Sentiment analysis identifies intrinsic preferences and behavioral patterns, improving user requirement comprehension. An attention-based deep learning framework with sentiment-infused preference modeling (DeepSU) is proposed to emulate human cognition effectively. Multidimensional preferences are captured by extracting salient features from travel platforms. Sentiment consistency detection identifies anomalous reviews by comparing inferred sentiment with ratings to refine the dataset. A co-attention mechanism integrates user features and sentiment estimations through learned attention weights, generating embeddings that encode personalized characteristics and affective tendencies toward attractions. Experimental results demonstrate that DeepSU outperforms the strongest baseline by 15.2% and 13.3% on the Ctrip travel dataset. It achieves lower RMSE than baseline methods under data sparsity and maintains performance advantages as the input scale increases, while keeping training time minimal. Ablation studies indicate that the sentiment analysis module contributes more significantly to overall performance than the user preference module. Evaluations on datasets from two distinct travel platforms demonstrate consistent superiority over baseline techniques, confirming robust generalization and reliability.},
  archive      = {J_JIIS},
  author       = {Chen, Tingting and Lin, Suqing and Wu, Jingheng and Zhang, Shuhua},
  doi          = {10.1007/s10844-025-00980-2},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {2203--2235},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Revisiting cognitive process-driven model with sentiment-infused user preference for recommendation},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combined GNN specialized in inductive prediction and PLM for natural language inductive reasoning. <em>JIIS</em>, <em>63</em>(6), 2177--2201. (<a href='https://doi.org/10.1007/s10844-025-00979-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inductive reasoning involves abstracting general principles from specific instances. It primarily relies on rules derived from relationships and is minimally dependent on specific data about entities, such as people, places, or organizations. Pre-trained language models (PLM) tend to focus on learning statistical features within a corpus. Thus, when inductive reasoning is expressed in a natural language, PLMs face challenges in learning the logical relations behind the text. Recently, researchers have explored graph neural network (GNN) architectures that excel in inductive inference on knowledge graphs (KGs) for inductive link prediction tasks; however, their application to natural language remains limited. To address the natural language inductive reasoning tasks, we propose a framework that utilizes a specific GNN module specialized in inductive link prediction as a reasoning mechanism. To construct inputs inferable to GNN from natural language, we first apply insights from a study of relation extraction tasks and use PLM to obtain embeddings for edge-related inferences. Subsequently, the newly designed module performs edge scoring and initializes the relation embeddings. The scores are used to prune the edges and are learned through edge weighting within the decoder. Experimental results on text datasets requiring logical inductive reasoning demonstrate that the proposed method notably improves PLM performance, outperforming the baselines. Furthermore, robustness evaluation on subsets provided by CLUTRR shows that our model surpasses other relational reasoning-based models in its ability to learn from and generalize noisy data.},
  archive      = {J_JIIS},
  author       = {Tomei, Koki and Hagiwara, Masafumi},
  doi          = {10.1007/s10844-025-00979-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {2177--2201},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Combined GNN specialized in inductive prediction and PLM for natural language inductive reasoning},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLIMONIIE: Large language instructed model for open named italian information extraction. <em>JIIS</em>, <em>63</em>(6), 2147--2175. (<a href='https://doi.org/10.1007/s10844-025-00978-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of unstructured documents generated daily underscores the urgent need to develop technologies to structure information effectively. Traditional Information Extraction (IE) models enable the transformation of textual data into structured formats (e.g., semantic triplets), facilitating efficient searches and uncovering hidden data insights. However, they require predefined ontologies and, often, extensive human efforts. On the other hand, Open IE tools extract information without any input knowledge, but they are limited in capturing entire and in-depth contexts. Furthermore, the state of the art presents a substantial discrepancy between the efforts carried out in English-centric methods and those in low-resource languages, such as Italian. Our study aims to address the aforementioned key challenges. To this end, we first define Open Named Information Extraction (ONIE), an approach that generalizes IE across diverse domains without requiring input ontologies and captures complex relationships. Then, we develop LLIMONIIE (Large Language Instructed Model for Open Named Italian Information Extraction), a novel end-to-end generative information extraction framework that leverages the capabilities of Large Language Models (LLMs) to perform ONIE from Italian documents, able to extract Named Entities and Open Relations uniformly. Furthermore, we devise an innovative dataset generation methodology to support our research. Finally, we release the code and dataset, contributing to the scientific community and the development of low-resource languages. Experiments demonstrate the potential of our proposal, achieving competitive results compared to the actual state of the art of Italian IE.},
  archive      = {J_JIIS},
  author       = {Piano, Leonardo and Pisu, Alessia and Tiddia, Sandro Gabriele and Carta, Salvatore and Giuliani, Alessandro and Pompianu, Livio},
  doi          = {10.1007/s10844-025-00978-w},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {2147--2175},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {LLIMONIIE: Large language instructed model for open named italian information extraction},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generation method of suspense stories based on new-type inference. <em>JIIS</em>, <em>63</em>(6), 2109--2145. (<a href='https://doi.org/10.1007/s10844-025-00977-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of artificial intelligence technology, its application in the field of creative writing has gradually become a research hotspot, especially in the generation of suspense stories. How to enhance the dramatic tension of suspense story plots while maintaining narrative coherence is an important challenge currently faced by researchers. This paper proposes a method for generating suspense stories based on a novel type of inference, aiming to advance the development of automatic suspense story generation technology. First, a new semantic knowledge framework—situation graph—is constructed, which can not only capture the semantics of micro-scenes but also dynamically track the evolution of the story. Second, the Psycho-Computational Suspense Model (PCSM) is proposed, which transforms psychological suspense heuristic rules into inferential constraint indicators and integrates them into the inference search process as suspense factors. Finally, Suspense-Aware Monte Carlo Tree Search (SA-MCTS) is introduced, which drives large language models (LLMs) to generate suspense stories through a co-evolution mechanism of dual inference paths. Experiments demonstrate that the proposed method has achieved significant results in terms of plot complexity, character depth, and suspense creation, providing new ideas and approaches for the development of automatic suspense story generation technology.},
  archive      = {J_JIIS},
  author       = {Bu, Wenjuan and Li, Zhuolun and Sha, Zihan and Zhao, Yuntian},
  doi          = {10.1007/s10844-025-00977-x},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {2109--2145},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Generation method of suspense stories based on new-type inference},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-distillation-based approach for detecting poisoning attacks in recommender systems. <em>JIIS</em>, <em>63</em>(6), 2079--2107. (<a href='https://doi.org/10.1007/s10844-025-00976-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of recommendation systems, some offenders inject a large number of malicious user profiles into the rating system to generate favorable recommendation results for themselves. Such attacks are referred to as “poisoning attacks”, which severely infringe upon the legitimate rights and interests of users and also cause losses to the interests of platforms and merchants. Poisoning attack detection is crucial for maintaining the security of recommender systems. However, existing poisoning attack detections mainly consider the user relationship with similar interaction histories, ignoring the implicit relationship between suspicious items and malicious users. Moreover, current poisoning attack detection methods based on graph convolutional neural networks ignore the differences in the ability of different layers of graph-based detectors to distinguish malicious users. To solve the above problems, we propose a poisoning attack detection method based on cross-distillation. First, we use singular value decomposition to extract four features from user and item implicit feature vectors to mine suspicious target items and construct a weighted suspicious user relationship graph by the maximum item suspicious degree between users. Then, we utilize noise and edge discard to augment the weighted suspicious user relationship graph, and use a cross-distillation model with different layers of teacher and student models to learn the user embeddings and employ class-wise loss to mitigate the imbalance classification and improve the learned embeddings. Finally, we combine different student models to detect malicious users. Experiments on three datasets show that our detection model outperforms the baseline models.},
  archive      = {J_JIIS},
  author       = {Wang, Zetian and Song, Weiming and Zhang, Peng and Ma, Ru and Zhang, Fuzhi},
  doi          = {10.1007/s10844-025-00976-y},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {2079--2107},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Cross-distillation-based approach for detecting poisoning attacks in recommender systems},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards robust multimodal emotion recognition in conversation with multi-modal transformer and variational distillation fusion. <em>JIIS</em>, <em>63</em>(6), 2057--2077. (<a href='https://doi.org/10.1007/s10844-025-00975-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Emotion Recognition in Conversation (MERC) utilizes multimodal information such as language, visual, and audio to enhance the understanding of human emotions. Current multimodal interaction frameworks inadequately resolve inherent information conflicts and redundancy due to their assumption of equivalent quality across heterogeneous modalities. In addition, inappropriate evaluation of the importance of modalities can also cause this problem. To address this issue, we introduce a $$\textbf{L}$$ anguage- $$\textbf{F}$$ ocused Augmented Transformer with $$\textbf{V}$$ ariational $$\textbf{D}$$ istillation Fusion network called $$\textbf{LFVD}$$ . In contrast to previous work, we suggest focusing on language modality through the Language-Focused Augmented Transformer, which extracts task-relevant signals from visual and audio modalities to help us understand language. Concurrently, this architecture derives conversational emotional atmosphere representation to refine multimodal integration, thereby mitigating the influence of redundant and conflicting information. Furthermore, Variational Distillation Fusion has been proposed in which multimodal representations are probabilistically encoded as variational distributions over Gaussian manifolds rather than deterministic embeddings. Subsequently, the importance of each modality is estimated automatically based on distribution differences. Experiments on the IEMOCAP and MELD datasets show that our proposed model outperforms previous state-of-the-art baseline models.},
  archive      = {J_JIIS},
  author       = {Zhu, Xiaofei and Jiang, Shuming},
  doi          = {10.1007/s10844-025-00975-z},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {2057--2077},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Towards robust multimodal emotion recognition in conversation with multi-modal transformer and variational distillation fusion},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). $$A^{2} h^{2}$$ for multimodal emotional data analysis. <em>JIIS</em>, <em>63</em>(6), 2031--2055. (<a href='https://doi.org/10.1007/s10844-025-00974-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As multimodal sentiment analysis technology continues to evolve, it is increasingly important to accurately capture and interpret sentiment information from different modalities. However, the traditional attention mechanism model employs a fixed number of attention heads across different attention levels, which makes it difficult to flexibly capture feature information at varying levels in text. This paper has proposed a deformable improvement strategy, comprising two key elements: Adaptive Attention Hierarchy and Head Optional Strategy, collectively referred to as the $$A^{2} H^{2}$$ strategy. The experimental results demonstrate that the sentiment analysis model shows improved performance, with an accuracy of 87.97% using the $$A^{2} H^{2}$$ strategy. In comparison to the prevailing sentiment analysis models, this deformable improvement strategy not only enhances the accuracy rate, but also reduces the information redundancy, improves the extraction efficiency of important features, and maintains the computational efficiency of the model in large-scale tasks. The codes are available at https://github.com/mmm587/A2H2 .},
  archive      = {J_JIIS},
  author       = {Wu, Jun and Liu, Jinyu and Zhang, Tianfeng and Guo, Shuai and Chen, Yu and Huang, Jiahui and Deng, Fang},
  doi          = {10.1007/s10844-025-00974-0},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {2031--2055},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {$$A^{2} h^{2}$$ for multimodal emotional data analysis},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep recommendation model based on semantic information and correlation between items. <em>JIIS</em>, <em>63</em>(6), 2007--2029. (<a href='https://doi.org/10.1007/s10844-025-00973-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The data sparsity problem constrains traditional recommendation methods, and the recommendation methods based on review texts effectively alleviate the sparsity of rating data by capturing user profiles and item attibutes from review texts. However, many of them ignore the fact that there exists a wealth of correlation information between items. This correlation information may help the recommender system understand the similarity between items and accordingly recommend to users items they may be interested in, which helps to improve the accuracy and diversity of recommendations. Based on the idea raised above, we propose a deep learning model based on semantic information and correlation between items (SMCI), which extracts rich semantic information from review texts and converts it into vector representation. This representation not only incorporates sentiment and topic information in reviews but also captures the correlation between users and items. In order to fully incorporate the correlation features between items, SMCI maps items’ similar representations in vector space based on users’ purchase sequences and predicts final ratings using the scaled dot product’s multi-head self-attention mechanism. Comparative experiments are conducted on seven public datasets. The experimental results show that the proposed model outperforms the baselines in terms of performance, which verifies the validity of our model.},
  archive      = {J_JIIS},
  author       = {Duan, Jiani and Hu, Jun and Zhong, Fujin and Liu, Li and Zhang, Qinghua},
  doi          = {10.1007/s10844-025-00973-1},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {2007--2029},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A deep recommendation model based on semantic information and correlation between items},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiffAste: A gini-adaptive diffusion-based data augmentation approach for aspect sentiment triplet extraction. <em>JIIS</em>, <em>63</em>(6), 1981--2006. (<a href='https://doi.org/10.1007/s10844-025-00972-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect Sentiment Triplet Extraction (ASTE), a core fine-grained sentiment analysis task, faces severe class imbalance, especially in neutral sentiment labels, which undermines model performance. Existing data augmentation methods for ASTE suffer from three key limitations: semantic inconsistencies, lack of complex entity structures, and inability to generate samples with specific sentiment labels. Moreover, current approaches fail to dynamically regulate the volume of augmented data, leading to suboptimal class distribution balancing. To address these challenges, we propose A Gini-Adaptive Diffusion-based Data Augmentation Approach for Aspect Sentiment Triplet Extraction (DiffAste). To our knowledge, this represents the first application of diffusion models to ASTE data augmentation, where the proposed method systematically combines masked matrices with conditional diffusion processes to generate linguistically diverse templates while rigorously preserving original entity semantics and sentiment orientations. We introduce a semantic filtering mix-up strategy to mitigate generative-model-induced noise and employ a KL divergence constraint to ensure the generation of neutral sentiment samples. We further design a Gini-Adaptive Sample Controller to utilize the Gini coefficient, dynamically balancing sample generation. Through extensive experiments, our approach achieves significant improvements, elevating F1 scores by 1% to 2% across all four sub-datasets while reducing the Gini coefficient by up to 0.14, demonstrating its effectiveness in class imbalance mitigation.},
  archive      = {J_JIIS},
  author       = {Huang, Jia and Yang, Lan and Wu, Like and Chen, Yifei},
  doi          = {10.1007/s10844-025-00972-2},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1981--2006},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {DiffAste: A gini-adaptive diffusion-based data augmentation approach for aspect sentiment triplet extraction},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From news to trends: A financial time series forecasting framework with LLM-driven news sentiment analysis and selective state spaces. <em>JIIS</em>, <em>63</em>(6), 1955--1980. (<a href='https://doi.org/10.1007/s10844-025-00971-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock price prediction is inherently challenging due to market volatility and the influence of external factors. Traditional forecasting methods primarily rely on historical price data, limiting their ability to capture market sentiment embedded in financial news. To address this limitation, we propose MambaMoE, a novel model that integrates historical stock prices with sentiment information extracted from financial news. Specifically, we fine-tune a DeepSeek-based large language model (LLM) for financial sentiment classification and incorporate the extracted sentiment information into our predictive framework. At the core of our approach is MambaMoE layer, which leverages the efficiency of state space models (SSMs) to model long-range dependencies while maintaining linear computational complexity, making it well-suited for financial time series forecasting. Additionally, the Mixture of Experts (MoE) mechanism improves the model’s ability to capture diverse market behaviors by dynamically selecting specialized experts based on stock data patterns. Experimental results demonstrate that MambaMoE outperforms LSTM-based models by 23.7% and Transformer-based models by 6.3%, highlighting its superior performance in short-term stock prediction.},
  archive      = {J_JIIS},
  author       = {Wang, Renjie and Sun, Minghui and Wang, Limin},
  doi          = {10.1007/s10844-025-00971-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1955--1980},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {From news to trends: A financial time series forecasting framework with LLM-driven news sentiment analysis and selective state spaces},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Context-aware chatbot for personal healthcare assistance using LLMs and LangChain. <em>JIIS</em>, <em>63</em>(6), 1921--1953. (<a href='https://doi.org/10.1007/s10844-025-00970-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chatbots have the potential to offer personalized responses and information to improve patients’ healthcare. However, contextual accuracy is critical because the lack of context awareness may endanger patients’ lives. This research addresses this issue by configuring the GPT-3.5-turbo language model, i.e. adjusting parameters, such as temperature and maximum token limit, and configuring with external knowledge bases using the retrieval-augmented-generation (RAG) approach, chain-of-thought (CoT) prompt engineering techniques using chains within the LangChain framework. We visualized and traced the results using the LangSmith platform, showing that all the chains and retrievers better understood the context. Our healthcare chatbot, intended for patients seeking personalized medical guidance before going to the doctor, was evaluated against ChatGPT using expert evaluation and meta-eval metrics. Evaluation results demonstrate that the proposed medical chatbot exhibits better contextual accuracy, conciseness, and coherence. Thus, this research highlights the potential of integrating the large language model techniques, with RAG, and prompt engineering, and also suggests the frameworks and evaluation methods for language model-based chatbots, to develop context-aware healthcare chatbots for personalized medical assistance.},
  archive      = {J_JIIS},
  author       = {Fatima, Syeda Kaneez and Arshad, Shazia and Hassan, Muhammad Awais and Iqbal, Faiza and Altaf, Ayesha and Aziz, Iram and Ashraf, Imran and Samee, Nagwan Abdel},
  doi          = {10.1007/s10844-025-00970-4},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1921--1953},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Context-aware chatbot for personal healthcare assistance using LLMs and LangChain},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing inter-sentence coherence of extractive summarization with multitask learning. <em>JIIS</em>, <em>63</em>(6), 1891--1919. (<a href='https://doi.org/10.1007/s10844-025-00967-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extractive summarization is a widely applied technique in information extraction, information retrieval and natural language processing (NLP) applications. However, traditional methods often struggle to maintain inter-sentence coherence in the extracted summaries. This paper proposes a multitask learning architecture for extractive summarization with coherence boosting. The architecture contains an extractive summarizer and a coherence discriminator module. The coherence discriminator is trained online using augmented sentence sequences. Its task is to judge whether the input sentences (embeddings) form a coherent sequence. Meanwhile, we maximize the coherent scores from the coherence discriminator by updating the parameters of the summarizer. Updating mechanisms of different modules by three learning objectives is designed for effective training. To make the sentence selection procedure differentiable for training, we apply a Gumbel-softmax function with a straight-through trick. Two representation merging strategies are introduced to ensure that the coherence discriminator always takes a sequence of sentence representations without masking vectors. Experiments show that our proposed method significantly improves the proportion of consecutive sentences in extracted summaries based on their positions in the original article, while goodness in terms of relevance metrics (i.e., Rouge scores and BertScores) are preserved. In addition, model-based evaluation (UniEval) and human evaluation also evidence the significant improvement in coherence and consistency of the extracted summaries given by the enhanced extractive summarizer.},
  archive      = {J_JIIS},
  author       = {Jie, Renlong and Meng, Xiaojun and Lifeng, Shang and Xin, Jiang and Liu, Qun},
  doi          = {10.1007/s10844-025-00967-z},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1891--1919},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Enhancing inter-sentence coherence of extractive summarization with multitask learning},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic-aware fake news detection with heterogeneous graph attention. <em>JIIS</em>, <em>63</em>(6), 1865--1890. (<a href='https://doi.org/10.1007/s10844-025-00966-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media unintentionally helps spread fake news, which threatens public trust and social stability. Existing detection methods typically model the sequential or co-occurrence relationships between words in news texts to extract semantic features of fake news content. Although effective, they still struggle with perceiving the fine-grained semantics of news content. They often overlook deeper semantic dependencies and fail to consider the varying contributions of different types of words to semantic expression. To tackle these challenges, we present a semantic-aware fake news detection method with heterogeneous graph attention (SHGAT). First, we construct a heterogeneous textual graph to capture the internal semantic dependencies and external knowledge associations in news posts by integrating relationships between semantic elements such as entity words, pattern words, and concept descriptions. To further enhance the fine-grained semantic perception of post content, we design a heterogeneous graph-based encoder with a dual-level attention mechanism to learn post patterns and knowledge-enhanced entity semantics. Additionally, an adaptive feature aggregation module is introduced to automatically select and optimize feature combinations. Extensive experiments conducted on two benchmark datasets demonstrate that our model achieves state-of-the-art accuracy, outperforming existing methods in the literature by approximately 2.9%.},
  archive      = {J_JIIS},
  author       = {Chen, Jing and Zhou, Gang and Lan, Mingjing and Wang, Shiyu and Li, Shunhang and Lu, Jicang},
  doi          = {10.1007/s10844-025-00966-0},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1865--1890},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Semantic-aware fake news detection with heterogeneous graph attention},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparing data reduction strategies for energy-efficient green recommender systems. <em>JIIS</em>, <em>63</em>(6), 1837--1863. (<a href='https://doi.org/10.1007/s10844-025-00965-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As recommendation algorithms become increasingly sophisticated and pervasive, their energy consumption and associated carbon emissions are rising significantly. To address this growing environmental concern, this work investigates the path toward ‘green recommender systems’ by examining how data reduction techniques can impact on algorithm performance and carbon footprint. We specifically investigated whether and how a reduction of the training data impacts the performance of several representative recommendation algorithms. To obtain a fair comparison, all the algorithms were run based on the implementations available in a popular recommendation library, i.e., RecBole, and by using the same experimental settings. Specifically, we employed distinct data reduction strategies: (a) random sampling of either users or item ratings; (b) reducing the overall dataset size; (c) filtering out more recent user ratings. Results indicate that data reduction can be a promising strategy to make recommender systems more environmentally sustainable with a relevant reduction in carbon emissions at the cost of a smaller reduction in predictive accuracy $$\varvec{-43.38\%}$$ of emissions for LightGCN algorithm and only $$\varvec{3.72\%}$$ loss in accuracy in a book recommendation scenario). Moreover, training recommender systems with less data makes the suggestions less prone to popularity bias. Overall, this study contributes to the ongoing challenge of developing recommendation algorithms that meet the principles of Sustainable Development Goals, by proposing the adoption of more sustainable practices in the field.},
  archive      = {J_JIIS},
  author       = {Spillo, Giuseppe and De Filippo, Allegra and Musto, Cataldo and Milano, Michela and Semeraro, Giovanni},
  doi          = {10.1007/s10844-025-00965-1},
  journal      = {Journal of Intelligent Information Systems},
  month        = {12},
  number       = {6},
  pages        = {1837--1863},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Comparing data reduction strategies for energy-efficient green recommender systems},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging large language models, graph neural networks, and explainable AI for revolutionizing the next-generation network intrusion detection systems. <em>JIIS</em>, <em>63</em>(5), 1807--1835. (<a href='https://doi.org/10.1007/s10844-025-00964-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As digital ecosystems, such as the Internet of Things (IoT), evolve, cyber threats have become increasingly sophisticated, posing greater challenges for Network Intrusion Detection Systems (NIDS). Artificial intelligence, particularly Large Language Models (LLMs), enhances cybersecurity through log analysis, anomaly detection, and threat intelligence. However, optimizing NIDS for real-time detection in dynamic, resource-limited contexts remains a significant challenge. This survey paper provides a comprehensive overview of modern AI-driven methodologies for enhancing NIDS, focusing on transformer-based techniques, graph-based models, and hybrid approaches incorporating explainable AI. LLMs, as transformer-based models, are effective in analyzing complex network data for better anomaly detection and threat prediction. Graph-based models, including Knowledge Graphs (KGs) and Graph Neural Networks (GNNs), are well-suited for relational data modeling and multistage attack identification. Hybrid frameworks combine various methods to improve generalizability, accuracy, and interpretability. The paper also highlights challenges such as data privacy and the need for lightweight architectures, which pave the way for sophisticated, adaptive cyber defenses against emerging threats.},
  archive      = {J_JIIS},
  author       = {AboulEla, Samar G. and Kashef, Rasha F.},
  doi          = {10.1007/s10844-025-00964-2},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1807--1835},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Leveraging large language models, graph neural networks, and explainable AI for revolutionizing the next-generation network intrusion detection systems},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SKT-SQL: Multi-decoupling and skeleton prompt framework for text-to-SQL on small-scale LMs. <em>JIIS</em>, <em>63</em>(5), 1779--1805. (<a href='https://doi.org/10.1007/s10844-025-00963-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the strong coupling between schema linking and structural parsing in text-to-SQL tasks for small-scale language models, as well as the neglect of SQL skeleton guidance in existing decoupling methods, this paper proposes SKT-SQL, a multi-stage decoupling framework. The framework redesigns the generation process through a three-stage decoupling mechanism: (1) leveraging a schema decoupler to eliminate irrelevant schema items and reduce semantic noise; (2) predicting query hardness to generate an abstract SQL skeleton, forming a structured template with operator logic; (3) utilizing the skeleton as dynamic prompts to guide a transformer-based seq2seq T5 model in precisely filling specific schema items, followed by execution-guided beam search to derive the final SQL query. This "structure-first, entity-later" paradigm eliminates the need to simultaneously resolve syntactic complexity and schema correlations, significantly reducing cognitive load. Experiments on the Spider 1.0 benchmark show that SKT-SQL-base achieves 80.8% execution accuracy (EX), surpassing the 12 $$\times$$ larger T5-3B model by 6.4% and outperforming T5-base by 22.9%. Compared to existing decoupling-based methods, this framework still demonstrates prominent application value, with skeleton prompting notably enhancing small-scale model performance. This study proves that explicit modeling of SQL syntactic skeletons can break through the structured semantic parsing bottleneck of small-scale language models, offering a novel paradigm for database interaction tasks in low-resource scenarios. Our code is available at https://github.com/JarvenYi/SKT-SQL.},
  archive      = {J_JIIS},
  author       = {Yi, Jiawen and Chen, Guo},
  doi          = {10.1007/s10844-025-00963-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1779--1805},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {SKT-SQL: Multi-decoupling and skeleton prompt framework for text-to-SQL on small-scale LMs},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning constraint orderings for direct diagnosis. <em>JIIS</em>, <em>63</em>(5), 1753--1777. (<a href='https://doi.org/10.1007/s10844-025-00962-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to efficiently resolve conflicts in interactive constraint-based applications is critical for user experience and system reliability. Conflict resolution can be regarded as a specific type of explanation, often denoted as diagnosis. Existing work on integrating machine learning with diagnostic reasoning emphasizes on the combination of hitting set approaches with probabilistic reasoning and memory-based machine learning. An alternative to such two-phase diagnosis approaches is direct diagnosis, which focuses on determining diagnoses without predetermining conflicts. In this article, we utilize diagnosis knowledge from the past to improve diagnosis efficiency while also maintaining user-defined preference criteria. Our approach integrates model-based collaborative filtering (feed-forward neural networks) and other machine learning approaches (e.g., logistic regression and random forest) with direct model-based diagnosis (FastDiag). The re-ordering of constraints as input to the diagnosis algorithm increases the efficiency of diagnostic reasoning for determining preference-preserving diagnoses. Through experiments on real-world configuration knowledge bases (B2C, BusyBox, EA and Linux kernel), we demonstrate significant runtime improvements and high accuracy in diagnosis prediction. With this, we also contribute to the growing body of literature on combining machine learning and constraint-based reasoning.},
  archive      = {J_JIIS},
  author       = {Uta, Mathias and Le, Viet-Man and Felfernig, Alexander and Helic, Denis},
  doi          = {10.1007/s10844-025-00962-4},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1753--1777},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Learning constraint orderings for direct diagnosis},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mental model shifts in human-LLM interactions. <em>JIIS</em>, <em>63</em>(5), 1737--1752. (<a href='https://doi.org/10.1007/s10844-025-00960-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines how humans interact with large language models (LLMs) in real-world, unconstrained settings, focusing on potential shifts in users’ mental models. Initially, many users approach LLMs as traditional software tools, employing structured, machine-like prompts. However, after their first interaction, a notable shift occurs, such as increased politeness, more natural language phrasing, and shorter, more contextually nuanced prompts. That is, users increasingly adopt conversational behaviors typical of human-to-human communication and, in turn, this suggests a cognitive transition in the way users perceive and engage with AI systems. Analyzing over 200,000 conversations with computational linguistics methods, we find initial indications supporting this change. These insights have implications for AI design, trust, and ethical concerns, highlighting the need for further research beyond a mostly computational perspective to strengthen our findings on how users cognitively frame their interactions with AI.},
  archive      = {J_JIIS},
  author       = {Schneider, Johannes},
  doi          = {10.1007/s10844-025-00960-6},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1737--1752},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Mental model shifts in human-LLM interactions},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DeepFinLLM: An intelligent financial advisor unleashing strategic insights with large language models. <em>JIIS</em>, <em>63</em>(5), 1713--1736. (<a href='https://doi.org/10.1007/s10844-025-00959-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demand for sophisticated advisory systems has intensified in the contemporary financial landscape, necessitating innovative solutions that deliver precise and timely insights for investors. Traditional financial models frequently encounter limitations, including inflexibility, dependence on static datasets, and inadequate adaptability to user-specific requirements. To address these challenges, we propose DeepFinLLM, a hybrid financial advisory system that integrates a state-of-the-art language model, specifically the DeepSeek Chat V3 0324, with the Financial Modeling Prep API. DeepFinLLM utilizes various financial data sources, encompassing historical market data, real-time financial news, and user-generated data, while employing advanced natural language processing techniques for comprehensive analysis. DeepFinLLM features semantic query parsing and hybrid retrieval systems to enhance the accuracy of financial question answering. Moreover, it provides personalized financial advice tailored to individual user preferences and incorporates continuous learning capabilities, significantly enhancing its applicability in today’s dynamic financial environment. This innovative system processes complex financial queries in real-time, achieving a notable accuracy rate of 94.2%, an F1 score of 0.92 in stock predictions, and an Exact Match rate of 87.5% in identifying relevant financial insights. DeepFinLLM serves as a robust solution for both expert and novice investors, facilitating informed decision-making and effectively navigating the complexities of the financial landscape.},
  archive      = {J_JIIS},
  author       = {Reddy, Veerababu and Veeranjaneyulu, N.},
  doi          = {10.1007/s10844-025-00959-z},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1713--1736},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {DeepFinLLM: An intelligent financial advisor unleashing strategic insights with large language models},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Survival concept-based learning models. <em>JIIS</em>, <em>63</em>(5), 1687--1711. (<a href='https://doi.org/10.1007/s10844-025-00958-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept-based learning enhances prediction accuracy and interpretability by leveraging high-level, human-understandable concepts. However, existing CBL frameworks do not address survival analysis tasks, which involve predicting event times in the presence of censored data – a common scenario in fields like medicine and reliability analysis. To bridge this gap, we propose two novel models: SurvCBM (Survival Concept-based Bottleneck Model) and SurvRCM (Survival Regularized Concept-based Model), which integrate concept-based learning with survival analysis to handle censored event time data. The models employ the Cox proportional hazards model and the Beran estimator. SurvCBM is based on the architecture of the well-known concept bottleneck model, offering interpretable predictions through concept-based explanations. SurvRCM uses concepts as regularization to enhance accuracy. Both models are trained end-to-end and provide interpretable predictions in terms of concepts. Two interpretability approaches are proposed: one leveraging the linear relationship in the Cox model and another using an instance-based explanation framework with the Beran estimator. Numerical experiments demonstrate that SurvCBM outperforms SurvRCM and traditional survival models, underscoring the importance and advantages of incorporating concept information. The code for the proposed algorithms is publicly available.},
  archive      = {J_JIIS},
  author       = {Kirpichenko, Stanislav R. and Utkin, Lev V. and Konstantinov, Andrei V. and Verbova, Natalya M.},
  doi          = {10.1007/s10844-025-00958-0},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1687--1711},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Survival concept-based learning models},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A method for multimodal sentiment analysis: Adaptive interaction and multi-scale fusion. <em>JIIS</em>, <em>63</em>(5), 1667--1686. (<a href='https://doi.org/10.1007/s10844-025-00957-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the potential issue of introducing irrelevant emotional data during the fusion of multimodal representations and the challenge of neglecting critical information at different scales within the sequence information after fusion, this study innovatively proposes the Adaptive Interaction and Multi-Scale Fusion Model (AIMS). Initially, multimodal feature fusion is achieved through the interaction of text features with video features and audio features respectively. Subsequently, two feature vectors related to text are subjected to deep interactive fusion to generate a comprehensive modal representation, thereby enhancing the expression of text-related information. Then, the model clearly employs a multi-scale feature pyramid network structure for feature extraction at multiple scales, effectively fusing sequence information in the integrated modal representation and capturing key sequence features in multimodal data. Finally, the multimodal fusion module integrates the final modal representation for more effective Multimodal Sentiment Analysis(MSA). Experimental results demonstrate that the AIMS model outperforms existing sentiment analysis models on the CMU-MOSEI, CMU-MOSI, CH-SIMSv2 and MELD datasets.},
  archive      = {J_JIIS},
  author       = {Wang, HaiLong and Cao, JiaXin and Liu, JinJin and Song, Jie},
  doi          = {10.1007/s10844-025-00957-1},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1667--1686},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A method for multimodal sentiment analysis: Adaptive interaction and multi-scale fusion},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KQFV: A knowledge-enhanced method using question answering for fact verification. <em>JIIS</em>, <em>63</em>(5), 1645--1666. (<a href='https://doi.org/10.1007/s10844-025-00956-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fact verification refers to the process of detecting false information based on evidence texts, a task that presents significant challenges. Current research faces issues such as the neglect of long-distance semantic dependencies and interference caused by redundant information. To address these challenges, this paper proposes a knowledge-enhanced method that incorporates question answering for fact verification. The method first introduces a question answering protocol pipeline to capture and classify fine-grained information while filtering out redundant data. Then it improves knowledge using this fine-grained information and constructs a graph with various types of entity nodes to uncover the potential semantic relationships between evidence and claims. The experimental results on the FEVER dataset demonstrate that the proposed method outperforms existing comparative models in both Fever Score (FS) and Label Accuracy (LA), thus validating the effectiveness of the model. On the test set, LA reached 0.748 and FS reached 0.707.},
  archive      = {J_JIIS},
  author       = {Bian, Yexin and Ma, Tinghuai},
  doi          = {10.1007/s10844-025-00956-2},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1645--1666},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {KQFV: A knowledge-enhanced method using question answering for fact verification},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Textual and structural dual enhancement for knowledge graph completion with large language models. <em>JIIS</em>, <em>63</em>(5), 1625--1643. (<a href='https://doi.org/10.1007/s10844-025-00953-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph completion (KGC) aims to predict missing facts in knowledge graphs(KGs). However, KGC faces two significant challenges: (i) low-quality entity descriptions in KGs and (ii) the structural sparsity of KGs. To address these issues, we propose a textual and structural dual enhancement (TSDE) framework that leverages large language models (LLMs) for graph data augmentation, thereby improving the performance of KGC models. To overcome the problem of low-quality entity descriptions, we designed a sampling algorithm to capture multiple paths surrounding entities, transforming this path information into text and integrating it into our carefully designed prompt templates to guide LLMs in generating high-quality descriptions enriched with contextual semantics. Additionally, to address the structural sparsity of KGs, we represent each entity description as a vector and calculate cosine similarity to identify a set of highly similar entities for each entity. We then assign similarity relations to these highly similar entity pairs to generate additional similar triples. After sampling these newly generated similar triples at a specified ratio, we incorporate them into the training set. We validated the effectiveness of the TSDE framework on two publicly available datasets: FB15k-237 and WN18RR. Experimental results demonstrate that the TSDE framework significantly enhances KGC model performance by refining entity descriptions and enriching KG structures.},
  archive      = {J_JIIS},
  author       = {Wang, Liqin and Gan, Yifan and Wang, Xu and Dong, Yongfeng and Xu, Zhihong},
  doi          = {10.1007/s10844-025-00953-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1625--1643},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Textual and structural dual enhancement for knowledge graph completion with large language models},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evidence selection via multi-aspect query diversification for cross-document relation extraction. <em>JIIS</em>, <em>63</em>(5), 1603--1623. (<a href='https://doi.org/10.1007/s10844-025-00952-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-document relation extraction (RE) aims to identify relations between target entities across multiple long documents. Due to the large scale and inherent noise in multi-document corpora, prior works primarily rely on heuristic methods based on bridge entities or capability-limited selectors for evidence sentence selection. However, these approaches often struggle to capture sufficient informative content and latent semantic relations embedded within documents comprehensively. To address this, we propose MAQD, a novel cross-document RE approach that enhances evidence selection through multi-aspect query diversification. Specifically, we construct a knowledge-aware entity graph from the original text and leverage large language models (LLMs) to accomplish multi-faceted query augmentation tasks based on the graph for query diversification. We also employ a multi-aspect reranking and aggregation mechanism to rerank candidate sentences from diverse perspectives and aggregate them to select the most relevant evidence sentences for final relation prediction. Experimental results on the benchmark dataset validate the superiority of MAQD over existing approaches, highlighting its effectiveness in cross-document RE.},
  archive      = {J_JIIS},
  author       = {Wang, Xinyi and Zhu, Xiangrong and Hu, Wei},
  doi          = {10.1007/s10844-025-00952-6},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1603--1623},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Evidence selection via multi-aspect query diversification for cross-document relation extraction},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid transformer-based recommender system for political news. <em>JIIS</em>, <em>63</em>(5), 1569--1601. (<a href='https://doi.org/10.1007/s10844-025-00951-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates a nudging-based news recommender designed to broaden exposure to political articles while preserving user satisfaction. We built a hybrid transformer-based recommender system that combines content-based embeddings (via a custom transformer architecture) with click-behavior signals to refine user profiles. A dedicated profile extension module augments each profile with semantically related concepts, subtly steering recommendations toward political news according to user-existing interests. In an online experiment with 168 participants, our nudging system significantly outperformed a popularity-based baseline (satisfaction: +12.84%, political clicks: +15.35%) and an interest-based baseline (satisfaction: +6.96%, political clicks: +6.44%). Notably, participants with the lowest initial political interest exhibited the largest engagement gains (clicks: +64.54% over popularity, +22.75% over interest) without compromising user satisfaction.},
  archive      = {J_JIIS},
  author       = {Vercoutere, Stefaan and De Pessemier, Toon and Martens, Luc},
  doi          = {10.1007/s10844-025-00951-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1569--1601},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Hybrid transformer-based recommender system for political news},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-aware graph flashback network for next location recommendation. <em>JIIS</em>, <em>63</em>(5), 1539--1567. (<a href='https://doi.org/10.1007/s10844-025-00950-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next Point-of-Interest (POI) recommendation predicts a user’s next likely destination based on historical check-ins, enhancing trip planning and location discovery. Current models, including sequence-based and graph-based approaches, often lack adaptability to temporal variations in relationships and treat graph construction as an isolated pre-training step, limiting their effectiveness. To address these challenges, we propose the Time-aware Graph Flashback Network (TGFN), introducing a Spatial-Temporal Knowledge Graph (STKG) that captures dynamic, time-evolving POI relationships. Our Time-TransH model learns both temporal edge variations and core feature representations, enabling real-time updates through weighted convolutions on location nodes and neighbors. By integrating relationship learning in an end-to-end framework, TGFN ensures accurate node representations. Experiments on real-world datasets show that TGFN significantly outperforms existing methods, achieving higher accuracy across multiple metrics.},
  archive      = {J_JIIS},
  author       = {Gao, Junheng and Liu, Wei and Liang, Shangsong},
  doi          = {10.1007/s10844-025-00950-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1539--1567},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Time-aware graph flashback network for next location recommendation},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic selection of ensemble technique for question answering systems: For indian government dataset. <em>JIIS</em>, <em>63</em>(5), 1511--1537. (<a href='https://doi.org/10.1007/s10844-025-00947-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel strategy for improving a question-answering system by dynamically selecting the best ensemble technique among RoBERTa, BERT, ALBERT, DistilBERT, and ELECTRA language models. A unique metric based on the Average Confidence Score of these models is used to implement dynamic ensemble strategy selection. We test the proposed technique on JUDVLP-QADB.v1, a freshly created question-answering dataset from public Indian government domains. On the JUDVLP-QADB.v1 dataset, the technique improved Exact Match and F1 score significantly. Our ensemble technique selection experiments are two-step. First, we run the same group ensembles with varied language model settings. Second, we combine the best-performing ensembles from different groups to generate cross-group ensembles, and finally we present a novel system for dynamically selecting the ideal ensemble technique. The suggested technique chose the RoBERTa ensemble for the same group and the RoBERTa and DistilBERT ensemble for the cross group during the assessment. After dynamically picking the right ensemble model, we received a maximum Exact Match score of 69.01 and an F1-Score of 83.69. These values show a 15% and 10.31% increase above baseline models. Our study found that dynamically selecting ensembles based on a parameter improves question-answering system performance on the JUDVLP-QADB.v1 test dataset. Our novel ensemble selection method simplifies the procedure by lowering the difficulty of picking from $$\left( {\begin{array}{c}n\\ 2\end{array}}\right) $$ different combinations of ensembles from a set of n models.},
  archive      = {J_JIIS},
  author       = {Pramanik, Sandip and Roy Gupta, Subrata and Das, Nibaran},
  doi          = {10.1007/s10844-025-00947-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1511--1537},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Dynamic selection of ensemble technique for question answering systems: For indian government dataset},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiffKD: Collaborative graph diffusion with knowledge distillation for multimodal recommendation. <em>JIIS</em>, <em>63</em>(5), 1487--1510. (<a href='https://doi.org/10.1007/s10844-025-00946-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal recommendation aims to predict users’ future behaviors based on historical interaction data and item multimodal information. Previous studies face two main issues. First, due to the complexity and high dimensionality of multimodal features, existing methods fail to effectively extract them, and their rich semantic information is often overlooked. Second, false positive and negative noise in user behavior data interferes with preference modeling-especially in Graph Convolutional Network(GCN)-based models, where such noise propagates through the graph and affects node representations. To address these challenges, we propose a knowledge distillation-based collaborative graph diffusion multimodal recommendation model (DiffKD). Specifically, DiffKD adopts a teacher-student framework, where the teacher extracts semantically rich multimodal features and transfers knowledge to the student via a transfer loss. To reduce noise while retaining key interactions, a diffusion model adds and removes noise to generate a user-item graph, which is fused with the original to form a collaborative graph. Finally, a multimodal feature encoder enhances user and item representations by combining high-order collaborative signals from the user-item graph with semantic relationships derived from the item-item graph. Extensive experiments on four public datasets show that DiffKD outperforms the strongest baseline by an average of 6.78%.},
  archive      = {J_JIIS},
  author       = {Ma, WenYu and Xia, HongBin and Liu, Yuan},
  doi          = {10.1007/s10844-025-00946-4},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1487--1510},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {DiffKD: Collaborative graph diffusion with knowledge distillation for multimodal recommendation},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing graph multi-hop reasoning for question answering with LLMs: An approach based on adaptive path generation. <em>JIIS</em>, <em>63</em>(5), 1455--1485. (<a href='https://doi.org/10.1007/s10844-025-00945-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing KG-based LLM reasoning methods often neglect the importance of KG’s structural information for reasoning, facing challenges when dealing with complex structures and large amounts of irrelevant information, particularly in knowledge graph question answering (KGQA). To address this issue, this paper proposes a KGQA model named Reasoning via Dynamic Planning on Graph (RDPG). It is based on an Adaptive Path Generation (APG) method put forward by us. RDPG aims to strengthen LLMs’ reasoning capabilities by integrating knowledge reasoning paths in KGs. The APG leverages LLMs’ interactive learning capabilities to dynamically adjust the depth and number of generated relation paths, constructing optimal path structures suitable for the current reasoning task. The generated reasoning paths meet the semantic requirements of the questions while avoiding unnecessary noise. Specifically, RDPG first dynamically generates candidate relation paths as reasoning plans based on the input question and LLMs’ real-time feedback, ensuring that the reasoning paths contain highly relevant information from the KG. Then, the model further alleviates the LLMs’ hallucination problem caused by irrelevant noise or missing information through path correction and expansion, providing a faithful reasoning foundation for LLMs. Finally, LLMs combine their built-in knowledge with retrieved external knowledge from KG, enhancing the reasoning process through Chain-of-Thought to meet complex reasoning demands. Experimental results demonstrate our method surpasses state-of-the-art approaches on two benchmark datasets. Additionally, further experiments validate the plug-and-play feature and effectiveness of our APG method in multi-hop KGQA tasks, indicating it applicable to different LLMs and KGs with strong adaptability and extensibility.},
  archive      = {J_JIIS},
  author       = {Ding, Lianhong and Ding, Na and Tao, Qi and Shi, Peng},
  doi          = {10.1007/s10844-025-00945-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {10},
  number       = {5},
  pages        = {1455--1485},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Enhancing graph multi-hop reasoning for question answering with LLMs: An approach based on adaptive path generation},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Evaluating user story quality with LLMs: A comparative study. <em>JIIS</em>, <em>63</em>(4), 1453--1454. (<a href='https://doi.org/10.1007/s10844-025-00948-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JIIS},
  author       = {Sharma, Amol and Tripathi, Anil Kumar},
  doi          = {10.1007/s10844-025-00948-2},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1453--1454},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Correction to: Evaluating user story quality with LLMs: A comparative study},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating user story quality with LLMs: A comparative study. <em>JIIS</em>, <em>63</em>(4), 1423--1451. (<a href='https://doi.org/10.1007/s10844-025-00939-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating the quality of user stories is crucial for the success of agile software development. This paper investigates the efficacy of Large Language Models (LLMs) in assessing the quality of individual user stories using the Quality User Story (QUS) framework, which categorizes quality criteria into syntactic, semantic, and pragmatic dimensions. Leveraging three state-of-the-art LLMs—GPT-4o, GPT-4-Turbo, and GPT-3.5-Turbo—this study employs two prompting strategies: context minimal and context rich, to gauge performance across eight user story quality criteria. To ensure robust validation, we generated 960 user stories using alternative LLMs (Gemini and Meta AI’s LLaMA3), which were then assessed for quality by 69 postgraduate students. The quality assessments were further verified by a team comprising a research scholar and a senior postgraduate student. The evaluation of these 960 user stories by the three LLMs under study reveal significant insights into their relative strengths and weaknesses. The results demonstrate that GPT-4o and GPT-4-Turbo exhibit superior performance in evaluating user stories, particularly excelling in syntactic and pragmatic criteria with minimal impact from additional contextual details. Conversely, GPT-3.5-Turbo reveals noticeable limitations, struggling to maintain effectiveness, particularly when handling richer contextual inputs. This research marks a pivotal step towards automated quality assessment in requirements engineering, highlighting both the potential and areas for improvement in leveraging LLMs for robust user story evaluation.},
  archive      = {J_JIIS},
  author       = {Sharma, Amol and Kumar Tripathi, Anil},
  doi          = {10.1007/s10844-025-00939-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1423--1451},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Evaluating user story quality with LLMs: A comparative study},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rumor detection for emergency events via few-shot ensembled prompt learning. <em>JIIS</em>, <em>63</em>(4), 1391--1422. (<a href='https://doi.org/10.1007/s10844-025-00944-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rumors on social media can cause panic during emergency events. Unlike conventional rumor detection, it is more challenging to detect rumors about emergency events that have not happened in history, due to the shortage of relevant corpus. Therefore, we treat emergency events rumor detection as a few-shot learning problem. Recently, large language models (LLMs) such as ChatGPT have been widely considered in various NLP tasks. However, LLMs may face limitations due to non-real-time knowledge and unwillingness to provide direct answers. Prompt learning effectively leverages pre-trained language models (PLMs), and prompt tuning can inject the latest knowledge into PLMs with very few instances. Therefore, we propose a template-based Ensembled Prompt Tuning (EPT) model. We contribute an approach leveraging the knowledge in PLMs to generate label words for verbalizer construction. Furthermore, we treat few-shot rumor detection as an MLM problem and design two types of prompt templates for online posts and comments. An ensemble strategy is introduced to make the final prediction. Experimental results on three datasets demonstrate the effectiveness of the proposed EPT model, outperforming current SOTA on accuracy and F1-score. Ablation study has shown the necessity and effectiveness of the ensemble strategy. Besides, we make comparisons with prevalent LLMs under both few-shot and zero-shot settings, the results show the competitiveness of our EPT model.},
  archive      = {J_JIIS},
  author       = {Su, Chen and Zhou, Junkang and Jiang, Zhentao and Zhu, Shuwei and Li, Chao and Fang, Wei and Lu, Heng-yang},
  doi          = {10.1007/s10844-025-00944-6},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1391--1422},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Rumor detection for emergency events via few-shot ensembled prompt learning},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying influential nodes using semi local isolating centrality based on average shortest path. <em>JIIS</em>, <em>63</em>(4), 1361--1390. (<a href='https://doi.org/10.1007/s10844-025-00943-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In complex networks, identifying influential nodes becomes critical as these networks emerge rapidly. Extensive studies have been carried out on intricate networks to comprehend diverse real-world networks, including transportation networks, facebook networks, animal social networks, etc. Centrality measures like degree, betweenness, closeness, and clustering centralities are used to find influential nodes, but these measures have limitations in implementation with large-scale networks. These centrality measures are classified into global and local centralities. Semi-local structures perform well compared to local and global centralities but efficient centrality for finding influential nodes remains a challenging issue in large-scale networks. To address this challenge, a Semi-Local Average Isolating Centrality (SAIC) metric is proposed that integrates semi-local and local information to identify important nodes in large networks, along with the relative change in average shortest path. Here, we consider extended neighborhood concept for selecting the nodes nearest neighbors along with the weighted edge policy to find the best influential nodes by using SAIC. Along with these, SAIC also consider isolated nodes which significantly impact the network connectedness by maximizing the number of connected components upon removal. As a result SAIC differentiates itself from other centrality metrics by employing a distributed approach to define semi-local structure and utilizing an efficient edge weighting policy. The analysis of SAIC has been performed on multiple real-time datasets using Kendall tau’s coefficient. Using the Susceptible-Infected-Recovered (SIR) and Independent Cascade(IC) models, the performance of SAIC has been examined to determine maximum information spread in comparison to the most recent metrics in some real-world datasets. Our proposed method SAIC performs better in terms of information spreading when compare with other exisiting methods, with an improvement ranging from 4.11% to 17.9%.},
  archive      = {J_JIIS},
  author       = {Madupuri, ReddyPriya and C.C, Sobin and Enduri, Murali Krishna and Anamalamudi, Satish},
  doi          = {10.1007/s10844-025-00943-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1361--1390},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Identifying influential nodes using semi local isolating centrality based on average shortest path},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid transformer based model for sarcasm detection from news headlines. <em>JIIS</em>, <em>63</em>(4), 1339--1359. (<a href='https://doi.org/10.1007/s10844-025-00941-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis becomes significantly challenging when there are traces of sarcastic words or phrases present in text. A common finding of the researchers working on sentiment analysis is that the presence of sarcastic comments escalates the complexity of sentiment analysis drastically. Consequently, it is a common practice to detect the sarcastic elements in a text prior to performing the sentiment analysis so as to increase the accuracy of the same. Sarcastic phrases often have an intrinsic linguistic pattern which the research community is working on during the last few years with an objective to identify them in a generically. But most of the cases the researchers used either rule based or machine learning-driven approach for the detection of sarcasm present in text. The scope of application of deep learning for identifying sarcastic comments is principally due to the scarcity of dataset. In order to bridge the gap, this article presents a novel hybrid transformer based approach that leverages the strengths of RoBERTa, Bidirectional Long Short-Term Memory (Bi-LSTM), and Multi-Head Attention in order to enhance the efficiency of sarcasm detection especially from News Headlines. Our approach combines contextual embeddings, sequential modelling and attention mechanisms to effectively capture the nuances of sarcastic expressions in text. Experimental results demonstrate that our model achieves competitive accuracy and efficiency, providing a robust solution for sarcasm detection tasks.},
  archive      = {J_JIIS},
  author       = {Khan, Amit and Majumdar, Dipankar and Mondal, Bikromadittya},
  doi          = {10.1007/s10844-025-00941-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1339--1359},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A hybrid transformer based model for sarcasm detection from news headlines},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generating textual explanations for scheduling systems leveraging the reasoning capabilities of large language models. <em>JIIS</em>, <em>63</em>(4), 1287--1337. (<a href='https://doi.org/10.1007/s10844-025-00940-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scheduling systems are critical for planning projects, resources, and activities across many industries to achieve goals efficiently. As scheduling requirements grow in complexity, the use of Artificial Intelligence (AI) solutions has received more attention. However, providing comprehensible explanations of these decision-making processes remains a challenge and blocker to adoption. The emergent field of eXplainable Artificial Intelligence (XAI) aims to address this by establishing human-centric interpretation of influencing factors for machine decisions. The leading field of autonomous interpretation in Natural Language Processing (NLP) is Large Language Model (LLM)s, for their generalist knowledge and reasoning capabilities. To explore LLMs’ potential to generate explanations for scheduling queries, we selected a benchmark set of Job Shop scheduling problems. A novel framework that integrates the selected language models, GPT-4 and Large Language Model Meta AI (LLaMA), into scheduling systems is introduced, facilitating human-like explanations to queries from different categories through few-shot learning. The explanations were analysed for accuracy, consistency, completeness, conciseness, and language across different scheduling problem sizes and complexities. The approach achieved an overall accuracy of 59% with GPT-4 and 35% with LLaMA, with minimal impact from the varied schedule sizes observed, proving the approach can handle different datasets and is performance scalable. Several responses demonstrated high comprehension of complex queries; however, response quality fluctuated due to the few-shot learning approach. This study establishes a baseline for measuring generalist LLM capabilities in handling explanations for autonomous scheduling systems, with promising results for an LLM providing XAI interactions to explain scheduling decisions.},
  archive      = {J_JIIS},
  author       = {Powell, Cheyenne and Riccardi, Annalisa},
  doi          = {10.1007/s10844-025-00940-w},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1287--1337},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Generating textual explanations for scheduling systems leveraging the reasoning capabilities of large language models},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MF-EDNet: Predicting stock market sector indices based on multi-feature fusion under emergency events. <em>JIIS</em>, <em>63</em>(4), 1265--1286. (<a href='https://doi.org/10.1007/s10844-025-00938-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The impact of emergency events on the stock market cannot be underestimated, as their unpredictability poses significant challenges to investors’ stock operations. This calls for researchers and investors to seek more effective features and reasonable methods to mitigate risks. In the context of multi-feature prediction methods, analyzing the correlation between multi-dimensional features or data has always been a challenging issue. This paper proposes a stock market index prediction framework based on an encoder-decoder architecture (MF-EDNet). The framework leverages the dynamic correlation between stock data and futures data as prior knowledge, integrating features of both internal sequences (industry indices) and external sequences (futures data) to capture the impact of emergency events on the stock market. The newly proposed Multi-Dimensional Convolutional Attention Module (MCAM) further enhances the feature extraction and attention capabilities of the attention mechanism. Experiments on multiple industry indices in the Chinese stock market demonstrate that MF-EDNet can effectively extract important features from stock and futures data, exhibiting good predictive performance under emergency events. The proposed MF-EDNet model achieved improvements of 35.8% and 22.9% in the Matthews correlation coefficient (MCC), a 3.3% increase in accuracy (ACC) and a 7.86% enhancement in profit compared to previous state-of-the-art methods.},
  archive      = {J_JIIS},
  author       = {Han, Tianjiao and Yuan, Chenxun and Wang, Pengcheng and Hao, Xingwei and Guo, Fenghua},
  doi          = {10.1007/s10844-025-00938-4},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1265--1286},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {MF-EDNet: Predicting stock market sector indices based on multi-feature fusion under emergency events},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid transformer-CNN architecture for multivariate time series forecasting: Integrating attention mechanisms with convolutional feature extraction. <em>JIIS</em>, <em>63</em>(4), 1233--1264. (<a href='https://doi.org/10.1007/s10844-025-00937-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately forecasting time series data remains a critical challenge, particularly in financial markets where volatility and noise obscure underlying patterns. Traditional deep learning approaches often struggle to simultaneously capture local and global dependencies, limiting their effectiveness in detecting directional changes. To address these challenges, we propose an innovative hybrid model that integrates Transformers with 1D Convolutional Neural Networks (1D-CNN), leveraging their complementary strengths. The self-attention mechanism of Transformers enhances the model’s ability to capture long-term dependencies, while 1D-CNN excels at extracting local patterns and refining feature representations. Unlike conventional models that aim to predict exact values, our approach is explicitly designed to learn and detect changes in trends rather than forecasting precise numerical values. The primary motivation of this work is to improve Directional Accuracy (DA) and Signal Directional Change Detection, two critical factors for robust time series forecasting in financial applications. Our model effectively mitigates the impact of market fluctuations by enhancing trend detection and reducing false signals. Performance evaluation is conducted using specialized metrics, including DA, Trend Consistency Index (TCI), Signal Shift Error (SSE), and Precision of Trend Change (PTC), ensuring a comprehensive assessment of the model’s predictive capabilities. Experimental results demonstrate that our hybrid model significantly outperforms both custom and state-of-the-art architectures, achieving superior accuracy in detecting trend reversals and signal shifts. This research contributes to advancing time series modeling by introducing a modular, scalable, and high-precision forecasting framework, applicable across various domains.},
  archive      = {J_JIIS},
  author       = {El Zaar, Abdellah and Mansouri, Amine and Benaya, Nabil and Bakir, Toufik and El Allati, Abderrahim},
  doi          = {10.1007/s10844-025-00937-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1233--1264},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Hybrid transformer-CNN architecture for multivariate time series forecasting: Integrating attention mechanisms with convolutional feature extraction},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-objective optimization approach for session-based recommendation systems. <em>JIIS</em>, <em>63</em>(4), 1203--1232. (<a href='https://doi.org/10.1007/s10844-025-00935-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems face the persistent challenge of balancing multiple conflicting objectives, such as relevance, diversity, and user engagement, while adapting to the complexities of session-based data. Traditional methods often struggle to address these challenges effectively, particularly when user interactions are diverse, sparse, or structured in short sessions. Moreover, the trade-offs between accuracy-focused metrics and diversity-oriented metrics pose additional hurdles in achieving well-rounded recommendations. This paper presents a novel session-based multi-objective recommendation approach designed to address these challenges. The method employs session clustering to group similar behavioral patterns, reducing complexity and enhancing focus. Within each cluster, focused item subsetting refines the recommendation space, enabling efficient identification of high-performing solutions. Additionally, Differential Evolution (DE)-based optimization facilitates a balance between competing objectives, while cross-cluster knowledge sharing accelerates convergence and enhances generalization by transferring effective strategies between session clusters. Extensive experiments conducted on real-world datasets demonstrate that the proposed approach consistently outperforms state-of-the-art session-based and multi-objective optimization-based recommender systems. These results highlight its ability to adapt to diverse interaction patterns and effectively balance conflicting objectives, making it a practical and scalable solution for modern recommendation systems.},
  archive      = {J_JIIS},
  author       = {Zaizi, Fatima Ezzahra and Qassimi, Sara and Rakrak, Said},
  doi          = {10.1007/s10844-025-00935-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1203--1232},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A multi-objective optimization approach for session-based recommendation systems},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM-enhanced representation learning for graph collaborative filtering recommendation models. <em>JIIS</em>, <em>63</em>(4), 1179--1202. (<a href='https://doi.org/10.1007/s10844-025-00933-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph collaborative filtering recommendation models have gained significant attention in recommender systems due to their ability to capture complex user-item relationships through interaction graphs. However, these models often overlook the rich information contained in textual and tabular data, which can provide valuable insights into user preferences and item characteristics. To address this limitation, we propose a model-agnostic multi-task representation learning framework, LLMGCF, which aims to enhance the performance of graph-based recommendation models by integrating textual data enriched by large language models (LLMs) and feature-engineered tabular data. Specifically, our framework leverage contrastive learning to align semantic signals derived from LLM-enhanced textual data, attribute-based tabular signals, and collaborative graph signals, enabling effective cross-modal knowledge fusion. Additionally, LLMGCF utilizes multi-task learning to jointly optimize the supervised recommendation retrieval task and the cross-modal knowledge alignment task. Experimental results on two public datasets demonstrate that LLMGCF outperforms state-of-the-art (SOTA) graph collaborative filtering models, achieving average improvements of approximately 4.17% in Recall and 3.68% in NDCG. Furthermore, our framework exhibits strong robustness against random noise, highlighting its practical applicability in real-world scenarios.},
  archive      = {J_JIIS},
  author       = {Mou, Daen and Wei, Zhihua and Ni, Lin and Song, Na and Sun, Yiwei and Chu, Weizhong and Jin, Benkai},
  doi          = {10.1007/s10844-025-00933-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1179--1202},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {LLM-enhanced representation learning for graph collaborative filtering recommendation models},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distant supervised relation extraction with label entailment and collaborative denoising. <em>JIIS</em>, <em>63</em>(4), 1153--1177. (<a href='https://doi.org/10.1007/s10844-025-00932-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distant supervision automatically generates large-scale annotated data for relation extraction by aligning texts with knowledge bases, reducing the dependence on human annotation. However, distant supervision relation extraction inevitably introduces label noise, including false positive (FP) noise caused by neglecting sentence meanings and false negative (FN) noise due to the incompleteness of knowledge bases. Previous sentence-level methods mainly focus on the FP noise and ignore the FN noise, which induces severe misleading in both training and testing procedures. To address this issue, we propose a novel two-stage sentence-level noise reduction framework that explicitly tackles both the FN and FP problems. At stage one, we perform noise-filtering with label entailment, which filters out the FN noise before training through semantic matching between the negative instance and every relation label. At stage two, we propose robust training with collaborative denoising, which dynamically removes FP noise during training by maintaining two relation classifiers simultaneously and enabling them to learn useful knowledge from each other. Experimental results show that our method achieves significant improvements over previous state-of-the-art methods on two widely-used benchmarks. For example, a 2.55% F1 score improvements on NYT-10 dataset with BiLSTM implementation is achieved. Moreover, we validate the effectiveness of our method in reducing both the FN and FP noise.},
  archive      = {J_JIIS},
  author       = {Xie, Tingyu and Li, Qi and Wang, Gaoang and Wang, Hongwei},
  doi          = {10.1007/s10844-025-00932-w},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1153--1177},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Distant supervised relation extraction with label entailment and collaborative denoising},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-training dual-network for denoising federated recommendation. <em>JIIS</em>, <em>63</em>(4), 1129--1151. (<a href='https://doi.org/10.1007/s10844-025-00930-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated recommendation (FR) offers users personalized recommendation services while safeguarding their privacy. Conventional FR considers all items that users interact with as items that users like. However, this assumption fails to capture genuine user preferences due to some noisy samples, in which users interact with items they do not like. Most research in FR disregards such noisy samples, consequently inducing local models to learn inaccurate user preferences. Since the global model is aggregated from local models, its performance is compromised, adversely affecting user experience. Furthermore, data heterogeneity, privacy protection, and communication burden requirements make denoising FR more complicated. In this paper, we propose a Self-Training Dual-Network (STDFed) for denoising FR. Specifically, each client’s global and local models inherently form a dual-network. On each client, STDFed considers samples with high predicted probabilities from the dual-network as clean samples to construct a self-training dataset, while the remaining are treated as unlabeled samples. The self-training dataset replaces the original dataset to support local training. In subsequent rounds, STDFed identifies the unlabeled samples with low predicted probabilities as noisy samples, which will be either discarded or labeled as 0 and then added to the self-training dataset. STDFed is model-agnostic and can be applied to most FR. Extensive experiments show that STDFed improves the performance of FR by an average of 6.96% across multiple datasets without increasing communication costs.},
  archive      = {J_JIIS},
  author       = {Liu, Pingshan and He, Haoning and Lu, Guoxin},
  doi          = {10.1007/s10844-025-00930-y},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1129--1151},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Self-training dual-network for denoising federated recommendation},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantification of part-of-speech relationships for aspect sentiment triplet extraction. <em>JIIS</em>, <em>63</em>(4), 1105--1127. (<a href='https://doi.org/10.1007/s10844-025-00929-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect Sentiment Triple Extraction (ASTE) is a fine-grained aspect-level sentiment analysis aimed at extracting aspect words, opinion words, and the sentiment polarity between them in text. Existing end-to-end ASTE models tend to ignore information such as the potential lexical relationships between words and their differences in importance, and fail to take full advantage of the interaction between lexical features and dependency features. To address the above problem, we propose a Quantification of Part-of-speech Relationships for Aspect Sentiment Triplet Extraction (QoPR-ASTE). The model first extracts contextual semantic features by combinatorial encoder; then analyzes the connection and dependency between lexical pairs of words to mine potential syntactic information, and assigns weights according to the importance, constructs lexical adjacency weight matrices and dependency type weight matrices, so as to remove the redundant information and strengthen the expression of syntactic features; then extracts the syntactic information by the two-group graphical convolutional network and the syntactic interaction module and fusion; finally, the semantic and syntactic information is fused through the multi-head attention graph transformation module, and the sentence is labeled using word pair relations and decoded to extract the triad. The F1 values of this model on the four public datasets demonstrate an improvement of 0.80%, 1.46%, 0.92%, and 0.78% compared to the PBLUN model, respectively. The experimental results indicate that the model is capable of efficiently mining potential semantic and syntactic information, thereby significantly enhancing the accuracy of triplet extraction.},
  archive      = {J_JIIS},
  author       = {Wang, Jiacan and Liu, Jianhua and Ke, Tianci and Chen, Kewei and Cai, Zijie and Xu, Ge},
  doi          = {10.1007/s10844-025-00929-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1105--1127},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Quantification of part-of-speech relationships for aspect sentiment triplet extraction},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensemble time series models for stock price prediction and portfolio optimization with sentiment analysis. <em>JIIS</em>, <em>63</em>(4), 1079--1103. (<a href='https://doi.org/10.1007/s10844-025-00928-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The work introduces a hybrid ensemble model that combines conventional stock market prediction models with sentiment analysis of news articles in order to improve the accuracy of predictions. By utilizing the advantages of Long Short-Term Memory(LSTM), Gated Recurrent Unit(GRU), Bidirectional LSTM (BiLSTM), and Recurrent Neural Network(RNN) models in an ensemble framework, we attain an impressive average prediction accuracy of 91.89% where our model was evaluated on ten stocks and surpassed the performance of current models. This outcome underscores the need to integrate news sentiment with technical indicators to get a thorough comprehension of market dynamics. Moreover, the proposed model-driven portfolio regularly outperforms the Nifty 50 benchmark at different risk tolerance levels (0.3, 0.5, and 0.7), generating a stable positive alpha. This indicates greater returns when adjusted for risk. The model’s ability to adapt to the varying needs of investors is demonstrated by the performance it achieved across risk profiles. The proposed model is also compared with the existing models to show the model’s efficiency.},
  archive      = {J_JIIS},
  author       = {Narayana, Malineni Lakshmi and Kartha, Arundhati J and Mandal, Ankur Kumar and P, Roshini and Suresh, Akshaya and Jose, Arun Cyril},
  doi          = {10.1007/s10844-025-00928-6},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1079--1103},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Ensemble time series models for stock price prediction and portfolio optimization with sentiment analysis},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive multi-round retrieval with knowledge distillation for sequential recommendation. <em>JIIS</em>, <em>63</em>(4), 1055--1077. (<a href='https://doi.org/10.1007/s10844-025-00926-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential Recommendation (SR) involves predicting the next item that a user is likely to interact with based on their historical interactions. SR models examine the sequence of a user’s actions to analyze complex behavioral patterns and capture diverse user preferences. However, existing works primarily rely on a single-round inference paradigm, which limits their ability to capture the ever-changing diversity of user preferences, and overlooks the influence of user noisy interactions. In this work, we propose MRKD, an adaptive multi-round retrieval framework for sequential recommendation via past-future knowledge distillation. MRKD comprises three key modules: user-wise translator, item-wise translator and past-future knowledge distillation. User-wise and item-wise translator extract meaningful context information from multi-round retrieval processes for refining the representations of items and users in proximity to the target item. The past-future knowledge distillation is to supervise the contextual aggregation process and prevent information loss via distilling valuable knowledge from users’ future interactions. We conduct experiments on five datasets and compare MRKD with 10 competitive baselines to evaluate its performance. Experimental results demonstrate the superiority of our MRKD, equipped with the adaptive multi-round retrieval strategy, over existing state-of-the-art models.},
  archive      = {J_JIIS},
  author       = {Mo, Yuhua and Liu, Yang and Ye, Chaowen and Cheng, Zhangtao and Deng, Chao and Zhuo, Zhencheng and Chen, Kaidi and Zhou, Fan},
  doi          = {10.1007/s10844-025-00926-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1055--1077},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Adaptive multi-round retrieval with knowledge distillation for sequential recommendation},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network translations for building SentiWordNets. <em>JIIS</em>, <em>63</em>(4), 1033--1054. (<a href='https://doi.org/10.1007/s10844-024-00911-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A SentiWordNet (SWN) is a WordNet, in which the synsets are annotated with sentiment scores. The initial steps for building a new SWN in a target language are similar to those for building a new WordNet. In particular, the creator may translate existing SWNs or WordNets to the target language or expand a seed sentiment lexicon. The next step involves training classifiers to identify the sentiment of the synset members. A major issue in building a new SWN is the lack of language resources for translating existing SWNs or WordNets to the target language and creating a dataset for training sentiment classifiers. Bilingual dictionaries are reliable aids in translation, but are expensive, may not be available, and time-consuming to construct. With the rapid development of artificial neural networks, machine translation systems have become commonplace and effective for a significant number of language pairs from around the world. Creating datasets for training machine translation models is also arguably cheaper than constructing bilingual dictionaries from scratch. This paper proposes effective approaches for constructing new SWNs using neural network translation systems. We introduce strategies for selecting synset members from translation candidates and computing sense-orders for these synset members. Our approaches are able to construct a new SWN in any language if the language is supported by machine translators.},
  archive      = {J_JIIS},
  author       = {Lam, Khang Nhut and Le, Trung Phuong and Ngu, Khanh Cong and Le, Kien Trung and Le, Phuc Minh and Nguyen, Huy Hoang-Dang and Kalita, Jugal},
  doi          = {10.1007/s10844-024-00911-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {8},
  number       = {4},
  pages        = {1033--1054},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Neural network translations for building SentiWordNets},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic memory-enhanced federated learning framework with trusted computing for multi-source data analysis. <em>JIIS</em>, <em>63</em>(3), 1011--1032. (<a href='https://doi.org/10.1007/s10844-025-00927-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of multi-source data and heightened privacy protection demands, securing data while preserving privacy has emerged as a critical challenge for organizations. Current multi-source data analysis approaches frequently fail to adequately capture temporal dependencies and inter-data correlations, limiting their ability to identify patterns and forecast trends effectively. To address these challenges, this paper proposes the Federated Trusted Network (FTN), which combines a Variable Forgetting LSTM module (VF-LSTM) and a Heterogeneous Aggregation GCN module (HA-GCN). The VF-LSTM module introduces a dynamic forgetting mechanism to flexibly capture temporal dependencies across different data types, while the HA-GCN module mines inherent correlations between different types of data through meta-path-based feature aggregation. Furthermore, FTN ensures data privacy and security by deploying trusted computing technology on local models across different application scenarios. Secure aggregation techniques are employed to integrate local model updates and generate a global model on the central server, enabling the identification of cross-domain patterns and insights. Across three healthcare scenarios, FTN demonstrates superior performance with ACC improvements of 1.1-1.3% and F1 improvements of 1.7-2.3% compared to state-of-the-art models. In the hospital healthcare scenario, FTN achieves 93.7% ACC and 93.1% F1 while maintaining privacy protection. These results validate FTN’s effectiveness in addressing temporal dependency and data correlation challenges.},
  archive      = {J_JIIS},
  author       = {Zhu, Bian and Niu, Ling},
  doi          = {10.1007/s10844-025-00927-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {1011--1032},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Dynamic memory-enhanced federated learning framework with trusted computing for multi-source data analysis},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intentional tendency-based dynamic heterogeneous graph network for emotion recognition in conversations. <em>JIIS</em>, <em>63</em>(3), 989--1010. (<a href='https://doi.org/10.1007/s10844-025-00925-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition in conversations(ERC) aims to identify the emotional state of an utterance based on contextual information. Existing problems: (1) Emotions being unstable and implicit, where implicit emotions may not be directly accessible through multimodal information. (2) Using only simple graph networks for modality modeling ignores the variability and complexity of relationships between modalities, although it reflects the dependencies between modalities and the coherence of contextual information. (3) Uneven sample sizes and similar emotion labels lead to poor ERC performance. To address these challenges, this paper proposes an Intentional Tendency-based Dynamic Heterogeneous Graph Network for ERC(IT-DHGN). Firstly, intentional tendencies are introduced to understand the intention behind each utterance, thereby providing additional emotional features for recognition. Secondly, when constructing a heterogeneous graph, intentional tendencies, text, audio and video are treated as heterogeneous nodes. The Dynamic Heterogeneous Graph Network module(DHGN) explores the heterogeneity between different data objects by integrating them, using the graph structure to dynamically capture dependencies and complementary information between modalities. Lastly, in the Contrast-Enhanced Optimization module(CEO), heterogeneity-based and homogeneity-based contrast enhancement strategies are employed to address the issue of indistinguishable samples with similar emotion labels in ERC. We conducted experiments on two conversation sentiment datasets and performed extensive analysis to validate the effectiveness of the IT-DHGN model.},
  archive      = {J_JIIS},
  author       = {Gan, Xinyi and Huang, Xianying and Zou, Shihao},
  doi          = {10.1007/s10844-025-00925-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {989--1010},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Intentional tendency-based dynamic heterogeneous graph network for emotion recognition in conversations},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MFIEA: Entity alignment through multi-modal feature interaction and knowledge facts. <em>JIIS</em>, <em>63</em>(3), 965--988. (<a href='https://doi.org/10.1007/s10844-025-00924-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity alignment (EA) plays a crucial role in knowledge graph fusion, as it seeks to identify identical entities across different knowledge graphs. Recent studies have utilized side information, such as entity names, to achieve satisfactory performance. However, these methods often overlook the impact of knowledge facts on EA and suffer significant performance deterioration when side information is unavailable. Additionally, while different modal features enhance alignment performance, they also introduce noise. Existing methods that perform feature-level fusion at an early stage are unable to effectively reduce the noise impact between different features. Thus, we propose a multi-modal feature interaction framework (MFIEA) for EA. Our approach employs a joint knowledge facts embedding strategy to embed features of entities and triples. It utilizes the context information of triples to enhance the alignment effect. Furthermore, we enhance EA with a feature interaction mechanism based on feature similarity, which captures the potential relationships between different features. The proposed approach effectively utilizes various feature information to achieve information complementarity, and it ensures robust performance even in the absence of side information. Extensive experimental results verify that MFIEA outperforms the state-of-the-art baselines on public datasets.},
  archive      = {J_JIIS},
  author       = {Zhang, Xiaoming and Lv, Menglong and Wang, Huiyong and Naseriparsa, Mehdi},
  doi          = {10.1007/s10844-025-00924-w},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {965--988},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {MFIEA: Entity alignment through multi-modal feature interaction and knowledge facts},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level language interaction transformer for multimodal sentiment analysis. <em>JIIS</em>, <em>63</em>(3), 945--964. (<a href='https://doi.org/10.1007/s10844-025-00923-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis is a rapidly evolving research field that combines data from various modalities such as text, images, and sound to analyze and understand human emotional states. This approach comprehensively captures the nuances of emotional expression, as people often convey emotions in multiple ways during communication, such as text, tone, facial expressions, and body language. However, redundant information between different modalities and irrelevant information unique to a single modality may hinder further improvement in model performance during cross-modality fusion. To address this, we propose a multimodal sentiment analysis method with multi-level language interaction. This method uses language features extracted at different scales by multi-layer Transformers combined with multimodal interaction layers to interact with visual and audio modalities at various levels, extracting complementary information between modalities and reducing redundancy and irrelevant interference information in the modality fusion process. Finally, the interaction’s feature representation is used for sentiment prediction. Experiments show that our model has achieved the best performance on several common datasets (MOSI, MOSEI, and CH-SIMS), especially with significant improvements in more fine-grained classification (Acc-5 and Acc-7).},
  archive      = {J_JIIS},
  author       = {Li, Yongtai and Liu, Anzhang and Lu, Yanlong},
  doi          = {10.1007/s10844-025-00923-x},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {945--964},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Multi-level language interaction transformer for multimodal sentiment analysis},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating control-theoretic predictive deep learning for resource-efficient computing systems. <em>JIIS</em>, <em>63</em>(3), 921--943. (<a href='https://doi.org/10.1007/s10844-025-00919-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) powers numerous applications on ubiquitous edge devices, but its high resource demands pose a challenge. Approximate computing is often proposed to alleviate this, yet such calculation usually suffers from a fixed level of accuracy loss. We propose a novel control-theoretic approach for predictive DL inference on resource constrained devices. Our system dynamically adjusts approximation levels based on a trade-off between resource utilisation and accuracy, considering future demands. Extensive experiments across diverse domains - human activity recognition, acoustic scene profiling, and computer vision - with various neural network architectures and approximation techniques, demonstrate that our approach achieves up to 50% energy savings while maintaining the desired inference accuracy and incurring minimal runtime overhead. Furthermore, we showcase our method in a real-world deployment on low-power edge devices and confirm its superiority over current state-of-the-art solutions.},
  archive      = {J_JIIS},
  author       = {Machidon, Alina L. and Pejović, Veljko},
  doi          = {10.1007/s10844-025-00919-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {921--943},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Integrating control-theoretic predictive deep learning for resource-efficient computing systems},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Histograms as tools for mining actionable knowledge – Principles and examples. <em>JIIS</em>, <em>63</em>(3), 893--919. (<a href='https://doi.org/10.1007/s10844-025-00922-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Actionable knowledge discovery is an established discipline of data mining. The goal is to find patterns hidden in the data that suggest actions beneficial to the data owner. Action rules are tools of actionable knowledge discovery. They are based on flexible and stable attributes. Action rules suggest the change of flexible attributes, leading to the desirable reclassification of a target attribute. The change of flexible attributes can be applied to a group of objects described by stable attributes. We introduce histogram action rules that deal with histograms of target attributes. These action rules propose changes to values of flexible attributes that result in a new shape of the target attribute histogram, such that comparing the shapes before and after the change reveals valuable information.},
  archive      = {J_JIIS},
  author       = {Rauch, Jan},
  doi          = {10.1007/s10844-025-00922-y},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {893--919},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Histograms as tools for mining actionable knowledge – Principles and examples},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PolyCard: A learned cardinality estimator for intersection queries on spatial polygons. <em>JIIS</em>, <em>63</em>(3), 873--891. (<a href='https://doi.org/10.1007/s10844-025-00921-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How can we estimate the result size for a given query on complex spatial objects like polygons? Estimating a query’s result size, also known as the cardinality estimation, plays a significant role in query scheduling and optimization. Accurate and fast cardinality estimation substantially improves query efficiency. Existing compatible solutions, mainly histogram-based, deal with polygons as their minimal bounding rectangles for easier processing, which leads to inaccurate estimation. To address this issue, we present PolyCard, a learned cardinality estimator for intersection queries on spatial polygons. We successfully apply learning techniques to spatial polygons with variable sizes. PolyCard has the following properties. (i) Accurate: PolyCard improves 30% accuracy compared with existing solutions, (ii) Fast: PolyCard takes only 4 microseconds for an estimation, and (iii) Stable: PolyCard is robust against datasets and queries of different cardinalities. Our experiments on four real-world datasets of millions of polygons demonstrate the efficiency and effectiveness of PolyCard.},
  archive      = {J_JIIS},
  author       = {Ji, Yuchen and Amagata, Daichi and Sasaki, Yuya and Hara, Takahiro},
  doi          = {10.1007/s10844-025-00921-z},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {873--891},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {PolyCard: A learned cardinality estimator for intersection queries on spatial polygons},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-view embedding for hyper-relational knowledge graphs with hierarchical structure. <em>JIIS</em>, <em>63</em>(3), 855--872. (<a href='https://doi.org/10.1007/s10844-024-00916-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a dual-view hyper-relational knowledge graph embedding model aimed at addressing the challenges of embedding complex relationships in knowledge graphs. Traditional methods primarily handle simple triplet relations and struggle with the complexity of hyper-relations. By integrating instance view and ontology view, our model, DVHE, captures hierarchical structural information between entities and is applied to link prediction tasks. Experimental results show that DVHE significantly outperforms existing single-view and dual-view models across multiple benchmark datasets, particularly in handling complex hyper-relations and hierarchical information. Ablation studies further validate the effectiveness of the model’s components, providing new insights for the development of knowledge graph embeddings.},
  archive      = {J_JIIS},
  author       = {Liu, Shuang and Xu, Liangyang and Liu, Yiying and Kolmanič, Simon},
  doi          = {10.1007/s10844-024-00916-2},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {855--872},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Dual-view embedding for hyper-relational knowledge graphs with hierarchical structure},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clustering of renewable energy assets to optimize resource allocation and operational strategies. <em>JIIS</em>, <em>63</em>(3), 831--853. (<a href='https://doi.org/10.1007/s10844-024-00914-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study clusters solar inverters and wind turbines to help Enlitia’s clients optimize resource allocation and operational strategies by identifying similar assets based on historical power production, meteorological data, and power curve characteristics. The project employs Data Mining techniques following the CRISP-DM methodology, emphasizing data cleaning to handle null values, duplicates, and outliers. For wind turbines, outliers are managed using power curves, while for solar inverters, I-V curves are utilized. Clustering begins after data cleaning, using algorithms from classical, ensemble, and time series clustering categories. Principal Component Analysis is applied to reduce computational costs while preserving significant data variation. Classical clustering involves five hierarchical, two partitional, one soft, one model-based, and two density-based algorithms, evaluated using four distinct indices. The top three classical algorithms proceed to ensemble clustering, combining the three algorithms via weighted major voting. Lastly, two time series clustering algorithms are applied to pre-processed datasets. Evaluation of segmentations indicates that time is a significant factor in data variation. Time series clustering consistently produces the best segmentations for both solar and wind datasets.},
  archive      = {J_JIIS},
  author       = {Abreu, Sara and Rodrigues, Fátima and Pereira, João},
  doi          = {10.1007/s10844-024-00914-4},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {831--853},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Clustering of renewable energy assets to optimize resource allocation and operational strategies},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning-based misbehavior classification system for VANET intrusion detection. <em>JIIS</em>, <em>63</em>(3), 807--830. (<a href='https://doi.org/10.1007/s10844-025-00920-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of vehicular security, detecting misbehavior is crucial, particularly when faced with attacks that traditional cryptographic methods may overlook. Machine Learning (ML) and Deep Learning (DL) techniques offer a promising solution for identifying these sophisticated patterns of misbehavior. However, existing methods often rely on centralized systems, raising privacy concerns and exacerbating latency issues in the dynamic and scalable nature of vehicular environments. We develop a collaborative learning system that uses Federated Learning (FL) to identify misbehavior in vehicular networks in order to address these issues. Our approach aims to alleviate privacy concerns and mitigate latency problems by decentralizing the learning process across vehicles. We utilize the VeReMi extension dataset and conduct thorough evaluations across various client counts, employing different aggregation strategies such as FedAvg, FedProx, and FedYogi. Our experimental results highlight the accuracy of FL-based approach in detecting misbehavior within vehicular networks. These findings underscore the potential of FL to improve security while preserving privacy and meeting the stringent demands of real-time operations and scalability.},
  archive      = {J_JIIS},
  author       = {Gurjar, Dayanand and Grover, Jyoti and Kheterpal, Vanisha and Vasilakos, Athanasios},
  doi          = {10.1007/s10844-025-00920-0},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {807--830},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Federated learning-based misbehavior classification system for VANET intrusion detection},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EST transformer: Enhanced spatiotemporal representation learning for time series anomaly detection. <em>JIIS</em>, <em>63</em>(3), 783--805. (<a href='https://doi.org/10.1007/s10844-025-00918-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection in time series data is of great importance across various domains, which aims to identify outliers in a sequence of time series data generated from various sensors or system operations that deviate significantly from the norm. Systems are often not composed of a single variable, and the detection of anomalies in multidimensional time series has attracted more attention from researchers and engineering practitioners. Multidimensional time series not only exhibit strong temporal characteristics but also have the inter-correlations between dimensions are extremely significant. But existing reconstruction-based models for multivariate time series anomaly detection often struggle to differentiate between normal and anomalous sequences during the reconstruction process. To address these issues, in this paper, we propose an novel method, the Enhanced Spatiotemporal Transformer (EST Transformer), which improves the conventional self-attention mechanism by incorporating state information to strengthen the model’s sensitivity to contextual information. Our proposed method amplifies the differences between the normal and anomalous sequence segments based on the state discrepancies within the context. Additionally, the proposed method employs variable self-attention to model dimensional correlations, thereby enhancing the model’s sequence reconstruction capabilities. The effectiveness of the proposed method has been verified on four publicly available datasets. And the experimental evaluations demonstrate that the proposed EST Transformer outperforms the various established baseline models across multiple benchmark datasets in terms of anomaly detection accuracy.},
  archive      = {J_JIIS},
  author       = {Gao, Yao and Su, Rui and Ben, Xianye and Chen, Lei},
  doi          = {10.1007/s10844-025-00918-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {783--805},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {EST transformer: Enhanced spatiotemporal representation learning for time series anomaly detection},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal knowledge graph completion based on product space and contrastive learning of commonsense. <em>JIIS</em>, <em>63</em>(3), 763--782. (<a href='https://doi.org/10.1007/s10844-024-00917-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Static knowledge graph completion (KGC) has made significant progress in the field of artificial intelligence. However, knowledge is time-sensitive, thus the introduction of Temporal Knowledge Graph Completion (TKGC) is necessary to accurately reflect its dynamic changes. Current TKGC methods often overlook the semantic similarity between entities and entity-relation pairs, which leads to a loss of rich semantic information in temporal knowledge graphs. Furthermore, using a single embedding space limits these methods’ ability to model various temporal patterns and rich semantic information. To address this issue, we propose a commonsense-based contrastive learning mechanism and a product space approach. Specifically, we incorporate commonsense information to learn time-invariant event representations and integrate relationship and temporal information into different embedding spaces to comprehensively capture semantic changes. Through these methods, we can effectively compare representations of the same entity at different time points, reducing the semantic distance between entities and entity-relation pairs, thereby significantly improving the performance of the completion task. Experimental results show that our method significantly enhances the performance of TKGC on multiple public datasets.},
  archive      = {J_JIIS},
  author       = {Chen, Zhenghao and Wu, Jianbin},
  doi          = {10.1007/s10844-024-00917-1},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {763--782},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Temporal knowledge graph completion based on product space and contrastive learning of commonsense},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MLLM4Rec: Multimodal information enhancing LLM for sequential recommendation. <em>JIIS</em>, <em>63</em>(3), 745--761. (<a href='https://doi.org/10.1007/s10844-024-00915-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, With the advent of large language models (LLMs) such as GPT-4, LLaMA, and ChatGLM, leveraging multimodal information (e.g., images and audio) to enhance recommendation systems has become possible. To further enhance the performance of recommendation systems based on large language models (LLMs), we propose MLLM4Rec, a sequence recommendation framework grounded in LLMs. Specifically, our approach integrates multimodal information, with a focus on image data, into LLMs to improve recommendation accuracy. By employing a hybrid prompt learning mechanism combined with role-playing for model fine-tuning, MLLM4Rec effectively bridges the gap between textual and visual representations, enabling text-based LLMs to “read” and interpret images. Moreover, the fine-tuned LLM is utilized to rank retrieval candidates, thereby maintaining its generative capabilities while optimizing item ranking according to user preferences. Extensive experiments were conducted on four publicly available benchmark datasets to evaluate the proposed method. The results demonstrate that MLLM4Rec outperforms partially LLM-based recommendation models, traditional sequential recommendation models, and sequential recommendation models pre-trained with multi-modal information in terms of NDCG, MRR, and Recall metrics.},
  archive      = {J_JIIS},
  author       = {Wang, Yuxiang and Shi, Xin and Zhao, Xueqing},
  doi          = {10.1007/s10844-024-00915-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {745--761},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {MLLM4Rec: Multimodal information enhancing LLM for sequential recommendation},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta learning-based relevant user identification and aggregation for cold-start recommendation. <em>JIIS</em>, <em>63</em>(3), 723--744. (<a href='https://doi.org/10.1007/s10844-024-00913-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cold-start has always been a major concern for recommendation systems. Heterogeneous Information Networks (HINs) are widely used due to their ability to provide rich auxiliary information to enhance the representation of users or items, effectively mitigating the cold start problem. However, the rich semantic information provided by relevant users is often overlooked. Meanwhile, the scarcity of training data has made meta learning widely used for cold start recommendation since it can learn general knowledge from a small amount of data and quickly adapt to new tasks. To address this issue, we propose a cold-start recommendation model based on meta learning for relevant user identification and aggregation, called IAML. First, IAML identifies relevant users with similar preferences by integrating meta-path-based and clustering methods, and constructs them into a neighbor set. Next, the information from neighbor nodes and their interactions are integrated to assess their impact on cold-start nodes, thereby obtaining a richer user representation. In view of the data sparsity in the training process, an optimized meta-learning algorithm MAML is introduced to enhance the model’s generalization ability with a limited amount of training data. Finally, extensive experimental results on three public datasets show that our IAML exhibits satisfactory performance across all metrics, both in cold-start and non-cold-start scenarios.},
  archive      = {J_JIIS},
  author       = {Xing, Qian and Xun, Yaling and Yang, Haifeng and Li, Yanfeng and Wang, Xing},
  doi          = {10.1007/s10844-024-00913-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {723--744},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Meta learning-based relevant user identification and aggregation for cold-start recommendation},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A quantum-like zero-shot approach for sentiment analysis in finance. <em>JIIS</em>, <em>63</em>(3), 705--721. (<a href='https://doi.org/10.1007/s10844-024-00912-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis has become an indispensable tool across various domains, including political communication, marketing analytics, and finance. In the financial sector, sentiments such as confidence or fear play a pivotal role in shaping market dynamics, influencing supply and demand, and precipitating significant price fluctuations. The timely extraction of sentiment from sources like financial news articles and social media posts is crucial for devising informed investment strategies. Despite its importance, current approaches to sentiment analysis in finance have not fully harnessed the potential of emerging technologies, such as large language models (LLMs) and quantum computing models. These cutting-edge technologies have demonstrated remarkable success in other areas of natural language processing (NLP), but their application in financial sentiment analysis remains limited. This paper aims to bridge this gap by introducing a novel quantum model for text representation, specifically designed for the financial domain. Our approach integrates this quantum representation with a vector-based representation generated by a pre-trained LLM specialized in finance. The resulting fusion of these two representations yields a more comprehensive input for an LLM, leading to a significant enhancement in the accuracy of the sentiment analysis task. We evaluate our approach through extensive experimental tests on a publicly available dataset and demonstrate that our quantum-based method outperforms state-of-the-art models on a widely recognized financial sentiment analysis benchmark. Our results highlight the potential of integrating quantum computing principles with traditional NLP methods for more accurate and effective sentiment analysis in finance.},
  archive      = {J_JIIS},
  author       = {Yang, Xi and Zhu, Jia and De Meo, Pasquale},
  doi          = {10.1007/s10844-024-00912-6},
  journal      = {Journal of Intelligent Information Systems},
  month        = {6},
  number       = {3},
  pages        = {705--721},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A quantum-like zero-shot approach for sentiment analysis in finance},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MYRTO: An efficient pervasive method for hybrid ML-based data filtered allocations. <em>JIIS</em>, <em>63</em>(2), 681--704. (<a href='https://doi.org/10.1007/s10844-024-00909-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a Pervasive Edge Computing (PEC) ecosystem, numerous Internet of Things (IoT) devices collect data from their environment and forward them to a network of Edge Computing (EC) nodes. Each EC node maintains a local dataset of the collected data and trains Machine Learning (ML) models to produce knowledge upon data, or to serve end user requests. Since data can be stored either on Cloud or on an EC node, a question arises regarding the optimal placement of such information with the ultimate goal of minimizing the latency when processing activities upon those data are requested. In this research, we tackle this issue by proposing MYRTO, which is novel methodology that decides where data should be allocated within a network of distributed nodes. MYRTO is a hybrid approach that utilises both data and statistical overlapping estimation techniques, to efficiently move data within the PEC network. Naturally, the collected data together with the data processing requests may alter the ML filters of the EC nodes. To account for this, MYRTO adopts a quantile regression technique that estimates the best data-ML filter overlapping and then, selects the appropriate nodes. If no nodes present adequate overlapping, the data are then uploaded to the Cloud. This way, our technique finds the optimal candidate for storing the IoT data between a large number of EC nodes, by selecting the one(s) that will exploit them more efficiently. We accompany our theoretical approach be a detailed evaluation methodology that clearly demonstrates the applicability of our work in PEC ecosystems.},
  archive      = {J_JIIS},
  author       = {Papathanasiou, Dimitrios and Tziouvaras, Athanasios and Kolomvatsos, Kostas},
  doi          = {10.1007/s10844-024-00909-1},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {681--704},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {MYRTO: An efficient pervasive method for hybrid ML-based data filtered allocations},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Addressing data imbalance for federated recommender systems: A rebalancing framework with gradient alignment regularization. <em>JIIS</em>, <em>63</em>(2), 657--679. (<a href='https://doi.org/10.1007/s10844-024-00910-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated recommender systems (FRSs) utilize decentralized data to offer personalized and privacy-preserving recommendations. Existing studies on FRSs overlook the issue of data imbalance, with clients possessing varying data volumes. Experimental results demonstrate that data imbalance across clients reduces the model’s performance in FRSs. In this paper, we propose BalFed for FRSs to address data imbalance. In BalFed, we devise gradient alignment regularization to reduce the negative impact of clients with excessive or insufficient data by constraining the gradient deviation between local and global models during training. Furthermore, we design an improved pseudo-labeling technique to address global data imbalance. The improved pseudo-labeling technique utilizes the inherent local and global models in FRSs to set dual thresholds, and thresholds are adaptively adjusted based on the performance of local models. We instantiate BalFed on various datasets, recommendation models, and federated algorithms. Evaluation results show an average performance improvement of 8.92% without introducing additional communication overhead, demonstrating its effectiveness.},
  archive      = {J_JIIS},
  author       = {Liu, Pingshan and Lu, Guoxin},
  doi          = {10.1007/s10844-024-00910-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {657--679},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Addressing data imbalance for federated recommender systems: A rebalancing framework with gradient alignment regularization},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stock price nowcasting and forecasting with deep learning. <em>JIIS</em>, <em>63</em>(2), 639--656. (<a href='https://doi.org/10.1007/s10844-024-00908-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have improved stock price forecasting with the emerging deep learning models. Despite advancements in deep learning, stock price prediction faces significant challenges. Existing studies predominantly focus on forecasting future prices, with limited attention to nowcasting, which predicts current or near-future market states. Additionally, most methods use univariate data, neglecting the valuable interactions between multiple financial variables. This study addresses these challenges by evaluating both forecasting and nowcasting approaches using deep learning. We incorporate multivariate inputs, including opening price, high, low, close, volume, inday-change and trend, to enhance the predictive power of our models. We implement and compare several deep learning methods: Long Short-Term Memory (LSTM) networks, Gated Recurrent Units (GRU), Convolutional Neural Networks combined with LSTM (CNN-LSTM), and the transformer-based Patch Time Series Transformer (PatchTST). Our experimental results reveal that the standard LSTM model achieves superior performance compared to the more recent PatchTST and CNN-LSTM models. Specifically, models perform better in nowcasting scenarios, likely due to smaller price fluctuations over shorter periods. Furthermore, our analysis shows that including variables such as opening prices, highest prices, and lowest prices enhances predictive accuracy, whereas trading volume tends to reduce performance. These findings suggest that deep learning models are more effective for real-time or near-term stock price prediction and highlight the importance of multivariate inputs in developing robust prediction models. This study provides valuable insights for enhancing the accuracy and reliability of stock price forecasts, with significant implications for financial analysts and investors.},
  archive      = {J_JIIS},
  author       = {Fan, Chuanzhi and Zhang, Xiang},
  doi          = {10.1007/s10844-024-00908-2},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {639--656},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Stock price nowcasting and forecasting with deep learning},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A denoising social recommendation method by fusing global-local node information of heterogeneous graphs. <em>JIIS</em>, <em>63</em>(2), 617--638. (<a href='https://doi.org/10.1007/s10844-024-00906-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presently, the integration of social networks into recommendation systems has emerged as a focal point in research and has found widespread applications in understanding user preferences. However, existing studies primarily focus on the influence of local information on recommendation effects, while the consideration of global information is relatively insufficient, which potentially further influences the topological structure of social communities. To address this challenge, we propose a Denoising Social Recommendation method by fusing Global-Local node information (GLDSR). First, user social relations and item association relations are combined to form a multi-assisted information graph. Simultaneously, user-item interaction relationships are integrated into the same heterogeneous graph, facilitating the propagation of multiple pieces of information within a unified framework. Subsequently, a denoising pre-training strategy is employed to filter out irrelevant features of nodes in the graph structure, and distinct encoders are devised for nodes based on heterogeneous relationships and global nodes within the graph. Finally, a relation aggregation network is deployed to capture relationship features. The effectiveness of the proposed model is evaluated on three real-world datasets, namely Ciao, Epinions, and Yelp. Experimental results demonstrate notable enhancements in hit rate (HR) and normalized discounted cumulative gain (NDCG) metrics.},
  archive      = {J_JIIS},
  author       = {Shen, Ningning and Zhao, Chao and Yan, Sitong and Jiang, Shaopeng},
  doi          = {10.1007/s10844-024-00906-4},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {617--638},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A denoising social recommendation method by fusing global-local node information of heterogeneous graphs},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SNOOKER: A dataset generator for helpdesk services. <em>JIIS</em>, <em>63</em>(2), 593--615. (<a href='https://doi.org/10.1007/s10844-024-00905-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of suitable datasets and data generators is crucial for developing intelligent systems, especially in helpdesk services. However, the lack of publicly accessible data generators focused on helpdesk operations, where incidents are often closed without detailing the treatment procedures, poses challenges to implementing intelligent systems such as recommender systems. To address this issue, a dataset generator can be employed to simulate helpdesk incidents. This paper introduces SNOOKER (dataSet geNeratOr fOr helpdesK sERvices), a customizable dataset generator designed to create and treat helpdesk tickets, including domain-specific incidents (e.g., cybersecurity) by orchestrating simulated actions and multiple IT teams. SNOOKER’s output is compared against a real anonymized dataset from S21Sec Cyber Solutions by Thales. The datasets are evaluated using Kolmogorov-Smirnov, Kullback-Leibler Divergence, and Hellinger distance tests, with results indicating similar distributions. For example, the first metric returned a low K-S value and a p-value exceeding 5%, while the second and third measures presented 0.003 and 0.03, respectively. Furthermore, experiments with different team configurations revealed that ticket scheduling highly depends on each team’s operators’ numbers and work shifts, increasing with unbalanced shifts and fewer operators.},
  archive      = {J_JIIS},
  author       = {Ferreira, Leonardo and Silva, Daniel Castro and Uriarte-Itzazelaia, Mikel},
  doi          = {10.1007/s10844-024-00905-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {593--615},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {SNOOKER: A dataset generator for helpdesk services},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent deep reinforcement learning for computation offloading in cooperative edge network. <em>JIIS</em>, <em>63</em>(2), 567--591. (<a href='https://doi.org/10.1007/s10844-024-00907-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Edge Computing (MEC) has emerged as an effective paradigm for reducing latency and enhancing computational efficiency. However, the rapid proliferation of edge servers and user devices has significantly increased the complexity of task processing and resource management. Traditional task offloading approaches often rely on centralized decision-making, resulting in high computational complexity and time costs. To address these challenges, this paper introduces a dynamic collaborative framework involving multiple users and edge servers. We formulate the problem of resource allocation and task offloading as a multi-objective Markov Decision Process (MDP) with a mixed action space. To solve this, we propose a novel algorithm called Multi-Agent Mobile Edge Computing (MA-MEC), which leverages multi-agent reinforcement learning. In MA-MEC, each mobile edge server (MES) operates as an independent learning agent. Through centralized training and decentralized execution, these agents collaborate to develop efficient task offloading strategies in complex and dynamic edge environments. Simulation results demonstrate the effectiveness of our approach. MES agents learn to execute tasks more efficiently, increasing the number of processed tasks by 12.5 $$\%$$ , while task offloading rates rise by 17 $$\%$$ , and time costs are reduced by 53 $$\%$$ compared to baseline methods. The proposed method shows significant advantages, especially in resource-constrained scenarios.},
  archive      = {J_JIIS},
  author       = {Wu, Pengju and Guan, Yepeng},
  doi          = {10.1007/s10844-024-00907-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {567--591},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Multi-agent deep reinforcement learning for computation offloading in cooperative edge network},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). News dissemination: A semantic approach to barrier classification. <em>JIIS</em>, <em>63</em>(2), 535--565. (<a href='https://doi.org/10.1007/s10844-024-00894-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dissemination of information worldwide is significantly facilitated by the news media, with many events having global relevance across various regions. However, certain news events receive limited coverage restricted to specific geographic areas, due to the barriers that hinder the spread of information. These barriers can be attributed to political, geographical, economic, cultural, or linguistic factors. In this research, we propose an approach for classifying these barriers by extracting semantic information from news articles using Wikipedia-concepts. Our methodology involves the collection of news articles, each annotated to indicate the specific barrier types, leveraging metadata from news publishers. Subsequently, we employ Wikipedia-concepts, in conjunction with the content of the news articles, as features to determine the barriers to news dissemination. Our approach is then compared with traditional text classification techniques, deep learning methods, and transformer-based models. We have performed experiments on news articles from ten categories of topics including health, sports, business, etc. The findings indicate that 1) Utilizing semantic knowledge yields distinct concepts across the ten categories, thereby enhancing the effectiveness and speed of the classification model. 2) The proposed approach, incorporating Wikipedia-concepts-based semantic knowledge, leads to improved performance in barrier classification when compared to using solely the body text of news articles. Specifically, there is an increase in the average F1-scores for four out of five barriers, with the economic barrier rising from 0.65 to 0.68, the linguistic barrier from 0.71 to 0.72, the political barrier from 0.68 to 0.70, and the geographical barrier from 0.63 to 0.68.},
  archive      = {J_JIIS},
  author       = {Sittar, Abdul and Mladenić, Dunja and Grobelnik, Marko},
  doi          = {10.1007/s10844-024-00894-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {535--565},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {News dissemination: A semantic approach to barrier classification},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classifying the content of online notepad services using active learning. <em>JIIS</em>, <em>63</em>(2), 507--533. (<a href='https://doi.org/10.1007/s10844-024-00902-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pastebin is an online notepad service to share text anonymously. However, it could be misused to propagate suspicious or even illegal activities, like leaking sensitive information or sharing hyperlinks to child sexual abuse material. Due to the high rate of daily upload pastes, manual inspection of this material is not feasible. Conversely, an automatic classifier could identify such activities with little or no human intervention. However, a supervised model may require a significant number of training samples and have to handle distinct text typologies presented in Pastebin. This paper presents a classification approach composed of three cascading supervised classifiers that use Active Learning to select and label the most informative samples from Pastebin. The modularity of the proposed design allows each classifier to adapt to a specific text typology. The first classifier determines whether the text is a code snippet, and the second is to identify whether it is readable. The third classification level is twofold: (i) a binary classifier to say whether the text is suspicious and (ii) a multiclass classifier with seven predefined categories of possibly illegal activities. The average class recall of the binary and multiclass classifiers is $$95.24\%$$ and $$80.33\%$$ , respectively. Additionally, this paper presents a dataset of 3.8 million Pastebin samples, called onlIne Notepad Services PastEbin aCtiviTies (INSPECT-3.8M), along with their labels using our classification framework. Our classifier recognised that $$7.54\%$$ of the collected samples are correlated with presumably criminal activities. Law enforcement agencies may benefit from the insights shared in our research when aiming to investigate or automate the monitoring of Pastebin or other Online Notepad Services. This would allow responsible authorities to block illegal content before it spreads to the public.},
  archive      = {J_JIIS},
  author       = {Al-Nabki, Mhd Wesam and Fidalgo, Eduardo and Alegre, Enrique and Delany, Sarah Jane and Jáñez-Martino, Francisco},
  doi          = {10.1007/s10844-024-00902-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {507--533},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Classifying the content of online notepad services using active learning},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained relation contrast enhancement of knowledge graph for recommendation. <em>JIIS</em>, <em>63</em>(2), 485--505. (<a href='https://doi.org/10.1007/s10844-024-00900-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of knowledge graphs (KGs) in recommender systems has achieved excellent results. Knowledge graphs, serving as auxiliary information, effectively alleviate issues related to data sparsity and the cold start problem, strengthening the modeling of item sets and the representation of user preferences. However, few works explore the fine-grained implicit relationships within knowledge graphs. In addition, most KG-based recommender systems only jointly model user-item interaction information and knowledge graph information, failing to effectively balance the relationship between these two types of information. To address these problems, we propose a Recommendation Algorithm Based on Fine-grained Relation Contrast Enhancement of Knowledge Graph (RA-FRCE). Specifically, we use the graph neural network to learn representations for nodes in the user-item interaction graph and collaborative knowledge graph. Then, we explore fine-grained implicit relationships in the knowledge graph, mine semantically similar items, and optimize the embedding of nodes through the implicit relationships. Subsequently, we conduct contrastive learning between semantic item information and item information in the collaborative knowledge graph to enhance item information. Finally, we adopt an adaptive adjustment fusion mechanism, dynamically adjusting the weights of interaction graph information and collaborative knowledge graph information to achieve collaborative optimization and adaptive fusion. Extensive experiments on three standard datasets show that our RA-FRCE model outperforms current state-of-the-art baselines. Our implementation codes are available at https://github.com/UPCRS/RAFRCE .},
  archive      = {J_JIIS},
  author       = {Zhang, Junsan and Wang, Te and Wu, Sini and Ding, Fengmei and Zhu, Jie},
  doi          = {10.1007/s10844-024-00900-w},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {485--505},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Fine-grained relation contrast enhancement of knowledge graph for recommendation},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the trie of rules: A fast data structure for the representation of association rules. <em>JIIS</em>, <em>63</em>(2), 463--483. (<a href='https://doi.org/10.1007/s10844-024-00899-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Association rule mining techniques can generate a large volume of sequential data when implemented on transactional databases. Extracting insights from a large set of association rules has been found to be a challenging process. When examining a ruleset, the fundamental question is how to summarise and represent meaningful mined knowledge efficiently. Many algorithms and strategies have been developed to address issue of knowledge extraction; however, the effectiveness of this process can be limited by the data structures. A better data structure can sufficiently affect the speed of the knowledge extraction process. This paper proposes a novel data structure, called the Trie of rules, for storing a ruleset that is generated by association rule mining. The resulting data structure is a prefix-tree graph structure made of pre-mined rules. This graph stores the rules as paths within the prefix-tree in a way that similar rules overlay each other. Each node in the tree represents a rule where a consequent is this node, and an antecedent is a path from this node to the root of the tree. The evaluation showed that the proposed representation technique shows significant value. It compresses a ruleset with no data loss and benefits in terms of time for basic operations such as searching for a specific rule, which is the base for many knowledge discovery methods. Moreover, our method demonstrated a significant improvement in graph traversal time compared to traditional data structures.},
  archive      = {J_JIIS},
  author       = {Kudriavtsev, Mikhail and Ngo, Vuong M. and Roantree, Mark and Bezbradica, Marija and McCarren, Andrew},
  doi          = {10.1007/s10844-024-00899-0},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {463--483},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Exploring the trie of rules: A fast data structure for the representation of association rules},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting inpatient admissions in district hospitals: A hybrid model approach. <em>JIIS</em>, <em>63</em>(2), 441--462. (<a href='https://doi.org/10.1007/s10844-024-00895-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The patient arrival pattern in a hospital is a critical area of concern for any healthcare delivery system. Weekends, holidays, festivities, and natural disasters might change arrival patterns. This non-uniform pattern and changeable medical care requirements necessitate effective healthcare planning and resource management. Near-accurate inpatient admission forecasting improves healthcare management. This study aims to develop the most suitable forecasting model and uncover the key features influencing inpatient admissions. This study uses data from January 2021 to October 2023 at three Indian district hospitals to forecast daily inpatient admissions for a monthly timeframe. We employ six forecasting models: random forest (RF), support vector regression (SVR), extreme gradient boosting (XGBoost), seasonal autoregressive integrated moving average with exogenous variables (SARIMAX), and linear regression (LR) models. We develop a hybrid model by integrating SARIMAX and XGBoost using a parallel-series approach to improve forecasting accuracy. Shapley Additive exPlanations (SHAP) scores determine inpatient admission feature consistency. The hybrid model outperforms all other models in all three hospitals. Individually, the SARIMAX and XGBoost models had higher error rates. The RollingMean_7, day of week, residual, holiday, and month consistently emerges as the most significant features for all hospitals. The developed hybrid model’s superiority in predicting inpatient admissions for all three hospitals highlights its practical applicability. The developed model, tested in three different settings, gives near-accurate predictions, irrespective of the pattern and quantum of arrival of patients in hospitals. Our hybrid approach enhances forecasting accuracy - crucial for managing resources, staff scheduling, and inventory in effective inpatient admissions management.},
  archive      = {J_JIIS},
  author       = {Gurjar, Anil and Ghosh, Anupam},
  doi          = {10.1007/s10844-024-00895-4},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {441--462},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Forecasting inpatient admissions in district hospitals: A hybrid model approach},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Persuasive explanations for path reasoning recommendations. <em>JIIS</em>, <em>63</em>(2), 413--439. (<a href='https://doi.org/10.1007/s10844-024-00896-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Providing explanations for recommendations has emerged as a critical factor for facilitating effective human decision-making and ensuring user satisfaction. While path-based explanation generation approaches in recommender systems leveraging knowledge graphs have been widely studied, they have overlooked the persuasiveness of explanations. This paper addresses this gap by introducing a personalized approach to measure the persuasiveness of each path explanation, utilizing users’ persuasion profiles derived from their personalities. Subsequently, a re-ranking approach is proposed to optimize the top-n list of recommended products, considering both recommendation utility and the persuasiveness of explanations. Experimental results on a real-world Movie recommendation dataset, employing the recent path reasoning recommender system baselines, demonstrate the effectiveness of our proposed approach in providing a relevant recommendation list with personalized persuasive explanations. Additionally, we investigate the influence of the proposed approach on multiple dimensions of explanation quality beyond persuasiveness. Furthermore, we explore the performance of our approach among user groups characterized by diverse personality traits.},
  archive      = {J_JIIS},
  author       = {Alizadeh Noughabi, Havva and Behkamal, Behshid and Zarrinkalam, Fattane and Kahani, Mohsen},
  doi          = {10.1007/s10844-024-00896-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {413--439},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Persuasive explanations for path reasoning recommendations},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An application of deep choice modeling for engagement maximization on Twitter/X. <em>JIIS</em>, <em>63</em>(2), 395--411. (<a href='https://doi.org/10.1007/s10844-024-00893-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the contemporary digital era, individuals are frequently inundated with voluminous content on their home timelines, leading to information overload. As a result, even relevant content might get sidelined and overlooked by users, resulting in a long-term negative impact on engagement. While existing state-of-the-art recommender systems address this problem successfully to an extent using the historical engagement data and users’ social graphs, they don’t explicitly account for users’ choice behavior on engagement in these platforms. In this work, we address the problem of maximizing user engagement with tweet content by explicitly considering the choice behavior of users. We formulate the engagement forecasting task as a multi-label classification problem that captures choice behavior based on an unsupervised clustering of tweet-topics. We propose a neural network model that incorporates engagement history and predicts user choices conditional on this context. We study the impact of recommending tweets on engagement outcomes by solving an appropriately defined tweet optimization problem based on our proposed model using a large publicly available dataset. Our extensive experiments reveal that our model outperforms the state-of-the-art recommendation methods and discrete choice models from the existing literature across multiple performance metrics.},
  archive      = {J_JIIS},
  author       = {Karra, Saketh Reddy and Tulabandhula, Theja},
  doi          = {10.1007/s10844-024-00893-6},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {395--411},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {An application of deep choice modeling for engagement maximization on Twitter/X},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MLGAT: Multi-layer graph attention networks for multimodal emotion recognition in conversations. <em>JIIS</em>, <em>63</em>(2), 375--394. (<a href='https://doi.org/10.1007/s10844-024-00879-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of digital interactions, multimodal emotion recognition has gained significant research interest. In conversations, people use multiple modalities like text, voice, and images to convey emotions.However, effectively integrating and utilizing these different modalities remains challenging. We propose a novel multimodal emotion recognition model named Multi-Layer Graph Attention Network (MLGAT) to address this. The model constructs a graph structure for each modality (text, speech, and image) and introduces a multi-layer graph attention mechanism to capture relationships between nodes within each modality effectively.The MLGAT network model fuses graph structures from multiple modalities into a unified multimodal graph, allowing joint learning and feature fusion. During training, multimodal sentiment labels supervise the network, enabling the model to learn effective sentiment representations. Experimental results show that the MLGAT model significantly improves the accuracy and robustness of multimodal emotion recognition compared to traditional models.},
  archive      = {J_JIIS},
  author       = {Wu, Jun and Wu, Junwei and Zheng, Yu and Zhan, Pengfei and Han, Min and Zuo, Gan and Yang, Li},
  doi          = {10.1007/s10844-024-00879-4},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {375--394},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {MLGAT: Multi-layer graph attention networks for multimodal emotion recognition in conversations},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous graphormer for extractive multimodal summarization. <em>JIIS</em>, <em>63</em>(2), 355--373. (<a href='https://doi.org/10.1007/s10844-024-00886-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal summarization with multimodal output (MSMO) aims to generate summaries that incorporate both text and images. Existing methods have not effectively leveraged intermodal relationships, such as sentence-image relationships, which are crucial for generating high-quality multimodal summaries. In this paper, we propose a heterogeneous graph-based model for multimodal summarization (HGMS) designed to efficiently leverage intermodal relationships within multimodal data. The model constructs a heterogeneous graph based on the relationships between modalities, containing nodes for words, sentences and images. An enhanced Graphormer is then proposed to update node representations, aiming to more effectively model intricate relationships between multiple modalities. To the best of our knowledge, we are the first to apply Graphormer in the field of graph-based summarization. Experimental results on a large-scale benchmark dataset demonstrate that HGMS achieves state-of-the-art performance in terms of automatic metrics and human evaluations.},
  archive      = {J_JIIS},
  author       = {Jiang, Xiankai and Chen, Jingqiang},
  doi          = {10.1007/s10844-024-00886-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {4},
  number       = {2},
  pages        = {355--373},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Heterogeneous graphormer for extractive multimodal summarization},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised seed-driven approach to topic modelling and clustering. <em>JIIS</em>, <em>63</em>(1), 333--353. (<a href='https://doi.org/10.1007/s10844-024-00891-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topic models are useful tools for extracting the most salient themes within a collection of documents, grouping them to construct clusters representative of each specific topic. These clusters summarize and represent the semantic contents of the documents for better document interpretation. In this work, we present a light approach able to learn topic representations in a Self-Supervised fashion. More specifically, we propose a lightweight and scalable architecture using a seed-word driven approach to simultaneously co-learn a representation from a document and its corresponding word embeddings. The results obtained on a variety of datasets of different sizes and natures show that our model is capable of extracting meaningful topics. Furthermore, our experiments on five benchmark datasets illustrate that our model outperforms both traditional and neural topic modelling baseline models in terms of different coherence and clustering accuracy measures.},
  archive      = {J_JIIS},
  author       = {Ravenda, Federico and Bahrainian, Seyed Ali and Raballo, Andrea and Mira, Antonietta and Crestani, Fabio},
  doi          = {10.1007/s10844-024-00891-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {333--353},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A self-supervised seed-driven approach to topic modelling and clustering},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement negative sampling recommendation based on collaborative knowledge graph. <em>JIIS</em>, <em>63</em>(1), 313--332. (<a href='https://doi.org/10.1007/s10844-024-00892-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sampling high-quality negative samples and training together with positive samples can help improve the performance and generalization ability of the recommendation model. However, traditional negative sampling methods, such as random sampling or heuristic rules, often fail to adequately capture negative samples that reflect the user’s true taste. To provide interpretability and diversity of negative samples, we propose a collaborative knowledge graph-based reinforcement negative sampling recommendation model called KGRec-RNS that formalizes the problem of finding negative signals into a Markov decision process (MDP). Firstly, user interaction data and external knowledge are integrated into a collaborative Bipartite-Knowledge graph (BKG) as MDP context information environment. Then, an Actor based sampler including graph learning module, neighbor attention module and neighbor pruning module is designed. The graph learning module utilizes graph convolutional neural network (GCN) to extract high-order information of each node, the neighbor attention module is adopted to distinguish the influence of different nodes, and the user conditional action pruning strategy is integrated. Thus, negative samples with interpretability can be screened out. Finally, a Critic based recommender was designed to evaluate the current state and the action reward to guide the policy update of the Actor network, thereby matching high-quality negative samples with positive samples. The experimental results on three real datasets demonstrate that our KGRec-RNS has significant advantages in providing more accurate and diverse recommendations.},
  archive      = {J_JIIS},
  author       = {Zhao, Mengjie and Xun, Yaling and Zhang, Jifu and Li, Yanfeng},
  doi          = {10.1007/s10844-024-00892-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {313--332},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Reinforcement negative sampling recommendation based on collaborative knowledge graph},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph attention networks with adaptive neighbor graph aggregation for cold-start recommendation. <em>JIIS</em>, <em>63</em>(1), 293--312. (<a href='https://doi.org/10.1007/s10844-024-00888-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cold-start problem is a long-standing problem in recommender systems, i.e., lack of historical interaction information hinders effective recommendations for new users and items. Existing methods typically incorporate attribute information of users and items to address the strict cold-start problem. Most existing recommendation methods overlook the sparsity of user attributes in cold start recommendation systems. In this paper, we develop a novel framework, Graph Attention Networks with Adaptive Neighbor Graph Aggregation for cold-start Recommendation (A-GAR), which utilizes the user/item relationship information in cold-start recommendation systems to alleviate the sparsity of attributes. we can achieve more accurate recommendations in cold-start scenarios by fully exploring the complex relations between users/items using graph structures. Specifically, to learn the complex relationships between user/item attributes, we utilize SENet (Squeeze and Excitation Network) and MLP (Multilayer Perceptron) networks to adaptively fuse the embeddings of user/item and their second-order interaction vectors, achieving high-order feature aggregation. To address the issue of lacking preference information in cold-start recommendations, we extend the variational autoencoder to reconstruct missing user preferences (item characteristics) from higher-order attribute features of users/items. In order to learn the potential semantic relationships of nodes in the neighbor graph structure, an attribute graph attention network is used to aggregate the neighbor information of users and the interaction information between neighbors. In this way, the high-order relationships between nodes and the potential semantics of adjacent graphs can be fully explored. Extensive experiments on three real-word datasets with various cold-start scenarios demonstrate that A-GAR yields significant improvements for strict cold-start recommendations.},
  archive      = {J_JIIS},
  author       = {Hu, Qian and Tan, Lei and Gong, Daofu and Li, Yan and Bu, Wenjuan},
  doi          = {10.1007/s10844-024-00888-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {293--312},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Graph attention networks with adaptive neighbor graph aggregation for cold-start recommendation},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nirdizati: An advanced predictive process monitoring toolkit. <em>JIIS</em>, <em>63</em>(1), 259--291. (<a href='https://doi.org/10.1007/s10844-024-00890-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive Process Monitoring (PPM) is a field of Process Mining that aims at predicting how an ongoing execution of a business process will develop in the future using past process executions recorded in event logs. The recent stream of publications in this field shows the need for tools able to support researchers and users in comparing and selecting the techniques that are the most suitable for them. In this paper, we present Nirdizati , a dedicated tool for supporting users in building, comparing and explaining the PPM models that can then be used to perform predictions on the future of an ongoing case. Nirdizati has been constructed by carefully considering the necessary capabilities of a PPM tool and by implementing them in a client-server architecture able to support modularity and scalability. The features of Nirdizati support researchers and practitioners within the entire pipeline for constructing reliable PPM models. The assessment using reactive design patterns and load tests provides an evaluation of the interaction among the architectural elements, and of the scalability with multiple users accessing the prototype in a concurrent manner, respectively. By providing a rich set of different state-of-the-art approaches, Nirdizati offers to Process Mining researchers and practitioners a useful and flexible instrument for comparing and selecting PPM techniques.},
  archive      = {J_JIIS},
  author       = {Rizzi, Williams and Di Francescomarino, Chiara and Ghidini, Chiara and Maggi, Fabrizio Maria},
  doi          = {10.1007/s10844-024-00890-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {259--291},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Nirdizati: An advanced predictive process monitoring toolkit},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedGR: Cross-platform federated group recommendation system with hypergraph neural networks. <em>JIIS</em>, <em>63</em>(1), 227--257. (<a href='https://doi.org/10.1007/s10844-024-00887-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group recommendation systems are widely applied in social media, e-commerce, and diverse platforms. These systems face challenges associated with data privacy constraints and protection regulations, impeding the sharing of user data for model improvement. To address the issue of data silos, federated learning emerges as a viable solution. However, difficulties arise due to the non-independent and non-identically distributed nature of data across different platforms, affecting performance. Furthermore, conventional federated learning often overlooks individual differences among stakeholders. In response to these challenges, we propose a pioneering cross-platform federated group recommendation system named FedGR. FedGR integrates hypergraph convolution, attention aggregation, and fully connected fusion components with federated learning to ensure exceptional model performance while preserving the confidentiality of private data. Additionally, we introduce a novel federated model aggregation strategy that prioritizes models with high training effectiveness, thereby improving overall model performance. To address individual differences, we design a temporal personalization update strategy for updating item representations, allowing local models to focus more on their individual characteristics. To evaluate FedGR, we apply our approach to three real-world datasets, demonstrating the robust capabilities of our cross-platform group recommendation system.},
  archive      = {J_JIIS},
  author       = {Zeng, Junlong and Huang, Zhenhua and Wu, Zhengyang and Chen, Zonggan and Chen, Yunwen},
  doi          = {10.1007/s10844-024-00887-4},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {227--257},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {FedGR: Cross-platform federated group recommendation system with hypergraph neural networks},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DA-BAG: A multi-model fusion text classification method combining BERT and GCN using self-domain adversarial training. <em>JIIS</em>, <em>63</em>(1), 205--225. (<a href='https://doi.org/10.1007/s10844-024-00889-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-training-based methods are considered some of the most advanced techniques in natural language processing tasks, particularly in text classification. However, these methods often overlook global semantic information. In contrast, traditional graph learning methods focus solely on structured information from text to graph, neglecting the hidden local information within the syntactic structure of the text. When combined, these approaches may introduce new noise and training biases. To tackle these challenges, we introduce DA-BAG, a novel approach that co-trains BERT and graph convolution models. Utilizing a self-domain adversarial training method on a single dataset, DA-BAG extracts multi-domain distribution features across multiple models, enabling self-adversarial domain adaptation training without the need for additional data, thereby enhancing model generalization and robustness. Furthermore, by incorporating an attention mechanism in multiple models, DA-BAG effectively combines the structural semantics of the graph with the token-level semantics of the pre-trained model, leveraging hidden information within the text’s syntactic structure. Additionally, a sequential multi-layer graph convolutional neural(GCN) connection structure based on a residual pre-activation variant is employed to stabilize the feature distribution of graph data and adjust the graph data structure accordingly. Extensive evaluations on 5 datasets(20NG, R8, R52, Ohsumed, MR) demonstrate that DA-BAG achieves state-of-the-art performance across a diverse range of datasets.},
  archive      = {J_JIIS},
  author       = {Shao, Dangguo and Su, Shun and Ma, Lei and Yi, Sanli and Lai, Hua},
  doi          = {10.1007/s10844-024-00889-2},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {205--225},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {DA-BAG: A multi-model fusion text classification method combining BERT and GCN using self-domain adversarial training},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing user experience: A content-based recommendation approach for addressing cold start in music recommendation. <em>JIIS</em>, <em>63</em>(1), 183--204. (<a href='https://doi.org/10.1007/s10844-024-00872-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems play a major role in modern music streaming platforms, assisting consumers in finding new music that suits their tastes. However, a significant challenge persists when it comes to recommending new songs that lack historical data. This study introduces a Content based Attentive Sequential Recommendation Model (CASRM) that deals with item cold start issue and recommends relevant and fresh music using Gated Graph Neural Networks (GNNs). Music metadata such as artists, albums, genres, and tags are included in the content information, along with context data incorporating user behaviour such as sessions, listening logs, and music playing sequences. By representing the music data as a graph, we can effectively capture the intricate relationships between songs and users. To capture users’ music preferences, we analyse their interactions with songs within the sessions. We incorporate content-based item embeddings for newly added items, enabling personalized recommendations for new songs based on their characteristics and similarities to the songs listened by users in the past. Specifically, we examined the proposed model on three distinct datasets, and the experimental outcomes show its efficacy in predicting music ratings for new songs. Compared to other baseline methods, the CASRM model achieves superior performance in providing accurate and diverse music recommendations in cold-start scenarios.},
  archive      = {J_JIIS},
  author       = {Jangid, Manisha and Kumar, Rakesh},
  doi          = {10.1007/s10844-024-00872-x},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {183--204},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Enhancing user experience: A content-based recommendation approach for addressing cold start in music recommendation},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting bipolar disorder on social media by post grouping and interpretable deep learning. <em>JIIS</em>, <em>63</em>(1), 161--182. (<a href='https://doi.org/10.1007/s10844-024-00884-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bipolar disorder is a disorder in which a person expresses manic and depressed emotions repeatedly. Diagnosing bipolar disorder accurately can be difficult because other mood disorders or even regular mood changes may have similar symptoms. Therefore, psychiatrists need to spend a long time observing and interviewing clients to make the diagnosis. Recent studies have trained machine learning models for detecting bipolar disorder on social media. However, most of these studies focused on increasing the accuracy of the model without explaining the classification results. Although the posts of a bipolar disorder user can be observed manually, doing so is not practical since a user can have many posts which may not depict any signs of bipolar disorder. Without any explanations, the trustworthiness of the model decreases. We propose a deep learning model that not only detects and classifies bipolar disorder users but also explains how the model generates the classification results. The posts are first grouped using Latent Dirichlet Allocation, a method commonly used to classify the topic of a text. These groups are then input into the model, and attention mechanisms are utilized to determine which groups have more attention weights and are considered more heavily. Finally, an explanation of the classification results is obtained by visualizing the attention weights. Several case studies are presented to demonstrate the explanations generated through our proposed model. Our model is also compared to other models, achieving the best performance with an F1-Score of 0.92.},
  archive      = {J_JIIS},
  author       = {Thamrin, Syauki Aulia and Chen, Eva E. and Chen, Arbee L. P.},
  doi          = {10.1007/s10844-024-00884-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {161--182},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Detecting bipolar disorder on social media by post grouping and interpretable deep learning},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pathways to success: A machine learning approach to predicting investor dynamics in equity and lending crowdfunding campaigns. <em>JIIS</em>, <em>63</em>(1), 135--159. (<a href='https://doi.org/10.1007/s10844-024-00883-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdfunding has evolved into a formidable mechanism for collective financing, challenging traditional funding sources such as bank loans, venture capital, and private equity with its global reach and versatile applications across various sectors. This paper explores the complex dynamics of crowdfunding platforms, particularly focusing on investor behaviour and investment patterns within equity and lending campaigns in Italy. By leveraging advanced machine learning techniques, including XGBoost and LSTM networks, we develop predictive models that dynamically analyze real-time and historical data to accurately forecast the success or failure of crowdfunding campaigns. To address the existing gaps in crowdfunding analysis tools, we introduce two novel datasets—one for equity crowdfunding and another for lending. Moreover, our approach extends beyond traditional binary success metrics, proposing novel measures. The insights gained from this study could support crowdfunding strategies, significantly improving project selection and promotional tactics on platforms. By enhancing decision-making processes and providing forward-looking guidance to investors, our computational model aims to empower both campaign creators and platform administrators, ultimately improving the overall efficacy and sustainability of crowdfunding as a financing tool.},
  archive      = {J_JIIS},
  author       = {Porro, Rosa and Ercole, Thomas and Pipitò, Giuseppe and Vessio, Gennaro and Loglisci, Corrado},
  doi          = {10.1007/s10844-024-00883-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {135--159},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Pathways to success: A machine learning approach to predicting investor dynamics in equity and lending crowdfunding campaigns},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning approaches to lexical simplification: A survey. <em>JIIS</em>, <em>63</em>(1), 111--134. (<a href='https://doi.org/10.1007/s10844-024-00882-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lexical Simplification (LS) is the task of substituting complex words within a sentence for simpler alternatives while maintaining the sentence’s original meaning. LS is the lexical component of Text Simplification (TS) systems with the aim of improving accessibility to various target populations such as individuals with low literacy or reading disabilities. Prior surveys have been published several years before the introduction of transformers, transformer-based large language models (LLMs), and prompt learning that have drastically changed the field of NLP. The high performance of these models has sparked renewed interest in LS. To reflect these recent advances, we present a comprehensive survey of papers published since 2017 on LS and its sub-tasks focusing on deep learning. Finally, we describe available benchmark datasets for the future development of LS systems.},
  archive      = {J_JIIS},
  author       = {North, Kai and Ranasinghe, Tharindu and Shardlow, Matthew and Zampieri, Marcos},
  doi          = {10.1007/s10844-024-00882-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {111--134},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Deep learning approaches to lexical simplification: A survey},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning approaches to predict the execution time of the meteorological simulation software COSMO. <em>JIIS</em>, <em>63</em>(1), 85--109. (<a href='https://doi.org/10.1007/s10844-024-00880-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the execution time of weather forecast models is a complex task, since these models are usually performed on High Performance Computing systems that require large computing capabilities. Indeed, a reliable prediction can imply several benefits, by allowing for an improved planning of the model execution, a better allocation of available resources, and the identification of possible anomalies. However, to make such predictions is usually hard, since there is a scarcity of datasets that benchmark the existing meteorological simulation models. In this work, we focus on the runtime predictions of the execution of the COSMO (COnsortium for SMall-scale MOdeling) weather forecasting model used at the Hydro-Meteo-Climate Structure of the Regional Agency for the Environment and Energy Prevention Emilia-Romagna. We show how a plethora of Machine Learning approaches can obtain accurate runtime predictions of this complex model, by designing a new well-defined benchmark for this application task. Indeed, our contribution is twofold: 1) the creation of a large public dataset reporting the runtime of COSMO run under a variety of different configurations; 2) a comparative study of ML models, which greatly outperform the current state-of-practice used by the domain experts. This data collection represents an essential initial benchmark for this application field, and a useful resource for analyzing the model performance: better accuracy in runtime predictions could help facility owners to improve job scheduling and resource allocation of the entire system; while for a final user, a posteriori analysis could help to identify anomalous runs.},
  archive      = {J_JIIS},
  author       = {De Filippo, Allegra and Di Giacomo, Emanuele and Borghesi, Andrea},
  doi          = {10.1007/s10844-024-00880-x},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {85--109},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Machine learning approaches to predict the execution time of the meteorological simulation software COSMO},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Span-based semantic syntactic dual enhancement for aspect sentiment triplet extraction. <em>JIIS</em>, <em>63</em>(1), 63--83. (<a href='https://doi.org/10.1007/s10844-024-00881-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-Based Sentiment Triple Extraction (ASTE), a critical sub-task of Aspect-Based Sentiment Analysis (ABSA), has received extensive attention in recent years. ASTE aims to extract structured sentiment triples from texts, with most existing studies focusing on designing new strategic frameworks. Nonetheless, these methods often overlook the complex characteristics of linguistic expression and the deeper semantic nuances, leading to deficiencies in extracting the semantic representations of triples and effectively utilizing syntactic relationships in texts. To address these challenges, this paper introduces a span-based semantic and syntactic Dual-Enhanced model that deeply integrates rich syntactic information, such as part-of-speech tagging, constituent syntax, and dependency syntax structures. Specifically, we designed a semantic encoder and a syntactic encoder to capture the semantic-syntactic information closely related to the sentence’s underlying intent. Through a Feature Interaction Module, we effectively integrate information across different dimensions and promote a more comprehensive understanding of the relationships between aspects and opinions. We also adopted a span-based tagging scheme that generates more precise aspect sentiment triple extractions by exploring cross-level information and constraints. Experimental results on benchmark datasets derived from the SemEval challenge prove that our model significantly outperforms existing baselines.},
  archive      = {J_JIIS},
  author       = {Ren, Shuxia and Guo, Zewei and Li, Xiaohan and Zhong, Ruikun},
  doi          = {10.1007/s10844-024-00881-w},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {63--83},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Span-based semantic syntactic dual enhancement for aspect sentiment triplet extraction},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal knowledge completion enhanced self-supervised entity alignment. <em>JIIS</em>, <em>63</em>(1), 43--62. (<a href='https://doi.org/10.1007/s10844-024-00878-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal graph entity alignment aims at finding the equivalent entity pairs across different temporal knowledge graphs (TKGs). Primarily methods mainly utilize a time-aware and relationship-aware approach to embed and align. However, the existence of long-tail entities in TKGs still restricts the accuracy of alignment, as the limited neighborhood information may restrict the available neighborhood information for obtaining high-quality embeddings, and hence would impact the efficiency of entity alignment in representation space. Moreover, most previous researches are supervised, with heavy dependence on seed labels for alignment, restricting their applicability in scenarios with limited resources. To tackle these challenges, we propose a Temporal Knowledge Completion enhanced Self-supervised Entity Alignment (TSEA). We argue that, with high-quality embeddings, the entities would be aligned in a self-supervised manner. To this end, TSEA is constituted of two modules: A graph completion module to predict the missing links for the long-tailed entities. With the improved graph, TSEA further incorporates a self-supervised entity alignment module to achieve unsupervised alignment. Experimental results on widely adopted benchmarks demonstrate improved performance compared to several recent baseline methods. Additional ablation experiments further corroborate the efficacy of the proposed modules.},
  archive      = {J_JIIS},
  author       = {Fu, Teng and Zhou, Gang},
  doi          = {10.1007/s10844-024-00878-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {43--62},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Temporal knowledge completion enhanced self-supervised entity alignment},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint entity and relation extraction with fusion of multi-feature semantics. <em>JIIS</em>, <em>63</em>(1), 21--42. (<a href='https://doi.org/10.1007/s10844-024-00871-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity relation extraction is a key technology for extracting structured information from unstructured text and serves as the foundation for building large-scale knowledge graphs. Current joint entity relation extraction methods primarily focus on improving the recognition of overlapping triplets to enhance the overall performance of the model. However, the model still faces numerous challenges in managing intra-triplet and inter-triplet interactions, expanding the breadth of semantic encoding, and reducing information redundancy during the extraction process. These issues make it challenging for the model to achieve satisfactory performance in both normal and overlapping triple extraction. To address these challenges, this study proposes a comprehensive prediction network that includes multi-feature semantic fusion. We have developed a semantic fusion module that integrates entity mask embedding sequences, which enhance connections between entities, and context embedding sequences that provide richer semantic information, to enhance inter-triplet interactions and expand semantic encoding. Subsequently, using a parallel decoder to simultaneously generate a set of triplets, improving the interaction between them. Additionally, we utilize an entity mask sequence to finely prune these triplets, optimizing the final set of triplets. Experimental results on the publicly available datasets NYT and WebNLG demonstrate that, with BERT as the encoder, our model outperforms the baseline model in terms of accuracy and F1 score.},
  archive      = {J_JIIS},
  author       = {Wang, Ting and Yang, Wenjie and Wu, Tao and Yang, Chuan and Liang, Jiaying and Wang, Hongyang and Li, Jia and Xiang, Dong and Zhou, Zheng},
  doi          = {10.1007/s10844-024-00871-y},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {21--42},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Joint entity and relation extraction with fusion of multi-feature semantics},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-task learning and mutual information maximization with crossmodal transformer for multimodal sentiment analysis. <em>JIIS</em>, <em>63</em>(1), 1--19. (<a href='https://doi.org/10.1007/s10844-024-00858-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effectiveness of multimodal sentiment analysis hinges on the seamless integration of information from diverse modalities, where the quality of modality fusion directly influences sentiment analysis accuracy. Prior methods often rely on intricate fusion strategies, elevating computational costs and potentially yielding inaccurate multimodal representations due to distribution gaps and information redundancy across heterogeneous modalities. This paper centers on the backpropagation of loss and introduces a Transformer-based model called Multi-Task Learning and Mutual Information Maximization with Crossmodal Transformer (MMMT). Addressing the issue of inaccurate multimodal representation for MSA, MMMT effectively combines mutual information maximization with crossmodal Transformer to convey more modality-invariant information to multimodal representation, fully exploring modal commonalities. Notably, it utilizes multi-modal labels for uni-modal training, presenting a fresh perspective on multi-task learning in MSA. Comparative experiments on the CMU-MOSI and CMU-MOSEI datasets demonstrate that MMMT improves model accuracy while reducing computational burden, making it suitable for resource-constrained and real-time performance-requiring application scenarios. Additionally, ablation experiments validate the efficacy of multi-task learning and probe the specific impact of combining mutual information maximization with Transformer in MSA.},
  archive      = {J_JIIS},
  author       = {Shi, Yang and Cai, Jinglang and Liao, Lei},
  doi          = {10.1007/s10844-024-00858-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {1--19},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Multi-task learning and mutual information maximization with crossmodal transformer for multimodal sentiment analysis},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
