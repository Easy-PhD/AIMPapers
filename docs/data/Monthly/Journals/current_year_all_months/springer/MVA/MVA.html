<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MVA</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mva">MVA - 4</h2>
<ul>
<li><details>
<summary>
(2026). A multi-target physiological signal detection method for UWB radar based on kalman tracking and dual-branch network. <em>MVA</em>, <em>37</em>(1), 1--13. (<a href='https://doi.org/10.1007/s00138-025-01754-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel non-contact physiological signal detection method using Ultra-Wideband (UWB) radar, integrating Kalman tracking and time-frequency deep learning to mitigate range gate jitter and noise in multi-target scenarios. A dynamic threshold adaptive peak detection method, combined with multi-Kalman filtering, ensures robust target acquisition. A deep learning model with frequency domain enhancement improves respiratory rate (RR) and heart rate (HR) detection accuracy. The framework employs multi-task learning, optimizing RR regression, HR classification, enhancing both interpretability and robustness. Experiments at 3 ms show a range detection error below 0.05 ms, with root mean square errors of 0.009 Hz and 0.04 Hz for RR and RR, respectively, over 60% more accurate than traditional fast Fourier transform methods. The approach is computationally efficient and highly applicable in telemedicine, smart home monitoring, and related fields.},
  archive      = {J_MVA},
  author       = {Li, Ziqi and Jia, Dongyao and He, Zihao and Wu, Nengkai},
  doi          = {10.1007/s00138-025-01754-0},
  journal      = {Machine Vision and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--13},
  shortjournal = {Mach. Vis. Appl.},
  title        = {A multi-target physiological signal detection method for UWB radar based on kalman tracking and dual-branch network},
  volume       = {37},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Advancing abstract reasoning for RPMs with a path aggregation network and deep predictive reasoning. <em>MVA</em>, <em>37</em>(1), 1--14. (<a href='https://doi.org/10.1007/s00138-025-01760-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagrammatic reasoning challenges machines to interpret visual patterns, infer abstract relationships, and apply logical rules-tasks at which humans naturally excel. Yet, capturing multi-scale dependencies and generalizing across diverse visual tasks remains difficult for artificial systems. To address these challenges, we present PAtNet, a novel neural architecture that introduces two key methodological innovations: a Path Aggregation Network (PAN) for robust multi-scale feature representation, and a Deep Predictive Reasoning Block (DPRB) that models contextual relationships and predicts missing or occluded feature components. These modules work in concert to enhance both hierarchical feature extraction and relational reasoning. Through comprehensive experiments on the RAVEN, I-RAVEN, and RAVEN-FAIR benchmarks, PAtNet consistently outperforms previous state-of-the-art methods, with accuracy improvements of 1.3%, 0.3 %, and 1.2%, respectively. Ablation studies further demonstrate that the synergy between multi-scale representations from PAN and the contextual inference of DPRB leads to more robust and interpretable diagrammatic reasoning, advancing the field toward deep learning models grounded in cognitive principles.},
  archive      = {J_MVA},
  author       = {Singh, Amresh Kumar and Khanna, Sandeep and Chattopadhyay, Chiranjoy},
  doi          = {10.1007/s00138-025-01760-2},
  journal      = {Machine Vision and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--14},
  shortjournal = {Mach. Vis. Appl.},
  title        = {Advancing abstract reasoning for RPMs with a path aggregation network and deep predictive reasoning},
  volume       = {37},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CCPose: High-precision six-dimensional pose estimation for industrial objects. <em>MVA</em>, <em>37</em>(1), 1--20. (<a href='https://doi.org/10.1007/s00138-025-01763-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-precision six-degree-of-freedom (6D) pose estimation of texture-less industrial objects is a critical capability for advancing industrial robotics, particularly in high-mix production environments. Existing methods often struggle with texture-less or reflective objects and lack the millimeter-level accuracy required for precise manipulation tasks. This paper introduces Center-and-Curvature Pose (CCPose), a novel approach that combines machine learning with classical optimization to address these challenges. CCPose operates through a three-stage process: (1) predicting center and curvature heatmaps using a fully convolutional neural network, (2) triangulating three-dimensional (3D) object centers from multi-view images, and (3) refining poses via a render-and-compare optimization. The method achieves state-of-the-art performance on the Texture-Less (T-LESS) dataset, significantly outperforming existing methods on metrics measuring 3D surface deviation. Additionally, the practical applicability of CCPose is demonstrated by the successful integration into a real-world robotic pick-and-place application, handling texture-less metal objects under various lighting conditions. The system generalizes well to unseen objects and provides interpretable outputs, facilitating data-driven improvements. This work represents a significant advancement in 6D pose estimation, offering a robust and precise solution for industrial automation.},
  archive      = {J_MVA},
  author       = {De Roovere, Peter and Daems, Rembert and Croenen, Jonathan and wyffels, Francis},
  doi          = {10.1007/s00138-025-01763-z},
  journal      = {Machine Vision and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--20},
  shortjournal = {Mach. Vis. Appl.},
  title        = {CCPose: High-precision six-dimensional pose estimation for industrial objects},
  volume       = {37},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A mamba-optimized decoder for improved medical image segmentation. <em>MVA</em>, <em>37</em>(1), 1--13. (<a href='https://doi.org/10.1007/s00138-025-01738-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both Transformer-based models and the emerging Mamba-based models exhibit a critical limitation: they predominantly focus on optimizing the encoder while largely overlooking the significance of the decoder. This imbalance in encoder-decoder architectures leads to severe structural asymmetry, which in turn constrains overall model performance. We conducted an in-depth study on the structural composition and functional mechanisms of decoders and proposed SegEO Mamba (i.e., SegMamba Enhanced and Optimized by Mamba) to overcome this issue. This model incorporates a learnable interpolation method that integrates encoder features for more effective upsampling, termed Position Offset with Encoder-Guided Adaptive Method for Upsampling (PE-Upsampling). Furthermore, we introduce Bidirectional Mamba Space and Channel Parallel Attention (BMSC Attention) within skip connections to enhance the fusion of encoder and decoder features. By progressively enriching the decoder, our approach restores balance within the encoder-decoder architecture, effectively alleviating performance constraints caused by structural imbalance. Our proposed SegEO Mamba framework demonstrates state-of-the-art performance across multiple medical imaging benchmarks: achieving a 90.97% Dice score for brain tumor segmentation on BraTS2023, maintaining competitive performance on AIIB2023, and notably attaining top-ranking segmentation performance for multiple abdominal organs on the BTCV benchmark. The model’s exceptional multi-organ segmentation capability robustly validates its strong generalization across diverse clinical scenarios. The code and the best model can be accessed at https://github.com/ZeKey780/SegEO .},
  archive      = {J_MVA},
  author       = {Dong, Zhiqi and Yang, Weibin and Xu, Mingyuan and Wang, Pengwei},
  doi          = {10.1007/s00138-025-01738-0},
  journal      = {Machine Vision and Applications},
  month        = {1},
  number       = {1},
  pages        = {1--13},
  shortjournal = {Mach. Vis. Appl.},
  title        = {A mamba-optimized decoder for improved medical image segmentation},
  volume       = {37},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
