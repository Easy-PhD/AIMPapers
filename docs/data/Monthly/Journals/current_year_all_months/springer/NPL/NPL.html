<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NPL</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="npl">NPL - 91</h2>
<ul>
<li><details>
<summary>
(2025). Accelerating graph substitutions in DNN optimization by heuristic algorithms. <em>NPL</em>, <em>57</em>(6), 1--14. (<a href='https://doi.org/10.1007/s11063-025-11806-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph substitution is a key optimization technique used in deep learning frameworks. Traditional search-based methods are one way to address the problem of graph substitution. However, with the ongoing expansion of deep neural networks (DNNs), the exploration of their vast equivalent graph search space becomes increasingly time-consuming. In this paper, we propose two heuristic methods to accelerate the search process in graph substitution, offering a relatively novel direction compared to existing methods. The first method employs a Memory-Augmented heuristic to optimize computation graphs. To further enhance the efficiency of computation graph optimization, the second method uses the simulated annealing method. This method adds computation graphs with degraded performance into the candidate set with a certain probability. The experimental results show that without significant compromise of inference performance, these two methods can find graph substitutions delivering similar DNN computing performance compared to existing searching methods, while the overall searching time can be reduced from hours to seconds. The source code is available at https://github.com/hudevictor/MAS-SAS .},
  archive      = {J_NPL},
  author       = {Hu, Chun and He, Yuxin and Huang, Yufan and He, Junhui and Yuan, Mengting and Li, Qingan},
  doi          = {10.1007/s11063-025-11806-1},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {6},
  pages        = {1--14},
  shortjournal = {Neural Process. Lett.},
  title        = {Accelerating graph substitutions in DNN optimization by heuristic algorithms},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Detecting bitcoin sentiment: Leveraging language model applications in sentiment analysis for bitcoin price prediction. <em>NPL</em>, <em>57</em>(6), 1--3. (<a href='https://doi.org/10.1007/s11063-025-11808-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NPL},
  author       = {Jung, Hae Sun and Lee, Haein and Kim, Jang Hyun},
  doi          = {10.1007/s11063-025-11808-z},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {6},
  pages        = {1--3},
  shortjournal = {Neural Process. Lett.},
  title        = {Correction: Detecting bitcoin sentiment: Leveraging language model applications in sentiment analysis for bitcoin price prediction},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based pathological image analysis algorithm for early diagnosis of breast cancer. <em>NPL</em>, <em>57</em>(6), 1--22. (<a href='https://doi.org/10.1007/s11063-025-11753-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an innovative deep neural network algorithm designed to improve the automatic recognition accuracy of epithelial and mesenchymal tissues in breast cancer pathological images. The key innovation centers around the development of two novel algorithms: the Tissue Enhancement Vision Fusion technique and the Comprehensive Gray-Scale Threshold Intelligent Judgment method. These algorithms optimize the analysis and diagnosis process of breast cancer pathological images by introducing new approaches to feature enhancement and quantitative assessment that have not been explored in existing literature. The Tissue Enhancement Vision Fusion technique enhances the intuitive observation of key features in images through heatmap generation, while the Comprehensive Gray-Scale Threshold Intelligent Judgment method quantitatively assesses image characteristics, thereby enhancing the precision and efficiency of the model in recognizing epithelial and mesenchymal tissues. By strategically adjusting the EfficientNet model structure in conjunction with these two newly proposed algorithms, the proposed deep learning framework significantly improves the performance of breast cancer pathological image processing. The experimental results demonstrate that the enhanced model achieves recognition accuracies of 0.8548 and 0.8125 for epithelial and mesenchymal tissues, respectively, outperforming existing methods in both accuracy and efficiency. This breakthrough not only validates the effectiveness of the proposed algorithms but also provides robust technical support for early detection and precise diagnosis of breast cancer.},
  archive      = {J_NPL},
  author       = {Huang, Tangsen and Huang, Xingru and Yin, Haibing},
  doi          = {10.1007/s11063-025-11753-x},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {6},
  pages        = {1--22},
  shortjournal = {Neural Process. Lett.},
  title        = {Deep learning-based pathological image analysis algorithm for early diagnosis of breast cancer},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view fusion and view-specific-labels learning for multi-label classification. <em>NPL</em>, <em>57</em>(6), 1--29. (<a href='https://doi.org/10.1007/s11063-025-11785-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-view multi-label learning, each sample is characterized by multiple views and simultaneously labeled with multiple semantic labels. Previous approaches typically combined information from various views to obtain a shared subspace, assuming each view has a shared set of labels. However, these methods ignore the diversity of multiple views, and each view can only capture a fraction of the complete label space. Moreover, the current approaches in this field often rely on either global label structures or local smoothness for learning label correlations, disregarding scenarios where both global and local correlations are crucial. To tackle these issues, we present a new method to improve multi-label classification through Multi-view Fusion and View-specific-labels Learning (MFVL). More concretely, we first get the shared subspace to capture shared information across the various views. Next, we combine it with the original multi-view dataset to construct a new multi-view dataset. To enhance multi-label classification performance, we learn view-specific labels and simultaneously consider global and local label correlations. Finally, our model is extended to nonlinear version to effectively handle linearly inseparable problem. In numerous experiments conducted on nine multi-view multi-label datasets, the proposed method achieves superior performance compared to state-of-the-art algorithms.},
  archive      = {J_NPL},
  author       = {Yang, Zhongliu and Yin, Jun},
  doi          = {10.1007/s11063-025-11785-3},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {6},
  pages        = {1--29},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-view fusion and view-specific-labels learning for multi-label classification},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A euclidean distance-based novel algorithm for binary feature selection. <em>NPL</em>, <em>57</em>(6), 1--54. (<a href='https://doi.org/10.1007/s11063-025-11797-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection, a critical technique for identifying optimal feature subsets, enhances model accuracy while reducing feature dimensionality. Although the recently proposed metaheuristic Horned Lizard Optimization Algorithm (HLOA) exhibits robust stochastic search capabilities for complex optimization problems, it is inherently incompatible with discrete binary tasks such as feature selection. While sigmoid functions conventionally bridge this gap, this paper introduces an innovative Euclidean-distance-based binarization mechanism and its enhanced variant to adapt HLOA's superior search performance to feature selection. Experimental validation across 20 UCI (University of California, Irvine) benchmark datasets demonstrates the efficacy of the proposed methods. Notably, on high-dimensional datasets (dimensionality > 1,000), our algorithms achieve significant reductions in feature size while consistently improving predictive accuracy.},
  archive      = {J_NPL},
  author       = {Wang, Haiyan and Han, Kai and Li, Chuang and Zhao, Jian and Che, Na and Liu, Xiaotong},
  doi          = {10.1007/s11063-025-11797-z},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {6},
  pages        = {1--54},
  shortjournal = {Neural Process. Lett.},
  title        = {A euclidean distance-based novel algorithm for binary feature selection},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State estimation and finite-time synchronization of fractional delayed neural network. <em>NPL</em>, <em>57</em>(6), 1--20. (<a href='https://doi.org/10.1007/s11063-025-11810-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper delves into the state estimation and finite-time (FT) synchronization for fractional neural networks with time delayed. Firstly, a Luenberger observer is proposed to estimate the unknown state. Secondly, the controller with sign or saturation functions is designed to achieve FT synchronization, which the saturation functions is utilized to avoid chattering phenomenon. Correspondingly, several algebraic-form-based synchronization criteria and the setting times are presented by means of the Jensen inequality, fractional-order Razumikhin theorem and fractional-order calculus property. Finally, two examples are listed to illustrate the correctness of the adopted approaches.},
  archive      = {J_NPL},
  author       = {Gui, Chunyan and Cao, Jinde and Zhang, Hai and Abdel-Aty, Mahmoud},
  doi          = {10.1007/s11063-025-11810-5},
  journal      = {Neural Processing Letters},
  month        = {12},
  number       = {6},
  pages        = {1--20},
  shortjournal = {Neural Process. Lett.},
  title        = {State estimation and finite-time synchronization of fractional delayed neural network},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting bitcoin sentiment: Leveraging language model applications in sentiment analysis for bitcoin price prediction. <em>NPL</em>, <em>57</em>(5), 1--25. (<a href='https://doi.org/10.1007/s11063-025-11787-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Bitcoin continues to establish itself as a global asset and discussions around relevant regulations become more active, there is an increasing demand for a comprehensive price prediction framework. To address this necessity, this study aims to enhance the accuracy of Bitcoin price predictions by integrating sentiment information with technical indicators, on-chain data, and cryptocurrency price data. Recognizing Bitcoin’s sensitivity to market sentiment, the proposed framework incorporates sentiment features derived from both lexicon-based methods and large language models. As unsupervised sentiment tools can introduce label noise particularly in domain-specific or ambiguous financial contexts, this study combines the outputs of multiple sentiment models at the feature level to construct a more stable representation. This design improves the robustness of downstream regression performance and distinguishes the framework from previous hybrid models that relied on a single sentiment source without component-wise evaluation. Experimental results using a dataset spanning 2700 days showed that the long short-term memory (LSTM) model with a 3-day window achieves the best performance with mean absolute percentage error (MAPE) of 3.93% and R-squared value of 0.99106. Feature importance analysis further demonstrates sentiment index as the most impactful feature, as excluding it resulted in the largest decline in predictive accuracy. Additionally, the model's performance was evaluated under four major volatility periods, revealing MAPE values ranging from 1.49 to 4.03%, highlighting the framework’s practical capability in rapidly adapting to sudden market shifts. In summary, integrating sentiment information attained from multiple language models significantly enhanced prediction accuracy compared to single source approaches. These findings highlight the framework’s practical value for sentiment-informed investment strategies and risk alerts, with a modular design that enables flexible adaptation and potential integration into automated trading systems.},
  archive      = {J_NPL},
  author       = {Jung, Hae Sun and Lee, Haein and Kim, Jang Hyun},
  doi          = {10.1007/s11063-025-11787-1},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1--25},
  shortjournal = {Neural Process. Lett.},
  title        = {Detecting bitcoin sentiment: Leveraging language model applications in sentiment analysis for bitcoin price prediction},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FDNet: A novel image focus discriminative network for enhancing camera autofocus. <em>NPL</em>, <em>57</em>(5), 1--20. (<a href='https://doi.org/10.1007/s11063-025-11788-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate activation and optimization of autofocus (AF) functions are essential for capturing high-quality images and minimizing camera response time. Traditional contrast detection autofocus (CDAF) methods suffer from a trade-off between accuracy and robustness, while learning-based methods often incur high spatio-temporal computational costs. To address these issues, we propose a lightweight focus discriminative network (FDNet) tailored for AF tasks. Built upon the ShuffleNet V2 backbone, FDNet leverages a genetic algorithm optimization (GAO) strategy to automatically search for efficient network structures, and incorporates coordinate attention (CA) and multi-scale feature fusion (MFF) modules to enhance spatial, directional, and contextual feature extraction. A dedicated focus stack dataset is constructed with high-quality annotations to support training and evaluation. Experimental results show that FDNet outperforms mainstream methods by up to 4% in classification accuracy while requiring only 0.2 GFLOPs, 0.5 M parameters, a model size of 2.1 MB, and an inference time of 0.06 s, achieving a superior balance between performance and efficiency. Ablation studies further confirm the effectiveness of the GAO, CA, and MFF components in improving the accuracy and robustness of focus feature classification.},
  archive      = {J_NPL},
  author       = {Kou, Chenhao and Xiao, Zhaolin and Jin, Haiyan and Guo, Qifeng and Su, Haonan},
  doi          = {10.1007/s11063-025-11788-0},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1--20},
  shortjournal = {Neural Process. Lett.},
  title        = {FDNet: A novel image focus discriminative network for enhancing camera autofocus},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-band video deblurring via efficient chunked additive attention and dynamic channel adaptive module. <em>NPL</em>, <em>57</em>(5), 1--14. (<a href='https://doi.org/10.1007/s11063-025-11798-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep learning-based deblurring methods perform well in the visible spectrum but suffer from high computational costs due to complex network designs. For infrared images, texture deficiency and edge degradation hinder effective feature learning. To overcome these problems, a Dynamic Channel Adaptive Network (EDCANet) is proposed, which is based on the Dynamic Channel Adaptive Module (DCAM) and Efficient Chunked Additive Attention (ECAA) integrated into a multi—scale network with an encoder—decoder architecture. The DCAM adaptively recalibrates input frame contributions through dynamic channel weighting. Additionally, the ECAA mechanism that decomposes attention operations into partitioned spatial and frequency domains is adopted to enhance contour recovery performance. Images across multiple spectral bands are used in experiments to verify the generalization ability of the proposed method and the effectiveness of structural contour and fine-grained detail recovery. Experimental results show that the EDCANet can process images in real time at a speed of 100 frames per second, with the Peak Signal-to-Noise Ratio (PSNR) exceeding 31 dB and the Structural Similarity Index (SSIM) surpassing 0.92 on infrared datasets. For visible light datasets, its PSNR reaches above 32 dB and SSIM exceeds 0.93.},
  archive      = {J_NPL},
  author       = {Ao, Yongqi and Zhu, Deyan and Li, Chengcheng and Zhang, Yufan and Xu, Jiayi},
  doi          = {10.1007/s11063-025-11798-y},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1--14},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-band video deblurring via efficient chunked additive attention and dynamic channel adaptive module},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STP-Cube—Multivariate time series forecasting based on spatiotemporal correlations and periodicity. <em>NPL</em>, <em>57</em>(5), 1--19. (<a href='https://doi.org/10.1007/s11063-025-11799-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of multivariate time series (MTS) forecasting aims to utilize historical time series data to predict future trends and variations. MTS data possesses numerous latent features, with spatiotemporal correlations and periodicity being particularly significant. Most existing methods focused on either spatiotemporal correlations or periodicity, limiting their effectiveness. The paper proposes a novel STP-cube model by simultaneously capturing both, offering a more robust solution for MTS forecasting. MTS data is first transformed into a three-dimensional structure—the cube, through special stacking. Then graph convolution is utilized to capture spatiotemporal dependencies among sensors and Conv2Ds in another dimension to extract periodic features within sensors. By incorporating both features, the forecasting effectiveness is significantly enhanced. STP-cube model shows robust performance across six public MTS datasets, particularly excelling on the ETTh1 dataset where it reduces MSE by 0.177 and MAE by 0.084 comparing to the SOTA model.},
  archive      = {J_NPL},
  author       = {Zhang, Yidong and Jing, Jie and Liu, Luqi and Lan, Chengming and Shi, Peng},
  doi          = {10.1007/s11063-025-11799-x},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1--19},
  shortjournal = {Neural Process. Lett.},
  title        = {STP-Cube—Multivariate time series forecasting based on spatiotemporal correlations and periodicity},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability and exponential lag-synchronization of a class of neural network with state dependent and distributed delays over a time scale. <em>NPL</em>, <em>57</em>(5), 1--24. (<a href='https://doi.org/10.1007/s11063-025-11802-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article tackles the stability and synchronization challenges of neural networks with distributed and state-dependent delays on a temporal domain, leveraging the powerful framework of time scales theory. By formulating the problem within this unified framework, we enable applications to both uniform and non-uniform time domains. Our investigation begins with a thorough analysis of the local exponential stability of the zero solution, employing a combination of pure analysis method, reduction to absurdity technique, and time scale theory. We derive a set of sufficient conditions that guarantee local exponential stability of neural networks with distributed and state-dependent delays. Furthermore, we examine exponential lag synchronization results, utilizing a range of analytical tools, including time scale theory, matrix norm theory, unified matrix-measure theory, and the Halanay inequality. To demonstrate the efficacy and broad applicability of our findings, we present a simulated example on random time scales. Specifically, the time scales theory allows us to effectively handle time scales by providing a unified framework that can seamlessly integrate both continuous and discrete time domains, thereby enabling the analysis of complex systems with varying time scales. Moreover, our approach leverages the flexibility of time scales theory to accommodate non-uniform time domains, making it an ideal tool for tackling real-world problems with intricate temporal dynamics.},
  archive      = {J_NPL},
  author       = {Abbas, Muhammad and Zada, Akbar and Popa, Ioan-Lucian and Kallekh, Afef},
  doi          = {10.1007/s11063-025-11802-5},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1--24},
  shortjournal = {Neural Process. Lett.},
  title        = {Stability and exponential lag-synchronization of a class of neural network with state dependent and distributed delays over a time scale},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From task-aware to task-agnostic parameter isolation for incremental learning. <em>NPL</em>, <em>57</em>(5), 1--28. (<a href='https://doi.org/10.1007/s11063-025-11792-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mitigating catastrophic forgetting in continual learning is a long-standing challenge for artificial intelligence. Often, methods used to alleviate forgetting make use of either rehearsal buffers, pretrained backbones or task-id knowledge. However, these requirements result in severe limitations regarding scalability, privacy preservation, and efficient deployment. In this work, we explore how to eliminate the need for such requirements in incremental learning approaches based on parameter isolation. We propose Low Interference Feature Extraction Subnetworks (LIFES), a method that learns a subnetwork per task and uses all of them concurrently at inference time. This solution minimises requirements; however, it creates the need to address certain challenges. To formalize them, we break down the catastrophic forgetting problem into 4 distinct causes, and address them with a novel lateral classifiers regularization, weight standardization, and subnetwork interference connection pruning. Specifically, the use of lateral classification shows very promising results, forcing the model to learn distributions with higher inter-class distance. Using these components, LIFES achieves competitive results in standard task-agnostic scenarios, demonstrating the viability of this new perspective for parameter isolation, which has minimal requirements. Finally, we discuss how future work can improve this new paradigm further, and how the strategies defined can be complementary to other approaches.},
  archive      = {J_NPL},
  author       = {Vicente-Sola, Alex and Kirkland, Paul and Di Caterina, Gaetano and Bihl, Trevor J and Masana, Marc},
  doi          = {10.1007/s11063-025-11792-4},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1--28},
  shortjournal = {Neural Process. Lett.},
  title        = {From task-aware to task-agnostic parameter isolation for incremental learning},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FEFM-YOLO11: Underwater object detection algorithm based on improved YOLO11. <em>NPL</em>, <em>57</em>(5), 1--19. (<a href='https://doi.org/10.1007/s11063-025-11805-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater object detection technology is extensively applied in subsea resource exploration and benthic environmental monitoring; however, the underwater environment presents significant challenges due to limited visibility caused by insufficient illumination and turbid water quality, severely impeding detection tasks. To address these challenges and enhance precision, this paper proposes FEFM-YOLO11—an enhanced YOLO11-based underwater object detection algorithm. Primarily, the algorithm substitutes two C3K2 modules in the backbone with a Feature Enhancement Module (FEM). Employing a multi-branch dilated convolutional structure, the FEM increases feature diversity, expands the network’s local receptive field, and enhances semantic representation of small objects, thereby strengthening detection capabilities. Subsequently, a Context-Aware Fusion Module (CAFM) is introduced in the Neck, which effectively models global and local features through integrated local feature capture (convolutional operations) and global feature extraction (attention mechanisms), consequently improving denoising performance. Furthermore, a dedicated small-target detection layer is incorporated to specifically boost detection performance for smaller underwater objects. Finally, the Wise IoU loss function was used for comprehensive evaluation and performance optimization, and the collaborative integration of these components effectively reduced the problem of missed detections caused by occlusion in dense cluster targets. Experimental results on the URPC2020 dataset demonstrate that the improved algorithm achieves enhancements of 2.0% points in mAP@50 and 1.9% points in mAP@50:95 compared to the baseline, confirming that FEFM-YOLO11 elevates detection precision and validates the feasibility and effectiveness of the proposed methodology.},
  archive      = {J_NPL},
  author       = {Wang, Qi and Liu, Zhichuan},
  doi          = {10.1007/s11063-025-11805-2},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1--19},
  shortjournal = {Neural Process. Lett.},
  title        = {FEFM-YOLO11: Underwater object detection algorithm based on improved YOLO11},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ghost-connect net: A generalization-enhanced guidance for sparse deep networks under distribution shifts. <em>NPL</em>, <em>57</em>(5), 1--40. (<a href='https://doi.org/10.1007/s11063-025-11758-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse deep neural networks (DNNs) excel in real-world applications like robotics and computer vision, by reducing computational demands that hinder usability. However, recent studies aim to boost DNN efficiency by trimming redundant neurons or filters based on task relevance, but neglect their adaptability to distribution shifts. We aim to enhance these existing techniques by introducing a companion network, Ghost Connect-Net (GC-Net), to monitor the connections in the original network with distribution generalization advantage. GC-Net’s weights represent connectivity measurements between consecutive layers of the original network. After pruning GC-Net, the pruned locations are mapped back to the original network as pruned connections, allowing for the combination of magnitude and connectivity-based pruning methods. Experimental results using common DNN benchmarks, such as CIFAR-10, Fashion MNIST, and Tiny ImageNet show promising results for hybridizing the method, and using GC-Net guidance for later layers of a network and direct pruning on earlier layers. We provide theoretical foundations for GC-Net’s approach to improving generalization under distribution shifts.},
  archive      = {J_NPL},
  author       = {Wisell, Mary and Sekeh, Salimeh},
  doi          = {10.1007/s11063-025-11758-6},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1--40},
  shortjournal = {Neural Process. Lett.},
  title        = {Ghost-connect net: A generalization-enhanced guidance for sparse deep networks under distribution shifts},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global dissipative examination of delayed memristive inertial neural networks with uncertain parameters. <em>NPL</em>, <em>57</em>(5), 1--27. (<a href='https://doi.org/10.1007/s11063-025-11784-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present article addresses the dissipative examination of Dynamic Systems, namely Inertial Neural Networks with memristor, parameter uncertainty and delays such as time-varying, distributed. A suitable variable substitution is implemented to convert the inertial system to the first order differential system. Exploiting the concept of matrix measure and properties to the Lyapunov function, a sufficient criteria for dissipative of the dynamical system is achieved through a generalized Halanay Inequality. Concurrently, the globally attractive sets are extracted from the network system with bound. The derived results are new-fangled concerning the dynamical systems with complex- the inertial and memristor term along with the mixed delays and parameter uncertainties. Finally, the numerical simulations are presented for better clarification and testimonial of obtained dissipative criteria with pictorial representation.},
  archive      = {J_NPL},
  author       = {Premalatha, S. and Shanmugapriya, M. M. and Indumathi, P. and Kumar, S. Santhosh},
  doi          = {10.1007/s11063-025-11784-4},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1--27},
  shortjournal = {Neural Process. Lett.},
  title        = {Global dissipative examination of delayed memristive inertial neural networks with uncertain parameters},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual decoder mathematical word problem solving model based on lie group intrinsic mean feature matrix. <em>NPL</em>, <em>57</em>(5), 1--24. (<a href='https://doi.org/10.1007/s11063-025-11804-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Math Word Problems (MWP) solving involves language comprehension and mathematical reasoning. Most of the existing models are primarily based on deep learning methods. However, deep learning models often exhibit large model scales (e.g., large number of parameters), high feature dimensions, and an imbalance between accuracy and computational efficiency. To address these issues, We propose a novel dual-decoder model for solving Mathematical Word Problems (MWP), which is constructed using a Lie Group intrinsic mean feature matrix and named the Dual-Decoder Neural Symbolic Machine (DDNSM). This model projects data samples onto a Lie Group manifold to effectively reduce the output feature dimensions of the encoder through a feature matrix built around the Lie Group intrinsic mean, thereby reducing the computational load in the decoding stage and improving model inference efficiency. Additionally, we designed a dual-decoder system, comprising a decoder based on global and local attention mechanisms and another structured around a tree built from the Lie Group intrinsic mean. Extensive experiments on multiple challenging public datasets demonstrate that our model achieves competitive results in MWP tasks, achieving competitive results in MWP tasks with improved accuracy and computational efficiency.},
  archive      = {J_NPL},
  author       = {Jian, Pengpeng and Sun, Tianhao and Ma, Bin and Xi, Hui and Yang, Yangrui},
  doi          = {10.1007/s11063-025-11804-3},
  journal      = {Neural Processing Letters},
  month        = {10},
  number       = {5},
  pages        = {1--24},
  shortjournal = {Neural Process. Lett.},
  title        = {Dual decoder mathematical word problem solving model based on lie group intrinsic mean feature matrix},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing deep learning with resilient adversarial network (RANet): An advanced adversarial resilience training framework for robust image classification. <em>NPL</em>, <em>57</em>(4), 1--34. (<a href='https://doi.org/10.1007/s11063-025-11777-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has revolutionized image classification and other AI-driven tasks. Yet, its vulnerability to adversarial attacks remains a critical limitation, particularly in safety–critical domains such as autonomous systems and healthcare. This study proposes the Resilient adversarial network (RANet), a novel defence framework designed to enhance the robustness of deep learning models against adversarial perturbations. RANet integrates adversarial resilience training (ART) through key components: a dedicated adversarial training layer, adaptive perturbation control, feature-space augmentation, and adversarial dropout. These modules collectively improve generalization and reduce susceptibility to both targeted and non-targeted attacks. Evaluated on datasets from the NIPS 2017 adversarial learning challenge, RANet achieves 92.5% accuracy on clean data and 75.3% on adversarial data, outperforming existing defence methods in both accuracy and robustness. The framework demonstrates a strong balance between performance and security, making it viable for real-world deployment.},
  archive      = {J_NPL},
  author       = {Alyahyan, Saleh},
  doi          = {10.1007/s11063-025-11777-3},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1--34},
  shortjournal = {Neural Process. Lett.},
  title        = {Enhancing deep learning with resilient adversarial network (RANet): An advanced adversarial resilience training framework for robust image classification},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EA-DETR: Edge-aware detection transformer for water surface floating object identification. <em>NPL</em>, <em>57</em>(4), 1--25. (<a href='https://doi.org/10.1007/s11063-025-11769-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designed to address the challenge of identifying water surface floating objects with transparent features under complex backgrounds such as irritating light sources, we introduce Edge-Aware Detection Transformer(EA-DETR), a novel end-to-end object detection model based on DINO-ResNet50. Three innovative strategies are mainly incorporated. First, Edge-Aware Denoising(EAD) Module, composed of convolutions and Squeeze-and-Excitation(SE) Module, accentuates boundary information across multi-scale features after Backbone of ResNet50. Secondly, Mamba-like Linear Attention(MLLA) Module continuously suppresses incorrect positional weights while emphasizing correct ones through linear operations in Transformer Encoder layers. Finally, a dynamic matching approach combines flexible coefficients for CIoU, a regularization item based on bounding box sizes and a frame utilizing Sober operator to convert coordinated into edges, thus capturing more detailed information of transparent objects by calculating extra segmentation mask loss fostered by boundaries. EA-DETR achieves 72.4% AP(0.5:0.95), 98.7% AP(0.5) and 65.7% AR(0.5:0.95) on the FloW-ImG Dataset, significantly outperforming other DETR-like models. Furthermore, it demonstrates ideal generalization and robustness, with results on the Trash_ICRA19 Dataset exhibiting 44.1% AP(0.5:0.95), 74.2% AP(0.5), and 64.5% AR(0.5:0.95). Overall, the architecture proposed can provide effective tools for learning ambiguous boundary features without disturbance of extreme lightness caused by water surface and the sun.},
  archive      = {J_NPL},
  author       = {Wang, Jiayi and Liu, Xiangyang},
  doi          = {10.1007/s11063-025-11769-3},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1--25},
  shortjournal = {Neural Process. Lett.},
  title        = {EA-DETR: Edge-aware detection transformer for water surface floating object identification},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-dimensional topological association strengthening clustering network. <em>NPL</em>, <em>57</em>(4), 1--22. (<a href='https://doi.org/10.1007/s11063-025-11781-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep graph clustering, as a fundamental task in data mining, has attracted widespread attention. Recently, excellent performance has been achieved by integrating graph structure and node attributes to generate consensus latent embeddings. However, existing clustering methods are limited by redundant information and unreliable clustering distribution, which hinders the discriminative power of the latent embeddings. To address this issue, we propose a novel deep graph clustering framework called Multi-dimensional Topological Association Strengthening Clustering Network (MTASCN). Specifically, we design a Multi-dimensional Feature Association Mechanism (MFAM), which extracts the competitive or cooperative relationship between features to alleviate the interference of redundant features and enhance the dominant features. In addition, we develop a Structure-oriented Multi-order Loss Module (SMLM) that reinforces the generation of clustering distribution under reliable structure information guidance by calculating the multi-order similarity between the latent embeddings and the original graph structure. Extensive experiments on five benchmark datasets have demonstrated that MTASCN consistently outperforms other clustering methods.},
  archive      = {J_NPL},
  author       = {Sun, Mengzhe and Han, Renda and Zeng, Moxuan and Li, Mengfei and Hu, Tianyu and Yang, Zhenhua and Wang, Ziyan and Liu, Jingxin and Xin, Wen and Feng, Jingmei},
  doi          = {10.1007/s11063-025-11781-7},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1--22},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-dimensional topological association strengthening clustering network},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cervical cancer classification using deep learning approach using colposcopy images. <em>NPL</em>, <em>57</em>(4), 1--27. (<a href='https://doi.org/10.1007/s11063-025-11770-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conventional approach of cervical cancer classification mostly depends on pathologists' expertise, which is typically less precise. Over the last 75 years, the incidence and death rates of cervical cance6r have decreased dramatically thanks in large part to the widespread use of colposcopy, an essential component of cervical cancer prevention. On the other hand, misdiagnoses and a decline in diagnostic efficacy have resulted from the increasing workload in visual screening. In deep learning, cervical cancer type classification has shown improved performance using medical image processing and Convolutional Neural Network (ConvNet) models, namely the ResNet50 model and Cervix Ensemble Network (CervixNET). In order to automatically identify cervical cancer from colposcopy images, this research presents two ConvNet architectures. In one architecture, ResNet50 functions as a transfer learning (TL) model, and for classification, a new model called CervixNET is created. Both models' sensitivity, specificity, and accuracy are evaluated. With an accuracy of 82.67%, ResNet50 produces findings that are quite excellent. For ResNet50, the kappa value suggests a moderate categorization. CervixNET, however, performs very well; its sensitivity, specificity, and kappa score are 99.58%, 99.63%, and 99.12%, respectively, in the experimental data. Notably, the CervixNET model's classification accuracy of 99.23% marks a notable increase over the ResNet50 (TL) model by 16.56%.},
  archive      = {J_NPL},
  author       = {Dayalane, Sundaranarayana and Murugesan, Sankar and Mathivanan, Sandeep Kumar and Rajadurai, Hariharan and Panneer Selvam, Karthikeyan and Shah, Mohd Asif},
  doi          = {10.1007/s11063-025-11770-w},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1--27},
  shortjournal = {Neural Process. Lett.},
  title        = {Cervical cancer classification using deep learning approach using colposcopy images},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph generation model for convolutional neural network architecture based on GCN and GAN. <em>NPL</em>, <em>57</em>(4), 1--11. (<a href='https://doi.org/10.1007/s11063-025-11773-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Neural Architecture Search (NAS) has garnered widespread attention in the field of deep learning due to its significant potential in automating the construction of deep models. However, existing NAS methods primarily focus on optimizing network architecture, utilizing search strategies to find a high-performing network architecture within the search space as effectively as possible. And this process often requires repetitive and continuous searching and evaluation. With the significant advancements in Artificial Intelligence Generated Content (AIGC), an increasing number of researchers are utilizing deep generative models to create graph data. Neural network architecture can be viewed as Directed Acyclic Graphs(DAG) with labeled nodes. Therefore, we propose a graph generation model based on Graph Convolutional Network (GCN) and Generative Adversarial Network(GAN) to generate network architecture. With the aim of avoiding the repetitive and continuous searching and evaluation process in NAS. The CNN architecture generated by our algorithm in this paper achieves an accuracy of 94.37% on the CIFAR-10 dataset. While it may not outperform many other CNN models in terms of performance, it doesn’t require any expert knowledge and is generated automatically by the model, avoiding the need for repetitive searching and evaluation.},
  archive      = {J_NPL},
  author       = {Song, Changwei and Ma, Yongjie},
  doi          = {10.1007/s11063-025-11773-7},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1--11},
  shortjournal = {Neural Process. Lett.},
  title        = {A graph generation model for convolutional neural network architecture based on GCN and GAN},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A transformer-based hierarchical hybrid encoder network for semantic segmentation. <em>NPL</em>, <em>57</em>(4), 1--24. (<a href='https://doi.org/10.1007/s11063-025-11774-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of semantic segmentation, the limited receptive field of convolutional neural networks leads to insufficient extraction of global features, thereby affecting the accuracy of network segmentation. To address this issue, a Hierarchical Hybrid Encoder Network (HHEnet) based on Transformers is proposed for semantic segmentation. Firstly, to solve the problem of limited global feature information caused by the network’s limited receptive field, a Hierarchical Hybrid Encoder (HHE) is introduced, which consists of a Hierarchical Convolutional Encoder (HCE) and a Hierarchical Transformer Encoder (HTE). The encoder combines the advantages of convolution and transformers, allowing for effective extraction of both shallow and deep features. In order to further enhance spatial and global semantic information, the Feature Enhancement Module (FEM) was introduced, which consisted of two feature enhancement modules: spatial feature enhancement module (SEM) and global feature enhancement module (GEM), which enhanced spatial detail information and global semantic information respectively. Thus the accuracy of semantic segmentation can be improved. Finally, to alleviate the discrepancy between the features of the convolutional encoder and the transformer encoder, a Feature Guidance Module (FGM) is introduced. Experimental results conducted on Cityscapes, ADE20K and PASCAL VOC2012 datasets achieved mIoU scores of up to 81.9%, 49.4% and 79.1%, respectively. Compared to state-of-the-art networks, the research results confirm the higher segmentation accuracy of the proposed HHEnet in this study.},
  archive      = {J_NPL},
  author       = {Zhao, Shan and Wu, Xuan and Tian, Kaiwen and Yuan, Yang},
  doi          = {10.1007/s11063-025-11774-6},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1--24},
  shortjournal = {Neural Process. Lett.},
  title        = {A transformer-based hierarchical hybrid encoder network for semantic segmentation},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized adaptive huber loss driven robust twin support vector machine learning framework for pattern classification. <em>NPL</em>, <em>57</em>(4), 1--39. (<a href='https://doi.org/10.1007/s11063-025-11783-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problem that the traditional Twin Support Vector Machine (TSVM) is sensitive to noise and outliers, this paper proposes a twin support vector machine model based on generalized adaptive Huber loss function (GAHTSVM). Via dynamically adjusting the robust parameters $$s$$ , the model can effectively suppress the adverse effects of noisy data points on the decision function, and improve the sparsity of the model by introducing insensitive region design. For non-convex optimization problems, concave-convex process (CCCP) is adopted to avoid quadratic programming problems and significantly improve the efficiency of the algorithm. Experiments show that GAHTSVM performs well in the scenarios where Gaussian noise is added to real-world datasets and outliers are introduced to artificial datasets: it is significantly better than other algorithms in low noise environment; In the high noise environment, it still maintains a leading position, and most datasets are ranked in the top; It performs well on two artificial datasets and is significantly superior to other algorithms.In conclusion, the model effectively overcomes the noise and outlier interference by dynamically adjusting the outlier penalty, and provides an efficient solution to the pattern recognition problem in high noise environment.},
  archive      = {J_NPL},
  author       = {Jiang, Tiantian and Wei, Bo and Yu, Guolin and Ma, Jun},
  doi          = {10.1007/s11063-025-11783-5},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1--39},
  shortjournal = {Neural Process. Lett.},
  title        = {Generalized adaptive huber loss driven robust twin support vector machine learning framework for pattern classification},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive enhanced knowledge distillation for learning MLPs on GNNs. <em>NPL</em>, <em>57</em>(4), 1--16. (<a href='https://doi.org/10.1007/s11063-025-11778-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, graph neural networks (GNNs) have emerged as a promising approach for classifying non-Euclidean structural data. However, the practical implementation of GNNs faces challenges related to their limited scalability due to the presence of multi-hop data dependencies. In order to tackle this issue, existing methods have employed teacher GNNs to generate labels, which are then used to train multilayer perceptrons (MLPs) based solely on node features, without considering any structural information. However, these methods primarily focus on the soft labels generated by the teacher GNNs, leading to suboptimal performance because they disregard significant features of the teacher GNNs. Additionally, since the structural information of the graph is omitted in the input of MLPs, it can be more susceptible to the influence of erroneous features. To address these limitations, this paper proposes a novel framework that incorporates a new distillation strategy to integrate soft feature similarity into MLPs, while also utilizing contrastive learning to enhance the training of student MLPs. Our model has accuracy, averaged over seven public datasets, 5.21% higher than state-of-the-art (SOTA) methods, and even 2.49% higher than teacher GNNs over five standard scaled datasets. At the same time, its inference time is only 1.17% of comparable GNNs.},
  archive      = {J_NPL},
  author       = {Hu, Wei and Pu, Juhua and Tang, Xiaolan and Liu, Xingwu},
  doi          = {10.1007/s11063-025-11778-2},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1--16},
  shortjournal = {Neural Process. Lett.},
  title        = {Contrastive enhanced knowledge distillation for learning MLPs on GNNs},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSFKAN: A multi-scale feature prediction network combined with KAN for medical image classification. <em>NPL</em>, <em>57</em>(4), 1--28. (<a href='https://doi.org/10.1007/s11063-025-11782-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The characteristics of the lesion areas in medical images are complex, and existing fully connected layer-based neural networks still cannot address the issue of linear kernels, making them inadequate for handling the nonlinear classification problem of medical image data. This paper investigates a multi-scale feature joint prediction Kolmogorov-Arnold Network convolutional network combined with a spatial attention mechanism for medical image classification applications. In this article, we propose the Multi-Scale Feature prediction network combined with Kolmogorov-Arnold Network. In this model, convolutional blocks are concatenated to output feature maps of different scales. These feature maps are then passed through a spatial attention module, and the output is weighted and summed using learnable weights in the Kolmogorov-Arnold Network layer for classification. The model is trained, tuned, and tested on three publicly available medical image datasets, including the skin cancer image dataset, COVID-19 lung CT dataset, and brain tumor MRI dataset. Experimental results show that the proposed model demonstrates strong performance in classification tasks across four datasets, achieving an accuracy of 87.27% for binary skin cancer classification, 94.12% for the three-class COVID-19 CT classification, and 97.48% for the four-class brain tumor CT classification. This performance outperforms the classification accuracy of the selected comparison methods. Additionally, we applied a perturbation rate of 0.5% and 1.0% using the FGSM method on the test sets of the three datasets and re-tested, finding that our method achieved higher accuracy than the comparison methods. Comprehensive experimental results validate the effectiveness of our proposed method, demonstrating its applicability and robustness in different medical scenarios. This approach is expected to enhance the performance of medical image-assisted classification.},
  archive      = {J_NPL},
  author       = {Gao, Jianyun and Liao, Yuan and Zhang, Zerui and Li, Shu and Wang, Hao},
  doi          = {10.1007/s11063-025-11782-6},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1--28},
  shortjournal = {Neural Process. Lett.},
  title        = {MSFKAN: A multi-scale feature prediction network combined with KAN for medical image classification},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FLSVR: Solving lagrangian support vector regression using functional iterative method. <em>NPL</em>, <em>57</em>(4), 1--25. (<a href='https://doi.org/10.1007/s11063-025-11780-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Lagrangian dual of the 2-norm support vector regression (LSVR) solves a quadratic programming problem (QPP) in 2m variables subject to the non-negative variable conditions where m is the size of the training set. Applying the Karush–Kuhn–Tucker (KKT) necessary and sufficient optimality conditions, this work's novel problem formulation is only derived as a fixed point problem in m variables. This problem is solvable either in its original form, having the non-smooth "plus" function, or by considering its equivalent absolute value equation problem using functional iterative methods. A linear convergence rate of the proposed iterative methods is rigorously established under appropriate assumptions. It leads to the unique optimum solution. Numerical experiments performed on several synthetic and real-world benchmark datasets demonstrate that the proposed formulation solved by iterative methods shows similar or better generalization capability with a learning speed much faster than support vector regression (SVR), very close to least squares SVR (LS-SVR), and comparable with ULSVR which indicates its effectiveness and superiority.},
  archive      = {J_NPL},
  author       = {Meena, Yogendra and Anagha, P. and Balasundaram, S.},
  doi          = {10.1007/s11063-025-11780-8},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1--25},
  shortjournal = {Neural Process. Lett.},
  title        = {FLSVR: Solving lagrangian support vector regression using functional iterative method},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Observer-based event-triggered control for quasi-containment in fractional-order multi-agent systems under DoS attacks. <em>NPL</em>, <em>57</em>(4), 1--34. (<a href='https://doi.org/10.1007/s11063-025-11789-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study concentrates on understanding quasi-containment control in fractional-order multi-agent systems (FOMASs) that occur during DoS attacks. Centered on the information available when events occur we develop a new event-based control method to strengthen system resistance against distributed communication failures. The study examines DoS attack effects on network communications while setting consensus requirements through fusion of algebraic graph theory, matrix theory and fractional calculus techniques. Linear matrix inequalities express constraints for achieving consensus that help demonstrate the necessary conditions for reaching this state. We establish a rigorous lower limit for inter-event periods with positive values which prevents Zeno behavior from developing. Our approach has been verified through numerical simulations which confirm both its operation success and resilience against DoS attacks.},
  archive      = {J_NPL},
  author       = {Alsinai, Ammar and Abdul Khaliq, Wajiha and Ullah Khan Niazi, Azmat and Saidani, Taoufik},
  doi          = {10.1007/s11063-025-11789-z},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1--34},
  shortjournal = {Neural Process. Lett.},
  title        = {Observer-based event-triggered control for quasi-containment in fractional-order multi-agent systems under DoS attacks},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSTCA: Multi-horizon spatiotemporal correlation aggregation for multivariate long-term time series forecasting. <em>NPL</em>, <em>57</em>(4), 1--23. (<a href='https://doi.org/10.1007/s11063-025-11791-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate Long Series Time-series Forecasting (MLSTF) plays an important role in enterprise production and operation. Previous MLSTF algorithms extract sequence features by adding correlation computation methods in time and variables, but still have the following problems: 1) Lack of multivariate correlation modeling in complex time patterns. 2) Lack of effective multi-scale feature alignment fusion of the data. In order to solve the above problems, this manuscript proposes the MSTCA network, which is a multi-horizon spatio-temporal correlation aggregation method. First, a Multi Scale Grid (MSG) batch sliding feature extraction strategy is proposed to converge multivariate information in different temporal modes by different size windows. Meanwhile, a gridding method is used to separate the features of different variables, which avoids the problem of losing the original information caused by unified multivariate aggregation. Second, in order to effectively extract the fragmented features of MSG, the channel Multiscale Graph Convolutional Network (MGCN) and Multiscale Hierarchical Attention (MHA) structure are designed to perform affinity discovery in multiscale spatial and temporal dimensions, respectively. Finally, in order to effectively fuse the multilevel features of MGCN and MHA, a feature-aligned Time Series Bidirectional Feature Pyramid Networks (TS-BiFPN) approach is proposed for robust characterization of multiscale advanced information patterns. Compared with the model based on graph convolution with self-attention structure, the accuracy of our proposed MSTCA model is significantly improved in long series time series prediction. Extensive experiments were conducted across multiple datasets under different configurations. The results demonstrate that the MSTCA model outperforms baseline methods, achieving the highest average ranking scores of 1.61 (MSE) and 1.82 (MAE) for MSE and MAE metrics, respectively.},
  archive      = {J_NPL},
  author       = {Shi, Dunhuang and Zhang, Tao and Duan, Yuntao and Sun, Lei},
  doi          = {10.1007/s11063-025-11791-5},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1--23},
  shortjournal = {Neural Process. Lett.},
  title        = {MSTCA: Multi-horizon spatiotemporal correlation aggregation for multivariate long-term time series forecasting},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of implicit relationships using uncertain knowledge graph embedding and bayesian networks. <em>NPL</em>, <em>57</em>(4), 1--22. (<a href='https://doi.org/10.1007/s11063-025-11794-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation prediction in knowledge graphs is a classic task. However, predicting unseen facts under the open-world assumption remains challenging, as conventional closure reasoning methods tend to fail. To address this, we propose an uncertain knowledge graph embedding and Bayesian inferring model, UKGEBN, which examines the capabilities of approximate inference under the open-world assumption. This model employs a large language model to encode entities and relations by treating facts as natural language sentences. It then learns knowledge confidence through a recurrent neural network and subsequently constructs Bayesian networks for the uncertain knowledge graph based on the learned confidence. The constructed Bayesian network can reasonably infer unseen knowledge facts, even if the elements of these facts-such as new entities and relationships-have never been encountered in the knowledge base before. The experimental results show that the new model has improved the MSE metric by 24.6% in relation prediction on the benchmark dataset. Case studies indicate that the model significantly enhances the revelation of latent semantic information, facilitating the prediction of implicit relationships in uncertain knowledge graphs.},
  archive      = {J_NPL},
  author       = {Yang, Shihan and Lin, Liannan and Liu, Chunjiang and Zhang, Mingkai and Yang, Haiyi},
  doi          = {10.1007/s11063-025-11794-2},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1--22},
  shortjournal = {Neural Process. Lett.},
  title        = {Prediction of implicit relationships using uncertain knowledge graph embedding and bayesian networks},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global mittag-leffler projective synchronization of distinct fractional-order delayed neural networks with inconsistent orders and interaction terms via integral sliding mode control. <em>NPL</em>, <em>57</em>(4), 1--19. (<a href='https://doi.org/10.1007/s11063-025-11793-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on the global Mittag–Leffler projective synchronization (GMLPS) of distinct fractional-order delayed neural networks (FODNNs) with inconsistent orders and interaction terms. Initially, a delayed fractional-order (FO) integral sliding surface is made by embedding the FO gradient fed into the controller, facilitating the formulation of a synchronous error system. Subsequently, a delayed sliding mode controller (SMC) is formulated using the sliding mode control theory to guarantee the occurrence of the sliding motion. Furthermore, error systems are shown to converge to the predefined sliding surface, enabling sliding motion through the fractional Lyapunov direct approach and the Razumikhin method. Novel criteria are established to achieve the GMLPS for distinct FODNNs with inconsistent orders and interaction terms. Finally, numerical experiments are exploited to highlight the performance of the obtained outcomes.},
  archive      = {J_NPL},
  author       = {Pavithra, G. and Dharani, S.},
  doi          = {10.1007/s11063-025-11793-3},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1--19},
  shortjournal = {Neural Process. Lett.},
  title        = {Global mittag-leffler projective synchronization of distinct fractional-order delayed neural networks with inconsistent orders and interaction terms via integral sliding mode control},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GPCNKB: An attack prediction and reasoning model based on an improved graph convolutional network. <em>NPL</em>, <em>57</em>(4), 1--32. (<a href='https://doi.org/10.1007/s11063-025-11795-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of artificial intelligence technology, network attack scenarios are becoming increasingly intricate. On the one hand, the amount of attack knowledge is increasing; on the other hand, the potential relationships between these pieces of knowledge are becoming more difficult to discover and identify. Existing methods struggle to characterize these complex attack scenarios effectively and accurately predicting attack patterns. To address these issues, this paper introduces a novel network attack prediction and reasoning method, GPCNKB, which adopts the design idea of“classification-first, reasoning-later”. First, knowledge graphs and embedding techniques are used to represent attack scenarios, then graph convolutional networks (GCNs) are applied to classify the scenarios, and finally, the knowledge graph embedding model is utilized to reason the attack knowledge within scenarios of the same category. This design reduces the scope of reasoning and enhances its accuracy, enabling more effective network attack predictions. Additionally, the method incorporates concepts from evolutionary computation to refine the GCN classification model. This refinement optimizes the training parameters of the graph convolution network and improve the universality of the model. Experimental results reveal that GPCNKB exhibits notable advantages in reasoning speed and effectively uncovers potential relationships among attack knowledge within the same attack category. This work provides a novel approach for reasoning and predicting complex multi-step network attacks.},
  archive      = {J_NPL},
  author       = {Ren, Weiwu and Yao, Jinyu and Hong, Yu},
  doi          = {10.1007/s11063-025-11795-1},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1--32},
  shortjournal = {Neural Process. Lett.},
  title        = {GPCNKB: An attack prediction and reasoning model based on an improved graph convolutional network},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spike-count reduction techniques for low power spiking neural networks. <em>NPL</em>, <em>57</em>(4), 1--23. (<a href='https://doi.org/10.1007/s11063-025-11786-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural network (SNN) has demonstrated its great potential in low-power neuromorphic applications. In SNN, computation activities are associated with the arrival and firing of spikes, its power consumption is directly correlated with the number of spikes propagated in the network. In this paper, we explore two methods to reduce the spike-count in the network, aiming to reduce the power consumption of SNN. We use Poisson distribution function in the input layer and through adjusting the correlation (called the gain in the paper) between the probability of spike generation and input values, the number of spikes in the input layer can be reduced to only 20% of the baseline model with the accuracy degradation of less than 1%. We also exploit the leaky-integrate-and-fire (LIF) mechanism and use the refractory period to reduce the generation of spikes from the neurons in the hidden layers. Through this method, the spike-count is reduced by 20% $$\sim $$ 50% while the performance degradation is still less than 1%. These two spike-count reduction techniques are implemented in Verilog RTL; the power simulation results demonstrate significant power reduction in performing SNN computations. We further discovered that for different network architectures, these two techniques have different trade-offs to achieve optimal spike-count reduction while maintaining satisfactory results. Compared with other spike-count reduction techniques, the proposed scheme is efficient and straightforward for hardware implementation, making it well-suited for edge computing scenarios.},
  archive      = {J_NPL},
  author       = {Kang, Xinyu and Yang, Zhitao and Ren, Yuan and Ye, Terry Tao},
  doi          = {10.1007/s11063-025-11786-2},
  journal      = {Neural Processing Letters},
  month        = {8},
  number       = {4},
  pages        = {1--23},
  shortjournal = {Neural Process. Lett.},
  title        = {Spike-count reduction techniques for low power spiking neural networks},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting depression in older adults: A novel feature selection and neural network framework. <em>NPL</em>, <em>57</em>(3), 1--21. (<a href='https://doi.org/10.1007/s11063-025-11760-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression in older adults is a significant public health issue with broad impacts on both individuals and society. The multifaceted nature of depression underscores the complexity of identifying and predicting risk factors, necessitating a sophisticated and accurate approach based on new emerging technologies. Compared to traditional statistical methods, machine learning provides a more detailed and individualized understanding of risk variables by analyzing large datasets, identifying patterns, and building predictive models. This study presented a novel feature selection method based on the relief and lasso algorithms. The proposed feature selection method selected the ten most significant features from the dataset. A neural network (NN) with hyperparameters optimized by a grid search technique was used to categorize depression. The feature selection and classification modules work together as a single unit, namely as (Relief_Lasso_NN). Data from the Swedish National Study on Aging and Care (SNAC) was used for this study. The collected dataset consists of 726 samples with 75 features per sample. Four experiments were conducted to validate the performance of the proposed (Relief_Lasso_NN) framework. The proposed model achieved an accuracy of 90.34% in predicting depression using only ten features from the dataset. The top 10 features identified by the proposed feature selection method significantly impact depression in older adults. Furthermore, the performance of seven other state-of-the-art machine learning models was also compared with the proposed framework.},
  archive      = {J_NPL},
  author       = {Javeed, Ashir and Anderberg, Peter and Ghazi, Ahmad Nauman and Saleem, Muhammad Asim and Sanmartin Berglund, Johan},
  doi          = {10.1007/s11063-025-11760-y},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--21},
  shortjournal = {Neural Process. Lett.},
  title        = {Predicting depression in older adults: A novel feature selection and neural network framework},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incremental affinity propagation based on cluster consolidation and stratification. <em>NPL</em>, <em>57</em>(3), 1--32. (<a href='https://doi.org/10.1007/s11063-025-11752-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern data mining applications require to perform incremental clustering over dynamic datasets by tracing temporal changes over the resulting clusters. In this paper, we propose A-Posteriori affinity Propagation (APP), an incremental extension of affinity propagation (AP) based on cluster consolidation and cluster stratification to achieve faithfulness and forgetfulness. APP enforces incremental clustering where i) new arriving objects are dynamically consolidated into previous clusters without the need to re-execute clustering over the entire dataset of objects, and ii) a faithful sequence of clustering results is produced and maintained over time, while allowing to forget obsolete clusters with decremental learning functionalities. Four popular labeled datasets are used to test the performance of APP with respect to benchmark clustering performances obtained by conventional AP and incremental affinity propagation based on nearest neighbor assignment algorithms. Experimental results show that APP achieves comparable clustering performance while enforcing scalability at the same time.},
  archive      = {J_NPL},
  author       = {Periti, Francesco and Montanelli, Stefano and Ferrara, Alfio and Castano, Silvana},
  doi          = {10.1007/s11063-025-11752-y},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--32},
  shortjournal = {Neural Process. Lett.},
  title        = {Incremental affinity propagation based on cluster consolidation and stratification},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking attention mechanism: Channel re-attention and spatial multi-region attention for fine-grained visual classification. <em>NPL</em>, <em>57</em>(3), 1--20. (<a href='https://doi.org/10.1007/s11063-025-11757-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained visual classification (FGVC) aims to classify sub-categories, such as different kinds of birds, varying brands of cars, etc. Learning feature representations from discriminative parts of an object has always played an essential role in this task. Recently, applying the attention mechanism to extract discriminative parts has become a trend. However, using the classical attention mechanism brings two main limitations in FGVC: First, they always focus on informative channels in feature maps but ignore those with poor information, which also contain fine-grained knowledge that is helpful for classification. Second, they largely stare at the most salient parts of objects but ignore the insignificant but discriminative parts. To address these limitations, we propose channel re-attention and spatial multi-region attention for fine-grained visual classification (CRA-SMRA), which incorporate two lightweight modules that can be easily inserted into existing convolutional neural networks (CNN): On the one hand, we provide a channel re-attention module (CRAM), which can select the importance of the channels of the feature map of the current stage, obtaining more discriminative features and enabling the network to mine useful fine-grained knowledge in information-poor channels. On the other hand, a spatial multi-region attention module (SMRAM) is proposed to calculate the spatial matching degree of feature maps in different stages, obtaining multi-stage feature maps that focus on different discriminative parts. Our method does not require bounding boxes/part annotations and can be trained in an end-to-end way. Extensive experimental results on several fine-grained benchmark datasets demonstrate that our approach achieves state-of-the-art performance.},
  archive      = {J_NPL},
  author       = {Wang, XiaoHui and Sun, Yulin and Liu, Xin and Zou, Zhipeng and Wang, Li and Wang, Kun and Liang, Xiaoyang and Liu, Wei},
  doi          = {10.1007/s11063-025-11757-7},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--20},
  shortjournal = {Neural Process. Lett.},
  title        = {Rethinking attention mechanism: Channel re-attention and spatial multi-region attention for fine-grained visual classification},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Control of double swing arm tracked robot based on deep reinforcement learning in various uneven terrains. <em>NPL</em>, <em>57</em>(3), 1--29. (<a href='https://doi.org/10.1007/s11063-025-11762-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a control method of double-swing-arm tracked robot based on deep reinforcement learning is proposed to solve the problem of stable operation of the robot on uneven terrain. A control algorithm without complex kinematics analysis is designed, so that the robot can learn independently and keep balance on various irregular terrain. This paper mainly studies the stability of the robot when crossing the terrain, so as to reduce the damage to the robot hardware. The main contributions are as follows: (1) Combining the hierarchical control strategy with the curiosity module, and testing in the simulation environment has achieved good performance; (2) By adding stability design, the robot can pass through uneven terrain more smoothly; (3) Three kinds of terrain task scenes are developed in the simulation environment, and the effectiveness of the control algorithm is verified. The experimental results show that this method can effectively improve the robot’s ability to cross complex terrain while maintaining high stability.},
  archive      = {J_NPL},
  author       = {Gao, Zhongye and Shen, Furao and Zhao, Jian},
  doi          = {10.1007/s11063-025-11762-w},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--29},
  shortjournal = {Neural Process. Lett.},
  title        = {Control of double swing arm tracked robot based on deep reinforcement learning in various uneven terrains},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic trade-offs in adversarial training: Exploring efficiency, robustness, forgetting, and interpretability. <em>NPL</em>, <em>57</em>(3), 1--24. (<a href='https://doi.org/10.1007/s11063-025-11751-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attacks pose a threat to neural networks, requiring robust methods to mitigate them. Adversarial Training has emerged as a promising approach; however, its practical application in real-world deep learning systems is hindered by the trade-offs between efficiency and robustness, as optimizing for one aspect may come at cost of the other. This paper presents a comprehensive investigation into the impact of different Adversarial Training approaches and model types on the robustness of adversarially trained models, while considering the dynamic trade-offs involved. Leveraging our previously published method, Delayed Adversarial Training with Non-Sequential Adversarial Epochs – DATNS, we conduct extended empirical analyses through new experiments to effectively balance these trade-offs and navigate the interplay between efficiency and robustness, as well as catastrophic forgetting and interpretability. By providing our insights on the discussed trade-offs this research aims to enable the development of more efficient, robust, and interpretable models against adversarial attacks.},
  archive      = {J_NPL},
  author       = {Kafali, Efi and Semertzidis, Theodoros and Daras, Petros},
  doi          = {10.1007/s11063-025-11751-z},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--24},
  shortjournal = {Neural Process. Lett.},
  title        = {Dynamic trade-offs in adversarial training: Exploring efficiency, robustness, forgetting, and interpretability},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lights, camera, adversary: Decoding the enigmatic world of malicious frames in real-time video surveillance systems. <em>NPL</em>, <em>57</em>(3), 1--35. (<a href='https://doi.org/10.1007/s11063-025-11756-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surveillance systems play a vital role in ensuring public safety by detecting criminal activity, managing traffic, and more. Nowadays, deep learning (DL) and machine learning (ML) techniques are widely used in these systems to enhance their accuracy and efficiency. However, recent studies have shown that artificial intelligence (AI)-based systems, particularly those using ML and DL, are vulnerable to adversarial attacks, which can cause the model to make incorrect decisions. These attacks were originally designed for image models. In this study, we propose a new approach where adversarial attacks can be extended to real-time video surveillance systems. To demonstrate this, we applied our method to a real-time face mask detection system. The system is based on Multi-Task Cascaded Convolutional Networks (MTCNN) for face detection and MobileNet-v2 for face mask classification. Our pioneering framework shows how state-of-the-art adversarial attacks can be adapted for real-time surveillance systems. Experimental results show the impact of the adversarial attack, reducing the model’s performance from a precision (P) of 0.93, recall (R) of 0.93, F1 score (F) of 0.93, and accuracy (A) of 0.93 to just 0.22, 0.21, 0.22, and 0.22, respectively. This research highlights the vulnerabilities of critical video surveillance systems to adversarial threats, emphasizing the urgent need for strong defense mechanisms before these systems are deployed in real-world scenarios.},
  archive      = {J_NPL},
  author       = {Sheikh, Burhan ul Haque and Zafar, Aasim},
  doi          = {10.1007/s11063-025-11756-8},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--35},
  shortjournal = {Neural Process. Lett.},
  title        = {Lights, camera, adversary: Decoding the enigmatic world of malicious frames in real-time video surveillance systems},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A forced decoding-based approach for enhancing low-resource ASR. <em>NPL</em>, <em>57</em>(3), 1--10. (<a href='https://doi.org/10.1007/s11063-025-11759-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multilingual automatic speech recognition represents a crucial research direction in tackling the challenges associated with low-resource scenarios. To effectively incorporate language-specific information in the joint training of a model across multiple languages and leverage linguistic similarities to enhance performance on the target low-resource language, this paper introduces a language similarity evaluation approach based on forced decoding. Specifically, when the target language is specified, the speeches of the source language are decoded into transcription in the target language, and the normalized posterior is utilized as the foundation for evaluating language similarity. Comprehensive experiments and analyses conducted on six low-resource languages reveal that the proposed approach achieves an average word error rate relative reduction of 21.74, 7.68, and 3.45% compared to three widely used benchmark methods, respectively, thereby validating the effectiveness of our approach.},
  archive      = {J_NPL},
  author       = {Liu, Yunpeng and Yang, Xukui and Qu, Dan},
  doi          = {10.1007/s11063-025-11759-5},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--10},
  shortjournal = {Neural Process. Lett.},
  title        = {A forced decoding-based approach for enhancing low-resource ASR},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information compensation graph contrastive learning for recommendation. <em>NPL</em>, <em>57</em>(3), 1--16. (<a href='https://doi.org/10.1007/s11063-024-11701-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying graph convolutional neural networks to collaborative filtering is a novel approach pertaining to recommendation systems currently, which has afforded suitable results. However, certain problems still limit the performance of graph collaborative filtering, such as the data uniformity problem. In other words, the quality of embedding the expression of different data after multiple convolutions is reduced, leading to the decline of push model performance. In this paper, we propose self-supervised contrastive learning using global information compensation of feature embeddings, which can effectively alleviate the problem of data uniformity and improve model robustness. Simultaneously, we also propose a graph convolution method using local cooperative propagation to improve the performance of the recommendation model. This embedding calculation method for local cooperative propagation can maximize the influence of low-layer embedding on high-layer embedding, thereby improving the high-layer embedding uniformity. Experiments show that compared with the baseline, our model exhibits significantly improved performance on the three public datasets. Partially on the ML-1 M dataset, the proposed ICCL exhibits a performance improvement of 7.96%, proving that our method is valid and explainable.},
  archive      = {J_NPL},
  author       = {Wang, Zhenhai and Guo, Yunlong and Zhao, Xiaoli and Liu, Qi and Li, Weimin and Liu, Chang},
  doi          = {10.1007/s11063-024-11701-1},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--16},
  shortjournal = {Neural Process. Lett.},
  title        = {Information compensation graph contrastive learning for recommendation},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ORCNet: A context-based network to simultaneously segment the ocular region components. <em>NPL</em>, <em>57</em>(3), 1--29. (<a href='https://doi.org/10.1007/s11063-025-11731-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate extraction of the Region of Interest is critical for successful ocular region-based biometrics. In this direction, we propose a new context-based segmentation approach, entitled Ocular Region Context Network (ORCNet), introducing a specific loss function, i.e., the Punish Context Loss (PC-Loss). The PC-Loss punishes the segmentation losses of a network by using a percentage difference value between the ground truth and the segmented masks. We obtain the percentage difference by taking into account Biederman’s semantic relationship concepts, in which we use three contexts (semantic, spatial, and scale) to evaluate the relationships of the objects in an image. Our proposal achieved promising results in the evaluated scenarios—iris, sclera, and ALL (iris + sclera) segmentations—, outperforming the literature baseline techniques. The ORCNet with ResNet-152 outperforms the best baseline (EncNet with ResNet-152) on average by 2. $$27\%$$ , 28. $$26\%$$ and 6. $$43\%$$ in terms of F-Score, Error Rate and Intersection Over Union, respectively. We also provide (for research purposes) 3191 manually labeled masks for the MICHE-I database, as another contribution of our work.},
  archive      = {J_NPL},
  author       = {Lucio, Diego Rafael and Zanlorensi, Luiz A. and Costa, Yandre M. G. and Menotti, David},
  doi          = {10.1007/s11063-025-11731-3},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--29},
  shortjournal = {Neural Process. Lett.},
  title        = {ORCNet: A context-based network to simultaneously segment the ocular region components},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed-time adaptive control for nonstrict-feedback nonlinear systems with input delay and unknown backlash-like hysteresis. <em>NPL</em>, <em>57</em>(3), 1--20. (<a href='https://doi.org/10.1007/s11063-025-11749-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article explores the tracking control challenge within nonstrict-feedback nonlinear systems featuring input delay and unknown backlash-like hysteresis. A fixed-time adaptive control scheme is developed to address this problem. Radial basis function neural networks play a key role in identifying the unknown nonlinear functions during the design process. Pade approximation and an intermediate variable are strategically employed to mitigate the impact of input delay, while the compensation for the effect of unknown hysteresis input is achieved through approximating another intermediate variable. By combining the adaptive backstepping control technique with fixed-time stability theory, the article presents an adaptive fixed-time control method. The control scheme proposed ensures the boundedness of all signals in the closed-loop system, as analyzed through the Lyapunov stability theory. This guarantees accurate tracking of desired signals within a fixed time. The efficacy of the proposed approach is additionally validated through simulation studies. The effectiveness of the proposed controller is validated with a real-world example involving an electromechanical system.},
  archive      = {J_NPL},
  author       = {Kharrat, Mohamed and Alhazmi, Hadil},
  doi          = {10.1007/s11063-025-11749-7},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--20},
  shortjournal = {Neural Process. Lett.},
  title        = {Fixed-time adaptive control for nonstrict-feedback nonlinear systems with input delay and unknown backlash-like hysteresis},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdamRAG: Adaptive algorithm with ravine method for training deep neural networks. <em>NPL</em>, <em>57</em>(3), 1--25. (<a href='https://doi.org/10.1007/s11063-025-11766-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive optimization algorithms, such as Adam, are widely employed in deep learning. However, because they primarily rely on learning rate adjustments, a trade-off often exists between optimization stability and generalization capability. To address this issue, we propose AdamRAG, a novel optimization algorithm that integrates adaptive methods with Ravine acceleration and momentum techniques, aiming to preserve the stability of adaptive algorithms while enhancing their generalization performance. Within the adaptive framework, AdamRAG introduces extrapolation steps based on Ravine acceleration, which not only accelerate convergence but also prevent the iterative process from becoming trapped in local saddle points, thereby boosting generalization. Simultaneously, the momentum method is employed to regulate the descent step sizes, further improving the algorithm’s stability. Theoretical analysis demonstrates that AdamRAG achieves sublinear convergence in non-convex optimization scenarios. Extensive experiments across tasks such as image classification, natural language processing, and reinforcement learning validate its effectiveness, with results indicating that AdamRAG outperforms established optimizers (e.g., NAG, Adam, Lion) in terms of both convergence speed and generalization performance. Furthermore, sensitivity analysis shows that AdamRAG exhibits greater robustness to variations in learning rate, significantly reducing the need for hyperparameter tuning. These findings suggest that by integrating Ravine acceleration, adaptive methods, and momentum techniques, AdamRAG effectively mitigates the trade-off between stability and generalization, providing an efficient and robust optimization tool for deep learning applications.},
  archive      = {J_NPL},
  author       = {Zhang, Yifan and Zhao, Di and Li, Hongyi and Pan, Chengwei},
  doi          = {10.1007/s11063-025-11766-6},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--25},
  shortjournal = {Neural Process. Lett.},
  title        = {AdamRAG: Adaptive algorithm with ravine method for training deep neural networks},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PCDM: Point cloud completion by conditional diffusion model. <em>NPL</em>, <em>57</em>(3), 1--19. (<a href='https://doi.org/10.1007/s11063-025-11767-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the point clouds collection process, the errors can be easily introduced into dataset, leading to biases in subsequent analyses, so the completion of point clouds is a critical step of point cloud analysis. In this paper, we introduce a conditional diffusion model architecture (PCDM) to solve point cloud completion problem. The diffusion model has shown remarkable success in image generation and has recently started to be applied in other domains, showing amazing results. By harnessing the potent generative abilities of diffusion models, we progressively get the complete point clouds derived from pure noise data. In the denosing process, we employ a Local-Global Net (LoGNet) to fuse global and local features, guiding the generation of point clouds by the model. Furthermore, to strike a balance between the completeness of the generated point cloud data and local details, we introduce an offset-attention mechanism to extract features from incomplete point clouds. Experiments conducted on multiple public datasets demonstrate that the point cloud completion method proposed in this paper outperforms previous approaches.},
  archive      = {J_NPL},
  author       = {Zhang, Cheng and Qi, Zhiqiang and Yuan, Wenwen and Qi, Wanlong and Yang, Zhengzheng and Su, Zhaobing},
  doi          = {10.1007/s11063-025-11767-5},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--19},
  shortjournal = {Neural Process. Lett.},
  title        = {PCDM: Point cloud completion by conditional diffusion model},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel GMFO-based identification method for MIMO hammerstein model with heavy-tailed noise. <em>NPL</em>, <em>57</em>(3), 1--28. (<a href='https://doi.org/10.1007/s11063-025-11768-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the identification of multi-input multi-output Hammerstein system with combined nonlinearities under the heavy-tailed noise. Considering the outliers in the noises may lead to the unsatisfactory identification results using analytical method, this paper proposes a novel identification scheme combining the advantages of Radial Basis Function Neural Network (RBFNN) and a recently proposed nature-inspired algorithm called moth-flame optimization (MFO). We use RBFNN to construct the static nonlinear block. The identification problem could be converted to an optimization problem, and the parameters of the linear part and nonlinear part are updated simultaneously. To improve its performance for identification, a novel version of MFO based on Gaussian-mixture distribution, which is named gaussian-mixture moth-flame optimization, is proposed. The main innovation is the discrete population initialization and the individual position adjustment using Gaussian-mixture distribution, which is conducive to jumping out of local optima caused by outliers. The simulation results illustrate the proposed method is effective and outperforms other common evolutionary algorithms.},
  archive      = {J_NPL},
  author       = {Wang, Jiaqi and Ling, Fuyu},
  doi          = {10.1007/s11063-025-11768-4},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--28},
  shortjournal = {Neural Process. Lett.},
  title        = {A novel GMFO-based identification method for MIMO hammerstein model with heavy-tailed noise},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial complex-valued neural processing using memristive hyperchaotic synchronization. <em>NPL</em>, <em>57</em>(3), 1--64. (<a href='https://doi.org/10.1007/s11063-025-11772-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study intends to boost the communication security in Industrial Internet of Things (IIoT) by addressing the alteration challenges of secure key exchange over public network. The objectives are to propose a cognitive Artificial Neural Network (ANN) synchronization combined with memristive hyperchaotic systems towards obtaining better synchronization performance, accuracy, random behaviour and overall security. The proposed method makes use of complex-valued ANN synchronization assisted with memristive hyperchaotic system that has dimensions 4D, 5D and 6D to produce high-entropy cryptographic keys. In this paper, Pseudo-Random Number Generation (PRNG) based on hyperchaotic is used to generate an input vector for ANN synchronization. A bi-directional learning approach is applied in the process of synchronization to improve the distribution of neuronal keys in a public channel between ANNs. A series of experiments were conducted using synchronized speed rate, entropy test as well as accuracy dominant test and performance key extraction phase using precision and recall and also F1-score. The proposed approach outperforms the existing traditional methods. It improves synchronization speed by 15%, synchronization accuracy by 93.8%, precision by 92.0% and F1 score by 93.3%. Therefore, and it can produce higher reliable key generation without any errors because the proposed system is generating high-entropy cryptographic keys with more than 7.5 bits that are able to strengthen IIoT communication against attacks by providing more randomness and security. Besides that, this faster and secured key exchange is possible due to memristive hyperchaotic structures that provide an excellent PRNG support, whereby they produced a remarkable reduction in error rate generated in key synchronization as well as low latency was achieved during key exchange process. An ANN-synchronized key exchange scheme is proposed in this research as the solution for secure IIoT communication problem. The proposed synchronization method uses hyperchaotic systems and coordination of two ANNs, which provides low-latency synchronization with high precision and high F1 score in comparison to the existing methods published in literature. The proposed key generation grows linearly with the number of nodes utilized in a network. Thus, it can also be used for IIoT real-time applications without privacy concerns.},
  archive      = {J_NPL},
  author       = {Zheng, Leiqing and Sarkar, Arindam and Noorwali, Abdulfattah and Mohammad, Alsharef},
  doi          = {10.1007/s11063-025-11772-8},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--64},
  shortjournal = {Neural Process. Lett.},
  title        = {Artificial complex-valued neural processing using memristive hyperchaotic synchronization},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MTCR: Method for matching texts against causal relationship. <em>NPL</em>, <em>57</em>(3), 1--23. (<a href='https://doi.org/10.1007/s11063-025-11743-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text matching is considered a vital task in natural language processing and constitutes a fundamental component of many NLP applications. In practical scenarios, there exist numerous texts with causal relationships, such as questions and answers in question-answering systems. For text matching tasks involving causal relationships, considering the causal connections between text pairs is of paramount importance. Furthermore, when dealing with lengthy texts, causal signals often exhibit sparsity, rendering the extraction of causal features a challenging endeavor. To address the aforementioned issues, this paper introduces an approach that amalgamates causal knowledge distillation and causal semantic extraction, denoted as the Method for Matching Texts with Causal Relationship (MTCR). This framework effectively learns deep semantic representations of causal relationships between texts. MTCR excels at handling text matching tasks that involve causal relationships, including tasks like natural language inference and answer selection. Simultaneously, it effectively identifies instances of causal inversions. Through experimentation on five benchmark text matching datasets, our research findings indicate that the proposed method can effectively handle text matching tasks involve causal relationships.},
  archive      = {J_NPL},
  author       = {Jiang, XinYue and He, JingSong and Gu, Li},
  doi          = {10.1007/s11063-025-11743-z},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--23},
  shortjournal = {Neural Process. Lett.},
  title        = {MTCR: Method for matching texts against causal relationship},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two types of stability criteria for incommensurate fractional-order inertial delay BAM neural networks. <em>NPL</em>, <em>57</em>(3), 1--16. (<a href='https://doi.org/10.1007/s11063-025-11765-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the global Mittag-Leffler stability and finite time stability of incommensurate fractional-order inertial delay BAM neural networks. Initially, the system, characterized by high-order incommensurate fractional-order dynamics, is transformed into a low-order system through an appropriate variable substitution. Subsequently, sufficient conditions for the achievement of global Mittag-Leffler stability and finite time stability are derived. These conditions are based on the properties of the Riemann-Liouville fractional derivative and integral, and the relation of fractional integral inequalities to the Bellman-Gronwall inequality. The efficacy and accuracy of the proposed theoretical results are substantiated through two numerical simulations.},
  archive      = {J_NPL},
  author       = {Danning, Xu and Wei, Liu},
  doi          = {10.1007/s11063-025-11765-7},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--16},
  shortjournal = {Neural Process. Lett.},
  title        = {Two types of stability criteria for incommensurate fractional-order inertial delay BAM neural networks},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PATCHOUT: Adversarial patch detection and localization using semantic consistency. <em>NPL</em>, <em>57</em>(3), 1--42. (<a href='https://doi.org/10.1007/s11063-025-11775-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer vision systems are actively deployed in safety-critical applications such as autonomous vehicles. Real-world adversarial patches are capable of compromising the artificial intelligence (AI) systems with catastrophic outcomes. Existing defenses against patch attacks are based on identifying neurons, features, or gradients of high intensity. However, these defenses are vulnerable to weaker attacks that have less obvious attack signatures. In this paper, we propose the PATCHOUT framework that detects and locates adversarial patches using semantic consistency. Within patch detection, the key insight is that the top class predictions for an entity are semantically consistent for benign images, whereas they are inconsistent for attacked images. Within patch localization, it is observed that patches are semantically consistent with a coarse grained segmentation of the image. This allows the PATCHOUT framework to detect and remove adversarial patches using a class consistency checker as well as image segmentation, attribution analysis, and image restoration techniques. The experimental evaluation demonstrates that PATCHOUT can detect a broad range of adversarial patches with over 90% accuracy. The framework achieves 20% higher accuracy than other defenses. The framework is also evaluated against unseen attacks and adaptive attacks, reducing the success rate of adaptive attacks from 56% to 24%.},
  archive      = {J_NPL},
  author       = {Simon, Dominic and Jha, Sumit and Ewetz, Rickard},
  doi          = {10.1007/s11063-025-11775-5},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--42},
  shortjournal = {Neural Process. Lett.},
  title        = {PATCHOUT: Adversarial patch detection and localization using semantic consistency},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The epochal sawtooth phenomenon: Unveiling training loss oscillations in adam and other optimizers. <em>NPL</em>, <em>57</em>(3), 1--19. (<a href='https://doi.org/10.1007/s11063-025-11776-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we identify and analyze a recurring training loss pattern, which we term the Epochal Sawtooth Phenomenon (ESP), commonly observed during training with adaptive gradient-based optimizers, particularly Adam optimizer. This pattern is characterized by a sharp drop in loss at the beginning of each epoch, followed by a gradual increase, resulting in a sawtooth-shaped loss curve. Through empirical observations, we demonstrate that while this effect is most pronounced with Adam, it persists, although less severely, with other optimizers such as RMSProp. We empirically analyze the mechanisms underlying ESP, focusing on key factors such as Adam’s $$\beta $$ parameters, batch size, data shuffling, and sample replacement. Our analysis shows that ESP arises from adaptive learning rate adjustments controlled by the second moment estimate. Additionally, we identify the “immediate re-exposure to samples” effect during data shuffling, which causes the model to learn or memorize more at the beginning of each epoch. We also find that smaller values of $$\beta _2$$ exacerbate ESP but can act as a form of regularization. While ESP is not necessarily indicative of overfitting, higher model capacity can amplify the phenomenon. To further support our analysis, we replicate ESP through a high-dimensional quadratic minimization task. We demonstrate that ESP can emerge even in simple optimization scenarios, reinforcing the generality of this pattern. The code for reproducing our experiments is available at https://github.com/qiliuchn/training-loss-pattern .},
  archive      = {J_NPL},
  author       = {Liu, Qi and Ma, Wanjing},
  doi          = {10.1007/s11063-025-11776-4},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--19},
  shortjournal = {Neural Process. Lett.},
  title        = {The epochal sawtooth phenomenon: Unveiling training loss oscillations in adam and other optimizers},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning approach for paragraph-level paraphrase generation for plagiarism detection. <em>NPL</em>, <em>57</em>(3), 1--42. (<a href='https://doi.org/10.1007/s11063-025-11771-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expressing information in different forms is an important skill that students should develop in school. This skill positively impacts academic reading and writing. However, it can also lead to negative consequences, such as plagiarism. Students may paraphrase original texts and present them as their own work. Therefore, the need to develop effective approaches to detect plagiarism and identify paraphrase has become increasingly important in academia, journalism, publishing, and other fields where innovation, novelty, and originality are highly valued, especially with the rising incidence of plagiarism in these areas because of the easy access to information on the internet and the capabilities of large language models. Most published detection methods analyse plagiarism at the sentence-level. We have developed approaches for generating and detecting paraphrased paragraphs by considering inter-sentence and intra-sentence relations, which enables the identification of paraphrased text at the paragraph-level. This includes joining, splitting, and/or shifting sentences within a paragraph, as students often plagiarise paragraphs. In the generating stage, we create the ALECS dataset, by developing three algorithms and applying a masking approach to tackle the paragraph’s syntactic and lexical layers while maintaining the paragraph’s semantics. ALECS can contribute to developing students’ abilities in paraphrasing, as there are more than 6 different forms for each source paragraph. In addition, as in this study, ALECS can be employed to train deep learning models for the purpose of generating or detecting plagiarised paragraphs. For the detection phase, our method shows robust results and outperforms existing work in detecting paragraph-level paraphrases, achieving a 90.1 F1 score with Longformer and reaching 96 when using a fine-tuned GPT-3.5.},
  archive      = {J_NPL},
  author       = {Saqaabi, Arwa Al and Stewart, Craig and Akrida, Eleni and Cristea, Alexandra I.},
  doi          = {10.1007/s11063-025-11771-9},
  journal      = {Neural Processing Letters},
  month        = {6},
  number       = {3},
  pages        = {1--42},
  shortjournal = {Neural Process. Lett.},
  title        = {A deep learning approach for paragraph-level paraphrase generation for plagiarism detection},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Character-level encoding based neural machine translation for hindi language. <em>NPL</em>, <em>57</em>(2), 1--21. (<a href='https://doi.org/10.1007/s11063-025-11718-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Machine Translation (NMT) is one step ahead of traditional statistical phrase-based translation systems because of its better translation ability. But it requires a large amount of parallel training data, which can be challenging for languages with limited resources like many Indian languages. In the past, researchers have tried to address the issue using data augmentation. In this paper, we present a data augmentation technique for the Hindi language based on five phrases: noun phrases, verb phrases, prepositional phrases, adjective phrases, and adverb phrases. We augment the training corpus using parser-generated phrasal segments and evaluate the efficiency of the proposed work on the Hindi language. Further, the paper presents training in the NMT model at the character level instead of the word level. This approach can help overcome challenges associated with word-level translations, such as handling rare and out-of-vocabulary words and phrases, dealing with morphological complexity, and addressing languages with ambiguous word boundaries. The proposed work was evaluated on a low-resource language pair, Hindi-English, using the Google Transformer model as the baseline state-of-the-art. The experiments used two distinct datasets: WMT14 Hin-Eng and Samanantar Hin-Eng parallel corpus with character-level encoding for the translation task. The proposed model is able to surpass the cutting-edge baseline and saw an increase in BLEU scores for the WMT14 translation challenge with +2.52 on base paper using three phrase sentences with character-level encoding and +2.68 BLEU Score on base paper using five phrase sentences with character-level encoding. Further, character-level encoding is evaluated on non-augmented Samanantar dataset; it performs better in the baseline approach for translation purposes. It clearly shows that the proposed model outperforms in Hindi language translation.},
  archive      = {J_NPL},
  author       = {Rathod, Divya and Yadav, Arun Kumar and Kumar, Mohit and Yadav, Divakar},
  doi          = {10.1007/s11063-025-11718-0},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1--21},
  shortjournal = {Neural Process. Lett.},
  title        = {Character-level encoding based neural machine translation for hindi language},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OTIEA: Ontology-enhanced triple intrinsic-correlation for cross-lingual entity alignment. <em>NPL</em>, <em>57</em>(2), 1--19. (<a href='https://doi.org/10.1007/s11063-025-11723-3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-lingual and cross-domain knowledge alignment without sufficient external resources is a fundamental and crucial task for fusing irregular message. Aiming to discover equivalent objects from different knowledge graphs (KGs), embedding-based entity alignment (EA) has been attracting great interest from industry and academic research recently. Most of related methods usually explore the correlation between entities and relations through neighbor nodes, structural information and external resources. However, the complex intrinsic interactions among triple elements and role information are rarely modeled, which leads to the inadequate illustration. In addition, external resources are unavailable in some scenarios especially cross-lingual and cross-domain applications, which reflects the weak scalability. To tackle the above insufficiency, a novel universal EA framework (OTIEA) based on ontology pair and role enhancement mechanism via triple-aware attention is proposed in this paper without introducing external resources. Specifically, an ontology-enhanced triple encoder is designed via mining intrinsic correlations and ontology pair information instead of independent elements. In addition, the EA-oriented representations can be obtained in triple-aware entity decoder by fusing role diversity. Finally, a bidirectional iterative alignment strategy is deployed to expand seed entity pairs. The experimental results on three real-world datasets show that our framework achieves a competitive performance compared with baselines.},
  archive      = {J_NPL},
  author       = {Zhang, Zhishuo and Tan, Chengxiang and Yang, Min and Zhao, Xueyan},
  doi          = {10.1007/s11063-025-11723-3},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1--19},
  shortjournal = {Neural Process. Lett.},
  title        = {OTIEA: Ontology-enhanced triple intrinsic-correlation for cross-lingual entity alignment},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedDefense: A defense mechanism for dishonest client attacks in federated learning. <em>NPL</em>, <em>57</em>(2), 1--21. (<a href='https://doi.org/10.1007/s11063-025-11724-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL), which allows multiple participants to co-train machine learning models, enhances privacy-preserving by avoiding exposing local data. In recent years, FL has been considered a promising paradigm. However, during the FL process, individual clients may fall out on the client’s side, or a particular client may engage in dishonest behavior such as uploading malicious data, thereby hindering the training of the global model. Most of the existing defense methods are considered only from the perspective of data filtering or model weighting, which have the disadvantages of poor robustness and high computational cost. Therefore, we propose a novel security FL (FedDefense) scheme based on client selection and adaptive rewards to defend against dishonest client attacks. First, to reduce the likelihood of poisoned clients participating in aggregation, we design a randomized subset method for client contribution evaluation via Kullback–Leibler (KL) divergence. Second, we reduce the server’s dependence on clients through a dynamic reward strategy to ensure healthy model training. Numerical analysis and performance evaluation show that the proposed technique prevents the threat of dishonest clients during FL processing. Compared with existing methods, our approach has significant advantages in terms of efficiency and performance.},
  archive      = {J_NPL},
  author       = {Yue, Gaofeng and Han, Xiaowei},
  doi          = {10.1007/s11063-025-11724-2},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1--21},
  shortjournal = {Neural Process. Lett.},
  title        = {FedDefense: A defense mechanism for dishonest client attacks in federated learning},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal aspect-based sentiment analysis with external knowledge and multi-granularity image-text features. <em>NPL</em>, <em>57</em>(2), 1--34. (<a href='https://doi.org/10.1007/s11063-025-11737-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal aspect-based sentiment analysis (MABSA) is an essential task in the field of sentiment analysis, which still confronts several critical challenges. The first challenge is how to effectively capture key information within both image and text features to enhance the recognition and understanding of complex sentiment expressions. The second challenge is how to achieve cross-modal alignment of multi-granularity text features and image features. The third challenge is how to narrow the semantic gap between image modality and text modality through effective cross-modal feature fusion. To address these issues, a framework that leverages external knowledge and multi-granularity image and text features (EKMG) is proposed. Firstly, an external knowledge enhanced semantic extraction module is introduced to fuse external knowledge with image features and text features, thereby capturing the key information from texts and images. Secondly, we design a multi-granularity image-text contrastive learning module. This module initially introduces a graph attention network and a novel cross-modal fusion mechanism to align image features and text features at multiple granularities. Additionally, the module employs an image-text contrastive learning strategy to narrow the semantic gap between different modalities. Experimental results on two public benchmark datasets demonstrate that EKMG achieves significant performance improvements compared to state-of-the-art baseline models.},
  archive      = {J_NPL},
  author       = {Liu, Zhanghui and Lin, Jiali and Chen, Yuzhong and Dong, Yu},
  doi          = {10.1007/s11063-025-11737-x},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1--34},
  shortjournal = {Neural Process. Lett.},
  title        = {Multimodal aspect-based sentiment analysis with external knowledge and multi-granularity image-text features},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved condition for ISS of stochastic memristive fuzzy Cohen–Grossberg BAM neural networks with time-varying delays. <em>NPL</em>, <em>57</em>(2), 1--34. (<a href='https://doi.org/10.1007/s11063-025-11739-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary objective of this paper is to conduct a comprehensive investigation into the model of a memristive fuzzy Cohen–Grossberg bidirectional associative memory neural network (MFCGBAMNN) that integrates time-varying delays and stochastic disturbances. This study aims to introduce an innovative approach for addressing the input-to-state stability (ISS) property within this intricate framework. To enhance the understanding of ISS characteristics in these networks, we develop a Lyapunov–Krasovskii function that is instrumental in analyzing stability amidst time-varying delays and stochastic disturbances, serving as a cornerstone for deriving sufficient conditions for ISS. In distinguishing this work from existing studies, we establish a stability analytical framework grounded in the Lyapunov–Krasovskii function. By employing non-smooth analysis techniques and stochastic analysis theory, we derive novel sufficient conditions for ISS. This methodology is particularly relevant to the complexities introduced by stochastic disturbances in the dynamics of neural networks. Moreover, the incorporation of set-valued maps in our analysis provides a solid framework for addressing the uncertainties inherent in memristive systems, thereby enhancing the reliability of the stability conditions derived. To substantiate our theoretical findings, we present two numerical examples that effectively demonstrate the applicability and efficacy of the proposed conditions.},
  archive      = {J_NPL},
  author       = {Santhosh Kumar, S. and Chandrasekar, A.},
  doi          = {10.1007/s11063-025-11739-9},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1--34},
  shortjournal = {Neural Process. Lett.},
  title        = {Improved condition for ISS of stochastic memristive fuzzy Cohen–Grossberg BAM neural networks with time-varying delays},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel non-iterative training method for CNN classifiers using Gram–Schmidt process. <em>NPL</em>, <em>57</em>(2), 1--17. (<a href='https://doi.org/10.1007/s11063-025-11741-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks have become prominent machine learning models, particularly in the realm of computer vision, due to their ability to predict and extract robust features from raw image data. CNNs, similar to other neural network models, undergo training via backpropagation, an iterative technique. However, the backpropagation algorithm has notable challenges, including slow convergence, susceptibility to local minima, and hypersensitivity to learning rates. These challenges not only impact the model’s accuracy but also make the training process computationally intensive. To address these limitations, We introduce a novel approach that trains the CNN classifier using a non-iterative learning method. The proposed approach involves automatic extraction of pertinent features from the raw-data, followed by the application of Gram–Schmidt process to decompose the feature matrix and determine classifier’s weights. The proposed method has shown enhanced predictive accuracy over state-of-the-art models when evaluated on two benchmark datasets, MNIST and CIFAR-10. The extensive experimentation using most cited pre-trained experiments validate the effectiveness of our proposed method.},
  archive      = {J_NPL},
  author       = {Azam, Basim and Kuttichira, Deepthi and Sanjeewani, Pubudu and Verma, Brijesh and Rahman, Ashfaqur and Wang, Lipo},
  doi          = {10.1007/s11063-025-11741-1},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1--17},
  shortjournal = {Neural Process. Lett.},
  title        = {A novel non-iterative training method for CNN classifiers using Gram–Schmidt process},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving text classification on deep neural network. <em>NPL</em>, <em>57</em>(2), 1--17. (<a href='https://doi.org/10.1007/s11063-025-11738-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of Internet information, the classification of massive Internet data plays a very important role in real life. Text classification has been widely used in spam text recognition, intention recognition, text matching, named entity recognition, and other fields. At present, many enterprises provide APIs for text classification for users. Users can upload their data to the cloud server deployed by service providers for analysis, and return the final classification results. However, there is a risk of user data and model leakage in this process. To solve this problem, we propose a privacy-preserving text classification scheme using CKKS fully homomorphic encryption scheme and self-attention mechanism model in the multi-party security computing scenario. Our scheme ensures that user can achieve efficient encrypted data analysis under the premise of their data security, and user must be authorized by the service provider to use the model. Finally, compared with the experimental results of the previous research on privacy text classification under fully homomorphic encryption, the implementation improves the accuracy by 7.97% at most and speed-ups 282.4 times for inference at most, and we ensure the security of the protocol participants.},
  archive      = {J_NPL},
  author       = {Li, Kunhong and Huang, Ruwei and Yang, Bo},
  doi          = {10.1007/s11063-025-11738-w},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1--17},
  shortjournal = {Neural Process. Lett.},
  title        = {Privacy-preserving text classification on deep neural network},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bipartite consensus in multi-agent systems: A node decomposition approach for privacy preservation. <em>NPL</em>, <em>57</em>(2), 1--14. (<a href='https://doi.org/10.1007/s11063-025-11717-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The consensus control protocol of the cooperative-competitive network requires nodes to transmit their own information to the rival group, which is detrimental to the security of the information. In this paper, we propose a novel node decomposition mechanism, which can prevent the state information from being revealed during the information exchange for multi-agent systems with antagonistic interactions. For each node, one of the two subnodes takes over the role of the primitive node with cooperative neighbors, and the other one is involved in antagonistic interactions. Under this method, the connectivity and structurally balanced of the system are not changed, so it can still achieve bipartite consensus. Besides, although the initial values of the two subnodes are chosen randomly, the average of these subnodes corresponds to the original state value, ensuring precise bipartite consensus. Moreover, we also prove that the privacy of a node can be guaranteed if and only if it has a neighbor in the same group. The effectiveness of the proposed approach is demonstrated by a numerical example.},
  archive      = {J_NPL},
  author       = {Wang, Yaqi and Zhang, Yuhong and Lu, Jianquan and Zhong, Jie and Li, Bowen},
  doi          = {10.1007/s11063-025-11717-1},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1--14},
  shortjournal = {Neural Process. Lett.},
  title        = {Bipartite consensus in multi-agent systems: A node decomposition approach for privacy preservation},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WACSO: Wolf crow search optimizer for convolutional neural network hyperparameter optimization. <em>NPL</em>, <em>57</em>(2), 1--22. (<a href='https://doi.org/10.1007/s11063-025-11740-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) experience performance and training efficiency changes according to the selection of correct hyperparameters. The research presents WACSO which combines Crow Search Optimization with Grey Wolf Optimizer to improve Convolutional Neural Networks hyperparameter selection through a hybrid metaheuristic algorithm. The hybrid algorithm WACSO uses exploration parts from CSO together with GWO exploitation mechanics to obtain optimized performance. WACSO reaches higher classification accuracy than traditional optimization algorithms when performing tests on the MNIST and CIFAR-10 datasets along with Random Search and particle swarm optimization and genetic algorithms and standalone CSO and standalone GWO. The best classification results reached 98.9% accuracy levels on MNIST along with 91.5% accuracy levels on CIFAR-10. The final outcomes of this system depend on the combination of model structure along with dataset challenges and available computational power. The investigation demonstrates that mixing algorithms drawn from nature can lead to successful CNN hyperparameter optimization. The promising outcomes of WACSO depend on multiple variables including computation expenses and sensitive parameter adjustments and universal result adaptability between different datasets and network setups. Research into WACSO should expand to involve longer evaluations across multiple datasets and various models to confirm widespread usage.},
  archive      = {J_NPL},
  author       = {Papalkar, Rahul Rajendra and Jadhav, Jayendra and Pattewar, Tareek and Thorat, Vivek and Morey, Pallavi and Deshmukh, Mayur and Jagdale, Rajkumar},
  doi          = {10.1007/s11063-025-11740-2},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1--22},
  shortjournal = {Neural Process. Lett.},
  title        = {WACSO: Wolf crow search optimizer for convolutional neural network hyperparameter optimization},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review: One-shot object detection methods for conditional detection of retail and warehouse products. <em>NPL</em>, <em>57</em>(2), 1--32. (<a href='https://doi.org/10.1007/s11063-025-11742-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facilitating the rapid dispatch and replenishment of products is a critical task in most large warehouses. Automated systems often rely on Deep Learning based object detection methods to monitor operations. A major challenge is the significant requirement for annotated data, and the system’s difficulty in adapting to new products. In contrast, human operators can quickly learn to recognize and adapt to new products with just a single example. This survey focuses on methods that enable conditional detection using a single support example per class. We first introduce common feature fusion techniques and discuss datasets suitable for warehouse and retail products. Next, we provide a comprehensive overview of the current State-Of-The-Art in One-Shot Object Detection. We categorize these approaches based on their detectors, which identify the object’s bounding boxes and classes. Then, we delve into detailed implementations of these methods, analyzing how they leverage this innovative vision approach to improve performance. Finally, we identify promising current trends in this emerging field.},
  archive      = {J_NPL},
  author       = {Desmarescaux, Matthieu and Kaddah, Wissam and Alfalou, Ayman and Deconninck, Jean-Charles},
  doi          = {10.1007/s11063-025-11742-0},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1--32},
  shortjournal = {Neural Process. Lett.},
  title        = {A review: One-shot object detection methods for conditional detection of retail and warehouse products},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image retrieval using multi-layer orientation histograms. <em>NPL</em>, <em>57</em>(2), 1--21. (<a href='https://doi.org/10.1007/s11063-025-11719-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various levels of feature maps extracted from the convolutional neural network models can capture multiple degrees of semantic cues in representation. However, learning the relationship between different semantic features across numerous layers can be challenging. Furthermore, existing representations cannot effectively capture the orientation cues. This paper proposes a representation method, the multi-layer orientation histogram, to address these problems. The main highlights are: (1) An iterative multi-layer integration method to combine the feature maps of various levels is suggested in this study. This method can provide discriminative characteristics based on spatial relationships. (2) An effective approach is suggested to apply Gabor filtering for detecting orientation cues. It can amplify the most dominant orientation cues and is convenient for efficiently using them in subsequent implementations. (3) The proposed representation directly captures orientation cues from each learned feature map. It can incorporate the learned deep features and orientation cues to create a more discriminative representation. Comparative experiments demonstrate that the proposed method exhibits a highly competitive performance on several benchmark datasets in terms of mean average precision. Moreover, this method can provide an effective architecture for learning discriminative global features.},
  archive      = {J_NPL},
  author       = {Li, Xiao-Peng and Liu, Guang-Hai and Lu, Fen},
  doi          = {10.1007/s11063-025-11719-z},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1--21},
  shortjournal = {Neural Process. Lett.},
  title        = {Image retrieval using multi-layer orientation histograms},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hydraulic-supports alignment by TD3 with segmented experience pool. <em>NPL</em>, <em>57</em>(2), 1--22. (<a href='https://doi.org/10.1007/s11063-025-11744-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hydraulic-supports alignment is to keep the coal mining face in line and is heavily influenced by the various geological states. The experiences produced by the moving process are unbalanced, which leads to the agent not learning important knowledge from the rare samples. This paper is the first to introduce the reinforcement learning to the hydraulic-supports alignment, and establish the Markov optimal decision model by TD3 algorithm. Aiming at the imbalance issue of the experience, this paper proposes a segmented experience pool and three sampling replay mechanisms according to the characteristics of the moving process with various geological states. Experimental results show that the improved TD3, utilizing a segmented experience pool with three different replay mechanisms, could effectively identify the optimal moving policy and achieve significant convergence in cases involving both normal movement and insufficient movement of hydraulic-supports. In contrast, the TD3 performs inadequately and struggles to find the optimal policy.},
  archive      = {J_NPL},
  author       = {Yang, Yi and Dai, Yapeng and Wang, Tian and Qian, Wei},
  doi          = {10.1007/s11063-025-11744-y},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1--22},
  shortjournal = {Neural Process. Lett.},
  title        = {Hydraulic-supports alignment by TD3 with segmented experience pool},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of data augmentation in domain generalization. <em>NPL</em>, <em>57</em>(2), 1--38. (<a href='https://doi.org/10.1007/s11063-025-11747-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most machine learning algorithms typically assume that the data distribution of the training and test sets are consistent, but this assumption often fails to hold in practical applications. Domain generalization aims to train a model using only available source data so that the model can generalize to unseen domains. Data augmentation is an important technique in domain generalization, but there are few comprehensive reviews investigating and summarizing its use in domain generalization. This study provides a comprehensive literature review of data augmentation methods in domain generalization for the first time. First, we formalize the definition of domain generalization and analyze the role of data augmentation in domain generalization. Second, we propose a new taxonomy that categorizes methods into three classes based on the augmentation objectives: domain-level, image-level, and feature-level augmentation. Third, we compare the experimental results of some data augmentation methods on three popular domain generalization datasets and discuss the characteristics and advantages of the current best methods. Fourth, we analyze the shortcomings of each category, propose the suggestions for improvements, and summarize the challenges and the future directions of data augmentation for achieving cross-domain generalization from both theoretical and practical perspectives.},
  archive      = {J_NPL},
  author       = {Zhong, Yingyi and Zhou, Wen’an and Wang, Zhixian},
  doi          = {10.1007/s11063-025-11747-9},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1--38},
  shortjournal = {Neural Process. Lett.},
  title        = {A survey of data augmentation in domain generalization},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-aware multi-view contrastive learning for recommendation. <em>NPL</em>, <em>57</em>(2), 1--25. (<a href='https://doi.org/10.1007/s11063-025-11750-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge-aware Recommendation (KGR) aims to utilize a knowledge graph to provide rich side information for items in a recommendation system and construct a unified graph containing users, items, and entities. In this paper, we present a new graph neural network for user-item-entity interaction modeling, named Graph Attention Intent Network, it employs different strategies to aggregate user and item information to generate high-quality representations. Typically, the description of user-item interactions is modeled as a bipartite graph, which overlooks the relations between users and between items, a significant aspect of realistic recommendation. Therefore, we propose a framework, named knowledge-aware multi-view contrastive learning for recommendation. It can explore effective user-user and item-item relations in the heterogeneous network of KGR, construct a user social graph and an item similarity graph, and combine the information of the two views into user-item-entity interaction modeling to enhance the representation of users and items. We introduce cross-graph contrastive learning to facilitate the integration of heterogeneous information while alleviating the sparse labeling problem of recommendation tasks. Experimental results on three benchmark datasets show that our model is more effective than other state-of-the-art models.},
  archive      = {J_NPL},
  author       = {Xie, Xiang and Xie, Zhenping and Liu, Yuan and Wang, Jia and Zhan, Qianyi},
  doi          = {10.1007/s11063-025-11750-0},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1--25},
  shortjournal = {Neural Process. Lett.},
  title        = {Knowledge-aware multi-view contrastive learning for recommendation},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-way decision enhanced graph convolutional networks for text classification. <em>NPL</em>, <em>57</em>(2), 1--26. (<a href='https://doi.org/10.1007/s11063-025-11722-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The graph convolutional network (GCN) has demonstrated effectiveness well in the text classification task. However, inadequate handling of uncertainty in prediction results exists due to the under-utilization of text features extracted by a single deep-learning model. To mitigate the potential risk of text misclassification, we proposed an enhanced GCN model for text classification based on three-way decision, incorporating shadowed set theory (3WD-GCN). In this approach, we first employ GCN as a primary classifier to handle textual data, obtaining the initial predicted results and the membership matrix. Depending on the idea of processing in threes, these results were divided into acceptance, rejection, and subdivision regions, respectively. For the subdivision region, we introduce SVM as a secondary classifier to process objects with poor conformability and distinguishability, which can reduce the uncertainty of prediction results and improve the overall performance of text classification. A series of experiments based on several benchmark datasets extensively evaluated the proposed method. The results demonstrate the validity of the approach and show a significant improvement over popular baseline text classification models.},
  archive      = {J_NPL},
  author       = {Jiang, Chunmao and Yang, Ziping and Yao, Jingtao},
  doi          = {10.1007/s11063-025-11722-4},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1--26},
  shortjournal = {Neural Process. Lett.},
  title        = {Three-way decision enhanced graph convolutional networks for text classification},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SFA: Efficient attention mechanism for superior CNN performance. <em>NPL</em>, <em>57</em>(2), 1--21. (<a href='https://doi.org/10.1007/s11063-025-11748-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention mechanisms are critical tools for enhancing the performance of convolutional neural networks (CNNs), focusing on spatial and channel dimensions of feature maps, known as spatial attention and channel attention, respectively. While many advanced attention methods combine these dimensions to improve performance, particularly in downstream computer vision tasks, such methods often introduce significant computational overhead or fail to effectively capture long-range spatial dependencies alongside channel attention. To address these challenges, this paper proposes the sequential fusion attention (SFA) method, which introduces a complementary fusion strategy to integrate spatial and channel attention. Spatial attention leverages strip pooling to model long-range dependencies, while channel attention employs dynamic encoding to refine features. By utilizing a grouped processing approach, the SFA module achieves an optimal balance between computational efficiency and representation power. Extensive experiments on benchmark datasets demonstrate that SFA consistently outperforms state-of-the-art attention mechanisms, delivering competitive accuracy in image classification, object detection, and semantic segmentation tasks while maintaining reduced model complexity. This work underscores the potential of lightweight attention mechanisms in modern computer vision and paves the way for further innovations in resource-efficient neural network design. Our code is publicly available at the following URL: https://github.com/Xuwei86/SFA},
  archive      = {J_NPL},
  author       = {Xu, Wei and Wan, Yi and Zhao, Dong},
  doi          = {10.1007/s11063-025-11748-8},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1--21},
  shortjournal = {Neural Process. Lett.},
  title        = {SFA: Efficient attention mechanism for superior CNN performance},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predict-and-optimize techniques for data-driven optimization problems: A review. <em>NPL</em>, <em>57</em>(2), 1--28. (<a href='https://doi.org/10.1007/s11063-025-11746-w'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning predictive models rely on data to make predictions for new input data. However, accurate predictions are not always the end goal; practitioners often aim to make informed decisions through optimization problems (OPs) based on these predictions. While the idea that better predictions lead to better decisions was widely accepted, the latest literature highlights that even small inaccuracies in predictions can lead to poor decisions depending on the structure of the OP. Therefore, recent research has been focused on end-to-end learning approaches that directly improve decision quality without considering prediction accuracy when solving data-driven OPs. Some of these end-to-end learning approaches are mainly called “predict-and-optimize” (PaO), and they aim to learn a predictor based on the quality of the downstream task decisions by incorporating mathematical programming into the learning process. This literature review discusses the variations of and approaches to PaO problems by proposing a unified notation and a taxonomy for them. Throughout the paper, we aim to provide a valuable roadmap for researchers and practitioners in the field, guiding them to choose data-driven methods to solve their decision problems effectively.},
  archive      = {J_NPL},
  author       = {Anis Lahoud, Alan and Khan, Ahmad Saeed and Schaffernicht, Erik and Trincavelli, Marco and Stork, Johannes Andreas},
  doi          = {10.1007/s11063-025-11746-w},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1--28},
  shortjournal = {Neural Process. Lett.},
  title        = {Predict-and-optimize techniques for data-driven optimization problems: A review},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-domain few-shot learning based on data corruption and dual attention mechanism. <em>NPL</em>, <em>57</em>(2), 1--21. (<a href='https://doi.org/10.1007/s11063-025-11755-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In few-shot learning, the model must first be trained using the same type of dataset, and its effectiveness may be compromised when identifying classes from different datasets. Therefore, recent research has proposed cross-domain few-shot learning, which aims to train a single-network model that can be applied across most datasets. Cross-domain few-shot learning typically involves two stages during training: (1) pre-training and (2) meta-training. In the pre-training stage, a feature extractor is trained using traditional supervised learning to extract features. In the meta-training stage, a classifier is trained using few-shot learning methods, whereby meta-learning algorithms classify the features extracted by the feature extractor. In this study, a dual attention mechanism that incorporates channel and spatial attention is introduced into the feature extractor in the pre-training stage, to enhance feature extraction capabilities. In the meta-training stage, samples obtained from Fourier-transform-based image corruption algorithms are introduced. The transformation algorithm scales the phase and amplitude of the Fourier transform output to change the texture and semantics of the image, allowing the classifier to learn more diverse images and improve its generalization ability. Finally, during the meta-training process, the prediction losses of the images before and after corruption are simultaneously calculated to maintain consistency in the prediction results and effectively mitigating the risk of overfitting. The experimental results demonstrate that the proposed method achieves better performance on the majority of the eight testing datasets, effectively reducing overfitting during training.},
  archive      = {J_NPL},
  author       = {Lee, Shih-Hsiung and Lin, Hsing-Yu and Yang, Chu-Sing},
  doi          = {10.1007/s11063-025-11755-9},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1--21},
  shortjournal = {Neural Process. Lett.},
  title        = {Cross-domain few-shot learning based on data corruption and dual attention mechanism},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HGBL: A fine granular hierarchical multi-label text classification model. <em>NPL</em>, <em>57</em>(1), 1--28. (<a href='https://doi.org/10.1007/s11063-024-11713-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical multi-label text classification is vital for natural language processing (NLP). However, existing research rarely makes full use of the interaction between labels and text features that are crucial to hierarchical multi-label text classification. To address this issue, a novel model named hierarchy-guided BiLSTM guided contrastive learning classification (HGBL) is proposed, which successfully enhances the interaction between labels and text features by incorporating global context and embedding the idea of contrastive learning into this model. During modeling, Graphormer is adopted to model the dependencies between labels, and the bidirectional recurrent network (BiLSTM) is used to integrate global context including label features. Afterwards, the contrastive learning module embeds hierarchical awareness into the fine-tuned bidirectional encoder representations from transformers (BERT) by training the value of the loss. Experimental results on NYT, WOS and RCV1-V2 datasets show that HGBL exhibits significant competitive advantages compared with 19 competitors in terms of several indicators and can be used effectively for hierarchical multi-label text classification problems.},
  archive      = {J_NPL},
  author       = {Zhang, Chaoqun and Dai, Linlin and Liu, Chengxing and Zhang, Longhao},
  doi          = {10.1007/s11063-024-11713-x},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--28},
  shortjournal = {Neural Process. Lett.},
  title        = {HGBL: A fine granular hierarchical multi-label text classification model},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual learning in medicine: A systematic literature review. <em>NPL</em>, <em>57</em>(1), 1--21. (<a href='https://doi.org/10.1007/s11063-024-11709-7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual Learning (CL) is a novel AI paradigm in which tasks and data are made available over time; thus, the trained model is computed on the basis of a stream of data. CL-based approaches are able to learn new skills and knowledge without forgetting the previous ones, with no guaranteed access to previously encountered data, and mitigating the so-called “catastrophic forgetting” phenomenon. Interestingly, by making AI systems able to learn and improve over time without the need for large amounts of new data or computational resources, CL can help at reducing the impact of computationally-expensive and energy-intensive activities; hence, CL can play a key role in the path towards more green AIs, enabling more efficient and sustainable uses of resources. In this work, we describe different methods proposed in the literature to solve CL tasks; we survey different applications, highlighting strengths and weaknesses, with a particular focus on the biomedical context. Furthermore, we discuss how to make the methods more robust and suitable for a wider range of applications.},
  archive      = {J_NPL},
  author       = {Bruno, Pierangela and Quarta, Alessandro and Calimeri, Francesco},
  doi          = {10.1007/s11063-024-11709-7},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--21},
  shortjournal = {Neural Process. Lett.},
  title        = {Continual learning in medicine: A systematic literature review},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LPM-net: A data-driven resource-efficient predictive motion planner for mobile robots. <em>NPL</em>, <em>57</em>(1), 1--15. (<a href='https://doi.org/10.1007/s11063-024-11671-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A data-driven predictive motion planner for mobile robots, referred to as LPM-Net, has been proposed in this paper. Conventional predictive motion planners are computationally expensive, often resulting in insufficient throughput on mobile robot hardware. LPM-Net is an imitation learning-assisted local predictive non-holonomic motion planner that is capable of learning from conventional motion planners regarded as paradigm models and replicating their behavior while satisfying the same kinodynamic constraints. In addition, LPM-Net is compatible with GPU and TPU hardware, allowing for faster and more efficient processing. LPM-Net uses convolutional and recurrent long short-term memory deep neural networks to predict steering commands. This has improved computational efficiency which allows autonomous vehicles to be equipped with more cost-effective computers. In the present study, LPM-Net was tuned to mimic the behavior of a model predictive controller paradigm model. Measurements in this study demonstrate that the proposed mimic planner, LPM-Net, consumes approximately half the processing power of the conventional predictive planner, albeit with a slight increase in hesitation when reaching goals.},
  archive      = {J_NPL},
  author       = {Amirhosseini, Fakhreddin and Nilforoushan, Zahra and Leili Mirtaheri, Seyedeh},
  doi          = {10.1007/s11063-024-11671-4},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--15},
  shortjournal = {Neural Process. Lett.},
  title        = {LPM-net: A data-driven resource-efficient predictive motion planner for mobile robots},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LieCConv: An image classification algorithm based on lie group convolutional neural network. <em>NPL</em>, <em>57</em>(1), 1--21. (<a href='https://doi.org/10.1007/s11063-024-11691-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Lie group convolutional neural networks (LG-CNNs), the calculation and storage of Lie group distances have quadratic space complexity. In order to improve the memory utilization efficiency of LG-CNNs, a novel Lie group convolutional neural network called LieCConv is proposed. LieCConv utilizes an innovative sampling algorithm and a linear space complexity calculation and storage approach for Lie group distances, substantially enhancing network memory efficiency. Firstly, LieCConv employs a novel sampling algorithm called array-neighborhood sampling (ANS) in the downsampling stage. ANS only requires neighborhood information to obtain an excellent sample set with a low threshold of use. The sample set generated by ANS reflects the distribution of the original set. Then, LieCConv adopts a batch calculation and storage scheme for Lie group distances, which effectively declines the space complexity of calculating and storing Lie group distances from quadratic complexity to linear complexity, reducing the memory consumption during training. Finally, the contrast between ANS and farthest point sampling was presented, demonstrating that ANS better captures the distribution characteristics of the original dataset. The memory usage of LieCConv and LieConv was compared, revealing that LieCConv reduces the memory usage for calculating and storing Lie group distances to less than 500 MB. And the performance of LieCConv was evaluated on RotMNIST, RotFashionMNIST and TT100K, validating that LieCConv is universal and effective.},
  archive      = {J_NPL},
  author       = {Zhang, Yunjie and Luo, Xizhao and Tao, Chongben and Qin, Bo and Yang, Anjia and Cao, Feng},
  doi          = {10.1007/s11063-024-11691-0},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--21},
  shortjournal = {Neural Process. Lett.},
  title        = {LieCConv: An image classification algorithm based on lie group convolutional neural network},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Harborfront anomaly detection. <em>NPL</em>, <em>57</em>(1), 1--16. (<a href='https://doi.org/10.1007/s11063-024-11696-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Creating high-quality datasets for the task of video anomaly detection is challenging due to a subjective anomaly definition and the rarity of anomalies, which oust the possibility of obtaining statistically significant data. This results in datasets where anomalies are placed in a single category, and are often considered less relevant from a security standpoint. Instead, we propose to create video anomaly datasets based on a framework utilizing object annotations to ease the annotation process and allow users to decide on the anomaly definition. Furthermore, this allows for a fine-grained evaluation w.r.t. anomaly types, which represents a novelty in the area of video anomaly detection. The framework is demonstrated using the existing thermal long-term drift (LTD) dataset, identifying and evaluating five different types of anomalies (appearance, motion, localization, density, and tampering) on six test sets. State-of-the-art anomaly detection methods are evaluated and found to underperform on the thermal anomaly detection dataset, which emphasizes a need for an adjustable anomaly definition in order to produce better anomaly datasets and models that generalize towards practical use. We share the code of the proposed framework to extract anomaly types along with object annotations for the LTD dataset at https://github.com/jagob/harborfront-vad .},
  archive      = {J_NPL},
  author       = {Dueholm, Jacob V. and Siemon, Mia and Ionescu, Radu T. and Moeslund, Thomas B. and Nasrollahi, Kamal},
  doi          = {10.1007/s11063-024-11696-9},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--16},
  shortjournal = {Neural Process. Lett.},
  title        = {Harborfront anomaly detection},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring dual coupledness for effective pruning in object detection. <em>NPL</em>, <em>57</em>(1), 1--19. (<a href='https://doi.org/10.1007/s11063-024-11697-8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pruning offers an efficient approach to compressing models deployed on resource-constrained devices. In this paper, we introduce a novel method called Dual-Coupledness Object Detection Pruning (DCODP), specifically designed for object detection models. Taking into account the complexity of model coupling, our algorithm utilizes a depth-first search approach to identify interlayer coupling within the model. It then groups sublayers with the same parent layer together. Filters corresponding to feature maps with strong coupling are pruned within the layer, and the same pruning operation is applied to the corresponding indices in other coupled layers. In order to prove the validity of our method, extensive experiments are conducted on PASCAL VOC2007, PASCAL VOC2012 and MS COCO2017. The results show that our DCODP achieves a significant reduction of 50% in parameters and an average of more than 70% impressive score.},
  archive      = {J_NPL},
  author       = {Xiaohui, Guan and Wenzhuo, Huang and Yaguan, Qian and Xinxin, Sun},
  doi          = {10.1007/s11063-024-11697-8},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--19},
  shortjournal = {Neural Process. Lett.},
  title        = {Exploring dual coupledness for effective pruning in object detection},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed-time synchronization of Caputo/Conformable fractional-order inertial cohen-grossberg neural networks via event-triggered One/Two-phase hybrid impulsive control. <em>NPL</em>, <em>57</em>(1), 1--57. (<a href='https://doi.org/10.1007/s11063-024-11703-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the fixed-time synchronization (FXS) problems of Caputo/conformable fractional-order inertial Cohen-Grossberg neural networks (FOICGNNs) by one/two-phase hybrid impulsive control (HIC) through event-triggered update strategies. By utilizing the properties of fractional calculus, several novel inequalities regarding the fixed-time convergence of hybrid impulsive systems (HIS) are obtained. We especially discuss and compare the cases of Caputo and conformable fractional order to gain deep insight into fractional calculus. By applying the Lyapunov stability theory, two hybrid controllers, which consist of event-triggered continuous controllers and impulsive controllers, are designed to realize the FXS of FOICGNNs. It’s worth pointing out that, we unprecedentedly study and compare the differences of the one-phase HIC and two-phase HIC, where a novel nonlinear impulsive controller is proposed and designed to obtain fixed-time convergence in the impulsive control phase. In addition, the exclusion of Zeno behavior is proved for the designed event-triggered strategy. Finally, several numerical examples are provided to illustrate the feasibility of the proposed control approach and the correctness of the theoretical results.},
  archive      = {J_NPL},
  author       = {Xiong, Yao and Li, Yesheng and Lv, Haifei and Wu, Wei and Xie, Songhua and Chen, Mengwei and Hu, Changkui and Li, Min},
  doi          = {10.1007/s11063-024-11703-z},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--57},
  shortjournal = {Neural Process. Lett.},
  title        = {Fixed-time synchronization of Caputo/Conformable fractional-order inertial cohen-grossberg neural networks via event-triggered One/Two-phase hybrid impulsive control},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Network clustering for multi-task learning. <em>NPL</em>, <em>57</em>(1), 1--12. (<a href='https://doi.org/10.1007/s11063-024-11712-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Multi-Task Learning (MTL) technique has been widely studied by worldwide researchers. The majority of current MTL studies adopt the hard parameter sharing structure, where hard layers tend to learn general representations over all tasks and specific layers are prone to learn specific representations for each task. Since the specific layers directly follow the hard layers, the MTL model needs to estimate this direct change (from general to specific) as well. To alleviate this problem, we introduce the novel cluster layer, which groups tasks into clusters during training procedures. In a cluster layer, the tasks in the same cluster are further required to share the same network. By this way, the cluster layer produces the general presentation for the same cluster, while produces relatively specific presentations for different clusters. The cluster layers are used as transitions between the hard layers and the specific layers. Thus, the MTL model can learn general representations to specific representations gradually. We evaluate our model with MTL document classification, and the results demonstrate the cluster layer is quite efficient in MTL.},
  archive      = {J_NPL},
  author       = {Mu, Zhiying and Gao, Dehong and Guo, Sensen},
  doi          = {10.1007/s11063-024-11712-y},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--12},
  shortjournal = {Neural Process. Lett.},
  title        = {Network clustering for multi-task learning},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Jointly learning type-aware relations and inter-aspect with graph convolutional networks for aspect sentiment analysis. <em>NPL</em>, <em>57</em>(1), 1--17. (<a href='https://doi.org/10.1007/s11063-024-11715-9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel approach for aspect-level sentiment analysis by leveraging the relationships between dependent types and aspects. The proposed method involves simplifying the type-aware graph convolutional network and designing a graph convolution module specifically for extracting relations between aspect words. The process begins with constructing an ordinary dependency graph for each sentence using a dependency tree. This graph is then refined by considering syntactic dependencies between context words and aspect-specific words, resulting in an aspect-focused graph. The aspect-focused graph, along with the corresponding embedding matrices, is fed into the aspect-focused GCN to capture the essential aspects and context words. Moreover, an inter-aspect GCN is employed to extract the dependencies between aspect words and other aspect words, utilizing the representations learned by the focused aspect GCN based on the inter-aspect graph. The L-layer of the GCN incorporates a bidirectional attentional mechanism to extract interrelationships, thus enhancing sentiment polarity judgment. Through interactive learning of aspect-specific affective features, the model acquires an understanding of the relationships between important text and aspect words, as well as the relationships among aspect words. Experimental results on five benchmark datasets demonstrate the superior performance of our proposed method compared to state-of-the-art approaches, exhibiting a significant improvement over the regular GCN model.},
  archive      = {J_NPL},
  author       = {Zong, Liansong and Hu, Dongfeng and Gui, Qingchi and Zhang, Pengfei and Wang, Jie},
  doi          = {10.1007/s11063-024-11715-9},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--17},
  shortjournal = {Neural Process. Lett.},
  title        = {Jointly learning type-aware relations and inter-aspect with graph convolutional networks for aspect sentiment analysis},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic evaluation of english translation based on multi-granularity interaction fusion. <em>NPL</em>, <em>57</em>(1), 1--17. (<a href='https://doi.org/10.1007/s11063-025-11716-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The latest neural machine translation automatic evaluation method uses pre-trained context word vectors to extract semantic features and directly concatenates them into the neural network to predict translation quality. However, the direct operation can easily lead to a lack of interaction between features, and the layer-by-layer prediction is prone to losing fine-grained matching information. To address these issues, we propose a multi-granularity interactive fusion English translation automatic evaluation, which introduces middle and late information fusion methods. First, we use a bilinear attention distribution to capture high-order cross language feature interactions. By stacking multiple high-order interaction blocks and equipping them with an index linear unit without parameters for middle fusion in a parameter-free manner. Second, we use fine-grained accurate matching sentence shift distance and sentence-level cosine similarity for late fusion. The experimental results on the WMT’21 Metrics Task benchmark dataset show that the proposed method can effectively improve its correlation with human evaluation and achieve comparable performance with the best participating system.},
  archive      = {J_NPL},
  author       = {Chen, Xibo and Yang, Yonghe and Hu, Haize},
  doi          = {10.1007/s11063-025-11716-2},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--17},
  shortjournal = {Neural Process. Lett.},
  title        = {Automatic evaluation of english translation based on multi-granularity interaction fusion},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature enhancement-based few-shot bearing surface defect image classification method. <em>NPL</em>, <em>57</em>(1), 1--24. (<a href='https://doi.org/10.1007/s11063-025-11720-6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of intelligent bearing surface defect classification based on deep neural networks remains challenging in real factories, due to the scarcity of defect samples. Under real-working conditions, with less training samples, the paper proposes a few-shot bearing defect image classification network which can recognize different bearing surface defects image, including notch, reddish rust, scratching, incising, conformity, pitting and mill scale. Based on general metric learning neural network framework, a local feature extraction layer is designed, which calculates the auto-correlation vector of global feature in a sliding region to enhance detail features. Additionally, a similar feature attention module emphasizes the the regions of similarity between the query set and the class prototype center to overcome the influence of background noise on classification. To validate the effectiveness of the proposed network, comparative experiments were conducted using the benchmark dataset miniImageNet, achieving classification accuracies of 59% in the 5-way 1-shot setting and 76% in the 5-way 5-shot setting respectively. Furthermore, to assess its performance in a real-factory condition, a self-made dataset of bearing defects from a factory was employed. The proposed network achieved a remarkable classification accuracy of 88% in the 5-way 5-shot setting. These experimental results confirm the practical application value of our few-shot bearing surface defect image classification network, demonstrating its ability to accurately recognize various bearing defects with limited training samples.},
  archive      = {J_NPL},
  author       = {Cang, Yan and Zhang, Xuanshang},
  doi          = {10.1007/s11063-025-11720-6},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--24},
  shortjournal = {Neural Process. Lett.},
  title        = {Feature enhancement-based few-shot bearing surface defect image classification method},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-dimensional feature interaction for conversational aspect-based quadruple sentiment analysis. <em>NPL</em>, <em>57</em>(1), 1--19. (<a href='https://doi.org/10.1007/s11063-025-11721-5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational aspect-level quadruple sentiment analysis (DiaASQ) is proposed as a new task that aims to extract target-aspect-opinion-sentiment quadruples in dialogues. However, this task faces the problem of complex context matching and multiple utterance feature modeling, which creates difficulties in extracting quadruples from multiple intersecting utterances. To address this problem, this paper proposes a Multi-dimensional Dialogue Feature Interaction (MDFI) approach. This method models dialogue features through an interactive network structure to capture interactions between utterance features. The approach adds two layers of ResNet to achieve deep association fusion based on multi-head self-attention. It superimposes the associated features of replies, speakers, and dialogue threads layer by layer and enhances the capability of conversation representation through linear augmentation. Our model outperforms the DiaASQ benchmark model in global utterance, intra-utterance, and cross-utterance quadruple extraction. In particular, the ZH dataset shows an improvement of 7.42 in global utterance and 9.66 in cross-utterance.},
  archive      = {J_NPL},
  author       = {Zhao, Zhongyang and Zhang, Long and Zheng, Qiusheng and Zhang, Junshuai},
  doi          = {10.1007/s11063-025-11721-5},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--19},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-dimensional feature interaction for conversational aspect-based quadruple sentiment analysis},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Value creation for healthcare ecosystems through artificial intelligence applied to physician-to-physician communication: A systematic review. <em>NPL</em>, <em>57</em>(1), 1--23. (<a href='https://doi.org/10.1007/s11063-025-11725-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study reviews the role of artificial intelligence (AI) in enhancing healthcare through an analysis of physician-to-physician communication. It seeks to identify the best practices for extracting value from professional medical chats (PMCs) and assess the impact of AI on patient outcomes and healthcare systems, emphasizing the integration of ethical and responsible AI practices. We conducted an extensive systematic literature review using the Web of Science Core Collection. Searches encompassed English-language articles published between January 2019 and July 2023 using keywords related to AI, machine learning, natural language processing, and physician communication. Of the 247 articles screened, 13 met the inclusion criteria given their in-depth analysis of AI in healthcare communication, methodological soundness, and relevance to clinical outcomes. The review provides insights into interprofessional communication dynamics, the advancement of NLP and deep learning in medical dialogues, and strategies for effective human-machine collaboration. Ethical considerations and the need for transparency in AI applications are key to these central findings. This study highlights the untapped potential of physician-generated real-world data in creating value for healthcare ecosystems. It advocates for a multidisciplinary strategy encompassing communication, education, and collaboration to advance AI in healthcare responsibly. Moreover, it suggests that by combining existing techniques in the AI discipline, including neural networks, generative AI, and genetic algorithms, as well as keeping a “physician in the loop” when building AI systems, we can have a significant impact on healthcare delivery and medical research.},
  archive      = {J_NPL},
  author       = {Rubinstein, Beny and Matos, Sergio},
  doi          = {10.1007/s11063-025-11725-1},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--23},
  shortjournal = {Neural Process. Lett.},
  title        = {Value creation for healthcare ecosystems through artificial intelligence applied to physician-to-physician communication: A systematic review},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AUMEs: AU detection-based dual-stream multi-task 3DCNN for micro-expression recognition. <em>NPL</em>, <em>57</em>(1), 1--24. (<a href='https://doi.org/10.1007/s11063-025-11726-0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro-expressions are brief, involuntary facial movements that can reveal real emotions. However, their short duration and low intensity pose a challenge for feature extraction and learning of neural networks. To overcome this challenge, we propose AUMEs, a 3DCNN-based multi-task learning framework that utilizes deep learning-based Lagrangian motion magnification and optical flow computation methods to enhance spatio-temporal features of micro-expressions, thus solving the problem of weak micro-expression motion intensity. AUMEs also use AU detection as a parallel task to improve the accuracy of micro-expression recognition by transferring knowledge from the AU detection task, and focal loss is utilized in model training to handle category imbalance in the micro-expression dataset. AUMEs achieve competitive results compared with existing SOTA methods on the CASMEII and SAMM datasets, achieving accuracy (Acc.) of 81.05% and 79.85%, UF1 score reaches 0.8880 and 0.7450 on the five-category task, and on the three-category UAR reached 89.02% and 75.86% and 0.8880 and 0.7450 for UF1. Furthermore, in both dataset analyses, the multi-task approach surpassed the single-task method across both the five-category and three-category classifications.},
  archive      = {J_NPL},
  author       = {Shi, Hu and Wang, Yanxia and Wang , Renjie and Liu, Dan},
  doi          = {10.1007/s11063-025-11726-0},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--24},
  shortjournal = {Neural Process. Lett.},
  title        = {AUMEs: AU detection-based dual-stream multi-task 3DCNN for micro-expression recognition},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot object detection based on global domain adaptation strategy. <em>NPL</em>, <em>57</em>(1), 1--16. (<a href='https://doi.org/10.1007/s11063-025-11727-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming to detect novel objects from only a few annotated samples, few-shot object detection (FSOD) has undergone remarkable development. Previous works rarely pay attention to the perspective of gradient propagation to optimize existing methods, therefore failing to make full use of information for novel objects in gradient propagation. We propose a method to solve this problem based on two-stage fine-tuning. A domain adaptation module with multi-constraints is used to promote the spread of gradients, a classification promotion network is used to improve the effect of classification, and a multi-path mask head is added to enrich RoI features. Experiments on PASCAL VOC and COCO datasets show that our model significantly raises the performance compared with previous methods (up to 1–5 $$\%$$ in average).},
  archive      = {J_NPL},
  author       = {Gong, Xiaolin and Cai, Youpeng and Wang, Jian and Liu, Daqing and Ma, Yongtao},
  doi          = {10.1007/s11063-025-11727-z},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--16},
  shortjournal = {Neural Process. Lett.},
  title        = {Few-shot object detection based on global domain adaptation strategy},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GrapHisto: A robust representation of graph-structured data for graph convolutional networks. <em>NPL</em>, <em>57</em>(1), 1--27. (<a href='https://doi.org/10.1007/s11063-025-11728-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning from graphs is an established branch of AI research motivated by the relevance of applications that involve graph-structured data. The most popular instance is the graph neural network (GNN). On the other hand, due to the promising results of deep learning models in the most diverse fields of application, several efforts have been made to replicate these successes when dealing with graphical data. A prominent specimen of the kind is the graph convolutional network (GCN). Along these lines, the paper propose a novel approach for processing graphs that exploits the capabilities of convolutional neural networks (CNNs) to learn from images. This is achieved by means of a new representation of graphs, called GrapHisto, that portrays graphs in the form of characteristic “pictures”. The GrapHisto is in the form of graph-specific, unique tensors encapsulating the graph topology and its features (i.e., the labels associated with vertexes and edges). This representation is fed to a CNN, and the resulting machine is termed GrapHisto-CNN. The paper provides some theoretical investigations of the properties of the approach, and proposes solutions to some practical issues. An experimental evaluation of the GrapHisto-CNN is reported, revolving around two setups: classification of synthetically-generated graphs, and molecule classification form the dataset QM9. The results show that the approach is effective and robust, and that it compares favorably with GNNs and GCNs.},
  archive      = {J_NPL},
  author       = {Benini, Marco and Bongini, Pietro and Trentin, Edmondo},
  doi          = {10.1007/s11063-025-11728-y},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--27},
  shortjournal = {Neural Process. Lett.},
  title        = {GrapHisto: A robust representation of graph-structured data for graph convolutional networks},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ECTTLNER: An effective cross-task transferring learning method for low-resource named entity recognition. <em>NPL</em>, <em>57</em>(1), 1--18. (<a href='https://doi.org/10.1007/s11063-025-11729-x'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition is a fundamental task in natural language processing that significantly impacts the performance of its downstream tasks. Cross-task transfer learning methods are more naturally suited for low-resource named entity recognition compared to cross-language and cross-domain transfer learning methods. Existing cross-task transfer learning methods improve the performance of the low-resource named entity recognition by leveraging relevant information from other auxiliary tasks, such as sentence-level and token-level information. However, these methods do not fully exploit token-level information of entities, leaving room for improvement in low-resource named entity recognition. To futher improve the performance of the low-resource named entity recognition, this paper proposes a simple and effective cross-task transfer learning method called ECTTLNER, which introduces Sentence Contains Entities, Sentence Entity Number, Token Is Entity, and Token Boundary Label prediction tasks into named entity recognition and performs multi-task learning together with the main sequence labeling task. Experimental results on three NER datasets demonstrate that ECTTLNER outperforms a set of state-of-the-art baseline models, and achieves more than a 2.6% improvement in F1-score over these baseline models, particularly in low-resource scenarios.},
  archive      = {J_NPL},
  author       = {Xu, Yiwu and Chen, Yun},
  doi          = {10.1007/s11063-025-11729-x},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--18},
  shortjournal = {Neural Process. Lett.},
  title        = {ECTTLNER: An effective cross-task transferring learning method for low-resource named entity recognition},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Power analysis attacks on NVM crossbar-based neuromorphic systems. <em>NPL</em>, <em>57</em>(1), 1--17. (<a href='https://doi.org/10.1007/s11063-025-11730-4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new adversarial attack strategy against neuromorphic systems using analysis of power consumption. Specifically, we show that neuromorphic designs based on non-volatile memory crossbars can leak important information about loss sensitivity in their power profile. Adversaries can use this information to craft evasion attacks even if they don’t know the dataset that the model was trained on. In our experiments, we show that these types of attacks are effective against both single-layer and multilayer neuromorphic implementations of neural networks, and they can be made query-efficient through Bayesian optimization. We also provide theoretical insights into the relationship between the loss sensitivity and the power consumption measurements, showing that, for single-layer networks, the correlation coefficient of these two metrics scales inversely with the square root of the input size. Finally, this paper proposes that low bitwidth quantization could be an effective defense strategy against the class of attacks discussed herein.},
  archive      = {J_NPL},
  author       = {Merkel, Cory and Su, Allen},
  doi          = {10.1007/s11063-025-11730-4},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--17},
  shortjournal = {Neural Process. Lett.},
  title        = {Power analysis attacks on NVM crossbar-based neuromorphic systems},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recent emerging techniques in explainable artificial intelligence to enhance the interpretable and understanding of AI models for human. <em>NPL</em>, <em>57</em>(1), 1--32. (<a href='https://doi.org/10.1007/s11063-025-11732-2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in Explainable Artificial Intelligence (XAI) aim to bridge the gap between complex artificial intelligence (AI) models and human understanding, fostering trust and usability in AI systems. However, challenges persist in comprehensively interpreting these models, hindering their widespread adoption. This study addresses these challenges by exploring recently emerging techniques in XAI. The primary problem addressed is the lack of transparency and interpretability in AI models to humanity for institution-wide use, which undermines user trust and inhibits their integration into critical decision-making processes. Through an in-depth review, this study identifies the objectives of enhancing the interpretability of AI models and improving human understanding of their decision-making processes. Various methodological approaches, including post-hoc explanations, model transparency methods, and interactive visualization techniques, are investigated to elucidate AI model behaviours. We further present techniques and methods to make AI models more interpretable and understandable to humans including their strengths and weaknesses to demonstrate promising advancements in model interpretability, facilitating better comprehension of complex AI systems by humans. In addition, we provide the application of XAI in local use cases. Challenges, solutions, and open research directions were highlighted to clarify these compelling XAI utilization challenges. The implications of this research are profound, as enhanced interpretability fosters trust in AI systems across diverse applications, from healthcare to finance. By empowering users to understand and scrutinize AI decisions, these techniques pave the way for more responsible and accountable AI deployment.},
  archive      = {J_NPL},
  author       = {Mathew, Daniel Enemona and Ebem, Deborah Uzoamaka and Ikegwu, Anayo Chukwu and Ukeoma, Pamela Eberechukwu and Dibiaezue, Ngozi Fidelia},
  doi          = {10.1007/s11063-025-11732-2},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--32},
  shortjournal = {Neural Process. Lett.},
  title        = {Recent emerging techniques in explainable artificial intelligence to enhance the interpretable and understanding of AI models for human},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Master–Slave finite-time synchronization of chaotic fractional-order neural networks under hybrid sampled-data control: An LMI approach. <em>NPL</em>, <em>57</em>(1), 1--16. (<a href='https://doi.org/10.1007/s11063-025-11733-1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a hybrid controller with a sampled data control is investigated to achieve finite-time master–slave synchronization of delayed fractional-order neural networks (DFONNs). A Lyapunov-Krasovskii functional is constructed to obtain the sufficient conditions that incorporate delay information. For the first time, the asymptotic stability of the error system is guaranteed in a finite-time using the inequality technique and a sampled-data hybrid controller. The obtained conditions are expressed via linear matrix inequality. Notably, the proposed approach outperforms existing methods, demonstrating improved results in a comparative analysis. An explicit formula is utilized to calculate the settling time, which is significantly influenced by the fractional order $$0<\beta \le 1$$ . The superior performance of the proposed control method is evident, showcasing its effectiveness through numerical simulations and addressing the synchronization problem in DFONNs.},
  archive      = {J_NPL},
  author       = {Kiruthika, R. and Manivannan, A.},
  doi          = {10.1007/s11063-025-11733-1},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--16},
  shortjournal = {Neural Process. Lett.},
  title        = {Master–Slave finite-time synchronization of chaotic fractional-order neural networks under hybrid sampled-data control: An LMI approach},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parkinsons detection from gait time series classification using modified metaheuristic optimized long short term memory. <em>NPL</em>, <em>57</em>(1), 1--29. (<a href='https://doi.org/10.1007/s11063-025-11735-z'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurodegenerative conditions are defined by the progressive deterioration and death of nerve cells in the core neural system. Most neurodegenerative conditions are not curable. While there have been significant improvements and techniques used to treat these diseases early diagnosis continues to play a crucial role in the entire approach. Conditions are often diagnosed only once they start negatively impacting the daily life of those affected. Early detection and timely preventative treatment can help improve patient subjective well-being. This study examines the application of a non-invasive gait analysis technique for the detection of Parkinson’s disease. Publicly available data collected from patients suffering from Parkinson’s along with control groups is utilized and combined with long-short-term neural networks to construct models capable of detecting signs on Parkinson’s disorder. However, because of the significant reliance of models on appropriate parameters selection, metaheuristic algorithms are used to fine tune the selection process, and a modified variation of the strongly founded PSO algorithm was proposed. Several contemporary optimizers are compared based on their ability to optimize model performance. This suggested approach achieved the superior outcomes with an accuracy of 89.92%. The constructed models have been evaluated to determine feature importance using game theory based methods.},
  archive      = {J_NPL},
  author       = {Markovic, Filip and Jovanovic, Luka and Spalevic, Petar and Kaljevic, Jelena and Zivkovic, Miodrag and Simic, Vladimir and Shaker, Hotefa and Bacanin, Nebojsa},
  doi          = {10.1007/s11063-025-11735-z},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1--29},
  shortjournal = {Neural Process. Lett.},
  title        = {Parkinsons detection from gait time series classification using modified metaheuristic optimized long short term memory},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: LPM-net: A data-driven resource-efficient predictive motion planner for mobile robots. <em>NPL</em>, <em>57</em>(1), 1. (<a href='https://doi.org/10.1007/s11063-025-11736-y'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NPL},
  author       = {Amirhosseini, Fakhreddin and Nilforoushan, Zahra and Mirtaheri, Seyedeh Leili},
  doi          = {10.1007/s11063-025-11736-y},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1},
  shortjournal = {Neural Process. Lett.},
  title        = {Correction: LPM-net: A data-driven resource-efficient predictive motion planner for mobile robots},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
