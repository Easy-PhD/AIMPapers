<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CAAITIT</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="caaitit">CAAITIT - 98</h2>
<ul>
<li><details>
<summary>
(2025). Exploring a hybrid convolutional framework for camouflage target classification in land-based hyperspectral images. <em>CAAITIT</em>, <em>10</em>(5), 1559--1572. (<a href='https://doi.org/10.1049/cit2.70051'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, camouflage technology has evolved from single-spectral-band applications to multifunctional and multispectral implementations. Hyperspectral imaging has emerged as a powerful technique for target identification due to its capacity to capture both spectral and spatial information. The advancement of imaging spectroscopy technology has significantly enhanced reconnaissance capabilities, offering substantial advantages in camouflaged target classification and detection. However, the increasing spectral similarity between camouflaged targets and their backgrounds has significantly compromised detection performance in specific scenarios. Conventional feature extraction methods are often limited to single, shallow spectral or spatial features, failing to extract deep features and consequently yielding suboptimal classification accuracy. To address these limitations, this study proposes an innovative 3D-2D convolutional neural networks architecture incorporating depthwise separable convolution (DSC) and attention mechanisms (AM). The framework first applies dimensionality reduction to hyperspectral images and extracts preliminary spectral-spatial features. It then employs an alternating combination of 3D and 2D convolutions for deep feature extraction. For target classification, the LogSoftmax function is implemented. The integration of depthwise separable convolution not only enhances classification accuracy but also substantially reduces model parameters. Furthermore, the attention mechanisms significantly improve the network's ability to represent multidimensional features. Extensive experiments were conducted on a custom land-based hyperspectral image dataset. The results demonstrate remarkable classification accuracy: 98.74% for grassland camouflage, 99.13% for dead leaf camouflage and 98.94% for wild grass camouflage. Comparative analysis shows that the proposed framework is outstanding in terms of classification accuracy and robustness for camouflage target classification.},
  archive      = {J_CAAITIT},
  author       = {Jiale Zhao and Dan Fang and Jianghu Deng and Jiaju Ying and Yudan Chen and Guanglong Wang and Bing Zhou},
  doi          = {10.1049/cit2.70051},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1559--1572},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Exploring a hybrid convolutional framework for camouflage target classification in land-based hyperspectral images},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SKANN: Selective kernel audio neural networks for underwater mixed ship event detection. <em>CAAITIT</em>, <em>10</em>(5), 1548--1558. (<a href='https://doi.org/10.1049/cit2.70037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater acoustic target recognition (UATR) has become increasingly prevalent for ocean detection, localisation, and identification. However, due to the complexity and variability of underwater environments, especially in multi ship event environments, where multiple acoustic signals coexist, practical applications face significant challenges. These challenges hinder single-category acoustic recognition algorithms, particularly in extracting time series features and achieving fine-grained or multi-scale feature fusion. This paper innovatively introduce the SKANN framework, which achieve precise submarine sound recognition in underwater mixed ship events environments through timing data enhancement and sampling training module and selective kernel feature extraction module. The timing data enhancement and sampling training module improves time sequence feature extraction through progressive acoustic sampling. The selective kernel feature extraction module effectively fuses multi-scale features by integrating selective kernel (SK) technology. To simulate concurrent ship events, we constructed the mixed ship noise dataset (M-DeepShip), providing an experimental basis and test platform for underwater mixed ship event detection. This dataset ensures that the model encounters diverse audio samples during training and validation, improving its ability to extract temporal features. Experimental results show that SKANN achieves a 93.6% recognition rate on the M-DeepShip dataset, demonstrating its effectiveness in recognising underwater mixed ship events. Given the complexity of real underwater environments, this work lays a crucial foundation for the sound recognition of submarine vessels. Future research will focus on real marine environments to validate and refine the models and methods for practical applications.},
  archive      = {J_CAAITIT},
  author       = {Chun Shan and Tongyi Zou and Lingjun Zhao and Qinnan Zhang and Yafeng Zhu and Guizani Mohsen and Jing Qiu},
  doi          = {10.1049/cit2.70037},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1548--1558},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {SKANN: Selective kernel audio neural networks for underwater mixed ship event detection},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A keypoint-guided feature partition network for occluded person re-identification. <em>CAAITIT</em>, <em>10</em>(5), 1535--1547. (<a href='https://doi.org/10.1049/cit2.70057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing occluded person re-identification methods employ hard or soft partition strategies to explore fine-grained information. However, the hard partition strategy which extracts region-level features may impair the semantic connectivity of correlated human body parts. A pose-guided soft partition establishes correlations among human keypoints, while the generated pixel-level embeddings may lose the surrounding semantic information. In this paper, we propose a keypoint-guided feature partition (KGFP) method that consists of a feature extractor, a hard partition branch, and a soft partition branch. Specifically, we adopt a vision transformer and a pose estimator to extract features and keypoint information. In the hard partition branch, we partition features into distinct groups and classify them into nonoccluded, semi-occluded, and occluded features to obtain region-level features and filter out occlusions. Furthermore, we design a dissimilarity loss to reduce the similarity between semi-occluded and occluded features. In the soft partition branch, we introduce a graph attention network and consider global and keypoint embeddings as nodes of a graph to discover interrelationships. Additionally, we formulate image alignment as a graph matching problem and propose a feature alignment-based graph to reduce position misalignment. Extensive experiments demonstrate that the proposed method achieves superior performance compared to state-of-the-art methods on Occluded-DukeMTMC, Markt1501, and DukeMTMC-reID.},
  archive      = {J_CAAITIT},
  author       = {Die Dai and Xu Zhang and Zhiguang Wu and Hongying Meng and Zuyu Zhang},
  doi          = {10.1049/cit2.70057},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1535--1547},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A keypoint-guided feature partition network for occluded person re-identification},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight YOLOv5 target detection model and its application to the measurement of 100-kernel weight of corn seeds. <em>CAAITIT</em>, <em>10</em>(5), 1521--1534. (<a href='https://doi.org/10.1049/cit2.70031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 100-kernel weight of corn seed is a crucial metric for assessing corn quality, and the current measurement means mostly involve manual counting of kernels followed by weighing on a balance, which is labour-intensive and time-consuming. Aiming to address the problem of low efficiency in measuring the 100-kernel weight of corn seeds, this study proposes a measurement method based on deep learning and machine vision. In this study, high-contrast camera technology was utilised to capture image data of corn seeds. And improvements were made to the feature extraction network of the YOLOv5 model by incorporating the MobileNetV3 network structure. The novel model employs deep separable convolution to decrease parameters and computational load. It incorporates a linear bottleneck and inverted residual structure to enhance efficiency. It introduces an SE attention mechanism for direct learning of channel number features and updates the activation function. Algorithms and experiments were subsequently designed to calculate the 100-grain weight in conjunction with the output of the model. The outcomes revealed that the enhanced model in this study achieved an accuracy of 90.1%, a recall rate of 91.3%, and a mAP (mean average precision) value of 92.2%. While meeting production requirements, this model significantly reduces the number of parameters compared to alternative models—50% of the original model. In an applied study focused on measuring the 100-kernel weight of corn seeds, the counting accuracy yielded a remarkable 97.18%, while the accuracy for weight measurement results reached 94.2%. This study achieves both efficient and precise measurement of the 100-kernel weight of maize seeds, presenting a novel perspective in the exploration of maize seed weight.},
  archive      = {J_CAAITIT},
  author       = {Helong Yu and Jiayao Zhao and Chun Guang Bi and Lei Shi and Huiling Chen},
  doi          = {10.1049/cit2.70031},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1521--1534},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A lightweight YOLOv5 target detection model and its application to the measurement of 100-kernel weight of corn seeds},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep backtracking bare-bones particle swarm optimisation algorithm for high-dimensional nonlinear functions. <em>CAAITIT</em>, <em>10</em>(5), 1501--1520. (<a href='https://doi.org/10.1049/cit2.70028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The challenge of optimising multimodal functions within high-dimensional domains constitutes a notable difficulty in evolutionary computation research. Addressing this issue, this study introduces the Deep Backtracking Bare-Bones Particle Swarm Optimisation (DBPSO) algorithm, an innovative approach built upon the integration of the Deep Memory Storage Mechanism (DMSM) and the Dynamic Memory Activation Strategy (DMAS). The DMSM enhances the memory retention for the globally optimal particle, promoting interaction between standard particles and their historically optimal counterparts. In parallel, DMAS assures the updated position of the globally optimal particle is appropriately aligned with the deep memory repository. The efficacy of DBPSO was rigorously assessed through a series of simulations employing the CEC2017 benchmark suite. A comparative analysis juxtaposed DBPSO's performance against five contemporary evolutionary algorithms across two experimental conditions: Dimension-50 and Dimension-100. In the 50D trials, DBPSO attained an average ranking of 2.03, whereas in the 100D scenarios, it improved to an average ranking of 1.9. Further examination utilising the CEC2019 benchmark functions revealed DBPSO's robustness, securing four first-place finishes, three second-place standings, and three third-place positions, culminating in an unmatched average ranking of 1.9 across all algorithms. These empirical results corroborate DBPSO's proficiency in delivering precise solutions for complex, high-dimensional optimisation challenges.},
  archive      = {J_CAAITIT},
  author       = {Jia Guo and Guoyuan Zhou and Ke Yan and Yi Di and Yuji Sato and Zhou He and Binghua Shi},
  doi          = {10.1049/cit2.70028},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1501--1520},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A deep backtracking bare-bones particle swarm optimisation algorithm for high-dimensional nonlinear functions},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design of a marker-based Human–Robot following motion control strategy. <em>CAAITIT</em>, <em>10</em>(5), 1489--1500. (<a href='https://doi.org/10.1049/cit2.70023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the challenges of jerky movements and poor tracking performance in outdoor environments for a following-type mobile robot, a novel marker-based human–machine following-motion control strategy is explored. This strategy decouples the control of linear velocity and angular velocity, handling them separately. First, in the design of linear-velocity control, using the identification of markers to determine the distance between the human and the robot, an enhanced virtual spring model is developed. This involves designing a weighted dynamic damping coefficient to address the rationality issues of the range and trend of the robot's following speed, thereby improving its smoothness and reducing the risk of target loss. Second, in the design of angular velocity control, a new concept of an ‘insensitive zone’ based on the offset of the marker's centre point is proposed, combined with a fuzzy controller to address the issue of robot jitter and enhance its resistance to interference. The experimental results indicate that the average variance in the human–robot distance is 1.037 m, whereas the average variance in the robot's linear velocity is 0.345 m/s. Due to the design of an insensitive region in parameter-adaptive fuzzy control, the average variance of angular velocity is only 0.031 rad/s. When the human–robot distance exhibits significant fluctuations, the fluctuations in both linear and angular velocities are comparatively small, allowing for stable and smooth following movements. This demonstrates the effectiveness of the motion control strategy designed in this study.},
  archive      = {J_CAAITIT},
  author       = {Zhigang Zhang and Yongsheng Guo and Xiaoxia Yu and Shuaishuai Ge},
  doi          = {10.1049/cit2.70023},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1489--1500},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Design of a marker-based Human–Robot following motion control strategy},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning-based multi-level knowledge distillation. <em>CAAITIT</em>, <em>10</em>(5), 1478--1488. (<a href='https://doi.org/10.1049/cit2.70036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing constraints of hardware devices, there is a growing demand for compact models to be deployed on device endpoints. Knowledge distillation, a widely used technique for model compression and knowledge transfer, has gained significant attention in recent years. However, traditional distillation approaches compare the knowledge of individual samples indirectly through class prototypes overlooking the structural relationships between samples. Although recent distillation methods based on contrastive learning can capture relational knowledge, their relational constraints often distort the positional information of the samples leading to compromised performance in the distilled model. To address these challenges and further enhance the performance of compact models, we propose a novel approach, termed contrastive learning-based multi-level knowledge distillation (CLMKD). The CLMKD framework introduces three key modules: class-guided contrastive distillation, gradient relation contrastive distillation, and semantic similarity distillation. These modules are effectively integrated into a unified framework to extract feature knowledge from multiple levels, capturing not only the representational consistency of individual samples but also their higher-order structure and semantic similarity. We evaluate the proposed CLMKD method on multiple image classification datasets and the results demonstrate its superior performance compared to state-of-the-art knowledge distillation methods.},
  archive      = {J_CAAITIT},
  author       = {Lin Li and Jianping Gou and Weihua Ou and Wenbai Chen and Lan Du},
  doi          = {10.1049/cit2.70036},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1478--1488},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Contrastive learning-based multi-level knowledge distillation},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximate-guided representation learning in vision transformer. <em>CAAITIT</em>, <em>10</em>(5), 1459--1477. (<a href='https://doi.org/10.1049/cit2.70041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the transformer model has demonstrated excellent performance in computer vision (CV) applications. The key lies in its guided representation attention mechanism, which uses dot-product to depict complex feature relationships, and comprehensively understands the context semantics to obtain feature weights. Then feature enhancement is implemented by guiding the target matrix through feature weights. However, the uncertainty and inconsistency of features are widespread that prone to confusion in the description of relationships within dot-product attention mechanisms. To solve this problem, this paper proposed a novel approximate-guided representation learning methodology for vision transformer. The kernelised matroids fuzzy rough set is defined, wherein the closed sets inside kernelised fuzzy information granules of matroids structures can constitute the subspace of lower approximation in rough sets. Thus, the kernel relation is employed to characterise image feature granules that will be reconstructed according to the independent set in matroids theory. Then, according to the characteristics of the closed set within matroids, the feature attention weight is formed by using the lower approximation to realise the approximate guidance of features. The approximate-guided representation mechanism can be flexibly deployed as a plug-and-play component in a wide range of CV tasks. Extensive empirical results demonstrate that the proposed method outperforms the majority of advanced prevalent models, especially in terms of robustness.},
  archive      = {J_CAAITIT},
  author       = {Kaili Wang and Xinwei Sun and Huijie He and Fenhua Bai and Tao Shen},
  doi          = {10.1049/cit2.70041},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1459--1477},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Approximate-guided representation learning in vision transformer},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving 3D object detection in neural radiance fields with channel attention. <em>CAAITIT</em>, <em>10</em>(5), 1446--1458. (<a href='https://doi.org/10.1049/cit2.70045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, 3D object detection using neural radiance fields (NeRF) has advanced significantly, yet challenges remain in effectively utilising the density field. Current methods often treat NeRF as a geometry learning tool or rely on volume rendering, neglecting the density field's potential and feature dependencies. To address this, we propose NeRF-C3D, a novel framework incorporating a multi-scale feature fusion module with channel attention (MFCA). MFCA leverages channel attention to model feature dependencies, dynamically adjusting channel weights during fusion to enhance important features and suppress redundancy. This optimises density field representation and improves feature discriminability. Experiments on 3D-FRONT, Hypersim, and ScanNet demonstrate NeRF-C3D's superior performance validating MFCA's effectiveness in capturing feature relationships and showcasing its innovation in NeRF-based 3D detection.},
  archive      = {J_CAAITIT},
  author       = {Minling Zhu and Yadong Gong and Dongbing Gu and Chunwei Tian},
  doi          = {10.1049/cit2.70045},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1446--1458},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Improving 3D object detection in neural radiance fields with channel attention},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RDHNet: Reversible data hiding method for securing colour images using AlexNet and watershed transform in a fusion domain. <em>CAAITIT</em>, <em>10</em>(5), 1422--1445. (<a href='https://doi.org/10.1049/cit2.70038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical images play a crucial role in diagnosis, treatment procedures and overall healthcare. Nevertheless, they also pose substantial risks to patient confidentiality and safety. Safeguarding the confidentiality of patients' data has become an urgent and practical concern. We present a novel approach for reversible data hiding for colour medical images. In a hybrid domain, we employ AlexNet, tuned with watershed transform (WST) and L-shaped fractal Tromino encryption. Our approach commences by constructing the host image's feature vector using a pre-trained AlexNet model. Next, we use the watershed transform to convert the extracted feature vector into a vector for a topographic map, which we then encrypt using an L-shaped fractal Tromino cryptosystem. We embed the secret image in the transformed image vector using a histogram-based embedding strategy to enhance payload and visual fidelity. When there are no attacks, the RDHNet exhibits robust performance, can be reversed to the original image and maintains a visually appealing stego image, with an average PSNR of 73.14 dB, an SSIM of 0.9999 and perfect values of NC = 1 and BER = 0 under normal conditions. The proposed RDHNet demonstrates a robust ability to withstand detrimental geometric and noise-adding attacks as well as various steganalysis methods. Furthermore, our RDHNet method initiative demonstrates efficacy in tackling contemporary confidentiality issues.},
  archive      = {J_CAAITIT},
  author       = {Mohamed Meselhy Eltoukhy and Faisal S. Alsubaei and Mostafa M. Abdel-Aziz and Khalid M. Hosny},
  doi          = {10.1049/cit2.70038},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1422--1445},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {RDHNet: Reversible data hiding method for securing colour images using AlexNet and watershed transform in a fusion domain},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing brain MRI super-resolution through multi-slice aware matching and fusion. <em>CAAITIT</em>, <em>10</em>(5), 1411--1421. (<a href='https://doi.org/10.1049/cit2.70032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In clinical diagnosis, magnetic resonance imaging (MRI) allows different contrast images to be obtained. High-resolution (HR) MRI presents fine anatomical structures, which is important for improving the efficiency of expert diagnosis and realising smart healthcare. However, due to the cost of scanning equipment and the time required for scanning, obtaining an HR brain MRI is quite challenging. Therefore, to improve the quality of images, reference-based super-resolution technology has come into existence. Nevertheless, the existing methods still have some drawbacks: (1) The advantages of different contrast images are not fully utilised. (2) The slice-by-slice scanning nature of magnetic resonance imaging is not considered. (3) The ability to capture contextual information and to match and fuse multi-scale, multi-contrast features is lacking. In this paper, we propose the multi-slice aware matching and fusion (MSAMF) network, which makes full use of multi-slice reference images information by introducing a multi-slice aware module and multi-scale matching strategy to capture corresponding contextual information in reference features at other scales. To further integrate matching features, a multi-scale fusion mechanism is also designed to progressively fuse multi-scale matching features, thereby generating more detailed super-resolution images. The experimental results support the benefits of our network in enhancing the quality of brain MRI reconstruction.},
  archive      = {J_CAAITIT},
  author       = {Jie Xiang and Ang Zhao and Xia Li and Xubin Wu and Yanqing Dong and Yan Niu and Xin Wen and Yidi Li},
  doi          = {10.1049/cit2.70032},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1411--1421},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Enhancing brain MRI super-resolution through multi-slice aware matching and fusion},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tibetan few-shot learning model with deep contextualised two-level word embeddings. <em>CAAITIT</em>, <em>10</em>(5), 1394--1410. (<a href='https://doi.org/10.1049/cit2.70047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning is the task of identifying new text categories from a limited set of training examples. The two key challenges in few-shot learning are insufficient understanding of new samples and imperfect modelling. The uniqueness of low-resource languages lies in their limited linguistic resources, which directly leads to the difficulty for models to learn sufficiently rich feature representations from limited samples. As a minority language, Tibetan few-shot learning requires further exploration. With limited data resources, if the model's understanding of text is noncontextual, it cannot provide sufficiently distinctive feature representations, limiting its performance in few-shot learning. Therefore, this paper proposed a few-shot learning architecture called two-level word embeddings matching networks (TWE-MN). TWE-MN is specifically designed to enhance the model's representational capacity and optimise its generalisation capabilities in data-scarce environments. As this paper focuses on Tibetan few-shot learning tasks, a pretrained Tibetan language model, BoBERT, was constructed. BoBERT, as the pre-embedding layer of TWE-MN, in combination with the BoBERT-augmented full-context embedding, can capture feature information from local to global levels. This paper evaluated the performance of TWE-MN in Tibetan few-shot learning tasks and Tibetan text classification tasks. The experimental results show that TWE-MN outperformed vanilla MN in all Tibetan few-shot learning tasks, with an average accuracy improvement of 4.5%–6.5% and up to 6.8% at most. In addition, this paper also explores the potential of TWE-MN in other NLP tasks, such as text classification and machine translation.},
  archive      = {J_CAAITIT},
  author       = {Ziyue Zhang and Yongbin Yu and Xiangxiang Wang and Xiao Feng and Yuze Li and Jiarun Shen and Dorje Tashi and Jin Zhang and Lobsang Yeshi and Lei Li and Nyima Tashi and Jingye Cai},
  doi          = {10.1049/cit2.70047},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1394--1410},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Tibetan few-shot learning model with deep contextualised two-level word embeddings},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VSMI2-PANet: Versatile scale-malleable image integration and patch wise attention network with transformer for lung tumour segmentation using multi-modal imaging techniques. <em>CAAITIT</em>, <em>10</em>(5), 1376--1393. (<a href='https://doi.org/10.1049/cit2.70039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer (LC) is a major cancer which accounts for higher mortality rates worldwide. Doctors utilise many imaging modalities for identifying lung tumours and their severity in earlier stages. Nowadays, machine learning (ML) and deep learning (DL) methodologies are utilised for the robust detection and prediction of lung tumours. Recently, multi modal imaging emerged as a robust technique for lung tumour detection by combining various imaging features. To cope with that, we propose a novel multi modal imaging technique named versatile scale malleable image integration and patch wise attention network ( ) which adopts three imaging modalities named computed tomography (CT), magnetic resonance imaging (MRI) and single photon emission computed tomography (SPECT). The designed model accepts input from CT and MRI images and passes it to the module that is composed of three sub-modules named image cropping module, scale malleable convolution layer (SMCL) and PANet module. CT and MRI images are subjected to image cropping module in a parallel manner to crop the meaningful image patches and provide them to the SMCL module. The SMCL module is composed of adaptive convolutional layers that investigate those patches in a parallel manner by preserving the spatial information. The output from the SMCL is then fused and provided to the PANet module. The PANet module examines the fused patches by analysing its height, width and channels of the image patch. As a result, it provides an output as high-resolution spatial attention maps indicating the location of suspicious tumours. The high-resolution spatial attention maps are then provided as an input to the backbone module which uses light wave transformer (LWT) for segmenting the lung tumours into three classes, such as normal, benign and malignant. In addition, the LWT also accepts SPECT image as input for capturing the variations precisely to segment the lung tumours. The performance of the proposed model is validated using several performance metrics, such as accuracy, precision, recall, F 1-score and AUC curve, and the results show that the proposed work outperforms the existing approaches.},
  archive      = {J_CAAITIT},
  author       = {Nayef Alqahtani and Arfat Ahmad Khan and Rakesh Kumar Mahendran and Muhammad Faheem},
  doi          = {10.1049/cit2.70039},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1376--1393},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {VSMI2-PANet: Versatile scale-malleable image integration and patch wise attention network with transformer for lung tumour segmentation using multi-modal imaging techniques},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic communication and predictive compression of kinaesthetic signals in robotics with learnable matrices. <em>CAAITIT</em>, <em>10</em>(5), 1363--1375. (<a href='https://doi.org/10.1049/cit2.70035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotics plays an increasingly important role in all areas of human activity. Teleoperation robots can effectively ensure the safety of operators when operating in difficult and high-risk industrial scenarios, which obviously requires instant and efficient signal compression and transmission in the system. However, most of the existing algorithms cannot fully explore the correlation within the signal, which mostly limits the compression efficiency. In this paper, a novel prediction-aided kinaesthetic-signal compression framework is proposed, which uses semantic communication methods to explore the temporal and spatial correlations of signals and employs neural network predictions to uncover their internal correlations. Specifically, the signal is first divided into two groups: the base part and the predictable part, and then a series of transformation matrices are introduced to establish the correlation between the two groups of the signal, which can be automatically optimised by a well-designed neural network. This strategy of using learnable transformation matrices for prediction can not only accurately construct the correlation within the signal through massive data mining but also efficiently execute inference in a simple matrix multiplication computing form. Experimental results demonstrate that the proposed method outperforms the existing traditional tactile codecs and the latest tactile semantic communication methods.},
  archive      = {J_CAAITIT},
  author       = {Wenrui Wang and Yang Chen and Xianqi Zhang and Wenxue Cui and Mengyao Ma and Jiahui Li and Xiaopeng Fan},
  doi          = {10.1049/cit2.70035},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1363--1375},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Semantic communication and predictive compression of kinaesthetic signals in robotics with learnable matrices},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). V-UNet: Medical image segmentation based on variational attention mechanism. <em>CAAITIT</em>, <em>10</em>(5), 1350--1362. (<a href='https://doi.org/10.1049/cit2.70053'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate medical image segmentation plays a crucial role in improving the precision of computer-aided diagnosis. However, complex boundary shapes, low contrast and blurred anatomical structures make fine-grained segmentation a challenging task. Variational Bayesian inference quantifies uncertainty through probability distributions and can construct robust probabilistic models for the boundaries of ambiguous organs and tissues. In this paper, we apply variational Bayesian inference to medical image segmentation and propose variational attention to model the uncertainty of low-contrast and blurry tissue and organ boundaries. This enhances the model's ability to perceive segmentation boundaries, improving robustness and segmentation accuracy. Variational attention first estimates the parameters of the probability distribution of latent representations based on input features. Then, it samples latent representations from the learnt distribution to generate attention weights that optimise the interaction between global features and ambiguous boundaries. We integrate variational attention into the U-Net model by replacing its skip connections, constructing a multi-scale variational attention segmentation model (V-UNet). Experiments on the ISBI 2012 and MoNuSeg 2018 datasets show that our method achieves Dice scores of 95.89% and 82.18%, respectively. Moreover, we integrate V-UNet into the Mask R-CNN framework by replacing the FPN feature extraction head and propose a two-stage segmentation method. Compared to the original Mask R-CNN, our method improves the Dice score by 0.81%, mAP by 8.06% and F1 score by 0.51%.},
  archive      = {J_CAAITIT},
  author       = {Yang Zhang and Qiang Yang and Tian Li and Fanghong Zhang and Yu Ren and Yinhao Li and Chuanyun Xu},
  doi          = {10.1049/cit2.70053},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1350--1362},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {V-UNet: Medical image segmentation based on variational attention mechanism},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid distributed and decentralised reinforcement learning for formation control of multi-robots with obstacle avoidance. <em>CAAITIT</em>, <em>10</em>(5), 1337--1349. (<a href='https://doi.org/10.1049/cit2.70002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, learning-based control for multi-robot systems (MRS) with obstacle avoidance has received increasing attention. The goals of formation control and obstacle avoidance could be intrinsically tied. As a result, developing a safe and near-optimal control policy with the actor-critic structure is challenging. Therefore, a hybrid distributed and decentralised asynchronous actor-critic reinforcement learning (Di-De-RL) technique is proposed to address this problem. First, we decompose the integrated formation control and collision avoidance problem into two successive ones. To solve them, we design a distributed reinforcement learning (Di-RL) algorithm that employs a neural network-based actor-critic structure for formation control, and a decentralised RL (De-RL) algorithm that incorporates a potential-field (PF)-based actor-critic structure for collision avoidance. In Di-RL, the actor-critic pairs are trained in a distributed manner to achieve near-optimal consensus formation control. With the trained policy of Di-RL fixed, the PF actor-critic pairs in De-RL are trained in a decentralised manner for safe collision avoidance. Such an asynchronous training design of the hybrid Di-RL and De-RL enables weight convergence and control safety in the learning process. The simulated and real-world experimental results demonstrate the effectiveness and enhanced performance of the approach in formation control with both static and dynamic obstacle avoidance, highlighting its advantages in resolving the conflict between the safety objective and optimal control.},
  archive      = {J_CAAITIT},
  author       = {Yaoqian Peng and Xinglong Zhang and Haibin Xie and Xin Xu},
  doi          = {10.1049/cit2.70002},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1337--1349},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Hybrid distributed and decentralised reinforcement learning for formation control of multi-robots with obstacle avoidance},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel AI-driven expert system for obesity diagnosis and personalised treatment. <em>CAAITIT</em>, <em>10</em>(5), 1320--1336. (<a href='https://doi.org/10.1049/cit2.70049'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obesity is a major risk factor for chronic diseases, underscoring the need for early diagnosis and effective management. This study presents a novel expert system designed to accurately classify obesity levels and provide personalised treatment recommendations. Five machine learning algorithms—decision tree, random forest, multinomial logistic regression (MLR), Naive Bayes, and support vector machine (SVM)—were evaluated using the SEMMA data mining methodology and the tidymodels framework. MLR demonstrated the highest accuracy (97.48%) and was selected as the final model. The system features a user-friendly interface built with R Shiny, facilitating real-time interaction and a seamless user experience. Treatment recommendations are generated through if-then rule-based logic, ensuring tailored guidance for each obesity category. Comparative analysis highlights the system's superior diagnostic accuracy and practical application in treatment guidance. Its accessibility, particularly in underserved rural populations, enhances public health outcomes by enabling early diagnosis, targeted interventions, and proactive obesity management.},
  archive      = {J_CAAITIT},
  author       = {Xuefang Li and Asefeh Asemi},
  doi          = {10.1049/cit2.70049},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1320--1336},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A novel AI-driven expert system for obesity diagnosis and personalised treatment},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning approach for automated estimation of 3D vertebral orientation of the lumbar spine. <em>CAAITIT</em>, <em>10</em>(5), 1306--1319. (<a href='https://doi.org/10.1049/cit2.70033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lumbar degenerative disc diseases constitute a major contributor to lower back pain. In pursuit of an enhanced understanding of lumbar degenerative pathology and the development of more effective treatment modalities, the application of precise measurement techniques for lumbar segment kinematics is imperative. This study aims to pioneer a novel automated lumbar spine orientation estimation method using deep learning techniques, to facilitate the automatic 2D–3D pre-registration of the lumbar spine during physiological movements, to enhance the efficiency of image registration and the accuracy of spinal segment kinematic measurements. A total of 12 asymptomatic volunteers were enrolled and captured in 2 oblique views with 7 different postures. Images were used for deep learning model development training and evaluation. The model was composed of a segmentation module using Mask R-CNN and an estimation module using ResNet50 architecture with a Squeeze-and-Excitation module. The cosine value of the angle between the prediction vector and the vector of ground truth was used to quantify the model performance. Data from another two prospective recruited asymptomatic volunteers were used to compare the time cost between model-assisted registration and manual registration without a model. The cosine values of vector deviation angles at three axes in the cartesian coordinate system were 0.9667 ± 0.004, 0.9593 ± 0.0047 and 0.9828 ± 0.0025, respectively. The value of the angular deviation between the intermediate vector obtained by utilising the three direction vectors and ground truth was 10.7103 ± 0.7466. Results show the consistency and reliability of the model's predictions across different experiments and axes and demonstrate that our approach significantly reduces the registration time (3.47 ± 0.90 min vs. 8.10 ± 1.60 min, p < 0.001), enhances the efficiency, and expands its broader utilisation of clinical research about kinematic measurements.},
  archive      = {J_CAAITIT},
  author       = {Nanfang Xu and Shanshan Liu and Yuepeng Chen and Kailai Zhang and Chenyi Guo and Cheng Zhang and Fei Xu and Qifeng Lan and Wanyi Fu and Xingyu Zhou and Bo Zhao and Aodong He and Xiangling Fu and Ji Wu and Weishi Li},
  doi          = {10.1049/cit2.70033},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1306--1319},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Deep learning approach for automated estimation of 3D vertebral orientation of the lumbar spine},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Arbitrary-scale point cloud upsampling via enhanced geometric spatial consistency. <em>CAAITIT</em>, <em>10</em>(5), 1291--1305. (<a href='https://doi.org/10.1049/cit2.70052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud upsampling is an essential yet challenging task in various 3D computer vision and graphics applications. Existing methods often struggle with limitations such as the generation of outliers or shrinkage artifacts. Additionally, these methods usually ignore the overall spatial structure of point clouds, leading to suboptimal results. To tackle these challenges, we propose a novel framework that enhances geometric spatial consistency in upsampled point clouds through a dual-supervision mechanism and enables the generation of high-fidelity results with precise geometric structures. Specifically, we first design a tailored feature extractor that iteratively extracts the comprehensive and distinctive features by integrating both fine-grained local geometric details and global structure information. Then, our network predicts the point-to-point distances and Chamfer distances of upsampled points to accurately capture the spatial relation within them. To enhance spatial consistency, we formulate a joint loss function that enables our model to perceive the spatial relations between points by indirect and direct supervision. This ensures the precise alignment between upsampled points and ground truth during training. Furthermore, we propose a coordinate reconstruction to generate more high-quality upsampled points iteratively. We conduct extensive experiments across multiple benchmark datasets and downstream tasks. The results comprehensively demonstrate that our method achieves state-of-the-art performance and exhibits superior generalisation capabilities.},
  archive      = {J_CAAITIT},
  author       = {Xianjing Cheng and Lintai Wu and Junhui Hou and Zhijun Hu and Jie Wen and Yong Xu},
  doi          = {10.1049/cit2.70052},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1291--1305},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Arbitrary-scale point cloud upsampling via enhanced geometric spatial consistency},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive block-wise prediction error-based (AdaBPE) reversible data hiding in encrypted images for medical image transmission. <em>CAAITIT</em>, <em>10</em>(5), 1269--1290. (<a href='https://doi.org/10.1049/cit2.12365'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Life expectancy has improved with new-age technologies and advancements in the healthcare sector. Though artificial intelligence (AI) and the Internet of Things (IoT) are revolutionising smart healthcare systems, security of the healthcare data is always a concern. Reversible data hiding (RDH) is widely explored in the healthcare domain for secure data transmission and in areas like cloud computing, satellite image transmission, etc. Medical image transmission plays an important role in the smart health sector. In the case of medical images, a minute error in the reconstructed medical image can mislead the doctor, posing a threat to the patient’s health. Many RDH schemes have been proposed, but very few address from the view of medical images, and that too on high-quality DICOM images. The proposed AdaBPE RDH scheme is a solution for secure transmission of the patient’s health report (PHR) and other sensitive information with medical specialists. The scheme put forward a technique that maintains a good trade-off between the smooth pixels for maximum embedding in a block and a lossless recovery. Here, the cover medium employed to hide the patient’s sensitive information is an encrypted 16-bit DICOM image. The scheme processes the cover image as disjoint blocks of equal size, embedding the information adaptively within the encrypted blocks pertaining to the nature of the actual pixel values in the block through MSB prediction error methodology. The outcomes are evaluated on both the 16-bit DICOM images and 8-bit natural images, and the scheme is well poised with RDH goal of BER = 0, PSNR = ∞ , and SSIM = 1, achieving an average embedding of 5.7067 bpp on high-quality medical images and 1.6769 bpp on natural images. The experimental results prove advantageous and are better than other similar state-of-the-art schemes.},
  archive      = {J_CAAITIT},
  author       = {Shaiju Panchikkil and Vazhora Malayil Manikandan and Partha Pratim Roy and Shuihua Wang and Yudong Zhang},
  doi          = {10.1049/cit2.12365},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {10},
  number       = {5},
  pages        = {1269--1290},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {An adaptive block-wise prediction error-based (AdaBPE) reversible data hiding in encrypted images for medical image transmission},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unified neural lexical analysis via two-stage span tagging. <em>CAAITIT</em>, <em>10</em>(4), 1254--1267. (<a href='https://doi.org/10.1049/cit2.70015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lexical analysis is a fundamental task in natural language processing, which involves several subtasks, such as word segmentation (WS), part-of-speech (POS) tagging, and named entity recognition (NER). Recent works have shown that taking advantage of relatedness between these subtasks can be beneficial. This paper proposes a unified neural framework to address these subtasks simultaneously. Apart from the sequence tagging paradigm, the proposed method tackles the multitask lexical analysis via two-stage sequence span classification. Firstly, the model detects the word and named entity boundaries by multi-label classification over character spans in a sentence. Then, the authors assign POS labels and entity labels for words and named entities by multi-class classification, respectively. Furthermore, a Gated Task Transformation (GTT) is proposed to encourage the model to share valuable features between tasks. The performance of the proposed model was evaluated on Chinese and Thai public datasets, demonstrating state-of-the-art results.},
  archive      = {J_CAAITIT},
  author       = {Yantuan Xian and Yefen Zhu and Zhentao Yu and Yuxin Huang and Junjun Guo and Yan Xiang},
  doi          = {10.1049/cit2.70015},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1254--1267},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Unified neural lexical analysis via two-stage span tagging},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring high dimensional feature space with channel-spatial nonlinear transforms for learned image compression. <em>CAAITIT</em>, <em>10</em>(4), 1235--1253. (<a href='https://doi.org/10.1049/cit2.70025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear transforms have significantly advanced learned image compression (LIC), particularly using residual blocks. This transform enhances the nonlinear expression ability and obtain compact feature representation by enlarging the receptive field, which indicates how the convolution process extracts features in a high dimensional feature space. However, its functionality is restricted to the spatial dimension and network depth, limiting further improvements in network performance due to insufficient information interaction and representation. Crucially, the potential of high dimensional feature space in the channel dimension and the exploration of network width/resolution remain largely untapped. In this paper, we consider nonlinear transforms from the perspective of feature space, defining high-dimensional feature spaces in different dimensions and investigating the specific effects. Firstly, we introduce the dimension increasing and decreasing transforms in both channel and spatial dimensions to obtain high dimensional feature space and achieve better feature extraction. Secondly, we design a channel-spatial fusion residual transform (CSR), which incorporates multi-dimensional transforms for a more effective representation. Furthermore, we simplify the proposed fusion transform to obtain a slim architecture (CSR-sm), balancing network complexity and compression performance. Finally, we build the overall network with stacked CSR transforms to achieve better compression and reconstruction. Experimental results demonstrate that the proposed method can achieve superior rate-distortion performance compared to the existing LIC methods and traditional codecs. Specifically, our proposed method achieves 9.38% BD-rate reduction over VVC on Kodak dataset.},
  archive      = {J_CAAITIT},
  author       = {Wen Tan and Fanyang Meng and Chao Li and Youneng Bao and Yongsheng Liang},
  doi          = {10.1049/cit2.70025},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1235--1253},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Exploring high dimensional feature space with channel-spatial nonlinear transforms for learned image compression},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy efficient VM selection using CSOA-VM model in cloud data centers. <em>CAAITIT</em>, <em>10</em>(4), 1217--1234. (<a href='https://doi.org/10.1049/cit2.70018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cloud data centres evolved with an issue of energy management due to the constant increase in size, complexity and enormous consumption of energy. Energy management is a challenging issue that is critical in cloud data centres and an important concern of research for many researchers. In this paper, we proposed a cuckoo search (CS)-based optimisation technique for the virtual machine (VM) selection and a novel placement algorithm considering the different constraints. The energy consumption model and the simulation model have been implemented for the efficient selection of VM. The proposed model CSOA-VM not only lessens the violations at the service level agreement (SLA) level but also minimises the VM migrations. The proposed model also saves energy and the performance analysis shows that energy consumption obtained is 1.35 kWh, SLA violation is 9.2 and VM migration is about 268. Thus, there is an improvement in energy consumption of about 1.8% and a 2.1% improvement (reduction) in violations of SLA in comparison to existing techniques.},
  archive      = {J_CAAITIT},
  author       = {Mandeep Singh Devgan and Tajinder Kumar and Purushottam Sharma and Xiaochun Cheng and Shashi Bhushan and Vishal Garg},
  doi          = {10.1049/cit2.70018},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1217--1234},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Energy efficient VM selection using CSOA-VM model in cloud data centers},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent medical diagnosis model based on graph neural networks for medical images. <em>CAAITIT</em>, <em>10</em>(4), 1201--1216. (<a href='https://doi.org/10.1049/cit2.70020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, numerous estimation issues have been solved due to the developments in data-driven artificial neural networks (ANN) and graph neural networks (GNN). The primary limitation of previous methodologies has been the dependence on data that can be structured in a grid format. However, physiological recordings often exhibit irregular and unordered patterns, posing a significant challenge in conceptualising them as matrices. As a result, GNNs which comprise interactive nodes connected by edges whose weights are defined by anatomical junctions or temporal relationships have received a lot of consideration by leveraging implicit data that exists in a biological system. Additionally, our study incorporates a structural GNN to effectively differentiate between different degrees of infection in both the left and right hemispheres of the brain. Subsequently, demographic data are included, and a multi-task learning architecture is devised, integrating classification and regression tasks. The trials used an authentic dataset, including 800 brain x-ray pictures, consisting of 560 instances classified as moderate cases and 240 instances classified as severe cases. Based on empirical evidence, our methodology demonstrates superior performance in classification, surpassing other comparison methods with a notable achievement of 92.27% in terms of area under the curve as well as a correlation coefficient of 0.62.},
  archive      = {J_CAAITIT},
  author       = {Ashutosh Sharma and Amit Sharma and Kai Guo},
  doi          = {10.1049/cit2.70020},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1201--1216},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Intelligent medical diagnosis model based on graph neural networks for medical images},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bat algorithm based on kinetic adaptation and elite communication for engineering problems. <em>CAAITIT</em>, <em>10</em>(4), 1174--1200. (<a href='https://doi.org/10.1049/cit2.12345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Bat algorithm, a metaheuristic optimization technique inspired by the foraging behaviour of bats, has been employed to tackle optimization problems. Known for its ease of implementation, parameter tunability, and strong global search capabilities, this algorithm finds application across diverse optimization problem domains. However, in the face of increasingly complex optimization challenges, the Bat algorithm encounters certain limitations, such as slow convergence and sensitivity to initial solutions. In order to tackle these challenges, the present study incorporates a range of optimization components into the Bat algorithm, thereby proposing a variant called PKEBA. A projection screening strategy is implemented to mitigate its sensitivity to initial solutions, thereby enhancing the quality of the initial solution set. A kinetic adaptation strategy reforms exploration patterns, while an elite communication strategy enhances group interaction, to avoid algorithm from local optima. Subsequently, the effectiveness of the proposed PKEBA is rigorously evaluated. Testing encompasses 30 benchmark functions from IEEE CEC2014, featuring ablation experiments and comparative assessments against classical algorithms and their variants. Moreover, real-world engineering problems are employed as further validation. The results conclusively demonstrate that PKEBA exhibits superior convergence and precision compared to existing algorithms.},
  archive      = {J_CAAITIT},
  author       = {Chong Yuan and Dong Zhao and Ali Asghar Heidari and Lei Liu and Shuihua Wang and Huiling Chen and Yudong Zhang},
  doi          = {10.1049/cit2.12345},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1174--1200},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Bat algorithm based on kinetic adaptation and elite communication for engineering problems},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sophisticated ensemble deep learning approaches for multilabel retinal disease classification in medical imaging. <em>CAAITIT</em>, <em>10</em>(4), 1159--1173. (<a href='https://doi.org/10.1049/cit2.70012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel ensemble Deep learning (DL)-based Multi-Label Retinal Disease Classification (MLRDC) system, known for its high accuracy and efficiency. Utilising a stacking ensemble approach, and integrating DenseNet201, EfficientNetB4, EfficientNetB3 and EfficientNetV2S models, exceptional performance in retinal disease classification is achieved. The proposed MLRDC model, leveraging DL as the meta-model, outperforms individual base detectors, with DenseNet201 and EfficientNetV2S achieving an accuracy of 96.5%, precision of 98.6%, recall of 97.1%, and F1 score of 97.8%. Weighted multilabel classifiers in the ensemble exhibit an average accuracy of 90.6%, precision of 98.3%, recall of 91.2%, and F1 score of 94.6%, whereas unweighted models achieve an average accuracy of 90%, precision of 98.6%, recall of 93.1%, and F1 score of 95.7%. Employing Logistic Regression (LR) as the meta-model, the proposed MLRDC system achieves an accuracy of 93.5%, precision of 98.2%, recall of 93.9%, and F1 score of 96%, with a minimal loss of 0.029. These results highlight the superiority of the proposed model over benchmark state-of-the-art ensembles, emphasising its practical applicability in medical image classification.},
  archive      = {J_CAAITIT},
  author       = {Asghar Amir and Tariqullah Jan and Mohammad Haseeb Zafar and Shadan Khan Khattak},
  doi          = {10.1049/cit2.70012},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1159--1173},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Sophisticated ensemble deep learning approaches for multilabel retinal disease classification in medical imaging},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tibetan medical named entity recognition based on syllable-word-sentence embedding transformer. <em>CAAITIT</em>, <em>10</em>(4), 1148--1158. (<a href='https://doi.org/10.1049/cit2.70029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tibetan medical named entity recognition (Tibetan MNER) involves extracting specific types of medical entities from unstructured Tibetan medical texts. Tibetan MNER provide important data support for the work related to Tibetan medicine. However, existing Tibetan MNER methods often struggle to comprehensively capture multi-level semantic information, failing to sufficiently extract multi-granularity features and effectively filter out irrelevant information, which ultimately impacts the accuracy of entity recognition. This paper proposes an improved embedding representation method called syllable–word–sentence embedding. By leveraging features at different granularities and using un-scaled dot-product attention to focus on key features for feature fusion, the syllable–word–sentence embedding is integrated into the transformer, enhancing the specificity and diversity of feature representations. The model leverages multi-level and multi-granularity semantic information, thereby improving the performance of Tibetan MNER. We evaluate our proposed model on datasets from various domains. The results indicate that the model effectively identified three types of entities in the Tibetan news dataset we constructed, achieving an F1 score of 93.59%, which represents an improvement of 1.24% compared to the vanilla FLAT. Additionally, results from the Tibetan medical dataset we developed show that it is effective in identifying five kinds of medical entities, with an F1 score of 71.39%, which is a 1.34% improvement over the vanilla FLAT.},
  archive      = {J_CAAITIT},
  author       = {Jin Zhang and Ziyue Zhang and Lobsang Yeshi and Dorje Tashi and Xiangshi Wang and Yuqing Cai and Yongbin Yu and Xiangxiang Wang and Nyima Tashi and Gadeng Luosang},
  doi          = {10.1049/cit2.70029},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1148--1158},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Tibetan medical named entity recognition based on syllable-word-sentence embedding transformer},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimising PID controllers for multi-area automatic generation control with improved NSGA-II. <em>CAAITIT</em>, <em>10</em>(4), 1135--1147. (<a href='https://doi.org/10.1049/cit2.70024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern automated generation control (AGC) is increasingly complex, requiring precise frequency control for stability and operational accuracy. Traditional PID controller optimisation methods often struggle to handle nonlinearities and meet robustness requirements across diverse operational scenarios. This paper introduces an enhanced strategy using a multi-objective optimisation framework and a modified non-dominated sorting genetic algorithm II (SNSGA). The proposed model optimises the PID controller by minimising key performance metrics: integration time squared error (ITSE), integration time absolute error (ITAE), and rate of change of deviation (J). This approach balances convergence rate, overshoot, and oscillation dynamics effectively. A fuzzy-based method is employed to select the most suitable solution from the Pareto set. The comparative analysis demonstrates that the SNSGA-based approach offers superior tuning capabilities over traditional NSGA-II and other advanced control methods. In a two-area thermal power system without reheat, the SNSGA significantly reduces settling times for frequency deviations: 2.94s for and 4.98s for , marking improvements of 31.6% and 13.4% over NSGA-II, respectively.},
  archive      = {J_CAAITIT},
  author       = {Yang Yang and Yuchao Gao and Shangce Gao and Jinran Wu},
  doi          = {10.1049/cit2.70024},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1135--1147},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Optimising PID controllers for multi-area automatic generation control with improved NSGA-II},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Co-DeepNet: A cooperative convolutional neural network for DNA methylation-based age prediction. <em>CAAITIT</em>, <em>10</em>(4), 1118--1134. (<a href='https://doi.org/10.1049/cit2.70026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction of the age of each individual is possible using the changing pattern of DNA methylation with age. In this paper an age prediction approach to work out multivariate regression problems using DNA methylation data is developed. In this research study a convolutional neural network (CNN)-based model optimised by the genetic algorithm (GA) is addressed. This paper contributes to enhancing age prediction as a regression problem using a union of two CNNs and exchanging knowledge between them. This specifically re-starts the training process from a possibly higher-quality point in different iterations and, consequently, causes potentially yeilds better results at each iteration. The method proposed, which is called cooperative deep neural network (Co-DeepNet), is tested on two types of age prediction problems. Sixteen datasets containing 1899 healthy blood samples and nine datasets containing 2395 diseased blood samples are employed to examine the method's efficiency. As a result, the mean absolute deviation (MAD) is 1.49 and 3.61 years for training and testing data, respectively, when the healthy data is tested. The diseased blood data show MAD results of 3.81 and 5.43 years for training and testing data, respectively. The results of the Co-DeepNet are compared with six other methods proposed in previous studies and a single CNN using four prediction accuracy measurements ( R 2 , MAD, MSE and RMSE). The effectiveness of the Co-DeepNet and superiority of its results is proved through the statistical analysis.},
  archive      = {J_CAAITIT},
  author       = {Najmeh Sadat Jaddi and Mohammad Saniee Abadeh and Niousha Bagheri Khoulenjani and Salwani Abdullah and MohammadMahdi Ariannejad and Mohd Zakree Ahmad Nazri and Fatemeh Alvankarian},
  doi          = {10.1049/cit2.70026},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1118--1134},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Co-DeepNet: A cooperative convolutional neural network for DNA methylation-based age prediction},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models with contrastive decoding algorithm for hallucination mitigation in low-resource languages. <em>CAAITIT</em>, <em>10</em>(4), 1104--1117. (<a href='https://doi.org/10.1049/cit2.70004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural machine translation (NMT) has advanced with deep learning and large-scale multilingual models, yet translating low-resource languages often lacks sufficient training data and leads to hallucinations. This often results in translated content that diverges significantly from the source text. This research proposes a refined Contrastive Decoding (CD) algorithm that dynamically adjusts weights of log probabilities from strong expert and weak amateur models to mitigate hallucinations in low-resource NMT and improve translation quality. Advanced large language NMT models, including ChatGLM and LLaMA, are fine-tuned and implemented for their superior contextual understanding and cross-lingual capabilities. The refined CD algorithm evaluates multiple candidate translations using BLEU score, semantic similarity, and Named Entity Recognition accuracy. Extensive experimental results show substantial improvements in translation quality and a significant reduction in hallucination rates. Fine-tuned models achieve higher evaluation metrics compared to baseline models and state-of-the-art models. An ablation study confirms the contributions of each methodological component and highlights the effectiveness of the refined CD algorithm and advanced models in mitigating hallucinations. Notably, the refined methodology increased the BLEU score by approximately 30% compared to baseline models.},
  archive      = {J_CAAITIT},
  author       = {Zan Hongying and Arifa Javed and Muhammad Abdullah and Javed Rashid and Muhammad Faheem},
  doi          = {10.1049/cit2.70004},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1104--1117},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Large language models with contrastive decoding algorithm for hallucination mitigation in low-resource languages},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-domain graph anomaly detection via graph transfer and graph decouple. <em>CAAITIT</em>, <em>10</em>(4), 1089--1103. (<a href='https://doi.org/10.1049/cit2.70014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain graph anomaly detection (CD-GAD) is a promising task that leverages knowledge from a labelled source graph to guide anomaly detection on an unlabelled target graph. CD-GAD classifies anomalies as unique or common based on their presence in both the source and target graphs. However, existing models often fail to fully explore domain-unique knowledge of the target graph for detecting unique anomalies. Additionally, they tend to focus solely on node-level differences, overlooking structural-level differences that provide complementary information for common anomaly detection. To address these issues, we propose a novel method, Synthetic Graph Anomaly Detection via Graph Transfer and Graph Decouple (GTGD), which effectively detects common and unique anomalies in the target graph. Specifically, our approach ensures deeper learning of domain-unique knowledge by decoupling the reconstruction graphs of common and unique features. Moreover, we simultaneously consider node-level and structural-level differences by transferring node and edge information from the source graph to the target graph, enabling comprehensive domain-common knowledge representation. Anomalies are detected using both common and unique features, with their synthetic score serving as the final result. Extensive experiments demonstrate the effectiveness of our approach, improving an average performance by 12.6 on the AUC-PR compared to state-of-the-art methods.},
  archive      = {J_CAAITIT},
  author       = {Changqin Huang and Xinxing Shi and Chengling Gao and Qintai Hu and Xiaodi Huang and Qionghao Huang and Ali Anaissi},
  doi          = {10.1049/cit2.70014},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1089--1103},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Cross-domain graph anomaly detection via graph transfer and graph decouple},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RNN-based sequence-aware recommenders for tourist attractions. <em>CAAITIT</em>, <em>10</em>(4), 1077--1088. (<a href='https://doi.org/10.1049/cit2.70027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting appropriate tourist attractions to visit in real time is an important problem for travellers. Since recommenders proactively suggest items based on user preference, they are a promising solution for this problem. Travellers visit tourist attractions sequentially by considering multiple attributes at the same time. Therefore, it is desirable to consider this when developing recommenders for tourist attractions. Using GRU4REC, we proposed RNN-based sequence-aware recommenders (RNN-SARs) that use multiple sequence datasets for training the recommended model, named multi-RNN-SARs. We proposed two types of multi-RNN-SARs—concatenate-RNN-SARs and parallel-RNN-SARs. In order to evaluate multi-RNN-SARs, we compared hit rate (HR) and mean reciprocal rank (MRR) of the item-based collaborative filtering recommender (item-CFR), RNN-SAR with the single-sequence dataset (basic-RNN-SAR), multi-RNN-SARs and the state-of-the-art SARs using a real-world travel dataset. Our research shows that multi-RNN-SARs have significantly higher performances compared to item-CFR. Not all multi-RNN-SARs outperform basic-RNN-SAR but the best multi-RNN-SAR achieves comparable performance to that of the state-of-the-art algorithms. These results highlight the importance of using multiple sequence datasets in RNN-SARs and the importance of choosing appropriate sequence datasets and learning methods for implementing multi-RNN-SARs in practice.},
  archive      = {J_CAAITIT},
  author       = {Hee Jun Lee and Yang Sok Kim and Won Seok Lee and In Hyeok Choi and Choong Kwon Lee},
  doi          = {10.1049/cit2.70027},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1077--1088},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {RNN-based sequence-aware recommenders for tourist attractions},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph neural networks empowered origin-destination learning for urban traffic prediction. <em>CAAITIT</em>, <em>10</em>(4), 1062--1076. (<a href='https://doi.org/10.1049/cit2.70021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban traffic prediction with high precision is always the unremitting pursuit of intelligent transportation systems and is instrumental in bringing smart cities into reality. The fundamental challenges for traffic prediction lie in the accurate modelling of spatial and temporal traffic dynamics. Existing approaches mainly focus on modelling the traffic data itself, but do not explore the traffic correlations implicit in origin-destination (OD) data. In this paper, we propose STOD-Net, a dynamic spatial-temporal OD feature-enhanced deep network, to simultaneously predict the in-traffic and out-traffic for each and every region of a city. We model the OD data as dynamic graphs and adopt graph neural networks in STOD-Net to learn a low-dimensional representation for each region. As per the region feature, we design a gating mechanism and operate it on the traffic feature learning to explicitly capture spatial correlations. To further capture the complicated spatial and temporal dependencies among different regions, we propose a novel joint feature, learning block in STOD-Net and transfer the hybrid OD features to each block to make the learning process spatiotemporal-aware. We evaluate the effectiveness of STOD-Net on two benchmark datasets, and experimental results demonstrate that it outperforms the state-of-the-art by approximately 5% in terms of prediction accuracy and considerably improves prediction stability up to 80% in terms of standard deviation.},
  archive      = {J_CAAITIT},
  author       = {Chuanting Zhang and Guoqing Ma and Liang Zhang and Basem Shihada},
  doi          = {10.1049/cit2.70021},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1062--1076},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Graph neural networks empowered origin-destination learning for urban traffic prediction},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sep-NMS: Unlocking the aptitude of two-stage referring expression comprehension. <em>CAAITIT</em>, <em>10</em>(4), 1049--1061. (<a href='https://doi.org/10.1049/cit2.70007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Referring expression comprehension (REC) aims to locate a specific region in an image described by a natural language. Existing two-stage methods generate multiple candidate proposals in the first stage, followed by selecting one of these proposals as the grounding result in the second stage. Nevertheless, the number of candidate proposals generated in the first stage significantly exceeds ground truth and the recall of critical objects is inadequate, thereby enormously limiting the overall network performance. To address the above issues, the authors propose an innovative method termed Separate Non-Maximum Suppression (Sep-NMS) for two-stage REC. Particularly, Sep-NMS models information from the two stages independently and collaboratively, ultimately achieving an overall improvement in comprehension and identification of the target objects. Specifically, the authors propose a Ref-Relatedness module for filtering referent proposals rigorously, decreasing the redundancy of referent proposals. A Relatedness module based on robust multimodal pre-trained encoders is built to precisely assess the relevance between language and proposals to improve the recall of critical objects. It is worth mentioning that the authors are the pioneers in utilising a multimodal pre-training model for proposal filtering in the first stage. Moreover, an Information Fusion module is designed to effectively amalgamate the multimodal information across two stages, ensuring maximum utilisation of the available information. Extensive experiments demonstrate that the approach achieves competitive performance with previous state-of-the-art methods. The datasets used are publicly available: RefCOCO, RefCOCO+: https://doi.org/10.1007/978-3-319-46475-6_5 and RefCOCOg: https://doi.org/10.1109/CVPR.2016.9 .},
  archive      = {J_CAAITIT},
  author       = {Jing Wang and Zhikang Wang and Xiaojie Wang and Fangxiang Feng and Bo Yang},
  doi          = {10.1049/cit2.70007},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1049--1061},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Sep-NMS: Unlocking the aptitude of two-stage referring expression comprehension},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WaveLiteDehaze-network: A low-parameter wavelet-based method for real-time dehazing. <em>CAAITIT</em>, <em>10</em>(4), 1033--1048. (<a href='https://doi.org/10.1049/cit2.70011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the image dehazing problem has received considerable attention over recent years, the existing models often prioritise performance at the expense of complexity, making them unsuitable for real-world applications, which require algorithms to be deployed on resource constrained-devices. To address this challenge, we propose WaveLiteDehaze-Network (WLD-Net), an end-to-end dehazing model that delivers performance comparable to complex models while operating in real time and using significantly fewer parameters. This approach capitalises on the insight that haze predominantly affects low-frequency information. By exclusively processing the image in the frequency domain using discrete wavelet transform (DWT), we segregate the image into high and low frequencies and process them separately. This allows us to preserve high-frequency details and recover low-frequency components affected by haze, distinguishing our method from existing approaches that use spatial domain processing as the backbone, with DWT serving as an auxiliary component. DWT is applied at multiple levels for better information retention while also accelerating computation by downsampling feature maps. Subsequently, a learning-based fusion mechanism reintegrates the processed frequencies to reconstruct the dehazed image. Experiments show that WLD-Net outperforms other low-parameter models on real-world hazy images and rivals much larger models, achieving the highest PSNR and SSIM scores on the O-Haze dataset. Qualitatively, the proposed method demonstrates its effectiveness in handling a diverse range of haze types, delivering visually pleasing results and robust performance, while also generalising well across different scenarios. With only 0.385 million parameters (more than 100 times smaller than comparable dehazing methods), WLD-Net processes 1024 × 1024 images in just 0.045 s, highlighting its applicability across various real-world scenarios. The code is available at https://github.com/AliMurtaza29/WLD-Net .},
  archive      = {J_CAAITIT},
  author       = {Ali Murtaza and Uswah Khairuddin and Ahmad ’Athif Mohd Faudzi and Kazuhiko Hamamoto and Yang Fang and Zaid Omar},
  doi          = {10.1049/cit2.70011},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1033--1048},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {WaveLiteDehaze-network: A low-parameter wavelet-based method for real-time dehazing},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage early exiting from globality towards reliability. <em>CAAITIT</em>, <em>10</em>(4), 1019--1032. (<a href='https://doi.org/10.1049/cit2.70010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early exiting has shown significant potential in accelerating the inference of pre-trained language models (PLMs) by allowing easy samples to exit from shallow layers. However, existing early exiting methods primarily rely on local information from individual samples to estimate prediction uncertainty for making exiting decisions, overlooking the global information provided by the sample population. This impacts the estimation of prediction uncertainty, compromising the reliability of exiting decisions. To remedy this, inspired by principal component analysis (PCA), the authors define a residual score to capture the deviation of features from the principal space of the sample population, providing a global perspective for estimating prediction uncertainty. Building on this, a two-stage exiting strategy is proposed that integrates global information from residual scores with local information from energy scores at both the decision and feature levels. This strategy incorporates three-way decisions to enable more reliable exiting decisions for boundary region samples by delaying judgement. Extensive experiments on the GLUE benchmark validate that the method achieves an average speed-up ratio of 2.17× across all tasks with minimal performance degradation. Additionally, it surpasses the state-of-the-art E-LANG by in model acceleration, along with a performance improvement of 0.6 points, demonstrating a better performance-efficiency trade-off.},
  archive      = {J_CAAITIT},
  author       = {Jianing He and Qi Zhang and Hongyun Zhang and Duoqian Miao},
  doi          = {10.1049/cit2.70010},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1019--1032},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Two-stage early exiting from globality towards reliability},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Point-PC: Point cloud completion guided by prior knowledge via causal inference. <em>CAAITIT</em>, <em>10</em>(4), 1007--1018. (<a href='https://doi.org/10.1049/cit2.12379'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of point cloud completion is to reconstruct raw scanned point clouds acquired from incomplete observations due to occlusion and restricted viewpoints. Numerous methods use a partial-to-complete framework, directly predicting missing components via global characteristics extracted from incomplete inputs. However, this makes detail recovery challenging, as global characteristics fail to provide complete missing component specifics. A new point cloud completion method named Point-PC is proposed. A memory network and a causal inference model are separately designed to introduce shape priors and select absent shape information as supplementary geometric factors for aiding completion. Concretely, a memory mechanism is proposed to store complete shape features and their associated shapes in a key-value format. The authors design a pre-training strategy that uses contrastive learning to map incomplete shape features into the complete shape feature domain, enabling retrieval of analogous shapes from incomplete inputs. In addition, the authors employ backdoor adjustment to eliminate confounders, which are shape prior components sharing identical semantic structures with incomplete inputs. Experiments conducted on three datasets show that our method achieves superior performance compared to state-of-the-art approaches. The code for Point-PC can be accessed by https://github.com/bizbard/Point-PC.git .},
  archive      = {J_CAAITIT},
  author       = {Xuesong Gao and Chuanqi Jiao and Ruidong Chen and Weijie Wang and Weizhi Nie},
  doi          = {10.1049/cit2.12379},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {1007--1018},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Point-PC: Point cloud completion guided by prior knowledge via causal inference},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing patient rehabilitation predictions with a hybrid anomaly detection model: Density-based clustering and interquartile range methods. <em>CAAITIT</em>, <em>10</em>(4), 983--1006. (<a href='https://doi.org/10.1049/cit2.70000'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a concerted effort to improve anomaly detection techniques, particularly in the context of high-dimensional, distributed clinical data. Analysing patient data within clinical settings reveals a pronounced focus on refining diagnostic accuracy, personalising treatment plans, and optimising resource allocation to enhance clinical outcomes. Nonetheless, this domain faces unique challenges, such as irregular data collection, inconsistent data quality, and patient-specific structural variations. This paper proposed a novel hybrid approach that integrates heuristic and stochastic methods for anomaly detection in patient clinical data to address these challenges. The strategy combines HPO-based optimal Density-Based Spatial Clustering of Applications with Noise for clustering patient exercise data, facilitating efficient anomaly identification. Subsequently, a stochastic method based on the Interquartile Range filters unreliable data points, ensuring that medical tools and professionals receive only the most pertinent and accurate information. The primary objective of this study is to equip healthcare professionals and researchers with a robust tool for managing extensive, high-dimensional clinical datasets, enabling effective isolation and removal of aberrant data points. Furthermore, a sophisticated regression model has been developed using Automated Machine Learning (AutoML) to assess the impact of the ensemble abnormal pattern detection approach. Various statistical error estimation techniques validate the efficacy of the hybrid approach alongside AutoML. Experimental results show that implementing this innovative hybrid model on patient rehabilitation data leads to a notable enhancement in AutoML performance, with an average improvement of 0.041 in the score, surpassing the effectiveness of traditional regression models.},
  archive      = {J_CAAITIT},
  author       = {Murad Ali Khan and Jong-Hyun Jang and Naeem Iqbal and Harun Jamil and Syed Shehryar Ali Naqvi and Salabat Khan and Jae-Chul Kim and Do-Hyeun Kim},
  doi          = {10.1049/cit2.70000},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {983--1006},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Enhancing patient rehabilitation predictions with a hybrid anomaly detection model: Density-based clustering and interquartile range methods},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diverse models, united goal: A comprehensive survey of ensemble learning. <em>CAAITIT</em>, <em>10</em>(4), 959--982. (<a href='https://doi.org/10.1049/cit2.70030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning, a pivotal branch of machine learning, amalgamates multiple base models to enhance the overarching performance of predictive models, capitalising on the diversity and collective wisdom of the ensemble to surpass individual models and mitigate overfitting. In this review, a four-layer research framework is established for the research of ensemble learning, which can offer a comprehensive and structured review of ensemble learning from bottom to top. Firstly, this survey commences by introducing fundamental ensemble learning techniques, including bagging, boosting, and stacking, while also exploring the ensemble's diversity. Then, deep ensemble learning and semi-supervised ensemble learning are studied in detail. Furthermore, the utilisation of ensemble learning techniques to navigate challenging datasets, such as imbalanced and high-dimensional data, is discussed. The application of ensemble learning techniques across various research domains, including healthcare, transportation, finance, manufacturing, and the Internet, is also examined. The survey concludes by discussing challenges intrinsic to ensemble learning.},
  archive      = {J_CAAITIT},
  author       = {Ziwei Fan and Zhiwen Yu and Kaixiang Yang and Wuxing Chen and Xiaoqing Liu and Guojie Li and Xianling Yang and C. L. Philip Chen},
  doi          = {10.1049/cit2.70030},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {959--982},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Diverse models, united goal: A comprehensive survey of ensemble learning},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robot manipulation based on embodied visual perception: A survey. <em>CAAITIT</em>, <em>10</em>(4), 945--958. (<a href='https://doi.org/10.1049/cit2.70022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual perception is critical in robotic operations, particularly in collaborative and autonomous robot systems. Through efficient visual systems, robots can acquire and process environmental information in real-time, recognise objects, assess spatial relationships, and make adaptive decisions. This review aims to provide a comprehensive overview of the latest advancements in the field of vision as applied to robotic perception, focusing primarily on visual applications in the areas of object perception, self-perception, human–robot collaboration, and multi-robot collaboration. By summarising the current state of development and analysing the challenges and opportunities that remain in these areas, this paper offers a thorough examination of the integration of visual perception with operational robotics. It further inspires future research and drives the application and development of visual perception across various robotic domains, enabling operational robots to better adapt to complex environments and reliably accomplish tasks.},
  archive      = {J_CAAITIT},
  author       = {Sicheng Wang and Milutin N. Nikolić and Tin Lun Lam and Qing Gao and Runwei Ding and Tianwei Zhang},
  doi          = {10.1049/cit2.70022},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {8},
  number       = {4},
  pages        = {945--958},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Robot manipulation based on embodied visual perception: A survey},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Layer-level adaptive gradient perturbation protecting deep learning based on differential privacy. <em>CAAITIT</em>, <em>10</em>(3), 929--944. (<a href='https://doi.org/10.1049/cit2.70008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning’s widespread dependence on large datasets raises privacy concerns due to the potential presence of sensitive information. Differential privacy stands out as a crucial method for preserving privacy, garnering significant interest for its ability to offer robust and verifiable privacy safeguards during data training. However, classic differentially private learning introduces the same level of noise into the gradients across training iterations, which affects the trade-off between model utility and privacy guarantees. To address this issue, an adaptive differential privacy mechanism was proposed in this paper, which dynamically adjusts the privacy budget at the layer-level as training progresses to resist member inference attacks. Specifically, an equal privacy budget is initially allocated to each layer. Subsequently, as training advances, the privacy budget for layers closer to the output is reduced (adding more noise), while the budget for layers closer to the input is increased. The adjustment magnitude depends on the training iterations and is automatically determined based on the iteration count. This dynamic allocation provides a simple process for adjusting privacy budgets, alleviating the burden on users to tweak parameters and ensuring that privacy preservation strategies align with training progress. Extensive experiments on five well-known datasets indicate that the proposed method outperforms competing methods in terms of accuracy and resilience against membership inference attacks.},
  archive      = {J_CAAITIT},
  author       = {Zhang Xiangfei and Zhang Qingchen and Jiang Liming},
  doi          = {10.1049/cit2.70008},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {929--944},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Layer-level adaptive gradient perturbation protecting deep learning based on differential privacy},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Syn-aug: An effective and general synchronous data augmentation framework for 3D object detection. <em>CAAITIT</em>, <em>10</em>(3), 912--928. (<a href='https://doi.org/10.1049/cit2.70001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation plays an important role in boosting the performance of 3D models, while very few studies handle the 3D point cloud data with this technique. Global augmentation and cut-paste are commonly used augmentation techniques for point clouds, where global augmentation is applied to the entire point cloud of the scene, and cut-paste samples objects from other frames into the current frame. Both types of data augmentation can improve performance, but the cut-paste technique cannot effectively deal with the occlusion relationship between the foreground object and the background scene and the rationality of object sampling, which may be counterproductive and may hurt the overall performance. In addition, LiDAR is susceptible to signal loss, external occlusion, extreme weather and other factors, which can easily cause object shape changes, while global augmentation and cut-paste cannot effectively enhance the robustness of the model. To this end, we propose Syn-Aug, a synchronous data augmentation framework for LiDAR-based 3D object detection. Specifically, we first propose a novel rendering-based object augmentation technique (Ren-Aug) to enrich training data while enhancing scene realism. Second, we propose a local augmentation technique (Local-Aug) to generate local noise by rotating and scaling objects in the scene while avoiding collisions, which can improve generalisation performance. Finally, we make full use of the structural information of 3D labels to make the model more robust by randomly changing the geometry of objects in the training frames. We verify the proposed framework with four different types of 3D object detectors. Experimental results show that our proposed Syn-Aug significantly improves the performance of various 3D object detectors in the KITTI and nuScenes datasets, proving the effectiveness and generality of Syn-Aug. On KITTI, four different types of baseline models using Syn-Aug improved mAP by 0.89%, 1.35%, 1.61% and 1.14% respectively. On nuScenes, four different types of baseline models using Syn-Aug improved mAP by 14.93%, 10.42%, 8.47% and 6.81% respectively. The code is available at https://github.com/liuhuaijjin/Syn-Aug .},
  archive      = {J_CAAITIT},
  author       = {Huaijin Liu and Jixiang Du and Yong Zhang and Hongbo Zhang and Jiandian Zeng},
  doi          = {10.1049/cit2.70001},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {912--928},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Syn-aug: An effective and general synchronous data augmentation framework for 3D object detection},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Molecular retrosynthesis top-K prediction based on the latent generation process. <em>CAAITIT</em>, <em>10</em>(3), 902--911. (<a href='https://doi.org/10.1049/cit2.70005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of organic synthesis, the core objective of retrosynthetic methods is to deduce possible synthetic routes and precursor molecules for complex target molecules. Traditional retrosynthetic methods, such as template-based retrosynthesis, have high accuracy and interpretability in specific types of reactions but are limited by the scope of the template library, making it difficult to adapt to new or uncommon reaction types. Moreover, sequence-to-sequence retrosynthetic prediction methods, although they enhance the flexibility of prediction, often overlook the complexity of molecular graph structures and the actual interactions between atoms, which limits the accuracy and reliability of the predictions. To address these limitations, this paper proposes a Molecular Retrosynthesis Top-k Prediction based on the Latent Generation Process (MRLGP) that uses latent variables from graph neural networks to model the generation process and produce diverse set of reactants. Utilising an encoding method based on Graphormer, the authors have also introduced topology-aware positional encoding to better capture the interactions between atomic nodes in the molecular graph structure, thereby more accurately simulating the retrosynthetic process. The MRLGP model significantly enhances the accuracy and diversity of predictions by correlating discrete latent variables with the reactant generation process and progressively constructing molecular graphs using a variational autoregressive decoder. Experimental results on benchmark datasets such as USPTO-50k, USPTO-Full, and USPTO-DIVERSE demonstrate that MRLGP outperforms baseline models on multiple Top-k evaluation metrics. Additionally, ablation experiments conducted on the USPTO-50K dataset further validate the effectiveness of the methods used in the encoder and decoder parts of the model.},
  archive      = {J_CAAITIT},
  author       = {Yupeng Liu and Han Zhang and Rui Hu},
  doi          = {10.1049/cit2.70005},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {902--911},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Molecular retrosynthesis top-K prediction based on the latent generation process},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topology-aware tensor decomposition for meta-graph learning. <em>CAAITIT</em>, <em>10</em>(3), 891--901. (<a href='https://doi.org/10.1049/cit2.12404'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous graphs generally refer to graphs with different types of nodes and edges. A common approach for extracting useful information from heterogeneous graphs is to use meta-graphs, which can be seen as a special kind of directed acyclic graph with same node and edge types as the heterogeneous graph. However, how to design proper meta-graphs is challenging. Recently, there have been many works on learning suitable meta-graphs from a heterogeneous graph. Existing methods generally introduce continuous weights for edges that are independent of each other, which ignores the topological structures of meta-graphs and can be ineffective. To address this issue, the authors propose a new viewpoint from tensor on learning meta-graphs. Such a viewpoint not only helps interpret the limitation of existing works by CANDECOMP/PARAFAC (CP) decomposition, but also inspires us to propose a topology-aware tensor decomposition, called TENSUS , that reflects the structure of DAGs. The proposed topology-aware tensor decomposition is easy to use and simple to implement, and it can be taken as a plug-in part to upgrade many existing works, including node classification and recommendation on heterogeneous graphs. Experimental results on different tasks demonstrate that the proposed method can significantly improve the state-of-the-arts for all these tasks.},
  archive      = {J_CAAITIT},
  author       = {Hansi Yang and Quanming Yao},
  doi          = {10.1049/cit2.12404},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {891--901},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Topology-aware tensor decomposition for meta-graph learning},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SG-TE: Spatial guidance and temporal enhancement network for facial-bodily emotion recognition. <em>CAAITIT</em>, <em>10</em>(3), 871--890. (<a href='https://doi.org/10.1049/cit2.70006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To overcome the deficiencies of single-modal emotion recognition based on facial expression or bodily posture in natural scenes, a spatial guidance and temporal enhancement (SG-TE) network is proposed for facial-bodily emotion recognition. First, ResNet50, DNN and spatial ransformer models are used to capture facial texture vectors, bodily skeleton vectors and whole-body geometric vectors, and an intraframe correlation attention guidance (S-CAG) mechanism, which guides the facial texture vector and the bodily skeleton vector by the whole-body geometric vector, is designed to exploit the spatial potential emotional correlation between face and posture. Second, an interframe significant segment enhancement (T-SSE) structure is embedded into a temporal transformer to enhance high emotional intensity frame information and avoid emotional asynchrony. Finally, an adaptive weight assignment (M-AWA) strategy is constructed to realise facial-bodily fusion. The experimental results on the BabyRobot Emotion Dataset (BRED) and Context-Aware Emotion Recognition (CAER) dataset indicate that the proposed network reaches accuracies of 81.61% and 89.39%, which are 9.61% and 9.46% higher than those of the baseline network, respectively. Compared with the state-of-the-art methods, the proposed method achieves 7.73% and 20.57% higher accuracy than single-modal methods based on facial expression or bodily posture, respectively, and 2.16% higher accuracy than the dual-modal methods based on facial-bodily fusion. Therefore, the proposed method, which adaptively fuses the complementary information of face and posture, improves the quality of emotion recognition in real-world scenarios.},
  archive      = {J_CAAITIT},
  author       = {Zhong Huang and Danni Zhang and Fuji Ren and Min Hu and Juan Liu and Haitao Yu},
  doi          = {10.1049/cit2.70006},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {871--890},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {SG-TE: Spatial guidance and temporal enhancement network for facial-bodily emotion recognition},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometry-enhanced implicit function for detailed clothed human reconstruction with RGB-D input. <em>CAAITIT</em>, <em>10</em>(3), 858--870. (<a href='https://doi.org/10.1049/cit2.70009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Realistic human reconstruction embraces an extensive range of applications as depth sensors advance. However, current state-of-the-art methods with RGB-D input still suffer from artefacts, such as noisy surfaces, non-human shapes, and depth ambiguity, especially for the invisible parts. The authors observe the main issue is the lack of geometric semantics without using depth input priors fully. This paper focuses on improving the representation ability of implicit function, exploring an effective method to utilise depth-related semantics effectively and efficiently. The proposed geometry-enhanced implicit function enhances the geometric semantics with the extra voxel-aligned features from point clouds, promoting the completion of missing parts for unseen regions while preserving the local details on the input. For incorporating multi-scale pixel-aligned and voxel-aligned features, the authors use the Squeeze-and-Excitation attention to capture and fully use channel interdependencies. For the multi-view reconstruction, the proposed depth-enhanced attention explicitly excites the network to “sense” the geometric structure for a more reasonable feature aggregation. Experiments and results show that our method outperforms current RGB and depth-based SOTA methods on the challenging data from Twindom and Thuman3.0, and achieves a detailed and completed human reconstruction, balancing performance and efficiency well.},
  archive      = {J_CAAITIT},
  author       = {Pengpeng Liu and Zhi Zeng and Qisheng Wang and Min Chen and Guixuan Zhang},
  doi          = {10.1049/cit2.70009},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {858--870},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Geometry-enhanced implicit function for detailed clothed human reconstruction with RGB-D input},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An EfficientNet integrated ResNet deep network and explainable AI for breast lesion classification from ultrasound images. <em>CAAITIT</em>, <em>10</em>(3), 842--857. (<a href='https://doi.org/10.1049/cit2.12385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is one of the major causes of deaths in women. However, the early diagnosis is important for screening and control the mortality rate. Thus for the diagnosis of breast cancer at the early stage, a computer-aided diagnosis system is highly required. Ultrasound is an important examination technique for breast cancer diagnosis due to its low cost. Recently, many learning-based techniques have been introduced to classify breast cancer using breast ultrasound imaging dataset (BUSI) datasets; however, the manual handling is not an easy process and time consuming. The authors propose an EfficientNet-integrated ResNet deep network and XAI-based framework for accurately classifying breast cancer (malignant and benign). In the initial step, data augmentation is performed to increase the number of training samples. For this purpose, three-pixel flip mathematical equations are introduced: horizontal, vertical, and 90°. Later, two pre-trained deep learning models were employed, skipped some layers, and fine-tuned. Both fine-tuned models are later trained using a deep transfer learning process and extracted features from the deeper layer. Explainable artificial intelligence-based analysed the performance of trained models. After that, a new feature selection technique is proposed based on the cuckoo search algorithm called cuckoo search controlled standard error mean. This technique selects the best features and fuses using a new parallel zero-padding maximum correlated coefficient features. In the end, the selection algorithm is applied again to the fused feature vector and classified using machine learning algorithms. The experimental process of the proposed framework is conducted on a publicly available BUSI and obtained 98.4% and 98% accuracy in two different experiments. Comparing the proposed framework is also conducted with recent techniques and shows improved accuracy. In addition, the proposed framework was executed less than the original deep learning models.},
  archive      = {J_CAAITIT},
  author       = {Kiran Jabeen and Muhammad Attique Khan and Ameer Hamza and Hussain Mobarak Albarakati and Shrooq Alsenan and Usman Tariq and Isaac Ofori},
  doi          = {10.1049/cit2.12385},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {842--857},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {An EfficientNet integrated ResNet deep network and explainable AI for breast lesion classification from ultrasound images},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Appearance consistency and motion coherence learning for internal video inpainting. <em>CAAITIT</em>, <em>10</em>(3), 827--841. (<a href='https://doi.org/10.1049/cit2.12405'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internal learning-based video inpainting methods have shown promising results by exploiting the intrinsic properties of the video to fill in the missing region without external dataset supervision. However, existing internal learning-based video inpainting methods would produce inconsistent structures or blurry textures due to the insufficient utilisation of motion priors within the video sequence. In this paper, the authors propose a new internal learning-based video inpainting model called appearance consistency and motion coherence network (ACMC-Net), which can not only learn the recurrence of appearance prior but can also capture motion coherence prior to improve the quality of the inpainting results. In ACMC-Net, a transformer-based appearance network is developed to capture global context information within the video frame for representing appearance consistency accurately. Additionally, a novel motion coherence learning scheme is proposed to learn the motion prior in a video sequence effectively. Finally, the learnt internal appearance consistency and motion coherence are implicitly propagated to the missing regions to achieve inpainting well. Extensive experiments conducted on the DAVIS dataset show that the proposed model obtains the superior performance in terms of quantitative measurements and produces more visually plausible results compared with the state-of-the-art methods.},
  archive      = {J_CAAITIT},
  author       = {Ruixin Liu and Yuesheng Zhu and GuiBo Luo},
  doi          = {10.1049/cit2.12405},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {827--841},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Appearance consistency and motion coherence learning for internal video inpainting},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extrapolation reasoning on temporal knowledge graphs via temporal dependencies learning. <em>CAAITIT</em>, <em>10</em>(3), 815--826. (<a href='https://doi.org/10.1049/cit2.70013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extrapolation on Temporal Knowledge Graphs (TKGs) aims to predict future knowledge from a set of historical Knowledge Graphs in chronological order. The temporally adjacent facts in TKGs naturally form event sequences, called event evolution patterns, implying informative temporal dependencies between events. Recently, many extrapolation works on TKGs have been devoted to modelling these evolutional patterns, but the task is still far from resolved because most existing works simply rely on encoding these patterns into entity representations while overlooking the significant information implied by relations of evolutional patterns. However, the authors realise that the temporal dependencies inherent in the relations of these event evolution patterns may guide the follow-up event prediction to some extent. To this end, a T emporal Re lational Co n text-based Temporal D ependencies Learning Network (TRenD) is proposed to explore the temporal context of relations for more comprehensive learning of event evolution patterns, especially those temporal dependencies caused by interactive patterns of relations. Trend incorporates a semantic context unit to capture semantic correlations between relations, and a structural context unit to learn the interaction pattern of relations. By learning the temporal contexts of relations semantically and structurally, the authors gain insights into the underlying event evolution patterns, enabling to extract comprehensive historical information for future prediction better. Experimental results on benchmark datasets demonstrate the superiority of the model.},
  archive      = {J_CAAITIT},
  author       = {Ye Wang and Binxing Fang and Shuxian Huang and Kai Chen and Yan Jia and Aiping Li},
  doi          = {10.1049/cit2.70013},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {815--826},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Extrapolation reasoning on temporal knowledge graphs via temporal dependencies learning},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal performance design of bat algorithm: An adaptive multi-stage structure. <em>CAAITIT</em>, <em>10</em>(3), 755--814. (<a href='https://doi.org/10.1049/cit2.12377'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bat algorithm (BA) is a metaheuristic algorithm for global optimisation that simulates the echolocation behaviour of bats with varying pulse rates of emission and loudness, which can be used to find the globally optimal solutions for various optimisation problems. Knowing the recent criticises of the originality of equations, the principle of BA is concise and easy to implement, and its mathematical structure can be seen as a hybrid particle swarm with simulated annealing. In this research, the authors focus on the performance optimisation of BA as a solver rather than discussing its originality issues. In terms of operation effect, BA has an acceptable convergence speed. However, due to the low proportion of time used to explore the search space, it is easy to converge prematurely and fall into the local optima. The authors propose an adaptive multi-stage bat algorithm (AMSBA). By tuning the algorithm's focus at three different stages of the search process, AMSBA can achieve a better balance between exploration and exploitation and improve its exploration ability by enhancing its performance in escaping local optima as well as maintaining a certain convergence speed. Therefore, AMSBA can achieve solutions with better quality. A convergence analysis was conducted to demonstrate the global convergence of AMSBA. The authors also perform simulation experiments on 30 benchmark functions from IEEE CEC 2017 as the objective functions and compare AMSBA with some original and improved swarm-based algorithms. The results verify the effectiveness and superiority of AMSBA. AMSBA is also compared with eight representative optimisation algorithms on 10 benchmark functions derived from IEEE CEC 2020, while this experiment is carried out on five different dimensions of the objective functions respectively. A balance and diversity analysis was performed on AMSBA to demonstrate its improvement over the original BA in terms of balance. AMSBA was also applied to the multi-threshold image segmentation of Citrus Macular disease, which is a bacterial infection that causes lesions on citrus trees. The segmentation results were analysed by comparing each comparative algorithm's peak signal-to-noise ratio, structural similarity index and feature similarity index. The results show that the proposed BA-based algorithm has apparent advantages, and it can effectively segment the disease spots from citrus leaves when the segmentation threshold is at a low level. Based on a comprehensive study, the authors think the proposed optimiser has mitigated the main drawbacks of the BA, and it can be utilised as an effective optimisation tool.},
  archive      = {J_CAAITIT},
  author       = {Helong Yu and Jiuman Song and Chengcheng Chen and Ali Asghar Heidari and Yuntao Ma and Huiling Chen and Yudong Zhang},
  doi          = {10.1049/cit2.12377},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {755--814},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Optimal performance design of bat algorithm: An adaptive multi-stage structure},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A demonstration trajectory segmentation approach for wheelchair-mounted assistive robots. <em>CAAITIT</em>, <em>10</em>(3), 738--754. (<a href='https://doi.org/10.1049/cit2.12358'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation of demonstration trajectories and learning the contained motion primitives can effectively enhance the assistive robot's intelligence to flexibly reproduce learnt tasks in an unstructured environment. With the aim to conveniently and accurately segment demonstration trajectories, a novel demonstration trajectory segmentation approach is proposed based on the beta process autoregressive hidden Markov model (BP-AR-HMM) algorithm and generalised time warping (GTW) algorithm aiming to enhance the segmentation accuracy utilising acquired demonstration data. This approach first adopts the GTW algorithm to align the multiple demonstration trajectories for the same task. Then, it adopts the BP-AR-HMM algorithm to segment the demonstration trajectories, acquire the contained motion primitives, and establish the related task library. This segmentation approach is validated on the 6-degree-of-freedom JACO robotic arm by assisting users to accomplish a holding water glass task and an eating task. The experimental results show that the motion primitives within the trajectories can be correctly segmented with a high segmentation accuracy.},
  archive      = {J_CAAITIT},
  author       = {Mingshan Chi and Yaxin Liu and Qiang Zhang and Chao Zeng},
  doi          = {10.1049/cit2.12358},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {738--754},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A demonstration trajectory segmentation approach for wheelchair-mounted assistive robots},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rehabilitation exoskeleton system with bidirectional virtual reality feedback training strategy. <em>CAAITIT</em>, <em>10</em>(3), 728--737. (<a href='https://doi.org/10.1049/cit2.12391'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual reality (VR) technology revitalises rehabilitation training by creating rich, interactive virtual rehabilitation scenes and tasks that deeply engage patients. Robotics with immersive VR environments have the potential to significantly enhance the sense of immersion for patients during training. This paper proposes a rehabilitation robot system. The system integrates a VR environment, the exoskeleton entity, and research on rehabilitation assessment metrics derived from surface electromyographic signal (sEMG). Employing more realistic and engaging virtual stimuli, this method guides patients to actively participate, thereby enhancing the effectiveness of neural connection reconstruction—an essential aspect of rehabilitation. Furthermore, this study introduces a muscle activation model that merges linear and non-linear states of muscle, avoiding the impact of non-linear shape factors on model accuracy present in traditional models. A muscle strength assessment model based on optimised generalised regression (WOA-GRNN) is also proposed, with a root mean square error of 0.017,347 and a mean absolute percentage error of 1.2461%, serving as critical assessment indicators for the effectiveness of rehabilitation. Finally, the system is preliminarily applied in human movement experiments, validating the practicality and potential effectiveness of VR-centred rehabilitation strategies in medical recovery.},
  archive      = {J_CAAITIT},
  author       = {Yongsheng Gao and Guodong Lang and Chenxiao Zhang and Rui Wu and Yanhe Zhu and Yu Zhao and Jie Zhao},
  doi          = {10.1049/cit2.12391},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {728--737},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Rehabilitation exoskeleton system with bidirectional virtual reality feedback training strategy},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A method for automatic feature points extraction of pelvic surface based on PointMLP_RegNet. <em>CAAITIT</em>, <em>10</em>(3), 716--727. (<a href='https://doi.org/10.1049/cit2.70003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of robot-assisted pelvic fracture reduction surgery heavily relies on the accuracy of 3D/3D feature-based registration. This process involves extracting anatomical feature points from pre-operative 3D images which can be challenging because of the complex and variable structure of the pelvis. PointMLP_RegNet, a modified PointMLP, was introduced to address this issue. It retains the feature extraction module of PointMLP but replaces the classification layer with a regression layer to predict the coordinates of feature points instead of conducting regular classification. A flowchart for an automatic feature points extraction method was presented, and a series of experiments was conducted on a clinical pelvic dataset to confirm the accuracy and effectiveness of the method. PointMLP_RegNet extracted feature points more accurately, with 8 out of 10 points showing less than 4 mm errors and the remaining two less than 5 mm. Compared to PointNet++ and PointNet, it exhibited higher accuracy, robustness and space efficiency. The proposed method will improve the accuracy of anatomical feature points extraction, enhance intra-operative registration precision and facilitate the widespread clinical application of robot-assisted pelvic fracture reduction.},
  archive      = {J_CAAITIT},
  author       = {Wei Kou and Rui Zhou and Hongmiao Zhang and Jianwen Cheng and Chi Zhu and Shaolong Kuang and Lihai Zhang and Lining Sun},
  doi          = {10.1049/cit2.70003},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {716--727},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A method for automatic feature points extraction of pelvic surface based on PointMLP_RegNet},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Needle detection and localisation for robot-assisted subretinal injection using deep learning. <em>CAAITIT</em>, <em>10</em>(3), 703--715. (<a href='https://doi.org/10.1049/cit2.12242'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subretinal injection is a complicated task for retinal surgeons to operate manually. In this paper we demonstrate a robust framework for needle detection and localisation in robot-assisted subretinal injection using microscope-integrated Optical Coherence Tomography with deep learning. Five convolutional neural networks with different architectures were evaluated. The main differences between the architectures are the amount of information they receive at the input layer. When evaluated on ex-vivo pig eyes, the top performing network successfully detected all needles in the dataset and localised them with an Intersection over Union value of 0.55. The algorithm was evaluated by comparing the depth of the top and bottom edge of the predicted bounding box to the ground truth. This analysis showed that the top edge can be used to predict the depth of the needle with a maximum error of 8.5 μm.},
  archive      = {J_CAAITIT},
  author       = {Mingchuan Zhou and Xiangyu Guo and Matthias Grimm and Elias Lochner and Zhongliang Jiang and Abouzar Eslami and Juan Ye and Nassir Navab and Alois Knoll and Mohammad Ali Nasseri},
  doi          = {10.1049/cit2.12242},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {703--715},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Needle detection and localisation for robot-assisted subretinal injection using deep learning},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Segmentation versus detection: Development and evaluation of deep learning models for prostate imaging reporting and data system lesions localisation on bi-parametric prostate magnetic resonance imaging. <em>CAAITIT</em>, <em>10</em>(3), 689--702. (<a href='https://doi.org/10.1049/cit2.12318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated prostate cancer detection in magnetic resonance imaging (MRI) scans is of significant importance for cancer patient management. Most existing computer-aided diagnosis systems adopt segmentation methods while object detection approaches recently show promising results. The authors have (1) carefully compared performances of most-developed segmentation and object detection methods in localising prostate imaging reporting and data system (PIRADS)-labelled prostate lesions on MRI scans; (2) proposed an additional customised set of lesion-level localisation sensitivity and precision; (3) proposed efficient ways to ensemble the segmentation and object detection methods for improved performances. The ground-truth (GT) perspective lesion-level sensitivity and prediction-perspective lesion-level precision are reported, to quantify the ratios of true positive voxels being detected by algorithms over the number of voxels in the GT labelled regions and predicted regions. The two networks are trained independently on 549 clinical patients data with PIRADS-V2 as GT labels, and tested on 161 internal and 100 external MRI scans. At the lesion level, nnDetection outperforms nnUNet for detecting both PIRADS ≥ 3 and PIRADS ≥ 4 lesions in majority cases. For example, at the average false positive prediction per patient being 3, nnDetection achieves a greater Intersection-of-Union (IoU)-based sensitivity than nnUNet for detecting PIRADS ≥ 3 lesions, being 80.78% ± 1.50% versus 60.40% ± 1.64% ( p < 0.01). At the voxel level, nnUnet is in general superior or comparable to nnDetection. The proposed ensemble methods achieve improved or comparable lesion-level accuracy, in all tested clinical scenarios. For example, at 3 false positives, the lesion-wise ensemble method achieves 82.24% ± 1.43% sensitivity versus 80.78% ± 1.50% (nnDetection) and 60.40% ± 1.64% (nnUNet) for detecting PIRADS ≥ 3 lesions. Consistent conclusions are also drawn from results on the external data set.},
  archive      = {J_CAAITIT},
  author       = {Zhe Min and Fernando J. Bianco and Qianye Yang and Wen Yan and Ziyi Shen and David Cohen and Rachael Rodell and Dean C. Barratt and Yipeng Hu},
  doi          = {10.1049/cit2.12318},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {689--702},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Segmentation versus detection: Development and evaluation of deep learning models for prostate imaging reporting and data system lesions localisation on bi-parametric prostate magnetic resonance imaging},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Processing water-medium spinal endoscopic images based on dual transmittance. <em>CAAITIT</em>, <em>10</em>(3), 678--688. (<a href='https://doi.org/10.1049/cit2.70016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time water-medium endoscopic images can assist doctors in performing operations such as tissue cleaning and nucleus pulpous removal. During medical operating procedures, it is inevitable that tissue particles, debris and other contaminants will be suspended within the viewing area, resulting in blurred images and the loss of surface details in biological tissues. Currently, few studies have focused on enhancing such endoscopic images. This paper proposes a water-medium endoscopic image processing method based on dual transmittance in accordance with the imaging characteristics of spinal endoscopy. By establishing an underwater imaging model for spinal endoscopy, we estimate the transmittance of the endoscopic images based on the boundary constraints and local image contrast. The two transmittances are then fused and combined with transmittance maps and ambient light estimations to restore the images before attenuation, ultimately enhancing the details and texture of the images. Experiments comparing classical image enhancement algorithms demonstrate that the proposed algorithm could effectively improve the quality of spinal endoscopic images.},
  archive      = {J_CAAITIT},
  author       = {Ning Hu and Qing Zhang},
  doi          = {10.1049/cit2.70016},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {678--688},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Processing water-medium spinal endoscopic images based on dual transmittance},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A human-robot collaboration method for uncertain surface scanning. <em>CAAITIT</em>, <em>10</em>(3), 666--677. (<a href='https://doi.org/10.1049/cit2.12227'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots are increasingly expected to replace humans in many repetitive and high-precision tasks, of which surface scanning is a typical example. However, it is usually difficult for a robot to independently deal with a surface scanning task with uncertainties in, for example the irregular surface shapes and surface properties. Moreover, it usually requires surface modelling with additional sensors, which might be time-consuming and costly. A human-robot collaboration-based approach that allows a human user and a robot to assist each other in scanning uncertain surfaces with uniform properties, such as scanning human skin in ultrasound examination is proposed. In this approach, teleoperation is used to obtain the operator's intent while allowing the operator to operate remotely. After external force perception and friction estimation, the orientation of the robot end-effector can be autonomously adjusted to keep as perpendicular to the surface as possible. Force control enables the robotic manipulator to maintain a constant contact force with the surface. And hybrid force/motion control ensures that force, position, and pose can be regulated without interfering with each other while reducing the operator's workload. The proposed method is validated using the Elite robot to perform a mock B-ultrasound scanning experiment.},
  archive      = {J_CAAITIT},
  author       = {Guanyi Zhao and Chao Zeng and Weiyong Si and Chenguang Yang},
  doi          = {10.1049/cit2.12227},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {666--677},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A human-robot collaboration method for uncertain surface scanning},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AESR3D: 3D overcomplete autoencoder for trabecular computed tomography super resolution. <em>CAAITIT</em>, <em>10</em>(3), 652--665. (<a href='https://doi.org/10.1049/cit2.12167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Osteoporosis is a major cause of bone fracture and can be characterised by both mass loss and microstructure deterioration of the bone. The modern way of osteoporosis assessment is through the measurement of bone mineral density, which is not able to unveil the pathological condition from the mesoscale aspect. To obtain mesoscale information from computed tomography (CT), the super-resolution (SR) approach for volumetric imaging data is required. A deep learning model AESR3D is proposed to recover high-resolution (HR) Micro-CT from low-resolution Micro-CT and implement an unsupervised segmentation for better trabecular observation and measurement. A new regularisation overcomplete autoencoder framework for the SR task is proposed and theoretically analysed. The best performance is achieved on structural similarity measure of trabecular CT SR task compared with the state-of-the-art models in both natural and medical image SR tasks. The HR and SR images show a high correlation ( r = 0.996, intraclass correlation coefficients = 0.917) on trabecular bone morphological indicators. The results also prove the effectiveness of our regularisation framework when training a large capacity model.},
  archive      = {J_CAAITIT},
  author       = {Shuwei Zhang and Yefeng Liang and Xingyu Li and Shibo Li and Xiaofeng Xiong and Lihai Zhang},
  doi          = {10.1049/cit2.12167},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {652--665},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {AESR3D: 3D overcomplete autoencoder for trabecular computed tomography super resolution},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model adaptation via credible local context representation. <em>CAAITIT</em>, <em>10</em>(3), 638--651. (<a href='https://doi.org/10.1049/cit2.12228'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional model transfer techniques, requiring the labelled source data, are not applicable in the privacy-protected medical fields. For the challenging scenarios, recent source data-free domain adaptation (SFDA) has become a mainstream solution but losing focus on the inter-sample class information. This paper proposes a new Credible Local Context Representation approach for SFDA. Our main idea is to exploit the credible local context for more discriminative representation. Specifically, we enhance the source model's discrimination by information regulating. To capture the context, a discovery method is developed that performs fixed steps walking in deep space and takes the credible features in this path as the context. In the epoch-wise adaptation, deep clustering-like training is conducted with two major updates. First, the context for all target data is constructed and then the context-fused pseudo-labels providing semantic guidance are generated. Second, for each target data, a weighting fusion on its context forms the anchored neighbourhood structure; thus, the deep clustering is switched from individual-based to coarse-grained. Also, a new regularisation building is developed on the anchored neighbourhood to drive the deep coarse-grained learning. Experiments on three benchmarks indicate that the proposed method can achieve state-of-the-art results.},
  archive      = {J_CAAITIT},
  author       = {Song Tang and Wenxin Su and Yan Yang and Lijuan Chen and Mao Ye},
  doi          = {10.1049/cit2.12228},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {6},
  number       = {3},
  pages        = {638--651},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Model adaptation via credible local context representation},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to ‘Trustworthy semi-supervised anomaly detection for online-to-offline logistics business in merchant identification’. <em>CAAITIT</em>, <em>10</em>(2), 634. (<a href='https://doi.org/10.1049/cit2.12392'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CAAITIT},
  doi          = {10.1049/cit2.12392},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {634},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Correction to ‘Trustworthy semi-supervised anomaly detection for online-to-offline logistics business in merchant identification’},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to DeepCNN: Spectro-temporal feature representation for speech emotion recognition. <em>CAAITIT</em>, <em>10</em>(2), 633. (<a href='https://doi.org/10.1049/cit2.12371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CAAITIT},
  doi          = {10.1049/cit2.12371},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {633},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Correction to DeepCNN: Spectro-temporal feature representation for speech emotion recognition},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph neural link predictor based on cycle structure. <em>CAAITIT</em>, <em>10</em>(2), 615--632. (<a href='https://doi.org/10.1049/cit2.12396'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the link prediction algorithms primarily focus on studying the interaction between nodes based on chain structure and star structure, which predominantly rely on low-order structural information and do not explore the multivariate interactions between nodes from the perspective of higher-order structural information present in the network. The cycle structure is a higher-order structure that lies between the star and clique structures, where all nodes within the same cycle can interact with each other, even in the absence of direct edges. If a node is encompassed by multiple cycles, it indicates that the node interacts and associates with a greater number of nodes in the network, and it means the node is more important in the network to some extent. Furthermore, if two nodes are included in multiple cycles, it signifies the two nodes are more likely to be connected. Therefore, firstly, a multi-information fusion node importance algorithm based on the cycle structure information is proposed, which integrates both high-order and low-order structural information. Secondly, the obtained integrated structure information and node feature information is regarded as the input features, a two-channel graph neural network model is designed to learn the cycle structure information. Then, the cycle structure information is utilised for the task of link prediction, and a graph neural link predictor with multi-information interactions based on the cycle structure is developed. Finally, extensive experimental validation and analysis show that the node ranking result of the proposed node importance index is more consistent with the actual situation, the proposed graph neural network model can effectively learn the cycle structure information, and using higher-order structural information—cycle information proves to significantly enhance the overall link prediction performance.},
  archive      = {J_CAAITIT},
  author       = {Yanlin Yang and Zhonglin Ye and Lei Meng and Mingyuan Li and Haixing Zhao},
  doi          = {10.1049/cit2.12396},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {615--632},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Graph neural link predictor based on cycle structure},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topological search and gradient descent boosted Runge–Kutta optimiser with application to engineering design and feature selection. <em>CAAITIT</em>, <em>10</em>(2), 557--614. (<a href='https://doi.org/10.1049/cit2.12387'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Runge–Kutta optimiser (RUN) algorithm, renowned for its powerful optimisation capabilities, faces challenges in dealing with increasing complexity in real-world problems. Specifically, it shows deficiencies in terms of limited local exploration capabilities and less precise solutions. Therefore, this research aims to integrate the topological search (TS) mechanism with the gradient search rule (GSR) into the framework of RUN, introducing an enhanced algorithm called TGRUN to improve the performance of the original algorithm. The TS mechanism employs a circular topological scheme to conduct a thorough exploration of solution regions surrounding each solution, enabling a careful examination of valuable solution areas and enhancing the algorithm’s effectiveness in local exploration. To prevent the algorithm from becoming trapped in local optima, the GSR also integrates gradient descent principles to direct the algorithm in a wider investigation of the global solution space. This study conducted a serious of experiments on the IEEE CEC2017 comprehensive benchmark function to assess the enhanced effectiveness of TGRUN. Additionally, the evaluation includes real-world engineering design and feature selection problems serving as an additional test for assessing the optimisation capabilities of the algorithm. The validation outcomes indicate a significant improvement in the optimisation capabilities and solution accuracy of TGRUN.},
  archive      = {J_CAAITIT},
  author       = {Jinge Shi and Yi Chen and Ali Asghar Heidari and Zhennao Cai and Huiling Chen and Guoxi Liang},
  doi          = {10.1049/cit2.12387},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {557--614},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Topological search and gradient descent boosted Runge–Kutta optimiser with application to engineering design and feature selection},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Laplacian attention: A plug-and-play algorithm without increasing model complexity for vision tasks. <em>CAAITIT</em>, <em>10</em>(2), 545--556. (<a href='https://doi.org/10.1049/cit2.12402'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most prevailing attention mechanism modules in contemporary research are convolution-based modules, and while these modules contribute to enhancing the accuracy of deep learning networks in visual tasks, they concurrently augment the overall model complexity. To address the problem, this paper proposes a plug-and-play algorithm that does not increase the complexity of the model, Laplacian attention (LA). The LA algorithm first calculates the similarity distance between feature points in the feature space and feature channel and constructs the residual Laplacian matrix between feature points through the similarity distance and Gaussian kernel. This construction serves to segregate non-similar feature points while aggregating those with similarities. Ultimately, the LA algorithm allocates the outputs of the feature channel and the feature space adaptively to derive the final LA outputs. Crucially, the LA algorithm is confined to the forward computation process and does not involve backpropagation or any parameter learning. The LA algorithm undergoes comprehensive experimentation on three distinct datasets—namely Cifar-10, miniImageNet, and Pascal VOC 2012. The experimental results demonstrate that, compared with the advanced attention mechanism modules in recent years, such as SENet, CBAM, ECANet, coordinate attention, and triplet attention, the LA algorithm exhibits superior performance across image classification, object detection and semantic segmentation tasks.},
  archive      = {J_CAAITIT},
  author       = {Xiaolei Chen and Yubing Lu and Runyu Wen},
  doi          = {10.1049/cit2.12402},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {545--556},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Laplacian attention: A plug-and-play algorithm without increasing model complexity for vision tasks},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Random strip peeling: A novel lightweight image encryption for IoT devices based on colour planes permutation. <em>CAAITIT</em>, <em>10</em>(2), 529--544. (<a href='https://doi.org/10.1049/cit2.12401'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel lightweight colour image encryption algorithm, specifically designed for resource-constrained environments such as Internet of Things (IoT) devices. As IoT systems become increasingly prevalent, secure and efficient data transmission becomes crucial. The proposed algorithm addresses this need by offering a robust yet resource-efficient solution for image encryption. Traditional image encryption relies on confusion and diffusion steps. These stages are generally implemented linearly, but this work introduces a new RSP (Random Strip Peeling) algorithm for the confusion step, which disrupts linearity in the lightweight category by using two different sequences generated by the 1D Tent Map with varying initial conditions. The diffusion stage then employs an XOR matrix generated by the Logistic Map. Different evaluation metrics, such as entropy analysis, key sensitivity, statistical and differential attacks resistance, and robustness analysis demonstrate the proposed algorithm's lightweight, robust, and efficient. The proposed encryption scheme achieved average metric values of 99.6056 for NPCR, 33.4397 for UACI, and 7.9914 for information entropy in the SIPI image dataset. It also exhibits a time complexity of for an image of size .},
  archive      = {J_CAAITIT},
  author       = {Kenan İnce and Cemile İnce and Davut Hanbay},
  doi          = {10.1049/cit2.12401},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {529--544},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Random strip peeling: A novel lightweight image encryption for IoT devices based on colour planes permutation},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning-based tracking control of AUV: Mixed policy improvement and game-based disturbance rejection. <em>CAAITIT</em>, <em>10</em>(2), 510--528. (<a href='https://doi.org/10.1049/cit2.12372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A mixed adaptive dynamic programming (ADP) scheme based on zero-sum game theory is developed to address optimal control problems of autonomous underwater vehicle (AUV) systems subject to disturbances and safe constraints. By combining prior dynamic knowledge and actual sampled data, the proposed approach effectively mitigates the defect caused by the inaccurate dynamic model and significantly improves the training speed of the ADP algorithm. Initially, the dataset is enriched with sufficient reference data collected based on a nominal model without considering modelling bias. Also, the control object interacts with the real environment and continuously gathers adequate sampled data in the dataset. To comprehensively leverage the advantages of model-based and model-free methods during training, an adaptive tuning factor is introduced based on the dataset that possesses model-referenced information and conforms to the distribution of the real-world environment, which balances the influence of model-based control law and data-driven policy gradient on the direction of policy improvement. As a result, the proposed approach accelerates the learning speed compared to data-driven methods, concurrently also enhancing the tracking performance in comparison to model-based control methods. Moreover, the optimal control problem under disturbances is formulated as a zero-sum game, and the actor-critic-disturbance framework is introduced to approximate the optimal control input, cost function, and disturbance policy, respectively. Furthermore, the convergence property of the proposed algorithm based on the value iteration method is analysed. Finally, an example of AUV path following based on the improved line-of-sight guidance is presented to demonstrate the effectiveness of the proposed method.},
  archive      = {J_CAAITIT},
  author       = {Jun Ye and Hongbo Gao and Manjiang Hu and Yougang Bian and Qingjia Cui and Xiaohui Qin and Rongjun Ding},
  doi          = {10.1049/cit2.12372},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {510--528},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Learning-based tracking control of AUV: Mixed policy improvement and game-based disturbance rejection},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clustering-based recommendation method with enhanced grasshopper optimisation algorithm. <em>CAAITIT</em>, <em>10</em>(2), 494--509. (<a href='https://doi.org/10.1049/cit2.12408'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, personalised recommendation systems are essential for enhancing user engagement and driving business growth. However, traditional recommendation algorithms, such as collaborative filtering, face significant challenges due to data sparsity, algorithm scalability, and the difficulty of adapting to dynamic user preferences. These limitations hinder the ability of systems to provide highly accurate and personalised recommendations. To address these challenges, this paper proposes a clustering-based recommendation method that integrates an enhanced Grasshopper Optimisation Algorithm (GOA), termed LCGOA, to improve the accuracy and efficiency of recommendation systems by optimising cluster centroids in a dynamic environment. By combining the K-means algorithm with the enhanced GOA, which incorporates a Lévy flight mechanism and multi-strategy co-evolution, our method overcomes the centroid sensitivity issue, a key limitation in traditional clustering techniques. Experimental results across multiple datasets show that the proposed LCGOA-based method significantly outperforms conventional recommendation algorithms in terms of recommendation accuracy, offering more relevant content to users and driving greater customer satisfaction and business growth.},
  archive      = {J_CAAITIT},
  author       = {Zihao Zhao and Yingchun Xia and Wenjun Xu and Hui Yu and Shuai Yang and Cheng Chen and Xiaohui Yuan and Xiaobo Zhou and Qingyong Wang and Lichuan Gu},
  doi          = {10.1049/cit2.12408},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {494--509},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Clustering-based recommendation method with enhanced grasshopper optimisation algorithm},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing skin cancer detection integrating a novel unsupervised classification and enhanced imaging techniques. <em>CAAITIT</em>, <em>10</em>(2), 474--493. (<a href='https://doi.org/10.1049/cit2.12410'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer, a severe health threat, can spread rapidly if undetected. Therefore, early detection can lead to an advanced and efficient diagnosis, thus reducing mortality. Unsupervised classification techniques analyse extensive skin image datasets, identifying patterns and anomalies without prior labelling, facilitating early detection and effective diagnosis and potentially saving lives. In this study, the authors aim to explore the potential of unsupervised learning methods in classifying different types of skin lesions in dermatoscopic images. The authors aim to bridge the gap in dermatological research by introducing innovative techniques that enhance image quality and improve feature extraction. To achieve this, enhanced super-resolution generative adversarial networks (ESRGAN) was fine-tuned to strengthen the resolution of skin lesion images, making critical features more visible. The authors extracted histogram features to capture essential colour characteristics and used the Davies–Bouldin index and silhouette score to determine optimal clusters. Fine-tuned k-means clustering with Euclidean distance in the histogram feature space achieved 87.77% and 90.5% test accuracies on the ISIC2019 and HAM10000 datasets, respectively. The unsupervised approach effectively categorises skin lesions, indicating that unsupervised learning can significantly advance dermatology by enabling early detection and classification without extensive manual annotation.},
  archive      = {J_CAAITIT},
  author       = {Md. Abdur Rahman and Nur Mohammad Fahad and Mohaimenul Azam Khan Raiaan and Mirjam Jonkman and Friso De Boer and Sami Azam},
  doi          = {10.1049/cit2.12410},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {474--493},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Advancing skin cancer detection integrating a novel unsupervised classification and enhanced imaging techniques},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RJAN: Region-based joint attention network for 3D shape recognition. <em>CAAITIT</em>, <em>10</em>(2), 460--473. (<a href='https://doi.org/10.1049/cit2.12388'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CAAITIT},
  author       = {Yue Zhao and Weizhi Nie and Jie Nie and Yuyi Zhang and Bo Wang},
  doi          = {10.1049/cit2.12388},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {460--473},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {RJAN: Region-based joint attention network for 3D shape recognition},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive learning for nested chinese named entity recognition via template words. <em>CAAITIT</em>, <em>10</em>(2), 450--459. (<a href='https://doi.org/10.1049/cit2.12403'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Chinese named entity recognition (NER) research utilises 1D lexicon-based sequence labelling frameworks, which can only recognise flat entities. While lexicons serve as prior knowledge and enhance semantic information, they also pose completeness and resource requirements limitations. This paper proposes a template-based classification (TC) model to avoid lexicon issues and to identify nested entities. Template-based classification provides a template word for each entity type, which utilises contrastive learning to integrate the common characteristics among entities with the same category. Contrastive learning makes template words the centre points of their category in the vector space, thus improving generalisation ability. Additionally, TC presents a 2D table-filling label scheme that classifies entities based on the attention distribution of template words. The proposed novel decoder algorithm enables TC recognition of both flat and nested entities simultaneously. Experimental results show that TC achieves the state-of-the-art performance on five Chinese datasets.},
  archive      = {J_CAAITIT},
  author       = {Yuke Wang and Qiao Liu and Tingting Dai and Junjie Lang and Ling Lu and Yinong Chen},
  doi          = {10.1049/cit2.12403},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {450--459},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Contrastive learning for nested chinese named entity recognition via template words},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tri-M2MT: Multi-modalities based effective acute bilirubin encephalopathy diagnosis through multi-transformer using neonatal magnetic resonance imaging. <em>CAAITIT</em>, <em>10</em>(2), 434--449. (<a href='https://doi.org/10.1049/cit2.12409'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acute Bilirubin Encephalopathy (ABE) is a significant threat to neonates and it leads to disability and high mortality rates. Detecting and treating ABE promptly is important to prevent further complications and long-term issues. Recent studies have explored ABE diagnosis. However, they often face limitations in classification due to reliance on a single modality of Magnetic Resonance Imaging (MRI). To tackle this problem, the authors propose a Tri-M2MT model for precise ABE detection by using tri-modality MRI scans. The scans include T1-weighted imaging (T1WI), T2-weighted imaging (T2WI), and apparent diffusion coefficient maps to get indepth information. Initially, the tri-modality MRI scans are collected and preprocessesed by using an Advanced Gaussian Filter for noise reduction and Z -score normalisation for data standardisation. An Advanced Capsule Network was utilised to extract relevant features by using Snake Optimization Algorithm to select optimal features based on feature correlation with the aim of minimising complexity and enhancing detection accuracy. Furthermore, a multi-transformer approach was used for feature fusion and identify feature correlations effectively. Finally, accurate ABE diagnosis is achieved through the utilisation of a SoftMax layer. The performance of the proposed Tri-M2MT model is evaluated across various metrics, including accuracy, specificity, sensitivity, F1-score, and ROC curve analysis, and the proposed methodology provides better performance compared to existing methodologies.},
  archive      = {J_CAAITIT},
  author       = {Kumar Perumal and Rakesh Kumar Mahendran and Arfat Ahmad Khan and Seifedine Kadry},
  doi          = {10.1049/cit2.12409},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {434--449},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Tri-M2MT: Multi-modalities based effective acute bilirubin encephalopathy diagnosis through multi-transformer using neonatal magnetic resonance imaging},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast surface-defect detection method based on dense-YOLO network. <em>CAAITIT</em>, <em>10</em>(2), 415--433. (<a href='https://doi.org/10.1049/cit2.12407'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient detection of surface defects is primary for ensuring product quality during manufacturing processes. To enhance the performance of deep learning-based methods in practical applications, the authors propose Dense-YOLO, a fast surface defect detection network that combines the strengths of DenseNet and you only look once version 3 (YOLOv3). The authors design a lightweight backbone network with improved densely connected blocks, optimising the utilisation of shallow features while maintaining high detection speeds. Additionally, the authors refine the feature pyramid network of YOLOv3 to increase the recall of tiny defects and overall positioning accuracy. Furthermore, an online multi-angle template matching technique is introduced based on normalised cross-correlation to precisely locate the detection area. This refined template matching method not only accelerates detection speed but also mitigates the influence of the background. To validate the effectiveness of our enhancements, the authors conduct comparative experiments across two private datasets and one public dataset. Results show that Dense-YOLO outperforms existing methods, such as faster R-CNN, YOLOv3, YOLOv5s, YOLOv7, and SSD, in terms of mean average precision (mAP) and detection speed. Moreover, Dense-YOLO outperforms networks inherited from VGG and ResNet, including improved faster R-CNN, FCOS, M2Det-320 and FRCN, in mAP.},
  archive      = {J_CAAITIT},
  author       = {Fengqiang Gao and Qingyuan Zhu and Guifang Shao and Yukang Su and Jianbo Yang and Xinyue Yu},
  doi          = {10.1049/cit2.12407},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {415--433},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A fast surface-defect detection method based on dense-YOLO network},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust style injection for person image synthesis. <em>CAAITIT</em>, <em>10</em>(2), 402--414. (<a href='https://doi.org/10.1049/cit2.12361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person Image Synthesis has been widely used in fashion with extensive application scenarios. The point of this task is how to synthesise person image from a single source image under arbitrary poses. Prior methods generate the person image with target pose well; however, they fail to preserve the fine style details of the source image. To address this problem, a robust style injection (RSI) model is proposed, which is a coarse-to-fine framework to synthesise target the person image. RSI develops a simple and efficient cross-attention based module to fuse the features of both source semantic styles and target pose for achieving the coarse aligned features. The adaptive instance normalisation is employed to enhance the aligned features in conjunction with source semantic styles. Subsequently, source semantic styles are further injected into the positional normalisation scheme to avoid the fine style details erosion caused by massive convolution. In training losses, optimal transport theory in the form of energy distance is introduced to constrain data distribution to refine the texture style details. Additionally, the authors’ model is capable of editing the shape and texture of garments to the target style separately. The experiments demonstrate that the authors’ RSI achieves better performance over the state-of-art methods.},
  archive      = {J_CAAITIT},
  author       = {Yan Huang and Jianjun Qian and Shumin Zhu and Jun Li and Jian Yang},
  doi          = {10.1049/cit2.12361},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {402--414},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Robust style injection for person image synthesis},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BAHGRF3: Human gait recognition in the indoor environment using deep learning features fusion assisted framework and posterior probability moth flame optimisation. <em>CAAITIT</em>, <em>10</em>(2), 387--401. (<a href='https://doi.org/10.1049/cit2.12368'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometric characteristics are playing a vital role in security for the last few years. Human gait classification in video sequences is an important biometrics attribute and is used for security purposes. A new framework for human gait classification in video sequences using deep learning (DL) fusion assisted and posterior probability-based moth flames optimization (MFO) is proposed. In the first step, the video frames are resized and fine-tuned by two pre-trained lightweight DL models, EfficientNetB0 and MobileNetV2. Both models are selected based on the top-5 accuracy and less number of parameters. Later, both models are trained through deep transfer learning and extracted deep features fused using a voting scheme. In the last step, the authors develop a posterior probability-based MFO feature selection algorithm to select the best features. The selected features are classified using several supervised learning methods. The CASIA-B publicly available dataset has been employed for the experimental process. On this dataset, the authors selected six angles such as 0°, 18°, 90°, 108°, 162°, and 180° and obtained an average accuracy of 96.9%, 95.7%, 86.8%, 90.0%, 95.1%, and 99.7%. Results demonstrate comparable improvement in accuracy and significantly minimize the computational time with recent state-of-the-art techniques.},
  archive      = {J_CAAITIT},
  author       = {Muhammad Abrar Ahmad Khan and Muhammad Attique Khan and Ateeq Ur Rehman and Ahmed Ibrahim Alzahrani and Nasser Alalwan and Deepak Gupta and Saima Ahmed Rahin and Yudong Zhang},
  doi          = {10.1049/cit2.12368},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {387--401},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {BAHGRF3: Human gait recognition in the indoor environment using deep learning features fusion assisted framework and posterior probability moth flame optimisation},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Which is more faithful, seeing or saying? multimodal sarcasm detection exploiting contrasting sentiment knowledge. <em>CAAITIT</em>, <em>10</em>(2), 375--386. (<a href='https://doi.org/10.1049/cit2.12400'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using sarcasm on social media platforms to express negative opinions towards a person or object has become increasingly common. However, detecting sarcasm in various forms of communication can be difficult due to conflicting sentiments. In this paper, we introduce a contrasting sentiment-based model for multimodal sarcasm detection (CS4MSD), which identifies inconsistent emotions by leveraging the CLIP knowledge module to produce sentiment features in both text and image. Then, five external sentiments are introduced to prompt the model learning sentimental preferences among modalities. Furthermore, we highlight the importance of verbal descriptions embedded in illustrations and incorporate additional knowledge-sharing modules to fuse such image-like features. Experimental results demonstrate that our model achieves state-of-the-art performance on the public multimodal sarcasm dataset.},
  archive      = {J_CAAITIT},
  author       = {Yutao Chen and Shumin Shi and Heyan Huang},
  doi          = {10.1049/cit2.12400},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {375--386},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Which is more faithful, seeing or saying? multimodal sarcasm detection exploiting contrasting sentiment knowledge},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature pyramid attention network for audio-visual scene classification. <em>CAAITIT</em>, <em>10</em>(2), 359--374. (<a href='https://doi.org/10.1049/cit2.12375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio-visual scene classification (AVSC) poses a formidable challenge owing to the intricate spatial-temporal relationships exhibited by audio-visual signals, coupled with the complex spatial patterns of objects and textures found in visual images. The focus of recent studies has predominantly revolved around extracting features from diverse neural network structures, inadvertently neglecting the acquisition of semantically meaningful regions and crucial components within audio-visual data. The authors present a feature pyramid attention network (FPANet) for audio-visual scene understanding, which extracts semantically significant characteristics from audio-visual data. The authors’ approach builds multi-scale hierarchical features of sound spectrograms and visual images using a feature pyramid representation and localises the semantically relevant regions with a feature pyramid attention module (FPAM). A dimension alignment (DA) strategy is employed to align feature maps from multiple layers, a pyramid spatial attention (PSA) to spatially locate essential regions, and a pyramid channel attention (PCA) to pinpoint significant temporal frames. Experiments on visual scene classification (VSC), audio scene classification (ASC), and AVSC tasks demonstrate that FPANet achieves performance on par with state-of-the-art (SOTA) approaches, with a 95.9 F1-score on the ADVANCE dataset and a relative improvement of 28.8%. Visualisation results show that FPANet can prioritise semantically meaningful areas in audio-visual signals.},
  archive      = {J_CAAITIT},
  author       = {Liguang Zhou and Yuhongze Zhou and Xiaonan Qi and Junjie Hu and Tin Lun Lam and Yangsheng Xu},
  doi          = {10.1049/cit2.12375},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {359--374},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Feature pyramid attention network for audio-visual scene classification},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence assisted prediction of optimum operating conditions of shell and tube heat exchangers: A grey-box approach. <em>CAAITIT</em>, <em>10</em>(2), 349--358. (<a href='https://doi.org/10.1049/cit2.12393'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a Grey-box (GB) model was developed to predict the optimum mass flow rates of inlet streams of a Shell and Tube Heat Exchanger (STHE) under varying process conditions. Aspen Exchanger Design and Rating (Aspen-EDR) was initially used to construct a first principle model (FP) of the STHE using industrial data. The Genetic Algorithm (GA) was incorporated into the FP model to attain the minimum exit temperature for the hot kerosene process stream under varying process conditions. A dataset comprised of optimum process conditions was generated through FP-GA integration and was utilised to develop an Artificial Neural Networks (ANN) model. Subsequently, the ANN model was merged with the FP model by substituting the GA, to form a GB model. The developed GB model, that is, ANN and FP integration, achieved higher effectiveness and lower outlet temperature than those derived through the standalone FP model. Performance of the GB framework was also comparable to the FP-GA approach but it significantly reduced the computation time required for estimating the optimum process conditions. The proposed GB-based method improved the STHE's ability to extract energy from the process stream and strengthened its resilience to cope with diverse process conditions.},
  archive      = {J_CAAITIT},
  author       = {Zahid Ullah and Iftikhar Ahmad and Abdul Samad and Husnain Saghir and Farooq Ahmad and Manabu Kano and Hakan Caliskan and Nesrin Caliskan and Hiki Hong},
  doi          = {10.1049/cit2.12393},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {349--358},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Artificial intelligence assisted prediction of optimum operating conditions of shell and tube heat exchangers: A grey-box approach},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D medical image segmentation using the serial–parallel convolutional neural network and transformer based on cross-window self-attention. <em>CAAITIT</em>, <em>10</em>(2), 337--348. (<a href='https://doi.org/10.1049/cit2.12411'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural network (CNN) with the encoder–decoder structure is popular in medical image segmentation due to its excellent local feature extraction ability but it faces limitations in capturing the global feature. The transformer can extract the global information well but adapting it to small medical datasets is challenging and its computational complexity can be heavy. In this work, a serial and parallel network is proposed for the accurate 3D medical image segmentation by combining CNN and transformer and promoting feature interactions across various semantic levels. The core components of the proposed method include the cross window self-attention based transformer (CWST) and multi-scale local enhanced (MLE) modules. The CWST module enhances the global context understanding by partitioning 3D images into non-overlapping windows and calculating sparse global attention between windows. The MLE module selectively fuses features by computing the voxel attention between different branch features, and uses convolution to strengthen the dense local information. The experiments on the prostate, atrium, and pancreas MR/CT image datasets consistently demonstrate the advantage of the proposed method over six popular segmentation models in both qualitative evaluation and quantitative indexes such as dice similarity coefficient, Intersection over Union, 95% Hausdorff distance and average symmetric surface distance.},
  archive      = {J_CAAITIT},
  author       = {Bin Yu and Quan Zhou and Li Yuan and Huageng Liang and Pavel Shcherbakov and Xuming Zhang},
  doi          = {10.1049/cit2.12411},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {337--348},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {3D medical image segmentation using the serial–parallel convolutional neural network and transformer based on cross-window self-attention},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain-independent adaptive histogram-based features for pomegranate fruit and leaf diseases classification. <em>CAAITIT</em>, <em>10</em>(2), 317--336. (<a href='https://doi.org/10.1049/cit2.12390'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CAAITIT},
  author       = {Mohanmuralidhar Prajwala and Prabhuswamy Prajwal Kumar and Shanubhog Maheshwarappa Gopinath and Shivakumara Palaiahnakote and Mahadevappa Basavanna and Daniel P. Lopresti},
  doi          = {10.1049/cit2.12390},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {4},
  number       = {2},
  pages        = {317--336},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Domain-independent adaptive histogram-based features for pomegranate fruit and leaf diseases classification},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-sensor missile-borne LiDAR point cloud data augmentation based on monte carlo distortion simulation. <em>CAAITIT</em>, <em>10</em>(1), 300--316. (<a href='https://doi.org/10.1049/cit2.12389'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CAAITIT},
  author       = {Luda Zhao and Yihua Hu and Fei Han and Zhenglei Dou and Shanshan Li and Yan Zhang and Qilong Wu},
  doi          = {10.1049/cit2.12389},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {300--316},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Multi-sensor missile-borne LiDAR point cloud data augmentation based on monte carlo distortion simulation},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extraction of typical operating scenarios of new power system based on deep time series aggregation. <em>CAAITIT</em>, <em>10</em>(1), 283--299. (<a href='https://doi.org/10.1049/cit2.12369'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting typical operational scenarios is essential for making flexible decisions in the dispatch of a new power system. A novel deep time series aggregation scheme (DTSAs) is proposed to generate typical operational scenarios, considering the large amount of historical operational snapshot data. Specifically, DTSAs analyse the intrinsic mechanisms of different scheduling operational scenario switching to mathematically represent typical operational scenarios. A Gramian angular summation field-based operational scenario image encoder was designed to convert operational scenario sequences into high-dimensional spaces. This enables DTSAs to fully capture the spatiotemporal characteristics of new power systems using deep feature iterative aggregation models. The encoder also facilitates the generation of typical operational scenarios that conform to historical data distributions while ensuring the integrity of grid operational snapshots. Case studies demonstrate that the proposed method extracted new fine-grained power system dispatch schemes and outperformed the latest high-dimensional feature-screening methods. In addition, experiments with different new energy access ratios were conducted to verify the robustness of the proposed method. DTSAs enable dispatchers to master the operation experience of the power system in advance, and actively respond to the dynamic changes of the operation scenarios under the high access rate of new energy.},
  archive      = {J_CAAITIT},
  author       = {Zhaoyang Qu and Zhenming Zhang and Nan Qu and Yuguang Zhou and Yang Li and Tao Jiang and Min Li and Chao Long},
  doi          = {10.1049/cit2.12369},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {283--299},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Extraction of typical operating scenarios of new power system based on deep time series aggregation},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pre-trained SAM as data augmentation for image segmentation. <em>CAAITIT</em>, <em>10</em>(1), 268--282. (<a href='https://doi.org/10.1049/cit2.12381'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation plays an important role in training deep neural model by expanding the size and diversity of the dataset. Initially, data augmentation mainly involved some simple transformations of images. Later, in order to increase the diversity and complexity of data, more advanced methods appeared and evolved to sophisticated generative models. However, these methods required a mass of computation of training or searching. In this paper, a novel training-free method that utilises the Pre-Trained Segment Anything Model (SAM) model as a data augmentation tool (PTSAM-DA) is proposed to generate the augmented annotations for images. Without the need for training, it obtains prompt boxes from the original annotations and then feeds the boxes to the pre-trained SAM to generate diverse and improved annotations. In this way, annotations are augmented more ingenious than simple manipulations without incurring huge computation for training a data augmentation model. Multiple comparative experiments on three datasets are conducted, including an in-house dataset, ADE20K and COCO2017. On this in-house dataset, namely Agricultural Plot Segmentation Dataset, maximum improvements of 3.77% and 8.92% are gained in two mainstream metrics, mIoU and mAcc, respectively. Consequently, large vision models like SAM are proven to be promising not only in image segmentation but also in data augmentation.},
  archive      = {J_CAAITIT},
  author       = {Junjun Wu and Yunbo Rao and Shaoning Zeng and Bob Zhang},
  doi          = {10.1049/cit2.12381},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {268--282},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Pre-trained SAM as data augmentation for image segmentation},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WaveSeg-UNet model for overlapped nuclei segmentation from multi-organ histopathology images. <em>CAAITIT</em>, <em>10</em>(1), 253--267. (<a href='https://doi.org/10.1049/cit2.12351'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nuclei segmentation is a challenging task in histopathology images. It is challenging due to the small size of objects, low contrast, touching boundaries, and complex structure of nuclei. Their segmentation and counting play an important role in cancer identification and its grading. In this study, WaveSeg-UNet, a lightweight model, is introduced to segment cancerous nuclei having touching boundaries. Residual blocks are used for feature extraction. Only one feature extractor block is used in each level of the encoder and decoder. Normally, images degrade quality and lose important information during down-sampling. To overcome this loss, discrete wavelet transform (DWT) alongside max-pooling is used in the down-sampling process. Inverse DWT is used to regenerate original images during up-sampling. In the bottleneck of the proposed model, atrous spatial channel pyramid pooling (ASCPP) is used to extract effective high-level features. The ASCPP is the modified pyramid pooling having atrous layers to increase the area of the receptive field. Spatial and channel-based attention are used to focus on the location and class of the identified objects. Finally, watershed transform is used as a post processing technique to identify and refine touching boundaries of nuclei. Nuclei are identified and counted to facilitate pathologists. The same domain of transfer learning is used to retrain the model for domain adaptability. Results of the proposed model are compared with state-of-the-art models, and it outperformed the existing studies.},
  archive      = {J_CAAITIT},
  author       = {Hameed Ullah Khan and Basit Raza and Muhammad Asad Iqbal Khan and Muhammad Faheem},
  doi          = {10.1049/cit2.12351},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {253--267},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {WaveSeg-UNet model for overlapped nuclei segmentation from multi-organ histopathology images},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Terahertz image denoising via multiscale hybrid-convolution residual network. <em>CAAITIT</em>, <em>10</em>(1), 235--252. (<a href='https://doi.org/10.1049/cit2.12380'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Terahertz imaging technology has great potential applications in areas, such as remote sensing, navigation, security checks, and so on. However, terahertz images usually have the problems of heavy noises and low resolution. Previous terahertz image denoising methods are mainly based on traditional image processing methods, which have limited denoising effects on the terahertz noise. Existing deep learning-based image denoising methods are mostly used in natural images and easily cause a large amount of detail loss when denoising terahertz images. Here, a residual-learning-based multiscale hybrid-convolution residual network (MHRNet) is proposed for terahertz image denoising, which can remove noises while preserving detail features in terahertz images. Specifically, a multiscale hybrid-convolution residual block (MHRB) is designed to extract rich detail features and local prediction residual noise from terahertz images. Specifically, MHRB is a residual structure composed of a multiscale dilated convolution block, a bottleneck layer, and a multiscale convolution block. MHRNet uses the MHRB and global residual learning to achieve terahertz image denoising. Ablation studies are performed to validate the effectiveness of MHRB. A series of experiments are conducted on the public terahertz image datasets. The experimental results demonstrate that MHRNet has an excellent denoising effect on synthetic and real noisy terahertz images. Compared with existing methods, MHRNet achieves comprehensive competitive results.},
  archive      = {J_CAAITIT},
  author       = {Heng Wu and Zijie Guo and Chunhua He and Shaojuan Luo and Bofang Song},
  doi          = {10.1049/cit2.12380},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {235--252},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Terahertz image denoising via multiscale hybrid-convolution residual network},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A criterion for selecting the appropriate one from the trained models for model-based offline policy evaluation. <em>CAAITIT</em>, <em>10</em>(1), 223--234. (<a href='https://doi.org/10.1049/cit2.12376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline policy evaluation, evaluating and selecting complex policies for decision-making by only using offline datasets is important in reinforcement learning. At present, the model-based offline policy evaluation (MBOPE) is widely welcomed because of its easy to implement and good performance. MBOPE directly approximates the unknown value of a given policy using the Monte Carlo method given the estimated transition and reward functions of the environment. Usually, multiple models are trained, and then one of them is selected to be used. However, a challenge remains in selecting an appropriate model from those trained for further use. The authors first analyse the upper bound of the difference between the approximated value and the unknown true value. Theoretical results show that this difference is related to the trajectories generated by the given policy on the learnt model and the prediction error of the transition and reward functions at these generated data points. Based on the theoretical results, a new criterion is proposed to tell which trained model is better suited for evaluating the given policy. At last, the effectiveness of the proposed criterion is demonstrated on both benchmark and synthetic offline datasets.},
  archive      = {J_CAAITIT},
  author       = {Chongchong Li and Yue Wang and Zhi-Ming Ma and Yuting Liu},
  doi          = {10.1049/cit2.12376},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {223--234},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A criterion for selecting the appropriate one from the trained models for model-based offline policy evaluation},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). D2LFS2Net: Multi-class skin lesion diagnosis using deep learning and variance-controlled marine predator optimisation: An application for precision medicine. <em>CAAITIT</em>, <em>10</em>(1), 207--222. (<a href='https://doi.org/10.1049/cit2.12267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In computer vision applications like surveillance and remote sensing, to mention a few, deep learning has had considerable success. Medical imaging still faces a number of difficulties, including intra-class similarity, a scarcity of training data, and poor contrast skin lesions, notably in the case of skin cancer. An optimisation-aided deep learning-based system is proposed for accurate multi-class skin lesion identification. The sequential procedures of the proposed system start with preprocessing and end with categorisation. The preprocessing step is where a hybrid contrast enhancement technique is initially proposed for lesion identification with healthy regions. Instead of flipping and rotating data, the outputs from the middle phases of the hybrid enhanced technique are employed for data augmentation in the next step. Next, two pre-trained deep learning models, MobileNetV2 and NasNet Mobile, are trained using deep transfer learning on the upgraded enriched dataset. Later, a dual-threshold serial approach is employed to obtain and combine the features of both models. The next step was the variance-controlled Marine Predator methodology, which the authors proposed as a superior optimisation method. The top features from the fused feature vector are classified using machine learning classifiers. The experimental strategy provided enhanced accuracy of 94.4% using the publicly available dataset HAM10000. Additionally, the proposed framework is evaluated compared to current approaches, with remarkable results.},
  archive      = {J_CAAITIT},
  author       = {Veena Dillshad and Muhammad Attique Khan and Muhammad Nazir and Oumaima Saidani and Nazik Alturki and Seifedine Kadry},
  doi          = {10.1049/cit2.12267},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {207--222},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {D2LFS2Net: Multi-class skin lesion diagnosis using deep learning and variance-controlled marine predator optimisation: An application for precision medicine},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visible and near-infrared image fusion based on information complementarity. <em>CAAITIT</em>, <em>10</em>(1), 193--206. (<a href='https://doi.org/10.1049/cit2.12378'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images with complementary spectral information can be recorded using image sensors that can identify visible and near-infrared spectrum. The fusion of visible and near-infrared (NIR) aims to enhance the quality of images acquired by video monitoring systems for the ease of user observation and data processing. Unfortunately, current fusion algorithms produce artefacts and colour distortion since they cannot make use of spectrum properties and are lacking in information complementarity. Therefore, an information complementarity fusion (ICF) model is designed based on physical signals. In order to separate high-frequency noise from important information in distinct frequency layers, the authors first extracted texture-scale and edge-scale layers using a two-scale filter. Second, the difference map between visible and near-infrared was filtered using the extended-DoG filter to produce the initial visible-NIR complementary weight map. Then, to generate a guide map, the near-infrared image with night adjustment was processed as well. The final complementarity weight map was subsequently derived via an arctanI function mapping using the guide map and the initial weight maps. Finally, fusion images were generated with the complementarity weight maps. The experimental results demonstrate that the proposed approach outperforms the state-of-the-art in both avoiding artificial colours as well as effectively utilising information complementarity.},
  archive      = {J_CAAITIT},
  author       = {Zhuo Li and Shiliang Pu and Mengqi Ji and Feng Zeng and Bo Li},
  doi          = {10.1049/cit2.12378},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {193--206},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Visible and near-infrared image fusion based on information complementarity},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MultiJSQ: Direct joint segmentation and quantification of left ventricle with deep multitask-derived regression network. <em>CAAITIT</em>, <em>10</em>(1), 175--192. (<a href='https://doi.org/10.1049/cit2.12382'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative analysis of clinical function parameters from MRI images is crucial for diagnosing and assessing cardiovascular disease. However, the manual calculation of these parameters is challenging due to the high variability among patients and the time-consuming nature of the process. In this study, the authors introduce a framework named MultiJSQ, comprising the feature presentation network (FRN) and the indicator prediction network (IEN), which is designed for simultaneous joint segmentation and quantification. The FRN is tailored for representing global image features, facilitating the direct acquisition of left ventricle (LV) contour images through pixel classification. Additionally, the IEN incorporates specifically designed modules to extract relevant clinical indices. The authors’ method considers the interdependence of different tasks, demonstrating the validity of these relationships and yielding favourable results. Through extensive experiments on cardiac MR images from 145 patients, MultiJSQ achieves impressive outcomes, with low mean absolute errors of 124 mm 2 , 1.72 mm, and 1.21 mm for areas, dimensions, and regional wall thicknesses, respectively, along with a Dice metric score of 0.908. The experimental findings underscore the excellent performance of our framework in LV segmentation and quantification, highlighting its promising clinical application prospects.},
  archive      = {J_CAAITIT},
  author       = {Xiuquan Du and Zheng Pei and Ying Liu and Xinzhi Cao and Lei Li and Shuo Li},
  doi          = {10.1049/cit2.12382},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {175--192},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {MultiJSQ: Direct joint segmentation and quantification of left ventricle with deep multitask-derived regression network},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grey-box modelling for estimation of optimum cut point temperature of crude distillation column. <em>CAAITIT</em>, <em>10</em>(1), 160--174. (<a href='https://doi.org/10.1049/cit2.12386'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A grey-box modelling framework was developed for the estimation of cut point temperature of a crude distillation unit (CDU) under uncertainty in crude composition and process conditions. First principle (FP) model of CDU was developed for Pakistani crudes from Zamzama and Kunnar fields. A hybrid methodology based on the integration of Taguchi method and genetic algorithm (GA) was employed to estimate the optimal cut point temperature for various sets of process variables. Optimised datasets were utilised to develop an artificial neural networks (ANN) model for the prediction of optimum values of cut points. The ANN model was then used to replace the hybrid framework of the Taguchi method and the GA. The integration of the ANN and FP model makes it a grey-box (GB) model. For the case of Zamama crude, the GB model helped in the decrease of up to 38.93% in energy required per kilo barrel of diesel and an 8.2% increase in diesel production compared to the stand-alone FP model under uncertainty. Similarly, for Kunnar crude, up to 18.87% decrease in energy required per kilo barrel of diesel and a 33.96% increase in diesel production was observed in comparison to the stand-alone FP model.},
  archive      = {J_CAAITIT},
  author       = {Junaid Shahzad and Iftikhar Ahmad and Muhammad Ahsan and Farooq Ahmad and Husnain Saghir and Manabu Kano and Hakan Caliskan and Hiki Hong},
  doi          = {10.1049/cit2.12386},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {160--174},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Grey-box modelling for estimation of optimum cut point temperature of crude distillation column},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bilingual phrase induction with local hard negative sampling. <em>CAAITIT</em>, <em>10</em>(1), 147--159. (<a href='https://doi.org/10.1049/cit2.12383'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bilingual lexicon induction focuses on learning word translation pairs, also known as bitexts, from monolingual corpora by establishing a mapping between the source and target embedding spaces. Despite recent advancements, bilingual lexicon induction is limited to inducing bitexts consisting of individual words, lacking the ability to handle semantics-rich phrases. To bridge this gap and support downstream cross-lingual tasks, it is practical to develop a method for bilingual phrase induction that extracts bilingual phrase pairs from monolingual corpora without relying on cross-lingual knowledge. In this paper, the authors propose a novel phrase embedding training method based on the skip-gram structure. Specifically, a local hard negative sampling strategy that utilises negative samples of central tokens in sliding windows to enhance phrase embedding learning is introduced. The proposed method achieves competitive or superior performance compared to baseline approaches, with exceptional results recorded for distant languages. Additionally, we develop a phrase representation learning method that leverages multilingual pre-trained language models. These mPLMs-based representations can be combined with the above-mentioned static phrase embeddings to further improve the accuracy of the bilingual phrase induction task. We manually construct a dataset of bilingual phrase pairs and integrate it with MUSE to facilitate the bilingual phrase induction task.},
  archive      = {J_CAAITIT},
  author       = {Hailong Cao and Hualin Miao and Weixuan Wang and Liangyou Li and Wei Peng and Tiejun Zhao},
  doi          = {10.1049/cit2.12383},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {147--159},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Bilingual phrase induction with local hard negative sampling},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-station multi-robot task assignment method based on deep reinforcement learning. <em>CAAITIT</em>, <em>10</em>(1), 134--146. (<a href='https://doi.org/10.1049/cit2.12394'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the problem of multi-station multi-robot spot welding task assignment, and proposes a deep reinforcement learning (DRL) framework, which is made up of a public graph attention network and independent policy networks. The graph of welding spots distribution is encoded using the graph attention network. Independent policy networks with attention mechanism as a decoder can handle the encoded graph and decide to assign robots to different tasks. The policy network is used to convert the large scale welding spots allocation problem to multiple small scale single-robot welding path planning problems, and the path planning problem is quickly solved through existing methods. Then, the model is trained through reinforcement learning. In addition, the task balancing method is used to allocate tasks to multiple stations. The proposed algorithm is compared with classical algorithms, and the results show that the algorithm based on DRL can produce higher quality solutions.},
  archive      = {J_CAAITIT},
  author       = {Junnan Zhang and Ke Wang and Chaoxu Mu},
  doi          = {10.1049/cit2.12394},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {134--146},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Multi-station multi-robot task assignment method based on deep reinforcement learning},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resource-adaptive and OOD-robust inference of deep neural networks on IoT devices. <em>CAAITIT</em>, <em>10</em>(1), 115--133. (<a href='https://doi.org/10.1049/cit2.12384'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiently executing inference tasks of deep neural networks on devices with limited resources poses a significant load in IoT systems. To alleviate the load, one innovative method is branching that adds extra layers with classification exits to a pre-trained model, enabling inputs with high-confidence predictions to exit early, thus reducing inference cost. However, branching networks, not originally tailored for IoT environments, are susceptible to noisy and out-of-distribution (OOD) data, and they demand additional training for optimal performance. The authors introduce BrevisNet, a novel branching methodology designed for creating on-device branching models that are both resource-adaptive and noise-robust for IoT applications. The method leverages the refined uncertainty estimation capabilities of Dirichlet distributions for classification predictions, combined with the superior OOD detection of energy-based models. The authors propose a unique training approach and thresholding technique that enhances the precision of branch predictions, offering robustness against noise and OOD inputs. The findings demonstrate that BrevisNet surpasses existing branching techniques in training efficiency, accuracy, overall performance, and robustness.},
  archive      = {J_CAAITIT},
  author       = {Cailen Robertson and Ngoc Anh Tong and Thanh Toan Nguyen and Quoc Viet Hung Nguyen and Jun Jo},
  doi          = {10.1049/cit2.12384},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {115--133},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Resource-adaptive and OOD-robust inference of deep neural networks on IoT devices},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KitWaSor: Pioneering pre-trained model for kitchen waste sorting with an innovative million-level benchmark dataset. <em>CAAITIT</em>, <em>10</em>(1), 94--114. (<a href='https://doi.org/10.1049/cit2.12399'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent sorting is an important prerequisite for the full quantitative consumption and harmless disposal of kitchen waste. The existing object detection method based on an ImageNet pre-trained model is an effective way of sorting. Owing to significant domain gaps between natural images and kitchen waste images, it is difficult to reflect the characteristics of diverse scales and dense distribution in kitchen waste based on an ImageNet pre-trained model, leading to poor generalisation. In this article, the authors propose the first pre-trained model for kitchen waste sorting called KitWaSor, which combines both contrastive learning (CL) and masked image modelling (MIM) through self-supervised learning (SSL). First, to address the issue of diverse scales, the authors propose a mixed masking strategy by introducing an incomplete masking branch based on the original random masking branch. It prevents the complete loss of small-scale objects while avoiding excessive leakage of large-scale object pixels. Second, to address the issue of dense distribution, the authors introduce semantic consistency constraints on the basis of the mixed masking strategy. That is, object semantic reasoning is performed through semantic consistency constraints to compensate for the lack of contextual information. To train KitWaSor, the authors construct the first million-level kitchen waste dataset across seasonal and regional distributions, named KWD-Million. Extensive experiments show that KitWaSor achieves state-of-the-art (SOTA) performance on the two most relevant downstream tasks for kitchen waste sorting (i.e. image classification and object detection), demonstrating the effectiveness of the proposed KitWaSor.},
  archive      = {J_CAAITIT},
  author       = {Leyuan Fang and Shuaiyu Ding and Hao Feng and Junwu Yu and Lin Tang and Pedram Ghamisi},
  doi          = {10.1049/cit2.12399},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {94--114},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {KitWaSor: Pioneering pre-trained model for kitchen waste sorting with an innovative million-level benchmark dataset},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperspectral image restoration using noise gradient and dual priors under mixed noise conditions. <em>CAAITIT</em>, <em>10</em>(1), 72--93. (<a href='https://doi.org/10.1049/cit2.12355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images obtained from hyperspectral sensors provide information about the target area that extends beyond the visible portions of the electromagnetic spectrum. However, due to sensor limitations and imperfections during the image acquisition and transmission phases, noise is introduced into the acquired image, which can have a negative impact on downstream analyses such as classification, target tracking, and spectral unmixing. Noise in hyperspectral images (HSI) is modelled as a combination from several sources, including Gaussian/impulse noise, stripes, and deadlines. An HSI restoration method for such a mixed noise model is proposed. First , a joint optimisation framework is proposed for recovering hyperspectral data corrupted by mixed Gaussian-impulse noise by estimating both the clean data as well as the sparse/impulse noise levels. Second , a hyper-Laplacian prior is used along both the spatial and spectral dimensions to express sparsity in clean image gradients. Third , to model the sparse nature of impulse noise, an ℓ 1 − norm over the impulse noise gradient is used. Because the proposed methodology employs two distinct priors, the authors refer to it as the hyperspectral dual prior (HySpDualP) denoiser. To the best of authors' knowledge, this joint optimisation framework is the first attempt in this direction. To handle the non-smooth and non-convex nature of the general ℓp − norm-based regularisation term, a generalised shrinkage/thresholding (GST) solver is employed. Finally , an efficient split-Bregman approach is used to solve the resulting optimisation problem. Experimental results on synthetic data and real HSI datacube obtained from hyperspectral sensors demonstrate that the authors’ proposed model outperforms state-of-the-art methods, both visually and in terms of various image quality assessment metrics.},
  archive      = {J_CAAITIT},
  author       = {Hazique Aetesam and Suman Kumar Maji and V. B. Surya Prasath},
  doi          = {10.1049/cit2.12355},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {72--93},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Hyperspectral image restoration using noise gradient and dual priors under mixed noise conditions},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving long-tail classification via decoupling and regularisation. <em>CAAITIT</em>, <em>10</em>(1), 62--71. (<a href='https://doi.org/10.1049/cit2.12374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world data always exhibit an imbalanced and long-tailed distribution, which leads to poor performance for neural network-based classification. Existing methods mainly tackle this problem by reweighting the loss function or rebalancing the classifier. However, one crucial aspect overlooked by previous research studies is the imbalanced feature space problem caused by the imbalanced angle distribution. In this paper, the authors shed light on the significance of the angle distribution in achieving a balanced feature space, which is essential for improving model performance under long-tailed distributions. Nevertheless, it is challenging to effectively balance both the classifier norms and angle distribution due to problems such as the low feature norm. To tackle these challenges, the authors first thoroughly analyse the classifier and feature space by decoupling the classification logits into three key components: classifier norm (i.e. the magnitude of the classifier vector), feature norm (i.e. the magnitude of the feature vector), and cosine similarity between the classifier vector and feature vector. In this way, the authors analyse the change of each component in the training process and reveal three critical problems that should be solved, that is, the imbalanced angle distribution, the lack of feature discrimination, and the low feature norm. Drawing from this analysis, the authors propose a novel loss function that incorporates hyperspherical uniformity, additive angular margin, and feature norm regularisation. Each component of the loss function addresses a specific problem and synergistically contributes to achieving a balanced classifier and feature space. The authors conduct extensive experiments on three popular benchmark datasets including CIFAR-10/100-LT, ImageNet-LT, and iNaturalist 2018. The experimental results demonstrate that the authors’ loss function outperforms several previous state-of-the-art methods in addressing the challenges posed by imbalanced and long-tailed datasets, that is, by improving upon the best-performing baselines on CIFAR-100-LT by 1.34, 1.41, 1.41 and 1.33, respectively.},
  archive      = {J_CAAITIT},
  author       = {Shuzheng Gao and Chaozheng Wang and Cuiyun Gao and Wenjian Luo and Peiyi Han and Qing Liao and Guandong Xu},
  doi          = {10.1049/cit2.12374},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {62--71},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Improving long-tail classification via decoupling and regularisation},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperspectral imagery quality assessment and band reconstruction using the prophet model. <em>CAAITIT</em>, <em>10</em>(1), 47--61. (<a href='https://doi.org/10.1049/cit2.12373'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Hyperspectral Imaging (HSI), the detrimental influence of noise and distortions on data quality is profound, which has severely affected the following-on analytics and decision-making such as land mapping. This study presents an innovative framework for assessing HSI band quality and reconstructing the low-quality bands, based on the Prophet model. By introducing a comprehensive quality metric to start, the authors approach factors in both spatial and spectral characteristics across local and global scales. This metric effectively captures the intricate noise and distortions inherent in the HSI data. Subsequently, the authors employ the Prophet model to forecast information within the low-quality bands, leveraging insights from neighbouring high-quality bands. To validate the effectiveness of the authors’ proposed model, extensive experiments on three publicly available uncorrected datasets are conducted. In a head-to-head comparison, the framework against six state-of-the-art band reconstruction algorithms including three spectral methods, two spatial-spectral methods and one deep learning method is benchmarked. The authors’ experiments also delve into strategies for band selection based on quality metrics and the quality evaluation of the reconstructed bands. In addition, the authors assess the classification accuracy utilising these reconstructed bands. In various experiments, the results consistently affirm the efficacy of the authors’ method in HSI quality assessment and band reconstruction. Notably, the authors’ approach obviates the need for manually prefiltering of noisy bands. This comprehensive framework holds promise in addressing HSI data quality concerns whilst enhancing the overall utility of HSI.},
  archive      = {J_CAAITIT},
  author       = {Ping Ma and Jinchang Ren and Zhi Gao and Yinhe Li and Rongjun Chen},
  doi          = {10.1049/cit2.12373},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {47--61},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Hyperspectral imagery quality assessment and band reconstruction using the prophet model},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Longitudinal velocity control of autonomous driving based on extended state observer. <em>CAAITIT</em>, <em>10</em>(1), 36--46. (<a href='https://doi.org/10.1049/cit2.12397'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active Disturbance Rejection Control (ADRC) possesses robust disturbance rejection capabilities, making it well-suited for longitudinal velocity control. However, the conventional Extended State Observer (ESO) in ADRC fails to fully exploit feedback from first-order and higher-order estimation errors and tracking error simultaneously, thereby diminishing the control performance of ADRC. To address this limitation, an enhanced car-following algorithm utilising ADRC is proposed, which integrates the improved ESO with a feedback controller. In comparison to the conventional ESO, the enhanced version effectively utilises multi-order estimation and tracking errors. Specifically, it enhances convergence rates by incorporating feedback from higher-order estimation errors and ensures the estimated value converges to the reference value by utilising tracking error feedback. The improved ESO significantly enhances the disturbance rejection performance of ADRC. Finally, the effectiveness of the proposed algorithm is validated through the Lyapunov approach and experiments.},
  archive      = {J_CAAITIT},
  author       = {Hongbo Gao and Hanqing Yang and Xiaoyu Zhang and Xiangyun Ren and Fenghua Liang and Ruidong Yan and Qingchao Liu and Mingmao Hu and Fang Zhang and Jiabing Gao and Siyu Bao and Keqiang Li and Deyi Li and Danwei Wang},
  doi          = {10.1049/cit2.12397},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {36--46},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Longitudinal velocity control of autonomous driving based on extended state observer},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning on medical image analysis. <em>CAAITIT</em>, <em>10</em>(1), 1--35. (<a href='https://doi.org/10.1049/cit2.12356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image analysis plays an irreplaceable role in diagnosing, treating, and monitoring various diseases. Convolutional neural networks (CNNs) have become popular as they can extract intricate features and patterns from extensive datasets. The paper covers the structure of CNN and its advances and explores the different types of transfer learning strategies as well as classic pre-trained models. The paper also discusses how transfer learning has been applied to different areas within medical image analysis. This comprehensive overview aims to assist researchers, clinicians, and policymakers by providing detailed insights, helping them make informed decisions about future research and policy initiatives to improve medical image analysis and patient outcomes.},
  archive      = {J_CAAITIT},
  author       = {Jiaji Wang and Shuihua Wang and Yudong Zhang},
  doi          = {10.1049/cit2.12356},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {1--35},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Deep learning on medical image analysis},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
