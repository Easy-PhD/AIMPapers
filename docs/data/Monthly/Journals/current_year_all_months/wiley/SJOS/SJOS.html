<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SJOS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="sjos">SJOS - 50</h2>
<ul>
<li><details>
<summary>
(2025). Corrigendum to “Statistical inference for generative adversarial networks and other minimax problems”. <em>SJOS</em>, <em>52</em>(3), 1477--1478. (<a href='https://doi.org/10.1111/sjos.12793'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SJOS},
  doi          = {10.1111/sjos.12793},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1477--1478},
  shortjournal = {Scand. J. Stat.},
  title        = {Corrigendum to “Statistical inference for generative adversarial networks and other minimax problems”},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dimension reduction for the estimation of the conditional tail index. <em>SJOS</em>, <em>52</em>(3), 1444--1476. (<a href='https://doi.org/10.1111/sjos.12792'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are interested in the relationship between the large values of a real random variable and its associated multidimensional covariate, in the context where the conditional distribution is heavy-tailed. Estimating the positive conditional tail index of a heavy-tailed conditional distribution is a crucial step for statistical inference, but the task becomes increasingly challenging as the covariate dimension increases. In this work, we assume the existence of a lower-dimensional linear subspace such that the conditional tail index depends on the covariate only through its projection onto this subspace. We propose a method to estimate this dimension reduction subspace and establish its consistency. Additionally, we introduce an estimator of the conditional tail index that leverages this dimension reduction and prove its consistency. We illustrate the benefits of this dimension reduction approach for estimating the conditional tail index through simulations and an application to real-world data.},
  archive      = {J_SJOS},
  author       = {Laurent Gardes and Alexandre Podgorny},
  doi          = {10.1111/sjos.12792},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1444--1476},
  shortjournal = {Scand. J. Stat.},
  title        = {Dimension reduction for the estimation of the conditional tail index},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse fréchet sufficient dimension reduction with graphical structure among predictors. <em>SJOS</em>, <em>52</em>(3), 1422--1443. (<a href='https://doi.org/10.1111/sjos.12791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fréchet regression has received considerable attention to model metric-space valued responses that are complex and non-Euclidean data, such as probability distributions and vectors on the unit sphere. However, existing Fréchet regression literature focuses on the classical setting where the predictor dimension is fixed, and the sample size goes to infinity. This paper proposes sparse Fréchet sufficient dimension reduction with graphical structure among high-dimensional Euclidean predictors. In particular, we propose a convex optimization problem that leverages the graphical information among predictors and avoids inverting the high-dimensional covariance matrix. We also provide the Alternating Direction Method of Multipliers (ADMM) algorithm to solve the optimization problem. Theoretically, the proposed method achieves subspace estimation and variable selection consistency under suitable conditions. Extensive simulations and a real data analysis are carried out to illustrate the finite-sample performance of the proposed method.},
  archive      = {J_SJOS},
  author       = {Jiaying Weng and Kai Tan and Cheng Wang and Zhou Yu},
  doi          = {10.1111/sjos.12791},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1422--1443},
  shortjournal = {Scand. J. Stat.},
  title        = {Sparse fréchet sufficient dimension reduction with graphical structure among predictors},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Statistical disaggregation—A monte carlo approach for imputation under constraints. <em>SJOS</em>, <em>52</em>(3), 1376--1421. (<a href='https://doi.org/10.1111/sjos.12790'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Equality-constrained models naturally arise in problems in which the measurements are taken at different levels of resolution. The challenge in this setting is that the models usually induce a joint distribution which is intractable. Resorting to instead sampling from the joint distribution by means of a Monte Carlo approach is also challenging. For example, a naive rejection sampler does not work when the probability mass of the constraint is zero. A typical example of such constrained problems is to learn energy consumption for a higher resolution level based on data at a lower resolution, for example, to decompose a daily reading into readings at a finer level. We introduce a novel Monte Carlo sampling algorithm based on Langevin diffusions and rejection sampling to solve the problem of sampling from equality-constrained models. Our method has the advantage of being exact for linear constraints and naturally deals with multimodal distributions on arbitrary constraints. We test our method on statistical disaggregation problems for electricity consumption datasets, and our approach provides better uncertainty estimation and accuracy in data imputation compared with other naive/unconstrained methods.},
  archive      = {J_SJOS},
  author       = {Shenggang Hu and Hongsheng Dai and Fanlin Meng and Louis Aslett and Murray Pollock and Gareth O. Roberts},
  doi          = {10.1111/sjos.12790},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1376--1421},
  shortjournal = {Scand. J. Stat.},
  title        = {Statistical disaggregation—A monte carlo approach for imputation under constraints},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semiparametric regression with localized bregman divergence. <em>SJOS</em>, <em>52</em>(3), 1330--1375. (<a href='https://doi.org/10.1111/sjos.12789'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on semiparametric regression based on minimizing the localized Bregman divergence. A local parametric model derived from the framework of the generalized linear model with multiple covariates and a linear predictor is utilized. The parameter vector included in the model is estimated under localization. The asymptotic behavior of both the locally estimated parameter vector and the induced regression estimator is investigated. Theoretical comparisons of estimators by using the divergence risk measure are also addressed. Further generalization, including a multivariate polynomial predictor, is explored, where Faa di Bruno's theorem concerning the derivative of a composition of multivariate functions is efficiently utilized. Simulations and application to a real dataset demonstrate that the proposed regression estimator works efficiently.},
  archive      = {J_SJOS},
  author       = {Hiroki Kosugi and Kanta Naito and Spiridon Penev},
  doi          = {10.1111/sjos.12789},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1330--1375},
  shortjournal = {Scand. J. Stat.},
  title        = {Semiparametric regression with localized bregman divergence},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Testing relevant hypotheses in functional variance function via self-normalization. <em>SJOS</em>, <em>52</em>(3), 1301--1329. (<a href='https://doi.org/10.1111/sjos.12788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel methodology for testing relevant hypotheses in the functional variance functions of contaminated functional data via spline-backfitted kernel smoothing and self-normalization. Our approach focuses on testing the null hypothesis of no relevant deviation instead of exact equality, such as the equality of two variance functions from two independent measurement errors. The proposed statistics enable testing of relevant hypotheses in one-sample, two-sample, and single or multiple change points problems, and exhibit oracle efficiency, meaning that developed procedures are asymptotically indistinguishable from those with true trajectories. Additionally, we demonstrate the finite sample properties of our proposed tests using a simulation study and electroencephalogram (EEG) data.},
  archive      = {J_SJOS},
  author       = {Qirui Hu},
  doi          = {10.1111/sjos.12788},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1301--1329},
  shortjournal = {Scand. J. Stat.},
  title        = {Testing relevant hypotheses in functional variance function via self-normalization},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A minimum wasserstein distance approach to fisher's combination of independent, discrete p-values. <em>SJOS</em>, <em>52</em>(3), 1281--1300. (<a href='https://doi.org/10.1111/sjos.12787'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a comprehensive framework to adjust a discrete test statistic for improving its hypothesis testing procedure. The adjustment minimizes the Wasserstein distance to a null-approximating continuous distribution, tackling some fundamental challenges inherent in combining statistical significances derived from discrete distributions. The related theory justifies Lancaster's mid-p and mean-value chi-squared statistics for Fisher's combination as special cases. To counter the conservative nature of Lancaster's testing procedures, we propose an updated null-approximating distribution. It is achieved by further minimizing the Wasserstein distance to the adjusted statistics within an appropriate distribution family. Specifically, in the context of Fisher's combination, we propose an optimal gamma distribution as a substitute for the traditionally used chi-squared distribution. This new approach yields an asymptotically consistent test that significantly improves Type I error control and enhances statistical power.},
  archive      = {J_SJOS},
  author       = {Gonzalo Contador and Zheyang Wu},
  doi          = {10.1111/sjos.12787},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1281--1300},
  shortjournal = {Scand. J. Stat.},
  title        = {A minimum wasserstein distance approach to fisher's combination of independent, discrete p-values},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced branching latin hypercube design and its application in automatic algorithm configuration. <em>SJOS</em>, <em>52</em>(3), 1239--1280. (<a href='https://doi.org/10.1111/sjos.12786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing experiments that involve branching and nested factors is challenging due to the complex relationships between these factors. Identification of optimal settings requires designs with good stratification properties for both nested and shared factors. To meet this requirement, we defined a type of enhanced branching Latin hypercube designs and developed several novel construction methods by integrating orthogonal arrays and sliced Latin hypercube designs. These designs exhibit attractive low-dimensional stratification properties and perform well in terms of column correlation. Additionally, the size of each design can be flexibly chosen based on the trade-off between the experimental budget and estimation accuracy. The simulation results demonstrate that the proposed design method exhibits significant superiority in terms of design metrics and estimation accuracy. Furthermore, we showcase the application of these designs in initializing automatic algorithm configuration. The proofs and additional design tables are provided in the Appendix.},
  archive      = {J_SJOS},
  author       = {Bing Wen and Sumin Wang and Fasheng Sun},
  doi          = {10.1111/sjos.12786},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1239--1280},
  shortjournal = {Scand. J. Stat.},
  title        = {Enhanced branching latin hypercube design and its application in automatic algorithm configuration},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mode-adaptive factor models. <em>SJOS</em>, <em>52</em>(3), 1206--1238. (<a href='https://doi.org/10.1111/sjos.12785'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factor models are indispensable tools in economics and finance, providing valuable insights into the latent structures underlying complex datasets. Nevertheless, the prevalence of heavy-tailed macroeconomic and financial data, often characterized by extreme values and greater skewness than that found in a normal distribution, presents significant analytical challenges. This article introduces mode-adaptive factor models (MAFM) for robust factor analysis in high-dimensional panel data, inspired by the equivalence between conventional principal component analysis and the constrained least squares method in factor models. Unlike traditional factor models that concentrate on mean estimation, MAFM leverage the mode to capture central tendencies more effectively, particularly in the presence of skewed and heavy-tailed distributions. To facilitate MAFM for factor analysis, we develop an iterative mode regression algorithm that integrates the expectation-maximization procedure, ensuring convergence to a stationary solution. We establish the theoretical properties of the MAFM estimators without imposing moment constraints on idiosyncratic errors and propose a mode information criterion for consistent factor number selection. We also suggest a data-dependent bandwidth selection procedure to enhance the flexibility of MAFM. The simulation studies demonstrate the effectiveness of MAFM across diverse distributional settings. An empirical application to macroeconomic forecasting further highlights the practical advantages of MAFM, showcasing their robustness and efficacy in real-world analyses.},
  archive      = {J_SJOS},
  author       = {Tao Wang},
  doi          = {10.1111/sjos.12785},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1206--1238},
  shortjournal = {Scand. J. Stat.},
  title        = {Mode-adaptive factor models},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unifying class of compound poisson integer-valued ARMA and GARCH models. <em>SJOS</em>, <em>52</em>(3), 1176--1205. (<a href='https://doi.org/10.1111/sjos.12784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {INAR (integer-valued autoregressive) and INGARCH (integer-valued GARCH) models are among the most commonly employed approaches for count time series modeling, but have been studied in largely distinct strands of literature. In this paper, a new class of generalized integer-valued ARMA (GINARMA) models is introduced which unifies a large number of compound Poisson INAR and INGARCH processes. Its stochastic properties, including stationarity and geometric ergodicity, are studied. Particular attention is given to a generalization of the INAR( p ) model which parallels the extension of the INARCH( p ) to the INGARCH( p , q ) model. For inference, we consider maximum likelihood, Gaussian quasi-likelihood, and moment-based approaches, along with likelihood ratio tests to distinguish between selected instances of our class. Models from the proposed class have a natural interpretation as stochastic epidemic processes, which throughout the article is used to illustrate our arguments. In a case study, different instances, including both established and newly introduced models, are applied to weekly case numbers of measles and mumps in Bavaria, Germany.},
  archive      = {J_SJOS},
  author       = {Johannes Bracher and Barbora Němcová},
  doi          = {10.1111/sjos.12784},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1176--1205},
  shortjournal = {Scand. J. Stat.},
  title        = {A unifying class of compound poisson integer-valued ARMA and GARCH models},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining stochastic tendency and distribution overlap towards improved nonparametric effect measures and inference. <em>SJOS</em>, <em>52</em>(3), 1138--1175. (<a href='https://doi.org/10.1111/sjos.12783'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fundamental functional in nonparametric statistics is the Mann-Whitney functional θ = P ⁡ ( X < Y ) , which constitutes the basis for the most popular nonparametric procedures. The functional θ measures a location or stochastic tendency effect between two distributions. A limitation of is its inability to capture scale differences. If differences of this nature are to be detected, specific tests for scale or omnibus tests need to be employed. However, the latter often suffer from low power, and they do not yield interpretable effect measures. In this article, we extend by additionally incorporating the recently introduced distribution overlap index (nonparametric dispersion measure) that can be expressed in terms of the quantile process. We derive the joint asymptotic distribution of the respective estimators of and and construct confidence regions. Extending the Wilcoxon–Mann–Whitney test, we introduce a new test based on the joint use of these functionals. It results in much larger consistency regions while maintaining competitive power to the rank sum test for situations in which alone would suffice. Compared with classical omnibus tests, the simulated power is much improved. Additionally, the newly proposed inference method yields effect measures whose interpretation is surprisingly straightforward.},
  archive      = {J_SJOS},
  author       = {Jonas Beck and Patrick B. Langthaler and Arne C. Bathke},
  doi          = {10.1111/sjos.12783},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1138--1175},
  shortjournal = {Scand. J. Stat.},
  title        = {Combining stochastic tendency and distribution overlap towards improved nonparametric effect measures and inference},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bandwidth selection for kernel intensity estimators for spatial point processes. <em>SJOS</em>, <em>52</em>(3), 1111--1137. (<a href='https://doi.org/10.1111/sjos.12782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intensity estimation through kernel smoothing is a popular non-parametric method of describing the characteristics of an underlying spatial point process. Key to the accuracy of this estimate is the choice of bandwidth. Too large or small a bandwidth can lead to features in the intensity being lost or to the introduction of artefacts. There are many available methods of bandwidth selection for spatial point patterns, but no consensus on the best option. Popular methods and software default options lead to very different intensity estimates and contrasting conclusions about the data that can be difficult to reconcile. In response, we propose new bandwidth selectors with more stable and consistent performance. These are adapted from popular plug-in and cross-validation techniques developed for general multivariate density estimation. The theoretical and practical performance of these proposed methods is explored and compared with other available methods in both simulated and real-data scenarios. We find that our proposed methods perform consistently well across a range of different intensity patterns. We end with a discussion on the implications of edge effects when applying these methods, given the constrained windows in which spatial point patterns are often observed.},
  archive      = {J_SJOS},
  author       = {Bethany J. Macdonald and Tilman M. Davies and Martin L. Hazelton},
  doi          = {10.1111/sjos.12782},
  journal      = {Scandinavian Journal of Statistics},
  month        = {9},
  number       = {3},
  pages        = {1111--1137},
  shortjournal = {Scand. J. Stat.},
  title        = {Bandwidth selection for kernel intensity estimators for spatial point processes},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ratio-consistency of some invariant U-statistic-based estimators with an application to high-dimensional data ranking. <em>SJOS</em>, <em>52</em>(2), 1092--1110. (<a href='https://doi.org/10.1111/sjos.12781'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ratio-consistency is a very desirable property of estimators, especially in high-dimensional statistics. In this article, unbiased and rotation-translation-invariant estimators based on linear combinations of U -statistics for some functions of the covariance matrix are derived using a general procedure. A useful result for showing the ratio-consistency of such a kind of estimators utilizing the formula for the variance of U -statistics is provided, and sufficient conditions for the ratio-consistency of these proposed unbiased estimators are then deduced. As an application, a novel procedure using these invariant estimators to rank high-dimensional data is proposed.},
  archive      = {J_SJOS},
  author       = {Jia Guo and Bu Zhou},
  doi          = {10.1111/sjos.12781},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {1092--1110},
  shortjournal = {Scand. J. Stat.},
  title        = {Ratio-consistency of some invariant U-statistic-based estimators with an application to high-dimensional data ranking},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Road traffic estimation and algorithmic routing in a spatially dependent network. <em>SJOS</em>, <em>52</em>(2), 1058--1091. (<a href='https://doi.org/10.1111/sjos.12780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work concerns a procedure to estimate the joint distribution of the per-edge travel times in a road traffic network with spatial dependence. The constructed estimator, based on the realized travel times of a collection of independently operating probe vehicles traversing the network, is shown to be consistent and rate-optimal. The obtained estimates of the joint travel-time distribution can be used in routing policies. In particular, as realized travel times are observed en route to the destination, spatial dependence can be leveraged to iteratively update the predictive distribution of the remaining travel time. Importantly, we can deal with general objective functions, reflecting the individual traveler's specific risk aversion, including ones that involve the uncertainty of the estimates. Through a series of numerical experiments, we systematically study the estimator's performance in combination with specific routing policies and objective functions.},
  archive      = {J_SJOS},
  author       = {Rens Kamphuis and Michel Mandjes and Paulo Serra},
  doi          = {10.1111/sjos.12780},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {1058--1091},
  shortjournal = {Scand. J. Stat.},
  title        = {Road traffic estimation and algorithmic routing in a spatially dependent network},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Kernel density estimation in metric spaces. <em>SJOS</em>, <em>52</em>(2), 1018--1057. (<a href='https://doi.org/10.1111/sjos.12779'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-Euclidean data analysis has become a crucial task in modern statistics, given the rapid emergence of non-Euclidean data in various fields. However, fundamental tools for non-Euclidean statistics are still lacking or under development. In this paper, we propose a generalized probability density estimation method for metric spaces, based on the metric distribution function. We extend the conventional kernel density estimation method to metric spaces and introduce local and global versions of metric kernel density estimation. We establish their large sample properties under regularity conditions. Furthermore, we develop a mean integrated squared error-based bandwidth selection criterion for these new estimators. Extensive simulations under various settings are conducted to demonstrate the finite-sample performance of our proposed estimators. We exemplify the efficacy of our methods using hippocampal data, specifically capturing hippocampal surface changes of representative samples at different levels of Alzheimer's disease (AD) and exploring factors affecting hippocampus shape and AD severity.},
  archive      = {J_SJOS},
  author       = {Chenfei Gu and Mian Huang and Xinyu Song and Xueqin Wang},
  doi          = {10.1111/sjos.12779},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {1018--1057},
  shortjournal = {Scand. J. Stat.},
  title        = {Kernel density estimation in metric spaces},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptively robust small area estimation: Balancing robustness and efficiency of empirical bayes confidence intervals. <em>SJOS</em>, <em>52</em>(2), 999--1017. (<a href='https://doi.org/10.1111/sjos.12778'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Empirical Bayes (EB) small area estimation based on the well-known Fay-Herriot model may produce unreliable estimates when outlying areas exist. Existing robust methods against outliers or model misspecification are generally inefficient when the assumed distribution is plausible. This article proposes a simple modification of the standard EB methods with adaptively balancing robustness and efficiency. The proposed method uses -divergence instead of the marginal log-likelihood and optimizes a tuning parameter controlling robustness by pursuing the efficiency of EB confidence intervals for areal parameters. We provide an asymptotic theory of the proposed method under both the correct specification of the assumed distribution and the existence of outlying areas. We investigate the numerical performance of the proposed method through simulations and two applications to small area estimation of average crime numbers.},
  archive      = {J_SJOS},
  author       = {Daisuke Kurisu and Takuya Ishihara and Shonosuke Sugasawa},
  doi          = {10.1111/sjos.12778},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {999--1017},
  shortjournal = {Scand. J. Stat.},
  title        = {Adaptively robust small area estimation: Balancing robustness and efficiency of empirical bayes confidence intervals},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Statistical inference in the presence of imputed survey data through regression trees and random forests. <em>SJOS</em>, <em>52</em>(2), 960--998. (<a href='https://doi.org/10.1111/sjos.12777'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Item nonresponse in surveys is usually handled through some form of imputation. In recent years, imputation through machine learning procedures has attracted a lot of attention in national statistical offices. However, little is known about the theoretical properties of the resulting point estimators in a survey setting. In this article, we study regression trees and random forests that provide flexible tools for obtaining imputed values. In a high-dimensional framework allowing the number of predictors to diverge, we lay out a set of conditions for establishing the mean square consistency of regression trees and random forests imputed estimators of a finite population mean. We propose a novel variance estimator based on a -fold cross-validation procedure. The proposed point and variance estimation are assessed through a simulation study in terms of bias, efficiency, and coverage rate of normal-based confidence intervals. Finally, the choice of hyperparameters involved in random forest algorithms is investigated through theoretical and empirical work.},
  archive      = {J_SJOS},
  author       = {Mehdi Dagdoug and Camelia Goga and David Haziza},
  doi          = {10.1111/sjos.12777},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {960--998},
  shortjournal = {Scand. J. Stat.},
  title        = {Statistical inference in the presence of imputed survey data through regression trees and random forests},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On high-dimensional variance estimation in survey sampling. <em>SJOS</em>, <em>52</em>(2), 924--959. (<a href='https://doi.org/10.1111/sjos.12776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using predictive modeling at different survey stages can improve the accuracy of a point estimator or help tackle issues such as missing values. So far, the existing literature on predictive models for survey data has predominantly concentrated on scenarios with low-dimensional data, wherein the number of variables is small compared with the sample size. In this article, assuming a linear regression model, we show that customary variance estimators based on a first Taylor expansion or jackknife may suffer from substantial bias in a high-dimensional setting. We explain why this is so through a mix of theoretical and empirical investigations. We propose some bias-adjusted variance estimators and show, theoretically and empirically, that the proposed variance estimators perform well in terms of bias, even in a high-dimensional setting.},
  archive      = {J_SJOS},
  author       = {Esther Eustache and Mehdi Dagdoug and David Haziza},
  doi          = {10.1111/sjos.12776},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {924--959},
  shortjournal = {Scand. J. Stat.},
  title        = {On high-dimensional variance estimation in survey sampling},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A joint estimation approach for monotonic regression functions in general dimensions. <em>SJOS</em>, <em>52</em>(2), 903--923. (<a href='https://doi.org/10.1111/sjos.12775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regression analysis under the assumption of monotonicity is a well-studied statistical problem and has been used in a wide range of applications. However, there remains a lack of a broadly applicable methodology that permits information borrowing, for efficiency gains, when jointly estimating multiple monotonic regression functions. We fill this gap in the literature and introduce a methodology which can be applied to both fixed and random designs and any number of explanatory variables (regressors). Our framework penalizes pairwise differences in the values of the monotonic function estimates, with the weight of penalty being determined, for instance, based on a statistical test for equivalence of functions at a point. Function estimates are subsequently derived using an iterative optimization routine which updates the individual function estimates in turn until convergence. Simulation studies for normally and binomially distributed response data illustrate that function estimates are improved when similarities between functions exist, and are not oversmoothed otherwise. We further apply our methodology to analyze two public health data sets: neonatal mortality data for Porto Alegre, Brazil, and stroke patient data for North West England.},
  archive      = {J_SJOS},
  author       = {Christian Rohrbeck and Deborah A. Costain},
  doi          = {10.1111/sjos.12775},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {903--923},
  shortjournal = {Scand. J. Stat.},
  title        = {A joint estimation approach for monotonic regression functions in general dimensions},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conditional Aalen–Johansen estimation. <em>SJOS</em>, <em>52</em>(2), 873--902. (<a href='https://doi.org/10.1111/sjos.12774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conditional Aalen–Johansen estimator, a general-purpose nonparametric estimator of conditional state occupation probabilities, is introduced. The estimator is applicable for any finite-state jump process and supports conditioning on external as well as internal covariate information. The conditioning feature permits for a much more detailed analysis of the distributional characteristics of the process. The estimator reduces to the conditional Kaplan–Meier estimator in the special case of a survival model and also englobes other, more recent, landmark estimators when covariates are discrete. Strong uniform consistency and asymptotic normality are established under lax moment conditions on the multivariate counting process, allowing in particular for an unbounded number of transitions.},
  archive      = {J_SJOS},
  author       = {Martin Bladt and Christian Furrer},
  doi          = {10.1111/sjos.12774},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {873--902},
  shortjournal = {Scand. J. Stat.},
  title        = {Conditional Aalen–Johansen estimation},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Likelihood analysis of latent functional response regression models for sequences of correlated binary data. <em>SJOS</em>, <em>52</em>(2), 840--872. (<a href='https://doi.org/10.1111/sjos.12773'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we study a functional regression setting where the random response curve is unobserved, and only its dichotomized version observed at a sequence of correlated binary data is available. We propose a practical computational framework for maximum likelihood analysis via the parameter expansion technique. Our proposal relies on the use of a complete data likelihood which can handle non-equally spaced and missing observations effectively. The proposed method is used in the Function-on-Scalar regression setting, with the latent response variable being a Gaussian random element taking values in a separable Hilbert space. Smooth estimates of functional regression coefficients and principal components are provided by introducing a novel adaptive EM algorithm. Finally, the performance of our novel method is demonstrated by various simulation studies and on a real case study. The proposed method is implemented in the R package dfrr . Supporting Information for this article are available online.},
  archive      = {J_SJOS},
  author       = {Fatemeh Asgari and Mohammad H. Alamatsaz and Saeed Hayati and Valeria Vitelli},
  doi          = {10.1111/sjos.12773},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {840--872},
  shortjournal = {Scand. J. Stat.},
  title        = {Likelihood analysis of latent functional response regression models for sequences of correlated binary data},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Support estimation and sign recovery in high-dimensional heteroscedastic mean regression. <em>SJOS</em>, <em>52</em>(2), 805--839. (<a href='https://doi.org/10.1111/sjos.12772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A current strand of research in high-dimensional statistics deals with robustifying the methodology with respect to deviations from the pervasive light-tail assumptions. In this article, we consider a linear mean regression model with random design and potentially heteroscedastic, heavy-tailed errors, and investigate support estimation and sign recovery. We use a strictly convex, smooth variant of the Huber loss function with tuning parameters depending on the parameters of the problem, as well as the adaptive LASSO penalty for computational efficiency. For the resulting estimator, we show sign-consistency and optimal rates of convergence in the norm as in the homoscedastic, light-tailed setting. In our simulations, we also connect to the recent literature on variable selection with the thresholded LASSO and false discovery rate control using knockoffs and indicate the relevance of the Donoho-Tanner transition curve for variable selection. The simulations illustrate the favorable numerical performance of the proposed methodology.},
  archive      = {J_SJOS},
  author       = {Philipp Hermann and Hajo Holzmann},
  doi          = {10.1111/sjos.12772},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {805--839},
  shortjournal = {Scand. J. Stat.},
  title        = {Support estimation and sign recovery in high-dimensional heteroscedastic mean regression},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the properties of distance covariance for categorical data: Robustness, sure screening, and approximate null distributions. <em>SJOS</em>, <em>52</em>(2), 777--804. (<a href='https://doi.org/10.1111/sjos.12771'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pearson's Chi-squared test, though widely used for detecting association between categorical variables, exhibits low statistical power in large sparse contingency tables. To address this limitation, two novel permutation tests have been recently developed: The distance covariance permutation test and the U-statistic permutation test. Both leverage the distance covariance functional but employ different estimators. In this work, we explore key statistical properties of the distance covariance for categorical variables. Firstly, we show that, unlike Chi-squared, the distance covariance functional is B-robust for any number of categories (fixed or diverging). Second, we establish the strong consistency of distance covariance screening under mild conditions, and simulations confirm its advantage over Chi-squared screening, especially for large sparse tables. We illustrate this novel screening method using the General Social Survey data. Finally, we derive an approximate null distribution for a bias-corrected distance correlation estimate, demonstrating its effectiveness through simulations and real-world applications.},
  archive      = {J_SJOS},
  author       = {Qingyang Zhang},
  doi          = {10.1111/sjos.12771},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {777--804},
  shortjournal = {Scand. J. Stat.},
  title        = {On the properties of distance covariance for categorical data: Robustness, sure screening, and approximate null distributions},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Post-selection inference for high-dimensional mediation analysis with survival outcomes. <em>SJOS</em>, <em>52</em>(2), 756--776. (<a href='https://doi.org/10.1111/sjos.12770'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is of substantial scientific interest to detect mediators that lie in the causal pathway from an exposure to a survival outcome. However, with high-dimensional mediators, as often encountered in modern genomic data settings, there is a lack of powerful methods that can provide valid post-selection inference for the identified marginal mediation effect. To resolve this challenge, we develop a post-selection inference procedure for the maximally selected natural indirect effect using a semiparametric efficient influence function approach. To this end, we establish the asymptotic normality of a stabilized one-step estimator that takes the selection of the mediator into account. Simulation studies show that our proposed method has good empirical performance. We further apply our proposed approach to a lung cancer dataset and find multiple DNA methylation CpG sites that might mediate the effect of cigarette smoking on lung cancer survival.},
  archive      = {J_SJOS},
  author       = {Tzu-Jung Huang and Zhonghua Liu and Ian W. McKeague},
  doi          = {10.1111/sjos.12770},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {756--776},
  shortjournal = {Scand. J. Stat.},
  title        = {Post-selection inference for high-dimensional mediation analysis with survival outcomes},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust composite quantile regression with large-scale streaming data sets. <em>SJOS</em>, <em>52</em>(2), 736--755. (<a href='https://doi.org/10.1111/sjos.12769'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Composite quantile regression (CQR) has advantages in robustness and high estimation efficiency. In modern statistical learning, we often encounter streaming data sets with unbounded cumulative data sizes. However, limited computer memory and non-smoothness of CQR objective function pose challenges to methods and algorithms. An interesting issue is how to implement CQR in the streaming data setting. To address this issue, this article first constructs a smooth CQR, and then an online renewable CQR procedure is proposed. In theory, the oracle property of the proposed renewable estimator is established, which gives theoretical guarantees. Numerical experiments also confirm the proposed methods.},
  archive      = {J_SJOS},
  author       = {Kangning Wang and Di Zhang and Xiaofei Sun},
  doi          = {10.1111/sjos.12769},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {736--755},
  shortjournal = {Scand. J. Stat.},
  title        = {Robust composite quantile regression with large-scale streaming data sets},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Post-selection inference for the cox model with interval-censored data. <em>SJOS</em>, <em>52</em>(2), 710--735. (<a href='https://doi.org/10.1111/sjos.12768'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a postselection inference method for the Cox proportional hazards model with interval-censored data, which provides asymptotically valid p -values and confidence intervals conditional on the model selected by lasso. The method is based on a pivotal quantity that is shown to converge to a uniform distribution under local parameters. Our method involves estimation of the efficient information matrix, for which several approaches are proposed with proof of their consistency. Thorough simulation studies show that our method has satisfactory performance in samples of modest sizes. The utility of the method is illustrated via an application to an Alzheimer's disease study.},
  archive      = {J_SJOS},
  author       = {Jianrui Zhang and Chenxi Li and Haolei Weng},
  doi          = {10.1111/sjos.12768},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {710--735},
  shortjournal = {Scand. J. Stat.},
  title        = {Post-selection inference for the cox model with interval-censored data},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel semiparametric approach to nonignorable missing data by catching covariate marginal information. <em>SJOS</em>, <em>52</em>(2), 691--709. (<a href='https://doi.org/10.1111/sjos.12767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonignorable missing data problems are challenging because of the parameter identifiability issue. Existing methods designed for handling nonignorable missing data often struggle to fully utilize covariate marginal information, leading to potential efficiency losses. We propose a novel approach that leverages both a logistic propensity score model and a semiparametric proportional likelihood ratio model (SPLRM) for the observed data. Our approach generally does not require instrumental variables or shadow variables, leading to improved identifiability in most scenarios. In the identifiable case, we use the density-ratio-model-based empirical likelihood to catch the covariate distribution information and estimate the target parameter. The proposed estimator is shown to be asymptotically normal and semiparametric efficient. In the exception case, we conduct a sensitivity analysis by making full use of the marginal covariate information. Our numerical results indicate that compared with existing estimators, the proposed estimator is more reliable and more robust to model mis-specification.},
  archive      = {J_SJOS},
  author       = {Manli Cheng and Yukun Liu and Jing Qin},
  doi          = {10.1111/sjos.12767},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {691--709},
  shortjournal = {Scand. J. Stat.},
  title        = {A novel semiparametric approach to nonignorable missing data by catching covariate marginal information},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive framework for evaluating time to event predictions using the restricted mean survival time. <em>SJOS</em>, <em>52</em>(2), 658--690. (<a href='https://doi.org/10.1111/sjos.12766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The restricted mean survival time (RMST) is a widely used quantity in survival analysis due to its straightforward interpretation. For instance, predicting the time to event based on patient attributes is of great interest when analyzing medical data. In this paper, we propose a novel framework for evaluating RMST estimations. A criterion that estimates the mean squared error of an RMST estimator using Inverse Probability Censoring Weighting (IPCW) is presented. A model-agnostic conformal algorithm adapted to right-censored data is also introduced to compute prediction intervals and to evaluate local variable importance. Finally, a model-agnostic statistical test is developed to assess global variable importance. Our framework is valid for any RMST estimator that is asymptotically convergent and works under model misspecification.},
  archive      = {J_SJOS},
  author       = {Ariane Cwiling and Vittorio Perduca and Olivier Bouaziz},
  doi          = {10.1111/sjos.12766},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {658--690},
  shortjournal = {Scand. J. Stat.},
  title        = {A comprehensive framework for evaluating time to event predictions using the restricted mean survival time},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enriched Pitman–Yor processes. <em>SJOS</em>, <em>52</em>(2), 631--657. (<a href='https://doi.org/10.1111/sjos.12765'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian non-parametrics has evolved into a broad area encompassing flexible methods for Bayesian inference, combinatorial structures, tools for complex data reduction, and more. Discrete prior laws play an important role in these developments, and various choices are available nowadays. However, many existing priors, such as the Dirichlet process, have limitations if data require nested clustering structures. Thus, we introduce a discrete non-parametric prior, termed the enriched Pitman–Yor process, which offers higher flexibility in modeling such elaborate partition structures. We investigate the theoretical properties of this novel prior and establish its formal connection with the enriched Dirichlet process and normalized random measures. Additionally, we present a square-breaking representation and derive closed-form expressions for the posterior law and associated urn schemes. Furthermore, we demonstrate that several established models, including Dirichlet processes with a spike-and-slab base measure and mixture of mixtures models, emerge as special instances of the enriched Pitman–Yor process, which therefore serves as a unified probabilistic framework for various Bayesian non-parametric priors. To illustrate its practical utility, we employ the enriched Pitman–Yor process for a species-sampling ecological problem.},
  archive      = {J_SJOS},
  author       = {Tommaso Rigon and Sonia Petrone and Bruno Scarpa},
  doi          = {10.1111/sjos.12765},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {631--657},
  shortjournal = {Scand. J. Stat.},
  title        = {Enriched Pitman–Yor processes},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted reduced rank estimators under cointegration rank uncertainty. <em>SJOS</em>, <em>52</em>(2), 595--630. (<a href='https://doi.org/10.1111/sjos.12764'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cointegration analysis was developed for nonstationary linear processes that exhibit stationary relationships between coordinates. Estimation of the cointegration relationships in a multidimensional cointegrated process typically proceeds in two steps. First, the rank is estimated, then the auto-regression matrix is estimated, conditionally on the estimated rank (reduced rank regression). The asymptotics of the estimator is usually derived under the assumption of knowing the true rank. In this paper, we quantify the asymptotic bias and find the asymptotic distributions of the cointegration estimator in case of misspecified rank. Furthermore, we suggest a new class of weighted reduced rank estimators that allow for more flexibility in settings where rank selection is hard. We show empirically that a proper choice of weights can lead to increased predictive performance when there is rank uncertainty. Finally, we illustrate the estimators on empirical EEG data from a psychological experiment on visual processing.},
  archive      = {J_SJOS},
  author       = {Christian Holberg and Susanne Ditlevsen},
  doi          = {10.1111/sjos.12764},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {595--630},
  shortjournal = {Scand. J. Stat.},
  title        = {Weighted reduced rank estimators under cointegration rank uncertainty},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph neural networks for the localization of faults in a partially observed regional transmission system. <em>SJOS</em>, <em>52</em>(2), 572--594. (<a href='https://doi.org/10.1111/sjos.12763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Localization of faults in a large power system is one of the most important and difficult tasks of power systems monitoring. A fault, typically a shorted line, can be seen almost instantaneously by all measurement devices throughout the system, but determining its location in a geographically vast and topologically complex system is difficult. The task becomes even more difficult if measurements devices are placed only at some network nodes. We show that regression graph neural networks we construct, combined with a suitable statistical methodology, can solve this task very well. A chief advance of our methods is that we construct networks that produce localization without having being trained on data that contain fault localization information. We show that a synergy of statistics and deep learning can produce results that none of these approaches applied separately can achieve.},
  archive      = {J_SJOS},
  author       = {Mantautas Rimkus and Piotr Kokoszka and Dongliang Duan and Xuao Wang and Haonan Wang},
  doi          = {10.1111/sjos.12763},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {572--594},
  shortjournal = {Scand. J. Stat.},
  title        = {Graph neural networks for the localization of faults in a partially observed regional transmission system},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal designs for testing pairwise differences: A graph-based game theoretic approach. <em>SJOS</em>, <em>52</em>(2), 533--571. (<a href='https://doi.org/10.1111/sjos.12757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a variety of experimental settings there is an interest in comparing pairs–of–treatments. Such experiments usually address one of the following two scientific questions: (1) is there a difference within any of the selected pairs of treatments? or (2) is there a difference within all of the selected pairs of treatments? In this article, we propose max–min optimal designs for testing the above hypotheses using a graph-based game theoretic approach. Some of the max–min designs obtained are well known, but not recognized as optimal, others are novel and provide an improvement over naive designs.},
  archive      = {J_SJOS},
  author       = {Arpan Singh and Satya Prakash Singh and Ori Davidov},
  doi          = {10.1111/sjos.12757},
  journal      = {Scandinavian Journal of Statistics},
  month        = {6},
  number       = {2},
  pages        = {533--571},
  shortjournal = {Scand. J. Stat.},
  title        = {Optimal designs for testing pairwise differences: A graph-based game theoretic approach},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The effect of screening for publication bias on the outcomes of meta-analyses. <em>SJOS</em>, <em>52</em>(1), 513--531. (<a href='https://doi.org/10.1111/sjos.12762'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conducting a meta-analysis on a body of studies subject to publication bias is a type of post-selection inference that may invalidate findings. Therefore, analysts often run a hypothesis test to check for publication bias prior to conducting a meta-analysis. However, conducting meta-analyses conditional on the outcome of such preliminary tests is itself a form of post-selection inference. We investigate the effect on the outcome of a meta-analysis of a null finding at the preliminary stage. We find that in many situations there is no or little bias in the findings at the main stage.},
  archive      = {J_SJOS},
  author       = {Haben Michael},
  doi          = {10.1111/sjos.12762},
  journal      = {Scandinavian Journal of Statistics},
  month        = {3},
  number       = {1},
  pages        = {513--531},
  shortjournal = {Scand. J. Stat.},
  title        = {The effect of screening for publication bias on the outcomes of meta-analyses},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new class of nonparametric tests for second-order stochastic dominance based on the lorenz P–P plot. <em>SJOS</em>, <em>52</em>(1), 480--512. (<a href='https://doi.org/10.1111/sjos.12761'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given samples from two non-negative random variables, we propose a family of tests for the null hypothesis that one random variable stochastically dominates the other at the second order. Test statistics are obtained as functionals of the difference between the identity and the Lorenz P–P plot, defined as the composition between the inverse unscaled Lorenz curve of one distribution and the unscaled Lorenz curve of the other. We determine upper bounds for such test statistics under the null hypothesis and derive their limit distribution, to be approximated via bootstrap procedures. We then establish the asymptotic validity of the tests under relatively mild conditions and investigate finite-sample properties through simulations. The results show that our testing approach can be a valid alternative to classic methods based on the difference in the integrals of the cumulative distribution functions, which require bounded support and struggle to detect departures from the null in some cases. The same approach can be extended to a family of fractional-degree stochastic orders, including the first order as a limiting case.},
  archive      = {J_SJOS},
  author       = {Tommaso Lando and Sirio Legramanti},
  doi          = {10.1111/sjos.12761},
  journal      = {Scandinavian Journal of Statistics},
  month        = {3},
  number       = {1},
  pages        = {480--512},
  shortjournal = {Scand. J. Stat.},
  title        = {A new class of nonparametric tests for second-order stochastic dominance based on the lorenz P–P plot},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting the sequence symmetry analysis design. <em>SJOS</em>, <em>52</em>(1), 469--479. (<a href='https://doi.org/10.1111/sjos.12759'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this paper is to re-examine the sequence symmetry analysis (SSA) in a mathematical framework to improve the understanding and use of the design. The mathematical properties of the crude, null-effects, and adjusted sequence ratios (SR) are analyzed in the presence of prescription time-trends and unmeasured time-invariant confounding. The theoretical results are illustrated in a simulation study. The crude SR can be interpreted as an estimator of the hazard ratio (HR) of treatment when the allowed time between initiation of the treatment and the outcome drug is small. The HR can easily be estimated flexibly as a function of covariates, such as age and sex, using logistic regression. The crude SR implicitly adjusts for unmeasured time-invariant confounding, whereas the null-effects SR, and thereby the adjusted SR, make little sense unless treatment and outcome are strictly independent. The use of the adjusted SR should be abandoned. Another design should be used if it is infeasible to require treatment and outcome sufficiently close. The crude SR can be modeled flexibly with logistic regression to estimate covariate-dependent HRs or at least to test whether the HR depends on covariates.},
  archive      = {J_SJOS},
  author       = {Jeppe Ekstrand Halkjær Madsen},
  doi          = {10.1111/sjos.12759},
  journal      = {Scandinavian Journal of Statistics},
  month        = {3},
  number       = {1},
  pages        = {469--479},
  shortjournal = {Scand. J. Stat.},
  title        = {Revisiting the sequence symmetry analysis design},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven estimation for multithreshold accelerated failure time model. <em>SJOS</em>, <em>52</em>(1), 447--468. (<a href='https://doi.org/10.1111/sjos.12758'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops a novel estimation framework for the multithreshold accelerated failure time model, which has distinct linear forms within different subdomains. One major challenge is to determine the number of threshold effects. We first show the selection consistency of a modified Bayesian information criterion under mild conditions. It is useful sometimes but heavily depends on the penalization magnitude, which usually varies from the model configuration and data distribution. To address this issue, we leverage a cross-validation criterion alongside an order-preserved sample-splitting scheme to yield a consistent estimation. The new criterion is completely data driven without additional parameters and thus robust to model setting and data distributions. The asymptotic properties for the parameter estimates are also carefully established. Additionally, we propose an efficient score-type test to examine the existence of threshold effects. The new statistic is free of estimating any potential threshold effects and is thus suitable for multithreshold scenarios. Numerical experiments validate the reliable finite-sample performance of our methodologies, which corroborates the theoretical results.},
  archive      = {J_SJOS},
  author       = {Chuang Wan and Hao Zeng and Wenyang Zhang and Wei Zhong and Changliang Zou},
  doi          = {10.1111/sjos.12758},
  journal      = {Scandinavian Journal of Statistics},
  month        = {3},
  number       = {1},
  pages        = {447--468},
  shortjournal = {Scand. J. Stat.},
  title        = {Data-driven estimation for multithreshold accelerated failure time model},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-assisted analysis of covariance estimators for stepped wedge cluster randomized experiments. <em>SJOS</em>, <em>52</em>(1), 416--446. (<a href='https://doi.org/10.1111/sjos.12755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stepped wedge cluster randomized experiments (SW-CREs) represent a class of unidirectional crossover designs. Although SW-CREs have become popular, definitions of estimands and robust methods to target estimands under the potential outcomes framework remain insufficient. To address this gap, we describe a class of estimands that explicitly acknowledge the multilevel data structure in SW-CREs and highlight three typical members of the estimand class that are interpretable. We then introduce four analysis of covariance (ANCOVA) working models to achieve estimand-aligned analyses with covariate adjustment. Each ANCOVA estimator is model-assisted, as its point estimator is consistent even when the working model is misspecified. Under the stepped wedge randomization scheme, we establish the finite population Central Limit Theorem for each estimator. We study the finite-sample operating characteristics of the ANCOVA estimators in simulations and illustrate their application by analyzing the Washington State Expedited Partner Therapy study.},
  archive      = {J_SJOS},
  author       = {Xinyuan Chen and Fan Li},
  doi          = {10.1111/sjos.12755},
  journal      = {Scandinavian Journal of Statistics},
  month        = {3},
  number       = {1},
  pages        = {416--446},
  shortjournal = {Scand. J. Stat.},
  title        = {Model-assisted analysis of covariance estimators for stepped wedge cluster randomized experiments},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tobit models for count time series. <em>SJOS</em>, <em>52</em>(1), 381--415. (<a href='https://doi.org/10.1111/sjos.12751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several models for count time series have been developed during the last decades, often inspired by traditional autoregressive moving average (ARMA) models for real-valued time series, including integer-valued ARMA (INARMA) and integer-valued generalized autoregressive conditional heteroscedasticity (INGARCH) models. Both INARMA and INGARCH models exhibit an ARMA-like autocorrelation function (ACF). To achieve negative ACF values within the class of INGARCH models, log and softplus link functions are suggested in the literature, where the softplus approach leads to conditional linearity in good approximation. However, the softplus approach is limited to the INGARCH family for unbounded counts, that is, it can neither be used for bounded counts, nor for count processes from the INARMA family. In this paper, we present an alternative solution, named the Tobit approach, for achieving approximate linearity together with negative ACF values, which is more generally applicable than the softplus approach. A Skellam–Tobit INGARCH model for unbounded counts is studied in detail, including stationarity, approximate computation of moments, maximum likelihood and censored least absolute deviations estimation for unknown parameters and corresponding simulations. Extensions of the Tobit approach to other situations are also discussed, including underlying discrete distributions, INAR models, and bounded counts. Three real-data examples are considered to illustrate the usefulness of the new approach.},
  archive      = {J_SJOS},
  author       = {Christian H. Weiß and Fukang Zhu},
  doi          = {10.1111/sjos.12751},
  journal      = {Scandinavian Journal of Statistics},
  month        = {3},
  number       = {1},
  pages        = {381--415},
  shortjournal = {Scand. J. Stat.},
  title        = {Tobit models for count time series},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Goodness-of-fit testing based on graph functionals for homogeneous Erdös–Rényi graphs. <em>SJOS</em>, <em>52</em>(1), 332--380. (<a href='https://doi.org/10.1111/sjos.12750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Erdös–Rényi graph is a popular choice to model network data as it is parsimoniously parameterized, straightforward to interpret and easy to estimate. However, it has limited suitability in practice, since it often fails to capture crucial characteristics of real-world networks. To check its adequacy, we propose a novel class of goodness-of-fit tests for homogeneous Erdös–Rényi models against heterogeneous alternatives that permit nonconstant edge probabilities. We allow for both asymptotically dense and sparse networks. The tests are based on graph functionals that cover a broad class of network statistics for which we derive limiting distributions in a unified manner. The resulting class of asymptotic tests includes several existing tests as special cases. Further, we propose a parametric bootstrap and prove its consistency, which avoids the often tedious variance estimation for asymptotic tests and enables performance improvements for small network sizes. Moreover, under certain fixed and local alternatives, we provide a power analysis for some popular choices of subgraph counts as goodness-of-fit test statistics. We evaluate the proposed class of tests and illustrate our theoretical findings by simulations.},
  archive      = {J_SJOS},
  author       = {Barbara Brune and Jonathan Flossdorf and Carsten Jentsch},
  doi          = {10.1111/sjos.12750},
  journal      = {Scandinavian Journal of Statistics},
  month        = {3},
  number       = {1},
  pages        = {332--380},
  shortjournal = {Scand. J. Stat.},
  title        = {Goodness-of-fit testing based on graph functionals for homogeneous Erdös–Rényi graphs},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cutoff for a class of auto-regressive models with vanishing additive noise. <em>SJOS</em>, <em>52</em>(1), 314--331. (<a href='https://doi.org/10.1111/sjos.12748'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the convergence rates for a family of auto-regressive Markov chains on Euclidean space depending on a parameter n $$ n $$ , where at each step a randomly chosen coordinate is replaced by a noisy damped weighted average of the others. The interest in the model comes from the connection with a certain Bayesian scheme introduced by de Finetti in the analysis of partially exchangeable data. Our main result shows that, when n gets large (corresponding to a vanishing noise), a cutoff phenomenon occurs.},
  archive      = {J_SJOS},
  author       = {Balázs Gerencsér and Andrea Ottolini},
  doi          = {10.1111/sjos.12748},
  journal      = {Scandinavian Journal of Statistics},
  month        = {3},
  number       = {1},
  pages        = {314--331},
  shortjournal = {Scand. J. Stat.},
  title        = {Cutoff for a class of auto-regressive models with vanishing additive noise},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A classical hypothesis test for assessing the homogeneity of disease transmission in stochastic epidemic models. <em>SJOS</em>, <em>52</em>(1), 295--313. (<a href='https://doi.org/10.1111/sjos.12743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of assessing the homogeneity of the disease transmission process in stochastic epidemic models in populations that are partitioned into social groups. We develop a classical hypothesis test for completed epidemics which assesses whether or not there is significant within-group transmission during an outbreak. The test is based on time-ordered group labels of individuals. The null hypothesis is that of homogeneity of disease transmission among individuals, a hypothesis under which the discrete random vector of groups labels has a known sampling distribution that is independent of any model parameters. The test exhibits excellent performance when applied to various scenarios of simulated data and is also illustrated using two real-life epidemic data sets. We develop some asymptotic theory including a central limit theorem. The test is practically very appealing, being computationally cheap and straightforward to implement, as well as being applicable to a wide range of real-life outbreak settings and to related problems in other fields.},
  archive      = {J_SJOS},
  author       = {Georgios Aristotelous and Theodore Kypraios and Philip D. O'Neill},
  doi          = {10.1111/sjos.12743},
  journal      = {Scandinavian Journal of Statistics},
  month        = {3},
  number       = {1},
  pages        = {295--313},
  shortjournal = {Scand. J. Stat.},
  title        = {A classical hypothesis test for assessing the homogeneity of disease transmission in stochastic epidemic models},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inference for all variants of the multivariate coefficient of variation in factorial designs. <em>SJOS</em>, <em>52</em>(1), 270--294. (<a href='https://doi.org/10.1111/sjos.12740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multivariate coefficient of variation (MCV) is an attractive and easy-to-interpret effect size for the dispersion in multivariate data. Recently, the first inference methods for the MCV were proposed for general factorial designs. However, the inference methods are primarily derived for one special MCV variant while there are several reasonable proposals. Moreover, when rejecting a global null hypothesis, a more in-depth analysis is of interest to find the significant contrasts of MCV. This paper concerns extending the nonparametric permutation procedure to the other MCV variants and a max-type test for post hoc analysis. To improve the small sample performance of the latter, we suggest a novel bootstrap strategy and prove its asymptotic validity. The actual performance of all proposed tests is compared in an extensive simulation study and illustrated by real data analysis. All methods are implemented in the R package GFDmcv, available on CRAN.},
  archive      = {J_SJOS},
  author       = {Marc Ditzhaus and Łukasz Smaga},
  doi          = {10.1111/sjos.12740},
  journal      = {Scandinavian Journal of Statistics},
  month        = {3},
  number       = {1},
  pages        = {270--294},
  shortjournal = {Scand. J. Stat.},
  title        = {Inference for all variants of the multivariate coefficient of variation in factorial designs},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adjusted location-invariant U-tests for the covariance matrix with elliptically high-dimensional data. <em>SJOS</em>, <em>52</em>(1), 249--269. (<a href='https://doi.org/10.1111/sjos.12738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes several covariance matrix U-tests, which are constructed by modifying the classical John-Nagao and Ledoit-Wolf tests, under the elliptically distributed data structure. We study the limiting distributions of these location-invariant test statistics as the data dimension p $$ p $$ may go to infinity in an arbitrary way as the sample size n $$ n $$ does. We find that they tend to have unsatisfactory size performances for general elliptical population. This is mainly because such population often possesses high-order correlations among their coordinates. Taking such kind of dependency into consideration, we propose necessary corrections for these tests to cope with elliptically high-dimensional data. For computational efficiency, alternative forms of the new test statistics are also provided. We derive the universal asymptotic null distributions of the proposed test statistics under elliptical distributions and beyond. The powers of the proposed tests are further investigated. The accuracy of the tests is demonstrated by simulations and an empirical study.},
  archive      = {J_SJOS},
  author       = {Kai Xu and Yeqing Zhou and Liping Zhu},
  doi          = {10.1111/sjos.12738},
  journal      = {Scandinavian Journal of Statistics},
  month        = {3},
  number       = {1},
  pages        = {249--269},
  shortjournal = {Scand. J. Stat.},
  title        = {Adjusted location-invariant U-tests for the covariance matrix with elliptically high-dimensional data},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimax rate of estimation for invariant densities associated to continuous stochastic differential equations over anisotropic hölder classes. <em>SJOS</em>, <em>52</em>(1), 185--248. (<a href='https://doi.org/10.1111/sjos.12735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of the nonparametric estimation for the density π $$ \pi $$ of the stationary distribution of a d $$ d $$ -dimensional stochastic differential equation ( X t ) t ∈ [ 0 , T ] $$ {\left({X}_t\right)}_{t\in \left[0,T\right]} $$ . From the continuous observation of the sampling path on [ 0 , T ] $$ \left[0,T\right] $$ , we study the estimation of π ( x ) $$ \pi (x) $$ as T $$ T $$ goes to infinity. For d ≥ 2 $$ d\ge 2 $$ , we characterize the minimax rate for the L 2 $$ {\mathbf{L}}^2 $$ -risk in pointwise estimation over a class of anisotropic Hölder functions π $$ \pi $$ with regularity β = ( β 1 , … , β d ) $$ \beta =\left({\beta}_1,\dots, {\beta}_d\right) $$ . For d ≥ 3 $$ d\ge 3 $$ , our finding is that, having ordered the smoothness such that β 1 ≤ ⋯ ≤ β d $$ {\beta}_1\le \cdots \le {\beta}_d $$ , the minimax rate depends on whether β 2 < β 3 $$ {\beta}_2<{\beta}_3 $$ or β 2 = β 3 $$ {\beta}_2={\beta}_3 $$ . In the first case, this rate is log T T γ $$ {\left(\frac{\log T}{T}\right)}^{\gamma } $$ , and in the second case, it is ( 1 T ) γ $$ {\left(\frac{1}{T}\right)}^{\gamma } $$ , where γ $$ \gamma $$ is an explicit exponent dependent on the dimension and β ‾ 3 $$ {\overline{\beta}}_3 $$ , the harmonic mean of smoothness over the d $$ d $$ directions after excluding β 1 $$ {\beta}_1 $$ and β 2 $$ {\beta}_2 $$ , the smallest ones. We also demonstrate that kernel-based estimators achieve the optimal minimax rate. Furthermore, we propose an adaptive procedure for both L 2 $$ {L}^2 $$ integrated and pointwise risk. In the two-dimensional case, we show that kernel density estimators achieve the rate log T T $$ \frac{\log T}{T} $$ , which is optimal in the minimax sense. Finally we illustrate the validity of our theoretical findings by proposing numerical results.},
  archive      = {J_SJOS},
  author       = {Chiara Amorino and Arnaud Gloter},
  doi          = {10.1111/sjos.12735},
  journal      = {Scandinavian Journal of Statistics},
  month        = {3},
  number       = {1},
  pages        = {185--248},
  shortjournal = {Scand. J. Stat.},
  title        = {Minimax rate of estimation for invariant densities associated to continuous stochastic differential equations over anisotropic hölder classes},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimation of win, loss probabilities, and win ratio based on right-censored event data. <em>SJOS</em>, <em>52</em>(1), 170--184. (<a href='https://doi.org/10.1111/sjos.12734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The win ratio has in the recent decade gained popularity for analyzing prioritized multiple event data in clinical cohort studies, in particular within cardiovascular research. The literature on estimation of the win ratio using censored event data is however sparse. The methods that have been suggested have either an insufficient adjustment of the censoring or by assuming the the win and loss probabilities are proportional over time. The assumption of proportional win and loss probabilities will often in practice not be satisfied. In this paper, we present estimates for the win ratio, and win and loss probabilities, under independent right-censoring and derive the asymptotic distribution of the estimates. The proposed win ratio estimate does not require the assumption of proportional win and loss probabilities. The small sample properties of the proposed method are studied in a simulation study showing that the variance formula is accurate even for small samples. The method is applied on two data sets.},
  archive      = {J_SJOS},
  author       = {Erik T. Parner and Morten Overgaard},
  doi          = {10.1111/sjos.12734},
  journal      = {Scandinavian Journal of Statistics},
  month        = {3},
  number       = {1},
  pages        = {170--184},
  shortjournal = {Scand. J. Stat.},
  title        = {Estimation of win, loss probabilities, and win ratio based on right-censored event data},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lancaster correlation: A new dependence measure linked to maximum correlation. <em>SJOS</em>, <em>52</em>(1), 145--169. (<a href='https://doi.org/10.1111/sjos.12733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We suggest novel correlation coefficients which equal the maximum correlation for a class of bivariate Lancaster distributions while being only slightly smaller than maximum correlation for a variety of further bivariate distributions. In contrast to maximum correlation, however, our correlation coefficients allow for rank and moment-based estimators which are simple to compute and have tractable asymptotic distributions. Confidence intervals resulting from these asymptotic approximations and the covariance bootstrap show good finite-sample coverage. In a simulation, the power of asymptotic as well as permutation tests for independence based on our correlation measures compares favorably with competing methods based on distance correlation or rank coefficients for functional dependence, among others. Moreover, for the bivariate normal distribution, our correlation coefficients equal the absolute value of the Pearson correlation, an attractive feature for practitioners which is not shared by various competitors. We illustrate the practical usefulness of our methods in applications to two real data sets.},
  archive      = {J_SJOS},
  author       = {Hajo Holzmann and Bernhard Klar},
  doi          = {10.1111/sjos.12733},
  journal      = {Scandinavian Journal of Statistics},
  month        = {3},
  number       = {1},
  pages        = {145--169},
  shortjournal = {Scand. J. Stat.},
  title        = {Lancaster correlation: A new dependence measure linked to maximum correlation},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tests under simple order in one-way ANCOVA. <em>SJOS</em>, <em>52</em>(1), 104--144. (<a href='https://doi.org/10.1111/sjos.12729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analysis of covariance (ANCOVA) models are used when apart from the main treatments, some covariates also affect the response variable. In this article, the problem of testing the homogeneity of treatment effects against ordered alternatives is addressed in a fixed effects one-way ANCOVA model when error variances are heterogeneous. The likelihood ratio test (LRT) and two approximate tests based on the asymptotic distributions of some union-intersection type test statistics are proposed. A parametric bootstrap technique has been used to implement the LRT and its asymptotic validity is proved. A method to construct simultaneous confidence intervals is proposed. All the test procedures are further extended to the case of more than one covariate. The robustness of tests is also studied under departure from normality. Extensive simulation studies show that the proposed test procedures perform well in terms of achieving the nominal size value and good power values.},
  archive      = {J_SJOS},
  author       = {Anjana Mondal and Somesh Kumar},
  doi          = {10.1111/sjos.12729},
  journal      = {Scandinavian Journal of Statistics},
  month        = {3},
  number       = {1},
  pages        = {104--144},
  shortjournal = {Scand. J. Stat.},
  title        = {Tests under simple order in one-way ANCOVA},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On maximizing the likelihood function of general geostatistical models. <em>SJOS</em>, <em>52</em>(1), 81--103. (<a href='https://doi.org/10.1111/sjos.12722'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {General geostatistical models are powerful tools for analyzing spatial datasets. A two-step estimation based on the likelihood function is widely used by researchers, but several theoretical and computational challenges remain to be addressed. First, it is unclear whether there is a unique global maximizer of the log-likelihood function, a seemingly simple but theoretically challenging question. The second challenge is the convexity of the log-likelihood function. Besides these two challenges in maximizing the likelihood function, we also study the theoretical property of the two-step estimation. Unlike many previous works, our results can apply to the non-twice differentiable covariance functions. In the simulation studies, three optimization algorithms are evaluated in terms of maximizing the log-likelihood functions.},
  archive      = {J_SJOS},
  author       = {Tingjin Chu},
  doi          = {10.1111/sjos.12722},
  journal      = {Scandinavian Journal of Statistics},
  month        = {3},
  number       = {1},
  pages        = {81--103},
  shortjournal = {Scand. J. Stat.},
  title        = {On maximizing the likelihood function of general geostatistical models},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimax estimation of functional principal components from noisy discretized functional data. <em>SJOS</em>, <em>52</em>(1), 38--80. (<a href='https://doi.org/10.1111/sjos.12719'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional Principal Component Analysis is a reference method for dimension reduction of curve data. Its theoretical properties are now well understood in the simplified case where the sample curves are fully observed without noise. However, functional data are noisy and necessarily observed on a finite discretization grid. Common practice consists in smoothing the data and then to compute the functional estimates, but the impact of this denoising step on the procedure's statistical performance are rarely considered. Here we prove new convergence rates for functional principal component estimators. We introduce a double asymptotic framework: one corresponding to the sampling size and a second to the size of the grid. We prove that estimates based on projection onto histograms show optimal rates in a minimax sense. Theoretical results are illustrated on simulated data and the method is applied to the visualization of genomic data.},
  archive      = {J_SJOS},
  author       = {Ryad Belhakem and Franck Picard and Vincent Rivoirard and Angelina Roche},
  doi          = {10.1111/sjos.12719},
  journal      = {Scandinavian Journal of Statistics},
  month        = {3},
  number       = {1},
  pages        = {38--80},
  shortjournal = {Scand. J. Stat.},
  title        = {Minimax estimation of functional principal components from noisy discretized functional data},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On a computable skorokhod's integral-based estimator of the drift parameter in fractional SDE. <em>SJOS</em>, <em>52</em>(1), 1--37. (<a href='https://doi.org/10.1111/sjos.12711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with a Skorokhod's integral-based least squares- (LS) type estimator of the drift parameter computed from multiple (possibly dependent) copies of the solution of a stochastic differential equation (SDE) driven by a fractional Brownian motion of Hurst index H ∈ ( 1 / 3 , 1 ) $$ H\in \left(1/3,1\right) $$ . On the one hand, some convergence results are established on our LS estimator when H = 1 / 2 $$ H=1/2 $$ . On the other hand, when H ≠ 1 / 2 $$ H\ne 1/2 $$ , Skorokhod's integral-based estimators cannot be computed from data, but in this paper some convergence results are established on a computable approximation of our LS estimator.},
  archive      = {J_SJOS},
  author       = {Nicolas Marie},
  doi          = {10.1111/sjos.12711},
  journal      = {Scandinavian Journal of Statistics},
  month        = {3},
  number       = {1},
  pages        = {1--37},
  shortjournal = {Scand. J. Stat.},
  title        = {On a computable skorokhod's integral-based estimator of the drift parameter in fractional SDE},
  volume       = {52},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
