<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AAIL</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aail">AAIL - 1</h2>
<ul>
<li><details>
<summary>
(2026). An explainable and lightweight CNN framework for robust potato leaf disease classification using grad-CAM visualization. <em>AAIL</em>, <em>7</em>(1), e70011. (<a href='https://doi.org/10.1002/ail2.70011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For identifying foliar diseases in crops at an early stage, accurate detection is necessary in maintaining food security, minimizing economic losses, and cultivating sustainable agriculture. In staple crops, potato is highly vulnerable to lethal diseases like Early Blight and Late Blight that can drastically affect both the quality and the quantity of the yield. Conventional diagnostic procedures using visual observation and/or laboratory examinations are frequently tedious, time-consuming, and susceptible to error. To address these problems, in this research, we propose a novel deep learning architecture using a customized convolutional neural network (CNN) for classifying potato leaf images into three distinct classes, namely Early Blight, Late Blight and Healthy. The model is trained on a selective and heavily augmented subset of the PlantVillage dataset containing 11,593 images and further optimized using regularization techniques like dropout and batch normalization. The system architecture is intended to keep the tradeoff between performance and computational efficiency, so as to fit real-world agricultural scenarios. To increase interpretability and improve trust, we use the Gradient-weighted Class Activation Mapping (Grad-CAM) to visualize the regions in space of the leaves that most contribute to the prediction of the model. The experimental results show superior performance and the proposed model reaches 99.14% accuracy and close-to-perfect precision, recall and F1-scores in all of the classes. Grad-CAM visualizations validate that the model is robust in attending to biologically meaningful regions for the disease symptoms. In addition, we perform comparative analyses against recent state-of-the-art models, and demonstrate that the proposed approach outperforms the others in accuracy and interpretability.},
  archive      = {J_AAIL},
  author       = {MD Jiabul Hoque and Md. Saiful Islam},
  doi          = {10.1002/ail2.70011},
  journal      = {Applied AI Letters},
  month        = {2},
  number       = {1},
  pages        = {e70011},
  shortjournal = {Appl. AI Lett.},
  title        = {An explainable and lightweight CNN framework for robust potato leaf disease classification using grad-CAM visualization},
  volume       = {7},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
