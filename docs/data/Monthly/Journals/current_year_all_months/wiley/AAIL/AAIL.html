<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AAIL</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aail">AAIL - 30</h2>
<ul>
<li><details>
<summary>
(2025). Multi-objective reinforcement learning for automated resilient cyber defence. <em>AAIL</em>, <em>6</em>(3), e70007. (<a href='https://doi.org/10.1002/ail2.70007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-attacks pose a security threat to military command and control networks, Intelligence, Surveillance, and Reconnaissance (ISR) systems, and civilian critical national infrastructure. The use of artificial intelligence and autonomous agents in these attacks increases the scale, range, and complexity of this threat and the subsequent disruption they cause. Autonomous Cyber Defence (ACD) agents aimto mitigate this threat by responding at machine speed and at the scale required to address the problem. Additionally, they reduce the burden on the limited number of human cyber experts available to respond to an attack. Sequential decision-making algorithms such as Deep Reinforcement Learning (RL) provide a promising route to create ACD agents. These algorithms focus on a single objectivesuch as minimising the intrusion of red agents on the network, by using a handcrafted weighted sum of rewards. This approach removes the ability to adapt the model during inference, and fails to address the many competing objectivespresent when operating and protecting these networks. Conflicting objectives, such as restoring a machine from a back-up image, must be carefully balanced with the cost of associated down-time or the disruption to network traffic or services that might result. Instead of pursuing a Single-Objective RL (SORL) approach, here we present a simple example of a multi-objective network defense game that requires consideration of both defending the network against red-agents and maintaining the critical functionality of green-agents. Two Multi-Objective Reinforcement Learning (MORL) algorithms, namely Multi-Objective Proximal Policy Optimization (MOPPO) and Pareto-Conditioned Networks (PCN), are used to create two trained ACD agents whose performance is compared on our Multi-Objective Cyber Defense game. The benefits and limitations of MORL ACD agents in comparison to SORL ACD agents are discussed based on the investigations of this game.},
  archive      = {J_AAIL},
  author       = {Ross O'Driscoll and Claudia Hagen and Joe Bater and James Adams},
  doi          = {10.1002/ail2.70007},
  journal      = {Applied AI Letters},
  month        = {10},
  number       = {3},
  pages        = {e70007},
  shortjournal = {Appl. AI Lett.},
  title        = {Multi-objective reinforcement learning for automated resilient cyber defence},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid AI and fuzzy MCDM approach for retailer evaluation: Leveraging sentiment analysis and expert insights. <em>AAIL</em>, <em>6</em>(3), e70006. (<a href='https://doi.org/10.1002/ail2.70006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a hybrid methodology for evaluating leading retail companies based on customer perspectives, combining Artificial Intelligence (AI)-driven sentiment analysis with fuzzy multiple criteria decision-making (MCDM). The framework integrates large-scale customer review analysis with expert decision-making to provide a comprehensive assessment of retail performance. The process begins with AI-based text mining to collect and analyze customer reviews, extracting emotional tones and identifying frequently mentioned criteria. Expert judgment is then applied to refine, organize, and assign importance to these criteria. The q-rung orthopair fuzzy set MCDM methodology is employed to address uncertainty, conflicting objectives, and qualitative expert opinions by translating them into a structured quantitative evaluation. This hybrid approach offers a balanced assessment that combines subjective and objective dimensions. As a case study, 2000 customer reviews from each of four major U.S. retailers—Amazon, Walmart, Costco, and Target—were analyzed to derive key evaluation criteria based on user feedback. The proposed method distinguishes itself through its unique integration of sentiment analysis and decision-makers' expert evaluations, enabling a holistic and robust evaluation of alternatives. By bridging customer perceptions with expert analysis, this methodology provides a deeper, more nuanced understanding of retailer performance, contributing to improved supplier selection and business decision-making processes. A second analysis, enabled by this methodology, also highlighted key performance differences among the retailers in areas such as customer service, delivery experience, and return/refund processes. Among the findings, Target and Amazon showed the strongest overall sentiment performance, while Costco excelled in return policies and Walmart exhibited weaker results in customer service and delivery. As a result, this hybrid methodology offers valuable insights for both decision-makers aiming to optimize supplier selection and customers seeking better shopping experiences.},
  archive      = {J_AAIL},
  author       = {Adem Pinar},
  doi          = {10.1002/ail2.70006},
  journal      = {Applied AI Letters},
  month        = {10},
  number       = {3},
  pages        = {e70006},
  shortjournal = {Appl. AI Lett.},
  title        = {A hybrid AI and fuzzy MCDM approach for retailer evaluation: Leveraging sentiment analysis and expert insights},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classical machine learning approaches for early hypertension risk prediction: A systematic review. <em>AAIL</em>, <em>6</em>(3), e70005. (<a href='https://doi.org/10.1002/ail2.70005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This review evaluates classical machine learning-based hypertension prediction models, emphasizing their role in addressing global health burdens , particularly in low- and middle-income countries. Hypertension affects over 1.28 billion people globally and contributes to cardiovascular disease and mortality. The review compares machine-learning techniques with traditional methods, focusing on key datasets, evaluation metrics, and model development to advance early detection and effective hypertension management. The review used the PRISMA framework, using databases such as Google Scholar, PubMed, and IEEE explorer to identify studies published between 2020 and 2024 on machine learning techniques, predictive models, and early detection of hypertension based on relevance, methodological rigor, and inclusion criteria. The study analyzed hypertension prediction models across various countries, including the US, England, Korea, Japan, China, Indonesia, Thailand, India, Bangladesh, Nepal, and several African countries. The models' performance varied with AUC statistic values ranging from 0.6 to 0.9, indicating a wide range of predictive accuracy. Machine learning techniques generally reported higher performance metrics than traditional statistical methods. Risk factor heterogeneity was evident, with models like random forest, logistic regression, and gradient-boosted trees showing high predictive accuracy. Emerging techniques like SMOTE (Synthetic Minority Oversampling Technique) and ensemble methods improved unbalanced data set performance. The review explores the potential of machine learning-based hypertension prediction models in healthcare, highlighting their ability to accurately predict hypertension risk, tailor interventions to specific populations, and optimize healthcare resources in low- and middle-income countries. However, challenges include data quality, model explainability, and ethical considerations. Despite these, ML integration offers scalable and cost-effective solutions, especially in resource-limited settings. Future research should focus on diverse datasets, advanced feature integration, and longitudinal validations.},
  archive      = {J_AAIL},
  author       = {Abebaw Agegne Engda and Ayodeji Olalekan Salau and Olubunmi Ajala},
  doi          = {10.1002/ail2.70005},
  journal      = {Applied AI Letters},
  month        = {10},
  number       = {3},
  pages        = {e70005},
  shortjournal = {Appl. AI Lett.},
  title        = {Classical machine learning approaches for early hypertension risk prediction: A systematic review},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tsetse fly detection and sex classification model enrichment employing YOLOv8 and YOLO11 architecture. <em>AAIL</em>, <em>6</em>(3), e70004. (<a href='https://doi.org/10.1002/ail2.70004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sterile insect technique (SIT) represents a highly effective and promising method for combating tsetse fly-related infections, which involves the release of sterilized male tsetse flies in the assigned zones. However, tsetse fly rearing poses specific challenges, particularly in the tsetse sex separation, as this process is labor-intensive and incurs significant costs. Here, we report a simple model that classifies tsetse flies by sex using an object detection model based on the YOLO algorithm. This paper also conducted a comparative analysis of YOLOv8 and YOLO11 deep learning models, focusing on their efficacy in tsetse fly detection and classification using a range of performance metrics and statistical analysis. The findings reveal that the classification accuracy of YOLO11 stands at 97.6%, whereas YOLOv8 achieves 95.6%. The classification precision of YOLO11 in identifying tsetse flies is 88.6%, while that of YOLOv8 is 85.9%. Additionally, YOLO11 demonstrates an inference speed of 13.0 ms, slightly faster than YOLOv8's 13.4 ms in tsetse sex detection. Moreover, YOLO11 outperformed YOLOv8 in both F1 score and mAP@0.5–0.9, a success attributed to its enhanced architectural design. However, statistical tests indicate there is no significant difference between the two models, achieving p values ≥ 0.05 for all metrics. This study adds value to tsetse rearing and fly-based disease control by offering automated tsetse sex detection insights into its practical uses in real-world contexts. Furthermore, this research enriches the understanding of the two models with tsetse flies as the focal point and recommends a more effective and accurate detection approach. Finally, integrating the model with the mobile object detection Android app will reduce tsetse sex sorting dependency on experienced technical experts and enhance tsetse rearing productivity.},
  archive      = {J_AAIL},
  author       = {Wegene Demisie Jima and Serkalem Fekadu Desta and Tesfaye Adisu Tarekegn and Genet Shewangizaw Gebremedhin and Ashenafi Bekele Gutema and Taye Girma Debelee},
  doi          = {10.1002/ail2.70004},
  journal      = {Applied AI Letters},
  month        = {10},
  number       = {3},
  pages        = {e70004},
  shortjournal = {Appl. AI Lett.},
  title        = {Tsetse fly detection and sex classification model enrichment employing YOLOv8 and YOLO11 architecture},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time variant node ranking technique for chatbot neural graph. <em>AAIL</em>, <em>6</em>(3), e70003. (<a href='https://doi.org/10.1002/ail2.70003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study seeks to put repetitiveness characteristics into AI. Closer ties between AI and human psychology can enhance the implementation of chatbots. Repetitiveness is a common characteristic of human behavior. Repetitiveness indicates which node is updated frequently and its importance. A chatbot needs to solve a situation regarding how quickly it will access its neural memory to retrieve information. Thus, the ranking of nodes in a neural network is necessary to allocate them to the chatbot's memory. The proposed ranking methodology takes affinity, number of edges, adjacency, average weight, and update time interval parameters into account to calculate the ranked value of each node. After that, a ranking tree is generated. This tree is finally considered the memory navigation path in that neural graph. If a node updates regularly with each clock pulse, which resembles a repetitive task, then its ranked value increases. This node should get preference over other low-ranked nodes. This study provides an approach to convert a neural graph into a ranking tree and a path to navigate through it. Thus, the chatbot can identify which node is more promising and has a shorter path than other nodes for information retrieval.},
  archive      = {J_AAIL},
  author       = {Ahmed Imtiaz and A. F. M. Zainul Abadin and Md. Harun Or Rashid},
  doi          = {10.1002/ail2.70003},
  journal      = {Applied AI Letters},
  month        = {10},
  number       = {3},
  pages        = {e70003},
  shortjournal = {Appl. AI Lett.},
  title        = {Time variant node ranking technique for chatbot neural graph},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Benford's law in basic RNN and long short-term memory and their associations. <em>AAIL</em>, <em>6</em>(3), e70002. (<a href='https://doi.org/10.1002/ail2.70002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benford's Law describes the distribution of numerical patterns, specifically focusing on the frequency of the leading digit in a set of natural numbers. It divides these numbers into nine groups based on their first digit, with the largest category comprising numbers beginning with 1, followed by those starting with 2, and so on. Each neuron within a neural network (NN) is associated with a numerical value called a weight, which is updated according to specific functions. This research examines the Degree of Benford's Law Existence (DBLE) across two language model methodologies: (1) recurrent neural networks (RNNs) and (2) long short-term memory (LSTM). Additionally, this study investigates whether models with higher performance exhibit a stronger presence of DBLE. Two neural network language models, namely: (1) simple RNN and (2) LSTM, were selected as the subject models for the experiment. Each model is tested with five different optimizers and four different datasets (textual corpora selected from Wikipedia). This results in a total of 20 different configurations for each model. The neuron weights for each configuration were extracted at each epoch, and the following metrics were measured at each epoch: (1) DBLE, (2) training set accuracy, (3) training set error, (4) test set accuracy, and (5) test set error. The results show that the weights in both models, across all optimizers, follow Benford's Law. Additionally, the findings indicate a strong correlation between DBLE and the performance on the training set in both language models. This means that models with higher performance on the training set exhibit a stronger correlation of DBLE.},
  archive      = {J_AAIL},
  author       = {Farshad Ghassemi Toosi},
  doi          = {10.1002/ail2.70002},
  journal      = {Applied AI Letters},
  month        = {10},
  number       = {3},
  pages        = {e70002},
  shortjournal = {Appl. AI Lett.},
  title        = {Benford's law in basic RNN and long short-term memory and their associations},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Utilizing AI in business and entrepreneurship: Implications for complex decision-making in engineering and product development settings. <em>AAIL</em>, <em>6</em>(3), e70001. (<a href='https://doi.org/10.1002/ail2.70001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) is rapidly transforming decision-making in business and entrepreneurship, with particularly significant implications for engineering and product development. This paper reviews existing literature and theoretical models to elucidate AI's role in strategic decision-making, while also identifying critical gaps in current research. To gain a comprehensive perspective, we employed a mixed-methods approach comprising surveys of 105 industry professionals and semi-structured interviews with key stakeholders. Our findings indicate that, although AI integration improves operational efficiency and enhances strategic insights, challenges related to data privacy, ethical concerns, and workforce training persist. These results underscore the need for balanced human–AI collaboration and robust governance frameworks to fully realize AI's potential in complex decision-making environments.},
  archive      = {J_AAIL},
  author       = {Nnamdi Gabriel Okafor and Patrick J. Murphy},
  doi          = {10.1002/ail2.70001},
  journal      = {Applied AI Letters},
  month        = {10},
  number       = {3},
  pages        = {e70001},
  shortjournal = {Appl. AI Lett.},
  title        = {Utilizing AI in business and entrepreneurship: Implications for complex decision-making in engineering and product development settings},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision transformer-enhanced multi-descriptor approach for robust age-invariant face recognition. <em>AAIL</em>, <em>6</em>(3), e70000. (<a href='https://doi.org/10.1002/ail2.70000'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a robust age-invariant face recognition framework, addressing challenges posed by age-related facial variations. Evaluated on the FGNet and Morph II datasets, the system integrates Viola-Jones for face detection, SIFT and LBP for feature extraction, and Vision Transformers (ViTs) for global feature representation. Feature fusion and dimensionality reduction (KPCA, IPCA, UMAP) enhance efficiency while retaining key discriminative information. Using Random Forest, KNN, and XGBoost classifiers, the model achieves 96% accuracy, demonstrating the effectiveness of combining traditional and deep learning techniques in advancing age-invariant face recognition.},
  archive      = {J_AAIL},
  author       = {Justice Kwame Appati and Emmanuel Tsifokor and Daniel Kwame Amissah and David Ebo Adjepon-Yamoah},
  doi          = {10.1002/ail2.70000},
  journal      = {Applied AI Letters},
  month        = {10},
  number       = {3},
  pages        = {e70000},
  shortjournal = {Appl. AI Lett.},
  title        = {Vision transformer-enhanced multi-descriptor approach for robust age-invariant face recognition},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thematic analysis of expert opinions on the use of large language models in software development. <em>AAIL</em>, <em>6</em>(3), e127. (<a href='https://doi.org/10.1002/ail2.127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have gained popularity in recent years due to their ability to generate human-like text and conduct context-aware conversations in natural languages. This ability can be greatly beneficial for fields like software development, where LLMs can assist with tasks such as code generation, code review, and debugging. In this paper, thematic analysis has been performed on unstructured opinions obtained from 11 experts about the integration of LLMs in the field of software development to understand their benefits and limitations using two natural language processing (NLP) techniques: sentiment analysis and keyword extraction and analysis. Sentiment analysis suggests that most experts were optimistic and pragmatic about the use of generative artificial intelligence in software development, although some experts engaged in critical reflection. Keyword extraction and analysis mapped several keywords to pre-defined themes, which highlighted benefits of LLMs such as improved code quality and enhanced developer productivity, as well as challenges such as the risk of over-reliance, and privacy and security concerns.},
  archive      = {J_AAIL},
  author       = {Sargam Yadav and Abhishek Kaushik and Asifa Mehmood Qureshi},
  doi          = {10.1002/ail2.127},
  journal      = {Applied AI Letters},
  month        = {10},
  number       = {3},
  pages        = {e127},
  shortjournal = {Appl. AI Lett.},
  title        = {Thematic analysis of expert opinions on the use of large language models in software development},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating reinforcement learning agents for autonomous cyber defence. <em>AAIL</em>, <em>6</em>(3), e125. (<a href='https://doi.org/10.1002/ail2.125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) is set to become an essential tool for defending against machine-speed attacks on increasingly connected cyber networks and systems. It will allow self-defending and self-recovering cyber-defence agents to be developed, which can respond to attacks in a timely manner. But how can these agents be trusted to perform as expected, and how can they be evaluated responsibly and thoroughly? To answer these questions, a Test and Evaluation (T&E) process has been developed to assess cyber-defence agents. The process evaluates the performance, effectiveness, resilience, and generalizability of agents in both low- and high-fidelity cyber environments. This paper demonstrates the low-fidelity part of the process by performing an example evaluation in the Cyber Operations Research Gym (CybORG) environment on Reinforcement Learning (RL) agents trained as part of Cyber Autonomy Gym for Experimentation (CAGE) Challenge 2. The process makes use of novel Measures of Effectiveness (MoE) metrics, which can be used in combination with performance metrics such as the RL reward. MoE are tailored for cyber defence, allowing a greater understanding of agents' defensive abilities within a cyber environment. Agents are evaluated against multiple conditions that perturb the environment to investigate their robustness to scenarios not seen during training. The results from this evaluation process will help inform decisions around the benefits and risks of integrating autonomous agents into existing or future cyber systems.},
  archive      = {J_AAIL},
  author       = {Abby Morris and Rachael Procter and Caroline Wallbank},
  doi          = {10.1002/ail2.125},
  journal      = {Applied AI Letters},
  month        = {10},
  number       = {3},
  pages        = {e125},
  shortjournal = {Appl. AI Lett.},
  title        = {Evaluating reinforcement learning agents for autonomous cyber defence},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A model-based deep-learning approach to reconstructing the highly articulated flight kinematics of bats. <em>AAIL</em>, <em>6</em>(2), e126. (<a href='https://doi.org/10.1002/ail2.126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bats are capable of highly dexterous flight maneuvers that rely heavily on highly articulated hand skeletons and malleable wing membranes. To understand the underlying mechanisms, large amounts of detailed data on bat flight kinematics are required. Conventional methods to obtain these data have been based on tracing landmarks and require substantial manual effort. To generate 3D reconstructions of the entire geometry of a flying bat in a fully automated fashion, the current work has developed an approach where the pose of a trainable articulated mesh template that is based on the bat's anatomy is optimized to fit a set of binary silhouettes representing views from different directions of the flying bat. This is followed by post-processing to smooth the reconstructed kinematics and simulate the non-rigid motion of the wing membranes. To evaluate the method, 10 flight sequences that represent several flight maneuvers (e.g., straight flight, takeoff, u-turn) and were recorded in a flight tunnel instrumented with 50 synchronized cameras have been reconstructed. A total of 4975 reconstructions are generated in this fashion and subject to qualitative and quantitative evaluations with promising results. The reconstructions are to be used for quantitative analyses of the maneuvering kinematics and the associated aerodynamics.},
  archive      = {J_AAIL},
  author       = {Yihao Hu and Chi Nnoka and Rolf Müller},
  doi          = {10.1002/ail2.126},
  journal      = {Applied AI Letters},
  month        = {4},
  number       = {2},
  pages        = {e126},
  shortjournal = {Appl. AI Lett.},
  title        = {A model-based deep-learning approach to reconstructing the highly articulated flight kinematics of bats},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ChemQuery: A natural language query-driven service for comprehensive exploration of chemistry patent literature. <em>AAIL</em>, <em>6</em>(2), e124. (<a href='https://doi.org/10.1002/ail2.124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patents are integral to our shared scientific knowledge, requiring companies and inventors to stay informed about them to conduct research, find licensing opportunities, and manage legal risks. However, the rising rate of filings has made this task increasingly challenging over the years. To address this issue, we introduce ChemQuery , a tool for easily exploring chemistry-related patents using natural language questions. Traditional systems rely on simplistic keyword-based searches to find patents that might be relevant to a user's request. In contrast, ChemQuery uses up-to-date information to return specific answers, along with their sources. It also offers a more comprehensive search experience to the users, thanks to capabilities like extracting molecules from diagrams, integrating information from PubChem, and allowing complex queries about molecular structures. We conduct a thorough empirical evaluation of ChemQuery and compare it with several baseline approaches. The results highlight the practical utility and limitations of our tool.},
  archive      = {J_AAIL},
  author       = {Shubham Gupta and Rafael Teixeira de Lima and Lokesh Mishra and Cesar Berrospi and Panagiotis Vagenas and Nikolaos Livathinos and Christoph Auer and Michele Dolfi and Peter Staar},
  doi          = {10.1002/ail2.124},
  journal      = {Applied AI Letters},
  month        = {4},
  number       = {2},
  pages        = {e124},
  shortjournal = {Appl. AI Lett.},
  title        = {ChemQuery: A natural language query-driven service for comprehensive exploration of chemistry patent literature},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Practical recommendations for artificial intelligence and machine learning in antimicrobial stewardship for africa. <em>AAIL</em>, <em>6</em>(2), e123. (<a href='https://doi.org/10.1002/ail2.123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The challenge of antimicrobial resistance (AMR) represents one of the most pressing global health crises, particularly, in resource-constrained settings like Africa. In this paper, we explore artificial intelligence (AI) and machine learning (ML) potential in transforming the potential for antimicrobial stewardship (AMS) to improve precision, efficiency, and effectiveness of antibiotic use. The deployment of AI-driven solutions presents unprecedented opportunities for optimizing treatment regimens, predicting resistance patterns, and improving clinical workflows. However, successfully integrating these technologies into Africa's health systems faces considerable obstacles, including limited human capacity and expertise, widespread public distrust, insufficient funding, inadequate infrastructure, fragmented data sources, and weak regulatory and policy enforcement. To harness the full potential of AI and ML in AMS, there is a need to first address these foundational barriers. Capacity-building initiatives are essential to equip healthcare professionals with the skills needed to leverage AI technologies effectively. Public trust must be cultivated through community engagement and transparent communication about the benefits and limitations of AI. Furthermore, technological solutions should be tailored to the unique constraints of resource-limited settings, with a focus on developing low-computational, explainable models that can operate with minimal infrastructure. Financial investment is critical to scaling successful pilot projects and integrating them into national health systems. Effective policy development is equally essential to establishing regulatory frameworks that ensure data security, algorithmic fairness, and ethical AI use. This comprehensive approach will not only improve the deployment of AI systems but also address the underlying issues that exacerbate AMR, such as unauthorized antibiotic sales and inadequate enforcement of guidelines. To effectively and sustainably combat AMR, a concerted effort involving governments, health organizations, communities, and technology developers is essential. Through collaborations and sharing a common goal, we can build resilient and effective AMS programs in Africa.},
  archive      = {J_AAIL},
  author       = {Tafadzwa Dzinamarira and Elliot Mbunge and Claire Steiner and Enos Moyo and Adewale Akinjeji and Kaunda Yamba and Loveday Mwila and Claude Mambo Muvunyi},
  doi          = {10.1002/ail2.123},
  journal      = {Applied AI Letters},
  month        = {4},
  number       = {2},
  pages        = {e123},
  shortjournal = {Appl. AI Lett.},
  title        = {Practical recommendations for artificial intelligence and machine learning in antimicrobial stewardship for africa},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A few-shot learning approach for a multilingual agro-information question answering system. <em>AAIL</em>, <em>6</em>(2), e122. (<a href='https://doi.org/10.1002/ail2.122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Across numerous households in Sub-Saharan Africa, agriculture plays a crucial role. One solution that can effectively bridge the support gap for farmers in the local community is a question–answer system based on agricultural expertise and agro-information. The more recent advancements in question answering research involve the use of large language models that are trained on an extensive amount of data. Due to this, conventional fine-tuning approaches have demonstrated a significant decline in performance when using a significantly smaller amount of data. One proposed alternative to address this decline is to use prompt-based fine-tuning, which allows the model to be fine-tuned with only a few examples, thus addressing the disparities between the objectives of pretraining and fine-tuning. Extensive research has been done on these methods, specifically on text classification and not question answering. In this research, our objective was to study the feasibility of recent few-shot learning approaches such as FewshotQA and Null-prompting for domain-specific agricultural data in four South African languages. We first explored creating a cross-lingual domain-specific extractive question answering dataset through an automated approach using the GPT model. Through exploratory data analysis, the GPT model was able to create a dataset, which requires minor improvements. We then evaluated the overall performance of the different approaches and investigated the effects of adapting these approaches to suit the new dataset. Results show these methods effectively capture semantic relationships and domain-specific terminology but exhibit limitations, including potential biases in automated annotation and plateauing F1 scores. This highlights the need for hybrid approaches that combine artificial intelligence and human supervision. Beyond academic insights, this study has practical significance for industry, demonstrating how prompt-based methods can help tailor AI models to specific use cases in low-resource settings.},
  archive      = {J_AAIL},
  author       = {Fiskani Ella Banda and Vukosi Marivate and Joyce Nakatumba-Nabende},
  doi          = {10.1002/ail2.122},
  journal      = {Applied AI Letters},
  month        = {4},
  number       = {2},
  pages        = {e122},
  shortjournal = {Appl. AI Lett.},
  title        = {A few-shot learning approach for a multilingual agro-information question answering system},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating adversarial attacks against artificial intelligence systems in application deployments. <em>AAIL</em>, <em>6</em>(2), e121. (<a href='https://doi.org/10.1002/ail2.121'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Businesses have invested billions into artificial intelligence (AI) applications, leading to a sharp rise in the number of AI applications being released to customers. Taking into account previous approaches to attacking machine learning models, we conduct a comparative analysis of adversarial attacks, contrasting large language models (LLMs) being deployed through application programming interfaces (APIs) with the same attacks against locally deployed models to evaluate the significance of security controls in production deployments on attack success in black-box environments. The article puts forward adversarial attacks that are adapted for remote model endpoints in order to create a threat model that can be used by security organizations to prioritize controls when deploying AI systems through APIs. This paper contributes: (1) a public repository of adversarial attacks adapted to handle remote models on https://github.com/l3ra/adversarial-ai , (2) benchmarking results of remote attacks comparing the effectiveness of attacks on remote models with those on local models, and (3) a framework for assessing future AI system deployment controls. By providing a practical framework for benchmarking the security of remote AI systems, this study contributes to the understanding of adversarial attacks in the context of natural language processing models deployed by production applications.},
  archive      = {J_AAIL},
  author       = {Lera Leonteva},
  doi          = {10.1002/ail2.121},
  journal      = {Applied AI Letters},
  month        = {4},
  number       = {2},
  pages        = {e121},
  shortjournal = {Appl. AI Lett.},
  title        = {Evaluating adversarial attacks against artificial intelligence systems in application deployments},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Empowering public health: AI-powered security solutions for AI-driven challenges. <em>AAIL</em>, <em>6</em>(2), e119. (<a href='https://doi.org/10.1002/ail2.119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The escalating integration of artificial intelligence (AI) in public healthcare has raised a critical concern: the vast amounts of data being generated and utilised by AI language models are not adequately connected to privacy and security considerations. This study addresses the problem by exploring how AI language models can be used to enhance digital security in public healthcare while addressing challenges related to privacy and ethics. The research adopts a three-phase methodology: a bibliometric analysis of literature from the Scopus database to identify research trends, the generation of AI-driven scenarios refined by healthcare professionals and analysing AI responses using grounded theory. Two scenarios, focused on AI-driven clinical decision support systems and AI-powered telemedicine platforms, were validated by healthcare experts and tested using ChatGPT-4 and Gemini, two prominent AI models. While ChatGPT-4 produced contextually specific and diverse responses, Gemini's outputs were inconsistent and repetitive, highlighting discrepancies in their performance. These discrepancies are linked to the data used to train these models, implying that incorporating more specialised healthcare data could enhance performance; however, such data usage must align with ethical guidelines. The analysis found that human, organizational, and technological dimensions are critical for addressing security issues and promoting trust in healthcare systems utilising AI. While AI-generated scenarios are a valuable starting point, they must be mediated by medical professionals to ensure practical applicability. The findings provide a theoretical framework for handling AI-generated issues related to privacy and security concerns, which can be used for future empirical research to enhance digital security in public healthcare.},
  archive      = {J_AAIL},
  author       = {Shahrukh Mushtaq and Qurra-Tul-Ain Hameeda},
  doi          = {10.1002/ail2.119},
  journal      = {Applied AI Letters},
  month        = {4},
  number       = {2},
  pages        = {e119},
  shortjournal = {Appl. AI Lett.},
  title        = {Empowering public health: AI-powered security solutions for AI-driven challenges},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving machine learning workflows using the “Normative-descriptive-prescriptive” decision framework. <em>AAIL</em>, <em>6</em>(2), e118. (<a href='https://doi.org/10.1002/ail2.118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To maximize business value from artificial intelligence and machine learning (ML) systems, understanding what leads to the effective development and deployment of ML systems is crucial. While prior research primarily focused on technical aspects, important issues related to improving decision-making across ML workflows have been overlooked. This paper introduces a “normative-descriptive-prescriptive” decision framework to address this gap. Normative guidelines outline best practices, descriptive dimensions describe actual decision-making, and prescriptive elements provide recommendations to bridge gaps. The three-step framework analyzes decision-making in key ML pipeline phases, identifying gaps and offering prescriptions for improved model building. Key descriptive findings include rushed problem-solving with convenient data, use of inaccurate success metrics, underestimation of downstream impacts, limited roles of subject matter experts, use of non-representative data samples, prioritization of prediction over explanation, lack of formal verification processes, and challenges in monitoring production models. The paper highlights biases, incentive issues, and systematic disconnects in decision-making across the ML pipeline as contributors to descriptive shortcomings. Practitioners can use the framework to pinpoint gaps, develop prescriptive interventions, and build higher quality, ethical, and legally compliant ML systems.},
  archive      = {J_AAIL},
  author       = {Naveen Gudigantala and Manaranjan Pradhan and Naga Vemprala},
  doi          = {10.1002/ail2.118},
  journal      = {Applied AI Letters},
  month        = {4},
  number       = {2},
  pages        = {e118},
  shortjournal = {Appl. AI Lett.},
  title        = {Improving machine learning workflows using the “Normative-descriptive-prescriptive” decision framework},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Building text-to-speech models for low-resourced languages from crowdsourced data. <em>AAIL</em>, <em>6</em>(2), e117. (<a href='https://doi.org/10.1002/ail2.117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-speech (TTS) models have expanded the scope of digital inclusivity by becoming a basis for assistive communication technologies for visually impaired people, facilitating language learning, and allowing for digital textual content consumption in audio form across various sectors. Despite these benefits, the full potential of TTS models is often not realized for the majority of low-resourced African languages because they have traditionally required large amounts of high-quality single-speaker recordings, which are financially costly and time-consuming to obtain. In this paper, we demonstrate that crowdsourced recordings can help overcome the lack of single-speaker data by compensating with data from other speakers of similar intonation (how the voice rises and falls in speech). We fine-tuned an English variational inference with adversarial learning for an end-to-end text-to-speech (VITS) model on over 10 h of speech from six female common voice (CV) speech data speakers for Luganda and Kiswahili. A human mean opinion score evaluation on 100 test sentences shows that the model trained on six speakers sounds more natural than the benchmark models trained on two speakers and a single speaker for both languages. In addition to careful data curation, this approach shows promise for advancing speech synthesis in the context of low-resourced African languages. Our final models for Luganda and Kiswahili are available at https://huggingface.co/marconilab/VITS-commonvoice-females .},
  archive      = {J_AAIL},
  author       = {Andrew Katumba and Sulaiman Kagumire and Joyce Nakatumba-Nabende and John Quinn and Sudi Murindanyi},
  doi          = {10.1002/ail2.117},
  journal      = {Applied AI Letters},
  month        = {4},
  number       = {2},
  pages        = {e117},
  shortjournal = {Appl. AI Lett.},
  title        = {Building text-to-speech models for low-resourced languages from crowdsourced data},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Developing an intelligent resume screening tool with AI-driven analysis and recommendation features. <em>AAIL</em>, <em>6</em>(2), e116. (<a href='https://doi.org/10.1002/ail2.116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current resume screening relies on manual review, causing delays and errors in evaluating large volumes of resumes. Lack of automation and data extraction leads to inefficiencies and potential biases. Recruiters face challenges in identifying qualified candidates due to oversight and time constraints. Inconsistent evaluation criteria hinder decision-making. These issues result in prolonged hiring processes, missed opportunities, and potential bias in candidate selection. The goal of this project is to develop an AI-powered Resume Analysis and Recommendation Tool, catering to the trend of recruiters spending less than 2 min on each CV. The tool will rapidly analyze all resume components while providing personalized predictions and recommendations to applicants for improving their CVs. It will present user-friendly data for recruiters, facilitating export to CSV for integration into their recruitment processes. Additionally, the tool will offer insights and analytics on popular roles and skills within the job market. Its user section will enable applicants to continually test and track their resumes, encouraging repeat usage and driving traffic. Colleges can benefit from gaining insights into students' resumes before placements. Overall, this AI-powered tool aims to enhance the resume evaluation process, benefiting both job seekers and employers. The primary aim of this project is to develop a Resume Analyzer using Python, incorporating advanced libraries such as Pyresparser, NLTK (Natural Language Toolkit), and MySQL. This automated system offers an efficient solution for parsing, analyzing, and extracting essential information from resumes. The user-friendly interface, developed using Streamlit, allows for seamless resume uploading, insightful data visualization, and analytics. The Resume Analyzer significantly streamlines the resume screening process, providing recruiters with valuable insights and enhancing their decision-making capabilities.},
  archive      = {J_AAIL},
  author       = {K. L. Abhishek and M. Niranjanamurthy and Shonit Aric and Syed Immamul Ansarullah and Anurag Sinha and G. Tejani and Mohd Asif Shah},
  doi          = {10.1002/ail2.116},
  journal      = {Applied AI Letters},
  month        = {4},
  number       = {2},
  pages        = {e116},
  shortjournal = {Appl. AI Lett.},
  title        = {Developing an intelligent resume screening tool with AI-driven analysis and recommendation features},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault detection and classification for photovoltaic panel system using machine learning techniques. <em>AAIL</em>, <em>6</em>(2), e115. (<a href='https://doi.org/10.1002/ail2.115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deployment of solar photovoltaic (PV) panel systems, as renewable energy sources, has seen a rise recently. Consequently, it is imperative to implement efficient methods for the accurate detection and diagnosis of PV system faults to prevent unexpected power disruptions. This paper introduces a potential strategy for fault identification and classification through the utilization of machine learning (ML) techniques. The study aimed to use ML algorithms to identify and classify normal operations, seven different types of faults, in two operational modes (maximum power point tracking and intermediate power point tracking). Four machine learning algorithms and ensemble methods (decision trees, k-nearest neighbors, random forest, and extreme gradient boosting) were employed, followed by hyperparameter tuning and cross-validation to determine the best configuration. The results indicated that ensemble methods, particularly XGBoost, excelled in detecting and classifying faults in PV systems, achieving a 99% accuracy rate after hyperparameter adjustments. The TPR values show a high sensitivity of 0.999, with some achieving a perfect score of 1.000. The FPR shows very low values, with the majority of metrics indicating FPRs at or close to 0%. This performance is crucial in the solar energy context, as failing to detect faults can result in significant energy loss and increased maintenance costs.},
  archive      = {J_AAIL},
  author       = {Ghalia Nassreddine and Amal El Arid and Mohamad Nassereddine and Obada Al Khatib},
  doi          = {10.1002/ail2.115},
  journal      = {Applied AI Letters},
  month        = {4},
  number       = {2},
  pages        = {e115},
  shortjournal = {Appl. AI Lett.},
  title        = {Fault detection and classification for photovoltaic panel system using machine learning techniques},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On training spiking neural networks by means of a novel quantum inspired machine learning method. <em>AAIL</em>, <em>6</em>(2), e114. (<a href='https://doi.org/10.1002/ail2.114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In spite of the high potential shown by spiking neural networks (e.g., temporal patterns), training them remains an open and complex problem. In practice, while in theory these networks are computationally as powerful as mainstream artificial neural networks, they have not reached the same accuracy levels yet. The major reason for such a situation seems to be represented by the lack of adequate training algorithms for deep spiking neural networks, since spike signals are not differentiable, that is, no direct way to compute a gradient is provided. Recently, a novel training method, based on the (digital) simulation of certain quantum systems, has been suggested. It has already shown interesting advantages, among which is the fact that no gradient is required to be computed. In this work, we apply this approach to the problem of training spiking neural networks, and we show that this recent training method is capable of training deep and complex spiking neural networks on the MNIST data set.},
  archive      = {J_AAIL},
  author       = {Jean Michel Sellier and Alexandre Martini},
  doi          = {10.1002/ail2.114},
  journal      = {Applied AI Letters},
  month        = {4},
  number       = {2},
  pages        = {e114},
  shortjournal = {Appl. AI Lett.},
  title        = {On training spiking neural networks by means of a novel quantum inspired machine learning method},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid deep learning paradigm for robust feature extraction and classification for cataracts. <em>AAIL</em>, <em>6</em>(2), e113. (<a href='https://doi.org/10.1002/ail2.113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study suggests using a hybrid convolutional neural networks-support vector machines architecture to extract reliable characteristics from medical images and classify them as an ensemble using four different models. Manual processing of fundus images for the automated identification of ocular disorders is laborious, error-prone, and time-consuming. This necessitates computer-assisted technologies that can automatically identify different ocular illnesses from fundus images. The interpretation of the photos also plays a massive role in the diagnosis. Automating the diagnosing procedure reduces human mistakes and helps with early cataract detection. The oneDNN library available in the oneAPI Environment provided by Intel has been used to optimize all transfer learning models for better performance. The suggested approach is verified through a range of metrics in experiments using the openly accessible Ocular Disease Intelligent Recognition dataset. The MobileNet Model outperformed other transfer learning techniques with an accuracy of 0.9836.},
  archive      = {J_AAIL},
  author       = {Akshay Bhuvaneswari Ramakrishnan and Mukunth Madavan and R. Manikandan and Amir H. Gandomi},
  doi          = {10.1002/ail2.113},
  journal      = {Applied AI Letters},
  month        = {4},
  number       = {2},
  pages        = {e113},
  shortjournal = {Appl. AI Lett.},
  title        = {A hybrid deep learning paradigm for robust feature extraction and classification for cataracts},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Technical language processing for telecommunications specifications. <em>AAIL</em>, <em>6</em>(2), e111. (<a href='https://doi.org/10.1002/ail2.111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) are continuously being evaluated in more diverse contexts. However, they still have challenges when extracting information from highly specific internal technical documentation. One specific area of real-world technical documentation is telecommunications engineering, which could benefit from domain-specific LLMs. In this article, we expand the notion of Technical Language Processing (TLP) to the telecommunications domain by introducing and analyzing the format of technical specifications from a leading telecommunications equipment vendor. Additionally, we highlight the importance of use case definitions by introducing requirement property mapping for maximizing information extraction. Also, we recommend actions to mitigate the effect of the internal specifications format on information extraction, which can lead to LLM-friendly internal specifications. Finally, a PoC is built to showcase the improvements of our proposed framework.},
  archive      = {J_AAIL},
  author       = {Felipe A. Rodriguez Y},
  doi          = {10.1002/ail2.111},
  journal      = {Applied AI Letters},
  month        = {4},
  number       = {2},
  pages        = {e111},
  shortjournal = {Appl. AI Lett.},
  title        = {Technical language processing for telecommunications specifications},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Earnings call scripts generation with large language models using few-shot learning prompt engineering and fine-tuning methods. <em>AAIL</em>, <em>6</em>(1), e110. (<a href='https://doi.org/10.1002/ail2.110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Company earnings calls are pivotal events that offer crucial insights into a company's financial well-being and future outlook. Large language models (LLMs) present a promising avenue for automatically generating the initial draft of earnings call scripts, leveraging financial data and past examples. We evaluate two distinct methods: (1) few-shot learning prompt engineering with a large language model (LLM) and (2) fine-tuning a large language model on earnings call transcript data. Our findings indicate that both methods can produce coherent scripts encompassing key metrics, updates, and guidance. However, there are inherent trade-offs in comprehensiveness, potential hallucinations, writing style, ease of use, and cost. We discuss the pros and cons of each method to guide practitioners on effectively harnessing LLMs for earnings call script generation. Notably, we employ a human and two different LLMs to act as judges to compare the outcomes generated by the two approaches.},
  archive      = {J_AAIL},
  author       = {Sovik Kumar Nath and Yanyan Zhang and Jia Vivian Li},
  doi          = {10.1002/ail2.110},
  journal      = {Applied AI Letters},
  month        = {2},
  number       = {1},
  pages        = {e110},
  shortjournal = {Appl. AI Lett.},
  title        = {Earnings call scripts generation with large language models using few-shot learning prompt engineering and fine-tuning methods},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scaling laws for discriminative classification in large language models. <em>AAIL</em>, <em>6</em>(1), e109. (<a href='https://doi.org/10.1002/ail2.109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern large language models (LLMs) represent a paradigm shift in what can plausibly be expected of machine learning models. The fact that LLMs can effectively generate sensible answers to a diverse range of queries suggests that they would be useful in customer support applications. While powerful, LLMs have been observed to be prone to hallucination which unfortunately makes their near-term use in customer support applications challenging. To address this issue, we present a system that allows us to use an LLM to augment our customer support advocates by re-framing the language modeling task as a discriminative classification task. In this framing, we seek to present the Top-K best template responses for a customer support advocate to use when responding to a customer. We present the result of both offline and online experiments where we observed offline gains and statistically significant online lifts for our experimental system. Along the way, we present observed scaling curves for validation loss and Top-K accuracy, resulted from model parameter ablation studies. We close by discussing the space of trade-offs with respect to model size, latency, and accuracy as well as and suggesting future applications to explore.},
  archive      = {J_AAIL},
  author       = {Dean Wyatte and Fatemeh Tahmasbi and Ming Li and Thomas Markovich},
  doi          = {10.1002/ail2.109},
  journal      = {Applied AI Letters},
  month        = {2},
  number       = {1},
  pages        = {e109},
  shortjournal = {Appl. AI Lett.},
  title        = {Scaling laws for discriminative classification in large language models},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-driven modeling of dynamic acoustic sensing in biomimetic soft-robotic pinnae. <em>AAIL</em>, <em>6</em>(1), e107. (<a href='https://doi.org/10.1002/ail2.107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biological function often depends on complex mechanisms of a dynamic, time-variant nature. An example is certain bat species (horseshoe bats—Rhinolophidae) that use intricate pinna musculatures to execute a variety of pinna deformations. While prior work has indicated the potential significance of these motions for sensory information encoding, it remains unclear how the complex time-variant pinna geometries could be controlled to enhance sensory performance. To address this issue, this work has investigated deep neural network models as digital twins for biomimetic pinnae. The networks were trained to predict the acoustic impacts of the deformed pinna geometries. A total of three network architectures have been evaluated for this purpose using physical numerical simulations (boundary element method) as ground truth. The networks predicted the acoustic beampattern function from pinna shape or even directly from the states of actuators that were used to deform the pinna shapes in simulation. Inserting prior knowledge in the form of beam-shaped basis functions did not improve network performance. The ability of the networks to produce beampattern predictions with low computational effort (in about three milliseconds each) should lend itself readily to supporting learning methods such as deep reinforcement learning that require many such functional evaluations.},
  archive      = {J_AAIL},
  author       = {Sounak Chakrabarti and Rolf Müller},
  doi          = {10.1002/ail2.107},
  journal      = {Applied AI Letters},
  month        = {2},
  number       = {1},
  pages        = {e107},
  shortjournal = {Appl. AI Lett.},
  title        = {Deep learning-driven modeling of dynamic acoustic sensing in biomimetic soft-robotic pinnae},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards predictive pollution control through traffic flux forecasting with deep learning: A case study in the city of valencia. <em>AAIL</em>, <em>6</em>(1), e106. (<a href='https://doi.org/10.1002/ail2.106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic congestion represents a significant urban challenge, with notable implications for public health and environmental well-being. Consequently, urban decision-makers prioritize the mitigation of congestion. This study delves into the efficacy of harnessing extensive data on urban traffic dynamics, coupled with comprehensive knowledge of road networks, to enable Artificial Intelligence (AI) in forecasting traffic flux well in advance. Such forecasts hold promise for informing emission reduction measures, particularly those aligned with Low Emission Zone policies. The investigation centers on Valencia, leveraging its robust traffic sensor infrastructure, one of the most densely deployed worldwide, encompassing approximately 3500 sensors strategically positioned across the city. Employing historical data spanning 2016 and 2017, we undertake the task of training and characterizing a Long Short-Term Memory (LSTM) Neural Network for the prediction of temporal traffic patterns. Our findings demonstrate the LSTM's efficacy in real-time forecasting of traffic flow evolution, facilitated by its ability to discern salient patterns within the dataset.},
  archive      = {J_AAIL},
  author       = {Miguel G. Folgado and Verónica Sanz and Johannes Hirn and Edgar Lorenzo-Sáez and Javier F. Urchueguía},
  doi          = {10.1002/ail2.106},
  journal      = {Applied AI Letters},
  month        = {2},
  number       = {1},
  pages        = {e106},
  shortjournal = {Appl. AI Lett.},
  title        = {Towards predictive pollution control through traffic flux forecasting with deep learning: A case study in the city of valencia},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fingerprinting-based indoor localization in a 3 × 3 meter grid using OFDM signals at sub-6 GHz. <em>AAIL</em>, <em>6</em>(1), e104. (<a href='https://doi.org/10.1002/ail2.104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately determining the indoor location of mobile devices has garnered significant interest due to the complex challenges posed by non-line-of-sight (NLOS) propagation and multipath effects. To address this challenge, this paper proposes a new approach to indoor positioning that utilises channel state information (CSI) and machine learning (ML) techniques to improve accuracy. The proposed method extracts the amplitude and phase differences of the subcarriers from the CSI data to create fingerprints. ML algorithms and network architecture are utilised to train the CSI data from two antennas, in the form of phase and amplitude. Experiments conducted in a standard indoor environment demonstrate the effectiveness of the proposed method.},
  archive      = {J_AAIL},
  author       = {Jaspreet Kaur and Kang Tan and Muhammad Z. Khan and Olaoluwa R. Popoola and Muhammad A. Imran and Qammer H. Abbasi and Hasan T. Abbas},
  doi          = {10.1002/ail2.104},
  journal      = {Applied AI Letters},
  month        = {2},
  number       = {1},
  pages        = {e104},
  shortjournal = {Appl. AI Lett.},
  title        = {Fingerprinting-based indoor localization in a 3 × 3 meter grid using OFDM signals at sub-6 GHz},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mechanical ventilator settings estimation from an AI model. <em>AAIL</em>, <em>6</em>(1), e103. (<a href='https://doi.org/10.1002/ail2.103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanical ventilation (MV) is used in subjects with respiratory problems for assistance in breathing. Various MV settings are adjusted at the clinician's discretion based on the patient's respiratory condition. In this study, an AI (artificial intelligence) model using artificial neural networks (ANNs) along with Bayesian Optimization (BO) was developed to estimate the desired MV settings for various subject scenarios. The ANN model with two hidden layers was trained with experimental data collected from subjects (canines and felines) in our previous work. Inverse mapping of the trained ANNs was conducted using BO to predict the acceptable MV settings for specific subject outcomes. Our results suggest that the model can support veterinarians in estimating the proper MV parameters for optimal subject outcome.},
  archive      = {J_AAIL},
  author       = {Ali Moghadam and Ramana M. Pidaparti},
  doi          = {10.1002/ail2.103},
  journal      = {Applied AI Letters},
  month        = {2},
  number       = {1},
  pages        = {e103},
  shortjournal = {Appl. AI Lett.},
  title        = {Mechanical ventilator settings estimation from an AI model},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid fuzzy deep belief network extreme learning machine framework with hyperbolic secant activation function for robust semi-supervised sentiment classification. <em>AAIL</em>, <em>6</em>(1), e102. (<a href='https://doi.org/10.1002/ail2.102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment classification deals with extracting and classifying the text sentiment. Fuzzy Deep Belief Network (DBN) has proved its efficiency in dealing with sentiment analysis and suitability for classifying unlabeled or semi-labeled data. Previous structures of deep belief networks are mostly made of traditional activation functions such as sigmoid. In this paper, a new activation function, which is referred to as hyperbolic secant function, is proposed. The new activation function not only solves gradient zeroing problem but also increases the accuracy and efficiency. Besides, extreme learning machine (ELM) is proposed as the decision layer to increase the accuracy and improve the generalizability through solving gradient-based learning problem. The efficiency of the proposed method has been experimented on “IMDB” movie critic dataset, 20-newspaper dataset and Sentiment Analysis dataset. The results of the proposed method are more accurate and precise as compared with the previous approaches.},
  archive      = {J_AAIL},
  author       = {Maryam Mozafari and Mohammad Hossein Moattar},
  doi          = {10.1002/ail2.102},
  journal      = {Applied AI Letters},
  month        = {2},
  number       = {1},
  pages        = {e102},
  shortjournal = {Appl. AI Lett.},
  title        = {A hybrid fuzzy deep belief network extreme learning machine framework with hyperbolic secant activation function for robust semi-supervised sentiment classification},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
