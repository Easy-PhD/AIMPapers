<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MOOR</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="moor">MOOR - 86</h2>
<ul>
<li><details>
<summary>
(2025). Comparison between mean-variance and monotone mean-variance preferences under jump diffusion and stochastic factor model. <em>MOOR</em>, <em>50</em>(3), 2405-2432. (<a href='https://doi.org/10.1287/moor.2022.0331'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper compares the optimal investment problems based on monotone mean-variance (MMV) and mean-variance (MV) preferences in a Lévy market with an untradable stochastic factor. It is an open question proposed by Trybuła and Zawisza. Using the dynamic programming and Lagrange multiplier methods, we get the Hamilton-Jacobi-Bellman-Isaacs (HJBI) and Hamilton-Jacobi-Bellman (HJB) equations corresponding to the two investment problems. The equations are transformed into a new-type parabolic equation, from which the optimal strategies under both preferences are derived. We prove that the two optimal strategies and value functions coincide if and only if an important market assumption holds. When the assumption is violated, MMV investors act differently from MV investors. Thus, we conclude that the difference between continuous-time MMV and MV portfolio selections is due to the discontinuity of the market. In addition, we derive the efficient frontier and analyze the economic impact of the jump diffusion risky asset. We also provide empirical evidence to demonstrate the validity of the assumption in real financial markets. Funding: This research was supported by National Natural Science Foundation of China [Grants 12271290 and 11871036].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0331},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2405-2432},
  shortjournal = {Math. Oper. Res.},
  title        = {Comparison between mean-variance and monotone mean-variance preferences under jump diffusion and stochastic factor model},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual solutions in convex stochastic optimization. <em>MOOR</em>, <em>50</em>(3), 2375-2404. (<a href='https://doi.org/10.1287/moor.2022.0270'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies duality and optimality conditions for general convex stochastic optimization problems. The main result gives sufficient conditions for the absence of a duality gap and the existence of dual solutions in a locally convex space of random variables. It implies, in particular, the necessity of scenario-wise optimality conditions that are behind many fundamental results in operations research, stochastic optimal control, and financial mathematics. Our analysis builds on the theory of Fréchet spaces of random variables whose topological dual can be identified with the direct sum of another space of random variables and a space of singular functionals. The results are illustrated by deriving sufficient and necessary optimality conditions for several more specific problem classes. We obtain significant extensions to earlier models, for example, on stochastic optimal control, portfolio optimization, and mathematical programming.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0270},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2375-2404},
  shortjournal = {Math. Oper. Res.},
  title        = {Dual solutions in convex stochastic optimization},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Langevin dynamics based algorithm e-THεO POULA for stochastic optimization problems with discontinuous stochastic gradient. <em>MOOR</em>, <em>50</em>(3), 2333-2374. (<a href='https://doi.org/10.1287/moor.2022.0307'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new Langevin dynamics based algorithm, called the extended tamed hybrid ε -order polygonal unadjusted Langevin algorithm (e-TH ε O POULA), to solve optimization problems with discontinuous stochastic gradients, which naturally appear in real-world applications such as quantile estimation, vector quantization, conditional value at risk (CVaR) minimization, and regularized optimization problems involving rectified linear unit (ReLU) neural networks. We demonstrate both theoretically and numerically the applicability of the e-TH ε O POULA algorithm. More precisely, under the conditions that the stochastic gradient is locally Lipschitz in average and satisfies a certain convexity at infinity condition, we establish nonasymptotic error bounds for e-TH ε O POULA in Wasserstein distances and provide a nonasymptotic estimate for the expected excess risk, which can be controlled to be arbitrarily small. Three key applications in finance and insurance are provided, namely, multiperiod portfolio optimization, transfer learning in multiperiod portfolio optimization, and insurance claim prediction, which involve neural networks with (Leaky)-ReLU activation functions. Numerical experiments conducted using real-world data sets illustrate the superior empirical performance of e-TH ε O POULA compared with SGLD (stochastic gradient Langevin dynamics), TUSLA (tamed unadjusted stochastic Langevin algorithm), adaptive moment estimation, and Adaptive Moment Estimation with a Strongly Non-Convex Decaying Learning Rate in terms of model accuracy. Funding: Financial support was provided by the Alan Turing Institute, London, under the Engineering and Physical Sciences Research Council [Grant EP/N510129/1]; the Ministry of Education of Singapore Academic Research Fund [Tier 2 Grant MOE-T2EP20222-0013]; the European Union’s Horizon 2020 Research and Innovation Programme [Marie Skłodowska-Curie Grant Agreement 801215]; the University of Edinburgh’s Data-Driven Innovation Programme, part of the Edinburgh and South East Scotland City Region Deal; an Institute of Information and Communications Technology Planning and Evaluation grant funded by the Korean Ministry of Science and ICT (MIST) [Grant 2020-0-01336]; the Artificial Intelligence Graduate School Program of the Ulsan National Institute of Science and Technology; a National Research Foundation of Korea grant funded by the Korean government (MSIT) [Grant RS-2023-00253002]; and the Guangzhou–Hong Kong University of Science and Technology (Guangzhou) Joint Funding Program [Grant 2024A03J0630].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0307},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2333-2374},
  shortjournal = {Math. Oper. Res.},
  title        = {Langevin dynamics based algorithm e-THεO POULA for stochastic optimization problems with discontinuous stochastic gradient},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A retrospective approximation approach for smooth stochastic optimization. <em>MOOR</em>, <em>50</em>(3), 2301-2332. (<a href='https://doi.org/10.1287/moor.2022.0136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic Gradient (SG) is the de facto iterative technique to solve stochastic optimization (SO) problems with a smooth (nonconvex) objective f and a stochastic first-order oracle. SG’s attractiveness is due in part to its simplicity of executing a single step along the negative subsampled gradient direction to update the incumbent iterate. In this paper, we question SG’s choice of executing a single step as opposed to multiple steps between subsample updates. Our investigation leads naturally to generalizing SG into Retrospective Approximation (RA), where, during each iteration, a “deterministic solver” executes possibly multiple steps on a subsampled deterministic problem and stops when further solving is deemed unnecessary from the standpoint of statistical efficiency. RA thus formalizes what is appealing for implementation—during each iteration, “plug in” a solver—for example, L-BFGS line search or Newton-CG— as is , and solve only to the extent necessary. We develop a complete theory using relative error of the observed gradients as the principal object, demonstrating that almost sure and L 1 consistency of RA are preserved under especially weak conditions when sample sizes are increased at appropriate rates. We also characterize the iteration and oracle complexity (for linear and sublinear solvers) of RA and identify a practical termination criterion leading to optimal complexity rates. To subsume nonconvex f , we present a certain “random central limit theorem” that incorporates the effect of curvature across all first-order critical points, demonstrating that the asymptotic behavior is described by a certain mixture of normals. The message from our numerical experiments is that the ability of RA to incorporate existing second-order deterministic solvers in a strategic manner might be important from the standpoint of dispensing with hyper-parameter tuning. Funding: R. Pasupathy received financial support from the Office of Naval Research [Grants N000141712295 and 13000991]. R. Bollapragada received financial support from the Lawrence Livermore National Laboratory and the National Science Foundation [Grant NSF DMS 2324643].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0136},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2301-2332},
  shortjournal = {Math. Oper. Res.},
  title        = {A retrospective approximation approach for smooth stochastic optimization},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The minimax property in infinite two-person win-lose games. <em>MOOR</em>, <em>50</em>(3), 2287-2300. (<a href='https://doi.org/10.1287/moor.2023.0352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore a version of the minimax theorem for two-person win-lose games with infinitely many pure strategies. In the countable case, we give a combinatorial condition on the game which implies the minimax property. In the general case, we prove that a game satisfies the minimax property along with all its subgames if and only if none of its subgames is isomorphic to the “larger number game.” This generalizes a recent theorem of Hanneke, Livni, and Moran. We also propose several applications of our results outside of game theory.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0352},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2287-2300},
  shortjournal = {Math. Oper. Res.},
  title        = {The minimax property in infinite two-person win-lose games},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Envy-free division of multilayered cakes. <em>MOOR</em>, <em>50</em>(3), 2261-2286. (<a href='https://doi.org/10.1287/moor.2022.0350'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dividing a multilayered cake under nonoverlapping constraints captures several scenarios (e.g., allocating multiple facilities over time where each agent can utilize at most one facility simultaneously). We establish the existence of an envy-free multidivision that is nonoverlapping and contiguous within each layer when the number of agents is a prime power, solving partially an open question by Hosseini et al. [Hosseini H, Igarashi A, Searns A (2020) Fair division of time: Multi-layered cake cutting. Proc. 29th Internat. Joint Conf. Artificial Intelligence (IJCAI) , 182–188; Hosseini H, Igarashi A, Searns A (2020) Fair division of time: Multi-layered cake cutting. Preprint, submitted April 28, http://arxiv.org/abs/2004.13397 ]. Our approach follows an idea proposed by Jojić et al. [Jojić D, Panina G, Živaljević R (2021) Splitting necklaces, with constraints. SIAM J. Discrete Math. 35(2):1268–1286] for envy-free divisions, relying on a general fixed-point theorem. We further design a fully polynomial-time approximation scheme for the two-layer, three-agent case, with monotone preferences. All results are actually established for divisions among groups of almost the same size. In the one-layer, three-group case, our algorithm is able to deal with any predetermined sizes, still with monotone preferences. For three groups, this provides an algorithmic version of a recent theorem by Segal-Halevi and Suksompong [Segal-Halevi E, Suksompong W (2021) How to cut a cake fairly: A generalization to groups. Amer. Math. Monthly 128(1):79–83]. Funding: This work was partially supported by the Japan Science and Technology Agency [Grant JPMJPR20C], Fusion Oriented REsearch for disruptive Science and Technology [Grant JPMJFR226O], and Exploratory Research for Advanced Technology [Grant JPMJER2301].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0350},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2261-2286},
  shortjournal = {Math. Oper. Res.},
  title        = {Envy-free division of multilayered cakes},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust online selection with uncertain offer acceptance. <em>MOOR</em>, <em>50</em>(3), 2226-2260. (<a href='https://doi.org/10.1287/moor.2023.0210'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online advertising has motivated interest in online selection problems. Displaying ads to the right users benefits both the platform (e.g., via pay-per-click) and the advertisers (by increasing their reach). In practice, not all users click on displayed ads, while the platform’s algorithm may miss the users most disposed to do so. This mismatch decreases the platform’s revenue and the advertiser’s chances to reach the right customers. With this motivation, we propose a secretary problem where a candidate may or may not accept an offer according to a known probability p . Because we do not know the top candidate willing to accept an offer, the goal is to maximize a robust objective defined as the minimum over integers k of the probability of choosing one of the top k candidates, given that one of these candidates will accept an offer. Using Markov decision process theory, we derive a linear program for this max-min objective whose solution encodes an optimal policy. The derivation may be of independent interest, as it is generalizable and can be used to obtain linear programs for many online selection models. We further relax this linear program into an infinite counterpart, which we use to provide bounds for the objective and closed-form policies. For p ≥ p * ≈ 0.6 , an optimal policy is a simple threshold rule that observes the first p 1 / ( 1 − p ) fraction of candidates and subsequently makes offers to the best candidate observed so far. Funding: Financial support from the U.S. National Science Foundation [Grants CCF-2106444, CCF-1910423, and CMMI 1552479] is gratefully acknowledged.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0210},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2226-2260},
  shortjournal = {Math. Oper. Res.},
  title        = {Robust online selection with uncertain offer acceptance},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The core of housing markets from an agent’s perspective: Is it worth sprucing up your home?. <em>MOOR</em>, <em>50</em>(3), 2199-2225. (<a href='https://doi.org/10.1287/moor.2023.0092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study housing markets as introduced by Shapley and Scarf. We investigate the computational complexity of various questions regarding the situation of an agent a in a housing market H : we show that it is NP -hard to find an allocation in the core of H in which (i) a receives a certain house, (ii) a does not receive a certain house, or (iii) a receives a house other than a ’s own. We prove that the core of housing markets respects improvement in the following sense: given an allocation in the core of H in which agent a receives a house h , if the value of the house owned by a increases, then the resulting housing market admits an allocation in its core in which a receives either h or a house that a prefers to h ; moreover, such an allocation can be found efficiently. We further show an analogous result in the S table R oommates setting by proving that stable matchings in a one-sided market also respect improvement. Funding: This work was supported by the Hungarian Scientific Research Fund [Grants K124171, K128611]. I. Schlotter is supported by the Hungarian Academy of Sciences under its Momentum Programme (LP2021-2) and its János Bolyai Research Scholarship. The research reported in this paper and carried out by T. Fleiner at the Budapest University of Technology and Economics was supported by the “TKP2020, National Challenges Program” of the National Research Development and Innovation Office [BME NC TKP2020 and OTKA K143858] and by the Higher Education Excellence Program of the Ministry of Human Capacities in the frame of the Artificial Intelligence research area of the Budapest University of Technology and Economics (BME FIKP-MI/SC). P. Biró gratefully acknowledges financial support from the Hungarian Scientific Research Fund, OTKA [Grant K143858] and the Hungarian Academy of Sciences [Momentum Grant LP2021-2].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0092},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2199-2225},
  shortjournal = {Math. Oper. Res.},
  title        = {The core of housing markets from an agent’s perspective: Is it worth sprucing up your home?},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of a class of minimization problems lacking lower semicontinuity. <em>MOOR</em>, <em>50</em>(3), 2175-2198. (<a href='https://doi.org/10.1287/moor.2023.0295'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimization of nonlower semicontinuous functions is a difficult topic that has been minimally studied. Among such functions is a Heaviside composite function that is the composition of a Heaviside function with a possibly nonsmooth multivariate function. Unifying a statistical estimation problem with hierarchical selection of variables and a sample average approximation of composite chance constrained stochastic programs, a Heaviside composite optimization problem is one whose objective and constraints are defined by sums of possibly nonlinear multiples of such composite functions. Via a pulled-out formulation, a pseudostationarity concept for a feasible point was introduced in an earlier work as a necessary condition for a local minimizer of a Heaviside composite optimization problem. The present paper extends this previous study in several directions: (a) showing that pseudostationarity is implied by (and thus, weaker than) a sharper subdifferential-based stationarity condition that we term epistationarity; (b) introducing a set-theoretic sufficient condition, which we term a local convexity-like property, under which an epistationary point of a possibly nonlower semicontinuous optimization problem is a local minimizer; (c) providing several classes of Heaviside composite functions satisfying this local convexity-like property; (d) extending the epigraphical formulation of a nonnegative multiple of a Heaviside composite function to a lifted formulation for arbitrarily signed multiples of the Heaviside composite function, based on which we show that an epistationary solution of the given Heaviside composite program with broad classes of B-differentiable component functions can in principle be approximately computed by surrogation methods. Funding: The work of Y. Cui was based on research supported by the National Science Foundation [Grants CCF-2153352, DMS-2309729, and CCF-2416172] and the National Institutes of Health [Grant 1R01CA287413-01]. The work of J.-S. Pang was based on research supported by the Air Force Office of Scientific Research [Grant FA9550-22-1-0045].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0295},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2175-2198},
  shortjournal = {Math. Oper. Res.},
  title        = {Analysis of a class of minimization problems lacking lower semicontinuity},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correlated equilibria in large anonymous bayesian games. <em>MOOR</em>, <em>50</em>(3), 2157-2174. (<a href='https://doi.org/10.1287/moor.2023.0278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider multipopulation Bayesian games with a large number of players. Each player aims at minimizing a cost function that depends on this player’s own action, the distribution of players’ actions in all populations, and an unknown state parameter. We study the nonatomic limit versions of these games and introduce the concept of Bayes correlated Wardrop equilibrium, which extends the concept of Bayes correlated equilibrium to nonatomic games. We prove that Bayes correlated Wardrop equilibria are limits of action flows induced by Bayes correlated equilibria of the game with a large finite set of small players. For nonatomic games with complete information admitting a convex potential, we prove that the set of correlated and of coarse correlated Wardrop equilibria coincide with the set of probability distributions over Wardrop equilibria and that all equilibrium outcomes have the same costs. We get the following consequences. First, all flow distributions of (coarse) correlated equilibria in convex potential games with finitely many players converge to mixtures of Wardrop equilibria when the weight of each player tends to zero. Second, for any sequence of flows satisfying a no-regret property, its empirical distribution converges to the set of distributions over Wardrop equilibria, and the average cost converges to the unique Wardrop cost. Funding: This work was partially supported by European Cooperation in Science and Technology Action 16228 GAMENET. F. Koessler acknowledges the support of the Agence Nationale de la Recherche [Grant StratCom ANR-19-CE26-0010-01]. M. Scarsini acknowledges the support of the Gruppo Nazionale per l’Analisi Matematica, la Probabilità e le loro Applicazioni project [Grant CUP_E53C22001930001], the Ministero dell’Università e della Ricerca Progetti di Rilevante Interesse Nazionale [Grant 2022EKNE5K], and the European Union-Next Generation EU, component M4C2, investment 1.1 (Ministero dell’Università e della Ricerca Progetti di Rilevante Interesse Nazionale Piano Nazionale di Ripresa e Resilienza) [Grant P2022XT8C8]. T. Tomala gratefully acknowledges the support of the HEC foundation and Agence Nationale de la Recherche/Investissements d’Avenir [Grant ANR-11-IDEX-0003/Labex Ecodec/ANR-11-LABX-0047].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0278},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2157-2174},
  shortjournal = {Math. Oper. Res.},
  title        = {Correlated equilibria in large anonymous bayesian games},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse integer programming is fixed-parameter tractable. <em>MOOR</em>, <em>50</em>(3), 2141-2156. (<a href='https://doi.org/10.1287/moor.2023.0162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the general integer programming problem where the number of variables n is a variable part of the input. We consider two natural parameters of the constraint matrix A : its numeric measure a and its sparsity measure d . We present an algorithm for solving integer programming in time g ( a , d ) poly ( n , L ) , where g is some computable function of the parameters a and d , and L is the binary encoding length of the input. In particular, integer programming is fixed-parameter tractable parameterized by a and d , and is solvable in polynomial time for every fixed a and d . Our results also extend to nonlinear separable convex objective functions. Funding: F. Eisenbrand, C. Hunkenschröder, and K.-M. Klein were supported by the Swiss National Science Foundation (SNSF) within the project “Convexity, geometry of numbers, and the complexity of integer programming” [Grant 163071]. A. Levin and S. Onn are partially supported by the Israel Science Foundation [Grant 308/18]. A. Levin is also partially supported by the Israel Science Foundation [Grant 1467/22]. S. Onn is also partially supported by the Dresner Chair at the Technion. M. Koutecký is partially supported by Charles University project UNCE 24/SCI/008, and by the project 22-22997S of the Grantová Agentura České Republiky (GA ČR).},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0162},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2141-2156},
  shortjournal = {Math. Oper. Res.},
  title        = {Sparse integer programming is fixed-parameter tractable},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On a network centrality maximization game. <em>MOOR</em>, <em>50</em>(3), 2112-2140. (<a href='https://doi.org/10.1287/moor.2022.0251'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a network formation game where n players, identified with the nodes of a directed graph to be formed, choose where to wire their outgoing links in order to maximize their PageRank centrality. Specifically, the action of every player i consists in the wiring of a predetermined number d i of directed out-links, and her utility is her own PageRank centrality in the network resulting from the actions of all players. We show that this is a potential game and that the best response correspondence always exhibits a local structure in that it is never convenient for a node i to link to other nodes that are at incoming distance more than d i from her. We then study the equilibria of this game determining necessary conditions for a graph to be a (strict, recurrent) Nash equilibrium. Moreover, in the homogeneous case, where players all have the same number d of out-links, we characterize the structure of the potential-maximizing equilibria, and in the special cases d = 1 and d = 2, we provide a complete classification of the set of (strict, recurrent) Nash equilibria. Our analysis shows in particular that the considered formation mechanism leads to the emergence of undirected and disconnected or loosely connected networks. Funding: This research was carried out within the framework of the Ministero dell’Università e della Ricerca (MIUR)-funded Progetto di Eccellenza of the Dipartimento di Scienze Matematiche G. L. Lagrange, Politecnico di Torino [CUP: E11G18000350001]. It received partial support from the MIUR-funded project PRIN 2017 “Advanced Network Control of Future Smart Grids” and from the Compagnia di San Paolo.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0251},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2112-2140},
  shortjournal = {Math. Oper. Res.},
  title        = {On a network centrality maximization game},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal ratcheting of dividends with capital injection. <em>MOOR</em>, <em>50</em>(3), 2073-2111. (<a href='https://doi.org/10.1287/moor.2023.0102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the optimal dividend problem with capital injection and ratcheting constraint with nondecreasing dividend payout rate. Capital injections are introduced in order to eliminate the possibility of bankruptcy. Under the Cramér–Lundberg risk model, the problem is formulated as a two-dimensional stochastic control problem. By applying the viscosity theory, we show that the value function is the unique viscosity solution to the associated Hamilton–Jacobi–Bellman equation. In order to obtain analytical results, we further study the problem with finite ratcheting constraint, where the dividend rate takes only a finite number of available values. We show that the value function under general ratcheting can be approximated arbitrarily closely by the one with finite ratcheting. Finally, we derive the expressions of value function when the threshold-type finite ratcheting dividend strategy with capital injection is applied, and we show the optimality of such a strategy under certain conditions of concavity. Numerical examples under various scenarios are provided at the end. Funding W. Wang was supported by the National Natural Science Foundation of China [Grants 12171405, 12271066, and 11661074] and the Fundamental Research Funds for the Central Universities of China [Grant 20720220044]. R. Xu was supported by the National Natural Science Foundation of China [Grants 12201506 and 12371468], the Natural Science Foundation of the Jiangsu Higher Education Institutions of China [Grant 21KJB110024], and Xi’an Jiaotong-Liverpool University Research Development Funding [Grant RDF-20-01-02].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0102},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2073-2111},
  shortjournal = {Math. Oper. Res.},
  title        = {Optimal ratcheting of dividends with capital injection},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the set of balanced games. <em>MOOR</em>, <em>50</em>(3), 2047-2072. (<a href='https://doi.org/10.1287/moor.2023.0379'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the geometric structure of the set of cooperative transferable utility games having a nonempty core, characterized by Bondareva and Shapley as balanced games. We show that this set is a nonpointed polyhedral cone, and we find the set of its extremal rays and facets. This study is also done for the set of balanced games whose value for the grand coalition is fixed, which yields an affine nonpointed polyhedral cone. Finally, the case of nonnegative balanced games with fixed value for the grand coalition is tackled. This set is a convex polytope, with remarkable properties. We characterize its vertices and facets, study the adjacency structure of vertices, develop an algorithm for generating vertices in a random uniform way, and show that this polytope is combinatorial and its adjacency graph is Hamiltonian. Last, we give a characterization of the set of games having a core reduced to a singleton. Funding: This work was supported by the Spanish Government [Grant PID2021-124933NB-I00].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0379},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2047-2072},
  shortjournal = {Math. Oper. Res.},
  title        = {On the set of balanced games},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parabolic regularity of spectral functions. <em>MOOR</em>, <em>50</em>(3), 2017-2046. (<a href='https://doi.org/10.1287/moor.2023.0010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the study of the second-order variational analysis of spectral functions. It is well-known that spectral functions can be expressed as a composite function of symmetric functions and eigenvalue functions. We establish several second-order properties of spectral functions when their associated symmetric functions enjoy these properties. Our main attention is given to characterize parabolic regularity for this class of functions. It was observed recently that parabolic regularity can play a central rule in ensuring the validity of important second-order variational properties, such as twice epi-differentiability. We demonstrates that for convex spectral functions, their parabolic regularity amounts to that of their symmetric functions. As an important consequence, we calculate the second subderivative of convex spectral functions, which allows us to establish second-order optimality conditions for a class of matrix optimization problems. Funding: The research of A. Mohammadi is funded by a postdoctoral fellowship from Georgetown University. E. Sarabi is partially supported by the U.S. National Science Foundation [Grant DMS 2108546].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0010},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {2017-2046},
  shortjournal = {Math. Oper. Res.},
  title        = {Parabolic regularity of spectral functions},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compact extended formulations for low-rank functions with indicator variables. <em>MOOR</em>, <em>50</em>(3), 1992-2016. (<a href='https://doi.org/10.1287/moor.2021.0281'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the mixed-integer epigraph of a special class of convex functions with nonconvex indicator constraints, which are often used to impose logical constraints on the support of the solutions. The class of functions we consider are defined as compositions of low-dimensional nonlinear functions with affine functions. Extended formulations describing the convex hull of such sets can easily be constructed via disjunctive programming although a direct application of this method often yields prohibitively large formulations, whose size is exponential in the number of variables. In this paper, we propose a new disjunctive representation of the sets under study, which leads to compact formulations with size exponential in the dimension of the nonlinear function but polynomial in the number of variables. Moreover, we show how to project out the additional variables for the case of dimension one, recovering or generalizing known results for the convex hulls of such sets (in the original space of variables). Our computational results indicate that the proposed approach can significantly improve the performance of solvers in structured problems. Funding: This work was supported by the National Science Foundation Division of Computing and Communication Foundations [Grant 2006762].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0281},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1992-2016},
  shortjournal = {Math. Oper. Res.},
  title        = {Compact extended formulations for low-rank functions with indicator variables},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information design and sharing in supply chains. <em>MOOR</em>, <em>50</em>(3), 1965-1991. (<a href='https://doi.org/10.1287/moor.2023.0008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the interplay between inventory replenishment policies and information sharing in the context of a two-tier supply chain with a single supplier and a single retailer serving an independent and identically distributed Gaussian market demand. We investigate how the retailer’s inventory policy impacts the supply chain’s cumulative expected long-term average inventory costs C in two extreme information-sharing cases: (a) full information sharing and (b) no information sharing. To find the retailer’s inventory policy that minimizes C , we formulate an infinite-dimensional optimization problem whose decision variables are the MA( ∞ ) coefficients that characterize a stationary ordering policy. Under full information sharing, the optimization problem admits a simple solution and the optimal policy is given by an MA(1) process. On the other hand, to solve the optimization problem under no information sharing, we reformulate the optimization from its time domain formulation to an equivalent z -transform formulation in which the decision variables correspond to elements of the Hardy space H 2 . This alternative representation allows us to use a number of results from H 2 theory to compute the optimal value of C and characterize a sequence of ϵ -optimal inventory policies under some mild technical conditions. By comparing the optimal solution under full information sharing and no information sharing, we derive a number of important practical takeaways. For instance, we show that there is value in information sharing if and only if the retailer’s optimal policy under full information sharing is not invertible with respect to the sequence of demand shocks. Furthermore, we derive a fundamental mathematical identity that reveals the value of information sharing by exploiting the canonical Smirnov–Beurling inner–outer factorization of the retailer’s orders when viewed as an element of H 2 . We also show that the value of information sharing can grow unboundedly when the cumulative supply chain costs are dominated by the supplier’s inventory costs. Funding: R. Caldentey acknowledges the University of Chicago Booth School of Business for financial support. Supplemental Material: The online appendix is available at https://doi.org/10.1287/moor.2023.0008 .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0008},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1965-1991},
  shortjournal = {Math. Oper. Res.},
  title        = {Information design and sharing in supply chains},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty propagation and dynamic robust risk measures. <em>MOOR</em>, <em>50</em>(3), 1939-1964. (<a href='https://doi.org/10.1287/moor.2023.0267'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a framework for quantifying propagation of uncertainty arising in a dynamic setting. Specifically, we define dynamic uncertainty sets designed explicitly for discrete stochastic processes over a finite time horizon. These dynamic uncertainty sets capture the uncertainty surrounding stochastic processes and models, accounting for factors such as distributional ambiguity. Examples of uncertainty sets include those induced by the Wasserstein distance and f -divergences. We further define dynamic robust risk measures as the supremum of all candidates’ risks within the uncertainty set. In an axiomatic way, we discuss conditions on the uncertainty sets that lead to well-known properties of dynamic robust risk measures, such as convexity and coherence. Furthermore, we discuss the necessary and sufficient properties of dynamic uncertainty sets that lead to time-consistencies of dynamic robust risk measures. We find that uncertainty sets stemming from f -divergences lead to strong time-consistency whereas the Wasserstein distance results in a new time-consistent notion of weak recursiveness. Moreover, we show that a dynamic robust risk measure is strong time-consistent or weak recursive if and only if it admits a recursive representation of one-step conditional robust risk measures arising from static uncertainty sets. Funding: M. Mailhot and S. M. Pesenti acknowledge support from the Canadian Statistical Sciences Institute (CANSSI) and from the Natural Sciences and Engineering Research Council of Canada [Grants RGPIN-2015-05447, DGECR-2020-00333, and RGPIN-2020-04289]. M. R. Moresco thanks the Horizon Postdoctoral Fellowship for the support.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0267},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1939-1964},
  shortjournal = {Math. Oper. Res.},
  title        = {Uncertainty propagation and dynamic robust risk measures},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Erratum to: Linear convergence of dual coordinate descent on nonpolyhedral convex problems. <em>MOOR</em>, <em>50</em>(3), 1935-1938. (<a href='https://doi.org/10.1287/moor.2024.0500'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our proof of linear convergence for Dykstra’s algorithm was erroneous, and in fact, there even exists a counterexample showing that the result is false.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2024.0500},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1935-1938},
  shortjournal = {Math. Oper. Res.},
  title        = {Erratum to: Linear convergence of dual coordinate descent on nonpolyhedral convex problems},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fair shares: Feasibility, domination, and incentives. <em>MOOR</em>, <em>50</em>(3), 1901-1934. (<a href='https://doi.org/10.1287/moor.2022.0257'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider fair allocation of indivisible goods to n equally entitled agents. Every agent i has a valuation function v i from some given class of valuation functions. A share s is a function that maps ( v i , n ) to a nonnegative value. A share is feasible if for every allocation instance, there is an allocation that gives every agent i a bundle that is acceptable with respect to v i , one of value at least her share value s ( v i , n ) . We introduce the following concepts. A share is self-maximizing if reporting the true valuation maximizes the minimum true value of a bundle that is acceptable with respect to the report. A share s ρ-dominates another share s ′ if s ( v i , n ) ≥ ρ · s ′ ( v i , n ) for every valuation function. We initiate a systematic study of feasible and self-maximizing shares and a systematic study of ρ -domination relation between shares, presenting both positive and negative results. Funding: The research of M. Babaioff is supported in part by a Golda Meir Fellowship. The research of U. Feige is supported in part by the Israel Science Foundation [Grant 1122/22].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0257},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1901-1934},
  shortjournal = {Math. Oper. Res.},
  title        = {Fair shares: Feasibility, domination, and incentives},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An augmented lagrangian approach to conically constrained nonmonotone variational inequality problems. <em>MOOR</em>, <em>50</em>(3), 1868-1900. (<a href='https://doi.org/10.1287/moor.2023.0167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider a nonmonotone (mixed) variational inequality (VI) model with (nonlinear) convex conic constraints. Through developing an equivalent Lagrangian function-like primal-dual saddle point system for the VI model in question, we introduce an augmented Lagrangian primal-dual method, called ALAVI (Augmented Lagrangian Approach to Variational Inequality) in the paper, for solving a general constrained VI model. Under an assumption, called the primal-dual variational coherence condition in the paper, we prove the convergence of ALAVI. Next, we show that many existing generalized monotonicity properties are sufficient—though by no means necessary—to imply the abovementioned coherence condition and thus are sufficient to ensure convergence of ALAVI. Under that assumption, we further show that ALAVI has in fact an o ( 1 / k ) global rate of convergence where k is the iteration count. By introducing a new gap function, this rate further improves to be O ( 1 / k ) if the mapping is monotone. Finally, we show that under a metric subregularity condition, even if the VI model may be nonmonotone, the local convergence rate of ALAVI improves to be linear. Numerical experiments on some randomly generated highly nonlinear and nonmonotone VI problems show the practical efficacy of the newly proposed method. Funding: L. Zhao and D. Zhu were partially supported by the Major Project of the National Natural Science Foundation of China [Grant 72293582], the National Key R&D Program of China [Grant 2023YFA0915202], and the Fundamental Research Funds for the Central Universities (the Interdisciplinary Program of Shanghai Jiao Tong University) [Grant YG2024QNA36]. L. Zhao was partially supported by the Startup Fund for Young Faculty at SJTU (SFYF at SJTU) [Grant 22X010503839].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0167},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1868-1900},
  shortjournal = {Math. Oper. Res.},
  title        = {An augmented lagrangian approach to conically constrained nonmonotone variational inequality problems},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonzero-sum optimal stopping game with continuous vs. periodic exercise opportunities. <em>MOOR</em>, <em>50</em>(3), 1832-1867. (<a href='https://doi.org/10.1287/moor.2023.0123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new nonzero-sum game of optimal stopping with asymmetric exercise opportunities. Given a stochastic process modeling the value of an asset, one player observes and can act on the process continuously, whereas the other player can act on it only periodically at independent Poisson arrival times. The first one to stop receives a reward, different for each player, whereas the other one gets nothing. We study how each player balances the maximization of gains against the maximization of the likelihood of stopping before the opponent. In such a setup driven by a Lévy process with positive jumps, we not only prove the existence but also explicitly construct a Nash equilibrium with values of the game written in terms of the scale function. Numerical illustrations with put-option payoffs are also provided to study the behavior of the players’ strategies as well as the quantification of the value of available exercise opportunities. Funding: K. Yamazaki was partly supported by The Japan Society for the Promotion of Science (JSPS) Grant-in-Aid for Scientific Research (KAKENHI) [Grants 19H01791, 20K03758, and 24K06844], Open Partnership Joint Research Projects [Grant JPJSBP120209921], and the University of Queensland [start-up grant].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0123},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1832-1867},
  shortjournal = {Math. Oper. Res.},
  title        = {Nonzero-sum optimal stopping game with continuous vs. periodic exercise opportunities},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploration noise for learning linear-quadratic mean field games. <em>MOOR</em>, <em>50</em>(3), 1762-1831. (<a href='https://doi.org/10.1287/moor.2021.0157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this paper is to demonstrate that common noise may serve as an exploration noise for learning the solution of a mean field game. This concept is here exemplified through a toy linear-quadratic model, for which a suitable form of common noise has already been proven to restore existence and uniqueness. We here go one step further and prove that the same form of common noise may force the convergence of the learning algorithm called fictitious play, and this without any further potential or monotone structure. Several numerical examples are provided to support our theoretical analysis. Funding: F. Delarue acknowledges the financial support of the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme [AdG ELISA project, Grant 101054746]. A. Vasileiadis acknowledge the financial support of French ANR project ANR-19-P3IA-0002-3IA Côte d'Azur-Nice-Interdisciplinary Institute for Artificial Intelligence.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0157},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1762-1831},
  shortjournal = {Math. Oper. Res.},
  title        = {Exploration noise for learning linear-quadratic mean field games},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A moment-sum-of-squares hierarchy for robust polynomial matrix inequality optimization with sum-of-squares convexity. <em>MOOR</em>, <em>50</em>(3), 1734-1761. (<a href='https://doi.org/10.1287/moor.2023.0361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a class of polynomial optimization problems with a robust polynomial matrix inequality (PMI) constraint where the uncertainty set itself is also defined by a PMI. These can be viewed as matrix generalizations of semi-infinite polynomial programs because they involve actually infinitely many PMI constraints in general. Under certain sum-of-squares (SOS)-convexity assumptions, we construct a hierarchy of increasingly tight moment-SOS relaxations for solving such problems. Most of the nice features of the moment-SOS hierarchy for the usual polynomial optimization are extended to this more complicated setting. In particular, asymptotic convergence of the hierarchy is guaranteed, and finite convergence can be certified if some flat extension condition holds true. To extract global minimizers, we provide a linear algebra procedure for recovering a finitely atomic matrix-valued measure from truncated matrix-valued moments. As an application, we are able to solve the problem of minimizing the smallest eigenvalue of a polynomial matrix subject to a PMI constraint. If SOS convexity is replaced by convexity, we can still approximate the optimal value as closely as desired by solving a sequence of semidefinite programs and certify global optimality in case that certain flat extension conditions hold true. Finally, an extension to the nonconvexity setting is provided under a rank 1 condition. To obtain the above-mentioned results, techniques from real algebraic geometry, matrix-valued measure theory, and convex optimization are employed. Funding: This work was supported by the National Key Research and Development Program of China [Grant 2023YFA1009401] and the National Natural Science Foundation of China [Grants 11571350 and 12201618].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0361},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1734-1761},
  shortjournal = {Math. Oper. Res.},
  title        = {A moment-sum-of-squares hierarchy for robust polynomial matrix inequality optimization with sum-of-squares convexity},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk-averse markov decision processes through a distributional lens. <em>MOOR</em>, <em>50</em>(3), 1707-1733. (<a href='https://doi.org/10.1287/moor.2023.0211'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By adopting a distributional viewpoint on law-invariant convex risk measures, we construct dynamic risk measures (DRMs) at the distributional level. We then apply these DRMs to investigate Markov decision processes, incorporating latent costs, random actions, and weakly continuous transition kernels. Furthermore, the proposed DRMs allow risk aversion to change dynamically. Under mild assumptions, we derive a dynamic programming principle and show the existence of an optimal policy in both finite and infinite time horizons. Moreover, we provide a sufficient condition for the optimality of deterministic actions. For illustration, we conclude the paper with examples from optimal liquidation with limit order books and autonomous driving. Funding: This work was supported by Natural Sciences and Engineering Research Council of Canada [Grants RGPAS-2018-522715 and RGPIN-2018-05705].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0211},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1707-1733},
  shortjournal = {Math. Oper. Res.},
  title        = {Risk-averse markov decision processes through a distributional lens},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the convex formulations of robust markov decision processes. <em>MOOR</em>, <em>50</em>(3), 1681-1706. (<a href='https://doi.org/10.1287/moor.2022.0284'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust Markov decision processes (MDPs) are used for applications of dynamic optimization in uncertain environments and have been studied extensively. Many of the main properties and algorithms of MDPs, such as value iteration and policy iteration, extend directly to RMDPs. Surprisingly, there is no known analog of the MDP convex optimization formulation for solving RMDPs. This work describes the first convex optimization formulation of RMDPs under the classical sa-rectangularity and s-rectangularity assumptions. By using entropic regularization and exponential change of variables, we derive a convex formulation with a number of variables and constraints polynomial in the number of states and actions, but with large coefficients in the constraints. We further simplify the formulation for RMDPs with polyhedral, ellipsoidal, or entropy-based uncertainty sets, showing that, in these cases, RMDPs can be reformulated as conic programs based on exponential cones, quadratic cones, and nonnegative orthants. Our work opens a new research direction for RMDPs and can serve as a first step toward obtaining a tractable convex formulation of RMDPs. Funding: The work in the paper was supported, in part, by NSF [Grants 2144601 and 1815275]; and Agence Nationale de la Recherche [Grant 11-LABX-0047].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0284},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1681-1706},
  shortjournal = {Math. Oper. Res.},
  title        = {On the convex formulations of robust markov decision processes},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimality conditions in control problems with random state constraints in probabilistic or almost sure form. <em>MOOR</em>, <em>50</em>(3), 1654-1680. (<a href='https://doi.org/10.1287/moor.2023.0177'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss optimality conditions for optimization problems involving random state constraints, which are modeled in probabilistic or almost sure form. Although the latter can be understood as the limiting case of the former, the derivation of optimality conditions requires substantially different approaches. We apply them to a linear elliptic partial differential equation with random inputs. In the probabilistic case, we rely on the spherical-radial decomposition of Gaussian random vectors in order to formulate fully explicit optimality conditions involving a spherical integral. In the almost sure case, we derive optimality conditions and compare them with a model based on robust constraints with respect to the (compact) support of the given distribution. Funding: The authors thank the Deutsche Forschungsgemeinschaft [Projects B02 and B04 in the “Sonderforschungsbereich/Transregio 154 Mathematical Modelling, Simulation and Optimization Using the Example of Gas Networks”] for support. C. Geiersbach acknowledges support from the Deutsche Forschungsgemeinschaft [Germany’s Excellence Strategy–the Berlin Mathematics Research Center MATH+ Grant EXC-2046/1, Project 390685689]. R. Henrion acknowledges support from the Fondation Mathématique Jacques Hadamard [Program Gaspard Monge in Optimization and Operations Research, including support to this program by Electricité de France].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0177},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1654-1680},
  shortjournal = {Math. Oper. Res.},
  title        = {Optimality conditions in control problems with random state constraints in probabilistic or almost sure form},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Order independence in sequential, issue-by-issue voting. <em>MOOR</em>, <em>50</em>(3), 1635-1653. (<a href='https://doi.org/10.1287/moor.2022.0342'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study when the voting outcome is independent of the order of issues put up for vote in a spatial multidimensional voting model. Agents equipped with norm-based preferences that use a norm to measure the distance from their ideal policy vote sequentially and issue by issue via simple majority. If the underlying norm is generated by an inner product—such as the Euclidean norm—then the voting outcome is order independent if and only if the issues are orthogonal. If the underlying norm is a general one, then the outcome is order independent if the basis defining the issues to be voted upon satisfies the following property; for any vector in the basis, any linear combination of the other vectors is Birkhoff–James orthogonal to it. We prove a partial converse in the case of two dimensions; if the underlying basis fails this property, then the voting order matters. Finally, despite existence results for the two-dimensional case and for the general l p case, we show that nonexistence of bases with this property is generic. Funding: The research of A. Gershkov is supported by the Israel Science Foundation [Grant 1118/22]. The research of B. Moldovanu is supported by the German Science Foundation through the Hausdorff Center for Mathematics and The Collaborative Research Center Transregio 224. The research of X. Shi is supported by the Social Sciences and Humanities Research Council of Canada.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0342},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1635-1653},
  shortjournal = {Math. Oper. Res.},
  title        = {Order independence in sequential, issue-by-issue voting},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large independent sets in recursive markov random graphs. <em>MOOR</em>, <em>50</em>(3), 1611-1634. (<a href='https://doi.org/10.1287/moor.2022.0215'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing the maximum size of an independent set in a graph is a famously hard combinatorial problem that has been well studied for various classes of graphs. When it comes to random graphs, the classic Erdős–Rényi–Gilbert random graph G n , p has been analyzed and shown to have the largest independent sets of size Θ ( log n ) with high probability (w.h.p.) This classic model does not capture any dependency structure between edges that can appear in real-world networks. We define random graphs G n , p r whose existence of edges is determined by a Markov process that is also governed by a decay parameter r ∈ ( 0 , 1 ] . We prove that w.h.p. G n , p r has independent sets of size ( 1 − r 2 + ε ) n log n for arbitrary ε > 0 . This is derived using bounds on the terms of a harmonic series, a Turán bound on a stability number, and a concentration analysis for a certain sequence of dependent Bernoulli variables that may also be of independent interest. Because G n , p r collapses to G n , p when there is no decay, it follows that having even the slightest bit of dependency (any r < 1 ) in the random graph construction leads to the presence of large independent sets, and thus, our random model has a phase transition at its boundary value of r = 1. This implies that there are large matchings in the line graph of G n , p r , which is a Markov random field. For the maximal independent set output by a greedy algorithm, we deduce that it has a performance ratio of at most 1 + log n ( 1 − r ) w.h.p. when the lowest degree vertex is picked at each iteration and also show that, under any other permutation of vertices, the algorithm outputs a set of size Ω ( n 1 / 1 + τ ) , where τ = 1 / ( 1 − r ) and, hence, has a performance ratio of O ( n 1 2 − r ) . Funding: The initial phase of this research was supported by the National Science Foundation [Grant DMS-1913294].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0215},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1611-1634},
  shortjournal = {Math. Oper. Res.},
  title        = {Large independent sets in recursive markov random graphs},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rockafellian relaxation and stochastic optimization under perturbations. <em>MOOR</em>, <em>50</em>(3), 1585-1610. (<a href='https://doi.org/10.1287/moor.2022.0122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practice, optimization models are often prone to unavoidable inaccuracies because of dubious assumptions and corrupted data. Traditionally, this placed special emphasis on risk-based and robust formulations, and their focus on “conservative” decisions. We develop, in contrast, an “optimistic” framework based on Rockafellian relaxations in which optimization is conducted not only over the original decision space but also jointly with a choice of model perturbation. The framework enables us to address challenging problems with ambiguous probability distributions from the areas of two-stage stochastic optimization without relatively complete recourse, probability functions lacking continuity properties, expectation constraints, and outlier analysis. We are also able to circumvent the fundamental difficulty in stochastic optimization that convergence of distributions fails to guarantee convergence of expectations. The framework centers on the novel concepts of exact and limit-exact Rockafellians, with interpretations of “negative” regularization emerging in certain settings. We illustrate the role of Phi-divergence, examine rates of convergence under changing distributions, and explore extensions to first-order optimality conditions. The main development is free of assumptions about convexity, smoothness, and even continuity of objective functions. Numerical results in the setting of computer vision and text analytics with label noise illustrate the framework. Funding: This work was supported by the Air Force Office of Scientific Research (Mathematical Optimization Program) under the grant: “Optimal Decision Making under Tight Performance Requirements in Adversarial and Uncertain Environments: Insight from Rockafellian Functions.”},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0122},
  journal      = {Mathematics of Operations Research},
  month        = {8},
  number       = {3},
  pages        = {1585-1610},
  shortjournal = {Math. Oper. Res.},
  title        = {Rockafellian relaxation and stochastic optimization under perturbations},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ρ-arbitrage and ρ-consistent pricing for star-shaped risk measures. <em>MOOR</em>, <em>50</em>(2), 1555-1583. (<a href='https://doi.org/10.1287/moor.2023.0173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper revisits mean-risk portfolio selection in a one-period financial market, where risk is quantified by a star-shaped risk measure ρ . We make three contributions. First, we introduce the new axiom of sensitivity to large expected losses and show that it is key to ensure the existence of optimal portfolios. Second, we give primal and dual characterizations of (strong) ρ -arbitrage. Finally, we use our conditions for the absence of (strong) ρ -arbitrage to explicitly derive the (strong) ρ -consistent price interval for an external financial contract.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0173},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1555-1583},
  shortjournal = {Math. Oper. Res.},
  title        = {ρ-arbitrage and ρ-consistent pricing for star-shaped risk measures},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rank-one boolean tensor factorization and the multilinear polytope. <em>MOOR</em>, <em>50</em>(2), 1514-1554. (<a href='https://doi.org/10.1287/moor.2022.0201'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the NP-hard problem of finding the closest rank-one binary tensor to a given binary tensor, which we refer to as the rank-one Boolean tensor factorization (BTF) problem. This optimization problem can be used to recover a planted rank-one tensor from noisy observations. We formulate rank-one BTF as the problem of minimizing a linear function over a highly structured multilinear set. Leveraging on our prior results regarding the facial structure of multilinear polytopes, we propose novel linear programming relaxations for rank-one BTF. We then establish deterministic sufficient conditions under which our proposed linear programs recover a planted rank-one tensor. To analyze the effectiveness of these deterministic conditions, we consider a semirandom model for the noisy tensor and obtain high probability recovery guarantees for the linear programs. Our theoretical results as well as numerical simulations indicate that certain facets of the multilinear polytope significantly improve the recovery properties of linear programming relaxations for rank-one BTF. Funding: A. Del Pia is partially funded by the Air Force Office of Scientific Research [Grant FA9550-23-1-0433]. A. Khajavirad is partially funded by the Air Force Office of Scientific Research [Grant FA9550-23-1-0123].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0201},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1514-1554},
  shortjournal = {Math. Oper. Res.},
  title        = {Rank-one boolean tensor factorization and the multilinear polytope},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investment timing and technological breakthroughs. <em>MOOR</em>, <em>50</em>(2), 1478-1513. (<a href='https://doi.org/10.1287/moor.2022.0022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the optimal investment policy of a firm facing both technological and cash-flow uncertainty. At any point in time, the firm can irreversibly invest in a stand-alone technology or wait for a technological breakthrough. Breakthroughs occur when market conditions become favorable enough, exceeding a threshold value that is ex ante unknown to the firm. The Markov state variables for the optimal investment policy are the current market conditions and their historic maximum, and the firm optimally invests in the stand-alone technology only when market conditions deteriorate enough after reaching a maximum. The path-dependent return required for investing in the stand-alone technology is always higher than if no technological breakthroughs could occur and can take arbitrarily large values following certain histories. Decreases in development costs or increases in the value of the new technology make the firm more prone to bearing downside risk and delaying investment in the stand-alone technology. Funding: This research has benefited from financial support of the ANR [Programmes d’Investissements d’Avenir CHESS ANR-17-EURE-0010 and ANITI ANR-19-PI3A-0004] and the research foundation TSE-Partnership [Chaire Marchés des Risques et Création de Valeur, Fondation du Risque/SCOR].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0022},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1478-1513},
  shortjournal = {Math. Oper. Res.},
  title        = {Investment timing and technological breakthroughs},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hidden convexity, optimization, and algorithms on rotation matrices. <em>MOOR</em>, <em>50</em>(2), 1454-1477. (<a href='https://doi.org/10.1287/moor.2023.0114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies hidden convexity properties associated with constrained optimization problems over the set of rotation matrices SO ( n ) . Such problems are nonconvex because of the constraint X ∈ SO ( n ) . Nonetheless, we show that certain linear images of SO ( n ) are convex, opening up the possibility for convex optimization algorithms with provable guarantees for these problems. Our main technical contributions show that any two-dimensional image of SO ( n ) is convex and that the projection of SO ( n ) onto its strict upper triangular entries is convex. These results allow us to construct exact convex reformulations for constrained optimization problems over SO ( n ) with a single constraint or with constraints defined by low-rank matrices. Both of these results are maximal in a formal sense. Funding: A. Ramachandran was supported by the H2020 program of the European Research Council [Grant 805241-QIP]. A. L. Wang was supported by the Nederlandse Organisatie voor Wetenschappelijk Onderzoek [Grant OCENW.GROOT.2019.015 (OPTIMAL)]. K. Shu was supported by the Georgia Institute of Technology (ACO-ARC fellowship).},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0114},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1454-1477},
  shortjournal = {Math. Oper. Res.},
  title        = {Hidden convexity, optimization, and algorithms on rotation matrices},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Procuring unverifiable information. <em>MOOR</em>, <em>50</em>(2), 1433-1453. (<a href='https://doi.org/10.1287/moor.2022.0085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study settings where information in the form of Bayesian signals is acquired by an expert on behalf of a principal. Information acquisition is costly for the expert and crucially not verifiable by the principal. The expert is compensated by the principal with a menu of state-contingent payments. We provide a full characterization of the set of all menus that implement (respectively, strictly implement) each signal. Moreover, we provide a closed-form characterization for the expected cost for the cheapest such menu, which we call proxy cost of the signal. Surprisingly, in general, the proxy cost is neither increasing in the Blackwell order nor posterior separable, even when the expert’s cost function is posterior separable itself. Subsequently, we study the full-agency problem (by introducing a downstream decision), thus endogenizing the signal. We show that there is always an optimal signal that can be strictly implemented, meaning that it is without loss of generality to exogenously restrict attention to strict implementation. As a result, similarly to Bayesian persuasion, the complexity of the principal’s optimal signal is bounded by the cardinality of the state space. Finally, we present some applications of interest. Funding: Financial support by the Wallander-Hedelius Foundation [Grants P2016-0072:1 and P20-0035 (to S. Sharma and M. Voorneveld)] is gratefully acknowledged.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0085},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1433-1453},
  shortjournal = {Math. Oper. Res.},
  title        = {Procuring unverifiable information},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How to design a stable serial knockout competition. <em>MOOR</em>, <em>50</em>(2), 1421-1432. (<a href='https://doi.org/10.1287/moor.2022.0352'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a new tournament format that consists of a series of individual knockout tournaments; we call this new format a serial knockout competition (SKC). This format has recently been adopted by the Professional Darts Corporation. Depending on the seedings of the players used for each of the knockout tournaments, players can meet in the various rounds (e.g., first round, second round … semifinal, final) of the knockout tournaments. Following a fairness principle of treating all players equal, we identify an attractive property of an SKCl each pair of players should potentially meet equally often in each of the rounds of the SKC. If the seedings are such that this property is indeed present, we call the resulting SKC stable . In this note, we formalize this notion, and we address the following question. Do there exist seedings for each of the knockout tournaments such that the resulting SKC is stable? We show using a connection to the Fano plane that the answer is yes for eight players, and we prove that the resulting SKC is unique up to permutations of the players. We further prove that stable SKCs exist for any numbers of players that are a power of two, and we provide stable schedules for competitions on 16 and 32 players. Funding: The research of F. Spieksma was partly funded by the Nederlandse Organisatie voor Wetenschappelijk Onderzoek [Grant 024.002.003].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0352},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1421-1432},
  shortjournal = {Math. Oper. Res.},
  title        = {How to design a stable serial knockout competition},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the simplex method for 0/1-polytopes. <em>MOOR</em>, <em>50</em>(2), 1398-1420. (<a href='https://doi.org/10.1287/moor.2021.0345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present three new pivot rules for the Simplex method for Linear Programs over 0/1-polytopes. We show that the number of nondegenerate steps taken using these three rules is strongly polynomial, linear in the number of variables, and linear in the dimension. Our bounds on the number of steps are asymptotically optimal on several well-known combinatorial polytopes. Our analysis is based on the geometry of 0/1-polytopes and novel modifications to the classical steepest-edge and shadow-vertex pivot rules. We draw interesting connections between our pivot rules and other well-known algorithms in combinatorial optimization. Funding: A. E. Black and J. A. De Loera are grateful for the support received through the National Science Foundation [Grants DMS-1818969 and NSF GRFP]. L. Sanita is grateful for the support received from the Nederlandse Organisatie voor Wetenschappelijk Onderzoek [Grant VI.Vidi.193.087].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0345},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1398-1420},
  shortjournal = {Math. Oper. Res.},
  title        = {On the simplex method for 0/1-polytopes},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variance-reduced accelerated first-order methods: Central limit theorems and confidence statements. <em>MOOR</em>, <em>50</em>(2), 1364-1397. (<a href='https://doi.org/10.1287/moor.2021.0068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a strongly convex stochastic optimization problem and propose three classes of variable sample-size stochastic first-order methods: (i) the standard stochastic gradient descent method, (ii) its accelerated variant, and (iii) the stochastic heavy-ball method. In each scheme, the exact gradients are approximated by averaging across an increasing batch size of sampled gradients. We prove that when the sample size increases at a geometric rate, the generated estimates converge in mean to the optimal solution at an analogous geometric rate for schemes (i)–(iii). Based on this result, we provide central limit statements, whereby it is shown that the rescaled estimation errors converge in distribution to a normal distribution with the associated covariance matrix dependent on the Hessian matrix, the covariance of the gradient noise, and the step length. If the sample size increases at a polynomial rate, we show that the estimation errors decay at a corresponding polynomial rate and establish the associated central limit theorems (CLTs). Under certain conditions, we discuss how both the algorithms and the associated limit theorems may be extended to constrained and nonsmooth regimes. Finally, we provide an avenue to construct confidence regions for the optimal solution based on the established CLTs and test the theoretical findings on a stochastic parameter estimation problem. Funding: This work was supported by the Office of Naval Research [Grant N00014-22-1-2589] and Basic Energy Sciences [Grant DE-SC0023303]. The work of J. Lei was partially supported by the National Natural Science Foundation of China [Grants 72271187 and 62088101]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/moor.2021.0068 .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0068},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1364-1397},
  shortjournal = {Math. Oper. Res.},
  title        = {Variance-reduced accelerated first-order methods: Central limit theorems and confidence statements},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Confidence intervals for piecewise normal distributions and stochastic variational inequalities. <em>MOOR</em>, <em>50</em>(2), 1333-1363. (<a href='https://doi.org/10.1287/moor.2023.0021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we first show how to obtain easy-to-compute confidence intervals for the center of a piecewise normal distribution given a sample from this distribution (assuming that the center belongs to a known affine set parallel to the common lineality space of all cones defining the piecewise normal distribution) by using certain skewed projectors on that space. We then extend this method to an asymptotic setting. Next, we apply this method to compute confidence intervals for the true solution of a stochastic variational inequality given a solution to a sample average approximation (SAA) problem for the general situation in which the asymptotic distribution of SAA solutions is piecewise normal. For stochastic complementarity problems, we obtain asymptotic normality of certain estimators of the true solution when the asymptotic distribution of the SAA solutions is piecewise normal. Funding: The research reported in this paper was supported the National Science Foundation [Grant DMS-1814894].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0021},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1333-1363},
  shortjournal = {Math. Oper. Res.},
  title        = {Confidence intervals for piecewise normal distributions and stochastic variational inequalities},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Markov decision processes with observation costs: Framework and computation with a penalty scheme. <em>MOOR</em>, <em>50</em>(2), 1305-1332. (<a href='https://doi.org/10.1287/moor.2023.0172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider Markov decision processes where the state of the chain is only given at chosen observation times and of a cost. Optimal strategies involve the optimization of observation times as well as the subsequent action values. We consider the finite horizon and discounted infinite horizon problems as well as an extension with parameter uncertainty. By including the time elapsed from observations as part of the augmented Markov system, the value function satisfies a system of quasivariational inequalities (QVIs). Such a class of QVIs can be seen as an extension to the interconnected obstacle problem. We prove a comparison principle for this class of QVIs, which implies the uniqueness of solutions to our proposed problem. Penalty methods are then utilized to obtain arbitrarily accurate solutions. Finally, we perform numerical experiments on three applications that illustrate our framework. Funding: J. Tam is supported by the Engineering and Physical Sciences Research Council [Grant 2269738].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0172},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1305-1332},
  shortjournal = {Math. Oper. Res.},
  title        = {Markov decision processes with observation costs: Framework and computation with a penalty scheme},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corruption-robust exploration in episodic reinforcement learning. <em>MOOR</em>, <em>50</em>(2), 1277-1304. (<a href='https://doi.org/10.1287/moor.2021.0202'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We initiate the study of episodic reinforcement learning (RL) under adversarial corruptions in both the rewards and the transition probabilities of the underlying system, extending recent results for the special case of multiarmed bandits. We provide a framework that modifies the aggressive exploration enjoyed by existing reinforcement learning approaches based on optimism in the face of uncertainty by complementing them with principles from action elimination. Importantly, our framework circumvents the major challenges posed by naively applying action elimination in the RL setting, as formalized by a lower bound we demonstrate. Our framework yields efficient algorithms that (a) attain near-optimal regret in the absence of corruptions and (b) adapt to unknown levels of corruption, enjoying regret guarantees that degrade gracefully in the total corruption encountered. To showcase the generality of our approach, we derive results for both tabular settings (where states and actions are finite) and linear Markov decision process settings (where the dynamics and rewards admit a linear underlying representation). Notably, our work provides the first sublinear regret guarantee that accommodates any deviation from purely independent and identically distributed transitions in the bandit-feedback model for episodic reinforcement learning. Supplemental Material: The online appendix is available at https://doi.org/10.1287/moor.2021.0202 .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0202},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1277-1304},
  shortjournal = {Math. Oper. Res.},
  title        = {Corruption-robust exploration in episodic reinforcement learning},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust multiple Stopping—A duality approach. <em>MOOR</em>, <em>50</em>(2), 1250-1276. (<a href='https://doi.org/10.1287/moor.2021.0237'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a method to solve, theoretically and numerically, general optimal stopping problems. Our general setting allows for multiple exercise rights—that is, optimal multiple stopping—for a robust evaluation that accounts for model uncertainty with a dominated family of priors and for general reward processes driven by multidimensional jump-diffusions. Our approach relies on first establishing robust martingale dual representation results for the multiple stopping problem that satisfy appealing almost sure pathwise optimality properties. Next, we exploit these theoretical results to develop upper and lower bounds that, as we formally show, not only converge to the true solution asymptotically, but also constitute genuine prelimiting upper and lower bounds. We illustrate the applicability of our approach in a few examples and analyze the impact of model uncertainty on optimal multiple stopping strategies. Funding: R. J. A. Laeven received financial support from the Netherlands Organization for Scientific Research (NWO) [Grants NWO-Vidi and NWO-Vici]. J. G. M. Schoenmakers received financial support from the Deutsche Forschungsgemeinschaft Excellence Cluster Math+ Berlin [Project AA4-2]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/moor.2021.0237 .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0237},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1250-1276},
  shortjournal = {Math. Oper. Res.},
  title        = {Robust multiple Stopping—A duality approach},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Liquid welfare guarantees for no-regret learning in sequential budgeted auctions. <em>MOOR</em>, <em>50</em>(2), 1233-1249. (<a href='https://doi.org/10.1287/moor.2023.0274'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the liquid welfare in sequential first-price auctions with budgeted buyers. We use a behavioral model for the buyers, assuming a learning style guarantee: the utility of each buyer is within a γ factor ( γ ≥ 1 ) of the utility achievable by shading their value with the same factor at each iteration. We show a γ + 1 / 2 + O ( 1 / γ ) price of anarchy for liquid welfare when valuations are additive. This is in stark contrast to sequential second-price auctions, where the resulting liquid welfare can be arbitrarily smaller than the maximum liquid welfare, even when γ = 1 . We prove a lower bound of γ on the liquid welfare loss under the given assumption in first-price auctions. Our liquid welfare results extend when buyers have submodular valuations over the set of items they win across iterations with a slightly worse price of anarchy bound of γ + 1 + O ( 1 / γ ) compared with the guarantee for the additive case. Funding: G. Fikioris is supported in part by the Air Force Office of Scientific Research [Grants FA9550-19-1-0183 and FA9550-23-1-0068], the Department of Defense (DoD) through the National Defense Science & Engineering Graduate (NDSEG) Fellowship Program, and the Onassis Foundation [Scholarship ID F ZS 068-1/2022-2023]. É. Tardos is supported in part by the NSF [Grant CCF-1408673] and AFOSR [Grants FA9550-19-1-0183, FA9550-23-1-0410, and FA9550-23-1-0068].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0274},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1233-1249},
  shortjournal = {Math. Oper. Res.},
  title        = {Liquid welfare guarantees for no-regret learning in sequential budgeted auctions},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal error bounds in the absence of constraint qualifications with applications to p-cones and beyond. <em>MOOR</em>, <em>50</em>(2), 1204-1232. (<a href='https://doi.org/10.1287/moor.2022.0135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove tight Hölderian error bounds for all p -cones. Surprisingly, the exponents differ in several ways from those that have been previously conjectured. Moreover, they illuminate p -cones as a curious example of a class of objects that possess properties in three dimensions that they do not in four or more. Using our error bounds, we analyse least squares problems with p -norm regularization, where our results enable us to compute the corresponding Kurdyka–Łojasiewicz exponents for previously inaccessible values of p . Another application is a (relatively) simple proof that most p -cones are neither self-dual nor homogeneous. Our error bounds are obtained under the framework of facial residual functions, and we expand it by establishing for general cones an optimality criterion under which the resulting error bound must be tight. Funding: The second author was partly supported by the Japan Society for the Promotion of Science Grant-in-Aid for Early-Career Scientists [Grants 19K20217, 23K16844] and Grant-in-Aid for Scientific Research [Grant (B)21H03398]. The third author was partly supported by the Hong Kong Research Grants Council [Grant PolyU153000/20p].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0135},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1204-1232},
  shortjournal = {Math. Oper. Res.},
  title        = {Optimal error bounds in the absence of constraint qualifications with applications to p-cones and beyond},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Is there a golden parachute in sannikov’s Principal–Agent problem?. <em>MOOR</em>, <em>50</em>(2), 1173-1203. (<a href='https://doi.org/10.1287/moor.2022.0305'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a complete review of the continuous-time optimal contracting problem introduced by Sannikov in the extended context allowing for possibly different discount rates for both parties. The agent’s problem is to seek for optimal effort given the compensation scheme proposed by the principal over a random horizon. Then, given the optimal agent’s response, the principal determines the best compensation scheme in terms of running payment, retirement, and lump-sum payment at retirement. A golden parachute is a situation where the agent ceases any effort at some positive stopping time and receives a payment afterward, possibly under the form of a lump-sum payment or of a continuous stream of payments. We show that a golden parachute only exists in certain specific circumstances. This is in contrast with the results claimed by Sannikov, where the only requirement is a positive agent’s marginal cost of effort at zero. In the general case, we prove that an agent with positive reservation utility is either never retired by the principal or retired above some given threshold (as in Sannikov’s solution). We show that different discount factors induce a facelifted utility function , which allows us to reduce the analysis to a setting similar to the equal-discount rates one. Finally, we also confirm that an agent with small reservation utility does have an informational rent, meaning that the principal optimally offers him a contract with strictly higher utility than his participation value.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0305},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1173-1203},
  shortjournal = {Math. Oper. Res.},
  title        = {Is there a golden parachute in sannikov’s Principal–Agent problem?},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning and balancing unknown loads in large-scale systems. <em>MOOR</em>, <em>50</em>(2), 1139-1172. (<a href='https://doi.org/10.1287/moor.2021.0212'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a system of identical server pools where tasks with exponentially distributed service times arrive as a time-inhomogeneous Poisson process. An admission threshold is used in an inner control loop to assign incoming tasks to server pools, while in an outer control loop, a learning scheme adjusts this threshold over time to keep it aligned with the unknown offered load of the system. In a many-server regime, we prove that the learning scheme reaches an equilibrium along intervals of time when the normalized offered load per server pool is suitably bounded and that this results in a balanced distribution of the load. Furthermore, we establish a similar result when tasks with Coxian distributed service times arrive at a constant rate and the threshold is adjusted using only the total number of tasks in the system. The novel proof technique developed in this paper, which differs from a traditional fluid limit analysis, allows us to handle rapid variations of the first learning scheme, triggered by excursions of the occupancy process that have vanishing size. Moreover, our approach allows us to characterize the asymptotic behavior of the system with Coxian distributed service times without relying on a fluid limit of a detailed state descriptor. Funding: The work in this paper was supported by the Nederlandse Organisatie voor Wetenschappelijk Onderzoek [Gravitation Grant NETWORKS-024.002.003 and Vici Grant 202.068].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0212},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1139-1172},
  shortjournal = {Math. Oper. Res.},
  title        = {Learning and balancing unknown loads in large-scale systems},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimating a function and its derivatives under a smoothness condition. <em>MOOR</em>, <em>50</em>(2), 1112-1138. (<a href='https://doi.org/10.1287/moor.2020.0161'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of estimating an unknown function f * : R d → R and its partial derivatives from a noisy data set of n observations, where we make no assumptions about f * except that it is smooth in the sense that it has square integrable partial derivatives of order m . A natural candidate for the estimator of f * in such a case is the best fit to the data set that satisfies a certain smoothness condition. This estimator can be seen as a least squares estimator subject to an upper bound on some measure of smoothness. Another useful estimator is the one that minimizes the degree of smoothness subject to an upper bound on the average of squared errors. We prove that these two estimators are computable as solutions to quadratic programs, establish the consistency of these estimators and their partial derivatives, and study the convergence rate as n → ∞ . The effectiveness of the estimators is illustrated numerically in a setting where the value of a stock option and its second derivative are estimated as functions of the underlying stock price.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2020.0161},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1112-1138},
  shortjournal = {Math. Oper. Res.},
  title        = {Estimating a function and its derivatives under a smoothness condition},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correlated equilibria for mean field games with progressive strategies. <em>MOOR</em>, <em>50</em>(2), 1072-1111. (<a href='https://doi.org/10.1287/moor.2022.0357'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a discrete space and time framework, we study the mean field game limit for a class of symmetric N -player games based on the notion of correlated equilibrium. We give a definition of correlated solution that allows us to construct approximate N -player correlated equilibria that are robust with respect to progressive deviations. We illustrate our definition by way of an example with explicit solutions. Funding: O. Bonesini acknowledges financial support from Engineering and Physical Sciences Research Council [Grant EP/T032146/1]. M. Fischer acknowledges partial support through the University of Padua [Research Project BIRD229791 “Stochastic mean field control and the Schrödinger problem”].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0357},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1072-1111},
  shortjournal = {Math. Oper. Res.},
  title        = {Correlated equilibria for mean field games with progressive strategies},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Equilibrium portfolio selection for smooth ambiguity preferences. <em>MOOR</em>, <em>50</em>(2), 1042-1071. (<a href='https://doi.org/10.1287/moor.2023.0112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the equilibrium portfolio selection for smooth ambiguity preferences in a continuous-time market. The investor is uncertain about the risky asset’s drift term and updates the subjective belief according to the Bayesian rule. A verification theorem is established, and an equilibrium strategy can be decomposed into a myopic demand and two hedging demands. When the prior is Gaussian, we provide an equilibrium solution in closed form. Moreover, a puzzle in the numerical results is interpreted via an alternative representation of the smooth ambiguity preferences. Funding: This work was supported by the National Key R&D Program of China [Grant 2020YFA0712700], the National Natural Science Foundation of China [Grants 11871036, 11901574, 12071146, 12271290, and 12371477], and the MOE Project of Key Research Institute of Humanities and Social Sciences [Grant 22JJD910003].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0112},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1042-1071},
  shortjournal = {Math. Oper. Res.},
  title        = {Equilibrium portfolio selection for smooth ambiguity preferences},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convexification of bilinear terms over network polytopes. <em>MOOR</em>, <em>50</em>(2), 1019-1041. (<a href='https://doi.org/10.1287/moor.2023.0001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well-known that the McCormick relaxation for the bilinear constraint z = xy gives the convex hull over the box domains for x and y . In network applications where the domain of bilinear variables is described by a network polytope, the McCormick relaxation, also referred to as linearization, fails to provide the convex hull and often leads to poor dual bounds. We study the convex hull of the set containing bilinear constraints z i , j = x i y j where x i represents the arc-flow variable in a network polytope, and y j is in a simplex. For the case where the simplex contains a single y variable, we introduce a systematic procedure to obtain the convex hull of the above set in the original space of variables, and show that all facet-defining inequalities of the convex hull can be obtained explicitly through identifying a special tree structure in the underlying network. For the generalization where the simplex contains multiple y variables, we design a constructive procedure to obtain an important class of facet-defining inequalities for the convex hull of the underlying bilinear set that is characterized by a special forest structure in the underlying network. Computational experiments conducted on different applications show the effectiveness of the proposed methods in improving the dual bounds obtained from alternative techniques. Funding: This work was supported by Air Force Office of Scientific Research [Grant FA9550-23-1-0183]; National Science Foundation, Division of Civil, Mechanical and Manufacturing Innovation [Grant 2338641]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/moor.2023.0001 .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0001},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {1019-1041},
  shortjournal = {Math. Oper. Res.},
  title        = {Convexification of bilinear terms over network polytopes},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficiency of stochastic coordinate proximal gradient methods on nonseparable composite optimization. <em>MOOR</em>, <em>50</em>(2), 993-1018. (<a href='https://doi.org/10.1287/moor.2023.0044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with composite optimization problems having the objective function formed as the sum of two terms; one has a Lipschitz continuous gradient along random subspaces and may be nonconvex, and the second term is simple and differentiable but possibly nonconvex and nonseparable. Under these settings, we design a stochastic coordinate proximal gradient method that takes into account the nonseparable composite form of the objective function. This algorithm achieves scalability by constructing at each iteration a local approximation model of the whole nonseparable objective function along a random subspace with user-determined dimension. We outline efficient techniques for selecting the random subspace, yielding an implementation that has low cost per iteration, also achieving fast convergence rates. We present a probabilistic worst case complexity analysis for our stochastic coordinate proximal gradient method in convex and nonconvex settings; in particular, we prove high-probability bounds on the number of iterations before a given optimality is achieved. Extensive numerical results also confirm the efficiency of our algorithm. Funding: This work was supported by Norway Grants 2014-2021 [Grant ELO-Hyp 24/2020]; Unitatea Executiva pentru Finantarea Invatamantului Superior, a Cercetarii, Dezvoltarii si Inovarii [Grants PN-III-P4-PCE-2021-0720, L2O-MOC, nr 70/2022]; and the ITN-ETN project TraDE-OPT funded by the European Union’s Horizon 2020 Research and Innovation Programme under the Marie Skłodowska-Curie grant agreement [Grant 861137].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0044},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {993-1018},
  shortjournal = {Math. Oper. Res.},
  title        = {Efficiency of stochastic coordinate proximal gradient methods on nonseparable composite optimization},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust-to-dynamics optimization. <em>MOOR</em>, <em>50</em>(2), 965-992. (<a href='https://doi.org/10.1287/moor.2023.0116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robust-to-dynamics optimization (RDO) problem is an optimization problem specified by two pieces of input: (i) a mathematical program (an objective function f : R n → R and a feasible set Ω ⊆ R n ) and (ii) a dynamical system (a map g : R n → R n ). Its goal is to minimize f over the set S ⊆ Ω of initial conditions that forever remain in Ω under g . The focus of this paper is on the case where the mathematical program is a linear program and where the dynamical system is either a known linear map or an uncertain linear map that can change over time. In both cases, we study a converging sequence of polyhedral outer approximations and (lifted) spectrahedral inner approximations to S . Our inner approximations are optimized with respect to the objective function f , and their semidefinite characterization—which has a semidefinite constraint of fixed size—is obtained by applying polar duality to convex sets that are invariant under (multiple) linear maps. We characterize three barriers that can stop convergence of the outer approximations to S from being finite. We prove that once these barriers are removed, our inner and outer approximating procedures find an optimal solution and a certificate of optimality for the RDO problem in a finite number of steps. Moreover, in the case where the dynamics are linear, we show that this phenomenon occurs in a number of steps that can be computed in time polynomial in the bit size of the input data. Our analysis also leads to a polynomial-time algorithm for RDO instances where the spectral radius of the linear map is bounded above by any constant less than one. Finally, in our concluding section, we propose a broader research agenda for studying optimization problems with dynamical systems constraints , of which RDO is a special case. Funding: O. Günlük was partially supported by the Office of Naval Research [Grant N00014-21-1-2575]. This work was partially funded by the Alfred P. Sloan Foundation, the Air Force Office of Scientific Research, Defense Advanced Research Projects Agency [Young Faculty Award], the National Science Foundation [Faculty Early Career Development Program Award], and Google [Faculty Award].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0116},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {965-992},
  shortjournal = {Math. Oper. Res.},
  title        = {Robust-to-dynamics optimization},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time high-probability bounds for Polyak–Ruppert averaged iterates of linear stochastic approximation. <em>MOOR</em>, <em>50</em>(2), 935-964. (<a href='https://doi.org/10.1287/moor.2022.0179'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a finite-time analysis of linear stochastic approximation (LSA) algorithms with fixed step size, a core method in statistics and machine learning. LSA is used to compute approximate solutions of a d -dimensional linear system A ¯ θ = b ¯ for which ( A ¯ , b ¯ ) can only be estimated by (asymptotically) unbiased observations { ( A ( Z n ) , b ( Z n ) ) } n ∈ N . We consider here the case where { Z n } n ∈ N is an a sequence of independent and identically distributed random variables sequence or a uniformly geometrically ergodic Markov chain. We derive p th moment and high-probability deviation bounds for the iterates defined by LSA and its Polyak–Ruppert-averaged version. Our finite-time instance-dependent bounds for the averaged LSA iterates are sharp in the sense that the leading term we obtain coincides with the local asymptotic minimax limit. Moreover, the remainder terms of our bounds admit a tight dependence on the mixing time t mix of the underlying chain and the norm of the noise variables. We emphasize that our result requires the LSA step size to scale only with logarithm of the problem dimension d . Funding: The work of A. Durmus and E. Moulines was partly supported by [Grant ANR-19-CHIA-0002]. This project received funding from the European Research Council [ERC-SyG OCEAN Grant 101071601]. The research of A. Naumov and S. Samsonov was prepared within the framework of the HSE University Basic Research Program.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0179},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {935-964},
  shortjournal = {Math. Oper. Res.},
  title        = {Finite-time high-probability bounds for Polyak–Ruppert averaged iterates of linear stochastic approximation},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Practical algorithms with guaranteed approximation ratio for traveling tournament problem with maximum tour length 2. <em>MOOR</em>, <em>50</em>(2), 910-934. (<a href='https://doi.org/10.1287/moor.2022.0356'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traveling tournament problem (TTP) is a hard but interesting sports scheduling problem inspired by Major League Baseball, which is to design a double round-robin schedule such that each pair of teams plays one game in each other’s home venue, minimizing the total distance traveled by all n teams ( n is even). In this paper, we consider TTP-2 (i.e., TTP under the constraint that at most two consecutive home games or away games are allowed for each team). In this paper, we propose practical algorithms for TTP-2 with improved approximation ratios. Because of the different structural properties of the problem, all known algorithms for TTP-2 are different for n /2 being odd and even, and our algorithms are also different for these two cases. For even n /2, our approximation ratio is 1 + 3 / n , improving the previous result of 1 + 4 / n . For odd n /2, our approximation ratio is 1 + 5 / n , improving the previous result of 3 / 2 + 6 / n . In practice, our algorithms are easy to implement. Experiments on well-known benchmark sets show that our algorithms beat previously known solutions for all instances with an average improvement of 5.66%. Funding: This work was supported by the National Natural Science Foundation of China [Grants 62372095 and 62172077] and the Sichuan Natural Science Foundation [Grant 2023NSFSC0059].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0356},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {910-934},
  shortjournal = {Math. Oper. Res.},
  title        = {Practical algorithms with guaranteed approximation ratio for traveling tournament problem with maximum tour length 2},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On constrained mixed-integer DR-submodular minimization. <em>MOOR</em>, <em>50</em>(2), 871-909. (<a href='https://doi.org/10.1287/moor.2022.0320'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diminishing returns (DR)–submodular functions encompass a broad class of functions that are generally nonconvex and nonconcave. We study the problem of minimizing any DR-submodular function with continuous and general integer variables under box constraints and, possibly, additional monotonicity constraints. We propose valid linear inequalities for the epigraph of any DR-submodular function under the constraints. We further provide the complete convex hull of such an epigraph, which, surprisingly, turns out to be polyhedral. We propose a polynomial-time exact separation algorithm for our proposed valid inequalities with which we first establish the polynomial-time solvability of this class of mixed-integer nonlinear optimization problems. Funding: This work was supported by the Office of Naval Research Global [Grant N00014-22-1-2602].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0320},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {871-909},
  shortjournal = {Math. Oper. Res.},
  title        = {On constrained mixed-integer DR-submodular minimization},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Opinion dynamics on directed complex networks. <em>MOOR</em>, <em>50</em>(2), 838-870. (<a href='https://doi.org/10.1287/moor.2022.0250'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and analyze a mathematical model for the evolution of opinions on directed complex networks. Our model generalizes the popular DeGroot and Friedkin-Johnsen models by allowing vertices to have attributes that may influence the opinion dynamics. We start by establishing sufficient conditions for the existence of a stationary opinion distribution on any fixed graph, and then provide an increasingly detailed characterization of its behavior by considering a sequence of directed random graphs having a local weak limit. Our most explicit results are obtained for graph sequences whose local weak limit is a marked Galton-Watson tree, in which case our model can be used to explain a variety of phenomena, for example, conditions under which consensus can be achieved, mechanisms in which opinions can become polarized, and the effect of disruptive stubborn agents on the formation of opinions. Funding: This work was supported by the National Science Foundation [Grants NSF-DMS-1929298 and CMMI-2243261].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0250},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {838-870},
  shortjournal = {Math. Oper. Res.},
  title        = {Opinion dynamics on directed complex networks},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simple and explicit bounds for multiserver queues with 1/1−ρ scaling. <em>MOOR</em>, <em>50</em>(2), 813-837. (<a href='https://doi.org/10.1287/moor.2022.0131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the first-come-first-serve (FCFS) G I / G I / n queue and prove the first simple and explicit bounds that scale as 1 1 − ρ under only the assumption that interarrival times have finite second moment, and service times have finite 2 + ϵ moment for some ϵ > 0 . Here, ρ denotes the corresponding traffic intensity. Conceptually, our results can be viewed as a multiserver analogue of Kingman’s bound. Our main results are bounds for the tail of the steady-state queue length and the steady-state probability of delay. The strength of our bounds (e.g., in the form of tail decay rate) is a function of how many moments of the service distribution are assumed finite. Our bounds scale gracefully, even when the number of servers grows large and the traffic intensity converges to unity simultaneously, as in the Halfin-Whitt scaling regime. Some of our bounds scale better than 1 1 − ρ in certain asymptotic regimes. In these same asymptotic regimes, we also prove bounds for the tail of the steady-state number in service. Our main proofs proceed by explicitly analyzing the bounding process that arises in the stochastic comparison bounds of Gamarnik and Goldberg for multiserver queues. Along the way, we derive several novel results for suprema of random walks and pooled renewal processes, which may be of independent interest. We also prove several additional bounds using drift arguments (which have much smaller prefactors) and point out a conjecture that would imply further related bounds and generalizations. We also show that when all moments of the service distribution are finite and satisfy a mild growth rate assumption, our bounds can be strengthened to yield explicit tail estimates decaying as O ( exp ( − x α ) ) , with α ∈ ( 0 , 1 ) , depending on the growth rate of these moments. Funding: Financial support from the National Science Foundation [Grant 1333457] is gratefully acknowledged. Supplemental Material: The supplemental appendix is available at https://doi.org/10.1287/moor.2022.0131 .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0131},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {813-837},
  shortjournal = {Math. Oper. Res.},
  title        = {Simple and explicit bounds for multiserver queues with 1/1−ρ scaling},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An approximation to the invariant measure of the limiting diffusion of G/Ph/n + GI queues in the Halfin–Whitt regime and related asymptotics. <em>MOOR</em>, <em>50</em>(2), 783-812. (<a href='https://doi.org/10.1287/moor.2021.0241'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a stochastic algorithm based on the Euler–Maruyama scheme to approximate the invariant measure of the limiting multidimensional diffusion of G / P h / n + G I queues in the Halfin–Whitt regime. Specifically, we prove a nonasymptotic error bound between the invariant measures of the approximate model from the algorithm and the limiting diffusion. To establish the error bound, we employ the recently developed Stein’s method for multidimensional diffusions, in which the regularity of Stein’s equation obtained by the partial differential equation (PDE) theory plays a crucial role. We further prove the central limit theorem (CLT) and the moderate deviation principle (MDP) for the occupation measures of the limiting diffusion of G / P h / n + G I queues and its Euler–Maruyama scheme. In particular, the variances in the CLT and MDP associated with the limiting diffusion are determined by Stein’s equation and Malliavin calculus, in which properties of a mollified diffusion and an associated weighted occupation time play a crucial role. Funding: X. Jin is supported in part by the Fundamental Research Funds for the Central Universities [Grants JZ2022HGQA0148 and JZ2023HGTA0170]. G. Pang is supported in part by the U.S. National Science Foundation [Grants DMS-1715875 and DMS-2216765]. L. Xu is supported in part by the National Nature Science Foundation of China [Grant 12071499], Macao Special Administrative Region [Grant FDCT 0090/2019/A2], and the University of Macau [Grant MYRG2018-00133-FST]. This work was supported by U.S. National Science Foundation [Grant DMS-2108683].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0241},
  journal      = {Mathematics of Operations Research},
  month        = {5},
  number       = {2},
  pages        = {783-812},
  shortjournal = {Math. Oper. Res.},
  title        = {An approximation to the invariant measure of the limiting diffusion of G/Ph/n + GI queues in the Halfin–Whitt regime and related asymptotics},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Steiner cut dominants. <em>MOOR</em>, <em>50</em>(1), 764-781. (<a href='https://doi.org/10.1287/moor.2022.0280'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a subset T of nodes of an undirected graph G , a T-Steiner cut is a cut δ ( S ) with T ∩ S ≠ ø and T \ S ≠ ø . The T-Steiner cut dominant of G is the dominant CUT + ( G , T ) of the convex hull of the incidence vectors of the T -Steiner cuts of G . For T = { s , t } , this is the well-understood s - t -cut dominant. Choosing T as the set of all nodes of G , we obtain the cut dominant for which an outer description in the space of the original variables is still not known. We prove that for each integer τ , there is a finite set of inequalities such that for every pair ( G , T ) with | T | ≤ τ , the nontrivial facet-defining inequalities of CUT + ( G , T ) are the inequalities that can be obtained via iterated applications of two simple operations, starting from that set. In particular, the absolute values of the coefficients and of the right-hand sides in a description of CUT + ( G , T ) by integral inequalities can be bounded from above by a function of | T | . For all | T | ≤ 5 , we provide descriptions of CUT + ( G , T ) by facet-defining inequalities, extending the known descriptions of s - t -cut dominants.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0280},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {764-781},
  shortjournal = {Math. Oper. Res.},
  title        = {Steiner cut dominants},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uniqueness of convex-ranged probabilities and applications to risk measures and games. <em>MOOR</em>, <em>50</em>(1), 743-763. (<a href='https://doi.org/10.1287/moor.2023.0015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit Marinacci’s uniqueness theorem for convex-ranged probabilities and its applications. Our approach does away with both the countable additivity and the positivity of the charges involved. In the process, we uncover several new equivalent conditions, which lead to a novel set of applications. These include extensions of the classic Fréchet–Hoeffding bounds as well as of the automatic Fatou property of law-invariant functionals. We also generalize existing results of the “collapse to the mean”-type concerning capacities and α -MEU preferences.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0015},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {743-763},
  shortjournal = {Math. Oper. Res.},
  title        = {Uniqueness of convex-ranged probabilities and applications to risk measures and games},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sample-path large deviations for unbounded additive functionals of the reflected random walk. <em>MOOR</em>, <em>50</em>(1), 711-742. (<a href='https://doi.org/10.1287/moor.2020.0094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove a sample-path large deviation principle (LDP) with sublinear speed for unbounded functionals of certain Markov chains induced by the Lindley recursion. The LDP holds in the Skorokhod space D [ 0 , 1 ] equipped with the M 1 ′ topology. Our technique hinges on a suitable decomposition of the Markov chain in terms of regeneration cycles. Each regeneration cycle denotes the area accumulated during the busy period of the reflected random walk. We prove a large deviation principle for the area under the busy period of the Markov random walk, and we show that it exhibits a heavy-tailed behavior. Funding: The research of B. Zwart and M. Bazhba is supported by the Nederlandse Organisatie voor Wetenschappelijk Onderzoek [Grant 639.033.413]. The research of J. Blanchet is supported by the National Science Foundation (NSF) [Grants 1915967, 1820942, and 1838576] as well as the Defense Advanced Research Projects Agency [Grant N660011824028]. The research of C.-H. Rhee is supported by the NSF [Grant CMMI-2146530].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2020.0094},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {711-742},
  shortjournal = {Math. Oper. Res.},
  title        = {Sample-path large deviations for unbounded additive functionals of the reflected random walk},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact characterization of the jointly optimal restocking and auditing policy in inventory systems with record inaccuracy. <em>MOOR</em>, <em>50</em>(1), 656-710. (<a href='https://doi.org/10.1287/moor.2022.0145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a continuous-time stochastic model of an inventory system with record inaccuracy. In this formulation, demand is modeled by a point process and is observable only when it leads to sales. In addition to demand that can reduce the stock, an unobservable stochastic loss process can also reduce the stock. The retailer’s goal is to identify the restocking and auditing policy that minimizes the expected discounted cost of carrying a product over an infinite horizon. We analytically characterize the optimal restocking and jointly optimal auditing policy. We prove that the optimal restocking policy is a threshold policy. Our proof of this result is based on a coupling argument that is valid for any demand and loss model. Unlike the optimal restocking policy, the jointly optimal auditing policy is not of threshold type. We show that a complete proof of this statement cannot be obtained by solely resorting to the first-order stochastic dominance property of the Bayesian shelf stock distribution induced by the demand and loss process. Instead, our characterization of the jointly optimal auditing policy is based on proving that the dynamics of the shelf stock distribution constitute a (strictly) sign-regular kernel. To our knowledge, this is the first paper that characterizes the optimal policy of a complex control problem by establishing sign regularity of its underlying Markovian dynamics. Our theoretical results lead to a fast algorithm for computing the exact jointly optimal auditing/restocking policy over the problem’s entire state space. This enables comparative statics analysis, which allows us to determine how inventory record inaccuracy affects the economic significance of various cost drivers. This, in turn, allows us to determine when or, better, under what conditions auditing can be an effective tool for reducing the total cost.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0145},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {656-710},
  shortjournal = {Math. Oper. Res.},
  title        = {Exact characterization of the jointly optimal restocking and auditing policy in inventory systems with record inaccuracy},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast rates for the regret of offline reinforcement learning. <em>MOOR</em>, <em>50</em>(1), 633-655. (<a href='https://doi.org/10.1287/moor.2021.0167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the regret of offline reinforcement learning in an infinite-horizon discounted Markov decision process (MDP). While existing analyses of common approaches, such as fitted Q -iteration (FQI), suggest root- n convergence for regret, empirical behavior exhibits much faster convergence. In this paper, we present a finer regret analysis that exactly characterizes this phenomenon by providing fast rates for the regret convergence. First, we show that given any estimate for the optimal quality function, the regret of the policy it defines converges at a rate given by the exponentiation of the estimate’s pointwise convergence rate, thus speeding up the rate. The level of exponentiation depends on the level of noise in the decision-making problem, rather than the estimation problem. We establish such noise levels for linear and tabular MDPs as examples. Second, we provide new analyses of FQI and Bellman residual minimization to establish the correct pointwise convergence guarantees. As specific cases, our results imply one-over- n rates in linear cases and exponential-in- n rates in tabular cases. We extend our findings to general function approximation by extending our results to regret guarantees based on L p -convergence rates for estimating the optimal quality function rather than pointwise rates, where L 2 guarantees for nonparametric estimation can be ensured under mild conditions. Funding: This work was supported by the Division of Information and Intelligent Systems, National Science Foundation [Grant 1846210].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0167},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {633-655},
  shortjournal = {Math. Oper. Res.},
  title        = {Fast rates for the regret of offline reinforcement learning},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal investment strategy for α-robust utility maximization problem. <em>MOOR</em>, <em>50</em>(1), 606-632. (<a href='https://doi.org/10.1287/moor.2023.0076'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In reality, investors are uncertain about the dynamics of risky asset returns. Therefore, investors prefer to make robust investment decisions. In this paper, we propose an α-robust utility maximization problem under uncertain parameters. The investor is allowed to invest in a financial market consisting of a risk-free asset and a risky asset. The uncertainty about the expected return rate is parameterized by a nonempty set. Different from most existing literature on robust utility maximization problems where investors are generally assumed to be extremely ambiguity averse because they tend to consider only expected utility in the worst-case scenario, we pay attention to the investors who are not only ambiguity averse but also ambiguity seeking. Under power utility, we provide the implicit function representations for the precommitted strategy, equilibrium strategy of the open-loop type, and equilibrium strategy of the closed-loop type. Some properties about the optimal trading strategies, the best-case and worst-case parameters under three different kinds of strategies, are provided. Funding: This work was supported by National Natural Science Foundation of China [Grants 12071147, 12171169, 12271171, 12371470, 71721001, 71931004, 72371256], the Shanghai Philosophy Social Science Planning Office Project [Grant 2022ZJB005], Fundamental Research Funds for the Central Universities [Grant 2022QKT001], the Excellent Young Team Project Natural Science Foundation of Guangdong Province of China [Grant 2023B1515040001], the Philosophy and Social Science Programming Foundation of Guangdong Province [Grant GD22CYJ17], the Nature Science Foundation of Guangdong Province of China [Grant 2022A1515011472], and the 111 Project [Grant B14019].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0076},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {606-632},
  shortjournal = {Math. Oper. Res.},
  title        = {Optimal investment strategy for α-robust utility maximization problem},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multilevel langevin pathwise average for gibbs approximation. <em>MOOR</em>, <em>50</em>(1), 573-605. (<a href='https://doi.org/10.1287/moor.2021.0243'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and study a new multilevel method for the numerical approximation of a Gibbs distribution π on R d , based on (overdamped) Langevin diffusions. This method relies on a multilevel occupation measure, that is, on an appropriate combination of R occupation measures of (constant-step) Euler schemes with respective steps γ r = γ 0 2 − r , r = 0 , … , R . We first state a quantitative result under general assumptions that guarantees an ε-approximation (in an L 2 -sense) with a cost of the order ε − 2 or ε − 2 | log ε | 3 under less contractive assumptions. We then apply it to overdamped Langevin diffusions with strongly convex potential U : R d → R and obtain an ε-complexity of the order O ( d ε − 2 log 3 ( d ε − 2 ) ) or O ( d ε − 2 ) under additional assumptions on U . More precisely, up to universal constants, an appropriate choice of the parameters leads to a cost controlled by ( λ ¯ U ∨ 1 ) 2 λ ¯ U − 3 d ε − 2 (where λ ¯ U and λ ¯ U respectively denote the supremum and the infimum of the largest and lowest eigenvalue of D 2 U ). We finally complete these theoretical results with some numerical illustrations, including comparisons to other algorithms in Bayesian learning and opening to the non–strongly convex setting. Funding: The authors are grateful to the SIRIC ILIAD Nantes-Angers program, supported by the French National Cancer Institute [INCA-DGOS-Inserm Grant 12558].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0243},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {573-605},
  shortjournal = {Math. Oper. Res.},
  title        = {Multilevel langevin pathwise average for gibbs approximation},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semidefinite approximations for bicliques and bi-independent pairs. <em>MOOR</em>, <em>50</em>(1), 537-572. (<a href='https://doi.org/10.1287/moor.2023.0046'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate some graph parameters dealing with bi-independent pairs ( A , B ) in a bipartite graph G = ( V 1 ∪ V 2 , E ) , that is, pairs ( A , B ) where A ⊆ V 1 , B ⊆ V 2 , and A ∪ B are independent. These parameters also allow us to study bicliques in general graphs. When maximizing the cardinality | A ∪ B | , one finds the stability number α ( G ) , well-known to be polynomial-time computable. When maximizing the product | A | · | B | , one finds the parameter g ( G ), shown to be NP-hard by Peeters in 2003, and when maximizing the ratio | A | · | B | / | A ∪ B | , one finds h ( G ), introduced by Vallentin in 2020 for bounding product-free sets in finite groups. We show that h ( G ) is an NP-hard parameter and, as a crucial ingredient, that it is NP-complete to decide whether a bipartite graph G has a balanced maximum independent set. These hardness results motivate introducing semidefinite programming (SDP) bounds for g ( G ), h ( G ), and α bal ( G ) (the maximum cardinality of a balanced independent set). We show that these bounds can be seen as natural variations of the Lovász ϑ-number, a well-known semidefinite bound on α ( G ) . In addition, we formulate closed-form eigenvalue bounds, and we show relationships among them as well as with earlier spectral parameters by Hoffman and Haemers in 2001 and Vallentin in 2020. Funding: This work was supported by H2020 Marie Skłodowska-Curie Actions [Grant 813211 (POEMA)].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0046},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {537-572},
  shortjournal = {Math. Oper. Res.},
  title        = {Semidefinite approximations for bicliques and bi-independent pairs},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mean-field multiagent reinforcement learning: A decentralized network approach. <em>MOOR</em>, <em>50</em>(1), 506-536. (<a href='https://doi.org/10.1287/moor.2022.0055'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the challenges for multiagent reinforcement learning (MARL) is designing efficient learning algorithms for a large system in which each agent has only limited or partial information of the entire system. Whereas exciting progress has been made to analyze decentralized MARL with the network of agents for social networks and team video games, little is known theoretically for decentralized MARL with the network of states for modeling self-driving vehicles, ride-sharing, and data and traffic routing. This paper proposes a framework of localized training and decentralized execution to study MARL with the network of states. Localized training means that agents only need to collect local information in their neighboring states during the training phase; decentralized execution implies that agents can execute afterward the learned decentralized policies, which depend only on agents’ current states. The theoretical analysis consists of three key components: the first is the reformulation of the MARL system as a networked Markov decision process with teams of agents, enabling updating the associated team Q-function in a localized fashion; the second is the Bellman equation for the value function and the appropriate Q-function on the probability measure space; and the third is the exponential decay property of the team Q-function, facilitating its approximation with efficient sample efficiency and controllable error. The theoretical analysis paves the way for a new algorithm LTDE-N eural -AC, in which the actor–critic approach with overparameterized neural networks is proposed. The convergence and sample complexity are established and shown to be scalable with respect to the sizes of both agents and states. To the best of our knowledge, this is the first neural network–based MARL algorithm with network structure and provable convergence guarantee. Funding: X. Wei is partially supported by NSFC no. 12201343. R. Xu is partially supported by the NSF CAREER award DMS-2339240.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0055},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {506-536},
  shortjournal = {Math. Oper. Res.},
  title        = {Mean-field multiagent reinforcement learning: A decentralized network approach},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Marginal values of a stochastic game. <em>MOOR</em>, <em>50</em>(1), 482-505. (<a href='https://doi.org/10.1287/moor.2023.0297'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-sum stochastic games are parameterized by payoffs, transitions, and possibly a discount rate. In this article, we study how the main solution concepts, the discounted and undiscounted values, vary when these parameters are perturbed. We focus on the marginal values, introduced by Mills in 1956 in the context of matrix games—that is, the directional derivatives of the value along any fixed perturbation. We provide a formula for the marginal values of a discounted stochastic game. Further, under mild assumptions on the perturbation, we provide a formula for their limit as the discount rate vanishes and for the marginal values of an undiscounted stochastic game. We also show, via an example, that the two latter differ in general. Funding: This work was supported by Fondation CFM pour la Recherche; the European Research Council [Grant ERC-CoG-863818 (ForM-SMArt)]; and Agence Nationale de la Recherche [Grant ANR-21-CE40-0020].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0297},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {482-505},
  shortjournal = {Math. Oper. Res.},
  title        = {Marginal values of a stochastic game},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence and stability of coupled belief-strategy learning dynamics in continuous games. <em>MOOR</em>, <em>50</em>(1), 459-481. (<a href='https://doi.org/10.1287/moor.2022.0161'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a learning dynamics to model how strategic agents repeatedly play a continuous game while relying on an information platform to learn an unknown payoff-relevant parameter. In each time step, the platform updates a belief estimate of the parameter based on players’ strategies and realized payoffs using Bayes’ rule. Then, players adopt a generic learning rule to adjust their strategies based on the updated belief. We present results on the convergence of beliefs and strategies and the properties of convergent fixed points of the dynamics. We obtain sufficient and necessary conditions for the existence of globally stable fixed points. We also provide sufficient conditions for the local stability of fixed points. These results provide an approach to analyzing the long-term outcomes that arise from the interplay between Bayesian belief learning and strategy learning in games and enable us to characterize conditions under which learning leads to a complete information equilibrium. Funding: Financial support from the Air Force Office of Scientific Research [Project Building Attack Resilience into Complex Networks], the Simons Institute [research fellowship], and a Michael Hammer Fellowship is gratefully acknowledged.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0161},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {459-481},
  shortjournal = {Math. Oper. Res.},
  title        = {Convergence and stability of coupled belief-strategy learning dynamics in continuous games},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A policy gradient algorithm for the risk-sensitive exponential cost MDP. <em>MOOR</em>, <em>50</em>(1), 431-458. (<a href='https://doi.org/10.1287/moor.2022.0139'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the risk-sensitive exponential cost Markov decision process (MDP) formulation and develop a trajectory-based gradient algorithm to find the stationary point of the cost associated with a set of parameterized policies. We derive a formula that can be used to compute the policy gradient from (state, action, cost) information collected from sample paths of the MDP for each fixed parameterized policy. Unlike the traditional average cost problem, standard stochastic approximation theory cannot be used to exploit this formula. To address the issue, we introduce a truncated and smooth version of the risk-sensitive cost and show that this new cost criterion can be used to approximate the risk-sensitive cost and its gradient uniformly under some mild assumptions. We then develop a trajectory-based gradient algorithm to minimize the smooth truncated estimation of the risk-sensitive cost and derive conditions under which a sequence of truncations can be used to solve the original, untruncated cost problem. Funding: This work was supported by the Office of Naval Research Global [Grant N0001419-1-2566], the Division of Computer and Network Systems [Grant 21-06801], the Army Research Office [Grant W911NF-19-1-0379], and the Division of Computing and Communication Foundations [Grants 17-04970 and 19-34986].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0139},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {431-458},
  shortjournal = {Math. Oper. Res.},
  title        = {A policy gradient algorithm for the risk-sensitive exponential cost MDP},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parametric semidefinite programming: Geometry of the trajectory of solutions. <em>MOOR</em>, <em>50</em>(1), 410-430. (<a href='https://doi.org/10.1287/moor.2021.0097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many applications, solutions of convex optimization problems are updated on-line, as functions of time. In this paper, we consider parametric semidefinite programs, which are linear optimization problems in the semidefinite cone whose coefficients (input data) depend on a time parameter . We are interested in the geometry of the solution (output data) trajectory, defined as the set of solutions depending on the parameter . We propose an exhaustive description of the geometry of the solution trajectory. As our main result, we show that only six distinct behaviors can be observed at a neighborhood of a given point along the solution trajectory. Each possible behavior is then illustrated by an example. Funding: This work was supported by OP RDE [Grant CZ.02.1.01/0.0/0.0/16_019/0000765].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0097},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {410-430},
  shortjournal = {Math. Oper. Res.},
  title        = {Parametric semidefinite programming: Geometry of the trajectory of solutions},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the (Im-)Possibility of representing probability distributions as a difference of I.I.D. noise terms. <em>MOOR</em>, <em>50</em>(1), 390-409. (<a href='https://doi.org/10.1287/moor.2023.0081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A random variable is difference-form decomposable ( DFD ) if it may be written as the difference of two i.i.d. random terms. We show that densities of such variables exhibit a remarkable degree of structure. Specifically, a DFD density can be neither approximately uniform, nor quasiconvex, nor strictly concave. On the other hand, a DFD density need, in general, be neither unimodal nor logconcave. Regarding smoothness, we show that a compactly supported DFD density cannot be analytic and will often exhibit a kink even if its components are smooth. The analysis highlights the risks for model consistency resulting from the strategy widely adopted in the economics literature of imposing assumptions directly on a difference of noise terms rather than on its components.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0081},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {390-409},
  shortjournal = {Math. Oper. Res.},
  title        = {On the (Im-)Possibility of representing probability distributions as a difference of I.I.D. noise terms},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal consumption and investment with independent stochastic labor income. <em>MOOR</em>, <em>50</em>(1), 356-389. (<a href='https://doi.org/10.1287/moor.2023.0119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a new dynamic continuous-time model of optimal consumption and investment to include independent stochastic labor income. We reduce the problem of solving the Bellman equation to a problem of solving an integral equation. We then explicitly characterize the optimal consumption and investment strategy as a function of income-to-wealth ratio. We provide some analytical comparative statics associated with the value function and optimal strategies. We also develop a quite general numerical algorithm for control iteration and solve the Bellman equation as a sequence of solutions to ordinary differential equations. This numerical algorithm can be readily applied to many other optimal consumption and investment problems especially with extra nondiversifiable Brownian risks, resulting in nonlinear Bellman equations. Finally, our numerical analysis illustrates how the presence of stochastic labor income affects the optimal consumption and investment strategy. Funding: A. Bensoussan was supported by the National Science Foundation under grant [DMS-2204795]. S. Park was supported by the Ministry of Education of the Republic of Korea and the National Research Foundation of Korea, South Korea [NRF-2022S1A3A2A02089950].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0119},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {356-389},
  shortjournal = {Math. Oper. Res.},
  title        = {Optimal consumption and investment with independent stochastic labor income},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strongly convergent homogeneous approximations to inhomogeneous markov jump processes and applications. <em>MOOR</em>, <em>50</em>(1), 334-355. (<a href='https://doi.org/10.1287/moor.2022.0153'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of time-inhomogeneous Markov jump processes is a traditional topic within probability theory that has recently attracted substantial attention in various applications. However, their flexibility also incurs a substantial mathematical burden which is usually circumvented by using well-known generic distributional approximations or simulations. This article provides a novel approximation method that tailors the dynamics of a time-homogeneous Markov jump process to meet those of its time-inhomogeneous counterpart on an increasingly fine Poisson grid. Strong convergence of the processes in terms of the Skorokhod J 1 metric is established, and convergence rates are provided. Under traditional regularity assumptions, distributional convergence is established for unconditional proxies, to the same limit. Special attention is devoted to the case where the target process has one absorbing state and the remaining ones transient, for which the absorption times also converge. Some applications are outlined, such as univariate hazard-rate density estimation, ruin probabilities, and multivariate phase-type density evaluation. Funding: M. Bladt and O. Peralta would like to acknowledge financial support from the Swiss National Science Foundation Project 200021_191984. O. Peralta acknowledges financial support from NSF Award #1653354 and AXA Research Fund Award on “Mitigating risk in the wake of the pandemic”.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0153},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {334-355},
  shortjournal = {Math. Oper. Res.},
  title        = {Strongly convergent homogeneous approximations to inhomogeneous markov jump processes and applications},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk sharing with lambda value at risk. <em>MOOR</em>, <em>50</em>(1), 313-333. (<a href='https://doi.org/10.1287/moor.2023.0246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the risk-sharing problem among multiple agents using lambda value at risk ( Λ VaR ) as their preferences via the tool of inf-convolution, where Λ VaR is an extension of value at risk ( VaR ). We obtain explicit formulas of the inf-convolution of multiple Λ VaR with monotone Λ and explicit forms of the corresponding optimal allocations, extending the results of the inf-convolution of VaR . It turns out that the inf-convolution of several Λ VaR is still a Λ VaR under some mild condition. Moreover, we investigate the inf-convolution of one Λ VaR and a general monotone risk measure without cash additivity, including Λ VaR , expected utility, and rank-dependent expected utility as special cases. The expression of the inf-convolution and the explicit forms of the optimal allocation are derived, leading to some partial solution of the risk-sharing problem with multiple Λ VaR for general Λ functions. Finally, we discuss the risk-sharing problem with Λ VaR + , another definition of lambda value at risk. We focus on the inf-convolution of Λ VaR + and a risk measure that is consistent with the second-order stochastic dominance, deriving very different expression of the inf-convolution and the forms of the optimal allocations.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0246},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {313-333},
  shortjournal = {Math. Oper. Res.},
  title        = {Risk sharing with lambda value at risk},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variational inequalities on unbounded domains for zero-sum singular controller vs. stopper games. <em>MOOR</em>, <em>50</em>(1), 277-312. (<a href='https://doi.org/10.1287/moor.2023.0029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a class of zero-sum games between a singular controller and a stopper over a finite-time horizon. The underlying process is a multidimensional (locally nondegenerate) controlled stochastic differential equation (SDE) evolving in an unbounded domain. We prove that such games admit a value and provide an optimal strategy for the stopper. The value of the game is shown to be the maximal solution in a suitable Sobolev class of a variational inequality of min-max type with an obstacle constraint and a gradient constraint. Although the variational inequality and the game are solved on an unbounded domain, we do not require boundedness of either the coefficients of the controlled SDE or of the cost functions in the game. Funding: A. Bovo was partially supported by the Doctoral Studentship from the University of Leeds.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0029},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {277-312},
  shortjournal = {Math. Oper. Res.},
  title        = {Variational inequalities on unbounded domains for zero-sum singular controller vs. stopper games},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A characterization of simultaneous optimization, majorization, and (Bi-)Submodular polyhedra. <em>MOOR</em>, <em>50</em>(1), 252-276. (<a href='https://doi.org/10.1287/moor.2023.0054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by resource allocation problems (RAPs) in power management applications, we investigate the existence of solutions to optimization problems that simultaneously minimize the class of Schur-convex functions, also called least-majorized elements. For this, we introduce a generalization of majorization and least-majorized elements, called ( a , b )-majorization and least ( a , b )-majorized elements, and characterize the feasible sets of problems that have such elements in terms of base and (bi-)submodular polyhedra. Hereby, we also obtain new characterizations of these polyhedra that extend classical characterizations in terms of optimal greedy algorithms from the 1970s. We discuss the implications of our results for RAPs in power management applications and derive a new characterization of convex cooperative games and new properties of optimal estimators of specific regularized regression problems. In general, our results highlight the combinatorial nature of simultaneously optimizing solutions and provide a theoretical explanation for why such solutions generally do not exist.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0054},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {252-276},
  shortjournal = {Math. Oper. Res.},
  title        = {A characterization of simultaneous optimization, majorization, and (Bi-)Submodular polyhedra},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stationary points of a shallow neural network with quadratic activations and the global optimality of the gradient descent algorithm. <em>MOOR</em>, <em>50</em>(1), 209-251. (<a href='https://doi.org/10.1287/moor.2021.0082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of training a shallow neural network with quadratic activation functions and the generalization power of such trained networks. Assuming that the samples are generated by a full rank matrix W * of the hidden network node weights, we obtain the following results. We establish that all full-rank approximately stationary solutions of the risk minimization problem are also approximate global optimums of the risk (in-sample and population). As a consequence, we establish that, when trained on polynomially many samples, the gradient descent algorithm converges to the global optimum of the risk minimization problem regardless of the width of the network when it is initialized at some value ν * , which we compute. Furthermore, the network produced by the gradient descent has a near zero generalization error. Next, we establish that initializing the gradient descent algorithm below ν * is easily achieved when the weights of the ground truth matrix W * are randomly generated and the matrix is sufficiently overparameterized. Finally, we identify a simple necessary and sufficient geometric condition on the size of the training set under which any global minimizer of the empirical risk has necessarily zero generalization error. Funding: The research of E. C. Kizildag is supported by Columbia University, with the Distinguished Postdoctoral Fellowship in Statistics. Support from the National Science Foundation [Grant DMS-2015517] is gratefully acknowledged.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0082},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {209-251},
  shortjournal = {Math. Oper. Res.},
  title        = {Stationary points of a shallow neural network with quadratic activations and the global optimality of the gradient descent algorithm},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Submodular functions and perfect graphs. <em>MOOR</em>, <em>50</em>(1), 189-208. (<a href='https://doi.org/10.1287/moor.2021.0302'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We give a combinatorial polynomial-time algorithm to find a maximum weight independent set in perfect graphs of bounded degree that do not contain a prism or a hole of length four as an induced subgraph. An even pair in a graph is a pair of vertices all induced paths between which are even. An even set is a set of vertices every two of which are an even pair. We show that every perfect graph that does not contain a prism or a hole of length four as an induced subgraph has a balanced separator which is the union of a bounded number of even sets, where the bound depends only on the maximum degree of the graph. This allows us to solve the maximum weight independent set problem using the well-known submodular function minimization algorithm. Funding: This work was supported by the Engineering and Physical Sciences Research Council [Grant EP/V002813/1]; the National Science Foundation [Grants DMS-1763817, DMS-2120644, and DMS-2303251]; and Alexander von Humboldt-Stiftung.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0302},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {189-208},
  shortjournal = {Math. Oper. Res.},
  title        = {Submodular functions and perfect graphs},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fluctuation theory of continuous-time, skip-free downward markov chains with applications to branching processes with immigration. <em>MOOR</em>, <em>50</em>(1), 169-188. (<a href='https://doi.org/10.1287/moor.2022.0246'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a comprehensive methodology for the fluctuation theory of continuous-time, skip-free Markov chains, extending and improving the recent work of Choi and Patie for discrete-time, skip-free Markov chains. As a significant application, we use it to derive a full set of fluctuation identities regarding exiting a finite or infinite interval for Markov branching processes with immigration, thereby uncovering many new results for this classic family of continuous-time Markov chains. The theory also allows us to recover in a simple manner fluctuation identities for skip-free downward compound Poisson processes.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0246},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {169-188},
  shortjournal = {Math. Oper. Res.},
  title        = {Fluctuation theory of continuous-time, skip-free downward markov chains with applications to branching processes with immigration},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Alternating and parallel proximal gradient methods for nonsmooth, nonconvex minimax: A unified convergence analysis. <em>MOOR</em>, <em>50</em>(1), 141-168. (<a href='https://doi.org/10.1287/moor.2022.0294'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is growing interest in nonconvex minimax problems that is driven by an abundance of applications. Our focus is on nonsmooth, nonconvex-strongly concave minimax, thus departing from the more common weakly convex and smooth models assumed in the recent literature. We present proximal gradient schemes with either parallel or alternating steps. We show that both methods can be analyzed through a single scheme within a unified analysis that relies on expanding a general convergence mechanism used for analyzing nonconvex, nonsmooth optimization problems. In contrast to the current literature, which focuses on the complexity of obtaining nearly approximate stationary solutions, we prove subsequence convergence to a critical point of the primal objective and global convergence when the latter is semialgebraic. Furthermore, the complexity results we provide are with respect to approximate stationary solutions. Lastly, we expand the scope of problems that can be addressed by generalizing one of the steps with a Bregman proximal gradient update, and together with a few adjustments to the analysis, this allows us to extend the convergence and complexity results to this broader setting. Funding: The research of E. Cohen was partially supported by a doctoral fellowship from the Israel Science Foundation [Grant 2619-20] and Deutsche Forschungsgemeinschaft [Grant 800240]. The research of M. Teboulle was partially supported by the Israel Science Foundation [Grant 2619-20] and Deutsche Forschungsgemeinschaft [Grant 800240].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0294},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {141-168},
  shortjournal = {Math. Oper. Res.},
  title        = {Alternating and parallel proximal gradient methods for nonsmooth, nonconvex minimax: A unified convergence analysis},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scheduling in the high-uncertainty heavy traffic regime. <em>MOOR</em>, <em>50</em>(1), 107-140. (<a href='https://doi.org/10.1287/moor.2022.0100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a model uncertainty approach to heavy traffic asymptotics that allows for a high level of uncertainty. That is, the uncertainty classes of underlying distributions accommodate disturbances that are of order 1 at the usual diffusion scale as opposed to asymptotically vanishing disturbances studied previously in relation to heavy traffic. A main advantage of the approach is that the invariance principle underlying diffusion limits makes it possible to define uncertainty classes in terms of the first two moments only. The model we consider is a single-server queue with multiple job types. The problem is formulated as a zero sum stochastic game played between the system controller, who determines scheduling and attempts to minimize an expected linear holding cost, and an adversary, who dynamically controls the service time distributions of arriving jobs and attempts to maximize the cost. The heavy traffic asymptotics of the game are fully solved. It is shown that an asymptotically optimal policy for the system controller is to prioritize according to an index rule, and for the adversary, it is to select distributions based on the system’s current workload. The workload-to-distribution feedback mapping is determined by a Hamilton–Jacobi–Bellman equation, which also characterizes the game’s limit value. Unlike in the vast majority of results in the heavy traffic theory and as a direct consequence of the diffusive size disturbances, the limiting dynamics under asymptotically optimal play are captured by a stochastic differential equation where both the drift and the diffusion coefficients may be discontinuous. Funding: R. Atar is supported by the Israeli Science Foundation [Grant 1035/20].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0100},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {107-140},
  shortjournal = {Math. Oper. Res.},
  title        = {Scheduling in the high-uncertainty heavy traffic regime},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polynomial voting rules. <em>MOOR</em>, <em>50</em>(1), 90-106. (<a href='https://doi.org/10.1287/moor.2023.0080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and study a new class of polynomial voting rules for a general decentralized decision/consensus system, and more specifically for the proof-of-stake protocol. The main idea, inspired by the Penrose square-root law and the more recent quadratic voting rule, is to differentiate a voter’s voting power and the voter’s share (fraction of the total in the system). We show that, whereas voter shares form a martingale process that converges to a Dirichlet distribution, their voting powers follow a supermartingale process that decays to zero over time. This prevents any voter from controlling the voting process and, thus, enhances security. For both limiting results, we also provide explicit rates of convergence. When the initial total volume of votes (or stakes) is large, we show a phase transition in share stability (or the lack thereof), corresponding to the voter’s initial share relative to the total. We also study the scenario in which trading (of votes/stakes) among the voters is allowed and quantify the level of risk sensitivity (or risk aversion) in three categories, corresponding to the voter’s utility being a supermartingale, a submartingale, and a martingale. For each category, we identify the voter’s best strategy in terms of participation and trading. Funding: W. Tang gratefully acknowledges financial support through the National Science Foundation [Grants DMS-2113779 and DMS-2206038] and through a start-up grant at Columbia University. D. D. Yao’s work is part of a Columbia–City University/Hong Kong collaborative project that is supported by InnoHK Initiative, the Government of Hong Kong Special Administrative Region, and the Laboratory for AI-Powered Financial Technologies.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2023.0080},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {90-106},
  shortjournal = {Math. Oper. Res.},
  title        = {Polynomial voting rules},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flow allocation games. <em>MOOR</em>, <em>50</em>(1), 68-89. (<a href='https://doi.org/10.1287/moor.2022.0355'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a game-theoretic variant of the maximum circulation problem. In a flow allocation game , we are given a directed flow network. Each node is a rational agent and can strategically allocate any incoming flow to the outgoing edges. Given the strategy choices of all agents, a maximal circulation that adheres to the chosen allocation strategies evolves in the network. Each agent wants to maximize the amount of flow through his or her node. Flow allocation games can be used to express strategic incentives of clearing in financial networks. We provide a cumulative set of results on the existence and computational complexity of pure Nash and strong equilibria as well as tight bounds on the (strong) prices of anarchy and stability. Our results show an interesting dichotomy. Ranking strategies over individual flow units allows us to obtain optimal strong equilibria for many objective functions. In contrast, more intuitive ranking strategies over edges can give rise to unfavorable incentive properties. Funding: This work was supported by Deutsche Forschungsgemeinschaft Research Group ADYN [411362735].},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2022.0355},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {68-89},
  shortjournal = {Math. Oper. Res.},
  title        = {Flow allocation games},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards optimal problem dependent generalization error bounds in statistical learning theory. <em>MOOR</em>, <em>50</em>(1), 40-67. (<a href='https://doi.org/10.1287/moor.2021.0076'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study problem-dependent rates, that is, generalization errors that scale near-optimally with the variance, effective loss, or gradient norms evaluated at the “best hypothesis.” We introduce a principled framework dubbed “uniform localized convergence” and characterize sharp problem-dependent rates for central statistical learning problems. From a methodological viewpoint, our framework resolves several fundamental limitations of existing uniform convergence and localization analysis approaches. It also provides improvements and some level of unification in the study of localized complexities, one-sided uniform inequalities, and sample-based iterative algorithms. In the so-called “slow rate” regime, we provide the first (moment-penalized) estimator that achieves the optimal variance-dependent rate for general “rich” classes; we also establish an improved loss-dependent rate for standard empirical risk minimization. In the “fast rate” regime, we establish finite-sample, problem-dependent bounds that are comparable to precise asymptotics. In addition, we show that iterative algorithms such as gradient descent and first order expectation maximization can achieve optimal generalization error in several representative problems across the areas of nonconvex learning, stochastic optimization, and learning with missing data. Supplemental Material: The online appendix is available at https://doi.org/10.1287/moor.2021.0076 .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2021.0076},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {40-67},
  shortjournal = {Math. Oper. Res.},
  title        = {Towards optimal problem dependent generalization error bounds in statistical learning theory},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The online saddle point problem and online convex optimization with knapsacks. <em>MOOR</em>, <em>50</em>(1), 1-39. (<a href='https://doi.org/10.1287/moor.2018.0330'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the online saddle point problem, an online learning problem where at each iteration, a pair of actions needs to be chosen without knowledge of the current and future (convex-concave) payoff functions. The objective is to minimize the gap between the cumulative payoffs and the saddle point value of the aggregate payoff function, which we measure using a metric called saddle point regret (SP-Regret). The problem generalizes the online convex optimization framework, but here, we must ensure that both players incur cumulative payoffs close to that of the Nash equilibrium of the sum of the games. We propose an algorithm that achieves SP-Regret proportional to ln ( T ) T in the general case, and log ( T ) SP-Regret for the strongly convex-concave case. We also consider the special case where the payoff functions are bilinear and the decision sets are the probability simplex. In this setting, we are able to design algorithms that reduce the bounds on SP-Regret from a linear dependence in the dimension of the problem to a logarithmic one. We also study the problem under bandit feedback and provide an algorithm that achieves sublinear SP-Regret. We then consider an online convex optimization with knapsacks problem motivated by a wide variety of applications, such as dynamic pricing, auctions, and crowdsourcing. We relate this problem to the online saddle point problem and establish O ( T ) regret using a primal-dual algorithm.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2018.0330},
  journal      = {Mathematics of Operations Research},
  month        = {2},
  number       = {1},
  pages        = {1-39},
  shortjournal = {Math. Oper. Res.},
  title        = {The online saddle point problem and online convex optimization with knapsacks},
  volume       = {50},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
