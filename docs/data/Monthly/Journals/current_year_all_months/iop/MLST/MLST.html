<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MLST</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mlst">MLST - 258</h2>
<ul>
<li><details>
<summary>
(2025). A high-performance and portable implementation of the SISSO method for CPUs and GPUs. <em>MLST</em>, <em>6</em>(4), 047001. (<a href='https://doi.org/10.1088/2632-2153/ae0ab3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sure-independence screening and sparsifying operator (SISSO) is an artificial intelligence (AI) method based on symbolic regression and compressed sensing widely used in materials science research. SISSO++ is its C++ implementation that employs MPI and OpenMP for parallelization, rendering it well-suited for high-performance computing (HPC) environments. As heterogeneous hardware becomes mainstream in the HPC and AI fields, we chose to port the SISSO++ code to GPUs using the Kokkos performance-portable library. Kokkos allows us to maintain a single codebase for both Nvidia and AMD GPUs, significantly reducing the maintenance effort. In this work, we summarize the necessary code changes we did to achieve hardware and performance portability. This is accompanied by performance benchmarks on Nvidia and AMD GPUs. We demonstrate the speedups obtained from using GPUs across the three most time-consuming parts of our code.},
  archive      = {J_MLST},
  author       = {Sebastian Eibl and Yi Yao and Matthias Scheffler and Markus Rampp and Luca M Ghiringhelli and Thomas A R Purcell},
  doi          = {10.1088/2632-2153/ae0ab3},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {047001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A high-performance and portable implementation of the SISSO method for CPUs and GPUs},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Configuration interaction guided sampling with interpretable restricted boltzmann machine. <em>MLST</em>, <em>6</em>(4), 045013. (<a href='https://doi.org/10.1088/2632-2153/ae0fd5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a data-driven approach using a restricted Boltzmann machine (RBM) to solve the Schrödinger equation in configuration space. Traditional configuration interaction (CI) methods construct the wavefunction as a linear combination of Slater determinants, but this becomes computationally expensive due to the factorial growth in the number of configurations. Our approach extends the use of a generative model such as the RBM by incorporating a taboo list strategy to enhance efficiency and convergence. The RBM is used to efficiently identify and sample the most significant determinants, thus accelerating convergence and substantially reducing computational cost. This method achieves up to 99.99% of the correlation energy while using up to four orders of magnitude fewer determinants compared to full CI calculations and up to two orders of magnitude fewer than previous state of the art methods. Beyond efficiency, our analysis reveals that the RBM learns electron distributions over molecular orbitals by capturing quantum patterns that resemble radial distribution functions linked to molecular bonding. This suggests that the learned pattern is interpretable, highlighting the potential of machine learning for explainable quantum chemistry},
  archive      = {J_MLST},
  author       = {Jorge I Hernandez-Martinez and Andres Mendez-Vazquez and Gerardo Rodriguez-Hernandez and Sandra Leticia Juarez-Osorio},
  doi          = {10.1088/2632-2153/ae0fd5},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045013},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Configuration interaction guided sampling with interpretable restricted boltzmann machine},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SIGD: Symmetry and interface guided diffusion architectures for inverse design engineering of 2D semiconductor materials. <em>MLST</em>, <em>6</em>(4), 045012. (<a href='https://doi.org/10.1088/2632-2153/ae107e'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse design of materials (IDMs) has increasingly becoming an integral part of the manufacturing process. Despite significant advance in algorithmics for this task, it has still not yet achieved widespread acceptance, mainly due to a gap between the capabilities of current state-of-the-art algorithmics and the requirements of industry. For IDM to be truly useful for industrial use cases, it needs to be much more flexible and amenable to modifications stemming from specific material specifications and constraints. In this work, a symmetry and interface-guided diffusion model, a robust and intuitive diffusion generative framework, was introduced for target design of two-dimensional semiconductor structures. Our framework addresses the lack of robust and highly-controllable generative models in this important subfield of materials engineering, and provides a basis for a much more enlarged role of generative models in 2D semiconductor structures.},
  archive      = {J_MLST},
  author       = {Yuheng Chen and Qing An and Weihua Yang and Zhongyuan Lai and Yuhua Wen and Tundong Liu},
  doi          = {10.1088/2632-2153/ae107e},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045012},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {SIGD: Symmetry and interface guided diffusion architectures for inverse design engineering of 2D semiconductor materials},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Many-body dynamics with explicitly time-dependent neural quantum states. <em>MLST</em>, <em>6</em>(4), 045011. (<a href='https://doi.org/10.1088/2632-2153/ae0f39'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulating the dynamics of many-body quantum systems is a significant challenge, especially in higher dimensions where entanglement grows rapidly. Neural quantum states (NQS) offer a promising tool for representing quantum wavefunctions, but their application to time evolution faces scaling challenges. We introduce the time-dependent neural quantum state (t-NQS), a novel approach incorporating explicit time dependence into the neural network ansatz. This framework optimizes a single, time-independent set of parameters to solve the time-dependent Schrödinger equation across an entire time interval. We detail an autoregressive, attention-based transformer architecture and techniques for extending the model’s applicability. To benchmark and demonstrate our method, we simulate quench dynamics in the 2D transverse field Ising model and the time-dependent preparation of the 2D antiferromagnetic state in a Heisenberg model, demonstrating state of the art performance, scalability, and extrapolation to unseen intervals. These results establish t-NQS as a powerful framework for exploring quantum dynamics in strongly correlated systems.},
  archive      = {J_MLST},
  author       = {Anka Van de Walle and Markus Schmitt and Annabelle Bohrdt},
  doi          = {10.1088/2632-2153/ae0f39},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045011},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Many-body dynamics with explicitly time-dependent neural quantum states},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HPGe-compton net: A physics-guided CNN for fast gamma spectra analysis via compton region learning. <em>MLST</em>, <em>6</em>(4), 045010. (<a href='https://doi.org/10.1088/2632-2153/ae0f38'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-purity germanium (HPGe) detectors have been golden standard for gamma spectrometry in low-level radioactive waste (LLW) analysis; however, their notable shortcoming is prolonged measurement durations for weak radioactive waste materials. The present study aimed to develop the HPGe-Compton Net, a 1D physics-guided convolutional neural network to accelerate LLW analysis by taking advantage of the entire response function of a HPGe detector for each radionuclide of interest, in contrast to the traditional methods that analyze only peak regions of the response. This acceleration is supported by two core innovative strategies: (a) channel-prompt method, a feature enhancement incorporating additional physical information to guide the model to locate the designated radionuclide; (b) the specially designed database to achieve effective targeted feature learning. The performance evaluation carried out for test data set showed a five times reduction in measurement time compared to a conventional spectral analysis method while maintaining comparable precision. Compton perturbation tests confirmed the model’s ‘smart’ adaptive utilization of the Compton regions. The generalization testing of four LLW samples as the external validation set proved its superior performance in low-count data with an average accuracy of 90% over 83% of the traditional method. Future work will focus on upgrading the HPGe-Compton Net for practical applications.},
  archive      = {J_MLST},
  author       = {Yanfeng Xie and Yiming Weng and Soo Hyun Byun},
  doi          = {10.1088/2632-2153/ae0f38},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045010},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {HPGe-compton net: A physics-guided CNN for fast gamma spectra analysis via compton region learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-based prediction of microparticle dynamics in externally driven strongly-coupled dusty plasmas. <em>MLST</em>, <em>6</em>(4), 045009. (<a href='https://doi.org/10.1088/2632-2153/ae0c54'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We implemented unsupervised machine learning to study strongly coupled dusty plasmas with an emphasis on the dynamics of small plasma crystals rotated as a result of irradiation with a pulsed electron beam. By applying a combination of clustering algorithms such as K-means, DBSCAN, and Hierarchical clustering, along with statistical analysis, we classify the trajectories of microparticles in dust crystals levitated in the sheath of a radio-frequency plasma. This approach enables the identification of dynamic patterns and facilitates predictions based on initial conditions and system parameters. We trained the clustering algorithms to predict dust trajectories, identifying the most likely ones based on the hierarchical relationships between them and the Silhouette and Davies–Bouldin scores. Our results demonstrate the power of combining data science with experimental plasma physics to address challenges in manipulating levitated dust crystals. This predictive model serves as a versatile tool for advancing research in dusty plasma systems and enhances our ability to control dust dynamics in strongly-coupled dusty plasmas.},
  archive      = {J_MLST},
  author       = {Maria Luiza Mitu and Dorina Ticoş and Nicoleta Udrea and Adrian Scurtu and Cătălin Mihai Ticoş},
  doi          = {10.1088/2632-2153/ae0c54},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045009},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine learning-based prediction of microparticle dynamics in externally driven strongly-coupled dusty plasmas},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliability of deep learning models for scanning electron microscopy analysis. <em>MLST</em>, <em>6</em>(4), 045008. (<a href='https://doi.org/10.1088/2632-2153/ae0ab1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scanning electron microscopy (SEM) provides high-resolution nanoscale imaging crucial for advanced materials characterization. Recent advancements in deep learning have significantly enhanced SEM analysis by automating the identification of nanoscale features. However, the reliability of these models remains insufficiently explored. We investigate two popular deep learning architectures, ResNet-50 and Swin Transformer, by systematically injecting faults into their weight parameters for SEM characterization. Our analysis demonstrates how performance degrades under varying fault scenarios, and also pinpoints which layers and bit positions exhibit heightened vulnerability. These findings provide insights for dependable, high-throughput automated materials characterization, thereby paving the way for more reliable deployment of SEM-based deep learning in industrial and research environments.},
  archive      = {J_MLST},
  author       = {Chuen-Wun Pai and Hung-Wei Hsueh and Shu-Han Hsu},
  doi          = {10.1088/2632-2153/ae0ab1},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045008},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Reliability of deep learning models for scanning electron microscopy analysis},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty quantification in graph neural networks with shallow ensembles. <em>MLST</em>, <em>6</em>(4), 045007. (<a href='https://doi.org/10.1088/2632-2153/ae0bf0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine-learned potentials (MLPs) have revolutionized materials discovery by providing accurate and efficient predictions of molecular and material properties. Graph neural networks (GNNs) have emerged as a state-of-the-art approach due to their ability to capture complex atomic interactions. However, GNNs often produce unreliable predictions when encountering out-of-domain data and it is difficult to identify when that happens. To address this challenge, we explore uncertainty quantification (UQ) techniques, focusing on direct propagation of shallow ensembles (DPOSEs) as a computationally efficient alternative to deep ensembles. By integrating DPOSE into the SchNet model, we assess its ability to provide reliable uncertainty estimates across several density functional theory datasets, including QM9, OC20, and Gold dataset. Our findings often demonstrate that DPOSE successfully distinguishes between in-domain and out-of-domain samples, exhibiting higher uncertainty for unobserved molecule and material classes. This work highlights the potential of lightweight UQ methods in improving the robustness of GNN-based materials modeling and lays the foundation for future integration with active learning strategies.},
  archive      = {J_MLST},
  author       = {Tirtha Vinchurkar and Kareem Abdelmaqsoud and John R Kitchin},
  doi          = {10.1088/2632-2153/ae0bf0},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045007},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Uncertainty quantification in graph neural networks with shallow ensembles},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Super-resolving 3D nanostructures using artificially generated image data and spatial transport simulations. <em>MLST</em>, <em>6</em>(4), 045006. (<a href='https://doi.org/10.1088/2632-2153/ae0c55'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An approach for deploying stochastic three-dimensional (3D) models to generate microstructural 3D image data for training super-resolution networks is investigated for three different scaling factors \alpha\in\{2,4,8\} . The presented approach addresses the issue of scarcity in training data by training the networks only on artificial image data, generated by means of a stochastic 3D model that produces digital twins of the nanoporous inner structure of active particles in battery cathodes. In addition, the performance of super-resolution networks is investigated when complementing the input data, i.e. low-resolved microstructural 3D image data, with spatially resolved transport simulations. The performance of the trained networks is evaluated based on real tomographic image data, and quantified with respect to various geometric descriptors and effective transport properties. It turned out that the integration of transport simulations into the training of super-resolution networks showed an increase in performance for the scaling factors \alpha\in\{2,4\} , but a decrease in performance for α = 8. However, training the networks on artificial image data was effective in all cases.},
  archive      = {J_MLST},
  author       = {Orkun Furat and Phillip Gräfensteiner and Rishabh Saxena and Markus Osenberg and Matthias Neumann and Ingo Manke and Thomas Carraro and Volker Schmidt},
  doi          = {10.1088/2632-2153/ae0c55},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045006},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Super-resolving 3D nanostructures using artificially generated image data and spatial transport simulations},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling the power of multimodal large language models for radio astronomical image understanding and question answering. <em>MLST</em>, <em>6</em>(4), 045005. (<a href='https://doi.org/10.1088/2632-2153/ae0c56'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although multimodal large language models (MLLMs) have shown remarkable achievements across various scientific domains, their applications in radio astronomy remain largely unexplored. In this paper, we investigate the potential of MLLMs for image understanding and visual question answering (VQA) in radio astronomy. This can facilitate the use of MLLMs as AI assistants in both research and education by discerning and describing complex astronomical information in human-readable languages. However, general-purpose MLLMs show inferior performance in radio astronomy because they typically lack specialized knowledge. To bridge this gap, we construct a new VQA dataset, RadioAstroVQA, from open data repositories. Specifically, we transform data samples from different repositories into VQA examples by extracting questions based on task descriptions and observation reports associated with images and then composing their answers using ground-truth labels and captions. Furthermore, by leveraging the RadioAstroVQA dataset, we fine-tune two MLLMs of different parameter scales to specifically enhance their capacities for radio astronomical image classification and VQA tasks. Finally, we conduct extensive experiments to show that the fine-tuned MLLMs are capable of handling multiple types of radio astronomical images and generating customized textual output tailored to specific task needs. They achieve accuracy comparable to or even better than that of existing deep learning models for classification tasks. They also demonstrate significantly better performance on VQA tasks compared to several state-of-the-art MLLMs in general domains. These results confirm the potential of MLLMs to serve as specialized AI assistants in the field of radio astronomy.},
  archive      = {J_MLST},
  author       = {Fuyong Zhao and Yuyang Li and Zhenyu Liu and Panfeng Chen and Cunshi Wang and Jifeng Liu and Hui Li and Yanhao Wang},
  doi          = {10.1088/2632-2153/ae0c56},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045005},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Unveiling the power of multimodal large language models for radio astronomical image understanding and question answering},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-fidelity learning for atomistic models via trainable data embeddings. <em>MLST</em>, <em>6</em>(4), 045004. (<a href='https://doi.org/10.1088/2632-2153/ae0d41'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an approach for end-to-end training of machine learning models for structure-property modeling on collections of datasets derived using different density functional theory functionals and basis sets. This approach overcomes the problem of data inconsistencies in the training of machine learning models on atomistic data. We rephrase the underlying problem as a multi-task learning scenario. We show that conditioning neural network-based models on trainable embedding vectors can effectively account for quantitative differences between methods. This allows for joint training on multiple datasets that would otherwise be incompatible. Therefore, this procedure circumvents the need for re-computations at a unified level of theory. Numerical experiments demonstrate that training on multiple reference methods enables transfer learning between tasks, resulting in even lower errors compared to training on separate tasks alone. Furthermore, we show that this approach can be used for multi-fidelity learning, improving data efficiency for the highest fidelity by an order of magnitude. To test scalability, we train a single model on a joint dataset compiled from ten disjoint subsets of the MultiXC-QM9 dataset generated by different reference methods. Again, we observe transfer learning effects that improve the model errors by a factor of 2 compared to training on each subset alone. We extend our investigation to machine learning force fields for material simulations. To this end, we incorporate trainable embedding vectors into the readout layer of a deep graph neural network (M3GNet) that is simultaneously trained on PBE and r2SCAN labels of the MatPES dataset. We observe that joint training on both fidelity levels reduces the amount of r2SCAN data required to achieve the accuracy of a single-fidelity model by a factor of 10.},
  archive      = {J_MLST},
  author       = {Rick Oerder and Gerrit Schmieden and Jan Hamaekers},
  doi          = {10.1088/2632-2153/ae0d41},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045004},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Multi-fidelity learning for atomistic models via trainable data embeddings},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anti-correlated noise in epoch-based stochastic gradient descent: Implications for weight variances in flat directions. <em>MLST</em>, <em>6</em>(4), 045003. (<a href='https://doi.org/10.1088/2632-2153/ae0ab2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic gradient descent (SGD) has become a cornerstone of neural network optimization due to its computational efficiency and generalization capabilities. However, the gradient noise introduced by SGD is often assumed to be uncorrelated over time, despite the common practice of epoch-based training where data is sampled without replacement. In this work, we challenge this assumption and investigate the effects of epoch-based noise correlations on the stationary distribution of discrete-time SGD with momentum. Our main contributions are twofold: first, we calculate the exact autocorrelation of the noise during epoch-based training under the assumption that the noise is independent of small fluctuations in the weight vector, revealing that SGD noise is inherently anti-correlated over time. Second, we explore the influence of these anti-correlations on the variance of weight fluctuations. We find that for directions with curvature of the loss greater than a hyperparameter-dependent crossover value, the conventional predictions of isotropic weight variance under stationarity, based on uncorrelated and curvature-proportional noise, are recovered. Anti-correlations have negligible effect here. However, for relatively flat directions, the weight variance is significantly reduced, leading to a considerable decrease in loss fluctuations compared to the constant weight variance assumption. Furthermore, we present a numerical experiment where training with these anti-correlations enhances test performance, suggesting that the inherent noise structure induced by epoch-based training may play a role in finding flatter minima that generalize better.},
  archive      = {J_MLST},
  author       = {Marcel Kühn and Bernd Rosenow},
  doi          = {10.1088/2632-2153/ae0ab2},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045003},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Anti-correlated noise in epoch-based stochastic gradient descent: Implications for weight variances in flat directions},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum generative adversarial networks with dual generators. <em>MLST</em>, <em>6</em>(4), 045002. (<a href='https://doi.org/10.1088/2632-2153/ae0bf7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum generative adversarial networks (QGANs) have demonstrated strong capabilities in tasks like synthetic data generation and detecting anomalies. Recent developments have increasingly integrated traditional machine learning techniques to boost the performance of QGANs. Motivated by this progress, we propose an innovative QGAN architecture that incorporates a classical learning component and employs a dual-generator design. Our approach improves upon the traditional hybrid quantum–classical GAN structure and introduces a redesigned loss function tailored for the new model. Experiments on multiple datasets indicate that our method surpasses previous techniques in image generation quality, achieving a 1.38% average reduction in Fréchet inception distance scores compared to the current state-of-the-art, and improvements of 6.52%, 0.36%, and 0.38% in structural similarity index, cosine similarity, and peak signal-to-noise ratio metrics, respectively. Additionally, our architecture supports the generation of larger images (up to 78\,\times\,78 ), as verified on the CelebA dataset. Simulations conducted in noisy conditions further confirm the robustness and effectiveness of both the proposed architecture and loss function.},
  archive      = {J_MLST},
  author       = {Quangong Ma and Chaolong Hao and NianWen Si and Dan Qu},
  doi          = {10.1088/2632-2153/ae0bf7},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045002},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Quantum generative adversarial networks with dual generators},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tensor network for anomaly detection in the latent space of proton collision events at the LHC. <em>MLST</em>, <em>6</em>(4), 045001. (<a href='https://doi.org/10.1088/2632-2153/ae0243'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pursuit of discovering new phenomena at the Large Hadron Collider (LHC) requires constant innovation in algorithms and technologies. Tensor networks are mathematical models at the intersection of classical and quantum machine learning, which present a promising and efficient alternative for tackling these challenges. In this study, we propose a tensor network-based strategy for anomaly detection at the LHC and demonstrate its superior performance in identifying new phenomena compared to established quantum methods. Our model is a parameterized matrix product state with an isometric feature map, processing a latent representation of simulated LHC data generated by an autoencoder. Our results highlight the potential of tensor networks to enhance new-physics discovery.},
  archive      = {J_MLST},
  author       = {Ema Puljak and Maurizio Pierini and Artur Garcia-Saez},
  doi          = {10.1088/2632-2153/ae0243},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {045001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Tensor network for anomaly detection in the latent space of proton collision events at the LHC},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative models for fast simulation of cherenkov detectors at the electron–ion collider. <em>MLST</em>, <em>6</em>(4), 040501. (<a href='https://doi.org/10.1088/2632-2153/ae0f72'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of deep learning (DL) into experimental nuclear and particle physics has driven significant progress in simulation and reconstruction workflows. However, traditional simulation frameworks such as Geant4 remain computationally intensive, especially for Cherenkov detectors, where simulating optical photon transport through complex geometries and reflective surfaces introduces a major bottleneck. To address this, we present an open, standalone fast simulation tool for detection of internally reflected Cherenkov light (DIRC) detectors, with a focus on the high-performance DIRC at the future electron–ion collider. Our framework incorporates a suite of generative models tailored to accelerate particle identification (PID) tasks by offering a scalable, graphical processing unit-accelerated alternative to full Geant4 -based simulations. Designed with accessibility in mind, our simulation package enables both DL researchers and physicists to efficiently generate high-fidelity large-scale datasets on demand, without relying on complex traditional simulation stacks. This flexibility supports the development and benchmarking of novel DL-driven PID methods.},
  archive      = {J_MLST},
  author       = {J Giroux and M Martinez and C Fanelli},
  doi          = {10.1088/2632-2153/ae0f72},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {040501},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Generative models for fast simulation of cherenkov detectors at the electron–ion collider},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Perspective on artificial intelligence for accelerated materials design (AI4Mat) workshops in 2024. <em>MLST</em>, <em>6</em>(4), 040201. (<a href='https://doi.org/10.1088/2632-2153/ae0d5d'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intersection of artificial intelligence and materials science has become increasingly interconnected, driving ambitious research initiatives across both fields. Since 2022, the AI for accelerated materials design (AI4Mat) workshops have provided a leading venue for showcasing cutting-edge advances in this emerging interdisciplinary domain while fostering critical discussions about the most pressing scientific and technical challenges. In 2024, AI4Mat hosted workshops at BOKU University and NeurIPS 2024, attracting researchers and practitioners from academia, industry, and government institutions worldwide. These workshops explored diverse research areas currently shaping the field, with participants engaging in comprehensive discussions that addressed the intersection’s most significant challenges from scientific, technical, and commercial perspectives. Through this holistic approach, AI4Mat’s 2024 workshops successfully illuminated the multifaceted nature of AI-driven materials research, highlighting both current achievements and future opportunities in this rapidly evolving field. In this article, the AI4Mat-2024 organizing committee presents key insights from our workshops and community discussions, outlining critical challenges in this emerging field while summarizing the latest advances in AI-accelerated materials design. We examine persistent challenges around data creation and reproducibility, alongside the growing commercial interest in developing new markets and optimization materials production processes at scale. The article also highlights significant research breakthroughs showcased at AI4Mat, including the application of large language models to accelerate materials science tasks, the development of sophisticated generative models for materials discovery, and the growing demand for interpretable AI methodologies that provide transparent insights into materials behavior.},
  archive      = {J_MLST},
  author       = {Santiago Miret and Marta Skreta and Geemi Wellawatte and Stefano Martiniani and N M Anoop Krishnan and George Karypis and Kevin Maik Jablonka},
  doi          = {10.1088/2632-2153/ae0d5d},
  journal      = {Machine Learning: Science and Technology},
  month        = {10},
  number       = {4},
  pages        = {040201},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Perspective on artificial intelligence for accelerated materials design (AI4Mat) workshops in 2024},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-fidelity learning for interatomic potentials: Low-level forces and high-level energies are all you need*. <em>MLST</em>, <em>6</em>(3), 035066. (<a href='https://doi.org/10.1088/2632-2153/ae040b'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The promise of machine learning interatomic potentials (MLIPs) has led to an abundance of public quantum mechanical (QM) training datasets. The quality of an MLIP is directly limited by the accuracy of the energies and atomic forces in the training dataset. Unfortunately, most of these datasets are computed with relatively low-accuracy QM methods, e.g. density functional theory with a moderate basis set. Due to the increased computational cost of more accurate QM methods, e.g. coupled-cluster theory with a complete basis set (CBS) extrapolation, most high-accuracy datasets are much smaller and often do not contain atomic forces. The lack of high-accuracy atomic forces is quite troubling, as training with force data greatly improves the stability and quality of the MLIP compared to training to energy alone. Because most datasets are computed with a unique level of theory, traditional single-fidelity (SF) learning is not capable of leveraging the vast amounts of published QM data. In this study, we apply multi-fidelity learning (MFL) to train an MLIP to multiple QM datasets of different levels of accuracy, i.e. levels of fidelity. Specifically, we perform three test cases to demonstrate that MFL with both low-level forces and high-level energies yields an extremely accurate MLIP—far more accurate than a SF MLIP trained solely to high-level energies and almost as accurate as a SF MLIP trained directly to high-level energies and forces. Therefore, MFL greatly alleviates the need for generating large and expensive datasets containing high-accuracy atomic forces and allows for more effective training to existing high-accuracy energy-only datasets. Indeed, low-accuracy atomic forces and high-accuracy energies are all that are needed to achieve a high-accuracy MLIP with MFL.},
  archive      = {J_MLST},
  author       = {Mitchell Messerly and Sakib Matin and Alice E A Allen and Benjamin Nebgen and Kipton Barros and Justin S Smith and Nicholas Lubbers and Richard Messerly},
  doi          = {10.1088/2632-2153/ae040b},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035066},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Multi-fidelity learning for interatomic potentials: Low-level forces and high-level energies are all you need*},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IFE.PTML: Advancing neurotherapeutic nanoparticle release-system design for enhanced brain delivery. <em>MLST</em>, <em>6</em>(3), 035065. (<a href='https://doi.org/10.1088/2632-2153/ae038a'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurodegenerative diseases (NDDs) are a major global health concern, exacerbated by the blood–brain barrier (BBB), which limits effective drug delivery to the brain. Designing nanoparticles (NPs) to cross the BBB and deliver drugs could greatly improve the treatment of NDDs; however, current approaches to designing materials for drug delivery are generally slow. This study introduces an approach integrating information fusion, Python encoding, perturbation theory, and machine learning to predict the behaviour of NPs as drug delivery systems. Using an extensive pharmacokinetic database, random forest, extreme gradient boosting, and decision tree algorithms are trained and optimised. The random forest model achieves accuracies of 95.1% and 89.7% on training and testing data, respectively. As a proof of concept for the model’s utility, four novel Fe 3 O 4 NP systems are synthesised via thermal decomposition and functionalised for water solubility. Structural, morphological, and magnetic characterisations are performed. The ML model is then applied to these synthesised NPs, with predictions identifying PMAO-coated NPs as promising candidates for BBB and neuronal cell lines. This design framework offers significant advancements in the efficient identification of promising potential NP candidates for NDDs drug delivery, enabling predictions of desirable bioactivity profiles.},
  archive      = {J_MLST},
  author       = {Andrea Ruiz-Escudero and Maxim Belii and Karam Nader and Maite Insausti and Idoia Castellanos-Rubio and Sonia Arrasate and Matthew M Montemore and Humberto González-Díaz},
  doi          = {10.1088/2632-2153/ae038a},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035065},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {IFE.PTML: Advancing neurotherapeutic nanoparticle release-system design for enhanced brain delivery},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward machine learning interatomic potentials for modeling uranium mononitride. <em>MLST</em>, <em>6</em>(3), 035064. (<a href='https://doi.org/10.1088/2632-2153/ae0242'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uranium mononitride (UN) is a promising accident-tolerant fuel because of its high fissile density and high thermal conductivity. In this study, we developed the first machine learning interatomic potentials for reliable atomic-scale modeling of UN at finite temperatures. We constructed a training set using density functional theory (DFT) calculations that was enriched through an active learning procedure, and two neural network potentials were generated. Both potentials successfully reproduce key thermophysical properties of interest, such as temperature-dependent lattice parameter, specific heat capacity, and bulk modulus. We also evaluated the energy of stoichiometric defect reactions and defect migration barriers and found close agreement with DFT predictions, demonstrating that our potentials can be used for modeling defects in UN. Additional tests provide evidence that our potentials are reliable for simulating diffusion, noble gas impurities, and radiation damage.},
  archive      = {J_MLST},
  author       = {Lorena Alzate-Vargas and Kashi N Subedi and Nicholas Lubbers and Michael W D Cooper and Roxanne M Tutchton and Tammie Gibson and Richard A Messerly},
  doi          = {10.1088/2632-2153/ae0242},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035064},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Toward machine learning interatomic potentials for modeling uranium mononitride},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Does this smell the same? learning representations of olfactory mixtures using inductive biases. <em>MLST</em>, <em>6</em>(3), 035063. (<a href='https://doi.org/10.1088/2632-2153/adfffc'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Olfaction—how molecules are perceived as odors to humans—is a relatively less understood sensory system compared to vision or hearing. Recently, the principal odor map (POM) was introduced to digitize the olfactory properties of single compounds. However, smells in real life are not pure single molecules, but complex mixtures of molecules, whose representations remain relatively under-explored due to limited data in olfactory mixtures. We introduce POMMix , a mixture model extension of POM which leverages mono-molecular olfactory data to build meaningful mixture representations of smells. Our model builds upon the symmetries of the problem space in a hierarchical manner: (1) graph neural networks for building mono-molecular embeddings, (2) attention mechanisms for aggregating molecular representations into mixture representations, and (3) cosine prediction heads to encode olfactory perceptual distance in the mixture embedding space. POMMix achieves state-of-the-art performance across multiple datasets. We perform comprehensive ablation studies of the components of POMMix to understand the contribution of each component. We evaluate the generalizability of the model, explore olfactory phenomena with the representations, and analyze the interpretability of the representations. Our work advances the effort to digitize olfaction, highlighting the synergy of domain expertise and deep learning in crafting mixture representations in low-data regimes.},
  archive      = {J_MLST},
  author       = {Gary Tom and Cher Tian Ser and Ella M Rajaonson and Stanley Lo and Hyun Suk Park and Brian K Lee and Benjamin Sanchez-Lengeling},
  doi          = {10.1088/2632-2153/adfffc},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035063},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Does this smell the same? learning representations of olfactory mixtures using inductive biases},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven prediction of blood glucose dynamics from vagus nerve recordings using neural controlled differential equations. <em>MLST</em>, <em>6</em>(3), 035062. (<a href='https://doi.org/10.1088/2632-2153/ae023f'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting blood glucose dynamics is crucial for understanding metabolic regulation and advancing bioelectronic medicine. The vagus nerve (VN) plays a key role in glucose homeostasis, yet its real-time relationship with blood glucose fluctuations remains underexplored. We introduce neural controlled differential equations (NCDEs) as a novel data-driven approach for modelling the complex interaction between VN activity and blood glucose levels in rats. We utilise data collected from 12 rats including high-frequency neural recordings from single-channel microwire electrodes implanted around the left cervical VN, alongside capillary blood glucose measurements taken every 5 min. We compare the performance of the NCDE against traditional machine learning models–feed-forward neural networks (FFNNs), convolutional neural networks (CNNs) and gated recurrent units (GRUs)— for forecasting future blood glucose levels. The input features comprised the frequency and mean amplitude of detected VN spikes, combined with initial glucose concentration over the prediction window. Results demonstrate that NCDE significantly outperforms FFNNs, CNNs, and GRUs achieving a mean squared error (MSE) below 10%, compared to over 15% for the baseline models. Furthermore, replacing the real neural recordings with random noise led to a sharp increase in MSE (over 20%), confirming the ability of the NCDE in extracting meaningful neural signal information. These findings underscore the potential of NCDEs to enhance physiological time-series modelling, particularly for applications in bioelectronic medicine and precision neural signal decoding.},
  archive      = {J_MLST},
  author       = {Antonio Malpica-Morales and Serafim Kalliadasis and George G Malliaras and Amparo Güemes},
  doi          = {10.1088/2632-2153/ae023f},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035062},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Data-driven prediction of blood glucose dynamics from vagus nerve recordings using neural controlled differential equations},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum architecture search for optimizing quantum generators in quantum GAN. <em>MLST</em>, <em>6</em>(3), 035061. (<a href='https://doi.org/10.1088/2632-2153/ae056d'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As quantum computing continues to advance alongside machine learning, Quantum Generative Adversarial Networks (QGANs) have gained attention as a compelling generative modeling approach in quantum machine learning. Despite their potential, most existing QGAN implementations rely on manually designed quantum circuits, which often suffer from high complexity and limited scalability. To overcome these limitations, we propose a Quantum Architecture Search (QAS) method built upon the SuperCircuit framework. This approach enables the automatic discovery of efficient quantum circuit structures tailored for generative tasks, thereby reducing gate count. However, applying SuperCircuit-based QAS directly to QGANs presents two primary challenges: an expansive search space and a lack of guarantees regarding circuit efficiency. To mitigate these issues, we incorporate Principal Component Analysis (PCA) and a PCA-guided feature distribution mechanism during preprocessing. This strategy both compresses the search space and ensures balanced allocation of principal components across sub-generators. Extensive experiments confirm the viability of the proposed framework. When employing the discovered quantum circuits, QAS-QGAN achieves image quality comparable to a state-of-the-art (SOTA) baseline (Silver et al 2023 2023 IEEE/CVF Int. Conf. on Computer Vision (ICCV) pp 7007–16) on both the MNIST and Fashion MNIST datasets. Notably, our model reduces the number of two-qubit gates by 52.08% on MNIST and 52.92% on Fashion MNIST, highlighting substantial improvements in quantum resource efficiency. Furthermore, the model successfully generates high-resolution facial images ( 109 \times 89 ) on the CelebA dataset, demonstrating strong scalability and practical applicability.},
  archive      = {J_MLST},
  author       = {Quangong Ma and Chaolong Hao and NianWen Si and Dan Qu},
  doi          = {10.1088/2632-2153/ae056d},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035061},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Quantum architecture search for optimizing quantum generators in quantum GAN},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SPIKANs: Separable physics-informed Kolmogorov–Arnold networks. <em>MLST</em>, <em>6</em>(3), 035060. (<a href='https://doi.org/10.1088/2632-2153/ae05af'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-Informed Neural Networks (PINNs) have emerged as a promising method for solving partial differential equations (PDEs) in scientific computing. While PINNs typically use multilayer perceptrons (MLPs) as their underlying architecture, recent advancements have explored alternative neural network structures. One such innovation is the Kolmogorov–Arnold Network (KAN), which has demonstrated benefits over traditional MLPs, including faster neural scaling and better interpretability. The application of KANs to physics-informed learning has led to the development of Physics-Informed KANs (PIKANs), enabling the use of KANs to solve PDEs. However, despite their advantages, KANs often suffer from slower training speeds, particularly in higher-dimensional problems where the number of collocation points grows exponentially with the dimensionality of the system. To address this challenge, we introduce Separable Physics-Informed Kolmogorov–Arnold Networks (SPIKANs). This novel architecture applies the principle of separation of variables to PIKANs, decomposing the problem such that each dimension is handled by an individual KAN. This approach drastically reduces the computational complexity of training without sacrificing accuracy, facilitating their application to higher-dimensional PDEs. Through a series of benchmark problems, we demonstrate the effectiveness of SPIKANs, showcasing their superior scalability and performance compared to PIKANs and highlighting their potential for solving complex, high-dimensional PDEs in scientific computing.},
  archive      = {J_MLST},
  author       = {Bruno Jacob and Amanda A Howard and Panos Stinis},
  doi          = {10.1088/2632-2153/ae05af},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035060},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {SPIKANs: Separable physics-informed Kolmogorov–Arnold networks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-inspired self-learning framework for unsupervised depth estimation on non-lambertian surfaces. <em>MLST</em>, <em>6</em>(3), 035059. (<a href='https://doi.org/10.1088/2632-2153/ae054b'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of scene depth from monocular images has become crucial in fields such as spatial perception and computer vision. However, unsupervised depth estimation methods based on view synthesis often ignore the significant impact of non-Lambertian surfaces and ghosting artifacts. In this study, we propose a self-learning depth reconstruction framework. This framework introduces a depth consistency loss to compensate for the failure of the photometric assumption in non-Lambertian regions. Additionally, we design an intrinsic consistency loss that leverages variance as a game-theoretic strategy to ensure the robustness of our model. Finally, we introduce a physics-inspired ghosting mask to eliminate ghosting artifacts. We also design a multi-path transformer layer that integrates the Transformer’s global dependency modeling capability into CNNs, thereby enhancing the model’s performance. Experimental results show that our model demonstrates excellent performance in non-Lambertian regions. Compared with state-of-the-art methods that merely rely on the photometric assumption, our method achieves average improvements of 9.29% and 2.86% on the Sq Rel and RMSE metrics across three network models. Furthermore, it exhibits outstanding zero-shot generalization capability on external datasets. The source code is available at https://github.com/IkeFwd/Icdepth .},
  archive      = {J_MLST},
  author       = {Ke Li and Bolin Song and Naiyao Wang and Zhen Wang and Ruijie Tian},
  doi          = {10.1088/2632-2153/ae054b},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035059},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Physics-inspired self-learning framework for unsupervised depth estimation on non-lambertian surfaces},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). D–MOPH–25: Diverse MOF–molecule pairs for henry’s constants prediction*. <em>MLST</em>, <em>6</em>(3), 035058. (<a href='https://doi.org/10.1088/2632-2153/ae0241'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational methods like grand-canonical Monte Carlo simulations and machine learning (ML) have accelerated metal–organic frameworks (MOF) exploration but are typically limited to a narrow range of adsorbates due to data availability and force field constraints. In this study, we introduce a dataset of diverse MOF–molecule pairs for Henry’s constant prediction, D–MOPH–25, which systematically explores a diverse chemical space by combining 113 molecular adsorbates with over 5000 MOF structures through an active learning process. D–MOPH–25 constitutes the most diverse adsorbate dataset used in any ML study of molecular adsorption in MOFs to date. Our workflow builds a benchmark for predicting Henry’s constants at 300 K, leveraging conformal prediction for uncertainty quantification. Assessment through Shannon entropy and uniform manifold approximation and projection confirms the comprehensiveness of D–MOPH–25 while highlighting the importance of robust classification to filter out unphysical data points in regression tasks. Although future enhancements in model architecture and sampling criteria could improve predictive performance, our dataset already spans the target space using only 2.31% of total possibilities. This comprehensive dataset facilitates assessment of model generalizability across adsorbate species and can establish a foundation for high-throughput MOF screening and ML-driven separation processes.},
  archive      = {J_MLST},
  author       = {Sihoon Choi and David S Sholl and Andrew J Medford},
  doi          = {10.1088/2632-2153/ae0241},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035058},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {D–MOPH–25: Diverse MOF–molecule pairs for henry’s constants prediction*},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resolving turbulent magnetohydrodynamics: A hybrid operator-diffusion framework. <em>MLST</em>, <em>6</em>(3), 035057. (<a href='https://doi.org/10.1088/2632-2153/ae054c'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a hybrid machine learning framework that combines physics-informed neural operators (PINOs) with score-based generative diffusion models to simulate the full spatio-temporal evolution of two-dimensional, incompressible, resistive magnetohydrodynamic turbulence across a broad range of Reynolds numbers ( \mathrm{Re} ). The framework leverages the equation-constrained generalization capabilities of PINOs to predict coherent, low-frequency dynamics, while a conditional diffusion model stochastically corrects high-frequency residuals, enabling accurate modeling of fully developed turbulence. Trained on a comprehensive ensemble of high-fidelity simulations with \mathrm{Re} \in \{100, 250, 500, 750, 1000, 3000, 10\,000\} , the approach achieves state-of-the-art accuracy in regimes previously inaccessible to deterministic surrogates. At \mathrm{Re} = 1000 and 3000, the model faithfully reconstructs the full spectral energy distributions of both velocity and magnetic fields late into the simulation, capturing non-Gaussian statistics, intermittent structures, and cross-field correlations with high fidelity. At extreme turbulence levels ( \mathrm{Re} = 10\,000 ), it remains the first surrogate capable of recovering the high-wavenumber evolution of the magnetic field, preserving large-scale morphology and enabling statistically meaningful predictions.},
  archive      = {J_MLST},
  author       = {Semih Kacmaz and E A Huerta and Roland Haas},
  doi          = {10.1088/2632-2153/ae054c},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035057},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Resolving turbulent magnetohydrodynamics: A hybrid operator-diffusion framework},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modular post-hoc enhancements for zero-shot histopathology classification using vision-language models. <em>MLST</em>, <em>6</em>(3), 035056. (<a href='https://doi.org/10.1088/2632-2153/ae0557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning with vision-language models (VLMs) has shown promising results in histopathological image classification. However, existing approaches often under-utilize domain-specific adaptations that could enhance performance in specialized medical tasks. In this study, we systematically evaluate three modular, post-hoc enhancements to standard zero-shot VLM pipelines: (1) cosine similarity calibration for affinity matrix construction, (2) prompt template enhancement via diverse clinical prompts, and (3) adaptive hyperparameter tuning using a Gaussian mixture model-based method for adjusting pseudo-labeling weights ( λ ) and support set contributions ( γ ), following Zanella et al We conduct extensive zero-shot experiments on the NCT-CRC-HE-100 K dataset, using 60 000 patches for validation of inference-time hyperparameters and reserving 40 000 patches as an independent test set. No training or fine-tuning was performed. The evaluation was carried out across five VLMs: CLIP, CONCH, PLIP, Quilt-B16, and Quilt-B32. Results show that each enhancement module yields significant accuracy gains. Cosine calibration improves CLIP (+7.8%), CONCH (+1.53%), PLIP (+14.3%), Quilt-B16 (+16.1%), and Quilt-B32 (+11.4%). Prompt enhancement yields accuracy gains in PLIP (+16.8%) and Quilt-B32 (+29.9%), with limited effect on CLIP or CONCH. Adaptive tuning yields large improvements in PLIP (+28.4%). The best performance is achieved with the full combination of enhancements, with PLIP reaching 87.88% (+27.88%, p < 0.001) and Quilt-B32 reaching 88.38% (+36.1%) over their baselines. CLIP showed significance only with cosine calibration ( p < 0.001), reflecting its contrastive learning backbone. Although CONCH reached the highest raw accuracy (92.63%) under the full enhancement setting, this performance appears primarily driven by its histopathology-specific pretraining; statistically significant gains emerged only in cosine-based combinations, indicating limited responsiveness to prompt or tuning. Our findings highlight the critical role of structured modular enhancements in optimizing VLM performance for specialized clinical domains.},
  archive      = {J_MLST},
  author       = {Shahd M Noman and Mayar Tarek Henedak and Mustafa Elattar},
  doi          = {10.1088/2632-2153/ae0557},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035056},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Modular post-hoc enhancements for zero-shot histopathology classification using vision-language models},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-type point cloud autoencoder: A complete equivariant embedding for molecule conformation and pose. <em>MLST</em>, <em>6</em>(3), 035055. (<a href='https://doi.org/10.1088/2632-2153/adff35'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representations are a foundational component of any modeling protocol, including on molecules and molecular solids. For tasks that depend on knowledge of both molecular conformation and 3D orientation, such as the modeling of molecular dimers, clusters, or condensed phases, we desire a rotatable representation that is provably complete in the types and positions of atomic nuclei and roto-inversion equivariant with respect to the input point cloud. In this paper, we develop, train, and evaluate a new type of autoencoder, molecular O(3) encoding net (Mo3ENet), for multi-type point clouds, for which we propose a new reconstruction loss, capitalizing on a Gaussian mixture representation of the input and output point clouds. Mo3ENet is end-to-end equivariant, meaning the learned representation can be manipulated on O(3), a practical bonus. An appropriately trained Mo3ENet latent space comprises a universal embedding for scalar, vector, and tensorial molecule property prediction tasks, as well as other downstream tasks incorporating the 3D molecular pose, and we demonstrate its fitness on several such tasks.},
  archive      = {J_MLST},
  author       = {Michael Kilgour and Mark E Tuckerman and Jutta Rogal},
  doi          = {10.1088/2632-2153/adff35},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035055},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Multi-type point cloud autoencoder: A complete equivariant embedding for molecule conformation and pose},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deterministic versus stochastic dynamical classifiers: Opposing random adversarial attacks with noise. <em>MLST</em>, <em>6</em>(3), 035054. (<a href='https://doi.org/10.1088/2632-2153/ae0244'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continuous-variable firing rate (CVFR) model, widely used in neuroscience to describe the complex dynamics of excitatory biological neurons, is here trained and tested as a dynamical classifier. To this end the model is supplied with a set of attractors which are a priori embedded in the inter-node coupling matrix, via its spectral decomposition. Learning amounts to tuning the residual parameters, in order to shape a non-equilibrium path which bridges the input (the data to be classified) and the output (the target memory slot). The imposed attractors are unaltered by the training, and this enables for ex post comparisons to be eventually drawn, e.g. as it concerns the size of their associated basins of attraction. A stochastic variant of the CVFR model is also studied and found to be robust to non-targeted adversarial attacks, which corrupt with a random perturbation the items to be eventually classified. Taken as a whole, here we show that a family of biologically plausible models written in terms of coupled ODEs can efficiently cope with a non-trivial classification task.},
  archive      = {J_MLST},
  author       = {Lorenzo Chicchi and Duccio Fanelli and Diego Febbe and Lorenzo Buffoni and Francesca Di Patti and Lorenzo Giambagli and Raffaele Marino},
  doi          = {10.1088/2632-2153/ae0244},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035054},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Deterministic versus stochastic dynamical classifiers: Opposing random adversarial attacks with noise},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A frequentist simulation-based inference treatment of sterile neutrino global fits. <em>MLST</em>, <em>6</em>(3), 035053. (<a href='https://doi.org/10.1088/2632-2153/ae040c'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A critical challenge in particle physics is combining results from diverse experimental setups that measure the same physical quantity to enhance precision and statistical power, a process known as a global fit. Global fits of sterile neutrino searches, hunts for additional neutrino oscillation frequencies and amplitudes, present an intriguing case study. In such a scenario, the key assumptions underlying Wilks’ theorem, a cornerstone of most classic frequentist analyses, do not hold. The method of Feldman and Cousins, a trials-based approach which does not assume Wilks’ theorem, becomes computationally prohibitive for complex or intractable likelihoods. To bypass this limitation, we borrow a technique from simulation-based inference (SBI) to estimate likelihood ratios for use in building trials-based confidence intervals, speeding up test statistic evaluations by a factor \gt\!\!\!10^4 per grid point, resulting in a faster, but approximate, frequentist fitting framework. Applied to a subset of sterile neutrino search data involving the disappearance of muon-flavor (anti)neutrinos, our method leverages machine learning (ML) to compute frequentist confidence intervals while significantly reducing computational expense. In addition, the SBI-based approach holds additional value by recognizing underlying systematic uncertainties that the Wilks approach does not. Thus, our method allows for more robust ML-based analyses critical to performing accurate but computationally feasible global fits. This allows, for the first time, a global fit to sterile neutrino data without assuming Wilks’ theorem. While we demonstrate the utility of such a technique studying sterile neutrino searches, it is applicable to both single-experiment and global fits of all kinds.},
  archive      = {J_MLST},
  author       = {Joshua Villarreal and Julia Woodward and John M Hardin and Janet M Conrad},
  doi          = {10.1088/2632-2153/ae040c},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035053},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A frequentist simulation-based inference treatment of sterile neutrino global fits},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-$T_\mathrm c$ superconductor candidates proposed by machine learning. <em>MLST</em>, <em>6</em>(3), 035052. (<a href='https://doi.org/10.1088/2632-2153/ae04c1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We cast the relation between the chemical composition of a solid-state material and its superconducting critical temperature ( T_\mathrm c ) as a statistical learning problem with reduced complexity. Training of query-aware similarity-based ridge regression models on experimental SuperCon data achieves average T_\mathrm c prediction errors of ±5 K for unseen out-of-sample materials. Two models were trained with one excluding high pressure data in training (‘ambient’ model) and a second also including high pressure data (‘implicit’ model). Subsequent utilization of the approach to scan ∼153 k materials in the Materials Project enables the ranking of candidates by T_\mathrm c while accounting for thermodynamic stability and small band gap. The ambient model is used to predict stable top three high- T_\mathrm c candidate materials that include those with large band gaps of LiCuF 4 (316 K), Ag 2 H 12 S(NO) 4 (316 K), and Na 2 H 6 PtO 6 (315 K). Filtering these candidates for those with small band gaps correspondingly yields LiCuF 4 (316 K), Cu 2 P 2 O 7 (311 K), and Cu 3 P 2 H 2 O 9 (307 K).},
  archive      = {J_MLST},
  author       = {Siwoo Lee and Jason Hattrick-Simpers and Young-June Kim and O Anatole von Lilienfeld},
  doi          = {10.1088/2632-2153/ae04c1},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035052},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {High-$T_\mathrm c$ superconductor candidates proposed by machine learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal cascade feature transfer for polymer property prediction. <em>MLST</em>, <em>6</em>(3), 035051. (<a href='https://doi.org/10.1088/2632-2153/ae023e'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel transfer learning approach called multi-modal cascade model with feature transfer for polymer property prediction. Polymers are characterized by a composite of data in several different formats, including molecular descriptors and additive information as well as chemical structures. However, in conventional approaches, prediction models were often constructed using each type of data separately. Our model enables more accurate prediction of physical properties for polymers by combining features extracted from the chemical structure by graph convolutional neural networks with features such as molecular descriptors and additive information. The predictive performance of the proposed method is empirically evaluated using several polymer datasets. We report that the proposed method shows high predictive performance compared to the baseline conventional approach using a single feature.},
  archive      = {J_MLST},
  author       = {Kiichi Obuchi and Yuta Yahagi and Kiyohiko Toyama and Shukichi Tanaka and Kota Matsui},
  doi          = {10.1088/2632-2153/ae023e},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035051},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Multi-modal cascade feature transfer for polymer property prediction},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DINAMO: Dynamic and INterpretable anomaly MOnitoring for large-scale particle physics experiments. <em>MLST</em>, <em>6</em>(3), 035050. (<a href='https://doi.org/10.1088/2632-2153/ae0240'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring reliable data collection in large-scale particle physics experiments demands data quality monitoring (DQM) procedures to detect possible detector malfunctions and preserve data integrity. Traditionally, this resource-intensive task has been handled by human shifters who struggle with frequent changes in operational conditions. We present D ynamic and IN terpretable A nomaly MO nitoring: a novel, interpretable, robust, and scalable DQM framework designed to automate anomaly detection in time-dependent settings. Our approach constructs evolving histogram templates with built-in uncertainties, featuring both a statistical variant—extending the classical exponentially weighted moving average—and a machine learning-enhanced version that leverages a transformer encoder for improved adaptability. Experimental validations on synthetic datasets demonstrate the high accuracy, adaptability, and interpretability of these methods. The statistical variant is being commissioned in the LHCb experiment at the large hadron collider, underscoring its real-world impact.},
  archive      = {J_MLST},
  author       = {Arsenii Gavrikov and Julián García Pardiñas and Alberto Garfagnini},
  doi          = {10.1088/2632-2153/ae0240},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035050},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {DINAMO: Dynamic and INterpretable anomaly MOnitoring for large-scale particle physics experiments},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometric GNNs for charged particle tracking at GlueX. <em>MLST</em>, <em>6</em>(3), 035049. (<a href='https://doi.org/10.1088/2632-2153/ae02df'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nuclear physics experiments are aimed at uncovering the fundamental building blocks of matter. The experiments involve high-energy collisions that produce complex events with many particle trajectories. Tracking charged particles resulting from collisions in the presence of a strong magnetic field is critical to enable the reconstruction of particle trajectories and precise determination of interactions. It is traditionally achieved through combinatorial approaches that scale worse than linearly as the number of hits grows. Since particle hit data naturally form a point cloud and can be structured as graphs, graph neural networks (GNNs) emerge as an intuitive and effective choice for this task. In this study, we evaluate the GNN model for track finding on the data from the GlueX experiment at Jefferson Lab. We use simulation data to train the model and test on both simulation and real GlueX measurements. We demonstrate that GNN-based track finding outperforms the currently used traditional method at GlueX in terms of segment-based efficiency at a fixed purity while providing faster inferences. We show that the GNN model can achieve significant speedup by processing multiple events in batches, which exploits the parallel computation capability of graphical processing units (GPUs). Finally, we compare the GNN implementation on GPU and field-programmable gate array and describe the trade-off.},
  archive      = {J_MLST},
  author       = {Ahmed Hossam Mohammed and Kishansingh Rajput and Simon Taylor and Denis Furletov and Sergey Furletov and Malachi Schram},
  doi          = {10.1088/2632-2153/ae02df},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035049},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Geometric GNNs for charged particle tracking at GlueX},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guided graph compression for quantum graph neural networks. <em>MLST</em>, <em>6</em>(3), 035048. (<a href='https://doi.org/10.1088/2632-2153/adffe2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are effective for processing graph-structured data but face challenges with large graphs due to high memory requirements and inefficient sparse matrix operations on GPUs. Quantum computing offers a promising avenue to address these issues and inspires new algorithmic approaches. In particular, quantum GNNs (QGNNs) have been explored in recent literature. However, current quantum hardware limits the dimension of the data that can be effectively encoded. Existing approaches either simplify datasets manually or use artificial graph datasets. This work introduces the guided graph compression (GGC) framework, which uses a graph autoencoder to reduce both the number of nodes and the dimensionality of node features. The compression is guided to enhance the performance of a downstream classification task, which can be applied either with a quantum or a classical classifier. The framework is evaluated on the Jet Tagging task, a classification problem of fundamental importance in high energy physics that involves distinguishing particle jets initiated by quarks from those by gluons. We compare GGC to a model that uses the autoencoder as a preprocessing step and to a baseline classical GNN classifier. Our numerical results demonstrate that GGC outperforms both alternatives, while also facilitating the testing of novel QGNN ansatzes on realistic datasets.},
  archive      = {J_MLST},
  author       = {Mikel Casals and Vasilis Belis and Elias F Combarro and Eduard Alarcón and Sofia Vallecorsa and Michele Grossi},
  doi          = {10.1088/2632-2153/adffe2},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035048},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Guided graph compression for quantum graph neural networks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development and application of a high-dimensional neural network potential for boron carbide. <em>MLST</em>, <em>6</em>(3), 035047. (<a href='https://doi.org/10.1088/2632-2153/adfffd'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A high-dimensional neural network potential (HDNNP) is developed to accurately model the potential energy surface of boron carbide. The HDNNP is trained on an extensive dataset of structures generated using a Monte Carlo algorithm, covering a wide range of stoichiometries and structural configurations. Density functional theory (DFT) calculations provided energy and atomic force data, which were encoded using atom-centered symmetry functions to capture local atomic environments. The resulting HDNNP exhibits exceptional predictive performance, accurately estimating energies and forces across diverse structural configurations of boron carbide. The model effectively captures essential structural, energetic, and mechanical properties, including elastic behavior and the influence of stoichiometry on stability. The HDNNP development followed an iterative refinement strategy, in which the initial training set was systematically expanded to 2931 structures by incorporating finite-temperature AIMD snapshots at 300 K, 600 K, and 1000 K, as well as extrapolative configurations from MD simulations and defect-containing cells. This approach resulted in an HDNNP model that is numerically stable and physically consistent up to 500 K, with only minor drift observed at 600 K. The HDNNP achieves exceptional accuracy in predicting energies, forces, and mechanical properties across temperatures, reproducing Young’s modulus values of 416 GPa at 10 K and 420\pm20 GPa at 300 K, in close agreement with DFT and experimental ranges. The predicted ultimate tensile strength of 43 GPa at a failure strain of 0.14 at 300 K is consistent with atomistic simulations (40.23 GPa, strain 0.12). Comparative MD simulations show that the HDNNP outperforms Tersoff and ReaxFF in both accuracy and computational efficiency, enabling timesteps up to an order of magnitude larger, achieving 43% faster performance than Tersoff and 79% faster than ReaxFF. These results highlight the HDNNP as a robust and efficient tool for simulating boron carbide across a range of temperatures and deformation conditions, offering quantum-level accuracy for large-scale atomistic modeling in extreme environments.},
  archive      = {J_MLST},
  author       = {Sara Sheikhi and Wylie Stroberg and James D Hogan},
  doi          = {10.1088/2632-2153/adfffd},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035047},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Development and application of a high-dimensional neural network potential for boron carbide},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel quintile multi-model ensemble approach for improving future extreme precipitation projections using XGBoost. <em>MLST</em>, <em>6</em>(3), 035046. (<a href='https://doi.org/10.1088/2632-2153/adfcb1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel quintile multi-model ensemble (QMME) framework is introduced to improve future precipitation projections from MMEs. The QMME method divides daily precipitation into five quintiles, thereby capturing not only extreme rainfall but also the full spectrum of precipitation intensities. This approach surpasses conventional ensembles, such as the equal MME (EMME) and the weighted MME (WMME), in accurately reflecting the distinct characteristics of individual climate models. To develop the QMME, this study first applies empirical quantile mapping to correct biases in daily precipitation outputs from 14 coupled model intercomparison project 6 (CMIP6) general circulation models (GCMs). Historical observations (1980–2014) from 61-gauge stations in South Korea are then used to evaluate GCM performance within each quintile. The QMME framework integrates each GCM’s historical performance and future uncertainty into a quintile-specific weights and combines them with XGBoost to generate enhanced precipitation time series. Four shared socioeconomic pathway (SSP) scenarios (SSP1-2.6, SSP2-4.5, SSP3-7.0, and SSP5-8.5) are considered to assess a range of future scenarios. As a result, the QMME consistently outperforms both EMME and WMME in capturing both extreme precipitation events and moderate rainfall conditions. An evaluation using reliability ensemble averaging confirms that the QMME more effectively accounts for inter-model variability and reduces uncertainty, thus providing robust projections of future precipitation. This quintile-based methodology can be readily extended to other hydroclimatic variables and geographic regions, offering significant potential for improving climate impact assessments and guiding risk management in water resources planning.},
  archive      = {J_MLST},
  author       = {Young Hoon Song and Mohamed Sanusi Shiru and Eun-Sung Chung},
  doi          = {10.1088/2632-2153/adfcb1},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035046},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A novel quintile multi-model ensemble approach for improving future extreme precipitation projections using XGBoost},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning and interpreting gravitational-wave features from CNNs with a random forest approach. <em>MLST</em>, <em>6</em>(3), 035045. (<a href='https://doi.org/10.1088/2632-2153/adfc27'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have attracted increasing attention in gravitational wave (GW) data analysis due to their ability to automatically learn hierarchical features from raw strain data. However, the physical meaning of these learned features remains underexplored, limiting the interpretability of such models. In this work, we propose a hybrid architecture that combines a CNN-based feature extractor with a random forest (RF) classifier to improve both detection performance and interpretability. Unlike prior approaches that directly connect classifiers to CNN outputs, our method introduces four physically interpretable metrics-variance, signal-to-noise ratio (SNR), waveform overlap, and peak amplitude-computed from the final convolutional layer. These are jointly used with the CNN output probability in the RF classifier to enable more informed decision boundaries. Tested on long-duration strain datasets, our hybrid model outperforms a baseline-CNN model, achieving a relative improvement of 21% in sensitivity at a fixed false alarm rate of 10 events per month. Notably, it also shows improved detection of low-SNR signals (SNR \unicode{x2A7D} 10), which are especially vulnerable to misclassification in noisy environments. Feature importance analysis and ablation studies reveal that handcrafted features play a significant role in classification decisions and contribute to improved performance. These findings suggest that physically motivated post-processing of CNN feature maps can serve as a valuable tool for interpretable and efficient GW detection, bridging the gap between deep learning and domain knowledge.},
  archive      = {J_MLST},
  author       = {Jun Tian and He Wang and Jibo He and Yu Pan and Shuo Cao and Qingquan Jiang},
  doi          = {10.1088/2632-2153/adfc27},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035045},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Learning and interpreting gravitational-wave features from CNNs with a random forest approach},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerating reaction rate predictions: A machine learning approach using a novel quantum chemical property for nucleophilic aromatic substitutions. <em>MLST</em>, <em>6</em>(3), 035044. (<a href='https://doi.org/10.1088/2632-2153/adfd37'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting reaction rate coefficients is crucial for various chemical engineering tasks, such as kinetic modeling and drug synthesis planning. Traditional methods like group additivity and rate rules have limitations, prompting the exploration of machine learning methods to predict these coefficients. These machine learning models are often combined with quantum chemical calculations to improve their performance. While often accurate, these approaches slow down predictions due to the need for quantum chemical calculations, particularly for transition states. This study addresses the issue by introducing a quantum chemical property that does not require transition state calculations but still correlates well with the rate coefficient. We further enhance the prediction speed by training a machine learning model to predict this property. Finally, we propose two approaches using this machine learning model to predict the rate coefficients of nucleophilic aromatic substitution reactions in fractions of a second.},
  archive      = {J_MLST},
  author       = {Lowie Tomme and István Lengyel and Florence H Vermeire and Christian V Stevens and Kevin M Van Geem},
  doi          = {10.1088/2632-2153/adfd37},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {035044},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Accelerating reaction rate predictions: A machine learning approach using a novel quantum chemical property for nucleophilic aromatic substitutions},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 32 examples of LLM applications in materials science and chemistry: Towards automation, assistants, agents, and accelerated scientific discovery. <em>MLST</em>, <em>6</em>(3), 030701. (<a href='https://doi.org/10.1088/2632-2153/ae011a'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) are reshaping many aspects of materials science and chemistry research, enabling advances in molecular property prediction, materials design, scientific automation, knowledge extraction, and more. Recent developments demonstrate that the latest class of models are able to integrate structured and unstructured data, assist in hypothesis generation, and streamline research workflows. To explore the frontier of LLM capabilities across the research lifecycle, we review applications of LLMs through 32 total projects developed during the second annual LLM hackathon for applications in materials science and chemistry, a global hybrid event. These projects spanned seven key research areas: (1) molecular and material property prediction, (2) molecular and material design, (3) automation and novel interfaces, (4) scientific communication and education, (5) research data management and automation, (6) hypothesis generation and evaluation, and (7) knowledge extraction and reasoning from the scientific literature. Collectively, these applications illustrate how LLMs serve as versatile predictive models, platforms for rapid prototyping of domain-specific tools, and much more. In particular, improvements in both open source and proprietary LLM performance through the addition of reasoning, additional training data, and new techniques have expanded effectiveness, particularly in low-data environments and interdisciplinary research. As LLMs continue to improve, their integration into scientific workflows presents both new opportunities and new challenges, requiring ongoing exploration, continued refinement, and further research to address reliability, interpretability, and reproducibility.},
  archive      = {J_MLST},
  author       = {Yoel Zimmermann and Adib Bazgir and Alexander Al-Feghali and Mehrad Ansari and Joshua Bocarsly and L Catherine Brinson and Yuan Chiang and Defne Circi and Min-Hsueh Chiu and Nathan Daelman and Matthew L Evans and Abhijeet S Gangan and Janine George and Hassan Harb and Ghazal Khalighinejad and Sartaaj Takrim Khan and Sascha Klawohn and Magdalena Lederbauer and Soroush Mahjoubi and Bernadette Mohr and Seyed Mohamad Moosavi and Aakash Naik and Aleyna Beste Ozhan and Dieter Plessers and Aritra Roy and Fabian Schöppach and Philippe Schwaller and Carla Terboven and Katharina Ueltzen and Yue Wu and Shang Zhu and Jan Janssen and Calvin Li and Ian Foster and Ben Blaiszik},
  doi          = {10.1088/2632-2153/ae011a},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {030701},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {32 examples of LLM applications in materials science and chemistry: Towards automation, assistants, agents, and accelerated scientific discovery},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Theoretical physics benchmark (TPBench)—a dataset and study of AI reasoning capabilities in theoretical physics. <em>MLST</em>, <em>6</em>(3), 030505. (<a href='https://doi.org/10.1088/2632-2153/adfcb0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a benchmark to evaluate the capability of AI to solve problems in theoretical physics (TP), focusing on high-energy theory and cosmology. The first iteration of our benchmark consists of 57 problems of varying difficulty, from undergraduate to research level. These problems are novel in the sense that they do not come from public problem collections. We evaluate our data set on various open and closed language models, including o3-mini, o1, DeepSeek-R1, GPT-4o and versions of Llama and Qwen. While we find impressive progress in model performance with the most recent models, our research-level difficulty problems are mostly unsolved. We address challenges of auto-verifiability and grading, and discuss common failure modes. While currently state-of-the art models are still of limited use for researchers, our results show that AI assisted TP research may become possible in the near future. We discuss the main obstacles towards this goal and possible strategies to overcome them. The public problems and solutions, results for various models, and updates to the data set and score distribution, are available on the website of the dataset tpbench.org .},
  archive      = {J_MLST},
  author       = {Daniel J H Chung and Zhiqi Gao and Yurii Kvasiuk and Tianyi Li and Moritz Münchmeyer and Maja Rudolph and Frederic Sala and Sai Chaitanya Tadepalli},
  doi          = {10.1088/2632-2153/adfcb0},
  journal      = {Machine Learning: Science and Technology},
  month        = {9},
  number       = {3},
  pages        = {030505},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Theoretical physics benchmark (TPBench)—a dataset and study of AI reasoning capabilities in theoretical physics},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heart disease prediction by tabular modeling with deep learning network and interpretability. <em>MLST</em>, <em>6</em>(3), 035043. (<a href='https://doi.org/10.1088/2632-2153/adfd39'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular disease remains one of the most prevalent causes of mortality globally, underscoring the critical necessity for precise predictive models for early detection and intervention. Despite the proven potential of machine learning (ML), including deep learning (DL) models and convolutional neural networks (CNNs), in healthcare, their application to structured tabular datasets for heart disease prediction remains limited. Existing models often lack interpretability, which hinders their application in clinical settings, where understanding the decision-making process is vital. In response to this, our study proposes an innovative CNN-based predictive model for heart disease utilizing tabular modeling techniques and incorporating an interpretability tool such as SHapley Additive exPlanations (SHAP). The aim was to enhance both predictive accuracy and model transparency, empowering clinicians to comprehend and trust the model’s decisions. The methodology included data preprocessing, designing a CNN architecture tailored for tabular data, and integrating SHAP. The results showed superior predictive performance compared with the baseline models, with 98.54% accuracy, 97.14% sensitivity, 100% specificity, and SHAP, providing valuable insights into feature importance. This research advances heart disease prediction by harnessing the adaptability of CNNs to structured tabular datasets, while addressing the critical need for model interpretability in healthcare applications.},
  archive      = {J_MLST},
  author       = {Mohammad H Alshayeji and Sa’ed Abed},
  doi          = {10.1088/2632-2153/adfd39},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035043},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Heart disease prediction by tabular modeling with deep learning network and interpretability},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A data-lean machine learning approach for damage extent estimation and classification in composite structures under multiple failure modes. <em>MLST</em>, <em>6</em>(3), 035042. (<a href='https://doi.org/10.1088/2632-2153/adfb20'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the critical challenge of performing accurate structural diagnostics in composite structures under data-scarce and sensor-limited conditions, a known limitation in many existing structural health monitoring (SHM) frameworks. We propose a novel, data-lean simulation–machine learning (ML) approach that integrates high-fidelity numerical modeling with lightweight ML algorithms for simultaneous damage extent estimation and failure mode classification. A time domain spectral finite element model is developed, incorporating physically modeled piezoelectric actuators/sensors and mixed-order layerwise mechanics (both linear and nonlinear), to simulate the electromechanical behavior of composite laminates with multiple concurrent failure mechanisms, namely, fiber breakage, matrix cracking, and delamination. A wide range of representative damage scenarios is constructed, combining intra-laminar and inter-laminar failures distributed through the laminate thickness. These scenarios are simulated using a pitch-and-catch configuration, where a Gaussian pulse is actuated and responses are collected from three spatially distributed sensors. The resulting noisy dataset is used to train ML models for both regression (damage extent) and classification (failure mode), within a unified learning pipeline utilizing interpretable feature representations. The study also explores the impact of data representation strategies and evaluates model performance through cross-validation. Initial results demonstrate strong predictive capabilities, highlighting the potential of simulation-enhanced, ML-enabled SHM systems for robust diagnostics in complex composite structures, even under minimal data and instrumentation constraints.},
  archive      = {J_MLST},
  author       = {Dimitrios Iason Papadopoulos and George Giannakopoulos and Vangelis Karkaletsis and Christoforos Rekatsinas},
  doi          = {10.1088/2632-2153/adfb20},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035042},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A data-lean machine learning approach for damage extent estimation and classification in composite structures under multiple failure modes},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatiotemporal forecasting of the edge localized modes in tokamak plasmas using neural networks. <em>MLST</em>, <em>6</em>(3), 035041. (<a href='https://doi.org/10.1088/2632-2153/adfb41'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence techniques have been increasingly adopted by the plasma and fusion science to address problems like plasma reconstruction, surrogate modeling, and tokamak/stellarator optimization. A key focus in sustained fusion research is the prediction and mitigation of edge-localized-modes (ELMs), instabilities that occur in short, periodic bursts and can cause erosion to the tokamak vessel wall. Recent research has demonstrated the power of neural networks in approximating continuous functions. In this work, we build spatiotemporal forecasting models that can predict the onset of ELMs and their evolution at early stages. We leverage recent advances in generative modeling, sequence-to-sequence modeling, and Fourier neural operators to propose architectures and training strategies that can learn to forecast short to long term dynamics of the noisy signals due to ELMs. We benchmark the developed model against a state-of-the-art foundation model using the beam emission spectroscopy (BES) data that captures the plasma fluctuations due to ELMs over a 8\times 8 spatial grid. Our models demonstrate high accuracy, outperforming the baselines, in predicting the evolution of BES signals during ELM events. Furthermore, the developed models exhibit high accuracy in predicting the rapid rise and relaxation of the signals due to ELMs within 30–80 µ s.},
  archive      = {J_MLST},
  author       = {Anirban Samaddar and Qian Gong and Sandeep Madireddy and Christopher Hansen and Semin Joung and David R Smith and Yixuan Sun and Fatima Ebrahimi and Prasanna Balapraksh and Andrew Oakleigh Nelson},
  doi          = {10.1088/2632-2153/adfb41},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035041},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Spatiotemporal forecasting of the edge localized modes in tokamak plasmas using neural networks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty quantification from ensemble variance scaling laws in deep neural networks. <em>MLST</em>, <em>6</em>(3), 035040. (<a href='https://doi.org/10.1088/2632-2153/adf7fe'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantifying the uncertainty from machine learning analyses is critical to their use in the physical sciences. In this work we focus on uncertainty inherited from the initialization distribution of neural networks. We compute the mean \mu_{\mathcal{L}} and variance \sigma_{\mathcal{L}}^2 of the test loss \mathcal{L} for an ensemble of multi-layer perceptrons with neural tangent kernel initialization in the infinite-width limit, and compare empirically to the results from finite-width networks for three example tasks: MNIST classification, CIFAR classification and calorimeter energy regression. We observe scaling laws as a function of training set size N_\mathcal{D} for both \mu_{\mathcal{L}} and \sigma_{\mathcal{L}} , but find that the coefficient of variation \epsilon_{\mathcal{L}} \equiv \sigma_{\mathcal{L}}/\mu_{\mathcal{L}} becomes independent of N_\mathcal{D} at both infinite and finite width for sufficiently large N_\mathcal{D} . This implies that the coefficient of variation of a finite-width network may be approximated by its infinite-width value, and may in principle be calculable using finite-width perturbation theory.},
  archive      = {J_MLST},
  author       = {Ibrahim Elsharkawy and Benjamin Hooberman and Yonatan Kahn},
  doi          = {10.1088/2632-2153/adf7fe},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035040},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Uncertainty quantification from ensemble variance scaling laws in deep neural networks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A data driven approach to classify descriptors based on their efficiency in translating noisy trajectories into physically-relevant information. <em>MLST</em>, <em>6</em>(3), 035039. (<a href='https://doi.org/10.1088/2632-2153/adfa66'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing the physical complexity of many-body dynamical systems can be a hard task. Starting from the trajectories of their constitutive units (raw data), typical approaches require choosing adequate parameters/descriptors to convert them into time-series that are then analyzed to extract human-interpretable information. However, identifying the best descriptor is often far from being trivial. Here we report a data-driven approach that allows to compare the efficiency of different types of descriptors in extracting information from noisy trajectories and translating them into physically-relevant information. As a prototypical example of a system with non-trivial internal complexity, we analyze molecular dynamics trajectories of an atomistic model system where ice and water coexist dynamically in correspondence of the solid/liquid transition temperature. We compare different types of general or specific descriptors often used to study aqueous systems, e.g. number of neighbors, molecular velocities, smooth overlap of atomic positions (SOAP), local environments and neighbors shuffling (LENS), orientational tetrahedral order, and distance from the fifth neighbor ( d 5 ). We use Onion clustering (an efficient unsupervised clustering method for timeseries analysis) to assess the maximum amount of information that can be extracted from the noisy trajectories by the various descriptors, which we then rank via a high-dimensional metric. Our results demonstrate how advanced descriptors, such as SOAP and LENS, outperform classical ones thanks to higher signal-to-noise ratios. Nonetheless, even the simplest descriptor can become as efficient (and even more) as advanced ones upon local-denoising of their signal. This is the case of, e.g. d 5 , among the worst performing descriptors, which becomes following to denoising by far the best one in resolving the non-strictly-local dynamical complexity of such an ice/water system. This work highlights the critical role of noise in the process of information extraction and it offers a data-driven approach to identify optimal descriptors for systems with characteristic internal complexity.},
  archive      = {J_MLST},
  author       = {Simone Martino and Domiziano Doria and Chiara Lionello and Matteo Becchi and Giovanni M Pavan},
  doi          = {10.1088/2632-2153/adfa66},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035039},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A data driven approach to classify descriptors based on their efficiency in translating noisy trajectories into physically-relevant information},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multifidelity Kolmogorov–Arnold networks. <em>MLST</em>, <em>6</em>(3), 035038. (<a href='https://doi.org/10.1088/2632-2153/adf702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a method for multifidelity Kolmogorov–Arnold networks (KANs), which use a low-fidelity model along with a small amount of high-fidelity data to train a model for the high-fidelity data accurately. Multifidelity KANs (MFKANs) reduce the amount of expensive high-fidelity data needed to accurately train a KAN by exploiting the correlations between the low- and high-fidelity data to give accurate and robust predictions in the absence of a large high-fidelity dataset. In addition, we show that MFKANs can be used to increase the accuracy of physics-informed KANs, without the use of training data.},
  archive      = {J_MLST},
  author       = {Amanda A Howard and Bruno Jacob and Panos Stinis},
  doi          = {10.1088/2632-2153/adf702},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035038},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Multifidelity Kolmogorov–Arnold networks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-exit Kolmogorov–Arnold networks: Enhancing accuracy and parsimony. <em>MLST</em>, <em>6</em>(3), 035037. (<a href='https://doi.org/10.1088/2632-2153/adf9bd'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kolmogorov–Arnold networks (KANs) uniquely combine high accuracy with interpretability, making them valuable for scientific modeling. However, it is unclear a priori how deep a network needs to be for any given task, and deeper KANs can be difficult to optimize and interpret. Here we introduce multi-exit KANs, where each layer includes its own prediction branch, enabling the network to make accurate predictions at multiple depths simultaneously. This architecture provides deep supervision that improves training while discovering the right level of model complexity for each task. Multi-exit KANs consistently outperform standard, single-exit versions on synthetic functions, dynamical systems, and real-world datasets. Remarkably, the best predictions often come from earlier, simpler exits, revealing that these networks naturally identify smaller, more parsimonious and interpretable models without sacrificing accuracy. To automate this discovery, we develop a differentiable ‘learning-to-exit’ algorithm that balances contributions from exits during training. Our approach offers scientists a practical way to achieve both high performance and interpretability, addressing a fundamental challenge in machine learning for scientific discovery.},
  archive      = {J_MLST},
  author       = {James Bagrow and Josh Bongard},
  doi          = {10.1088/2632-2153/adf9bd},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035037},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Multi-exit Kolmogorov–Arnold networks: Enhancing accuracy and parsimony},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BiCrossNet: Resource-efficient cross-view geolocalization with binary neural networks. <em>MLST</em>, <em>6</em>(3), 035036. (<a href='https://doi.org/10.1088/2632-2153/adfa67'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents BiCrossNet, a novel approach to cross-view geolocalization utilizing binary neural networks to significantly reduce computational complexity while maintaining competitive performance. Key contributions include the development of a Bi-Gradual Unfreezing method to enhance transfer learning, a Bi-Partitioned Optimization strategy to improve training stability, and the use of logit-based knowledge distillation to supplement standard losses. Experimental results on the University-1652 and SUES-200 datasets demonstrate that BiCrossNet establishes a new benchmark in the efficiency-performance trade-off. It achieves up to a 90.87-fold reduction in operations and uses 4.64 times less disk space compared to similar-performing state-of-the-art models on the SUES-200 dataset, and a 30-fold reduction in operations and 5.13 times less disk space on the University-1652 dataset. The code is available at https://anonymous.4open.science/r/BiCrossNet-FB7A/README.md .},
  archive      = {J_MLST},
  author       = {Federico Fontana and Thomas Jantos and Jan Steinbrener and Luigi Cinque and Gian Luca Foresti and Bernhard Rinner},
  doi          = {10.1088/2632-2153/adfa67},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035036},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {BiCrossNet: Resource-efficient cross-view geolocalization with binary neural networks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A kinetic-based regularization method for data science applications. <em>MLST</em>, <em>6</em>(3), 035035. (<a href='https://doi.org/10.1088/2632-2153/adf93a'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a physics-based regularization technique for function learning, inspired by statistical mechanics. By drawing an analogy between optimizing the parameters of an interpolator and minimizing the energy of a system, we introduce corrections that impose constraints on the lower-order moments of the data distribution. This minimizes the discrepancy between the discrete and continuum representations of the data, in turn allowing to access more favorable energy landscapes, thus improving the accuracy of the interpolator. Our approach improves performance in both interpolation and regression tasks, even in high-dimensional spaces. Unlike traditional methods, it does not require empirical parameter tuning, making it particularly effective for handling noisy data. We also show that thanks to its local nature, the method offers computational and memory efficiency advantages over Radial Basis Function interpolators, especially for large datasets.},
  archive      = {J_MLST},
  author       = {Abhisek Ganguly and Alessandro Gabbana and Vybhav Rao and Sauro Succi and Santosh Ansumali},
  doi          = {10.1088/2632-2153/adf93a},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035035},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A kinetic-based regularization method for data science applications},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting the von neumann entanglement entropy using a graph neural network. <em>MLST</em>, <em>6</em>(3), 035034. (<a href='https://doi.org/10.1088/2632-2153/adf811'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Calculating the von Neumann entanglement entropy from experimental data is challenging due to its dependence on the complete wavefunction, forcing reliance on approximations such as classical mutual information (MI). We propose a machine learning approach using a graph neural network to predict the von Neumann entropy directly from experimentally accessible bitstrings. We test this approach on a Rydberg ladder system and achieve a mean absolute error of 3.6\,\times 10^{-3} when evaluating within the training range on a dataset with entropy values ranging from 0 to 1.9. The model achieves a mean absolute percentage error of 1.44% and outperforms MI-based bounds. When tested beyond the training range, the model maintains reasonable accuracy. Furthermore, we demonstrate that fine-tuning the model with small datasets significantly improves performance on data outside the original training range.},
  archive      = {J_MLST},
  author       = {Anas Saleh},
  doi          = {10.1088/2632-2153/adf811},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035034},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Predicting the von neumann entanglement entropy using a graph neural network},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics instrument design with reinforcement learning. <em>MLST</em>, <em>6</em>(3), 035033. (<a href='https://doi.org/10.1088/2632-2153/adf7ff'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a case for the use of reinforcement learning (RL) for the design of physics instruments as an alternative to gradient-based instrument-optimization methods. Its applicability is demonstrated using two empirical studies. One is longitudinal segmentation of calorimeters and the second is both transverse segmentation as well as longitudinal placement of trackers in a spectrometer. In both of the experiments, the RL agent found non-trivial designs which outperformed the baselines. Based on these experiments, we propose an alternative approach that offers unique advantages over differentiable programming and surrogate-based differentiable design optimization methods. First, RL algorithms possess inherent exploratory capabilities, which help mitigate the risk of convergence to local optima. Second, this approach eliminates the necessity of constraining the design to a predefined detector model with fixed parameters. Instead, it allows for the flexible placement of a variable number of detector components and facilitates discrete decision-making. We then discuss the road map of how this idea can be extended into designing very complex instruments. The presented study sets the stage for a novel framework in physics instrument design, offering a scalable and efficient framework that can be pivotal for future projects such as the future circular collider, where highly optimized detectors are essential for exploring physics at unprecedented energy scales.},
  archive      = {J_MLST},
  author       = {Shah Rukh Qasim and Patrick Owen and Nicola Serra},
  doi          = {10.1088/2632-2153/adf7ff},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035033},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Physics instrument design with reinforcement learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SIDDA: SInkhorn dynamic domain adaptation for image classification with equivariant neural networks. <em>MLST</em>, <em>6</em>(3), 035032. (<a href='https://doi.org/10.1088/2632-2153/adf701'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern neural networks (NNs) often do not generalize well in the presence of a ‘covariate shift’; that is, in situations where the training and test data distributions differ, but the conditional distribution of classification labels given the data remains unchanged. In such cases, NN generalization can be reduced to a problem of learning more robust, domain-invariant features. Domain adaptation (DA) methods include a broad range of techniques aimed at achieving this; however, these methods have struggled with the need for extensive hyperparameter tuning, which then incurs significant computational costs. In this work, we introduce SInkhorn Dynamic Domain Adaptation (SIDDA), an out-of-the-box DA training algorithm built upon the Sinkhorn divergence, that can achieve effective domain alignment with minimal hyperparameter tuning and computational overhead. We demonstrate the efficacy of our method on multiple simulated and real datasets of varying complexity, including simple shapes, handwritten digits, real astronomical observations, and remote sensing data. These datasets exhibit covariate shifts due to noise, blurring, differences between telescopes, and variations in imaging wavelengths. SIDDA is compatible with a variety of NN architectures, and it works particularly well in improving classification accuracy and model calibration when paired with symmetry-aware equivariant NNs (ENNs). We find that SIDDA consistently enhances the generalization capabilities of NNs, achieving up to a {\approx}40\% improvement in classification accuracy on unlabeled target data, while also providing a more modest performance gain of \lesssim 1\% on labeled source data. We also study the efficacy of DA on ENNs with respect to the varying group orders of the dihedral group D N , and find that the model performance improves as the degree of equivariance increases. Finally, if SIDDA achieves proper domain alignment, it also enhances model calibration on both source and target data, with the most significant gains in the unlabeled target domain—achieving over an order of magnitude improvement in the expected calibration error and Brier score. SIDDA’s versatility across various NN models and datasets, combined with its automated approach to domain alignment, has the potential to significantly advance multi-dataset studies by enabling the development of highly generalizable models.},
  archive      = {J_MLST},
  author       = {Sneh Pandya and Purvik Patel and Brian D Nord and Mike Walmsley and Aleksandra Ćiprijanović},
  doi          = {10.1088/2632-2153/adf701},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035032},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {SIDDA: SInkhorn dynamic domain adaptation for image classification with equivariant neural networks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conditional diffusion-flow models for generating 3D cosmic density fields: Applications to f(R) cosmologies. <em>MLST</em>, <em>6</em>(3), 035031. (<a href='https://doi.org/10.1088/2632-2153/adf8b1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next-generation galaxy surveys promise unprecedented precision in testing gravity at cosmological scales. However, realising this potential requires accurately modelling the non-linear cosmic web. We address this challenge by exploring conditional generative modelling to create 3D dark matter density fields via score-based (diffusion) and flow-based methods. Our results demonstrate the power of diffusion models to accurately reproduce the matter power spectra and bispectra, even for unseen configurations. They also offer a significant speed-up with slightly reduced accuracy, when flow-based reconstructing the probability distribution function, but they struggle with higher-order statistics. To improve conditional generation, we introduce a novel multi-output model to develop feature representations of the cosmological parameters. Our findings offer a powerful tool for exploring deviations from standard gravity, combining high precision with reduced computational cost, thus paving the way for more comprehensive and efficient cosmological analyses .},
  archive      = {J_MLST},
  author       = {Julieth K Riveros and Paola A Saavedra and Héctor J Hortúa and Jorge Enrique García-Farieta and Ivan Olier},
  doi          = {10.1088/2632-2153/adf8b1},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035031},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Conditional diffusion-flow models for generating 3D cosmic density fields: Applications to f(R) cosmologies},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the energy landscape of RBMs: Reciprocal space insights into bosons, hierarchical learning and symmetry breaking. <em>MLST</em>, <em>6</em>(3), 035030. (<a href='https://doi.org/10.1088/2632-2153/adf521'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep generative models have become ubiquitous due to their ability to learn and sample from complex distributions. Despite the proliferation of various frameworks, the relationships among these models remain largely unexplored, a gap that hinders the development of a unified theory of AI learning. In this work, we address two central challenges: clarifying the connections between different deep generative models and deepening our understanding of their learning mechanisms. We focus on Restricted Boltzmann Machines (RBMs), a class of generative models known for their universal approximation capabilities for discrete distributions. By introducing a reciprocal space formulation for RBMs, we reveal a connection between these models, diffusion processes, and systems of coupled bosons. Our analysis shows that at initialization, the RBM operates at a saddle point, where the local curvature is determined by the singular values of the weight matrix, whose distribution follows the Marc̆enko-Pastur law and exhibits rotational symmetry. During training, this rotational symmetry is broken due to hierarchical learning, where different degrees of freedom progressively capture features at multiple levels of abstraction. This leads to a symmetry breaking in the energy landscape, reminiscent of Landau’s theory. This symmetry breaking in the energy landscape is characterized by the singular values and the weight matrix eigenvector matrix. We derive the corresponding free energy in a mean-field approximation. We show that in the limit of infinite size RBM, the reciprocal variables are Gaussian distributed. Our findings indicate that in this regime, there will be some modes for which the diffusion process will not converge to the Boltzmann distribution. To illustrate our results, we trained replicas of RBMs with different hidden layer sizes using the MNIST dataset. Our findings not only bridge the gap between disparate generative frameworks but also shed light on the fundamental processes underpinning learning in deep generative models.},
  archive      = {J_MLST},
  author       = {J Quetzalcóatl Toledo-Marin and Anindita Maiti and Geoffrey C Fox and Roger G Melko},
  doi          = {10.1088/2632-2153/adf521},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035030},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Exploring the energy landscape of RBMs: Reciprocal space insights into bosons, hierarchical learning and symmetry breaking},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Symbolic approximations to ricci-flat metrics via extrinsic symmetries of Calabi–Yau hypersurfaces. <em>MLST</em>, <em>6</em>(3), 035029. (<a href='https://doi.org/10.1088/2632-2153/adf68c'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ever since Yau’s non-constructive existence proof of Ricci-flat metrics on Calabi–Yau (CY) manifolds, finding their explicit construction remains a major obstacle to development of both string theory and algebraic geometry. Recent computational approaches employ machine learning to create novel neural representations for approximating these metrics, offering high accuracy but limited interpretability. In this paper, we analyse machine learning approximations to flat metrics of Fermat CY n -folds and some of their one-parameter deformations in three dimensions in order to discover their new properties. We formalise cases in which the flat metric has more symmetries than the underlying manifold, and prove that these symmetries imply that the flat metric admits a surprisingly compact representation for certain choices of complex structure moduli. We show that such symmetries uniquely determine the flat metric on certain loci on the Fermat manifold, for which we present an analytic form. We also incorporate our theoretical results into neural networks to reduce Ricci curvature for multiple CY manifolds compared to previous machine learning approaches. We conclude with distilling the ML models to obtain closed form expressions for Kähler metrics with near-zero scalar curvature, discovering them directly from numerical data.},
  archive      = {J_MLST},
  author       = {Viktor Mirjanić and Challenger Mishra},
  doi          = {10.1088/2632-2153/adf68c},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035029},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Symbolic approximations to ricci-flat metrics via extrinsic symmetries of Calabi–Yau hypersurfaces},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive continuous-discrete variables optimization for active learning with extremely sparse data in optical material design. <em>MLST</em>, <em>6</em>(3), 035028. (<a href='https://doi.org/10.1088/2632-2153/adf68d'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing planar multilayer (PML) optical coatings remains challenging due to the vast parametric space and complex figure of merit requirements. This study introduces an adaptive thickness approach combined with active learning (i.e. an adaptive scheme) for concurrent material selection and thickness optimization, where thickness is adaptively sampled in a continuous spectrum, and material status is labeled as a discrete binary variable for flexible design exploration. In the adaptive scheme, we examine the performance of three machine learning (ML) models—Gaussian process regression, factorization machines (FM), and field-aware FM—for a surrogate function, and ML model-specific optimization algorithms such as discrete particle swarm optimization, artificial bee colony optimization, and simulated annealing. The optimal PML structure’s secondary criteria (e.g. total thickness, number of layers) are investigated and compared with the conventional fixed thickness approach (i.e. fixed scheme). As a benchmarking study, we optimize an ultrathin Ge-YF 3 antireflective PML coating on a high-index Si substrate using the adaptive scheme. It identified an optimal five-layer design with 0.47% average reflectance, requiring only ∼10% of the training data of the fixed scheme and 0.002% of total possible states, reducing computational costs and enhancing practical applicability. Furthermore, we confirmed the applicability of the adaptive scheme to extended design problems, including two-dimensional photonic structures and multilayer coatings composed of four materials.},
  archive      = {J_MLST},
  author       = {Serang Jung and Eungkyu Lee},
  doi          = {10.1088/2632-2153/adf68d},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035028},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Adaptive continuous-discrete variables optimization for active learning with extremely sparse data in optical material design},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature learning and generalization in deep networks with orthogonal weights. <em>MLST</em>, <em>6</em>(3), 035027. (<a href='https://doi.org/10.1088/2632-2153/adf278'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fully-connected deep neural networks with weights initialized from independent Gaussian distributions can be tuned to criticality, which prevents the exponential growth or decay of signals propagating through the network. However, such networks still exhibit fluctuations that grow linearly with the depth of the network, which may impair the training of networks with width comparable to depth. We show analytically that rectangular networks with tanh activations and weights initialized from the ensemble of orthogonal matrices have corresponding preactivation fluctuations which are independent of depth, to leading order in inverse width. Moreover, we demonstrate numerically that, at initialization, all correlators involving the neural tangent kernel (NTK) and its descendants at leading order in inverse width—which govern the evolution of observables during training—saturate at a depth of {\sim}20 , rather than growing without bound as in the case of Gaussian initializations. We speculate that this structure preserves finite-width feature learning while reducing overall noise, thus improving both generalization and training speed in deep networks with depth comparable to width. We provide some experimental justification by relating empirical measurements of the NTK to the superior performance of deep non-linear orthogonal networks trained under full-batch gradient descent on the MNIST and CIFAR-10 classification tasks.},
  archive      = {J_MLST},
  author       = {Hannah Day and Yonatan Kahn and Daniel A Roberts},
  doi          = {10.1088/2632-2153/adf278},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035027},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Feature learning and generalization in deep networks with orthogonal weights},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Photonic indistinguishability characterization and optimization for cavity-based single-photon source. <em>MLST</em>, <em>6</em>(3), 035026. (<a href='https://doi.org/10.1088/2632-2153/adf53c'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indistinguishability of single photons from independent sources is critically important for scalable quantum technologies. We provide a comprehensive comparison of single-photon indistinguishability of different kinds of cavity quantum electrodynamics (CQEDs) systems by numerically simulating Hong–Ou–Mandel two-photon interference. We find that the CQED system using natural atoms exhibits superiority in indistinguishability, benefiting from the inherently identical features. Moreover, a \Lambda- type three-level atom shows essential robustness against variation of various system parameters because it exploits the two ground states with considerably smaller decay rates for single-photon generation. Furthermore, a machine learning-based framework is proposed to significantly and robustly improve single-photon indistinguishability for two non-identical CQED systems. This work may pave the way for designing and engineering reliable and scalable photon-based quantum technologies.},
  archive      = {J_MLST},
  author       = {Miao Cai and Mingyuan Chen and Jiangshan Tang and Keyu Xia},
  doi          = {10.1088/2632-2153/adf53c},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035026},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Photonic indistinguishability characterization and optimization for cavity-based single-photon source},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast jet tagging with MLP-mixers on FPGAs. <em>MLST</em>, <em>6</em>(3), 035025. (<a href='https://doi.org/10.1088/2632-2153/adf596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore the innovative use of MLP-Mixer models for real-time jet tagging and establish their feasibility on resource-constrained hardware like FPGAs. MLP-Mixers excel in processing sequences of jet constituents, achieving state-of-the-art performance on datasets mimicking Large Hadron Collider conditions. By using advanced optimization techniques such as High-Granularity Quantization and Distributed Arithmetic, we achieve unprecedented efficiency. These models match or surpass the accuracy of previous architectures, reduce hardware resource usage by up to 97%, double the throughput, and half the latency. Additionally, non-permutation-invariant architectures enable smart feature prioritization and efficient FPGA deployment, setting a new benchmark for machine learning in real-time data processing at particle colliders.},
  archive      = {J_MLST},
  author       = {Chang Sun and Jennifer Ngadiuba and Maurizio Pierini and Maria Spiropulu},
  doi          = {10.1088/2632-2153/adf596},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035025},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Fast jet tagging with MLP-mixers on FPGAs},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimising entanglement distribution policies under classical communication constraints assisted by reinforcement learning. <em>MLST</em>, <em>6</em>(3), 035024. (<a href='https://doi.org/10.1088/2632-2153/adeefa'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum repeaters play a crucial role in the effective distribution of entanglement over long distances. The nearest-future type of quantum repeater requires two operations: entanglement generation across neighbouring repeaters and entanglement swapping to promote short-range entanglement to long-range. For many hardware setups, these actions are probabilistic, leading to longer distribution times and incurred errors. Significant efforts have been vested in finding the optimal entanglement-distribution policy, i.e. the protocol specifying when a network node needs to generate or swap entanglement, such that the expected time to distribute long-distance entanglement is minimal. This problem is even more intricate in more realistic scenarios, especially when classical communication delays are taken into account. In this work, we formulate our problem as a Markov decision problem and use reinforcement learning (RL) to optimise over centralised strategies, where one designated node instructs other nodes which actions to perform. Contrary to most RL models, ours can be readily interpreted. Additionally, we introduce and evaluate a fixed local policy, the ‘predictive swap-asap’ policy, where nodes only coordinate with nearest neighbours. Compared to the straightforward generalisation of the common swap-asap policy to the scenario with classical communication effects, the ‘wait-for-broadcast swap-asap’ policy, both of the aforementioned entanglement-delivery policies are faster at high success probabilities. Our work showcases the merit of considering policies acting with incomplete information in the realistic case when classical communication effects are significant.},
  archive      = {J_MLST},
  author       = {Jan Li and Tim Coopmans and Patrick Emonts and Kenneth Goodenough and Jordi Tura and Evert van Nieuwenburg},
  doi          = {10.1088/2632-2153/adeefa},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035024},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Optimising entanglement distribution policies under classical communication constraints assisted by reinforcement learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lattice protein folding with variational annealing. <em>MLST</em>, <em>6</em>(3), 035023. (<a href='https://doi.org/10.1088/2632-2153/adf376'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the principles of protein folding is a cornerstone of computational biology, with implications for drug design, bioengineering, and the understanding of fundamental biological processes. Lattice protein folding models offer a simplified yet powerful framework for studying the complexities of protein folding, enabling the exploration of energetically optimal folds under constrained conditions. However, finding these optimal folds is a computationally challenging combinatorial optimization problem. In this work, we introduce a novel upper-bound training scheme that employs masking to identify the lowest-energy folds in two-dimensional hydrophobic-polar lattice protein folding. By leveraging dilated recurrent neural networks (RNNs) integrated with an annealing process driven by temperature-like fluctuations, our method accurately predicts optimal folds for benchmark systems of up to 60 beads. Our approach also effectively masks invalid folds from being sampled without compromising the autoregressive sampling properties of RNNs. This scheme is generalizable to three spatial dimensions and can be extended to lattice protein models with larger alphabets. Our findings emphasize the potential of advanced machine learning techniques in tackling complex protein folding problems and a broader class of constrained combinatorial optimization challenges.},
  archive      = {J_MLST},
  author       = {Shoummo A Khandoker and Estelle M Inack and Mohamed Hibat-Allah},
  doi          = {10.1088/2632-2153/adf376},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035023},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Lattice protein folding with variational annealing},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A genetic algorithm to generate maximally orthogonal frames in complex space. <em>MLST</em>, <em>6</em>(3), 035022. (<a href='https://doi.org/10.1088/2632-2153/adf53d'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A frame is a generalization of a basis of a vector space to a redundant overspanning set whose vectors are linearly dependent. Frames find applications in signal processing and quantum information theory. We present a genetic algorithm that can generate maximally orthogonal frames (MOFs) of arbitrary size n in d -dimensional complex space. First, we formalize the concept of MOF and demonstrate that it depends on the choice of an energy function to weigh the different pairwise overlaps between vectors. Then, we discuss the relation between different energy functions and well-known frame varieties such as tight and Grassmannian frames and complex projective p -designs. Obtaining MOFs poses a global non-convex minimization problem. We discuss the relation with established numerical problems such as the Thomson problem and the problem of finding optimal packings in complex projective space. To tackle the minimization, we design a hybrid genetic algorithm that features local optimization of the parents. To assess the performance of the algorithm, we propose two visualization techniques that allow us to analyze the coherence and uniformity of high-dimensional frames. The genetic algorithm is able to produce highly-symmetric universal frames, such as equiangular tight frames, symmetric, informationally complete, positive operator-valued measurements and maximal sets of mutually unbiased bases, for configurations of up to d = 6 and n = 36, with runtimes of the order of several minutes on a regular desktop computer for the largest configurations.},
  archive      = {J_MLST},
  author       = {Sebastián Roca-Jerat and Juan Román-Roche},
  doi          = {10.1088/2632-2153/adf53d},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035022},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A genetic algorithm to generate maximally orthogonal frames in complex space},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collective variables of neural networks: Empirical time evolution and scaling laws. <em>MLST</em>, <em>6</em>(3), 035021. (<a href='https://doi.org/10.1088/2632-2153/adee76'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a novel framework for understanding learning dynamics and scaling relations in neural networks. We show that certain measures on the spectrum of the empirical neural tangent kernel (NTK), specifically entropy and trace, provide insight into the representations learned by a neural network and how these can be improved through architecture scaling. These results are demonstrated first on test cases before being applied to more complex networks, including transformers, auto-encoders, graph neural networks, and reinforcement learning studies. In testing on a wide range of architectures, we highlight the universal nature of training dynamics and further discuss how it can be used to understand the mechanisms behind learning in neural networks. We identify two such dominant mechanisms present throughout machine learning training. The first, information compression, is seen through a reduction in the entropy of the NTK spectrum during training, and occurs predominantly in small neural networks. The second, coined structure formation, is seen through an increasing entropy and thus, the creation of structure in the neural network representations beyond the prior established by the network at initialization. Due to the ubiquity of the latter in deep neural network architectures and its flexibility in the creation of feature-rich representations, we argue that this network entropy evolution be considered the onset of a deep learning regime.},
  archive      = {J_MLST},
  author       = {Samuel Tovey and Sven Krippendorf and Michael Spannowsky and Konstantin Nikolaou and Christian Holm},
  doi          = {10.1088/2632-2153/adee76},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035021},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Collective variables of neural networks: Empirical time evolution and scaling laws},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian model parameter learning in linear inverse problems: Application in EEG focal source imaging. <em>MLST</em>, <em>6</em>(3), 035020. (<a href='https://doi.org/10.1088/2632-2153/aded57'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse problems are often described as limited-data problems in which the signal of interest cannot be observed directly. Therefore, a physics-based forward model that relates the signal with the observations is typically needed. Unfortunately, unknown model parameters and imperfect forward models can still undermine the signal recovery. Even though supervised machine learning techniques offer promising avenues to improve the robustness of the solutions, we have to rely on model-based learning when there is no access to ground truth for the training. In this work, we studied a linear inverse problem that included an unknown non-linearly related model parameter and utilized a Bayesian model-based learning approach that allowed reliable signal recovery and subsequently estimation of the unknown model parameter. This approach, often referred to as Bayesian approximation error approach, employed a simplified model of the physics of the problem augmented with an approximation error term that compensated for the simplification. An error subspace was spanned with the help of the eigenvectors of the approximation error covariance matrix which allowed, alongside the primary signal, simultaneous estimation of the induced error. The estimated error and signal were then used to determine the unknown model parameter. For the model parameter estimation, we tested several different approaches: a conditional Gaussian regression, an iterative (model-based) optimization, and a Gaussian process that was modeled with the help of physics-informed learning. In addition, alternating optimization was used as a reference method. As an example application, we focused on the problem of reconstructing brain activity from EEG recordings (a.k.a. EEG source imaging) under the condition that the electrical conductivity of the patient’s skull was unknown in the model. Poorly selected conductivity values cause well-documented artifacts in the EEG source imaging results, and the determination of patient-specific head tissue conductivities is a significant technical problem. Our results demonstrated clear improvements in EEG source localization accuracy and provided feasible estimates for the unknown model parameter, skull conductivity.},
  archive      = {J_MLST},
  author       = {Alexandra Koulouri and Ville Rimpiläinen},
  doi          = {10.1088/2632-2153/aded57},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035020},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Bayesian model parameter learning in linear inverse problems: Application in EEG focal source imaging},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain-specific large language model for predicting band gap and formation energy of III-VIIIB and III-IVA nitrides based on fine-tuned GPT-3.5-turbo. <em>MLST</em>, <em>6</em>(3), 035019. (<a href='https://doi.org/10.1088/2632-2153/adf374'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The structure and electronic properties of nitrides have garnered significant research interest. To improve prediction efficiency and generalization ability, this study proposes an large language model (LLM) fine-tuning method trained by data with description of nitride crystal structure, obtaining textual data directly through automated workflow, bypassing the need for complex feature engineering. The outcomes demonstrate a notable enhancement in the prediction of material properties. With the GPT-3.5-turbo model fine-tuned, the \mathit{R}^{2} value went up from 0.6890 to 0.9868 and from 0.5119 to 0.9824. The fine-tuned GPT-3.5-turbo model outperforms GPT-3.5 and GPT-4.0 in terms of average prediction accuracy, with a 73.43 {\%} and 67.13 {\%} increase, respectively. Additionally, the generalizability of the model is checked by applying it to unknown nitrides. The average accuracy of the fine-tuned GPT-3.5-turbo model are 90.50 {\%} and 80.40 {\%} , compared with the results of the first principles calculation. These outcomes are on par with what shallow ML models achieve. The results of this work demonstrate that fine-tuned LLMs can serve as effective and generalizable tools for predicting the band gap ( {\mathit E_g} ) and formation energy ( \Delta{\textit{H}_\mathrm{f}} ) of III-VIIIB and III-IVA nitrides, thereby simplifying the prediction process and saving time.},
  archive      = {J_MLST},
  author       = {Lin Hu and Guozhu Jia},
  doi          = {10.1088/2632-2153/adf374},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035019},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Domain-specific large language model for predicting band gap and formation energy of III-VIIIB and III-IVA nitrides based on fine-tuned GPT-3.5-turbo},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An informativeness score for optimal mixed datasets using gaussian process regression. <em>MLST</em>, <em>6</em>(3), 035018. (<a href='https://doi.org/10.1088/2632-2153/adf2f5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For many systems composed of numerous subsystems, it is useful to have predictive models of the subsystems themselves. Gaussian process regression (GPR) is a machine learning technique which gives uncertainty in its predictions. The ability to calculate prediction uncertainty leads to the ability to calculate an optimally informative training data subset. Our previous work details a process for generating subsystem models with data from a shared source of system-level training data using GPR. In this study, we present a method for calculating an optimally informative dataset for numerous subsystem models. We then demonstrate our technique’s effectiveness using a mixture of non-expert produced whole-system data and expert produced subsystem-specific data. We show that regardless of dataset size, models made with a dataset selected according to our optimally whole-system informative criterion are more accurate than models made with arbitrarily included data or datasets optimized without a whole-system view. In many cases, using optimally informative data shared across all subsystem models lead to better accuracy than randomly selected datasets that are 50% larger.},
  archive      = {J_MLST},
  author       = {Cameron J LaMack and Eric M Schearer},
  doi          = {10.1088/2632-2153/adf2f5},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {035018},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {An informativeness score for optimal mixed datasets using gaussian process regression},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond euclid: An illustrated guide to modern machine learning with geometric, topological, and algebraic structures. <em>MLST</em>, <em>6</em>(3), 031002. (<a href='https://doi.org/10.1088/2632-2153/adf375'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The enduring legacy of Euclidean geometry underpins classical machine learning, which, for decades, has been primarily developed for data lying in Euclidean space. Yet, modern machine learning increasingly encounters richly structured data that is inherently non-Euclidean. This data can exhibit intricate geometric, topological and algebraic structure: from the geometry of the curvature of space-time, to topologically complex interactions between neurons in the brain, to the algebraic transformations describing symmetries of physical systems. Extracting knowledge from such non-Euclidean data necessitates a broader mathematical perspective. Echoing the 19th-century revolutions that gave rise to non-Euclidean geometry, an emerging line of research is redefining modern machine learning with non-Euclidean structures. Its goal: generalizing classical methods to unconventional data types with geometry, topology, and algebra. In this review, we provide an accessible gateway to this fast-growing field and propose a graphical taxonomy that integrates recent advances into an intuitive unified framework. We subsequently extract insights into current challenges and highlight exciting opportunities for future development in this field.},
  archive      = {J_MLST},
  author       = {Mathilde Papillon and Sophia Sanborn and Johan Mathe and Louisa Cornelis and Abby Bertics and Domas Buracas and Hansen J Lillemark and Christian Shewmake and Fatih Dinc and Xavier Pennec and Nina Miolane},
  doi          = {10.1088/2632-2153/adf375},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {031002},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Beyond euclid: An illustrated guide to modern machine learning with geometric, topological, and algebraic structures},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CrysMTM: A multiphase, temperature-resolved, multimodal dataset for crystalline materials. <em>MLST</em>, <em>6</em>(3), 030603. (<a href='https://doi.org/10.1088/2632-2153/adf9bc'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present CrysMTM, a large-scale, multimodal dataset designed to benchmark temperature- and phase-sensitive machine learning models for crystalline materials. The dataset comprises approximately 30 000 atomistic samples covering the three primary polymorphs of titanium dioxide–anatase, brookite, and rutile–each evaluated across a temperature spectrum ranging from cryogenic to ambient and elevated conditions. Each data entry integrates three complementary modalities: (1) three-dimensional atomic coordinates, (2) RGBA molecular visualizations, and (3) structured textual metadata encompassing geometric descriptors, local bonding environments, and phase transformation parameters. This multimodal structure enables both supervised and self-supervised learning across graph-based, image-based, and language-based architectures. CrysMTM supports rigorous evaluation of model robustness under thermal perturbations and crystallographic phase transitions. Baseline benchmarking across 18 models–including graph neural networks (GNNs), convolutional neural networks, and foundation models–reveals significant property-specific challenges. For example, bandgap predictions exhibit errors exceeding 25%, while volumetric expansion and atomic displacement estimations frequently deviate by more than 100%. Even state-of-the-art GNNs, which achieve an average in-distribution (ID) mean absolute percentage error of approximately 20%, show a threefold increase under out-of-distribution (OOD) thermal conditions. In contrast, a few-shot multimodal large language model reduces global prediction error from 96% to 23% and narrows the performance gap between ID and OOD cases to just four percentage points. These results highlight both the selective difficulty posed by temperature-sensitive geometric targets and the considerable room for innovation in model design. All dataset files, model implementations, and pretrained checkpoints are available at https://github.com/KurbanIntelligenceLab/CrysMTM .},
  archive      = {J_MLST},
  author       = {Can Polat and Erchin Serpedin and Mustafa Kurban and Hasan Kurban},
  doi          = {10.1088/2632-2153/adf9bc},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {030603},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {CrysMTM: A multiphase, temperature-resolved, multimodal dataset for crystalline materials},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Calculated solvation and ionization energies for thousands of organic molecules relevant to battery design. <em>MLST</em>, <em>6</em>(3), 030602. (<a href='https://doi.org/10.1088/2632-2153/adf595'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present high-quality reference data for two fundamentally important groups of molecular properties related to a compound’s utility as a lithium battery electrolyte. The first property is energy changes associated with charge excitations of molecules, namely ionization potential and electron affinity. They were estimated for 7000 randomly chosen molecules with up to 9 non-hydrogen atoms C, N, O, and F (QM9 dataset) using the DH-HF, DF-HF-CABS, PNO-LMP2-F12, and PNO-LCCSD(T)-F12 methods as implemented in the Molpro software, and the aug-cc-pVTZ basis set. Additionally, we provide the corresponding atomization energies at these levels of theory, as well as the CPU time and disk space used during the calculations. The second property is solvation energies for 39 different solvents, which we estimate for 18361 molecules connected to battery design (Electrolyte Genome Project dataset), 309463 randomly chosen molecules with up to 17 non-hydrogen atoms C, N, O, S, and halogens (GDB17 dataset), as well as 88418 atoms-in-molecules of the ZINC database of commercially available compounds and 37772 atoms-in-molecules of GDB17. For these calculations we used the COnductor-like Screening MOdel for Real Solvents (COSMO-RS) method; we additionally provide estimates of gas-phase atomization energies, as well as information about conformers considered during the COSMO-RS calculations, namely coordinates, energies, and dipole moments.},
  archive      = {J_MLST},
  author       = {Jan Weinreich and Konstantin Karandashev and Daniel Jose Arismendi Arrieta and Kersti Hermansson and O Anatole von Lilienfeld},
  doi          = {10.1088/2632-2153/adf595},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {030602},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Calculated solvation and ionization energies for thousands of organic molecules relevant to battery design},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Benchmarking universal machine learning interatomic potentials for rapid analysis of inelastic neutron scattering data*. <em>MLST</em>, <em>6</em>(3), 030504. (<a href='https://doi.org/10.1088/2632-2153/adfa68'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate calculation of phonons and vibrational spectra remains a significant challenge, requiring highly precise evaluations of interatomic forces. Traditional methods based on the quantum description of the electronic structure, while widely used, are computationally expensive and demand substantial expertise. Emerging universal machine learning interatomic potentials (uMLIPs) offer a transformative alternative by employing pre-trained neural network surrogates to predict interatomic forces directly from atomic coordinates. This approach dramatically reduces computation time and minimizes the need for technical knowledge. In this paper, we produce a phonon database comprising nearly 5000 inorganic crystals to benchmark the performance of several leading uMLIPs. We further assess these models in real-world applications by using them to analyze experimental inelastic neutron scattering data collected on a variety of materials. Through detailed comparisons, we identify the strengths and limitations of these uMLIPs, providing insights into their accuracy and suitability for fast calculations of phonons and related properties, as well as the potential for real-time interpretation of neutron scattering spectra. Our findings highlight how the rapid advancement of AI in science is revolutionizing experimental research and data analysis.},
  archive      = {J_MLST},
  author       = {Bowen Han and Yongqiang Cheng},
  doi          = {10.1088/2632-2153/adfa68},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {030504},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Benchmarking universal machine learning interatomic potentials for rapid analysis of inelastic neutron scattering data*},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discriminative versus generative approaches to simulation-based inference. <em>MLST</em>, <em>6</em>(3), 030503. (<a href='https://doi.org/10.1088/2632-2153/adf68b'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the fundamental, emergent, and phenomenological parameters of particle and nuclear physics are determined through parametric template fits. Simulations are used to populate histograms which are then matched to data. This approach is inherently lossy, since histograms are binned and low-dimensional. Deep learning has enabled unbinned and high-dimensional parameter estimation through neural likelihood(-ratio) estimation. We compare two approaches for neural simulation-based inference (NSBI): one based on discriminative learning (classification) and one based on generative modeling. These two approaches are directly evaluated on the same datasets, with a similar level of hyperparameter optimization in both cases. In addition to a Gaussian dataset, we study NSBI using a Higgs boson dataset from the FAIR Universe Challenge. We find that both the direct likelihood and likelihood ratio estimation are able to effectively extract parameters with reasonable uncertainties. For the numerical examples and within the set of hyperparameters studied, we found that the likelihood ratio method is more accurate and/or precise. Both methods have a significant spread from the network training and would require ensembling or other mitigation strategies in practice.},
  archive      = {J_MLST},
  author       = {Benjamin Sluijter and Sascha Diefenbacher and Wahid Bhimji and Benjamin Nachman},
  doi          = {10.1088/2632-2153/adf68b},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {030503},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Discriminative versus generative approaches to simulation-based inference},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BenchMake: Turn any scientific data set into a reproducible benchmark. <em>MLST</em>, <em>6</em>(3), 030502. (<a href='https://doi.org/10.1088/2632-2153/adf810'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benchmark data sets are a cornerstone of machine learning development and applications, ensuring new methods are robust, reliable and competitive. The relative rarity of benchmark sets in computational science, due to the uniqueness of the problems and the pace of change in the associated domains, makes evaluating new innovations difficult for computational scientists. In this paper a new tool is developed and tested to potentially turn any of the increasing numbers of scientific data sets made openly available into a benchmark accessible to the community. BenchMake uses non-negative matrix factorization to deterministically identify and isolate challenging edge cases on the convex hull (the smallest convex set that contains all existing data instances) and partitions a required fraction of matched data instances into a testing set that maximizes divergence and statistical significance, across tabular, graph, image, signal and textual modalities. BenchMake splits are compared to establish splits and random splits using ten publicly available benchmark sets from different areas of science, with different sizes, shapes, distributions.},
  archive      = {J_MLST},
  author       = {A S Barnard},
  doi          = {10.1088/2632-2153/adf810},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {030502},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {BenchMake: Turn any scientific data set into a reproducible benchmark},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing space sensor resilience with transfer learning in data-scarce scenarios. <em>MLST</em>, <em>6</em>(3), 03LT01. (<a href='https://doi.org/10.1088/2632-2153/adfd38'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Mars exploration missions, harsh environmental conditions, such as those generated by dust devils, can damage sensing systems. Soft sensors offer a promising solution in such scenarios, but their implementation is challenging when data is scarce. This paper explores the use of transfer learning (TL) to enhance sensor resilience, specifically addressing the issue of limited data availability. First, pre-trained models are developed using wind sensor data from the Temperature and Wind Sensors for the TWINS instrument (NASA InSight Mission), serving as the source domain for this study. These models account for the malfunction of a single wind sensing board or transducer. The pre-trained models are then adapted using TL to the Mars Environmental Dynamics Analyzer (MEDA) wind sensor (NASA Perseverance Mission), which shares common sensing principles, and which suffered a malfunction during the mission. Hyperparameter tuning further improves the performance of the TL models, yielding better results than models trained solely on a small MEDA dataset. The results demonstrate the effectiveness of the TL-based approach in recovering variables from the MEDA wind sensor despite partial failures and data limitations. Overall, the TL-based method improves performance by 10.21%–22.04% compared to models trained exclusively on the limited MEDA dataset.},
  archive      = {J_MLST},
  author       = {Dileep Kumar and Manuel Domínguez-Pumar and Beatriz Otero-Calviño and Joan Pons-Nin and Josefina Torres and Mercedes Marín and Javier Gómez-Elvira and Luis Mora and Sara Navarro and Jose Rodríguez-Manfredi},
  doi          = {10.1088/2632-2153/adfd38},
  journal      = {Machine Learning: Science and Technology},
  month        = {8},
  number       = {3},
  pages        = {03LT01},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Enhancing space sensor resilience with transfer learning in data-scarce scenarios},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variational autoencoders for at-source data reduction and anomaly detection in high energy particle detectors. <em>MLST</em>, <em>6</em>(3), 035017. (<a href='https://doi.org/10.1088/2632-2153/adf0c0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detectors in next-generation high-energy physics experiments face several daunting requirements, such as high data rates, damaging radiation exposure, and stringent constraints on power, space, and latency. To address these challenges, machine learning in readout electronics can be leveraged for smart detector designs, enabling intelligent inference and data reduction at-source. Variational autoencoders (VAEs) offer a variety of benefits for front-end readout; an on-sensor encoder can perform efficient lossy data compression while simultaneously providing a latent space representation that can be used for anomaly detection. Results are presented from low-latency and resource-efficient VAEs for front-end data processing in a futuristic silicon pixel detector. Encoder-based data compression is found to preserve good performance of off-detector analysis while significantly reducing the off-detector data rate as compared to a similarly sized data filtering approach. Furthermore, the latent space information is found to be a useful discriminator in the context of real-time sensor defect monitoring. Together, these results highlight the multifaceted utility of autoencoder-based front-end readout schemes and motivate their consideration in future detector designs.},
  archive      = {J_MLST},
  author       = {Alexander Yue and Haoyi Jia and Julia Gonski},
  doi          = {10.1088/2632-2153/adf0c0},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035017},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Variational autoencoders for at-source data reduction and anomaly detection in high energy particle detectors},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Architecture-aware minimization (A2M): How to find flat minima in neural architecture search. <em>MLST</em>, <em>6</em>(3), 035016. (<a href='https://doi.org/10.1088/2632-2153/adf02e'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural architecture search (NAS) has become an essential tool for designing effective and efficient neural networks. In this paper, we investigate the geometric properties of neural architecture spaces commonly used in differentiable NAS methods, specifically NAS-Bench-201 and differentiable architecture search (DARTS). By introducing notions of flatness in architecture space such as neighborhoods and accuracy barriers along paths, we reveal locality and flatness characteristics analogous to the well-known properties of neural network loss landscapes in weight space. In particular, we unveil the detailed geometrical structure of the architecture search landscape by uncovering the absence of barriers between well-performing architectures, finding that highly accurate architectures cluster together in flat regions, while suboptimal architectures instead remain isolated, showing higher values of the barriers. Building on these insights, we propose architecture-aware minimization (A 2 M), a novel analytically derived algorithmic framework that explicitly biases, for the first time, the gradient of differentiable NAS methods towards flat minima in architecture space . A 2 M consistently improves generalization over state-of-the-art DARTS-based algorithms on benchmark datasets including CIFAR-10, CIFAR-100, and ImageNet-16-120, across both NAS-Bench-201 and DARTS search spaces. Notably, A 2 M is able to increase the test accuracy, on average across different differentiable NAS methods, by +3.60% on CIFAR-10, +4.60% on CIFAR-100, and +3.64% on ImageNet-16-120 - while finding architectures with low accuracy barriers. A 2 M can be easily integrated into existing differentiable NAS frameworks, offering a versatile tool for future research and applications in automated machine learning. We will open-source our code at https://github.com/AI-Tech-Research-Lab/AsquaredM .},
  archive      = {J_MLST},
  author       = {Matteo Gambella and Fabrizio Pittorino and Manuel Roveri},
  doi          = {10.1088/2632-2153/adf02e},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035016},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Architecture-aware minimization (A2M): How to find flat minima in neural architecture search},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Training multi-layer binary neural networks with random local binary error signals. <em>MLST</em>, <em>6</em>(3), 035015. (<a href='https://doi.org/10.1088/2632-2153/adf0c1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary neural networks (BNNs) significantly reduce computational complexity and memory usage in machine and deep learning by representing weights and activations with just one bit. However, most existing training algorithms for BNNs rely on quantization-aware floating-point stochastic gradient descent (SGD), limiting the full exploitation of binary operations to the inference phase only. In this work, we propose, for the first time, a fully binary and gradient-free training algorithm for multi-layer BNNs, eliminating the need for back-propagated floating-point gradients. Specifically, the proposed algorithm relies on local binary error signals and binary weight updates, employing integer-valued hidden weights that serve as a synaptic metaplasticity mechanism, thereby enhancing its neurobiological plausibility. Our proposed solution enables the training of binary multi-layer perceptrons by using exclusively XNOR, Popcount, and increment/decrement operations. Experimental results on multi-class classification benchmarks show test accuracy improvements of up to +35.47% over the only existing fully binary single-layer state-of-the-art solution. Compared to full-precision SGD, our solution improves test accuracy by up to +35.30% under the same total memory demand, while also reducing computational cost by two to three orders of magnitude in terms of the total number of Boolean gates. The proposed algorithm is made available to the scientific community as a public repository.},
  archive      = {J_MLST},
  author       = {Luca Colombo and Fabrizio Pittorino and Manuel Roveri},
  doi          = {10.1088/2632-2153/adf0c1},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035015},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Training multi-layer binary neural networks with random local binary error signals},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stereological 3D modeling of nano-scale catalyst particles using TEM projections. <em>MLST</em>, <em>6</em>(3), 035014. (<a href='https://doi.org/10.1088/2632-2153/ade92d'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Catalysis, particularly heterogeneous catalysis, is crucial in the chemical industry and energy storage. Approximately 80% of all chemical products produced by heterogeneous catalysis are produced by solid catalysts, which are essential for the synthesis of ammonia, methanol, and hydrocarbons. Despite extensive use, challenges in catalyst development remain, including enhancing selectivity, stability, and activity. These effective properties are influenced by the nanoscale morphology of the catalysts, whereby the size of the nanoparticles is only one key descriptor. To investigate the relationship between nanoparticle morphology and catalytic performance, a comprehensive 3D analysis of nano-scale catalyst particles is necessary. However, traditional imaging techniques for a representative recording of this size range, such as transmission electron microscopy (TEM), are mostly limited to 2D. Thus, in the present paper, a stochastic 3D model is developed for a data-driven analysis of the nanostructure of catalyst particles. The calibration of this model is achieved using 2D TEM data from two different length scales, allowing for a statistically representative 3D modeling of catalyst particles. Furthermore, digital twins of catalyst particles can be drawn for the stochastic 3D model for virtual materials testing, enhancing the understanding of the relationship between catalyst nanostructure and performance.},
  archive      = {J_MLST},
  author       = {Lukas Fuchs and Kerstin Wein and Jens Friedland and Orkun Furat and Robert Güttel and Volker Schmidt},
  doi          = {10.1088/2632-2153/ade92d},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035014},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Stereological 3D modeling of nano-scale catalyst particles using TEM projections},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient solving of schrödinger equation using deep convolutional neural network model with an attention mechanism and transfer learning. <em>MLST</em>, <em>6</em>(3), 035013. (<a href='https://doi.org/10.1088/2632-2153/adeef9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have developed a deep convolutional neural network integrated with attention mechanisms to directly process two-dimensional stochastically constrained electrostatic potentials, and established an end-to-end mapping from electrostatic potentials to ground-state energy. Compared with existing methods, this model achieves superior median absolute error-with only 1/10 of the required data volume-and adopts a lightweight architecture to reduce parameter redundancy. Furthermore, we proposed a transfer learning strategy that uses the pre-trained model as a ‘large model’ and fine-tunes it using three specific potential functions: simple harmonic oscillator (ho), infinite well (iw), and double inverted negative Gaussian (ng). Experimental results demonstrate that the adapted ‘large model’ accurately predicts these specific potential functions, effectively addressing the common generalization limitations in neural network-based partial differential equation solutions. This approach establishes a novel paradigm integrating efficiency and high precision for multi-electron system calculations.},
  archive      = {J_MLST},
  author       = {Ziyi Zhao and Shishun Zhao and Mingjun Zhou and Yujun Yang},
  doi          = {10.1088/2632-2153/adeef9},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035013},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Efficient solving of schrödinger equation using deep convolutional neural network model with an attention mechanism and transfer learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mamba time series forecasting with uncertainty quantification. <em>MLST</em>, <em>6</em>(3), 035012. (<a href='https://doi.org/10.1088/2632-2153/adec3b'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State space models, such as Mamba, have recently garnered attention in time series forecasting (TSF) due to their ability to capture sequence patterns. However, in electricity consumption benchmarks, Mamba forecasts exhibit a mean error of approximately 8%. Similarly, in traffic occupancy benchmarks, the mean error reaches 18%. This discrepancy leaves us to wonder whether the prediction is simply inaccurate or falls within error given spread in historical data. To address this limitation, we propose a method to quantify the predictive uncertainty of Mamba forecasts. To achieve this, we propose a dual-network framework based on the Mamba architecture for probabilistic forecasting, where one network generates point forecasts while the other estimates predictive uncertainty by modeling variance. We abbreviate our tool, Mamba with probabilistic TSF, as Mamba-ProbTSF and the code for its implementation is available on GitHub https://github.com/PessoaP/Mamba-ProbTSF . Evaluating this approach on synthetic and real-world benchmark datasets, we find Kullback–Leibler divergence between the learned distributions and the data–which, in the limit of infinite data, should converge to zero if the model correctly captures the underlying probability distribution–reduced to the order of 10 −3 for synthetic data and 10 −1 for real-world benchmark. We find that in both the electricity consumption and traffic occupancy benchmark, the true trajectory stays within the predicted uncertainty interval at the two-sigma level about 95% of the time. We further compare Mamba-ProbTSF against leading probabilistic forecast methods, DeepAR and ARIMA, and show that our method consistently achieves lower forecast errors while offering more reliable uncertainty quantification. We end with a consideration of potential limitations, adjustments to improve performance, and considerations for applying this framework to processes for purely or largely stochastic dynamics where the stochastic changes accumulate as observed, for example, in pure Brownian motion or molecular dynamics trajectories.},
  archive      = {J_MLST},
  author       = {Pedro Pessoa and Paul Campitelli and Douglas P Shepherd and S Banu Ozkan and Steve Pressé},
  doi          = {10.1088/2632-2153/adec3b},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035012},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Mamba time series forecasting with uncertainty quantification},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Randomized tensor network reservoir computing: Validity and learnability phase transitions. <em>MLST</em>, <em>6</em>(3), 035011. (<a href='https://doi.org/10.1088/2632-2153/aded56'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reservoir computing (RC) systems, traditionally based on echo state networks (ESN) or liquid state machines, have shown significant potential in dynamic temporal data modeling, such as weather forecasting and astronomical predictions. However, these frameworks are known not being applicable to quantum dynamics-based RC. Tensor networks (TNs), with their efficient representation of high-dimensional quantum information and entanglement, are powerful tools for modeling correlated quantum dynamics. Introducing randomized effects into TNs, akin to randomization of recurrent connections in traditional RC, is expected to generate diverse quantum correlation patterns and provide robust, generalizable quantum-inspired dynamic models through randomization. In this work, we propose a novel randomized TN-based RC scheme, experimentally demonstrating its validity. A theoretical model selection criterion is constructed to find the optimal TNRC hyperparameters. Critical phenomena along with the phase transitions of learnability near the edge of chaos in TN RC are clearly identified. The distribution-independent universality in phase transitions observed in TN RC is captured by the newly developed learning theory and a self-consistent mean-field theory of the spin-glass type. The performance advantage of TNRC over ESN is demonstrated in several forecasting experiments. Our findings lay the groundwork for future explorations into randomized TN quantum machine learning, phase transitions in quantum RC, and the manipulation of critical phenomena in complex systems.},
  archive      = {J_MLST},
  author       = {Shinji Sato and Daiki Sasaki and Chih-Chieh Chen and Kodai Shiba and Tomah Sogabe},
  doi          = {10.1088/2632-2153/aded56},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035011},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Randomized tensor network reservoir computing: Validity and learnability phase transitions},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ordered embeddings and intrinsic dimensionalities with information-ordered bottlenecks. <em>MLST</em>, <em>6</em>(3), 035010. (<a href='https://doi.org/10.1088/2632-2153/ade94d'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the information-ordered bottleneck (IOB), a neural layer designed to adaptively compress data into latent variables ordered by likelihood maximization. Without retraining, IOB nodes can be truncated at any bottleneck width, capturing the most crucial information in the first latent variables. Unifying several prior approaches, we demonstrate that IOB models achieve efficient compression of essential information for a given encoding architecture, while also assigning a semantically meaningful ordering to latent representations. IOBs demonstrate a remarkable ability to compress embeddings of high-dimensional image and text data, leveraging the performance of SOTA architectures such as CNNs, transformers, and diffusion models. Moreover, we introduce a novel theory for estimating global intrinsic dimensionality with IOBs and show that they recover SOTA dimensionality estimates for complex synthetic data. Furthermore, we showcase the utility of these models for exploratory analysis through applications on heterogeneous datasets, enabling computer-aided discovery of dataset complexity.},
  archive      = {J_MLST},
  author       = {Matthew Ho and Xiaosheng Zhao and Benjamin D Wandelt},
  doi          = {10.1088/2632-2153/ade94d},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035010},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Ordered embeddings and intrinsic dimensionalities with information-ordered bottlenecks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural architecture codesign for fast physics applications. <em>MLST</em>, <em>6</em>(3), 035009. (<a href='https://doi.org/10.1088/2632-2153/adede1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a pipeline to streamline neural architecture codesign for physics applications to reduce the need for ML expertise when designing models for novel tasks. Our method employs neural architecture search and network compression in a two-stage approach to discover hardware efficient models. This approach consists of a global search stage that explores a wide range of architectures while considering hardware constraints, followed by a local search stage that fine-tunes and compresses the most promising candidates. We exceed performance on various tasks and show further speedup through model compression techniques such as quantization-aware-training and neural network pruning. We synthesize the optimal models to high level synthesis code for FPGA deployment with the hls4ml library. Additionally, our hierarchical search space provides greater flexibility in optimization, which can easily extend to other tasks and domains. We demonstrate this with two case studies: Bragg peak finding in materials science and jet classification in high energy physics, achieving models with improved accuracy, smaller latencies, or reduced resource utilization relative to the baseline models.},
  archive      = {J_MLST},
  author       = {Jason Weitz and Dmitri Demler and Luke McDermott and Nhan Tran and Javier Duarte},
  doi          = {10.1088/2632-2153/adede1},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035009},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Neural architecture codesign for fast physics applications},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network approach for line detection in complex atomic emission spectra measured by high-resolution fourier transform spectroscopy. <em>MLST</em>, <em>6</em>(3), 035008. (<a href='https://doi.org/10.1088/2632-2153/adece6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The atomic spectra and structure of the low-ionisation open d- and f-shell elements are extremely complex, tens of thousands of fine structure lines are observable between the infrared and ultraviolet per species. These transitions underpin most spectroscopic plasma diagnostics, yet their fundamental data remain incomplete and are in high demand in astronomy and fusion research. A key limitation is the substantial human effort required to extract transition wavenumbers and intensities from Fourier transform spectra, as existing peak-detection methods based on thresholding and convolutional kernels frequently fail on blended or weak lines that make up the majority of spectral lines. We approach this challenge by framing spectral line detection as a sequential point-wise binary classification problem to be learned by bidirectional long short-term memory and fully connected neural networks. We trained the model using spectra simulations and evaluated model predictions on experimental spectra of Ni (nuclear charge Z = 28) covering 1800–70 000 cm −1 (5555–143 nm) and Nd ( Z = 60) covering 25 369–32 485 cm −1 (394–308 nm) recorded under various experimental conditions. The neural network approach outperforms existing peak-detection methods, particularly for noisy, blended, and/or instrument-distorted lines. In our model evaluation by brief energy level analysis, lines newly detected by the neural networks enabled the confident identification of two Ni II energy levels, 3d ^8(^3\text{F}_4)6\text{f} \,\,[2]_{3/2} at 134 261.8946 ± 0.0081 cm −1 and 3d ^8(^3\text{F}_4)6\text{f} \,\,[1]_{3/2} at 134 249.5264 ± 0.0054 cm −1 , previously deemed to be unidentifiable using the Ni spectra.},
  archive      = {J_MLST},
  author       = {Milan Ding and Sean Z J Lim and Xiaoran Yu and Christian P Clear and Juliet C Pickering},
  doi          = {10.1088/2632-2153/adece6},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035008},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A neural network approach for line detection in complex atomic emission spectra measured by high-resolution fourier transform spectroscopy},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Considering the ethics of large machine learning models in the chemical sciences. <em>MLST</em>, <em>6</em>(3), 035007. (<a href='https://doi.org/10.1088/2632-2153/adec3c'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundation models, including large language models, vision-language models, and similar large-scale machine learning tools, are quickly becoming ubiquitous in society and in the professional world. Chemical practitioners are not immune to the appeal of foundation models, nor are they immune to the many risks and harms that these models introduce. In this work, I present the first analysis of foundation models using the combined lens of scientific ethics and chemical professional ethics. I find that general-purpose generative foundation models are in many ways incompatible with the moral practice of chemistry, though there are fewer ethical problems with chemistry-specific foundation models. My discussion concludes with an examination of how the harm associated with foundation models can be minimized and further poses a set of serious lingering questions for chemical practitioners and scientific ethicists.},
  archive      = {J_MLST},
  author       = {Evan Walter Clark Spotte-Smith},
  doi          = {10.1088/2632-2153/adec3c},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035007},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Considering the ethics of large machine learning models in the chemical sciences},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging text and crystal structures: Literature-driven contrastive learning for materials science. <em>MLST</em>, <em>6</em>(3), 035006. (<a href='https://doi.org/10.1088/2632-2153/ade58c'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding structure–property relationships is an essential yet challenging aspect of materials discovery and development. To facilitate this process, recent studies in materials informatics have sought latent embedding spaces of crystal structures to capture their similarities based on properties and functionalities. However, abstract feature-based embedding spaces are human-unfriendly and prevent intuitive and efficient exploration of the vast materials space. Here we introduce Contrastive Language–Structure Pre-training (CLaSP), a learning paradigm for constructing crossmodal embedding spaces between crystal structures and texts. CLaSP aims to achieve material embeddings that (1) capture property- and functionality-related similarities between crystal structures and (2) allow intuitive retrieval of materials via user-provided description texts as queries. To compensate for the lack of sufficient datasets linking crystal structures with textual descriptions, CLaSP leverages a dataset of over 400 000 published crystal structures and corresponding publication records, including paper titles and abstracts, for training. We demonstrate the effectiveness of CLaSP through text-based crystal structure screening and embedding space visualization.},
  archive      = {J_MLST},
  author       = {Yuta Suzuki and Tatsunori Taniai and Ryo Igarashi and Kotaro Saito and Naoya Chiba and Yoshitaka Ushiku and Kanta Ono},
  doi          = {10.1088/2632-2153/ade58c},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035006},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Bridging text and crystal structures: Literature-driven contrastive learning for materials science},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Atomic orbits in molecules and materials for improving machine learning force fields. <em>MLST</em>, <em>6</em>(3), 035005. (<a href='https://doi.org/10.1088/2632-2153/adea0b'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate representation of atoms within their environment forms the backbone of any reliable machine learning force field (MLFF). While modern MLFFs treat atoms of the same type as indistinguishable, their identities can be further resolved by accounting for the composition of their chemical environment. This can improve the parameterization of the MLFF model in chemically diverse systems. In this work, we introduce a novel, data-driven approach designed to find permutation symmetries in isolated and periodic systems, delivering key insights that enable the identification of atomic ‘orbits’, atoms that share consistent chemical and structural environments throughout the dataset. We demonstrate the effectiveness of the orbit representation by incorporating it into the kernel-based symmetric gradient-domain ML (sGDML) model and the equivariant message-passing neural network, MACE. For sGDML, trained on ethanol, 1,8-naphthyridine, D-alanine, and D-histidine adsorbed on graphene, we establish a strong correlation between force prediction accuracy and chemical diversity, quantified by orbit count. The results for the Ac-Phe-Ala5-Lys molecule further underscore the critical role of orbits in force reconstruction across various MLFF architectures. Incorporating orbits into MACE enables us to reduce the model size by an order of magnitude while preserving predictive accuracy, as demonstrated for the CsPbI 3 perovskite slab and graphene with a pyridinic-N defect. Overall, our approach provides a scalable and efficient solution for modeling complex chemical systems with state-of-the-art MLFFs.},
  archive      = {J_MLST},
  author       = {Anton Charkin-Gorbulin and Artem Kokorin and Huziel E Sauceda and Stefan Chmiela and Claudio Quarti and David Beljonne and Alexandre Tkatchenko and Igor Poltavsky},
  doi          = {10.1088/2632-2153/adea0b},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035005},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Atomic orbits in molecules and materials for improving machine learning force fields},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active delta-learning for fast construction of interatomic potentials and stable molecular dynamics simulations. <em>MLST</em>, <em>6</em>(3), 035004. (<a href='https://doi.org/10.1088/2632-2153/adeb46'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active learning (AL) requires massive time for comprehensive sampling of complex potential energy surfaces to achieve desirable accuracy and stability of machine learning (ML) potentials. Here, we develop an active delta-learning (ADL) protocol for speeding up AL and building delta-learning models yielding stable simulations. ADL converges after a few iterations and needs tenfold fewer sampled points than without delta-learning while leading to models of similar accuracy, as we show on the test simulations of Diels–Alder reactions. The test reactions include one small (ethene + 1,3-butadiene) and one relatively big (C 60 + 2,3-dimethyl-1,3-butadiene) system, treated with a target density functional theory level (U)B3LYP(-D4)/6-31G* and a baseline semi-empirical quantum mechanical method, GFN2-xTB. The crucial advantage of the models built with the delta-learning protocol is their remarkable simulation stability: even models from the initial ADL iterations yield reasonable results. In contrast, the pure ML potentials built without delta-learning often lead to the collapse in simulations, i.e. to unphysical structures.},
  archive      = {J_MLST},
  author       = {Yaohuang Huang and Yi-Fan Hou and Pavlo O Dral},
  doi          = {10.1088/2632-2153/adeb46},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035004},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Active delta-learning for fast construction of interatomic potentials and stable molecular dynamics simulations},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evidential deep learning for uncertainty quantification and out-of-distribution detection in jet identification using deep neural networks. <em>MLST</em>, <em>6</em>(3), 035003. (<a href='https://doi.org/10.1088/2632-2153/ade51b'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current methods commonly used for uncertainty quantification (UQ) in deep learning (DL) models utilize Bayesian methods which are computationally expensive and time-consuming. In this paper, we provide a detailed study of UQ based on evidential DL (EDL) for deep neural network models designed to identify jets in high energy proton–proton collisions at the Large Hadron Collider and explore its utility in anomaly detection (AD). EDL is a DL approach that treats learning as an evidence acquisition process designed to provide confidence (or epistemic uncertainty) about test data. Using publicly available datasets for jet classification benchmarking, we explore hyperparameter optimizations for EDL applied to the challenge of UQ for jet identification. We also investigate how the uncertainty is distributed for each jet class, how this method can be implemented for the detection of anomalies, how the uncertainty compares with Bayesian ensemble methods, and how the uncertainty maps onto latent spaces for the models. Our studies uncover some pitfalls of EDL applied to AD and a more effective way to quantify uncertainty from EDL as compared with the foundational EDL setup. These studies illustrate a methodological approach to interpreting EDL in jet classification models, providing new insights on how EDL quantifies uncertainty and detects out-of-distribution data which may lead to improved EDL methods for DL models applied to classification tasks.},
  archive      = {J_MLST},
  author       = {Ayush Khot and Xiwei Wang and Avik Roy and Volodymyr Kindratenko and Mark S Neubauer},
  doi          = {10.1088/2632-2153/ade51b},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035003},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Evidential deep learning for uncertainty quantification and out-of-distribution detection in jet identification using deep neural networks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-guided construction of an analytic kinetic energy functional for orbital free density functional theory. <em>MLST</em>, <em>6</em>(3), 035002. (<a href='https://doi.org/10.1088/2632-2153/ade7ca'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) of kinetic energy functionals (KEF) for orbital-free density functional theory (DFT) holds the promise of addressing an important bottleneck in large-scale ab initio materials modeling where sufficiently accurate analytic KEFs are lacking. However, ML models are not as easily handled as analytic expressions; they need to be provided in the form of algorithms and associated data. Here, we bridge the two approaches and construct an analytic expression for a KEF guided by interpretative ML of crystal cell-averaged kinetic energy densities ( {\bar{\tau}} ) of several hundred materials. A previously published dataset including multiple phases of 433 unary, binary, and ternary compounds containing Li, Al, Mg, Si, As, Ga, Sb, Na, Sn, P, and In was used for training, including data at the equilibrium geometry as well as strained structures. A hybrid Gaussian process regression—neural network method was used to understand the type of functional dependence of \overline\tau on the features which contained cell-averaged terms of the 4th order gradient expansion and the product of the electron density and Kohn–Sham (KS) effective potential. Based on this analysis, an analytic model is constructed that can reproduce KS DFT energy–volume curves with sufficient accuracy (pronounced minima that are sufficiently close to the minima of the Kohn–Sham DFT-based curves and with sufficiently close curvatures) to enable structure optimizations and elastic response calculations.},
  archive      = {J_MLST},
  author       = {Sergei Manzhos and Johann Lüder and Pavlo Golub and Manabu Ihara},
  doi          = {10.1088/2632-2153/ade7ca},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035002},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine learning-guided construction of an analytic kinetic energy functional for orbital free density functional theory},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight ECG signal classification via linear law-based feature extraction. <em>MLST</em>, <em>6</em>(3), 035001. (<a href='https://doi.org/10.1088/2632-2153/ade6c3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces LLT-ECG, a novel semi-supervised method for electrocardiogram (ECG) signal classification that leverages principles from theoretical physics to generate features without relying on backpropagation or hyperparameter tuning. The method identifies linear laws that capture shared patterns within a reference class, enabling compact and verifiable representations of time series data. We evaluate the method on two PhysioNet datasets, TwoLeadECG and variable projection networks (VPNet). On TwoLeadECG, a minimal configuration—using only the linear law-based transformation (LLT) and a linear decision rule—reaches 73.1% accuracy using just two features. On VPNet, LLT-ECG combined with classifiers like k-nearest neighbors and support vector machines achieves up to 96.4% accuracy, comparable to deep learning models. These results highlight LLT-ECG’s promise for lightweight, interpretable, and high-performing ECG classification.},
  archive      = {J_MLST},
  author       = {Péter Pósfay and Marcell T Kurbucz and Péter Kovács and Antal Jakovác},
  doi          = {10.1088/2632-2153/ade6c3},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {035001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Lightweight ECG signal classification via linear law-based feature extraction},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Outlook towards deployable continual learning for particle accelerators. <em>MLST</em>, <em>6</em>(3), 031001. (<a href='https://doi.org/10.1088/2632-2153/adeb45'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle accelerators are high power complex machines. To ensure uninterrupted operation of these machines, thousands of pieces of equipment need to be synchronized, which requires addressing many challenges including design, optimization and control, anomaly detection and machine protection. With recent advancements, machine learning (ML) holds promise to assist in more advance prognostics, optimization, and control. While ML based solutions have been developed for several applications in particle accelerators, only few have reached deployment and even fewer to long term usage, due to particle accelerator data distribution drifts caused by changes in both measurable and non-measurable parameters. In this paper, we identify some of the key areas within particle accelerators where continual learning can allow maintenance of ML model performance with distribution drifts. Particularly, we first discuss existing applications of ML in particle accelerators, and their limitations due to distribution drift. Next, we review existing continual learning techniques and investigate their potential applications to address data distribution drifts in accelerators. By identifying the opportunities and challenges in applying continual learning, this paper seeks to open up the new field and inspire more research efforts towards deployable continual learning for particle accelerators.},
  archive      = {J_MLST},
  author       = {Kishansingh Rajput and Sen Lin and Auralee Edelen and Willem Blokland and Malachi Schram},
  doi          = {10.1088/2632-2153/adeb45},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {031001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Outlook towards deployable continual learning for particle accelerators},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aspen open jets: Unlocking LHC data for foundation models in particle physics. <em>MLST</em>, <em>6</em>(3), 030601. (<a href='https://doi.org/10.1088/2632-2153/ade58f'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundation models are deep learning models pre-trained on large amounts of data which are capable of generalizing to multiple datasets and/or downstream tasks. This work demonstrates how data collected by the CMS experiment at the Large Hadron Collider can be useful in pre-training foundation models for HEP. Specifically, we introduce the AspenOpenJets (AOJs) dataset, consisting of approximately 178 M high p_\mathrm{T} jets derived from CMS 2016 Open Data. We show how pre-training the OmniJet - α foundation model on AOJs improves performance on generative tasks with significant domain shift: generating boosted top and QCD jets from the simulated JetClass dataset. In addition to demonstrating the power of pre-training of a jet-based foundation model on actual proton–proton collision data, we provide the ML-ready derived AOJs dataset for further public use.},
  archive      = {J_MLST},
  author       = {Oz Amram and Luca Anzalone and Joschka Birk and Darius A Faroughy and Anna Hallin and Gregor Kasieczka and Michael Krämer and Ian Pang and Humberto Reyes-Gonzalez and David Shih},
  doi          = {10.1088/2632-2153/ade58f},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {030601},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Aspen open jets: Unlocking LHC data for foundation models in particle physics},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Universal machine learning interatomic potentials poised to supplant DFT in modeling general defects in metals and random alloys. <em>MLST</em>, <em>6</em>(3), 030501. (<a href='https://doi.org/10.1088/2632-2153/adea2d'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in machine learning, combined with the generation of extensive density functional theory (DFT) datasets, have enabled the development of universal machine learning interatomic potentials (uMLIPs). These models offer broad applicability across the periodic table, achieving first-principles accuracy at a fraction of the computational cost of traditional DFT calculations. In this study, we demonstrate that state-of-the-art pretrained uMLIPs can effectively replace DFT for accurately modeling complex defects in a wide range of metals and alloys. Our investigation spans diverse scenarios, including grain boundaries and general defects in pure metals, defects in high-entropy alloys, hydrogen-alloy interactions, and solute-defect interactions. Remarkably, the latest EquiformerV2 models achieve DFT-level accuracy on comprehensive defect datasets, with root mean square errors below 5 meV atom −1 for energies and 100 meV Å −1 for forces, outperforming specialized machine learning potentials such as moment tensor potential and atomic cluster expansion. We also present a systematic analysis of accuracy versus computational cost and explore uncertainty quantification for uMLIPs. A detailed case study of tungsten (W) demonstrates that data on pure W alone is insufficient for modeling complex defects in uMLIPs, underscoring the critical importance of advanced machine learning architectures and diverse datasets, which include over 100 million structures spanning all elements. These findings establish uMLIPs as a robust alternative to DFT and a transformative tool for accelerating the discovery and design of high-performance materials.},
  archive      = {J_MLST},
  author       = {Fei Shuang and Zixiong Wei and Kai Liu and Wei Gao and Poulumi Dey},
  doi          = {10.1088/2632-2153/adea2d},
  journal      = {Machine Learning: Science and Technology},
  month        = {7},
  number       = {3},
  pages        = {030501},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Universal machine learning interatomic potentials poised to supplant DFT in modeling general defects in metals and random alloys},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective bayesian optimization of eco-friendly gas mixtures for resistive plate chambers. <em>MLST</em>, <em>6</em>(2), 025077. (<a href='https://doi.org/10.1088/2632-2153/ade6c5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing environmentally friendly gas mixtures for resistive plate chambers (RPCs) has been a research focus for the last few years. This study presents a novel approach for autonomous optimization of the detector performance and environmental impact of gas mixtures and enabling a more efficient evaluation for finding a suitable replacement for RPCs. The proposed framework is built upon multi-objective Bayesian optimization (BO) with Pareto front prediction and per-point noise implementation. This work fills a research gap by applying advanced optimization tools, specifically BO, to challenges in gaseous detectors, gas insulation systems and electrical engineering: An approach that is not commonly used in the field. This framework can be applied in both experimental and simulation studies, and is applied here in a study of CO 2 -based standard mixtures, intending to enhance avalanche-to-streamer separation and to reduce the gas mixture’s CO 2 equivalent (CO 2 e). The resulting optimization includes 259 simulated gas mixtures and indicates that reducing the environmental impact of CO 2 -based standard mixtures always comes at the cost of reducing the separation. No mixture with performance superior to or similar to the gas mixtures currently in use could be found while also significantly reducing the CO 2 e. This optimization yields a detailed simulated data set for gas mixture replacement in RPCs, showing a hypervolume improvement that exceeds traditional methods within 33% of the number of iterations, thus eliminating the need for time-consuming traditional parameter space sampling approaches. Future enhancements utilizing ultralow global warming potential gases, such as HFO-1234ze(E), or additional objectives, can be realized within this novel current framework.},
  archive      = {J_MLST},
  author       = {Pit Bechtold and Dario Stocco and Christian M Franck},
  doi          = {10.1088/2632-2153/ade6c5},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025077},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Multi-objective bayesian optimization of eco-friendly gas mixtures for resistive plate chambers},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable classification of levantine ceramic thin sections via neural networks. <em>MLST</em>, <em>6</em>(2), 025076. (<a href='https://doi.org/10.1088/2632-2153/ade6c4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of ceramic thin sections is fundamental for understanding ancient pottery production techniques, provenance, and trade networks. Although effective, traditional petrographic analysis is time-consuming. This study explores the application of deep learning models, specifically convolutional neural networks (CNNs) and vision transformers (ViTs), as complementary tools to support the classification of Levantine ceramics based on their petrographic fabrics . A dataset of 1424 thin section images from 178 ceramic samples belonging to several archaeological sites across the Levantine area, mostly from the Bronze Age, with few samples dating to the Iron Age, was used to train and evaluate these models. The results demonstrate that transfer learning significantly improves classification performance, with a ResNet18 model achieving 92.11% accuracy and a ViT reaching 88.34%. Explainability techniques, including Guided Gradient-based Class Activation Maps and attention maps, were applied to interpret and visualize the models’ decisions, revealing that both CNNs and ViTs successfully focus on key mineralogical features for the classification of the samples into their respective petrographic fabrics . These findings highlight the potential of explainable AI in archaeometric studies, providing a reproducible and efficient methodology for ceramic analysis while maintaining transparency in model decision-making.},
  archive      = {J_MLST},
  author       = {Sara Capriotti and Alessio Devoto and Simone Scardapane and Silvano Mignardi and Laura Medeghini},
  doi          = {10.1088/2632-2153/ade6c4},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025076},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Interpretable classification of levantine ceramic thin sections via neural networks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Is tokenization needed for masked particle modeling?. <em>MLST</em>, <em>6</em>(2), 025075. (<a href='https://doi.org/10.1088/2632-2153/addb98'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we significantly enhance masked particle modeling (MPM), a self-supervised learning scheme for constructing highly expressive representations of unordered sets relevant to developing foundation models for high-energy physics. In MPM, a model is trained to recover the missing elements of a set, a learning objective that requires no labels and can be applied directly to experimental data. We achieve significant performance improvements over previous work on MPM by addressing inefficiencies in the implementation and incorporating a more powerful decoder. We compare several pre-training tasks and introduce new reconstruction methods that utilize conditional generative models without data tokenization or discretization. We show that these new methods outperform the tokenized learning objective from the original MPM on a new test bed for foundation models for jets, which includes using a wide variety of downstream tasks relevant to jet physics, such as classification, secondary vertex finding, and track identification.},
  archive      = {J_MLST},
  author       = {Matthew Leigh and Samuel Klein and François Charton and Tobias Golling and Lukas Heinrich and Michael Kagan and Inês Ochoa and Margarita Osadchy},
  doi          = {10.1088/2632-2153/addb98},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025075},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Is tokenization needed for masked particle modeling?},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine-learning based high-bandwidth magnetic sensing. <em>MLST</em>, <em>6</em>(2), 025074. (<a href='https://doi.org/10.1088/2632-2153/ade51c'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have seen significant growth of quantum technologies, and specifically quantum sensing, both in terms of the capabilities of advanced platforms and their applications. One of the leading platforms in this context is nitrogen-vacancy (NV) color centers in diamond, providing versatile, high-sensitivity, and high-spatial-resolution magnetic sensing. Nevertheless, current schemes for spin resonance magnetic sensing (as applied by NV quantum sensing) suffer from tradeoffs associated with sensitivity, dynamic range, and bandwidth. Here we address this issue, and implement machine learning tools to enhance NV magnetic sensing in terms of the sensitivity/bandwidth tradeoff in large dynamic range scenarios. Our results indicate a potential reduction of required data points by at least a factor of 3, while maintaining the current error level. Our results promote quantum machine learning protocols for sensing applications towards more feasible and efficient quantum technologies.},
  archive      = {J_MLST},
  author       = {Galya Haim and Stefano Martina and John Howell and Nir Bar-Gill and Filippo Caruso},
  doi          = {10.1088/2632-2153/ade51c},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025074},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine-learning based high-bandwidth magnetic sensing},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Designing precise dynamical steady states in disordered networks. <em>MLST</em>, <em>6</em>(2), 025073. (<a href='https://doi.org/10.1088/2632-2153/ade590'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Elastic structures can be designed to exhibit precise, complex, and exotic functions. While recent work has focused on the quasistatic limit governed by force balance, the mechanics at a finite driving rate are governed by Newton’s equations. The goal of this work is to study the feasibility, constraints, and implications of creating disordered structures with exotic properties in the dynamic regime. The dynamical regime offers responses that cannot be realized in quasistatics, such as responses at an arbitrary phase, frequency-selective responses, and history-dependent responses. We employ backpropagation through time and gradient descent to design spatially specific steady states in disordered spring networks. We find that a broad range of steady states can be achieved with small alterations to the structure, operating both at small and large amplitudes. We study the effect of varying the damping, which interpolates between the underdamped and the overdamped regime, as well as the amplitude, frequency, and phase. We show that convergence depends on several competing effects, including chaos, large relaxation times, a gradient bias due to finite time simulations, and strong attenuation. By studying the eigenmodes of the linearized system, we show that the systems adapt very specifically to the task they were trained to perform. Our work demonstrates that within physical bounds, a broad array of exotic behaviors in the dynamic regime can be obtained, allowing for a richer range of possible applications.},
  archive      = {J_MLST},
  author       = {Marc Berneman and Daniel Hexner},
  doi          = {10.1088/2632-2153/ade590},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025073},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Designing precise dynamical steady states in disordered networks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FFTL-net: A network for the classification of skin diseases based on feature fusion and transfer learning. <em>MLST</em>, <em>6</em>(2), 025072. (<a href='https://doi.org/10.1088/2632-2153/ade4f0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective is to address the issues of data imbalance, overfitting, and inadequate generalization ability in skin disease datasets and recognition models. The proposed model for the classification of skin diseases is based on the fusion of features and the utilization of transfer learning. The model’s architecture is predicated on a dense connection network that serves as its fundamental framework, with LBP and HOG features incorporated as supplementary inputs. Subsequently, a feature fusion module integrated with an attention mechanism is employed to extract and combine features. Finally, the Softmax-loss function of category equilibrium and the domain adaptive strategy based on the maximum mean difference are established. The integration of prior knowledge into the deep network is a critical step in addressing the challenges of overfitting and data imbalance in skin disease classification. The FFTL-Net achieved AUC value of 98.16% on the International skin imaging collaboration (ISIC) 2018 dataset and 98.31% on the ISIC 2019 dataset. This represents an improvement of 1.25% and 0.33% compared to the second-ranked algorithm, respectively. The experimental results demonstrate the efficacy of the model in addressing the data imbalance issue in skin disease datasets, with prediction accuracies of at least 93% being achieved for BCC and other rare samples. The model demonstrates superior recognition accuracy, augmented generalization capability, and an absence of indications of overfitting.},
  archive      = {J_MLST},
  author       = {Xiaowei Song and Yurong Mei and Zhilei Zhao and Hao Chang and Lina Han and Hui Wang and Xinyi Zhang and Guoqiang Wang},
  doi          = {10.1088/2632-2153/ade4f0},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025072},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {FFTL-net: A network for the classification of skin diseases based on feature fusion and transfer learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequential learning on a tensor network born machine with trainable token embedding. <em>MLST</em>, <em>6</em>(2), 025071. (<a href='https://doi.org/10.1088/2632-2153/adde29'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models aim to learn the probability distributions underlying data, enabling the generation of new, realistic samples. Quantum-inspired generative models, such as Born machines based on the matrix product state (MPS) framework, have demonstrated remarkable capabilities in unsupervised learning tasks. This study advances the Born machine paradigm by introducing trainable token embeddings through positive operator-valued measurements (POVMs), replacing the traditional approach of static tensor indices. Key technical innovations include encoding tokens as quantum measurement operators with trainable parameters and leveraging QR decomposition to adjust the physical dimensions of the MPS. This approach maximizes the utilization of operator space and enhances the model’s expressiveness. Empirical results on RNA data demonstrate that the proposed method significantly reduces negative log-likelihood compared to one-hot embeddings, with higher physical dimensions further enhancing single-site probabilities and multi-site correlations. The model also outperforms GPT-2 in single-site estimation and achieves competitive correlation modeling, showcasing the potential of trainable POVM embeddings for complex data correlations in quantum-inspired sequence modeling.},
  archive      = {J_MLST},
  author       = {Wanda Hou and Miao Li and Yi-Zhuang You},
  doi          = {10.1088/2632-2153/adde29},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025071},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Sequential learning on a tensor network born machine with trainable token embedding},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view mixture-of-experts for predicting molecular properties using SMILES, SELFIES, and graph-based representations. <em>MLST</em>, <em>6</em>(2), 025070. (<a href='https://doi.org/10.1088/2632-2153/ade4ef'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chemical foundation models are generally based on a two-step approach-pre-training on unlabeled data followed by fine-tuning on specific tasks-to boost model capacity. With the increasing demand for training efficiency, mixture-of-experts (MoEs) has become essential for scaling large models by selectively activating sub-networks of experts through a gating network, thereby optimizing performance. This paper presents molecular MoL-MoE, a multi-view MoEs framework designed to predict molecular properties by integrating latent spaces derived from SMILES, SELFIES, and molecular graphs. Our approach leverages the complementary strengths of these representations to enhance predictive accuracy. Here, we evaluate the performance of MoL-MoE with a total of 12 experts, organized into 4 experts for each modality (SMILES, SELFIES, and molecular graphs). We evaluate MoL-MoE on a range of benchmark datasets from MoleculeNet, demonstrating its superior performance compared to state-of-the-art methods across all nine datasets considering two different routing activation settings: k = 4 and k = 6. The results underscore the model’s robustness and adaptability in handling various complex molecular prediction tasks. Our analysis of routing activation patterns reveals that MoL-MoE dynamically adjusts its use of different molecular representations based on task-specific requirements. This adaptability highlights the importance of representation choice in optimizing model performance. Source code for MoL-MoE is available at https://github.com/IBM/materials/tree/main/models/mol_moe .},
  archive      = {J_MLST},
  author       = {Eduardo Soares and Victor Yukio Shirasuna and Emilio Vital Brazil and Indra Priyadarsini and Seiji Takeda},
  doi          = {10.1088/2632-2153/ade4ef},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025070},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Multi-view mixture-of-experts for predicting molecular properties using SMILES, SELFIES, and graph-based representations},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NeuralPDR: Neural differential equations as surrogate models for photodissociation regions. <em>MLST</em>, <em>6</em>(2), 025069. (<a href='https://doi.org/10.1088/2632-2153/ade4ee'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational astrochemical models are essential for helping us interpret and understand the observations of different astrophysical environments. In the age of high-resolution telescopes such as JWST and ALMA, the substructure of many objects can be resolved, raising the need for astrochemical modeling at these smaller scales, meaning that the simulations of these objects need to include both the physics and chemistry to accurately model the observations. The computational cost of the simulations coupling both the three-dimensional hydrodynamics and chemistry is enormous, creating an opportunity for surrogate models that can effectively substitute the chemical solver. In this work we present surrogate models that can replace the original chemical code, namely Latent Augmented Neural Ordinary Differential Equations. We train these surrogate architectures on three datasets of increasing physical complexity, with the last dataset derived directly from a three-dimensional simulation of a molecular cloud using a photodissociation region (PDR) code, 3D-PDR . We show that these surrogate models can provide speedup and reproduce the original observable column density maps of the dataset. This enables the rapid inference of the chemistry (on the GPU), allowing for the faster statistical inference of observations or increasing the resolution in hydrodynamical simulations of astrophysical environments.},
  archive      = {J_MLST},
  author       = {Gijs Vermariën and Thomas G Bisbas and Serena Viti and Yue Zhao and Xuefei Tang and Rahul Ravichandran},
  doi          = {10.1088/2632-2153/ade4ee},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025069},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {NeuralPDR: Neural differential equations as surrogate models for photodissociation regions},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning approach to reconstruct density matrices from quantum marginals. <em>MLST</em>, <em>6</em>(2), 025068. (<a href='https://doi.org/10.1088/2632-2153/ade48d'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a machine learning (ML)-based approach to address a specific aspect of the Quantum Marginal Problem: reconstructing a global density matrix compatible with a given set of quantum marginals. Our method integrates a quantum marginal imposition technique with convolutional denoising autoencoders. The loss function is carefully designed to enforce essential physical constraints, including Hermiticity, positivity, and normalization. Through extensive numerical simulations, we demonstrate the effectiveness of our approach, achieving high success rates and accuracy. Furthermore, we show that, in many cases, our model offers a faster alternative to state-of-the-art semidefinite programming solvers without compromising solution quality. These results highlight the potential of ML techniques for solving complex problems in quantum mechanics.},
  archive      = {J_MLST},
  author       = {Daniel Uzcategui-Contreras and Antonio Guerra and Sebastian Niklitschek and Aldo Delgado},
  doi          = {10.1088/2632-2153/ade48d},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025068},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine learning approach to reconstruct density matrices from quantum marginals},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal multi-output ordinal regression for discovering gravitationally-lensed transients. <em>MLST</em>, <em>6</em>(2), 025067. (<a href='https://doi.org/10.1088/2632-2153/ade360'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gravitational lenses are caused by massive astronomical objects that distort space-time, bending light. They can distort transient astrophysical events, such as supernovae (SN), which are the subject of extensive study. However, gravitationally-lensed supernovae are rare, with only a few detected so far. Future astronomical surveys will collect huge amounts of data, calling for automated and accurate discovery techniques to find them. Still, only a few works aim to discover gravitationally-lensed supernovae, most use only a few classes to characterize candidate observations, and only a few exploit spatial and temporal information. This work introduces Hydra, a novel pipeline designed to process spatio-temporal data for identifying and counting astronomical objects, including gravitational lenses and transients. Hydra performs two tasks: (i) counting the occurrences of 7 types of astronomical objects within each observation and (ii) classifying candidate events and objects (e.g. gravitational lenses and transient events). Across four datasets, Hydra achieves an average macro F 1 score higher than 79% for the counting task and macro F 1 scores ranging from {\approx}59\% to {\approx}94\% for classification. These results demonstrate its potential for improving automated discovery in future astronomical surveys and for counting objects in multimodal data.},
  archive      = {J_MLST},
  author       = {Nicolò Oreste Pinciroli Vago and Piero Fraternali},
  doi          = {10.1088/2632-2153/ade360},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025067},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Multimodal multi-output ordinal regression for discovering gravitationally-lensed transients},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving thermal state preparation of Sachdev–Ye–Kitaev model with reinforcement learning on quantum hardware. <em>MLST</em>, <em>6</em>(2), 025066. (<a href='https://doi.org/10.1088/2632-2153/ade361'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Sachdev–Ye–Kitaev (SYK) model, known for its strong quantum correlations and chaotic behavior, serves as a key platform for quantum gravity studies. However, variationally preparing thermal states on near-term quantum processors for large systems ( N > 12, where N is the number of Majorana fermions) presents a significant challenge due to the rapid growth in the complexity of parameterized quantum circuits. This paper addresses this challenge by integrating reinforcement learning (RL) with convolutional neural networks, employing an iterative approach to optimize the quantum circuit and its parameters. The refinement process is guided by a composite reward signal derived from entropy and the expectation values of the SYK Hamiltonian. This approach reduces the number of controlled-NOT gates by two orders of magnitude for systems N\unicode{x2A7E}12 compared to traditional methods like first-order Trotterization. We demonstrate the effectiveness of the RL framework in both noiseless and noisy quantum hardware environments, maintaining high accuracy in thermal state preparation. This work advances a scalable, RL-based framework with applications for quantum gravity studies and out-of-time-ordered thermal correlators computation in quantum many-body systems on near-term quantum hardware. The code is available at solving_SYK_with_RL repository.},
  archive      = {J_MLST},
  author       = {Akash Kundu},
  doi          = {10.1088/2632-2153/ade361},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025066},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Improving thermal state preparation of Sachdev–Ye–Kitaev model with reinforcement learning on quantum hardware},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Searching for ribbons with machine learning. <em>MLST</em>, <em>6</em>(2), 025065. (<a href='https://doi.org/10.1088/2632-2153/ade362'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We apply Bayesian optimization and reinforcement learning to a problem in topology: the question of when a knot bounds a ribbon disk. This question is relevant in an approach to disproving the four-dimensional smooth Poincaré conjecture; using our programs, we rule out many potential counterexamples to the conjecture. We also show that the programs are successful in detecting many ribbon knots in the range of up to 70 crossings.},
  archive      = {J_MLST},
  author       = {Sergei Gukov and James Halverson and Ciprian Manolescu and Fabian Ruehle},
  doi          = {10.1088/2632-2153/ade362},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025065},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Searching for ribbons with machine learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RegAL: Python package for active learning of regression problems. <em>MLST</em>, <em>6</em>(2), 025064. (<a href='https://doi.org/10.1088/2632-2153/addf11'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasingly more research areas rely on machine learning methods to accelerate discovery while saving resources. Machine learning models, however, usually require large datasets of experimental or computational results, which in certain fields—such as (bio)chemistry, materials science, or medicine—are rarely given and often prohibitively expensive to obtain. To bypass that obstacle, active learning methods are employed to develop machine learning models with a desired performance while requiring the least possible number of computational or experimental results from the domain of application. For this purpose, the model's knowledge about certain regions of the application domain is estimated to guide the choice of the model's training set. Although active learning is widely studied for classification problems (discrete outcomes), comparatively few works handle this method for regression problems (continuous outcomes). In this work, we present our Python package regAL , which allows users to evaluate different active learning strategies for regression problems. With a minimal input of just the dataset in question, but many additional customization and insight options, this package is intended for anyone who aims to perform and understand active learning in their problem-specific scope. Program summary Program title: regAL 1 Program source: https://doi.org/10.5281/zenodo.15309124 , https://git.rz.tu-bs.de/proppe-group/active-learning/regAL Programming language: Python 3+ Program dependencies: numpy, scikit-learn, matplotlib, pandas},
  archive      = {J_MLST},
  author       = {Elizaveta Surzhikova and Jonny Proppe},
  doi          = {10.1088/2632-2153/addf11},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025064},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {RegAL: Python package for active learning of regression problems},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning from topology: Cosmological parameter estimation from the large-scale structure. <em>MLST</em>, <em>6</em>(2), 025063. (<a href='https://doi.org/10.1088/2632-2153/ade114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The topology of the large-scale structure of the Universe contains valuable information on the underlying cosmological parameters. While persistent homology can extract this topological information, the optimal method for parameter estimation from the tool remains an open question. To address this, we propose a neural network model to map persistence images to cosmological parameters. Through a parameter recovery test, we demonstrate that our model makes accurate and precise estimates, considerably outperforming conventional Bayesian inference approaches.},
  archive      = {J_MLST},
  author       = {Jacky H T Yip and Adam Rouhiainen and Gary Shiu},
  doi          = {10.1088/2632-2153/ade114},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025063},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Learning from topology: Cosmological parameter estimation from the large-scale structure},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning for reparameterization of multi-scale closures. <em>MLST</em>, <em>6</em>(2), 025062. (<a href='https://doi.org/10.1088/2632-2153/add8de'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific machine learning (ML) is becoming increasingly useful in learning closure models for multi-scale physics problems; however, many ML approaches require a vast array of training data and can struggle with generalization and interpretability. Here, rather than learning an entire closure operator, we adopt an existing reduced-dimension model of the microphysics and learn an optimal re-parameterization of the solver. We demonstrate two approaches for training the reduced dimension closure model (1) an a priori method that optimizes the closure parameterization and the neural network parameters separately and (2) an a posteriori method that simultaneously optimizes both. Using the simulation of biomass pyrolysis as a motivating example, we show that the a posteriori method achieves better target losses and is less dependent on training dataset size for generalizability. We then demonstrate the impact that implementing this reparameterization has at the macroscale, showing improved predictive performance with no modification to the underlying macroscale solvers.},
  archive      = {J_MLST},
  author       = {Hilary Egan and Meagan Crowley and Hariswaran Sitaraman and Lila Branchaw and Peter Ciesielski},
  doi          = {10.1088/2632-2153/add8de},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025062},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine learning for reparameterization of multi-scale closures},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flow annealed importance sampling bootstrap meets differentiable particle physics. <em>MLST</em>, <em>6</em>(2), 025061. (<a href='https://doi.org/10.1088/2632-2153/addbc1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-energy physics requires the generation of large numbers of simulated data samples from complex but analytically tractable distributions called matrix elements. Surrogate models, such as normalizing flows, are gaining popularity for this task due to their computational efficiency. We adopt an approach based on flow annealed importance sampling bootstrap (FAB) that evaluates the differentiable target density during training and helps avoid the costly generation of training data in advance. We show that FAB reaches higher sampling efficiency with fewer target evaluations in high dimensions in comparison to other methods.},
  archive      = {J_MLST},
  author       = {Annalena Kofler and Vincent Stimper and Mikhail Mikhasenko and Michael Kagan and Lukas Heinrich},
  doi          = {10.1088/2632-2153/addbc1},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025061},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Flow annealed importance sampling bootstrap meets differentiable particle physics},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient prediction of aerodynamic forces in rarefied flow using convolutional neural network based multi-process method. <em>MLST</em>, <em>6</em>(2), 025060. (<a href='https://doi.org/10.1088/2632-2153/addf10'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The direct simulation Monte Carlo (DSMC) is a widely used approach for studying aerodynamics effects of rarefied flows, but it is highly time-consuming and may exhibit statistical fluctuations. In this study, we propose an efficient aerodynamic prediction method based on convolutional neural networks (CNNs) to further explore the application of deep learning in improving the efficiency of DSMC for calculating the aerodynamics of rarefied flows. The method includes centroid aerodynamics forces prediction (CFP) and surface aerodynamic forces distribution prediction (SFP), both of which are trained using a dataset of free molecular flow around obstacles derived from DSMC simulations. The SFP is designed to bridge the gap between flow field and surface forces, with two characteristics extraction methods developed specifically for this purpose. Additionally, two data preprocessing methods are designed to suppress the statistical noise inherent in DSMC simulations. Both CFP and SFP have demonstrated optimal performance in terms of accuracy and resistance to overfitting, achieving considerable predictive accuracy. The SFP exhibits a significant speedup, enabling real-time prediction of aerodynamic distributions from flow field. The results demonstrate that the proposed CNN-based approach offers a promising solution for the efficient calculation of aerodynamic forces in rarefied flows, and provide a robust foundation for ongoing development.},
  archive      = {J_MLST},
  author       = {Haifeng Huang and Guobiao Cai and Chuanfeng Wei and Baiyi Zhang and Xiang Cui and Yongjia Zhao and Huiyan Weng and Weizong Wang and Lihui Liu and Bijiao He},
  doi          = {10.1088/2632-2153/addf10},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025060},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Efficient prediction of aerodynamic forces in rarefied flow using convolutional neural network based multi-process method},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NCoder—a quantum field theory approach to encoding data. <em>MLST</em>, <em>6</em>(2), 025059. (<a href='https://doi.org/10.1088/2632-2153/ade04c'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a novel approach to interpretable AI inspired by quantum field theory which we call the NCoder . The NCoder is a modified autoencoder neural network whose latent layer is prescribed to be a subset of n -point correlation functions. Regarding images as draws from a lattice field theory, this architecture mimics the task of perturbatively constructing the effective action of the theory order by order in an expansion using Feynman diagrams. Alternatively, the NCoder may be regarded as simulating the procedure of statistical inference whereby high dimensional data is first summarized in terms of several lower dimensional summary statistics (here the n -point correlation functions), and subsequent out-of-sample data is generated by inferring the data generating distribution from these statistics. In this way the NCoder suggests a fascinating correspondence between perturbative renormalizability and the sufficiency of models. We demonstrate the efficacy of the NCoder by applying it to the generation of MNIST images, and find that generated images can be correctly classified using only information from the first three n -point functions of the image distribution.},
  archive      = {J_MLST},
  author       = {D S Berman and M S Klinger and A G Stapleton},
  doi          = {10.1088/2632-2153/ade04c},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025059},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {NCoder—a quantum field theory approach to encoding data},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning for detection of equivariant finite symmetry groups in dynamical systems. <em>MLST</em>, <em>6</em>(2), 025058. (<a href='https://doi.org/10.1088/2632-2153/ade04d'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we introduce the equivariance seeker model (ESM), a data-driven method for discovering the underlying finite equivariant symmetry group of an arbitrary function. ESM achieves this by optimizing a loss function that balances equivariance preservation with the penalization of redundant solutions, ensuring the complete and accurate identification of all symmetry transformations. We apply this framework specifically to dynamical systems, identifying their symmetry groups directly from observed trajectory data. To demonstrate its versatility, we test ESM on multiple systems in two distinct scenarios: (i) when the governing equations are known theoretically and (ii) when they are unknown, and the equivariance finding relies solely on observed data. The latter case highlights ESM's fully data-driven capability, as it requires no prior knowledge of the system's equations to operate.},
  archive      = {J_MLST},
  author       = {Pablo Calvo-Barlés and Sergio G Rodrigo and Luis Martín-Moreno},
  doi          = {10.1088/2632-2153/ade04d},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025058},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine learning for detection of equivariant finite symmetry groups in dynamical systems},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving generative inverse design of molecular catalysts in small data regime. <em>MLST</em>, <em>6</em>(2), 025057. (<a href='https://doi.org/10.1088/2632-2153/addc32'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep generative models are a powerful tool for exploring the chemical space within inverse-design workflows; however, their effectiveness relies on sufficient training data and effective mechanisms for guiding the model to optimize specific properties. We demonstrate that designing an expert-informed data representation and training procedure allows leveraging data augmentation while maintaining the required sampling controllability. We focus our discussion on a specific class of compounds (transition metal complexes), and a popular class of generative models (equivariant diffusion models), although we envision that the approach could be extended to other chemical spaces and model types. Through experiments, we demonstrate that augmenting the training database with generic but related unlabeled data enables a practical level of performance to be reached.},
  archive      = {J_MLST},
  author       = {François Cornet and Pratham Deshmukh and Bardi Benediktsson and Mikkel N Schmidt and Arghya Bhowmik},
  doi          = {10.1088/2632-2153/addc32},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025057},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Improving generative inverse design of molecular catalysts in small data regime},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A theoretical perspective on mode collapse in variational inference. <em>MLST</em>, <em>6</em>(2), 025056. (<a href='https://doi.org/10.1088/2632-2153/adde2a'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While deep learning has expanded the possibilities for highly expressive variational families, the practical benefits of these tools for variational inference (VI) are often limited by the minimization of the traditional Kullback–Leibler objective, which can yield suboptimal solutions. A major challenge in this context is mode collapse : the phenomenon where a model concentrates on a few modes of the target distribution during training, despite being statistically capable of expressing them all. In this work, we carry a theoretical investigation of mode collapse for the gradient flow on Gaussian mixture models. We identify the key low-dimensional statistics characterizing the flow, and derive a closed set of low-dimensional equations governing their evolution. Leveraging this compact description, we show that mode collapse is present even in statistically favorable scenarios, and identify two key mechanisms driving it: mean alignment and vanishing weight. Our theoretical findings are consistent with the implementation of VI using normalizing flows, a class of popular generative models, thereby offering practical insights.},
  archive      = {J_MLST},
  author       = {Roman Soletskyi and Marylou Gabrié and Bruno Loureiro},
  doi          = {10.1088/2632-2153/adde2a},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025056},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A theoretical perspective on mode collapse in variational inference},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient autoencoder pipeline for discovering high entropy alloys with molecular dynamics data. <em>MLST</em>, <em>6</em>(2), 025055. (<a href='https://doi.org/10.1088/2632-2153/addf0f'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we utilize computationally efficient molecular dynamics simulations to create a machine learning pipeline for discovery of crystalline multi-component alloys. We employ high-quality interatomic potentials to create a dataset of NiFeCr structures and apply crystal diffusion variational autoencoder to maximize their mechanical properties, i.e. bulk modulus. As part of the experiment, we utilize local search coupled with classical interatomic potentials to explore the local structure space and show that utilization of this procedure greatly improves optimization capability of the neural model. We also expand the model with an extra submodule, which attains 42% improvement on modeling the crystalline phase of the structures. Ultimately, we verify the global stability of the created structures with quantum mechanical calculation methods.},
  archive      = {J_MLST},
  author       = {Amirhossein D Naghdi and Grzegorz Kaszuba and Stefanos Papanikolaou and Andrzej Jaszkiewicz and Piotr Sankowski},
  doi          = {10.1088/2632-2153/addf0f},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025055},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Efficient autoencoder pipeline for discovering high entropy alloys with molecular dynamics data},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretation of chemical reaction yields with graph neural additive network. <em>MLST</em>, <em>6</em>(2), 025054. (<a href='https://doi.org/10.1088/2632-2153/addfaa'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction of chemical yields is crucial for exploring untapped chemical reactions and optimizing synthetic pathways for targeted compounds. Recently, graph neural networks have proven successful in achieving high predictive accuracy. However, they remain intrinsically black-box models, offering limited interpretability. Understanding how each reaction component contributes to the yield of a chemical reaction can help identify critical factors driving the success or failure of reactions, thereby potentially revealing opportunities for yield optimization. In this study, we present a novel method for interpretable chemical reaction yield prediction, which represents the yield of a chemical reaction as a simple summation of component-wise contributions from individual reaction components. To build an interpretable prediction model, we introduce a graph neural additive network architecture, wherein shared neural networks process individual reaction components in an input reaction while leveraging a reaction-level embedding to derive their respective contributions. The predicted yield is obtained by summing these component-wise contributions. The model is trained using a learning objective designed to effectively quantify the contributions of individual components by amplifying the influence of significant components and suppressing that of less influential components. The experimental results on benchmark datasets demonstrated that the proposed method achieved both high predictive accuracy and interpretability, making it suitable for practical use in synthetic pathway design for real-world applications.},
  archive      = {J_MLST},
  author       = {Youngchun Kwon and Yongsik Jung and Youn-Suk Choi and Seokho Kang},
  doi          = {10.1088/2632-2153/addfaa},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025054},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Interpretation of chemical reaction yields with graph neural additive network},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). First-passage approach to optimizing perturbations for improved training of machine learning models. <em>MLST</em>, <em>6</em>(2), 025053. (<a href='https://doi.org/10.1088/2632-2153/add8df'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models have become indispensable tools in applications across the physical sciences. Their training is often time-consuming, vastly exceeding the inference timescales. Several protocols have been developed to perturb the learning process and improve the training, such as shrink and perturb, warm restarts, and stochastic resetting. For classifiers, these perturbations have been shown to result in enhanced speedups or improved generalization. However, the design of such perturbations is usually done ad hoc by intuition and trial and error. To rationally optimize training protocols, we frame them as first-passage processes and consider their response to perturbations. We show that if the unperturbed learning process reaches a quasi-steady state, the response at a single perturbation frequency can predict the behavior at a wide range of frequencies. We employ this approach to a CIFAR-10 classifier using the ResNet-18 model and identify a useful perturbation and frequency among several possibilities. We demonstrate the transferability of the approach to other datasets, architectures, optimizers and even tasks (regression instead of classification). Our work allows optimization of perturbations for improving the training of machine learning models using a first-passage approach.},
  archive      = {J_MLST},
  author       = {Sagi Meir and Tommer D Keidar and Shlomi Reuveni and Barak Hirshberg},
  doi          = {10.1088/2632-2153/add8df},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025053},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {First-passage approach to optimizing perturbations for improved training of machine learning models},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Density estimation via binless multidimensional integration. <em>MLST</em>, <em>6</em>(2), 025052. (<a href='https://doi.org/10.1088/2632-2153/add3bc'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the binless multidimensional thermodynamic integration (BMTI) method for nonparametric, robust, and data-efficient density estimation. BMTI estimates the logarithm of the density by initially computing log-density differences between neighbouring data points. Subsequently, such differences are integrated, weighted by their associated uncertainties, using a maximum-likelihood formulation. This procedure can be seen as an extension to a multidimensional setting of the thermodynamic integration , a technique developed in statistical physics. The method leverages the manifold hypothesis, estimating quantities within the intrinsic data manifold without defining an explicit coordinate map. It does not rely on any binning or space partitioning, but rather on the construction of a neighbourhood graph based on an adaptive bandwidth selection procedure. BMTI mitigates the limitations commonly associated with traditional nonparametric density estimators, effectively reconstructing smooth profiles even in high-dimensional embedding spaces. The method is tested on a variety of complex synthetic high-dimensional datasets, where it is shown to outperform traditional estimators, and is benchmarked on realistic datasets from the chemical physics literature.},
  archive      = {J_MLST},
  author       = {Matteo Carli and Alex Rodriguez and Alessandro Laio and Aldo Glielmo},
  doi          = {10.1088/2632-2153/add3bc},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025052},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Density estimation via binless multidimensional integration},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VISION: A modular AI assistant for natural human-instrument interaction at scientific user facilities. <em>MLST</em>, <em>6</em>(2), 025051. (<a href='https://doi.org/10.1088/2632-2153/add9e4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific user facilities, such as synchrotron beamlines, are equipped with a wide array of hardware and software tools that require a codebase for human-computer-interaction. This often necessitates developers to be involved to establish connection between users/researchers and the complex instrumentation. The advent of generative AI presents an opportunity to bridge this knowledge gap, enabling seamless communication and efficient experimental workflows. Here we present a modular architecture for the Vi rtual S cientific Compan ion by assembling multiple AI-enabled cognitive blocks that each scaffolds large language models (LLMs) for a specialized task. With VISION, we performed LLM-based operation on the beamline workstation with low latency and demonstrated the first voice-controlled experiment at an x-ray scattering beamline. The modular and scalable architecture allows for easy adaptation to new instruments and capabilities. Development on natural language-based scientific experimentation is a building block for an impending future where a science exocortex—a synthetic extension to the cognition of scientists—may radically transform scientific practice and discovery.},
  archive      = {J_MLST},
  author       = {Shray Mathur and Noah van der Vleuten and Kevin G Yager and Esther H R Tsai},
  doi          = {10.1088/2632-2153/add9e4},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025051},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {VISION: A modular AI assistant for natural human-instrument interaction at scientific user facilities},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven thrust prediction in applied-field magnetoplasmadynamic thrusters for space missions using artificial intelligence-based models. <em>MLST</em>, <em>6</em>(2), 025050. (<a href='https://doi.org/10.1088/2632-2153/addb06'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustainability in space is now the centre of attention for different space research organisations given the scale of current investment in planetary search activities, ambitious plans for habitation in future, and focus on electric space propulsion systems. One potential propulsive means for future spacecraft is the applied-field magnetoplasmadynamic thruster (AF-MPDT). This type of thruster uses the principle of the Lorentz force, where ionized gas is propelled through the interaction of a current and a magnetic field. These thrusters are characterized by nonlinear and complex interaction between controllable parameters, such as current and magnetic field, and structural attributes like part dimensions including anode and cathode radii. Consequently, traditional empirical modelling approaches have encountered challenges in predicting certain outputs, such as thrust, with sufficient precision across different operational regimes. As an alternative to analytical/empirical formulas that approximate the true physics only partially, this paper demonstrates the potential of artificial intelligence (AI) techniques to predict thrust in AF-MPDTs. Through training and meticulous hyperparameter tuning, this study compares 7 different AI models fed with experimental data from 21 thrusters and their different configurations, reaching a total of 58 thruster designs, spanning decades of thruster research and development work. Results indicate that the supervised ensemble algorithm, eXtreme Gradient Boosting (XGBoost), outperforms all other utilized techniques such as random forest, Gradient Boosting Regressor, support vector regression, kernel ridge regression, K-nearest neighbors, and Gaussian process regression. With a Goodness of Fit ( R 2 ) of 98.55%, root mean square error of 1.421 N, and mean absolute error of 0.453 N, XGBoost specifically, and AI in general, has demonstrated its superiority, by significantly improving on the accuracy of previously published empirical models for AF-MPDT thrust prediction. Additionally, the fast response associated with these techniques further expands their applicability to real-time data operation or to being used as a subroutine in thruster design procedure. This can potentially become a fundamental component of AF-MPDT designing software, whereby it may be used to check a configuration's functionality, applicability and feasibility all in a few milliseconds. This data-driven approach can be helpful in upscaling or specially down-scaling AF-MPDTs to make them better suited for many lower power space applications.},
  archive      = {J_MLST},
  author       = {Tarik Pinaffo Almeida and Shahin Alipour Bonab and Mohammad Yazdani-Asrami},
  doi          = {10.1088/2632-2153/addb06},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025050},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Data-driven thrust prediction in applied-field magnetoplasmadynamic thrusters for space missions using artificial intelligence-based models},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards arbitrary QUBO optimization: Analysis of classical and quantum-activated feedforward neural networks. <em>MLST</em>, <em>6</em>(2), 025049. (<a href='https://doi.org/10.1088/2632-2153/addb97'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quadratic unconstrained binary optimization (QUBO) is at the heart of many industries and academic fields such as logistics, supply chain, finance, pharmaceutical science, chemistry, IT, and energy sectors, among others (Bangert 2012 Optimization for Industrial Problems (Springer Science & Business Media)). These problems typically involve optimizing a large number of binary variables, which makes finding exact solutions exponentially more difficult. Consequently, most QUBO problems are classified as NP-hard (Garey and Johnson 1979 Computers and Intractability vol 174 (Freeman); Lucas 2014 Front. Phys. 2 5). To address this challenge, we developed a powerful feedforward neural network (FNN) optimizer for arbitrary QUBO problems. In this work, we demonstrate that the FNN optimizer can provide high-quality approximate solutions for large problems, including dense 80-variable weighted MaxCut and random QUBOs, achieving an average accuracy of over 99% in less than 1.1 s on an 8-core CPU. Additionally, the FNN optimizer outperformed the Gurobi optimizer (Gurobi Optimization, LLC 2023 Gurobi Optimizer Reference Manual) by 72% on 200-variable random QUBO problems within a 100 s computation time limit, exhibiting strong potential for real-time optimization tasks. Building on this model, we explored the novel approach of integrating FNNs with a quantum annealer-based activation function to create a quantum–classical encoder–decoder optimizer, aiming to further enhance the performance of FNNs in QUBO optimization.},
  archive      = {J_MLST},
  author       = {Chia-Tso Lai and Carsten Blank and Peter Schmelcher and Rick Mukherjee},
  doi          = {10.1088/2632-2153/addb97},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025049},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Towards arbitrary QUBO optimization: Analysis of classical and quantum-activated feedforward neural networks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WEISS: Wasserstein efficient sampling strategy for LLMs in drug design. <em>MLST</em>, <em>6</em>(2), 025048. (<a href='https://doi.org/10.1088/2632-2153/addc33'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autoregressive models have gained popularity in the field of drug design due to their capability to sample novel molecules from a vast chemical space efficiently. Sampling novel and diverse molecules in an efficient manner is a crucial aspect, as it is important for downstream tasks such as reinforcement learning to identify novel molecules with pre-defined desired properties. Existing sampling strategies like multinomial sampling and beam search often struggle with mode collapses or are computational inefficient, respectively. To address these limitations, we introduce WEISS (Wasserstein efficient sampling strategy), a framework that seamlessly enables autoregressive models to efficiently sample diverse molecules. Our approach, which draws inspiration from the Wasserstein autoencoder, is compatible with any encoder–decoder-based autoregressive model. We show that WEISS effectively mitigates mode collapsing while maintaining token sampling speed 25 times faster than beam search. Secondly, we showcase the efficacy of the proposed method for various drug design tasks such as molecular property optimization and single-step retrosynthesis prediction.},
  archive      = {J_MLST},
  author       = {Riccardo Tedoldi and Junyong Li and Ola Engkvist and Andrea Passerini and Annie M Westerlund and Alessandro Tibo},
  doi          = {10.1088/2632-2153/addc33},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {025048},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {WEISS: Wasserstein efficient sampling strategy for LLMs in drug design},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The OpenLAM challenges: LAM crystal philately competition. <em>MLST</em>, <em>6</em>(2), 020701. (<a href='https://doi.org/10.1088/2632-2153/add3bf'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the success of large language models, the development of large atomistic models (LAMs) has rapidly gained momentum in scientific computation. Since 2022, the Deep Potential team has been actively pretraining LAMs and launched the OpenLAM Initiative, which advocates for creating a community-driven platform aimed at accelerating the development of open-source foundation models by sharing curated datasets, algorithms, and relevant workflows. As part of the OpenLAM Initiative, the OpenLAM Challenges are competitions designed to benchmark atomic modeling methods, encourage community collaboration, and accelerate advances in machine learning-driven scientific discovery. The LAM Crystal Philately competition, as an example, aims to construct an open-source database of crystal structures by collecting unique configurations with arbitrary chemical compositions. During the competition, structures submitted by participants are validated by an LAM based on energy and force criteria, and their stabilities are assessed using the OpenLAM convex hull derived from all structures within the database. The first round of the LAM Crystal Philately competition has collected over 19.8 million valid structures, including approximately 350 000 on the OpenLAM convex hull, driving advancements in generative modeling and materials science applications.},
  archive      = {J_MLST},
  author       = {Anyang Peng and Xinzijian Liu and Ming-Yu Guo and Linfeng Zhang and Han Wang},
  doi          = {10.1088/2632-2153/add3bf},
  journal      = {Machine Learning: Science and Technology},
  month        = {6},
  number       = {2},
  pages        = {020701},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {The OpenLAM challenges: LAM crystal philately competition},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Path-minimizing latent ODEs for improved extrapolation and inference. <em>MLST</em>, <em>6</em>(2), 025047. (<a href='https://doi.org/10.1088/2632-2153/addc34'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Latent ordinary differential equation (ODE) models provide flexible descriptions of dynamic systems, but they can struggle with extrapolation and predicting complicated non-linear dynamics. The latent ODE approach implicitly relies on encoders to identify unknown system parameters and initial conditions (ICs), whereas the evaluation times are known and directly provided to the ODE solver. This dichotomy can be exploited by encouraging time-independent latent representations. By replacing the common variational penalty in latent space with an \ell_2 penalty on the path length of each system, the models learn data representations that can easily be distinguished from those of systems with different configurations. This results in faster training, smaller models, more accurate interpolation and long-time extrapolation compared to the baseline ODE models with a gated recurent unit (GRU), recurrent neural network, and long-short-term-memory encoder/decoders on tests with damped harmonic oscillator, self-gravitating fluid, and predator-prey systems. We also demonstrate superior results for simulation-based inference of the Lotka–Volterra parameters and ICs by using the latents as data summaries for a conditional normalizing flow. Our change to the training loss is agnostic to the specific recognition network used by the decoder and can therefore easily be adopted by other latent ODE models.},
  archive      = {J_MLST},
  author       = {Matt L Sampson and Peter Melchior},
  doi          = {10.1088/2632-2153/addc34},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025047},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Path-minimizing latent ODEs for improved extrapolation and inference},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An information theoretic limit to data amplification. <em>MLST</em>, <em>6</em>(2), 025046. (<a href='https://doi.org/10.1088/2632-2153/add78d'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years generative artificial intelligence has been used to create data to support scientific analysis. For example, generative adversarial networks (GANs) have been trained using Monte Carlo simulated input and then used to generate data for the same problem. This has the advantage that a GAN creates data in a significantly reduced computing time. N training events for a GAN can result in NG generated events with the gain factor G being greater than one. This appears to violate the principle that one cannot get information for free. This is not the only way to amplify data so this process will be referred to as data amplification which is studied using information theoretic concepts. It is shown that a gain greater than one is possible whilst keeping the information content of the data unchanged. This leads to a mathematical bound, 2\log (\text{Generated}\ \text{Events}) \unicode{x2A7E} {\text{3log(Training Events)}} , which only depends on the number of generated and training events. This study determined the conditions for both the underlying and reconstructed probability distributions to ensure this bound. In particular, the resolution of variables in amplified data is not improved by the process but the increase in sample size can still improve statistical significance. The bound was confirmed using computer simulation and analysis of GAN generated data from the literature.},
  archive      = {J_MLST},
  author       = {S J Watts and L Crow},
  doi          = {10.1088/2632-2153/add78d},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025046},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {An information theoretic limit to data amplification},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermal damage detection of EAST internal component based on machine learning. <em>MLST</em>, <em>6</em>(2), 025045. (<a href='https://doi.org/10.1088/2632-2153/addbc2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the discharge process, thermal events are common and destructive in Tokamak experiments. High energy particles in plasma can collide with device components such as limiters and diverters, which can lead to overheating, material cracking, and even damage to the structure of the device. Therefore, we need efficient detection methods to monitor thermal events in real-time. To address the challenge of identifying thermal damage to internal components of the first wall during the Experimental Advanced Superconducting Tokamak (EAST) discharges, we introduce the YOLOv8 model for hotspot detection on EAST and present the customized EAST- You Only Look Once (YOLO) algorithm, derived from an enhanced YOLOv8 framework. YOLOv8, known for its strong performance in real-time object detection, serves as a robust base model for this task. However, its performance on small object detection, such as early-stage thermal damage, is limited. Improvements are needed for specialized tasks, particularly for early warning and precise identification of small internal component damage during the initial stages of EAST discharges. we enhance the YOLOv8 model by incorporating specialized layers for detecting small targets and integrating the CBAM attention mechanism. These adjustments result in a network model capable of sensitively detecting internal component damage in EAST. Experimental results demonstrate that EAST-YOLO surpasses several versions of traditional YOLOv8 models in model evaluation metrics, achieving a precision of 97.5%, mAP50 of 97.7%, and a Recall of 94.0%. This problem- oriented approach significantly improves the operational safety and stability of the EAST device by enabling early detection of thermal events. The AI-based detection method provides a new solution to safeguarding the fusion device, while also offering potential avenues for integrating artificial intelligence technologies into EAST feedback control and operating systems in the future.},
  archive      = {J_MLST},
  author       = {Zhongfang Guan and Bin Zhang and Jian Liu and Jinping Qian and Xianzu Gong and Runze Chen and Zuhao Wang and Binfu Gao and Yutong Guo and Chuannan Xuan and Cong Cao and Tianqi Jia and Pan Li and Wenbin Liu and Wei Wang and Yunchan Hu and Yifan He and Kangjia Yang and Wenyi Lu and Chunyu He and the EAST team},
  doi          = {10.1088/2632-2153/addbc2},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025045},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Thermal damage detection of EAST internal component based on machine learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable autoencoder for neutron star dense matter parameter estimation. <em>MLST</em>, <em>6</em>(2), 025044. (<a href='https://doi.org/10.1088/2632-2153/add3bd'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a physics-informed autoencoder (AE) designed to encode the equation of state of neutron stars into an interpretable latent space. In particular the input will be encoded in the mass, radius, and tidal deformability values of a neutron star. Unlike traditional black-box models, our approach incorporates additional loss functions to enforce explainability in the encoded representations. This method enhances the transparency of machine learning models in physics, providing a robust proof-of-concept tool to study compact stars data. Our results demonstrate that the proposed AE not only accurately estimates the equation of state parameters and central density/pressure but also offers insights into the physical connection between equation of state and observable physical quantities. This framework conceptualizes the physical differential equations themselves as the 'encoders', allowing interpretability of the latent space.},
  archive      = {J_MLST},
  author       = {Francesco Di Clemente and Matteo Scialpi and Michał Bejger},
  doi          = {10.1088/2632-2153/add3bd},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025044},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Explainable autoencoder for neutron star dense matter parameter estimation},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiscale bayesian approach to quantification and denoising of energy-dispersive x-ray data. <em>MLST</em>, <em>6</em>(2), 025043. (<a href='https://doi.org/10.1088/2632-2153/add8e1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy dispersive x-ray (EDX) spectrum imaging yields compositional information with a spatial resolution down to the atomic level. However, experimental limitations often produce extremely sparse and noisy EDX spectra. Under such conditions, every detected x-ray must be leveraged to obtain the maximum possible amount of information about the sample. To this end, we introduce a robust multiscale Bayesian approach that accounts for the Poisson statistics in the EDX data and leverages their underlying spatial correlations. This is combined with EDX spectral simulation (elemental contributions and Bremsstrahlung background) into a Bayesian estimation strategy. When tested using simulated datasets, the chemical maps obtained with this approach are more accurate and preserve a higher spatial resolution than those obtained by standard methods. These properties translate to experimental datasets, where the method enhances the atomic resolution chemical maps of a canonical tetragonal ferroelectric PbTiO 3 sample, such that ferroelectric domains are mapped with unit-cell resolution.},
  archive      = {J_MLST},
  author       = {Pau Torruella and Abderrahim Halimi and Ludovica Tovaglieri and Céline Lichtensteiger and Duncan T L Alexander and Cécile Hébert},
  doi          = {10.1088/2632-2153/add8e1},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025043},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A multiscale bayesian approach to quantification and denoising of energy-dispersive x-ray data},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-target property prediction and optimization using latent spaces of generative model. <em>MLST</em>, <em>6</em>(2), 025042. (<a href='https://doi.org/10.1088/2632-2153/add8e0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-target property prediction has the potential to improve generalization by exploiting the positive transfer between targets. Molecular generative models utilize independent single-target property prediction networks to discover novel molecules. We propose using multi-target networks to jointly predict several molecular properties and learn better representations by exploiting auxiliary information. Our multi-target model shows improvement in prediction accuracy on the test set. We additionally present results demonstrating promising performance in property prediction in these generative models does not translate to optimization. More specifically, random exploration is competitive with gradient-based strategies and better methods are needed.},
  archive      = {J_MLST},
  author       = {Anirudh Jain and Markus Heinonen and Heikki Käsnänen and Julius Sipilä and Samuel Kaski},
  doi          = {10.1088/2632-2153/add8e0},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025042},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Multi-target property prediction and optimization using latent spaces of generative model},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting high-impact research topics via machine learning on evolving knowledge graphs. <em>MLST</em>, <em>6</em>(2), 025041. (<a href='https://doi.org/10.1088/2632-2153/add6ef'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth in scientific publications poses a severe challenge for human researchers. It forces attention to more narrow sub-fields, which makes it challenging to discover new impactful research ideas and collaborations outside one's own field. While there are ways to predict a scientific paper's future citation counts, they need the research to be finished and the paper written, usually assessing impact long after the idea was conceived. Here we show how to predict the impact of onsets of ideas that have never been published by researchers. For that, we developed a large evolving knowledge graph built from more than 21 million scientific papers. It combines a semantic network created from the content of the papers and an impact network created from the historic citations of papers. Using machine learning, we can predict the dynamic of the evolving network into the future with high accuracy (AUC values beyond 0.9 for most experiments), and thereby the impact of new research directions. We envision that the ability to predict the impact of new ideas will be a crucial component of future artificial muses that can inspire new impactful and interesting scientific ideas.},
  archive      = {J_MLST},
  author       = {Xuemei Gu and Mario Krenn},
  doi          = {10.1088/2632-2153/add6ef},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025041},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Forecasting high-impact research topics via machine learning on evolving knowledge graphs},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the nexus of many-body theories through neural network techniques: The tangent model. <em>MLST</em>, <em>6</em>(2), 025040. (<a href='https://doi.org/10.1088/2632-2153/add78c'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a physically informed neural network (NN) representation of the effective interactions associated with coupled-cluster downfolding models to describe chemical systems and processes. The NN representation not only allows us to evaluate the effective interactions efficiently for various geometrical configurations of chemical systems corresponding to various levels of complexity of the underlying wave functions, but also reveals that the bare and effective interactions are related by a tangent function of some latent variables. We refer to this characterization of the effective interaction as a tangent model. We discuss the connection between this tangent model for the effective interaction with the previously developed theoretical analysis that examines the difference between the bare and effective Hamiltonians in the corresponding active spaces.},
  archive      = {J_MLST},
  author       = {Senwei Liang and Karol Kowalski and Chao Yang and Nicholas P Bauman},
  doi          = {10.1088/2632-2153/add78c},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025040},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Exploring the nexus of many-body theories through neural network techniques: The tangent model},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shuffle window transformer DeepLabV3+: A lightweight convolutional neural network and transformer based hybrid semantic segmentation network. <em>MLST</em>, <em>6</em>(2), 025039. (<a href='https://doi.org/10.1088/2632-2153/add853'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation is a critical task in computer vision. Constructing complex semantic segmentation models with high accuracy, low spatial occupancy, and low computational complexity remains a challenge. To address this, this paper proposes a semantic segmentation network based on a hybrid architecture of convolutional neural network and Transformer, named shuffle window transformer DeeplabV3+ (SWT-DeepLabV3+). The network introduces a new module, called the SWT. When the window size is fixed, by integrating window attention (WA) and shuffle WA mechanisms, cross-window global context modeling with linear computational complexity is achieved. Additionally, we enhance the atrous spatial pyramid pooling (ASPP) by incorporating strip pooling to construct a strip ASPP, effectively extracting both regular and irregular multi-scale (MS) features. Simultaneously, the network adopts adaptive spatial feature fusion in the shallow layers. Dynamic adjustment of MS feature weights improves the backbone network's ability to capture shallow discriminative features. Experimental results demonstrate that on three public datasets (PASCAL VOC 2012, Cityscapes, and CamVid), SWT-DeepLabV3+ exhibits outstanding segmentation performance under conditions of lower parameter count and computational cost, validating the model's capability to achieve efficient processing while maintaining high accuracy.},
  archive      = {J_MLST},
  author       = {Yane Li and Zhichao Chen and Hongxia Qi and Ming Fan and Lihua Li},
  doi          = {10.1088/2632-2153/add853},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025039},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Shuffle window transformer DeepLabV3+: A lightweight convolutional neural network and transformer based hybrid semantic segmentation network},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wilsonian renormalization of neural network gaussian processes*. <em>MLST</em>, <em>6</em>(2), 025038. (<a href='https://doi.org/10.1088/2632-2153/adc8fc'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Separating relevant and irrelevant information is key to any modeling process or scientific inquiry. Theoretical physics offers a powerful tool for achieving this in the form of the renormalization group (RG). Here we demonstrate a practical approach to performing Wilsonian RG in the context of Gaussian Process (GP) Regression. We systematically integrate out the unlearnable modes of the GP kernel, thereby obtaining an RG flow of the GP in which the data sets the IR scale. In simple cases, this results in a universal flow of the ridge parameter, which becomes input-dependent in the richer scenario in which non-Gaussianities are included. In addition to being analytically tractable, this approach goes beyond structural analogies between RG and neural networks by providing a natural connection between RG flow and learnable vs. unlearnable modes. Studying such flows may improve our understanding of feature learning in deep neural networks, and enable us to identify potential universality classes in these models.},
  archive      = {J_MLST},
  author       = {Jessica N Howard and Ro Jefferson and Anindita Maiti and Zohar Ringel},
  doi          = {10.1088/2632-2153/adc8fc},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025038},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Wilsonian renormalization of neural network gaussian processes*},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal spectroscopic measurement design: Bayesian framework for rational data acquisition. <em>MLST</em>, <em>6</em>(2), 025037. (<a href='https://doi.org/10.1088/2632-2153/add0f6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an optimal experimental design method for spectroscopic measurements that can determine the appropriate number and placement of measurement points in a rational manner. Spectroscopic measurements are fundamental for material characterization. It is essential to determine the optimal experimental conditions in an automated, mathematically guaranteed manner for rational and autonomous experiments; however, these conditions have traditionally been determined on the basis of the intuition of human experts. In this work, we developed a method for extracting prior information from a standard spectral database and incorporating it into the Bayesian experimental design framework to determine the optimal measurement points automatically. We verified the proposed method by applying it to x-ray absorption spectrum measurements and evaluated its optimality through conventional analysis. We found that only 70% of the measurement points used in previous studies were sufficient and that the obtained points are consistent with the experts' intuition. The proposed method is expected to enable more rational and efficient fully automated experiments in the future.},
  archive      = {J_MLST},
  author       = {Yusei Ito and Yasuo Takeichi and Hideitsu Hino and Kanta Ono},
  doi          = {10.1088/2632-2153/add0f6},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025037},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Optimal spectroscopic measurement design: Bayesian framework for rational data acquisition},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Img2Neuro: Brain-trained neural activity encoders for enhanced object recognition. <em>MLST</em>, <em>6</em>(2), 025036. (<a href='https://doi.org/10.1088/2632-2153/add3be'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For decades, the brain's visual pathway has inspired machine and deep learning models, yet these models oversimplify the brain's complex visual processing. This is manifested in the significant superiority of the brain in comparison to the developed models in terms of the accuracy and the amount of data needed for training. Therefore, rather than using the brain as an inspiration, in this paper, we introduce Img2Neuro; a convolutional neural network model feature extractor that predicts the visual brain's response to images by encoding neural activity. Img2Neuro is trained on natural scene images paired with single-neuron recordings from the visual cortex and thalamus of mice and monkeys. We explore the feasibility of using Img2Neuro as a feature extractor for object recognition, where the output of Img2Neuro in response to unseen images is used as input to classifiers with the task of recognizing the object in the image. We evaluated our approach on three benchmark datasets; namely, MNIST, Fashion-MNIST, and Cifar10. In our experiments, we examined the classification performance when Img2Neuro is used as a feature extractor compared to using the images as direct input to the classifier, using five different classifiers; namely, linear discriminant analysis, perceptron, logistic regression, ridge classifier, and a single-layer neural network. The results demonstrate superior performance when using Img2Neuro in most datasets and across all classifiers, reaching an enhancement in accuracy of 9% on the MNIST dataset, 2% on FashionMNIST, and 18% on Cifar10 in some cases compared to using raw images as an input in the classifiers. The performance enhancements suggest that brain-trained encoders can effectively capture image features for object recognition tasks. By leveraging neural response data, Img2Neuro demonstrates a promising avenue for bridging the gap between biological and artificial visual processing, ultimately leading to novel strategies for improving state-of-the-art object recognition models.},
  archive      = {J_MLST},
  author       = {Mona A Aboelnaga and Mohamed W El-Kharashi and Seif Eldawlatly},
  doi          = {10.1088/2632-2153/add3be},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025036},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Img2Neuro: Brain-trained neural activity encoders for enhanced object recognition},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural signatures of depression: Classifying drug-naïve MDD patients with time- and frequency-domain EEG features during emotional processing. <em>MLST</em>, <em>6</em>(2), 025035. (<a href='https://doi.org/10.1088/2632-2153/add4bb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate classification of major depressive disorder (MDD) remains a significant challenge, particularly because of the confounding effect of medications. This study bridges this gap by focusing on the classification of drug-naïve individuals diagnosed with MDD and healthy controls (HCs) using electroencephalogram (EEG) data recorded during emotional processing tasks. This study involved 14 HCs and 14 drug-naïve individuals diagnosed with MDD (aged 18–31, 12+ years of education, 12 F/2 M). The participants were presented with positive, neutral, and negative images collected from the International Affective Picture System. The mean power amplitudes of event-related potentials (ERP), including the P200, P300, early, middle, and late components of the late positive potential (LPP), were computed, along with band power features, and used as features for classifiers. A support vector machine model was employed for classification to evaluate the individual contributions of ERP components and band power features and explore the combined effects of ERP components and band power features within themselves. The alpha band power achieved the highest individual classification accuracy among the band power features for negative stimuli (92.86%). The late LPP component was the most discriminative ERP component for positive stimuli, yielding an accuracy rate of 89.29%. Combined analysis of the band power features exhibited high accuracy for both positive and negative stimuli (92.86% each). When the ERP components were combined, the classifier achieved the highest accuracy of 89.29% for both negative and neutral stimuli. Our findings suggest that alpha band power and LPP responses to negative and positive stimuli, respectively, can be used to detect MDD. The comparable performance of individual features to that of the combined feature sets indicates their strength as indicators of emotional processing in MDD. These findings provide valuable insights into the development of more reliable diagnostic tools and treatment monitoring strategies that focus on emotional processing in MDD.},
  archive      = {J_MLST},
  author       = {Bernis Sütçübaşı and Tuğçe Ballı and Barış Metin and Emine Elif Tülay},
  doi          = {10.1088/2632-2153/add4bb},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025035},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Neural signatures of depression: Classifying drug-naïve MDD patients with time- and frequency-domain EEG features during emotional processing},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Driving enhanced exciton transfer by automatic differentiation. <em>MLST</em>, <em>6</em>(2), 025034. (<a href='https://doi.org/10.1088/2632-2153/add23b'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We model and study the processes of excitation, absorption, and transfer in various networks. The model consists of a harmonic oscillator representing a single-mode radiation field, a two-level system acting as an antenna, a network through which the excitation propagates, and another two-level system at the end serving as a sink. We investigate how off-resonant excitations can be optimally absorbed and transmitted through the network. Three strategies are considered: optimising network energies, adjusting the couplings between the radiation field, the antenna, and the network, or introducing and optimising driving fields at the start and end of the network. These strategies are tested on three different types of network with increasing complexity: nearest-neighbour and star configurations, and one associated with the Fenna–Matthews–Olson complex. The results show that, among the various strategies, the introduction of driving fields is the most effective, leading to a significant increase in the probability of reaching the sink in a given time. This result remains stable across networks of varying dimensionalities and types, and the driving process requires only a few parameters to be effective.},
  archive      = {J_MLST},
  author       = {E Ballarin and D A Chisholm and A Smirne and M Paternostro and F Anselmi and S Donadi},
  doi          = {10.1088/2632-2153/add23b},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025034},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Driving enhanced exciton transfer by automatic differentiation},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature extraction and classification of digital rock images via pre-trained convolutional neural network and unsupervised machine learning. <em>MLST</em>, <em>6</em>(2), 025033. (<a href='https://doi.org/10.1088/2632-2153/adcf71'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the microstructure of porous media is crucial in various fields—particularly in petroleum engineering, hydrogeology, and materials science—because it directly influences the properties of porous materials and the behavior of fluids within their pores. Traditional characterization methods often struggle to capture the complex, heterogeneous micro-scale features of rock structures. To address this challenge, this study presents a novel approach for the classification and visualization of rock microstructure from micro-computed tomography images, leveraging pre-trained convolutional neural network (CNN) models (AlexNet, GoogLeNet, Inception v3 Net, ResNet, and DenseNet) combined with unsupervised machine learning (USML) techniques principal component analysis, multidimensional scaling, isometric mapping, t-distributed stochastic neighbor embedding (t-SNE), and uniform manifold approximation projection (UMAP)). Using pre-trained CNNs allows us to extract rich feature representations without the need for large, specialized training datasets, effectively capturing intricate patterns in the microstructures. The application of USML methods enables us to reduce dimensionality and uncover latent structures in the data without supervision. We tested the effectiveness of our method through three distinct case studies that include a wide variety of porous structures and found high classification accuracy using DenseNet and t-SNE or UMAP. Our approach successfully distinguishes similar rock samples that have been difficult to classify using conventional features such as porosity, specific surface area, and Euler characteristics, as demonstrated by silhouette score, Davies–Bouldin Index, and Caliński–Harabasz Index. To enhance the interpretability of the machine learning approach, we proposed a patch-based analysis to identify local characteristic textural patterns that contribute significantly to the classification of individual rock samples. By visualizing the spatial distribution of these patterns and quantifying their characteristics, we gained insights into the microstructural differences between rock samples, providing an effective tool for interpreting the classification results and understanding the underlying factors that differentiate various rock types.},
  archive      = {J_MLST},
  author       = {Masashige Shiga and Masao Sorai and Tetsuya Morishita and Masaatsu Aichi and Naoki Nishiyama and Takashi Fujii},
  doi          = {10.1088/2632-2153/adcf71},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025033},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Feature extraction and classification of digital rock images via pre-trained convolutional neural network and unsupervised machine learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum generative learning for high-resolution medical image generation. <em>MLST</em>, <em>6</em>(2), 025032. (<a href='https://doi.org/10.1088/2632-2153/add1a9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integration of quantum computing in generative machine learning models has the potential to offer benefits such as training speed-up and superior feature extraction. However, the existing quantum generative adversarial networks (QGANs) fail to generate high-quality images due to their patch-based, pixel-wise learning approaches. These methods capture only local details, ignoring the global structure and semantic information of images. In this work, we address these challenges by proposing a quantum image generative learning (QIGL) approach for high-quality medical image generation. Our proposed quantum generator leverages variational quantum circuit approach addressing scalability issues by extracting principal components from the images instead of dividing them into patches. Additionally, we integrate the Wasserstein distance within the QIGL framework to generate a diverse set of medical samples. Through a systematic set of simulations on x-ray images from knee osteoarthritis and medical MNIST datasets, our model demonstrates superior performance, achieving the lowest Fréchet inception distance scores compared to its classical counterpart and advanced QGAN models reported in the literature.},
  archive      = {J_MLST},
  author       = {Amena Khatun and Kübra Yeter Aydeniz and Yaakov S Weinstein and Muhammad Usman},
  doi          = {10.1088/2632-2153/add1a9},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025032},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Quantum generative learning for high-resolution medical image generation},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MATSE—multi-fidelity augmented time-series emulation: Galvanic corrosion applications. <em>MLST</em>, <em>6</em>(2), 025031. (<a href='https://doi.org/10.1088/2632-2153/add23a'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex physio-chemical phenomena can be investigated using high-fidelity physics-based finite element (FE) models. These models provide accurate predictions of the response of interest, as well as insights into its evolution over time. However, these models are computationally expensive, limiting widespread use. Machine learning (ML)-based protocols can significantly accelerate predictions from high-fidelity models. However, the training costs associated with these models can be prohibitive. This expense can be mitigated by effectively integrating results from lower-fidelity models. Therefore, a protocol that leverages low-fidelity results to accelerate high-fidelity predictions is desirable. This work introduces a multi-fidelity Gaussian process regression framework designed to emulate time-series outputs from high-fidelity models. The framework integrates low-fidelity model responses with Taylor-series approximations, facilitated by automatic differentiation, to propagate predictions and uncertainties across time and fidelity. The protocol is validated by accurately predicting both analytical and FE examples. A well-known example for time-series models, specifically the pendulum with moving support point and the evolution of the total current output of corroding galvanic couples in two case studies across five model fidelities are investigated. Although developed in the context of corrosion, this versatile ML framework shows immense potential for various engineering applications.},
  archive      = {J_MLST},
  author       = {Aditya Venkatraman and Ryan M Katona and David Montes de Oca Zapiain},
  doi          = {10.1088/2632-2153/add23a},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {025031},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {MATSE—multi-fidelity augmented time-series emulation: Galvanic corrosion applications},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing friction stir-based techniques with machine learning: A comprehensive review. <em>MLST</em>, <em>6</em>(2), 021001. (<a href='https://doi.org/10.1088/2632-2153/adcff6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {FSTs are advanced solid-state processing methods that address the growing industrial demand for lightweight components with enhanced mechanical properties. These techniques, including friction stir welding and friction stir processing, are distinguished by their capability to refine microstructures and improve the quality and longevity of welds and surfaces, making them integral to modern manufacturing. Recent advancements in machine learning (ML) have facilitated the integration of data-driven approaches into FST applications, demonstrating significant potential for optimising performance. This review explores the use of ML in FSTs, highlighting how various ML models improve the prediction of mechanical properties and the optimisation of processing parameters. Findings indicate that ML provides higher accuracy in predictions for FST applications than traditional statistical methods, while hybrid ML techniques further enhance outcomes by refining process control. The review further highlights existing knowledge gaps and proposes directions for future research to enhance ML integration in FSTs. This comprehensive synthesis is drawn from academic literature primarily sourced from the Scopus and Web of Science databases, supplemented by insights from recent books published in the past 15 years.},
  archive      = {J_MLST},
  author       = {Noah E El-Zathry and Stephen Akinlabi and Wai Lok Woo and Vivek Patel and Rasheedat M Mahamood and Ibrahim Sabry},
  doi          = {10.1088/2632-2153/adcff6},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {021001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Enhancing friction stir-based techniques with machine learning: A comprehensive review},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Region versus query based instance segmentation models: Application to the estimation of aggregated TiO2 particles size distribution measured by SEM. <em>MLST</em>, <em>6</em>(2), 020502. (<a href='https://doi.org/10.1088/2632-2153/add239'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance segmentation model performances is commonly evaluated through challenges using toy datasets such as CIFAR and ImageNet. Although, it is necessary to help improving state-of-the-art models, it remains far from critical industrial application where accurate measurement is required to ensure optimal process control, quality assurance and safety. This paper compares the performance of ready-to-deploy state-of-the-art instance segmentation models, specifically region and query-based models, across COCO and task-specific designed metrics in the context of the estimation of aggregated TiO 2 particle size distribution from scanning electron microscopy (SEM) measurements. The numerical comparison is conducted on custom datasets, addressing well-known challenges of SEM microscopists: high resolution images showing a massive number of overlapping instances, images measured with diverse imaging parameters (operator control) or the presence of a mixture of aggregated particles. Our findings highlight the strengths and limitations of each model category, providing insights into their suitability for high-stakes industrial deployment. Finally, we propose a customized inference procedure that leverages the performance of transformers on images that contain a small number of instances within dense and clustered scenes.},
  archive      = {J_MLST},
  author       = {Paul Monchot and Loïc Coquelin and Nicolas Fischer},
  doi          = {10.1088/2632-2153/add239},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {020502},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Region versus query based instance segmentation models: Application to the estimation of aggregated TiO2 particles size distribution measured by SEM},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLM4Mat-bench: Benchmarking large language models for materials property prediction. <em>MLST</em>, <em>6</em>(2), 020501. (<a href='https://doi.org/10.1088/2632-2153/add3bb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) are increasingly being used in materials science. However, little attention has been given to benchmarking and standardized evaluation for LLM-based materials property prediction, which hinders progress. We present LLM4Mat-Bench, the largest benchmark to date for evaluating the performance of LLMs in predicting the properties of crystalline materials. LLM4Mat-Bench contains about 1.9 M crystal structures in total, collected from 10 publicly available materials data sources, and 45 distinct properties. LLM4Mat-Bench features different input modalities: crystal composition, CIF, and crystal text description, with 4.7 M, 615.5 M, and 3.1B tokens in total for each modality, respectively. We use LLM4Mat-Bench to fine-tune models with different sizes, including LLM-Prop and MatBERT, and provide zero-shot and few-shot prompts to evaluate the property prediction capabilities of LLM-chat-like models, including Llama, Gemma, and Mistral. The results highlight the challenges of general-purpose LLMs in materials science and the need for task-specific predictive models and task-specific instruction-tuned LLMs in materials property prediction 7 .},
  archive      = {J_MLST},
  author       = {Andre Niyongabo Rubungo and Kangming Li and Jason Hattrick-Simpers and Adji Bousso Dieng},
  doi          = {10.1088/2632-2153/add3bb},
  journal      = {Machine Learning: Science and Technology},
  month        = {5},
  number       = {2},
  pages        = {020501},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {LLM4Mat-bench: Benchmarking large language models for materials property prediction},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integer linear programming for unsupervised training set selection in molecular machine learning. <em>MLST</em>, <em>6</em>(2), 025030. (<a href='https://doi.org/10.1088/2632-2153/adcd38'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integer linear programming (ILP) is an elegant approach to solve linear optimization problems, naturally described using integer decision variables. Within the context of physics-inspired machine learning (ML) applied to chemistry, we demonstrate the relevance of an ILP formulation to select molecular training sets for predictions of size-extensive properties. We show that our algorithm outperforms existing unsupervised training set selection approaches, especially when predicting properties of molecules larger than those present in the training set. We argue that the reason for the improved performance is due to the selection that is based on the notion of local similarity (i.e. per-atom) and a unique ILP approach that finds optimal solutions efficiently. Altogether, this work provides a practical algorithm to improve the performance of physics-inspired ML models and offers insights into the conceptual differences with existing training set selection approaches.},
  archive      = {J_MLST},
  author       = {Matthieu Haeberle and Puck van Gerwen and Ruben Laplaza and Ksenia R Briling and Jan Weinreich and Friedrich Eisenbrand and Clémence Corminboeuf},
  doi          = {10.1088/2632-2153/adcd38},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025030},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Integer linear programming for unsupervised training set selection in molecular machine learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nearest-neighbors neural network architecture for efficient sampling of statistical physics models. <em>MLST</em>, <em>6</em>(2), 025029. (<a href='https://doi.org/10.1088/2632-2153/adcdc1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of sampling efficiently the Gibbs–Boltzmann distribution of disordered systems is important both for the theoretical understanding of these models and for the solution of practical optimization problems. Unfortunately, this task is known to be hard, especially for spin-glass-like problems at low temperatures. Recently, many attempts have been made to tackle the problem by mixing classical Monte Carlo schemes with newly devised neural networks that learn to propose smart moves. In this article, we introduce the nearest-neighbors neural network ( \text{4N} ) architecture, a physically interpretable deep architecture whose number of parameters scales linearly with the size of the system and that can be applied to a large variety of topologies. We show that the \text{4N} architecture can accurately learn the Gibbs–Boltzmann distribution for a prototypical spin-glass model, the two-dimensional Edwards–Anderson model, and specifically for some of its most difficult instances. In particular, it captures properties such as the energy, the correlation function and the overlap probability distribution. Finally, we show that the \text{4N} performance increases with the number of layers, in a way that clearly connects to the correlation length of the system, thus providing a simple and interpretable criterion to choose the optimal depth.},
  archive      = {J_MLST},
  author       = {Luca Maria Del Bono and Federico Ricci-Tersenghi and Francesco Zamponi},
  doi          = {10.1088/2632-2153/adcdc1},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025029},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Nearest-neighbors neural network architecture for efficient sampling of statistical physics models},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aortic KD former: Aortic multiclass segmentation using SegFormer via knowledge distillation. <em>MLST</em>, <em>6</em>(2), 025028. (<a href='https://doi.org/10.1088/2632-2153/adca84'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the effectiveness of knowledge distillation for semantic segmentation of aortic structures using deep learning models. We employ SegFormer B5 as the teacher model and SegFormer B0 as the student model. Knowledge distillation is applied through three methods: output-based distillation, inner feature maps-based distillation, and integrated distillation, which combines both logits and feature maps. Our results show that while the student model (SegFormer B0) has significantly fewer parameters (3,715,686) compared to the teacher model (SegFormer B5) with 84,597,958 parameters, it achieves performance closely approaching that of the teacher. Among the evaluated techniques, inner feature map distillation yields the best performance, with a mean IoU of 0.9994, a mean Dice score of 0.9549, and a loss of 0.0020, demonstrating its superior capability in transferring knowledge effectively. The study highlights the potential of inner feature map distillation as the most effective method for achieving high performance with reduced model complexity.},
  archive      = {J_MLST},
  author       = {Nancy Mohamed Soliman and Medhat Awadalla and Mohamed Elhelw and Mustafa Elattar},
  doi          = {10.1088/2632-2153/adca84},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025028},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Aortic KD former: Aortic multiclass segmentation using SegFormer via knowledge distillation},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperparameter optimisation in deep learning from ensemble methods: Applications to proton structure. <em>MLST</em>, <em>6</em>(2), 025027. (<a href='https://doi.org/10.1088/2632-2153/adcd39'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models are defined in terms of a large number of hyperparameters, such as network architectures and optimiser settings. These hyperparameters must be determined separately from the model parameters such as network weights, and are often fixed by ad-hoc methods or by manual inspection of the results. An algorithmic, objective determination of hyperparameters demands the introduction of dedicated target metrics, different from those adopted for the model training. Here we present a new approach to the automated determination of hyperparameters in deep learning models based on statistical estimators constructed from a ensemble of models sampling the underlying probability distribution in model space. This strategy requires the simultaneous parallel training of up to several hundreds of models and can be effectively implemented by deploying hardware accelerators such as graphical processing units (GPUs). As a proof-of-concept, we apply this method to the determination of the partonic substructure of the proton within the NNPDF framework and demonstrate the robustness of the resultant model uncertainty estimates. The new GPU-optimised NNPDF code results in a speed-up of up to two orders of magnitude, a stabilisation of the memory requirements, and a reduction in energy consumption of up to 90% as compared to sequential CPU-based model training. While focusing on proton structure, our method is fully general and is applicable to any deep learning problem relying on hyperparameter optimisation for an ensemble of models.},
  archive      = {J_MLST},
  author       = {Juan Cruz-Martinez and Aron Jansen and Gijs van Oord and Tanjona R Rabemananjara and Carlos M R Rocha and Juan Rojo and Roy Stegeman},
  doi          = {10.1088/2632-2153/adcd39},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025027},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Hyperparameter optimisation in deep learning from ensemble methods: Applications to proton structure},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transfer learning from first-principles calculations to experiments with chemistry-informed domain transformation. <em>MLST</em>, <em>6</em>(2), 025026. (<a href='https://doi.org/10.1088/2632-2153/adcdc0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulation-to-Real (Sim2Real) transfer learning (TL), the machine learning technique that efficiently solves a real-world task by leveraging knowledge from computational data, has received increasing attention in materials science as a promising solution to the scarcity of experimental data. We proposed an efficient TL scheme from first-principles calculations to experiments based on the chemistry-informed domain transformation that bridges the heterogeneous source and target domains by harnessing the underlying physics and chemistry. The proposed method maps the computational data from the simulation space (source domain) into the space of experimental data (target domain). During this process, these qualitatively different domains are efficiently integrated using two pieces of prior chemical knowledge: (1) the statistical ensemble, and (2) the relationship between source and target quantities. As a proof-of-concept, we predict the catalyst activity for the reverse water-gas shift reaction by using the abundant first-principles data in addition to the experimental data. Through the demonstration, we confirmed that the TL model exhibits positive transfer in accuracy and data efficiency. In particular, a significantly high accuracy was achieved despite using a few (less than ten) target data in domain transformation, whose test error is one order of magnitude smaller than that of a full scratch model trained with over 100 target data. This result indicates that the proposed method leverages the high prediction performance with few target data, which helps to save the number of trials in real laboratories.},
  archive      = {J_MLST},
  author       = {Yuta Yahagi and Kiichi Obuchi and Fumihiko Kosaka and Kota Matsui},
  doi          = {10.1088/2632-2153/adcdc0},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025026},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Transfer learning from first-principles calculations to experiments with chemistry-informed domain transformation},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural networks for parameter estimation in geostatistical models with geometric anisotropies. <em>MLST</em>, <em>6</em>(2), 025025. (<a href='https://doi.org/10.1088/2632-2153/adcdc2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents two neural network approaches for estimating the covariance function of a spatial Gaussian random field defined in a portion of the euclidean plane. Our proposal builds upon recent contributions, expanding from the purely isotropic setting to encompass geometrically anisotropic correlation structures, i.e. random fields with correlation ranges that vary across different directions. We conduct experiments with both simulated and real data to assess the performance of the methodology and to provide guidelines to practitioners.},
  archive      = {J_MLST},
  author       = {Alejandro Villazón and Alfredo Alegría and Xavier Emery},
  doi          = {10.1088/2632-2153/adcdc2},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025025},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Neural networks for parameter estimation in geostatistical models with geometric anisotropies},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shallow recurrent decoder for reduced order modeling of e × b plasma dynamics. <em>MLST</em>, <em>6</em>(2), 025024. (<a href='https://doi.org/10.1088/2632-2153/adcd20'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reduced-order models (ROMs) are becoming increasingly important for rendering complex and multiscale spatiotemporal dynamics computationally tractable. Computationally efficient ROMs are especially essential for optimized design of technologies as well as for gaining physical understanding. Plasma simulations, in particular those applied to the study of E × B plasma discharges and technologies, such as Hall thrusters for spacecraft propulsion, require substantial computational resources in order to resolve the multidimensional dynamics that span across wide spatial and temporal scales. While high-fidelity computational tools are available, their applications are limited to simplified geometries and narrow conditions, making simulations of full-scale plasma systems or comprehensive parametric studies computationally prohibitive. In addition, experimental setups involve limitations such as the finite spatial resolution of diagnostics and constraints imposed by geometrical accessibility. Consequently, both scientific research and industrial development of plasma systems, including E × B technologies, can greatly benefit from advanced ROM techniques that enable estimating the distributions of plasma properties across the entire system. We develop a model reduction scheme based upon a shallow recurrent decoder (SHRED) architecture using as few measurements of the system as possible. This scheme employs a neural network to encode limited sensor measurements in time (of either local or global properties) and reconstruct full spatial state vector via a shallow decoder network. Leveraging the theory of separation of variables, the SHRED architecture demonstrates the ability to reconstruct complete spatial fields with as few as three-point sensors, including fields dynamically coupled to the measured variables but not directly observed. The effectiveness of the ROMs derived with SHRED is demonstrated across several plasma configurations representative of different geometries in typical E × B plasma discharges and Hall thrusters.},
  archive      = {J_MLST},
  author       = {Farbod Faraji and Maryam Reza and J Nathan Kutz},
  doi          = {10.1088/2632-2153/adcd20},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025024},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Shallow recurrent decoder for reduced order modeling of e × b plasma dynamics},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative adversarial networks for creating realistic training data for machine learning-based segmentation of FIB tomography data. <em>MLST</em>, <em>6</em>(2), 025023. (<a href='https://doi.org/10.1088/2632-2153/adc870'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate 3D reconstruction of the structure of nanomaterials is essential for studying their physical properties. Focused ion beam (FIB) tomography is a preferred method for creating 3D image stacks of micrometer-sized material volumes at nanometer resolution. To achieve valid 3D reconstructions from FIB tomography data, semantic segmentation of these images using machine learning-based methods is often beneficial. However, supervised machine learning requires a large amount of training data and ground truth, which is challenging because FIB tomography is a destructive technique. This motivates the use of synthetic training data generated with Monte Carlo simulations of the FIB tomography process. However, these simulations are computationally expensive, and the resulting synthetic imaging data still differs from real FIB tomography data in terms of the statistical distribution of various features. In this study, we propose a novel approach to overcome both problems, i.e. requiring high computation time and difference in data distribution, using generative adversarial networks.},
  archive      = {J_MLST},
  author       = {Trushal Sardhara and Christian J Cyron and Martin Ritter and Roland C Aydin},
  doi          = {10.1088/2632-2153/adc870},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025023},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Generative adversarial networks for creating realistic training data for machine learning-based segmentation of FIB tomography data},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retentive neural quantum states: Efficient ansätze for ab initio quantum chemistry. <em>MLST</em>, <em>6</em>(2), 025022. (<a href='https://doi.org/10.1088/2632-2153/adcb88'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural-network quantum states (NQS) has emerged as a powerful application of quantum-inspired deep learning for variational Monte Carlo methods, offering a competitive alternative to existing techniques for identifying ground states of quantum problems. A significant advancement toward improving the practical scalability of NQS has been the incorporation of autoregressive models, most recently transformers, as variational ansätze. Transformers learn sequence information with greater expressiveness than recurrent models, but at the cost of increased time complexity with respect to sequence length. We explore the use of the retentive network (RetNet), a recurrent alternative to transformers, as an ansatz for solving electronic ground state problems in ab initio quantum chemistry. Unlike transformers, RetNets overcome this time complexity bottleneck by processing data in parallel during training, and recurrently during inference. We give a simple computational cost estimate of the RetNet and directly compare it with similar estimates for transformers, establishing a clear threshold ratio of problem-to-model size past which the RetNet's time complexity outperforms that of the transformer. Though this efficiency comes at the expense of decreased expressiveness relative to the transformer, we overcome this gap through training strategies that leverage the autoregressive structure of the model—namely, variational neural annealing. Our findings support the RetNet as a means of improving the time complexity of NQS without sacrificing accuracy. We provide further evidence that the ablative improvements of neural annealing extend beyond the RetNet architecture, suggesting it would serve as an effective general training strategy for autoregressive NQS.},
  archive      = {J_MLST},
  author       = {Oliver Knitter and Dan Zhao and James Stokes and Martin Ganahl and Stefan Leichenauer and Shravan Veerapaneni},
  doi          = {10.1088/2632-2153/adcb88},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025022},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Retentive neural quantum states: Efficient ansätze for ab initio quantum chemistry},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diversity-based two-phase pruning strategy for maximizing image segmentation generalization with applications in transmission electron microscopy. <em>MLST</em>, <em>6</em>(2), 025021. (<a href='https://doi.org/10.1088/2632-2153/adc9fa'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For artificial intelligence applications in transmission electron microscopy (TEM), hardware and computational constraints often obstruct real-time data processing, inflating operational costs, consuming valuable instrument time, and heightening the risk of damage to beam-sensitive specimens, thereby complicating reliable data interpretation. To address these issues, we propose a two-stage pruning strategy that reduces deep-learning model size and computational overhead while preserving high performance and generalization across diverse datasets. Unlike conventional pruning techniques, which typically rely solely on weight magnitude and risk overlooking critical variability and directional properties in weight vectors, our approach initially removes filters with low magnitude and insufficient variability, followed by pruning filters with high linear similarity to eliminate redundancy. This one-shot pruning process, followed by fine-tuning, minimizes accuracy loss and mitigates barriers to deep learning integration in TEM workflows. Our method expedites TEM analysis, enabling more efficient, real-time, and cost-effective materials characterization. Additionally, this work lays a foundation for investigating the broader applicability and versatility to different architectures and tasks, particularly in resource-constrained environments where both model size and computational efficiency are critical.},
  archive      = {J_MLST},
  author       = {Ze-Wei Ye and Hung-Wei Hsueh and Shu-Han Hsu},
  doi          = {10.1088/2632-2153/adc9fa},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025021},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Diversity-based two-phase pruning strategy for maximizing image segmentation generalization with applications in transmission electron microscopy},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning density functionals from noisy quantum data. <em>MLST</em>, <em>6</em>(2), 025020. (<a href='https://doi.org/10.1088/2632-2153/adcb89'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The search for useful applications of noisy intermediate-scale quantum (NISQ) devices in quantum simulation has been hindered by their intrinsic noise and the high costs associated with achieving high accuracy. A promising approach to finding utility despite these challenges involves using quantum devices to generate training data for classical machine learning (ML) models. In this study, we explore the use of noisy data generated by quantum algorithms in training an ML model to learn a density functional for the Fermi–Hubbard model. We benchmark various ML models against exact solutions, demonstrating that a neural-network ML model can successfully generalize from small datasets subject to noise typical of NISQ algorithms. The learning procedure can effectively filter out unbiased sampling noise, resulting in a trained model that outperforms any individual training data point. Conversely, when trained on data with expressibility and optimization error typical of the variational quantum eigensolver, the model replicates the biases present in the training data. The trained models can be applied to solving new problem instances in a Kohn–Sham-like density optimization scheme, benefiting from automatic differentiability and achieving reasonably accurate solutions on most problem instances. Our findings suggest a promising pathway for leveraging NISQ devices in practical quantum simulations, highlighting both the potential benefits and the challenges that need to be addressed for successful integration of quantum computing and ML techniques.},
  archive      = {J_MLST},
  author       = {Emiel Koridon and Felix Frohnert and Eric Prehn and Evert van Nieuwenburg and Jordi Tura and Stefano Polla},
  doi          = {10.1088/2632-2153/adcb89},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025020},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Learning density functionals from noisy quantum data},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The more the better or the less the better: LASSO versus random forest in forecasting seasonal precipitation for drought management. <em>MLST</em>, <em>6</em>(2), 025019. (<a href='https://doi.org/10.1088/2632-2153/adbe24'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting of drought with long-term persistence has been a difficult task, since the major driving force-precipitation-does not exhibit a long-term relation with climate variables. Although drought indices, such as standardized precipitation index (SPI), have been successfully applied for forecasting, the forecasts directly applying SPI are not always useful for water management. Meanwhile, to efficiently manage drought, global climate variables can be applied for direct precipitation forecasting. Therefore, the current study aimed at forecasting the accumulated seasonal precipitation (ASP) over South Korea from globally gridded climate variables, such as sea surface temperature (SST) and mean sea level pressure (MSLP). The major issue when building a forecast model is how to handle the extensive number of predictors derived from globally gridded climate variables, when the condition that the observed response variable (here, ASP) contains only a limited number of records exists. Overcoming this limitation, two conceptually dissonant models, Least Absolute Shrinkage and Selection Operator (LASSO) and Random forest (RF) were tested and compared. The LASSO model selects only a limited number of predictors by assigning zero values to its regression parameters, while the RF model is an ensemble of a number of simple tree models by employing all feasible variables. The globally gridded Difference of Climate Index derived by subtracting the climate variable of one location from that of the other location, SST, MSLP and their combination were applied as candidate predictors. The final predictors were determined by employing the thresholds of cross-correlation at each season. Results concluded that the LASSO model with the combined MSLPSST variables presented the best performance in all seasons. The current study can provide a critical lesson for future studies when applying globally gridded climate variables to analyze hydrological and environmental data with limited records.},
  archive      = {J_MLST},
  author       = {Taesam Lee and Yejin Kong and Vijay P Singh},
  doi          = {10.1088/2632-2153/adbe24},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025019},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {The more the better or the less the better: LASSO versus random forest in forecasting seasonal precipitation for drought management},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Harnessing the power of gradient-based simulations for multi-objective optimization in particle accelerators. <em>MLST</em>, <em>6</em>(2), 025018. (<a href='https://doi.org/10.1088/2632-2153/adc221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle accelerator operation requires simultaneous optimization of multiple objectives. Multi-objective optimization (MOO) is particularly challenging due to trade-offs between the objectives. Evolutionary algorithms, such as genetic algorithms (GAs), have been leveraged for many optimization problems, however, they do not apply to complex control problems by design. This paper demonstrates the power of differentiability for solving MOO problems in particle accelerators using a deep differentiable reinforcement learning (DDRL) algorithm. We compare the DDRL algorithm with model-free reinforcement learning (MFRL), GA, and Bayesian optimization (BO) for simultaneous optimization of heat load and trip rates in the continuous electron beam accelerator facility. The underlying problem enforces strict constraints on both individual states and actions as well as cumulative (global) constraints on energy requirements of the beam. Using historical accelerator data, we develop a physics-based surrogate model which is differentiable and allows for back-propagation of gradients. The results are evaluated in the form of a Pareto-front with two objectives. We show that the DDRL outperforms MFRL, BO, and GA on high dimensional problems.},
  archive      = {J_MLST},
  author       = {Kishansingh Rajput and Malachi Schram and Auralee Edelen and Jonathan Colen and Armen Kasparian and Ryan Roussel and Adam Carpenter and He Zhang and Jay Benesch},
  doi          = {10.1088/2632-2153/adc221},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025018},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Harnessing the power of gradient-based simulations for multi-objective optimization in particle accelerators},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAGIPS: A physics-inspired scalable asynchronous generative inverse-problem solver. <em>MLST</em>, <em>6</em>(2), 025017. (<a href='https://doi.org/10.1088/2632-2153/adc8fb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving large-scale inverse problems using deep-learning algorithms have become an essential part of modern research and industrial applications. The complexity of the underlying inverse problem may require the utilization of high performance computing systems which poses a challenge on the algorithmic design of the inverse problem solver. Most deep learning algorithms require, due to their design, custom parallelization techniques in order to be resource efficient while showing a reasonable convergence. In this paper we introduce a S calable A synchronous G enerative I nverse P roblem S olver (SAGIPS) on high-performance computing systems. We present a workflow that utilizes an asynchronous ring-allreduce algorithm to transfer the gradients of the generator network across multiple GPUs. Experiments with a scientific proxy application demonstrate that SAGIPS shows near linear weak scaling, together with a convergence quality that is comparable to traditional methods. The approach presented here allows leveraging Generative Adverserial Network across multiple GPUs, promising advancements in solving complex inverse problems at scale.},
  archive      = {J_MLST},
  author       = {Daniel Lersch and Malachi Schram and Zhenyu Dai and Kishansingh Rajput and Nobuo Sato and Xingfu Wu and J Taylor Childers and Steven Goldenberg},
  doi          = {10.1088/2632-2153/adc8fb},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025017},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {SAGIPS: A physics-inspired scalable asynchronous generative inverse-problem solver},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prior guided deep difference meta-learner for fast adaptation to stylized segmentation. <em>MLST</em>, <em>6</em>(2), 025016. (<a href='https://doi.org/10.1088/2632-2153/adc970'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiotherapy treatment planning requires segmenting anatomical structures in various styles, influenced by guidelines, protocols, preferences, or dose planning needs. Deep learning-based auto-segmentation models, trained on anatomical definitions, may not match local clinicians' styles at new institutions. Adapting these models can be challenging without sufficient resources. We hypothesize that consistent differences between segmentation styles and anatomical definitions can be learned from initial patients and applied to pre-trained models for more precise segmentation. We propose a Prior-guided deep difference meta-learner (DDL) to learn and adapt these differences. We collected data from 440 patients for model development and 30 for testing. The dataset includes contours of the prostate clinical target volume (CTV), parotid, and rectum. We developed a deep learning framework that segments new images with a matching style using example styles as a prior, without model retraining. The pre-trained segmentation models were adapted to three different clinician styles for post-operative CTV for prostate, parotid gland, and rectum segmentation. We tested the model's ability to learn unseen styles and compared its performance with transfer learning, using varying amounts of prior patient style data (0–10 patients). Performance was quantitatively evaluated using dice similarity coefficient (DSC) and Hausdorff distance. With exposure to only three patients for the model, the average DSC (%) improved from 78.6, 71.9, 63.0, 69.6, 52.2 and 46.3–84.4, 77.8, 73.0, 77.8, 70.5, 68.1, for CTV style1 , CTV style2 , CTV style3 , Parotid superficial , Rectum superior , and Rectum posterior , respectively. The proposed Prior-guided DDL is a fast and effortless network for adapting a structure to new styles. The improved segmentation accuracy may result in reduced contour editing time, providing a more efficient and streamlined clinical workflow.},
  archive      = {J_MLST},
  author       = {Dan Nguyen and Anjali Balagopal and Ti Bai and Michael Dohopolski and Mu-Han Lin and Steve Jiang},
  doi          = {10.1088/2632-2153/adc970},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025016},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Prior guided deep difference meta-learner for fast adaptation to stylized segmentation},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transfer learning nonlinear plasma dynamic transitions in low dimensional embeddings via deep neural networks. <em>MLST</em>, <em>6</em>(2), 025015. (<a href='https://doi.org/10.1088/2632-2153/adca83'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning algorithms provide a new paradigm to study high-dimensional dynamical behaviors, such as those in fusion plasma systems. Development of novel, data-driven model reduction methods, coupled with detection of abnormal modes with plasma physics, opens a unique opportunity to identify plasma instabilities through automated construction of parsimonious models that can be tuned to balance accuracy and cost. Our fusion transfer learning (FTL) model demonstrates success in rapidly reconstructing nonlinear kink mode structures by learning from a limited amount of nonlinear simulation data. The knowledge transfer process leverages a pre-trained neural encoder–decoder network, initially trained on linear simulations, to effectively capture nonlinear dynamics. The low-dimensional embeddings extract the coherent structures of interest, while preserving the inherent dynamics of the complex system. Experimental results highlight FTL's capacity to capture transitional behaviors and dynamical features in plasma dynamics—a task often challenging for conventional methods. The model developed in this study is generalizable and can be extended broadly through transfer learning to address various magnetohydrodynamics modes.},
  archive      = {J_MLST},
  author       = {Zhe Bai and Xishuo Wei and William Tang and Leonid Oliker and Zhihong Lin and Samuel Williams},
  doi          = {10.1088/2632-2153/adca83},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025015},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Transfer learning nonlinear plasma dynamic transitions in low dimensional embeddings via deep neural networks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transfer learning and the early estimation of single-photon source quality using machine learning methods. <em>MLST</em>, <em>6</em>(2), 025014. (<a href='https://doi.org/10.1088/2632-2153/adc86f'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of single-photon sources (SPSs) is central to numerous systems and devices proposed amidst a modern surge in quantum technology. However, manufacturing schemes remain imperfect, and single-photon emission purity must often be experimentally verified via interferometry. Such a process is typically slow and costly, which has motivated growing research into whether SPS quality can be more rapidly inferred from incomplete emission statistics. Hence, this study is a sequel to previous work that demonstrated significant uncertainty in the standard method of quality estimation, i.e. the least-squares fitting of a physically motivated function, and asks: can machine learning (ML) do better? The study leverages eight datasets obtained from measurements involving an exemplary quantum emitter, i.e. a single InGaAs/GaAs epitaxial quantum dot; these eight contexts predominantly vary in the intensity of the exciting laser. Specifically, via a form of 'transfer learning', five ML models, three linear and two ensemble-based, are trained on data from seven of the contexts and tested on the eighth. Validation metrics quickly reveal that even a linear regressor can outperform standard fitting when it is tested on the same contexts it was trained on, but the success of transfer learning is less assured, even though statistical analysis, made possible by data augmentation, suggests its superiority as an early estimator. Accordingly, the study concludes by discussing future strategies for grappling with the problem of SPS context dissimilarity, e.g. feature engineering and model adaptation.},
  archive      = {J_MLST},
  author       = {David Jacob Kedziora and Anna Musiał and Wojciech Rudno-Rudziński and Bogdan Gabrys},
  doi          = {10.1088/2632-2153/adc86f},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025014},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Transfer learning and the early estimation of single-photon source quality using machine learning methods},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph2Mat: Universal graph to matrix conversion for electron density prediction. <em>MLST</em>, <em>6</em>(2), 025013. (<a href='https://doi.org/10.1088/2632-2153/adc871'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electron density is a fundamental observable of an atomic system from which all ground-state properties can be computed. As a prediction target for machine learning (ML) models, electron density is often represented on a dense real space grid, which is data heavy, or through density fitting approximations. In this work, we show the power of targeting the density matrix (DM), a linear-scaling sparse SE(3) equivariant matrix that encodes the exact density. We introduce Graph2Mat, a universal function for converting molecular graphs into equivariant matrices. We demonstrate how a ML model that combines this Graph2Mat approach with state-of-the-art molecular graph representations can accurately predict the DM of molecular systems. The models achieve state-of-the-art performance on electron density prediction by matching the accuracy of grid-based methods, while using datasets that are at least one order of magnitude smaller. Accurately predicted electron densities can also accelerate density functional theory (DFT) calculations by reducing the number of self-consistent field (SCF) iterations needed to converge. In this work, we get an average 40% reduction on the number of SCF steps in DFT calculations of QM9 molecules with SIESTA. The novel prediction model also allows for two new and promising measures of uncertainty (total charge error and self-consistency error) that will facilitate its practical usage, e.g. within active learning workflows. These results open the door for many applications using hybrid ML-accelerated DFT methodologies, and uncertainty aware single iteration ab initio molecular dynamics.},
  archive      = {J_MLST},
  author       = {Pol Febrer and Peter Bjørn Jørgensen and Miguel Pruneda and Alberto García and Pablo Ordejón and Arghya Bhowmik},
  doi          = {10.1088/2632-2153/adc871},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025013},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Graph2Mat: Universal graph to matrix conversion for electron density prediction},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Logic replicant: A new machine learning algorithm for multiclass classification in small datasets. <em>MLST</em>, <em>6</em>(2), 025012. (<a href='https://doi.org/10.1088/2632-2153/adc86e'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiclass classification with small datasets often presents a significant challenge for conventional machine learning (ML) algorithms, predicting with an accuracy affected by this context of data scarcity. To remedy this, this papers presents a novel ML model based on a differentiable deterministic finite-state machine (DFSM) that improves the prediction performance compared with state-of-the-art multiclass classifiers applied in this ambit of small data per class. The proposed model uses a logic-arithmetic function that replicates the inherent classification logic of the problem rather than finding patterns of feature similarity. Our algorithm, called logic replicant, allows to learn problems that other classification models cannot. As the logic replicant is a DFSM it can learn any combinational logic, but it goes beyond this point learning other types of problems such as handwritten-digit recognition, and the detection of mice with Down syndrome based on the presence of 77 proteins. Our ML algorithm is also easy to interpret using quantitative diagrams, in comparison to less interpretable algorithms such as artificial neural networks, random forest, and others. The results obtained with different data sets related to math, physics, biology and image recognition show that our design based on a logic-arithmetic function and being a DFSM improves the generalisation capacity (better prediction accuracy) of the logic replicant compared to other state-of-the-art ML approaches.},
  archive      = {J_MLST},
  author       = {Pedro Corral and Roberto Centeno and Víctor Fresno},
  doi          = {10.1088/2632-2153/adc86e},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025012},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Logic replicant: A new machine learning algorithm for multiclass classification in small datasets},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optical flow estimation based on global cross information and dynamic encoder–dynamic decoder. <em>MLST</em>, <em>6</em>(2), 025011. (<a href='https://doi.org/10.1088/2632-2153/adc8fa'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the problem that the lack of a global perspective leads to local misestimation and overall structural dislocation when optical flow estimates large-scale motion and complex scenes, this paper proposes an optical flow estimation based on global cross information and dynamic encoder–dynamic decoder. The network architecture is improved stage by stage according to the streaming direction of the encoder and decoder data streams. For the encoder, relative and absolute position coding are adopted to construct a mixed coding network, and the learnable weights are used to dynamically adjust the mixed position coding information to enrich the global and local position information. For the enhancer layer after the encoder, the contextual information of the input sequence is captured through cross attention and a feed-forward neural network to construct a global cross information attention network, which acquires the global perspective under the premise of adapting to large-scale motion. For the decoder, bilinear interpolation and deformable convolution are combined to construct a dynamic anisotropic upsampling module, and dynamic anisotropic upsampling of the input feature maps is realized by adjusting the offsets of the sampling points to enhance the ability to process high-resolution details and complex motion boundaries. Finally, the performance of the proposed method is evaluated in the endpoint error value, estimation time and number of parameters. The experimental results show that compared with the RAFT benchmark network, the model in this paper preserves the global features and edge detail information of large-scale motion without significantly increasing the number of model parameters.},
  archive      = {J_MLST},
  author       = {Haoxin Guo and Yifan Wang and Xiaobo Guo},
  doi          = {10.1088/2632-2153/adc8fa},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025011},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Optical flow estimation based on global cross information and dynamic encoder–dynamic decoder},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural scaling laws from large-N field theory: Solvable model beyond the ridgeless limit. <em>MLST</em>, <em>6</em>(2), 025010. (<a href='https://doi.org/10.1088/2632-2153/adc872'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many machine learning models based on neural networks exhibit scaling laws: their performance scales as power laws with respect to the sizes of the model and training data set. We use large- N field theory methods to solve a model recently proposed by Maloney, Roberts and Sully which provides a simplified setting to study neural scaling laws. Our solution extends the result in this latter paper to general nonzero values of the ridge parameter, which are essential to regularize the behavior of the model. In addition to obtaining new and more precise scaling laws, we also uncover a duality transformation at the diagrams level which explains the symmetry between model and training data set sizes. The same duality underlies recent efforts to design neural networks to simulate quantum field theories.},
  archive      = {J_MLST},
  author       = {Zhengkang Zhang},
  doi          = {10.1088/2632-2153/adc872},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025010},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Neural scaling laws from large-N field theory: Solvable model beyond the ridgeless limit},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust prediction of chaotic systems with random errors using dynamical system deep learning. <em>MLST</em>, <em>6</em>(2), 025009. (<a href='https://doi.org/10.1088/2632-2153/adc873'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To predict nonlinear dynamical systems, a novel method called the dynamical system deep learning (DSDL), which is based on the state space reconstruction (SSR) theory and utilizes time series data for model training, was recently proposed. In the real world, observational data of chaotic systems are subject to random errors. Given the high nonlinearity and sensitivity of chaotic systems, the impact of random errors poses a significant challenge to the prediction. Mitigating the impact of random errors in the prediction of chaotic systems is a significant practical challenge. Traditional data-driven methods exhibit insufficient robustness against superimposed random errors, due to little consideration for temporal dynamic evolutionary of chaotic systems. Therefore, reducing the impact of random errors in the prediction of chaotic systems remains a difficult issue. In previous work, the DSDL demonstrated superiority in the noise-free scenario. This study primarily introduces the delay embedding theorem under noisy conditions and investigates the predictive capability of the DSDL in the presence of random errors in the training data. The performance of the DSDL is tested on three example systems, namely the Lorenz system, hyperchaotic Lorenz system and conceptual ocean–atmosphere coupled Lorenz system. The results show that the DSDL exhibits high accuracy and stability compared to various traditional machine learning methods and previous dynamic methods. Notably, as the magnitude of errors decreases, the advantage of the DSDL over traditional machine learning methods becomes more pronounced, highlighting the DSDL's capacity to effectively extract the temporal evolution characteristics of chaotic systems from time series and to identify the true system state within observational error bands, significantly mitigating the impact of random errors. Moreover, unlike other contemporary deep learning methods, the DSDL requires faster hyperparameter tuning by using fewer parameters for improving accuracy, and based on the advantage of the SSR theoretical framework, the DSDL does not require prior knowledge of the original governing equations. Our work extends the theoretical applicability of the DSDL under random error conditions and points to the new and superior data-driven method DSDL based on the dynamic framework, holding significant potential for mitigating the impact of random errors and achieving robust predictions of real-world systems.},
  archive      = {J_MLST},
  author       = {Zixiang Wu and Jianping Li and Hao Li and Mingyu Wang and Ning Wang and Guangcan Liu},
  doi          = {10.1088/2632-2153/adc873},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025009},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Robust prediction of chaotic systems with random errors using dynamical system deep learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamics-based predictions of infinite-dimensional complex systems using dynamical system deep learning method. <em>MLST</em>, <em>6</em>(2), 025008. (<a href='https://doi.org/10.1088/2632-2153/adc53b'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting complex nonlinear chaotic dynamical systems constitutes a critical and formidable challenge across various disciplines. A novel methodology termed dynamical system deep learning (DSDL) has recently been introduced and utilized for the prediction of nonlinear chaotic dynamical systems. This method not only exceeds current techniques but also extracts key variables of the target dynamical systems, thereby providing a feasible resolution to the 'black box' problem. Nonetheless, the present focus of this method has chiefly been on predicting finite-dimensional dynamical systems, but real-world phenomena are mainly governed by partial differential equations (PDEs). This research selects the Lorenz' 96 system, a set of coupled ordinary differential equations with spatiotemporal dynamics, and the Kuramoto–Sivashinsky PDE as representative examples of infinite-dimensional dynamical systems to evaluate the effectiveness of the DSDL. We also conduct comparisons with several mainstream methods including the ANN, RC-ESN, LSTM, NG-RC and SINDy. The findings demonstrate that the DSDL method exhibits outstanding prediction performance for PDEs. In long-term predictions, DSDL's results align most accurately with the statistical characteristics of the reference true values, outperforming the other methods mentioned above. Finally, this study discusses the efficacy, efficiency and superiority of the DSDL in predicting dynamical systems, as well as its significant contributions to key variable extraction.},
  archive      = {J_MLST},
  author       = {Hao Li and Jianping Li and Zixiang Wu and Mingyu Wang and Guangcan Liu and Ruipeng Sun and Ruize Li and Ning Wang and Houbin Song and Shixin Zhen},
  doi          = {10.1088/2632-2153/adc53b},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025008},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Dynamics-based predictions of infinite-dimensional complex systems using dynamical system deep learning method},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FDDM: Unsupervised medical image translation with a frequency-decoupled diffusion model. <em>MLST</em>, <em>6</em>(2), 025007. (<a href='https://doi.org/10.1088/2632-2153/adc656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have demonstrated significant potential in producing high-quality images in medical image translation to aid disease diagnosis, localization, and treatment. Nevertheless, current diffusion models often fall short when it comes to faithfully translating medical images. They struggle to accurately preserve anatomical structures, especially when working with unpaired datasets. In this study, we introduce the frequency decoupled diffusion model (FDDM) for magnetic resonance (MR)-to-computed tomography (CT) conversion. The differences between MR and CT images lie in both anatomical structures (e.g. the outlines of organs or bones) and the data distribution (e.g. intensity values and contrast within). Therefore, FDDM first converts anatomical information using an initial conversion module. Then, the converted anatomical information guides a subsequent diffusion model to generate high-quality CT images. Our diffusion model uses a dual-path reverse diffusion process for low-frequency and high-frequency information, achieving a better balance between image quality and anatomical accuracy. We extensively evaluated FDDM using two public datasets for brain MR-to-CT and pelvis MR-to-CT translations. The results show that FDDM outperforms generative adversarial network (GAN)-based, variational autoencoder (VAE)-based, and diffusion-based models. The evaluation metrics included Fréchet inception distance (FID), mean absolute error, mean squared error, structural similarity index measure, and Dice similarity coefficient (DICE). FDDM achieved the best scores on all metrics for both datasets, particularly excelling in FID, with scores of 25.9 for brain data and 29.2 for pelvis data, significantly outperforming the other methods. These results demonstrate that FDDM can generate high-quality target domain images while maintaining the accuracy of translated anatomical structures, thereby facilitating more precise/accurate downstream tasks including anatomy segmentation and radiotherapy planning.},
  archive      = {J_MLST},
  author       = {Yunxiang Li and Hua-Chieh Shao and Xiaoxue Qian and You Zhang},
  doi          = {10.1088/2632-2153/adc656},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025007},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {FDDM: Unsupervised medical image translation with a frequency-decoupled diffusion model},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable correlator transformer for image-like quantum matter data. <em>MLST</em>, <em>6</em>(2), 025006. (<a href='https://doi.org/10.1088/2632-2153/adc071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to their inherent capabilities of capturing non-local dependencies, Transformer neural networks have quickly been established as the paradigmatic architecture for large language models and image processing. Next to these traditional applications, machine learning (ML) methods have also been demonstrated to be versatile tools in the analysis of image-like data of quantum phases of matter, e.g. given snapshots of many-body wave functions obtained in ultracold atom experiments. While local correlation structures in image-like data of physical systems can reliably be detected, identifying phases of matter characterized by global, non-local structures with interpretable ML methods remains a challenge. Here, we introduce the correlator Transformer (CoTra), which classifies different phases of matter while at the same time yielding full interpretability in terms of physical correlation functions. The network's underlying structure is a tailored attention mechanism, which learns efficient ways to weigh local and non-local correlations for a successful classification. We demonstrate the versatility of the CoTra by detecting local order in the Heisenberg antiferromagnet, and show that local gauge constraints in one- and two-dimensional lattice gauge theories can be identified. Furthermore, we establish that the CoTra reliably detects non-local structures in images of correlated fermions in momentum space (Cooper pairs) and that it can distinguish percolating from non-percolating images.},
  archive      = {J_MLST},
  author       = {Abhinav Suresh and Henning Schlömer and Baran Hashemi and Annabelle Bohrdt},
  doi          = {10.1088/2632-2153/adc071},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025006},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Interpretable correlator transformer for image-like quantum matter data},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph representation of local environments for learning high-entropy alloy properties. <em>MLST</em>, <em>6</em>(2), 025005. (<a href='https://doi.org/10.1088/2632-2153/adc0e1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have excelled in predictive modeling for both crystals and molecules, owing to the expressiveness of graph representations. High-entropy alloys (HEAs), however, lack chemical long-range order, limiting the applicability of current graph representations. To overcome this challenge, we propose a representation of HEAs as a collection of local environment graphs. Based on this representation, we introduce the LESets machine learning model, an accurate, interpretable GNN for HEA property prediction. We demonstrate the accuracy of LESets in modeling the mechanical properties of quaternary HEAs. Through analyses and interpretation, we further extract insights into the modeling and design of HEAs. In a broader sense, LESets extends the potential applicability of GNNs to disordered materials with combinatorial complexity formed by diverse constituents and their flexible configurations.},
  archive      = {J_MLST},
  author       = {Hengrui Zhang and Ruishu Huang and Jie Chen and James M Rondinelli and Wei Chen},
  doi          = {10.1088/2632-2153/adc0e1},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025005},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Graph representation of local environments for learning high-entropy alloy properties},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On learning higher-order cumulants in diffusion models. <em>MLST</em>, <em>6</em>(2), 025004. (<a href='https://doi.org/10.1088/2632-2153/adc53a'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To analyse how diffusion models learn correlations beyond Gaussian ones, we study the behaviour of higher-order cumulants, or connected n -point functions, under both the forward and backward process. We derive explicit expressions for the moment- and cumulant-generating functionals, in terms of the distribution of the initial data and properties of forward process. It is shown analytically that during the forward process higher-order cumulants are conserved in models without a drift, such as the variance-expanding scheme, and that therefore the endpoint of the forward process maintains nontrivial correlations. We demonstrate that since these correlations are encoded in the score function, higher-order cumulants are learnt in the backward process, also when starting from a normal prior. We confirm our analytical results in an exactly solvable toy model with nonzero cumulants and in scalar lattice field theory.},
  archive      = {J_MLST},
  author       = {Gert Aarts and Diaa E Habibi and Lingxiao Wang and Kai Zhou},
  doi          = {10.1088/2632-2153/adc53a},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025004},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {On learning higher-order cumulants in diffusion models},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inferring interpretable models of fragmentation functions using symbolic regression. <em>MLST</em>, <em>6</em>(2), 025003. (<a href='https://doi.org/10.1088/2632-2153/adb3ec'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning is rapidly making its path into the natural sciences, including high-energy physics. We present the first study that infers, directly from experimental data, a functional form of fragmentation functions. The latter represent a key ingredient to describe physical observables measured in high-energy physics processes that involve hadron production, and predict their values at different energies. Fragmentation functions cannot be calculated in theory and have to be determined instead from data. Traditional approaches rely on global fits of experimental data to learn the parameters of a pre-assumed functional form inspired from phenomenological models of hadron production. This novel approach uses an ML technique, namely symbolic regression (SR), to learn an analytical model from measured charged hadron multiplicities. The function studied by SR resembles the Lund string function and describes the data well, thus representing a potential candidate for use in global FFs fits.},
  archive      = {J_MLST},
  author       = {Nour Makke and Sanjay Chawla},
  doi          = {10.1088/2632-2153/adb3ec},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025003},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Inferring interpretable models of fragmentation functions using symbolic regression},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tensor tree learns hidden relational structures in data to construct generative models. <em>MLST</em>, <em>6</em>(2), 025002. (<a href='https://doi.org/10.1088/2632-2153/adc2c7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the tensor tree network with the Born machine framework, we propose a general method for constructing a generative model by expressing the target distribution function as the amplitude of the quantum wave function represented by a tensor tree. The key idea is dynamically optimizing the tree structure that minimizes the bond mutual information. The proposed method offers enhanced performance and uncovers hidden relational structures in the target data. We illustrate potential practical applications with four examples: (i) random patterns, (ii) QMNIST handwritten digits, (iii) Bayesian networks, and (iv) the pattern of stock price fluctuation pattern in S&P500. In (i) and (ii), the strongly correlated variables were concentrated near the center of the network; in (iii), the causality pattern was identified; and in (iv), a structure corresponding to the eleven sectors emerged.},
  archive      = {J_MLST},
  author       = {Kenji Harada and Tsuyoshi Okubo and Naoki Kawashima},
  doi          = {10.1088/2632-2153/adc2c7},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025002},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Tensor tree learns hidden relational structures in data to construct generative models},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative super-resolution AI accelerates nanoscale analysis of cells. <em>MLST</em>, <em>6</em>(2), 025001. (<a href='https://doi.org/10.1088/2632-2153/adc3e9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Super-resolution microscopy (SRM) surpasses Abbe's diffraction limit, thus enabling nanoscale observation of cells. However, SRM techniques, such as stochastic optical reconstruction microscopy (STORM), suffer from long acquisition times which can significantly impact imaging throughput. To address this issue, we adapted the enhanced super-resolution generative adversarial network from natural to microscopy images. Our goal is to generate super-resolution images from widefield microscopy images in shorter times. We implemented this for imaging microtubules of cells to obtain STORM-like images. Different models were trained by using transfer learning and progressive fine-tuning. The generated images, evaluated by peak signal-to-noise ratio, structural similarity index and expert human validation, prove that this deep learning approach is suitable for microscopy, allowing for 4x-higher throughput of nanoscale imaging compared to unsupported techniques.},
  archive      = {J_MLST},
  author       = {Simone Lossano and Simone Capaccioli and Francesca Cella Zanacchi and Eleonora Da Pozzo and Francesca Del Debbio and Maria Evelina Fantacci and Francesca Lizzi and Raffaella Magrassi and Benedetta Noferi and Dario Pisignano and Camilla Scapicchio and Alessandra Retico},
  doi          = {10.1088/2632-2153/adc3e9},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {025001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Generative super-resolution AI accelerates nanoscale analysis of cells},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ChemLit-QA: A human evaluated dataset for chemistry RAG tasks. <em>MLST</em>, <em>6</em>(2), 020601. (<a href='https://doi.org/10.1088/2632-2153/adc2d6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieval-Augmented Generation (RAG) is a widely used strategy in Large-Language Models (LLMs) to extrapolate beyond the inherent pre-trained knowledge. Hence, RAG is crucial when working in data-sparse fields such as Chemistry. The evaluation of RAG systems is commonly conducted using specialized datasets. However, existing datasets, typically in the form of scientific Question-Answer-Context (QAC) triplets or QA pairs, are often limited in size due to the labor-intensive nature of manual curation or require further quality assessment when generated through automated processes. This highlights a critical need for large, high-quality datasets tailored to scientific applications. We introduce ChemLit-QA, a comprehensive, expert-validated, open-source dataset comprising over 1,000 entries specifically designed for chemistry. Our approach involves the initial generation and filtering of a QAC dataset using an automated framework based on GPT-4 Turbo, followed by rigorous evaluation by chemistry experts. Additionally, we provide two supplementary datasets: ChemLit-QA-neg focused on negative data, and ChemLit-QA-multi focused on multihop reasoning tasks for LLMs, which complement the main dataset on hallucination detection and more reasoning-intensive tasks.},
  archive      = {J_MLST},
  author       = {Geemi P Wellawatte and Huixuan Guo and Magdalena Lederbauer and Anna Borisova and Matthew Hart and Marta Brucka and Philippe Schwaller},
  doi          = {10.1088/2632-2153/adc2d6},
  journal      = {Machine Learning: Science and Technology},
  month        = {4},
  number       = {2},
  pages        = {020601},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {ChemLit-QA: A human evaluated dataset for chemistry RAG tasks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty quantification with bayesian higher order ReLU-KANs. <em>MLST</em>, <em>6</em>(1), 015073. (<a href='https://doi.org/10.1088/2632-2153/adbeb7'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the first method of uncertainty quantification in the domain of Kolmogorov–Arnold Networks, specifically focusing on (Higher Order) ReLU-KANs to enhance computational efficiency given the computational demands of Bayesian methods. The method we propose is general in nature, providing access to both epistemic and aleatoric uncertainties. It is also capable of generalization to other various basis functions. We validate our method through a series of closure tests, commonly found in the KAN literature, including simple one-dimensional functions and application to the domain of (stochastic) partial differential equations. Referring to the latter, we demonstrate the method's ability to correctly identify functional dependencies introduced through the inclusion of a stochastic term.},
  archive      = {J_MLST},
  author       = {J Giroux and C Fanelli},
  doi          = {10.1088/2632-2153/adbeb7},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015073},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Uncertainty quantification with bayesian higher order ReLU-KANs},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving early detection of gravitational waves from binary neutron stars using CNNs and FPGAs. <em>MLST</em>, <em>6</em>(1), 015072. (<a href='https://doi.org/10.1088/2632-2153/adbf66'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of gravitational waves (GWs) from binary neutron stars (BNSs) with possible telescope follow-ups opens a window to ground-breaking discoveries in the field of multi-messenger astronomy. With the improved sensitivity of current and future GW detectors, more BNS detections are expected in the future. Therefore, enhancing low-latency GW search algorithms to achieve rapid speed, high accuracy, and low computational cost is essential. One innovative solution to reduce latency is the use of machine learning (ML) methods embedded in field-programmable gate arrays (FPGAs). In this work, we present a novel WaveNet -based method, leveraging the state-of-the-art ML model, to produce early-warning alerts for BNS systems. Using simulated GW signals embedded in Gaussian noise from the Advanced LIGO and Advanced Virgo detectors' third observing run (O3) as a proof-of-concept dataset, we demonstrate significant performance improvements. Compared to the current leading ML-based early-warning system, our approach enhances detection accuracy from 66.81% to 76.22% at a 1% false alarm probability. Furthermore, we evaluate the time, energy, and economical cost of our model across CPU, GPU, and FPGA platforms, showcasing its potential for deployment in real-time GW detection pipelines.},
  archive      = {J_MLST},
  author       = {Ana Martins and Melissa Lopez and Gregory Baltus and Quirijn Meijer and Marc van der Sluys and Chris Van Den Broeck and Sarah Caudill},
  doi          = {10.1088/2632-2153/adbf66},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015072},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Improving early detection of gravitational waves from binary neutron stars using CNNs and FPGAs},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-fidelity transfer learning for quantum chemical data using a robust density functional tight binding baseline. <em>MLST</em>, <em>6</em>(1), 015071. (<a href='https://doi.org/10.1088/2632-2153/adc222'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has revolutionized the development of interatomic potentials over the past decade, offering unparalleled computational speed without compromising accuracy. However, the performance of these models is highly dependent on the quality and amount of training data. Consequently, the current scarcity of high-fidelity datasets (i.e. beyond semilocal density functional theory) represents a significant challenge for further improvement. To address this, this study investigates the performance of transfer learning (TL) across multiple fidelities for both molecules and materials. Crucially, we disentangle the effects of multiple fidelities and different configuration/chemical spaces for pre-training and fine-tuning, in order to gain a deeper understanding of TL for chemical applications. This reveals that negative transfer, driven by noise from low-fidelity methods such as a density functional tight binding baseline, can significantly impact fine-tuned models. Despite this, the multi-fidelity approach demonstrates superior performance compared to single-fidelity learning. Interestingly, it even outperforms TL based on foundation models in some cases, by leveraging an optimal overlap of pre-training and fine-tuning chemical spaces.},
  archive      = {J_MLST},
  author       = {Mengnan Cui and Karsten Reuter and Johannes T Margraf},
  doi          = {10.1088/2632-2153/adc222},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015071},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Multi-fidelity transfer learning for quantum chemical data using a robust density functional tight binding baseline},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LatentDE: Latent-based directed evolution for protein sequence design. <em>MLST</em>, <em>6</em>(1), 015070. (<a href='https://doi.org/10.1088/2632-2153/adc2e2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Directed evolution (DE) has been the most effective method for protein engineering that optimizes biological functionalities through a resource-intensive process of screening or selecting among a vast range of mutations. To mitigate this extensive procedure, recent advancements in machine learning-guided methodologies center around the establishment of a surrogate sequence-function model. In this paper, we propose latent-based DE (LDE), an evolutionary algorithm designed to prioritize the exploration of high-fitness mutants in the latent space. At its core, LDE is a regularized variational autoencoder (VAE), harnessing the capabilities of the state-of-the-art protein language model, ESM-2, to construct a meaningful latent space of sequences. From this encoded representation, we present a novel approach for efficient traversal on the fitness landscape, employing a combination of gradient-based methods and DE. Experimental evaluations conducted on eight protein sequence design tasks demonstrate the superior performance of our proposed LDE over previous baseline algorithms. Our implementation is publicly available at https://github.com/HySonLab/LatentDE .},
  archive      = {J_MLST},
  author       = {Thanh V T Tran and Nhat Khang Ngo and Viet Thanh Duy Nguyen and Truong-Son Hy},
  doi          = {10.1088/2632-2153/adc2e2},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015070},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {LatentDE: Latent-based directed evolution for protein sequence design},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-precision prediction of non-resonant high-order harmonics energetic particle modes via stacking ensemble strategies. <em>MLST</em>, <em>6</em>(1), 015069. (<a href='https://doi.org/10.1088/2632-2153/adbfdb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the prediction accuracy and stability of non-resonant high-order harmonics energetic particle modes (EPMs) is crucial for achieving tokamak plasmas steady state operation. This study adopts a stacking ensemble learning model for the EPMs prediction. This ensemble model has a 2-layer structure with the base learner and the meta-learner: the first layer, base learners include K-nearest neighbor regression, Extreme Gradient Boosting, gradient boosting regression (GBR), decision tree (DT) and support vector regression (SVR); the second layer, meta-learners output the final result via GBR. The developed stacking model is designed for multi-objective prediction, including the grow rate ( γ ) and mode frequency ( ω ) of the EPMs. The evaluation results indicate that the performance of the proposed model surpasses most supervised learning algorithms. Specifically, in comparison with the SVR and Bagging algorithms, the growth rate predictions of stacking model reduces Root mean squared error (RMSE) by 45% and 33%, mean absolute error (MAE) by 47% and 32%, and increases the R -squared coefficient ( R 2 ) by 5% and 3%, respectively. Similarly, for the mode frequency predictions, RMSE decreases by 34% and 65%, MAE by 23% and 50%, while R 2 improves by 2% and 7%, respectively. In terms of computational cost, the stacking model can conserve more time and expense than kinetic-hybrid simulations of EPMs. Therefore, the proposed model can be well applied to the prediction of the high-energy particle instability phenomenon in tokamak reactors.},
  archive      = {J_MLST},
  author       = {Sheng Liu and Zhenzhen Ren and Weihua Wang and Kai Zhong and Jinhong Yang and Hongwei Ning},
  doi          = {10.1088/2632-2153/adbfdb},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015069},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {High-precision prediction of non-resonant high-order harmonics energetic particle modes via stacking ensemble strategies},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generating quantum reservoir state representations with random matrices. <em>MLST</em>, <em>6</em>(1), 015068. (<a href='https://doi.org/10.1088/2632-2153/adc0e2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We demonstrate a novel approach to reservoir computation measurements using random matrices. We do so to motivate how atomic-scale devices could be used for real-world computational applications. Our approach uses random matrices to construct reservoir measurements, introducing a simple, scalable means of generating state representations. In our studies, two reservoirs, a five-atom Heisenberg spin chain and a five-qubit quantum circuit, perform time series prediction and data interpolation. The performance of the measurement technique and current limitations are discussed in detail, along with an exploration of the diversity of measurements provided by the random matrices. In addition, we explore the role of reservoir parameters such as coupling strength and measurement dimension, providing insight into how these learning machines could be automatically tuned for different problems. This research highlights the use of random matrices to measure simple quantum reservoirs for natural learning devices, and outlines a path forward for improving their performance and experimental realization.},
  archive      = {J_MLST},
  author       = {Samuel Tovey and Tobias Fellner and Christian Holm and Michael Spannowsky},
  doi          = {10.1088/2632-2153/adc0e2},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015068},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Generating quantum reservoir state representations with random matrices},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CNN-based vortex detection in atomic 2D bose gases in the presence of a phononic background. <em>MLST</em>, <em>6</em>(1), 015067. (<a href='https://doi.org/10.1088/2632-2153/adbfdc'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum vortices play a crucial role in both equilibrium and dynamical phenomena in two-dimensional (2D) superfluid systems. Experimental detection of these excitations in 2D ultracold atomic gases typically involves examining density depletions in absorption images, however the presence of a significant phononic background renders the problem challenging, beyond the capability of simple algorithms or the human eye. Here, we utilize a convolutional neural network to detect vortices in the presence of strong long- and intermediate-length scale density modulations in finite-temperature 2D Bose gases. We train the model on datasets obtained from ab initio Monte Carlo simulations using the classical-field method for density and phase fluctuations, and Gross–Pitaevskii simulation of realistic expansion dynamics. We use the model to analyze experimental images and benchmark its performance by comparing the results to the matter-wave interferometric detection of vortices, confirming the observed scaling of vortex density across the Berezinskii–Kosterlitz–Thouless critical point. The combination of a relevant simulation pipeline with machine-learning methods is a key development towards the comprehensive understanding of complex vortex-phonon dynamics in out-of-equilibrium 2D quantum systems.},
  archive      = {J_MLST},
  author       = {M Sesodia and S Sunami and E Chang and E Rydow and C J Foot and A Beregi},
  doi          = {10.1088/2632-2153/adbfdc},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015067},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {CNN-based vortex detection in atomic 2D bose gases in the presence of a phononic background},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid vision transformer framework for efficient and explainable SEM image-based nanomaterial classification. <em>MLST</em>, <em>6</em>(1), 015066. (<a href='https://doi.org/10.1088/2632-2153/adc072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scanning electron microscopy images, with their high potential to reveal detailed microstructural and compositional information across various fields, are challenging to label and process due to the large volumes being generated, the presence of noise and artifacts, and the reliance on domain expertise. Moreover, the lack of scalable, automated, and interpretable methods for analyzing scanning electron microscopy images has prompted this research, which focuses on three primary objectives. First, the use of semi-supervised learning techniques, including pseudo-labeling and consistency regularization, aims to utilize both labeled and unlabeled scanning electron microscopy data by generating pseudo-labels for the unlabeled data and enforcing consistency in predictions for perturbed inputs. Second, this study introduces a hybrid Vision Transformer (ViT-ResNet50) model, which combines the representational power of ViT with the feature extraction capabilities of ResNet50. Lastly, the use of SHapley Additive exPlanations enhances the model's interpretability, revealing critical image regions that contribute to predictions. To evaluate performance, the model is assessed using confusion matrices, test accuracy, precision, recall, F1 scores, receiver operating characteristic—area under the curve scores, model fit duration, and trainable parameters, along with a comparative analysis to demonstrate its competitiveness against state-of-the-art models in both semi-supervised and supervised (completely labeled data) settings. As a result, the semi-supervised based ViT-ResNet50 model achieved accuracies of 93.65% and 84.76% on the scanning electron microscopy Aversa and UltraHigh Carbon Steel Database, respectively, with notable interpretability, surpassing baseline models like ResNet101, InceptionV3, InceptionResNetV2, and InceptionV4. The findings highlight the potential of semi-supervised to improve model performance in scenarios with limited labeled data, though challenges such as class imbalance and increased computational cost suggest areas for further optimization.},
  archive      = {J_MLST},
  author       = {Manpreet Kaur and Camilo E Valderrama and Qian Liu},
  doi          = {10.1088/2632-2153/adc072},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015066},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Hybrid vision transformer framework for efficient and explainable SEM image-based nanomaterial classification},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian optimization of hybrid quantum LSTM in a mixed model for precipitation forecasting. <em>MLST</em>, <em>6</em>(1), 015065. (<a href='https://doi.org/10.1088/2632-2153/adbbad'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precipitation forecasting has important applications in meteorological research. Accurate forecasting is of great significance for reducing the impact of floods, optimizing crop planting plans, rationally allocating water resources, and ensuring traffic safety. However, the factors affecting precipitation are complex and nonlinear, and have spatiotemporal variability, making rainfall forecasting extremely challenging. In response to these challenges, this paper proposes a hybrid model based on temporal convolutional network, quantum long short-term memory network (QLSTM), and random forest regression (RFR) to achieve more accurate rainfall forecasting. The hyperparameters of the model are optimized using the Bayesian optimization algorithm to obtain the best performance. Experiments are conducted on meteorological datasets from Seattle and Ukraine, and the results are verified using mean absolute error (MAE), root mean square error (RMSE), and bias evaluation indicators. The results show that the proposed hybrid model outperforms traditional models such as RFR, support vector machine, K-nearest neighbor, LSTM, and QLSTM in terms of MAE, RMSE, and bias. The proposed model achieves improvements of 1.89 \% MAE, 2.65 \% RMSE, and 31 \% Bias, respectively. These results highlight the improved forecast accuracy and robustness of the proposed hybrid model. This research provides a new approach to weather forecasting and demonstrates the potential of combining quantum computing with traditional machine learning techniques.},
  archive      = {J_MLST},
  author       = {Yumin Dong and Huanxin Ding},
  doi          = {10.1088/2632-2153/adbbad},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015065},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Bayesian optimization of hybrid quantum LSTM in a mixed model for precipitation forecasting},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-powered data cleaning for LEGEND: A semi-supervised approach using affinity propagation and support vector machines. <em>MLST</em>, <em>6</em>(1), 015064. (<a href='https://doi.org/10.1088/2632-2153/adbb37'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neutrinoless double-beta decay ( 0\nu\beta\beta ) is a rare nuclear process that, if observed, will provide insight into the nature of neutrinos and help explain the matter-antimatter asymmetry in the Universe. The large enriched germanium experiment for neutrinoless double-beta decay (LEGEND) will operate in two phases to search for 0\nu\beta\beta . The first (second) stage will employ 200 (1000) kg of High-Purity Germanium (HPGe) enriched in 76 Ge to achieve a half-life sensitivity of 10 27 (10 28 ) years. In this study, we present a semi-supervised data-driven approach to remove non-physical events captured by HPGe detectors powered by a novel artificial intelligence model. We utilize affinity propagation to cluster waveform signals based on their shape and a support vector machine to classify them into different categories. We train, optimize, and test our model on data taken from a natural abundance HPGe detector installed in the Full Chain Test experimental stand at the University of North Carolina at Chapel Hill. We demonstrate that our model yields a maximum sacrifice of physics events of 0.024 ^{+0.004}_{-0.003} \% after data cleaning. Our model is being used to accelerate data cleaning development for LEGEND-200 and will serve to improve data cleaning procedures for LEGEND-1000.},
  archive      = {J_MLST},
  author       = {E León and A Li and M A Bahena Schott and B Bos and M Busch and J R Chapman and G L Duran and J Gruszko and R Henning and E L Martin and J F Wilkerson},
  doi          = {10.1088/2632-2153/adbb37},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015064},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine learning-powered data cleaning for LEGEND: A semi-supervised approach using affinity propagation and support vector machines},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning for structure-preserving universal stable koopman-inspired embeddings for nonlinear canonical hamiltonian dynamics. <em>MLST</em>, <em>6</em>(1), 015063. (<a href='https://doi.org/10.1088/2632-2153/adb9b5'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovering a suitable coordinate transformation for nonlinear systems enables the construction of simpler models, facilitating prediction, control, and optimization for complex nonlinear systems. To that end, Koopman operator theory offers a framework for global linearization of nonlinear systems, thereby allowing the usage of linear tools for design studies. In this work, we focus on the identification of global linearized embeddings for canonical nonlinear Hamiltonian systems through a symplectic transformation. While this task is often challenging, we leverage the power of deep learning to discover the desired embeddings. Furthermore, to overcome the shortcomings of Koopman operators for systems with continuous spectra, we apply the lifting principle and learn global cubicized embeddings. Additionally, a key emphasis is given to enforce the bounded stability for the dynamics of the discovered embeddings. We demonstrate the capabilities of deep learning in acquiring compact symplectic coordinate transformations and the corresponding simple dynamical models, fostering data-driven learning of nonlinear canonical Hamiltonian systems, even those with continuous spectra.},
  archive      = {J_MLST},
  author       = {Pawan Goyal and Süleyman Yıldız and Peter Benner},
  doi          = {10.1088/2632-2153/adb9b5},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015063},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Deep learning for structure-preserving universal stable koopman-inspired embeddings for nonlinear canonical hamiltonian dynamics},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic resetting mitigates latent gradient bias of SGD from label noise. <em>MLST</em>, <em>6</em>(1), 015062. (<a href='https://doi.org/10.1088/2632-2153/adbc46'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Giving up and starting over may seem wasteful in many situations such as searching for a target or training deep neural networks (DNNs). Our study, though, demonstrates that resetting from a checkpoint can significantly improve generalization performance when training DNNs with noisy labels. In the presence of noisy labels, DNNs initially learn the general patterns of the data but then gradually memorize the corrupted data, leading to overfitting. By deconstructing the dynamics of stochastic gradient descent (SGD), we identify the behavior of a latent gradient bias induced by noisy labels, which harms generalization. To mitigate this negative effect, we apply the stochastic resetting method to SGD, inspired by recent developments in the field of statistical physics achieving efficient target searches. We first theoretically identify the conditions where resetting becomes beneficial, and then we empirically validate our theory, confirming the significant improvements achieved by resetting. We further demonstrate that our method is both easy to implement and compatible with other methods for handling noisy labels. Additionally, this work offers insights into the learning dynamics of DNNs from an interpretability perspective, expanding the potential to analyze training methods through the lens of statistical physics.},
  archive      = {J_MLST},
  author       = {Youngkyoung Bae and Yeongwoo Song and Hawoong Jeong},
  doi          = {10.1088/2632-2153/adbc46},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015062},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Stochastic resetting mitigates latent gradient bias of SGD from label noise},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear gaussian process tomography with imposed non-negativity constraints on physical quantities for plasma diagnostics. <em>MLST</em>, <em>6</em>(1), 015061. (<a href='https://doi.org/10.1088/2632-2153/adbbae'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel tomographic method, nonlinear Gaussian process tomography (nonlinear GPT), that uses the Laplace approximation to impose constraints on non-negative physical quantities, such as the emissivity in plasma optical diagnostics. While positive-valued posteriors have previously been introduced through sampling-based approaches in the original GPT method, our alternative approach implements a logarithmic Gaussian process (log-GP) for faster computation and more natural enforcement of non-negativity. The effectiveness of the proposed log-GP tomography is demonstrated through a case study using the Ring Trap 1 device, where log-GPT outperforms existing methods, standard GPT, and the minimum Fisher information methods in terms of reconstruction accuracy. The results highlight the effectiveness of nonlinear GPT for imposing physical constraints in applications to an inverse problem.},
  archive      = {J_MLST},
  author       = {Kenji Ueda and Masaki Nishiura},
  doi          = {10.1088/2632-2153/adbbae},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015061},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Nonlinear gaussian process tomography with imposed non-negativity constraints on physical quantities for plasma diagnostics},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic deep learning based super-resolution for the shallow water equations. <em>MLST</em>, <em>6</em>(1), 015060. (<a href='https://doi.org/10.1088/2632-2153/ada19f'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correctly capturing the transition to turbulence in a barotropic instability requires fine spatial resolution. To reduce computational cost, we propose a dynamic super-resolution approach where a transient simulation on a coarse mesh is frequently corrected using a U-net-type neural network. For the nonlinear shallow water equations, we demonstrate that a simulation with the Icosahedral Nonhydrostatic ocean model with a 20 km resolution plus dynamic super-resolution trained on a 2.5km resolution achieves discretization errors comparable to a simulation with 10 km resolution. The neural network, originally developed for image-based super-resolution in post-processing, is trained to compute the difference between solutions on both meshes and is used to correct the coarse mesh solution every 12 h. We show that the ML-corrected coarse solution correctly maintains a balanced flow and captures the transition to turbulence in line with the higher resolution simulation. After an 8 d simulation, the L 2 -error of the corrected run is similar to a simulation run on a finer mesh. While mass is conserved in the corrected runs, we observe some spurious generation of kinetic energy.},
  archive      = {J_MLST},
  author       = {Maximilian Witte and Fabrício R Lapolli and Philip Freese and Sebastian Götschel and Daniel Ruprecht and Peter Korn and Christopher Kadow},
  doi          = {10.1088/2632-2153/ada19f},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015060},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Dynamic deep learning based super-resolution for the shallow water equations},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal equivariant architectures from the symmetries of matrix-element likelihoods. <em>MLST</em>, <em>6</em>(1), 015059. (<a href='https://doi.org/10.1088/2632-2153/adbab1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Matrix-Element Method (MEM) has long been a cornerstone of data analysis in high-energy physics. It leverages theoretical knowledge of parton-level processes and symmetries to evaluate the likelihood of observed events. In parallel, the advent of geometric deep learning has enabled neural network architectures that incorporate known symmetries directly into their design, leading to more efficient learning. This paper presents a novel approach that combines MEM-inspired symmetry considerations with equivariant neural network design for particle physics analysis. Even though Lorentz invariance and permutation invariance over all reconstructed objects are the largest and most natural symmetry in the input domain, we find that they are sub-optimal in most practical search scenarios. We propose a longitudinal boost-equivariant message-passing neural network architecture that preserves relevant discrete symmetries. We present numerical studies demonstrating MEM-inspired architectures achieve new state-of-the-art performance in distinguishing di-Higgs decays to four bottom quarks from the QCD background, with enhanced sample and parameter efficiencies. This synergy between MEM and equivariant deep learning opens new directions for physics-informed architecture design, promising more powerful tools for probing physics beyond the Standard Model.},
  archive      = {J_MLST},
  author       = {Daniel Maître and Vishal S Ngairangbam and Michael Spannowsky},
  doi          = {10.1088/2632-2153/adbab1},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015059},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Optimal equivariant architectures from the symmetries of matrix-element likelihoods},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards virtual painting recolouring using vision transformer on x-ray fluorescence datacubes. <em>MLST</em>, <em>6</em>(1), 015058. (<a href='https://doi.org/10.1088/2632-2153/adb937'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this contribution, we define (and test) a pipeline to perform virtual painting recolouring using raw data of x-ray Fluorescence (XRF) analysis on pictorial artworks. To circumvent the small dataset size, we generate a synthetic dataset, starting from a database of XRF spectra; furthermore, to ensure a better generalisation capacity (and to tackle the issue of in-memory size and inference time), we define a Deep Variational Embedding network to embed the XRF spectra into a lower dimensional, K-Means friendly, metric space. We thus train a set of models to assign coloured images to embedded XRF images. We report here the devised pipeline performances in terms of visual quality metrics, and we close on a discussion on the results.},
  archive      = {J_MLST},
  author       = {Alessandro Bombini and Fernando García-Avello Bofías and Francesca Giambi and Chiara Ruberto},
  doi          = {10.1088/2632-2153/adb937},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015058},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Towards virtual painting recolouring using vision transformer on x-ray fluorescence datacubes},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DeepAir: Deep learning and satellite imagery to estimate high-resolution PM2.5 at scale. <em>MLST</em>, <em>6</em>(1), 015057. (<a href='https://doi.org/10.1088/2632-2153/adb67a'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air pollution, specifically PM 2.5 , has become a significant global concern owing to its detrimental impacts on public health. Even so, the high-resolution monitoring of air pollution is still a challenge on a global scale. To cope with this, machine learning (ML) techniques have been utilized to infer the concentration of air pollutants at a fine scale. In this study, we propose DeepAir , a learning framework for estimating PM 2.5 concentrations at a fine scale with sparsely distributed observations. DeepAir integrates a pre-trained convolutional neural network with the LightGBM method. This framework estimates the PM 2.5 concentration of a given patch, utilizing a synergy of geographical information, meteorological conditions, and satellite observations. We select California as the focal region and train the model with data from 2014 to 2017 provided by 130 PM 2.5 observation stations in the state. Upon training, the model can be applied to estimate the daily PM 2.5 concentrations at 1 km resolution across California. Our methodology meticulously incorporates meteorological variables, with a particular emphasis on wildfire propagation, and contemplates the complex interplay of various features. To ascertain the efficacy of our model, we employ the 10-fold cross-validation technique, which confirms that our model surpasses traditional ML and standalone deep learning methods.},
  archive      = {J_MLST},
  author       = {Wenxuan Guo and Zhaoping Hu and Ling Jin and Yanyan Xu and Marta C Gonzalez},
  doi          = {10.1088/2632-2153/adb67a},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {015057},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {DeepAir: Deep learning and satellite imagery to estimate high-resolution PM2.5 at scale},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diverse explanations from data-driven and domain-driven perspectives in the physical sciences. <em>MLST</em>, <em>6</em>(1), 013002. (<a href='https://doi.org/10.1088/2632-2153/ad9137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning methods have been remarkably successful in material science, providing novel scientific insights, guiding future laboratory experiments, and accelerating materials discovery. Despite the promising performance of these models, understanding the decisions they make is also essential to ensure the scientific value of their outcomes. However, there is a recent and ongoing debate about the diversity of explanations, which potentially leads to scientific inconsistency. This Perspective explores the sources and implications of these diverse explanations in ML applications for physical sciences. Through three case studies in materials science and molecular property prediction, we examine how different models, explanation methods, levels of feature attribution, and stakeholder needs can result in varying interpretations of ML outputs. Our analysis underscores the importance of considering multiple perspectives when interpreting ML models in scientific contexts and highlights the critical need for scientists to maintain control over the interpretation process, balancing data-driven insights with domain expertise to meet specific scientific needs. By fostering a comprehensive understanding of these inconsistencies, we aim to contribute to the responsible integration of eXplainable artificial intelligence into physical sciences and improve the trustworthiness of ML applications in scientific discovery.},
  archive      = {J_MLST},
  author       = {Sichao Li and Xin Wang and Amanda Barnard},
  doi          = {10.1088/2632-2153/ad9137},
  journal      = {Machine Learning: Science and Technology},
  month        = {3},
  number       = {1},
  pages        = {013002},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Diverse explanations from data-driven and domain-driven perspectives in the physical sciences},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced feature encoding and classification on distributed quantum hardware. <em>MLST</em>, <em>6</em>(1), 015056. (<a href='https://doi.org/10.1088/2632-2153/adb4bc'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The steady progress of quantum hardware is motivating the search for novel quantum algorithm optimization strategies for near-term, real-world applications. In this study, we propose a novel feature map optimization strategy for quantum support vector machines (QSVMs), designed to enhance binary classification while taking into account backend-specific parameters, including qubit connectivity, native gate sets, and circuit depth, which are critical factors in noisy intermediate scale quantum devices. The dataset we utilised belongs to the neutrino physics domain, with applications in the search for neutrinoless double beta decay. A key contribution of this work is the parallelization of the classification task to commercially available superconducting quantum hardware to speed up the genetic search processes. The study was carried out by partitioning each quantum processing unit (QPU) into several sub-units with the same topology to implement individual QSVM instances. We conducted parallelization experiments with three IBM backends with more than 100 qubits, ranking the sub-units based on their susceptibility to noise. Data-driven simulations show how, under certain restrictions, parallelized genetic optimization can occur with the tested devices when retaining the top 20% ranked sub-units in the QPU.},
  archive      = {J_MLST},
  author       = {R Moretti and A Giachero and V Radescu and M Grossi},
  doi          = {10.1088/2632-2153/adb4bc},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015056},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Enhanced feature encoding and classification on distributed quantum hardware},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DCG—differentiable connected geometries for AI-compatible multi-domain optimization and inverse design. <em>MLST</em>, <em>6</em>(1), 015055. (<a href='https://doi.org/10.1088/2632-2153/adb3ef'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of geometry and topology optimization, discovering geometries that optimally satisfy specific problem criteria is a complex challenge in both engineering and scientific research. In this work, we propose a new approach for the creation of multidomain connected geometries that are designed to work with automatic differentiation. We introduce the concept of differentiable connected geometries, discussing its theoretical aspects and illustrating its application through simple toy examples and a more sophisticated photonic optimization task. Since these geometries are built upon the principles of automatic differentiation, they are compatible with existing deep learning frameworks, a feature we demonstrate via the application examples. This methodology provides a systematic way to approach geometric design and optimization in computational fields involving dependent geometries, potentially improving the efficiency and effectiveness of optimization tasks in scientific and engineering applications.},
  archive      = {J_MLST},
  author       = {Alexander Luce and Daniel Grünbaum and Florian Marquardt},
  doi          = {10.1088/2632-2153/adb3ef},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015055},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {DCG—differentiable connected geometries for AI-compatible multi-domain optimization and inverse design},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New gravitational wave discoveries enabled by machine learning. <em>MLST</em>, <em>6</em>(1), 015054. (<a href='https://doi.org/10.1088/2632-2153/adb5ed'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of gravitational waves (GWs) has revolutionized our understanding of the Universe, offering unprecedented insights into its dynamics. A major goal of GW data analysis is to speed up the detection and parameter estimation process using machine learning (ML) techniques, in light of an anticipated surge in detected events that would render traditional methods impractical. Here, we present new GW candidate events, the first to be identified in data from a network of interferometric detectors through ML. We discuss several new enhancements of our ResNet-based deep learning code, AresGW, that increased its sensitivity, including a new hierarchical classification of triggers, based on different noise and frequency filters. The enhancements resulted in a significant reduction in the false alarm rate, allowing AresGW to surpass traditional pipelines in the number of detected events in its effective training range (single source masses between 7 and 50 solar masses and source chirp masses between 10 and 40 solar masses), when the new detections are included. We calculate the astrophysical significance of events detected with AresGW using a logarithmic ranking statistic and injections into O3 data. Furthermore, we present spectrograms, parameter estimation, and reconstruction in the time domain for our new candidate events and discuss the distribution of their properties. In addition, the AresGW code exhibited very good performance when tested across various two-detector setups and on observational data from the O1 and O2 observing periods. Our findings underscore the remarkable potential of AresGW as a fast and sensitive detection algorithm for GW astronomy, paving the way for a larger number of future discoveries.},
  archive      = {J_MLST},
  author       = {Alexandra E Koloniari and Evdokia C Koursoumpa and Paraskevi Nousi and Paraskevas Lampropoulos and Nikolaos Passalis and Anastasios Tefas and Nikolaos Stergioulas},
  doi          = {10.1088/2632-2153/adb5ed},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015054},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {New gravitational wave discoveries enabled by machine learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable and accurate simulation of electrolyte solutions with quantum chemical accuracy. <em>MLST</em>, <em>6</em>(1), 015053. (<a href='https://doi.org/10.1088/2632-2153/adaf76'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrolyte solutions play critical role in a vast range of important applications, yet an accurate and scalable method of predicting their properties without fitting to experiment has remained out of reach, despite over a century of effort. Here, we combine state-of-the-art density functional theory and equivariant neural network potentials to demonstrate this capability, reproducing key structural, thermodynamic, and kinetic properties. We show that neural network potentials can be recursively trained on a subset of their own output to enable coarse-grained/continuum-solvent molecular simulations that can access much longer timescales than possible with all atom simulations. We observe the surprising formation of Li cation dimers along with identical anion-anion pairing of chloride and bromide anions. Finally, we simulate the crystal phase and infinite dilution pairing free energies despite being trained only on moderate concentration solutions. This approach should be scaled to build a greatly expanded database of electrolyte solution properties than currently exists.},
  archive      = {J_MLST},
  author       = {Junji Zhang and Joshua Pagotto and Tim Gould and Timothy T Duignan},
  doi          = {10.1088/2632-2153/adaf76},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015053},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Scalable and accurate simulation of electrolyte solutions with quantum chemical accuracy},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Refereeing the referees: Evaluating two-sample tests for validating generators in precision sciences. <em>MLST</em>, <em>6</em>(1), 015052. (<a href='https://doi.org/10.1088/2632-2153/adb3ee'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a robust methodology to evaluate the performance and computational efficiency of non-parametric two-sample tests, specifically designed for high-dimensional generative models in scientific applications such as in particle physics. The study focuses on tests built from univariate integral probability measures: the sliced Wasserstein distance and the mean of the Kolmogorov–Smirnov (KS) statistics, already discussed in the literature, and the novel sliced KS statistic. These metrics can be evaluated in parallel, allowing for fast and reliable estimates of their distribution under the null hypothesis. We also compare these metrics with the recently proposed unbiased Fréchet Gaussian distance and the unbiased quadratic Maximum Mean Discrepancy, computed with a quartic polynomial kernel. We evaluate the proposed tests on various distributions, focusing on their sensitivity to deformations parameterized by a single parameter ε . Our experiments include correlated Gaussians and mixtures of Gaussians in 5, 20, and 100 dimensions, and a particle physics dataset of gluon jets from the JetNet dataset, considering both jet- and particle-level features. Our results demonstrate that one-dimensional-based tests provide a level of sensitivity comparable to other multivariate metrics, but with significantly lower computational cost, making them ideal for evaluating generative models in high-dimensional settings. This methodology offers an efficient, standardized tool for model comparison and can serve as a benchmark for more advanced tests, including machine-learning-based approaches.},
  archive      = {J_MLST},
  author       = {Samuele Grossi and Marco Letizia and Riccardo Torre},
  doi          = {10.1088/2632-2153/adb3ee},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015052},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Refereeing the referees: Evaluating two-sample tests for validating generators in precision sciences},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autoencoder-assisted study of directed percolation with spatial long-range interactions. <em>MLST</em>, <em>6</em>(1), 015051. (<a href='https://doi.org/10.1088/2632-2153/adb370'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining the universality class of reaction–diffusion processes with long-range interactions in non-equilibrium phase transitions is both challenging and intriguing. Identifying critical points is fundamental for studying the phase transition characteristics of these universality classes. Unlike Monte Carlo simulations of statistical system observables, machine learning methods can extract evolutionary information from clusters of such systems, enabling a faster approach to phase transition regions. We developed a method that uses the one-dimensional encoding output of a stacked autoencoder (SAE) to determine the critical point in systems undergoing (1+1)-dimensional directed percolation with spatial long-range interactions. We validate this method by examining the power-law behavior of particle density at the critical point, which strongly supports our approach. As the system adheres to the scaling relation t_f{\sim}L^{z} at the critical point, we conducted extensive simulations at this critical probability to determine the dynamic exponent z . In addition, the SAE is also capable of identifying the characteristic time of critical states. Finally, we tested two other heavy-tailed distributions that generate random step lengths: the Lévy distribution and the Cauchy distribution, which introduce different global spreading mechanisms. This method remains effective for determining the critical points in these systems. Our findings highlight the promising applications of SAE techniques for processes involving long-range interactions.},
  archive      = {J_MLST},
  author       = {Yanyang Wang and Yuxiang Yang and Wei Li},
  doi          = {10.1088/2632-2153/adb370},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015051},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Autoencoder-assisted study of directed percolation with spatial long-range interactions},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning group invariant Calabi–Yau metrics by fundamental domain projections. <em>MLST</em>, <em>6</em>(1), 015050. (<a href='https://doi.org/10.1088/2632-2153/adb4bb'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present new invariant machine learning models that approximate the Ricci-flat metric on Calabi–Yau (CY) manifolds with discrete symmetries. We accomplish this by combining state of the art models for predicting such metrics, based on the so-called φ -model of the cymetric package, with non-trainable, G -invariant, canonicalization layers that project the φ -model's input data (i.e. points sampled from the CY geometry) to the fundamental domain of a given symmetry group G . These G -invariant layers are easy to concatenate, provided one compatibility condition is fulfilled, and combine well with both standard and spectral versions of the φ -model. Through experiments on different CY geometries, we find that, for fixed point sample size and training time, canonicalized models give slightly more accurate metric approximations than the standard φ -model. On highly symmetric spaces, we also observe significantly faster convergence upon training. The method may also be used to compute the Ricci-flat metric on smooth CY quotients. We demonstrate this aspect by experiments on a smooth \mathbb{Z}^2_5 quotient of a 5-parameter quintic CY manifold.},
  archive      = {J_MLST},
  author       = {Yacoub Hendi and Magdalena Larfors and Moritz Walden},
  doi          = {10.1088/2632-2153/adb4bb},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015050},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Learning group invariant Calabi–Yau metrics by fundamental domain projections},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast bayesian inference for neutrino non-standard interactions at dark matter direct detection experiments. <em>MLST</em>, <em>6</em>(1), 015049. (<a href='https://doi.org/10.1088/2632-2153/adb3ed'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-dimensional parameter spaces are commonly encountered in physics theories that go beyond the standard model. However, they often possess complicated posterior geometries that are expensive to traverse using techniques traditional to astroparticle physics. Several recent innovations, which are only beginning to make their way into this field, have made navigating such complex posteriors possible. These include GPU acceleration, automatic differentiation, and neural-network-guided reparameterization. We apply these advancements to dark matter direct detection experiments in the context of non-standard neutrino interactions and benchmark their performances against traditional nested sampling techniques when conducting Bayesian inference. Compared to nested sampling alone, we find that these techniques increase performance for both nested sampling and Hamiltonian Monte Carlo, accelerating inference by factors of \mathord{\sim} 100 and \mathord{\sim} 60 , respectively. As nested sampling also evaluates the Bayesian evidence, these advancements can be exploited to improve model comparison performance while retaining compatibility with existing implementations that are widely used in the natural sciences. Using these techniques, we perform the first scan in the neutrino non-standard interactions parameter space for direct detection experiments whereby all parameters are allowed to vary simultaneously. We expect that these advancements are broadly applicable to other areas of astroparticle physics featuring multi-dimensional parameter spaces.},
  archive      = {J_MLST},
  author       = {Dorian W P Amaral and Shixiao Liang and Juehang Qin and Christopher Tunnell},
  doi          = {10.1088/2632-2153/adb3ed},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015049},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Fast bayesian inference for neutrino non-standard interactions at dark matter direct detection experiments},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LTAU-FF: Loss trajectory analysis for uncertainty in atomistic force fields. <em>MLST</em>, <em>6</em>(1), 015048. (<a href='https://doi.org/10.1088/2632-2153/adb4b9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model ensembles are effective tools for estimating prediction uncertainty in deep learning atomistic force fields. However, their widespread adoption is hindered by high computational costs and overconfident error estimates. In this work, we address these challenges by leveraging distributions of per-sample errors obtained during training and employing a distance-based similarity search in the model latent space. Our method, which we call LTAU (Loss Trajectory Analysis for Uncertainty), efficiently estimates the full probability distribution function of errors for any test point using the logged training errors, achieving speeds that are 2–3 orders of magnitudes faster than typical ensemble methods and allowing it to be used for tasks where training or evaluating multiple models would be infeasible. We apply LTAU towards estimating parametric uncertainty in atomistic force fields ( LTAU-FF ), demonstrating that it produces well-calibrated confidence intervals and predicts errors that correlate strongly with the true errors for data near the training domain. Furthermore, we show that the errors predicted by LTAU-FF can be used in practical applications for detecting out-of-domain data, tuning model performance, and predicting failure during simulations. We believe that LTAU will be a valuable tool for uncertainty quantification in atomistic force fields and is a promising method that should be further explored in other domains of machine learning.},
  archive      = {J_MLST},
  author       = {Joshua A Vita and Amit Samanta and Fei Zhou and Vincenzo Lordi},
  doi          = {10.1088/2632-2153/adb4b9},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015048},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {LTAU-FF: Loss trajectory analysis for uncertainty in atomistic force fields},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Validating large-scale quantum machine learning: Efficient simulation of quantum support vector machines using tensor networks. <em>MLST</em>, <em>6</em>(1), 015047. (<a href='https://doi.org/10.1088/2632-2153/adb4ba'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an efficient tensor-network-based approach for simulating large-scale quantum circuits exemplified by quantum support vector machines (QSVMs). Experimentally, leveraging the cuTensorNet library on multiple GPUs, our method effectively reduces the exponential runtime growth to near-quadratic scaling with respect to the number of qubits in practical scenarios. Traditional state-vector simulations become computationally infeasible beyond approximately 50 qubits; in contrast, our simulator successfully handles QSVMs with up to 784 qubits, executing simulations within seconds on a single high-performance GPU. Furthermore, utilizing the message passing interface for multi-GPU environments, our method demonstrates strong linear scalability, effectively decreasing computation time as dataset sizes increase. We validate our framework using the MNIST and Fashion MNIST datasets, achieving successful multiclass classification and highlighting the potential of QSVMs for high-dimensional data analysis. By integrating tensor-network techniques with advanced high-performance computing resources, this work demonstrates both the feasibility and scalability of simulating large-qubit quantum machine learning models, providing a valuable validation tool within the emerging Quantum-HPC ecosystem.},
  archive      = {J_MLST},
  author       = {Kuan-Cheng Chen and Tai-Yue Li and Yun-Yuan Wang and Simon See and Chun-Chieh Wang and Robert Wille and Nan-Yow Chen and An-Cheng Yang and Chun-Yu Lin},
  doi          = {10.1088/2632-2153/adb4ba},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015047},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Validating large-scale quantum machine learning: Efficient simulation of quantum support vector machines using tensor networks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overcoming sparse datasets with multi-task learning as applied to high entropy alloys. <em>MLST</em>, <em>6</em>(1), 015046. (<a href='https://doi.org/10.1088/2632-2153/adb53c'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of novel High Entropy Alloys for use in high-temperature applications is an area of active interest due to their potential to provide exceptional properties compared to conventional alloys. Since the increased popularity of machine learning, an important cog in the design process has been training surrogate models on alloy properties. However, these Single-Task models are trained on individual mechanical properties and do not take advantage of the relatedness between properties. Multi-Task models can capture the interdependencies between tasks, leading to potentially more accurate predictions for all tasks. In this paper, we investigate if Multi-Task models can show improvement over Single-Task models when used for predicting the mechanical properties of these alloys. To ensure fair evaluation between the models, we apply L 0 regularization and skip connections to the models, which allows them to adjust the number of model parameters and depth for optimal performance. We find that the Multi-Task models can leverage task relationships to perform better than Single-Task models, especially for high amounts of missing data in the tasks. Furthermore, adding simple auxiliary targets can boost Multi-Task performance even further despite not being effective as input descriptors to single-task models themselves. We anticipate that the proposed strategies can achieve more accurate predictions and consequently enable better design capabilities for such data-constrained domains without incurring much additional computational cost.},
  archive      = {J_MLST},
  author       = {Arindam Debnath and Wesley F Reinhart},
  doi          = {10.1088/2632-2153/adb53c},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015046},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Overcoming sparse datasets with multi-task learning as applied to high entropy alloys},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging multi-task learning regressor chains for small and sparse tabular data in materials design. <em>MLST</em>, <em>6</em>(1), 015045. (<a href='https://doi.org/10.1088/2632-2153/adae53'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has become increasingly important in materials design, yet traditional single-task learning (STL) models fail to fully exploit the potential of available data in scenarios involving multiple targets and incomplete datasets. While STL models overlook the inherent correlations between target properties, this study showcases how multi-task learning (MTL) effectively leverages these correlations. Therefore, the performance of MTL methods compared to STL is evaluated across five datasets, covering twelve prediction tasks and incorporating different types and levels of data sparsity. Our findings reveal that MTL significantly outperforms STL, particularly in sparse data scenarios, with up to 15% prediction improvements across all tasks. Moreover, MTL methods utilizing regressor chains with automated machine learning tools achieve superior performance compared to those based on neural networks, with minimal training effort required. This work advances data efficiency in data-driven materials design, establishing MTL as a potent tool for simultaneous learning and predicting multiple material properties.},
  archive      = {J_MLST},
  author       = {Felix Conrad and Hajo Wiemer and Steffen Ihlenfeldt},
  doi          = {10.1088/2632-2153/adae53},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015045},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Leveraging multi-task learning regressor chains for small and sparse tabular data in materials design},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph neural network simulation of dispersed systems. <em>MLST</em>, <em>6</em>(1), 015044. (<a href='https://doi.org/10.1088/2632-2153/adb0a0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a graph neural network (GNN) that accurately simulates a multidisperse suspension of interacting spherical particles. Our machine learning framework is built upon the recent work of Sanchez-Gonzalez et al (2020 ICML vol 119 (PMLR) pp 8459–68) on graph network simulators, and efficiently learns the intricate dynamics of the interacting particles. Nodes and edges of the GNN correspond, respectively, to the particles with their individual properties/data (e.g. radius, position, velocity) and the pairwise interactions between the particles (e.g. electrostatics, hydrodynamics). A key contribution of our work is to account for the finite dimensions of the particles and their impact on the system dynamics. We test our GNN against a representative case study of a multidisperse mixture of two-dimensional spheres sedimenting under gravity in a liquid and interacting with each other by a Lennard–Jones potential. The present GNN framework offers a fast and accurate method for the theoretical study of complex physical systems such as field-induced behavior of colloidal suspensions and ionic liquids. Our implementation of the GNN is available on GitHub at github.com/rfjd/GNS-DispersedSystems .},
  archive      = {J_MLST},
  author       = {Aref Hashemi and Aliakbar Izadkhah},
  doi          = {10.1088/2632-2153/adb0a0},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015044},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A graph neural network simulation of dispersed systems},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Satellite image classification with neural quantum kernels. <em>MLST</em>, <em>6</em>(1), 015043. (<a href='https://doi.org/10.1088/2632-2153/ada86c'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving practical applications of quantum machine learning (QML) for real-world scenarios remains challenging despite significant theoretical progress. This paper proposes a novel approach for classifying satellite images, a task of particular relevance to the earth observation industry, using QML techniques. Specifically, we focus on classifying images that contain solar panels, addressing a complex real-world classification problem. Our approach begins with classical pre-processing to reduce the dimensionality of the satellite image dataset. We then apply neural quantum kernels-quantum kernels derived from trained quantum neural networks-for classification. We evaluate several strategies within this framework, demonstrating results that are competitive with the best classical methods. Key findings include the robustness of or results and their scalability, with successful performance achieved up to 8 qubits.},
  archive      = {J_MLST},
  author       = {Pablo Rodriguez-Grasa and Robert Farzan-Rodriguez and Gabriele Novelli and Yue Ban and Mikel Sanz},
  doi          = {10.1088/2632-2153/ada86c},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015043},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Satellite image classification with neural quantum kernels},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum resources of quantum and classical variational methods. <em>MLST</em>, <em>6</em>(1), 015042. (<a href='https://doi.org/10.1088/2632-2153/adaca2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational techniques have long been at the heart of atomic, solid-state, and many-body physics. They have recently extended to quantum and classical machine learning, providing a basis for representing quantum states via neural networks. These methods generally aim to minimize the energy of a given ansatz, though open questions remain about the expressivity of quantum and classical variational ansätze. The connection between variational techniques and quantum computing, through variational quantum algorithms, offers opportunities to explore the quantum complexity of classical methods. We demonstrate how the concept of non-stabilizerness, or magic, can create a bridge between quantum information and variational techniques and we show that energy accuracy is a necessary but not always sufficient condition for accuracy in non-stabilizerness. Through systematic benchmarking of neural network quantum states, matrix product states, and variational quantum methods, we show that while classical techniques are more accurate in non-stabilizerness, not accounting for the symmetries of the system can have a severe impact on this accuracy. Our findings form a basis for a universal expressivity characterization of both quantum and classical variational methods.},
  archive      = {J_MLST},
  author       = {Thomas Spriggs and Arash Ahmadi and Bokai Chen and Eliska Greplova},
  doi          = {10.1088/2632-2153/adaca2},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015042},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Quantum resources of quantum and classical variational methods},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning-based architecture search for quantum machine learning. <em>MLST</em>, <em>6</em>(1), 015041. (<a href='https://doi.org/10.1088/2632-2153/adaf75'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum machine learning (QML) models use encoding circuits to map data into a quantum Hilbert space. While it is well known that the architecture of these circuits significantly influences core properties of the resulting model, they are often chosen heuristically. In this work, we present a approach using reinforcement learning techniques to generate problem-specific encoding circuits to improve the performance of QML models. By specifically using a model-based reinforcement learning algorithm, we reduce the number of necessary circuit evaluations during the search, providing a sample-efficient framework. In contrast to previous search algorithms, our method uses a layered circuit structure that significantly reduces the search space. Additionally, our approach can account for multiple objectives such as solution quality and circuit depth. We benchmark our tailored circuits against various reference models, including models with problem-agnostic circuits and classical models. Our results highlight the effectiveness of problem-specific encoding circuits in enhancing QML model performance.},
  archive      = {J_MLST},
  author       = {Frederic Rapp and David A Kreplin and Marco F Huber and Marco Roth},
  doi          = {10.1088/2632-2153/adaf75},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015041},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Reinforcement learning-based architecture search for quantum machine learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Medical image segmentation assisted with clinical inputs via language encoder in a deep learning framework. <em>MLST</em>, <em>6</em>(1), 015040. (<a href='https://doi.org/10.1088/2632-2153/adb371'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Auto-segmentation of tumor volumes and organs at risk (OARs) is a critical step in cancer radiotherapy treatment planning, where rapid, precise adjustments to treatment plans are required to match the patient anatomy. Although auto-segmentation has been clinically accepted for most OARs, auto-segmentation of tumor volumes, particularly clinical target volumes (CTVs), remains a challenge. This difficulty arises because images alone are often insufficient to capture the necessary information for accurate delineation of microscopic tumor invasion invisible on the image itself. Methods: We propose a deep learning-based medical image segmentation framework designed to mimic the clinical process of delineating CTVs and OARs. At its core, the model performs precise segmentation of medical images while enhancing accuracy by integrating clinical information in text format. A transformer-based text encoder converts textual clinical data into vectors, which are incorporated into the segmentation process with image features. This integration bridges the gap between traditional automated segmentation methods and clinician-guided, context-rich delineations. The framework's effectiveness is demonstrated through a prostate segmentation example in the context of radiation therapy for localized prostate cancer, where incorporating clinical context significantly impacts the delineation process. Results: In our experiments, we included additional clinical information potentially influencing clinicians' prostate segmentation. The results show that our proposed method not only outperforms the baseline model, but also surpasses current state-of-the-art methods, with or without clinical contexts. Furthermore, our method demonstrates high performance even with limited data. Conclusion: This proposed segmentation framework has shown to significantly improve auto-segmentation, particularly for CTVs, in cancer radiotherapy.},
  archive      = {J_MLST},
  author       = {Hengrui Zhao and Biling Wang and Deepkumar Mistry and Jing Wang and Michael Dohopolski and Daniel Yang and Weiguo Lu and Steve Jiang and Dan Nguyen},
  doi          = {10.1088/2632-2153/adb371},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015040},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Medical image segmentation assisted with clinical inputs via language encoder in a deep learning framework},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A generative modeling approach to reconstructing 21 cm tomographic data. <em>MLST</em>, <em>6</em>(1), 015039. (<a href='https://doi.org/10.1088/2632-2153/adb19c'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyses of the cosmic 21 cm signal are hampered by astrophysical foregrounds that are far stronger than the signal itself. These foregrounds, typically confined to a wedge-shaped region in Fourier space, often necessitate the removal of a vast majority of modes, thereby degrading the quality of the data anisotropically. To address this challenge, we introduce a novel deep generative model based on stochastic interpolants to reconstruct the 21 cm data lost to wedge filtering. Our method leverages the non-Gaussian nature of the 21 cm signal to effectively map wedge-filtered 3D lightcones to samples from the conditional distribution of wedge-recovered lightcones. We demonstrate how our method is able to restore spatial information effectively, considering both varying cosmological initial conditions and astrophysics. Furthermore, we discuss a number of future avenues where this approach could be applied in analyses of the 21 cm signal, potentially offering new opportunities to improve our understanding of the Universe during the epochs of cosmic dawn and reionization. Code, pre-trained models, and scripts for making plots in this paper can be found here .},
  archive      = {J_MLST},
  author       = {Nashwan Sabti and Ram Purandhar Reddy Sudha and Julian B Muñoz and Siddharth Mishra-Sharma and Taewook Youn},
  doi          = {10.1088/2632-2153/adb19c},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015039},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A generative modeling approach to reconstructing 21 cm tomographic data},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coupled CANN-DEM simulation in solid mechanics. <em>MLST</em>, <em>6</em>(1), 015038. (<a href='https://doi.org/10.1088/2632-2153/adaf74'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A general, unified neural network approach as replacement for the finite element method without the need for analytic expressions for material laws is suggested. The complete simulation process from the material characterization to simulations on a structural level takes place in the new neural network framework. The drawback of many conventional analytic expressions of material laws to require large numbers of experiments for parametrization is addressed by an integrated inverse approach. Specifically, an adaptation of the Deep Energy Method is combined with a Constitutive Artificial Neural Network (CANN) and trained on measured displacement fields and prescribed boundary conditions in a coupled procedure. Tests on compressible and incompressible Neo-Hookean solids with up to twelve CANN parameters show high accuracy of the approach and very good generalization of CANNs. A small extent of data is required for robust and reliable training.},
  archive      = {J_MLST},
  author       = {Stefan Hildebrand and Jonathan Georg Friedrich and Melika Mohammadkhah and Sandra Klinge},
  doi          = {10.1088/2632-2153/adaf74},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015038},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Coupled CANN-DEM simulation in solid mechanics},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain knowledge-based deterministic graph traversal method for white blood cell classification. <em>MLST</em>, <em>6</em>(1), 015037. (<a href='https://doi.org/10.1088/2632-2153/adb126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {White blood cells (WBCs) play a crucial role in human immunity by defending the body against harmful antigens. Classifying WBCs into their five distinct types provides valuable information for assessing human health and identifying various medical conditions. Computer vision models in the literature utilize machine learning and deep learning techniques, to attain high classification accuracy, but they involve complex architectures. In contrast, the proposed work leverages domain knowledge about WBCs to construct a directed graph and applies a deterministic traversal method to the graph to perform classification. The proposed method is trained and tested using multiple datasets namely, the Blood Cell Count and Detection (BCCD) and LISC datasets to evaluate the performance on varying datasets. The performance metrics include accuracy, precision, recall, and F1-score. The results demonstrate the effectiveness of the approach, achieving 99.13% accuracy, 99.25% precision, 99.25% recall, and 99.25% F1 score, on the BCCD dataset. 97.05% accuracy, 97.04% precision, 96.93% recall, and 96.94% F1 score on the LISC dataset making it efficient for WBC classification task.},
  archive      = {J_MLST},
  author       = {Jeneessha P and Vinoth Kumar Balasubramanian},
  doi          = {10.1088/2632-2153/adb126},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015037},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Domain knowledge-based deterministic graph traversal method for white blood cell classification},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient monte carlo simulation of streamer discharges with deep-learning denoising models. <em>MLST</em>, <em>6</em>(1), 015036. (<a href='https://doi.org/10.1088/2632-2153/adaca1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric breakdown in non-conducting gases is a complex process that in its first stages is characterized by filamentary discharges called streamers. Streamer dynamics are inherently nonlinear and span broad temporal and spatial scales, making numerical simulation challenging. Although Monte Carlo methods are intuitive and they model the full electron energy distribution without a priori prescriptions, they suffer from artificial sampling noise which, combined with the non-linearity of streamers, distorts their evolution. Here we investigate the use of deep-learning techniques to mitigate the noise introduced by Monte Carlo sampling. We observe that traditional techniques for noise reduction in images are not satisfactory because they do not impose strict conservation of electric charge. Then we present a charge-conserving denoising filter to improve the efficiency of Monte Carlo simulations of streamers.},
  archive      = {J_MLST},
  author       = {F M Bayo-Muñoz and A Malagón-Romero and A Luque},
  doi          = {10.1088/2632-2153/adaca1},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015036},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Efficient monte carlo simulation of streamer discharges with deep-learning denoising models},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Closed-form interpretation of neural network classifiers with symbolic gradients. <em>MLST</em>, <em>6</em>(1), 015035. (<a href='https://doi.org/10.1088/2632-2153/ad9fd0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I introduce a unified framework for finding a closed-form interpretation of any single neuron in an artificial neural network. Using this framework I demonstrate how to interpret neural network classifiers to reveal closed-form expressions of the concepts encoded in their decision boundaries. In contrast to neural network-based regression, for classification, it is in general impossible to express the neural network in the form of a symbolic equation even if the neural network itself bases its classification on a quantity that can be written as a closed-form equation. The interpretation framework is based on embedding trained neural networks into an equivalence class of functions that encode the same concept. I interpret these neural networks by finding an intersection between the equivalence class and human-readable equations defined by a symbolic search space. The approach is not limited to classifiers or full neural networks and can be applied to arbitrary neurons in hidden layers or latent spaces.},
  archive      = {J_MLST},
  author       = {Sebastian J Wetzel},
  doi          = {10.1088/2632-2153/ad9fd0},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015035},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Closed-form interpretation of neural network classifiers with symbolic gradients},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inception networks, data augmentation and transfer learning in EEG-based photosensitivity diagnosis. <em>MLST</em>, <em>6</em>(1), 015034. (<a href='https://doi.org/10.1088/2632-2153/adb008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photosensitivity refers to a neurophysiological condition in which the brain generates epileptic discharges known as Photoparoxysmal Responses (PPR) in response to light flashes. In severe cases, these PPR can lead to epileptic seizures. The standardized diagnostic procedure for this condition is called Intermittent Photic Stimulation. During this procedure, the patient is exposed to a flashing light, aiming to trigger these epileptic reactions while preventing their full development. Meanwhile, brain activity is monitored using Electroencephalography, which is visually analyzed by clinical staff to identify these responses. Hence, the automatic detection of PPR becomes a highly unbalanced problem that has been barely studied in the literature due to photosensitivity's low prevalence. This research tackles this problem and proposes using Inception-based deep learning (DL) neural networks that, together with transfer learning, are trained in epilepsy seizure detection and tuned in the PPR automatic detection task. A data augmentation (DA) technique is also applied to balance the available data set, evaluating its effects on the DL models. The proposal outperformed state-of-the-art solutions in the literature, achieving higher ratios on standard performance metrics, and with DA significantly improving the Sensitivity without affecting Accuracy and Specificity. This project is currently being developed with patients from Burgos University Hospital, Spain.},
  archive      = {J_MLST},
  author       = {Fernando Moncada Martins and Víctor M González and José R Villar and Beatriz García López and Ana Isabel Gómez-Menéndez},
  doi          = {10.1088/2632-2153/adb008},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015034},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Inception networks, data augmentation and transfer learning in EEG-based photosensitivity diagnosis},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Randomized radial basis function neural network for solving multiscale elliptic equations. <em>MLST</em>, <em>6</em>(1), 015033. (<a href='https://doi.org/10.1088/2632-2153/ad979c'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ordinary deep neural network (DNN)-based methods frequently encounter difficulties when tackling multiscale and high-frequency partial differential equations. To overcome these obstacles and improve computational accuracy and efficiency, this paper presents the Randomized Radial Basis Function Neural Network (RRNN), an innovative approach explicitly crafted for solving multiscale elliptic equations. The RRNN method commences by decomposing the computational domain into non-overlapping subdomains. Within each subdomain, the solution to the localized subproblem is approximated by a RRNN with a Gaussian kernel. This network is distinguished by the random assignment of width and center coefficients for its activation functions, thereby rendering the training process focused solely on determining the weight coefficients of the output layer. For each subproblem, similar to the Petrov–Galerkin finite element method, a linear system will be formulated on the foundation of a weak formulation. Subsequently, a selection of collocation points is stochastically sampled at the boundaries of the subdomain, ensuring the satisfaction of C 0 and C 1 continuity and boundary conditions to couple these localized solutions. The network is ultimately trained using the least squares method to ascertain the output layer weights. To validate the RRNN method's effectiveness, an extensive array of numerical experiments has been executed. The RRNN is firstly compared with a variety of DNN methods based on gradient descent optimization. The comparative analysis demonstrates the RRNN's superior performance with respect to computational accuracy and training time. Furthermore, it is contrasted with to local extreme learning machine method, which also utilizes domain decomposition and the least squares method. The comparative findings suggest that the RRNN method can attain enhanced accuracy at a comparable computational cost, particularly pronounced in scenarios with a smaller scale ratio ɛ .},
  archive      = {J_MLST},
  author       = {Yuhang Wu and Ziyuan Liu and Wenjun Sun and Xu Qian},
  doi          = {10.1088/2632-2153/ad979c},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015033},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Randomized radial basis function neural network for solving multiscale elliptic equations},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantitative assessment of PINN inference on experimental data for gravity currents flows. <em>MLST</em>, <em>6</em>(1), 015032. (<a href='https://doi.org/10.1088/2632-2153/adaca0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we apply physics informed neural networks (PINNs) to infer velocity and pressure field from light attenuation technique (LAT) measurements for gravity current induced by lock-exchange. In a PINN model, physical laws are embedded in the loss function of a neural network, such that the model fits the training data but is also constrained to reduce the residuals of the governing equations. PINNs are able to solve ill-posed inverse problems training on sparse and noisy data, and therefore can be applied to real engineering applications. The noise robustness of PINNs and the model parameters are investigated in a 2 dimensions toy case on a lock-exchange configuration, employing synthetic data. Then we train a PINN with experimental LAT measurements and quantitatively compare the velocity fields inferred to particle image velocimetry measurements performed simultaneously on the same experiment. The results state that accurate and useful quantities can be derived from a PINN model trained on real experimental data which is encouraging for a better description of gravity currents.},
  archive      = {J_MLST},
  author       = {Mickaël Delcey and Yoann Cheny and Jean Schneider and Simon Becker and Sébastien Kiesgen De Richter},
  doi          = {10.1088/2632-2153/adaca0},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015032},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Quantitative assessment of PINN inference on experimental data for gravity currents flows},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Into the latent space of capacitive sensors: Interpolation and synthetic data generation using variational autoencoders. <em>MLST</em>, <em>6</em>(1), 015031. (<a href='https://doi.org/10.1088/2632-2153/adb009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For many sensing applications, collecting a large experimental dataset could be a time-consuming and expensive task that can also hinder the implementation of Machine Learning models for analyzing sensor data. Therefore, this paper proposes the generation of synthetic signals through a Variational Autoencoder (VAE) to enlarge a spectra dataset acquired with a capacitive sensor based on a Dielectric Resonator. Trained with signals of several water/glycerine concentrations, this generative model learns the dataset characteristics and builds a representative latent space. Consequently, exploring this latent space is a critical task to control the generation of synthetic signals and interpolating concentrations unmeasured by the sensor. For this reason, this paper proposes a search method based on Bayesian Optimization that automatically explores the latent space. The results show excellent signal reconstruction quality, proving that the VAE architecture can successfully generate realistic synthetic signals from capacitive sensors. In addition, the proposed search method obtains a reasonable interpolation capability by finding latent encodings that generate signals related to the target glycerin concentrations. Moreover, this approach could be extended to other sensing technologies.},
  archive      = {J_MLST},
  author       = {Miguel Monteagudo Honrubia and Francisco Javier Herraiz-Martínez and Javier Matanza Domingo},
  doi          = {10.1088/2632-2153/adb009},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015031},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Into the latent space of capacitive sensors: Interpolation and synthetic data generation using variational autoencoders},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine-learning emergent spacetime from linear response in future tabletop quantum gravity experiments. <em>MLST</em>, <em>6</em>(1), 015030. (<a href='https://doi.org/10.1088/2632-2153/adb09f'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel interpretable neural network (NN) model designed to perform precision bulk reconstruction under the AdS/CFT correspondence. According to the correspondence, a specific condensed matter system on a ring is holographically equivalent to a gravitational system on a bulk disk, through which tabletop quantum gravity experiments may be possible as reported in (Hashimoto et al 2023 Phys. Rev. Res. 5 023168). The purpose of this paper is to reconstruct a higher-dimensional gravity metric from the condensed matter system data via machine learning using the NN. Our machine reads spatially and temporarily inhomogeneous linear response data of the condensed matter system, and incorporates a novel layer that implements the Runge–Kutta method to achieve better numerical control. We confirm that our machine can let a higher-dimensional gravity metric be automatically emergent as its interpretable weights, using a linear response of the condensed matter system as data, through supervised machine learning. The developed method could serve as a foundation for generic bulk reconstruction, i.e. a practical solution to the AdS/CFT correspondence, and would be implemented in future tabletop quantum gravity experiments.},
  archive      = {J_MLST},
  author       = {Koji Hashimoto and Koshiro Matsuo and Masaki Murata and Gakuto Ogiwara and Daichi Takeda},
  doi          = {10.1088/2632-2153/adb09f},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015030},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine-learning emergent spacetime from linear response in future tabletop quantum gravity experiments},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discovering emergent connections in quantum physics research via dynamic word embeddings. <em>MLST</em>, <em>6</em>(1), 015029. (<a href='https://doi.org/10.1088/2632-2153/adb00a'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the field of quantum physics evolves, researchers naturally form subgroups focusing on specialized problems. While this encourages in-depth exploration, it can limit the exchange of ideas across structurally similar problems in different subfields. To encourage cross-talk among these different specialized areas, data-driven approaches using machine learning have recently shown promise to uncover meaningful connections between research concepts, promoting cross-disciplinary innovation. Current state-of-the-art approaches represent concepts using knowledge graphs and frame the task as a link prediction problem, where connections between concepts are explicitly modeled. In this work, we introduce a novel approach based on dynamic word embeddings for concept combination prediction. Unlike knowledge graphs, our method captures implicit relationships between concepts, can be learned in a fully unsupervised manner, and encodes a broader spectrum of information. We demonstrate that this representation enables accurate predictions about the co-occurrence of concepts within research abstracts over time. To validate the effectiveness of our approach, we provide a comprehensive benchmark against existing methods and offer insights into the interpretability of these embeddings, particularly in the context of quantum physics research. Our findings suggest that this representation offers a more flexible and informative way of modeling conceptual relationships in scientific literature.},
  archive      = {J_MLST},
  author       = {Felix Frohnert and Xuemei Gu and Mario Krenn and Evert van Nieuwenburg},
  doi          = {10.1088/2632-2153/adb00a},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015029},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Discovering emergent connections in quantum physics research via dynamic word embeddings},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep(er) reconstruction of imaging cherenkov detectors with swin transformers and normalizing flow models. <em>MLST</em>, <em>6</em>(1), 015028. (<a href='https://doi.org/10.1088/2632-2153/ada8f4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imaging Cherenkov detectors are crucial for particle identification (PID) in nuclear and particle physics experiments. Fast reconstruction algorithms are essential for near real-time alignment, calibration, data quality control, and efficient analysis. At the future electron–ion collider (EIC), the ePIC detector will feature a dual Ring Imaging Cherenkov (RICH) detector in the hadron direction, a Detector of Internally Reflected Cherenkov (DIRC) in the barrel, and a proximity focus RICH in the electron direction. This paper focuses on the DIRC detector, which presents complex hit patterns and is also used for PID of pions and kaons in the experiment at JLab. We present Deep(er)RICH, an extension of the seminal DeepRICH work, offering improved and faster PID compared to traditional methods and, for the first time, fast and accurate simulation. This advancement addresses a major bottleneck in Cherenkov detector simulations involving photon tracking through complex optical elements. Our results leverage advancements in Vision Transformers, specifically hierarchical Swin Transformer and normalizing flows. These methods enable direct learning from real data and the reconstruction of complex topologies. We conclude by discussing the implications and future extensions of this work, which can offer capabilities for PID for multiple cutting-edge experiments like the future EIC.},
  archive      = {J_MLST},
  author       = {C Fanelli and J Giroux and J Stevens},
  doi          = {10.1088/2632-2153/ada8f4},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015028},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Deep(er) reconstruction of imaging cherenkov detectors with swin transformers and normalizing flow models},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting nonequilibrium green’s function dynamics and photoemission spectra via nonlinear integral operator learning. <em>MLST</em>, <em>6</em>(1), 015027. (<a href='https://doi.org/10.1088/2632-2153/ada99d'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the dynamics of nonequilibrium quantum many-body systems is an important research topic in a wide range of fields across condensed matter physics, quantum optics, and high-energy physics. However, numerical studies of large-scale nonequilibrium phenomena in realistic materials face serious challenges due to intrinsic high-dimensionality of quantum many-body problems and the absence of time-invariance. The nonequilibrium properties of many-body systems can be described by the dynamics of the correlator, or the Green's function of the system, whose time evolution is given by a high-dimensional system of integro-differential equations, known as the Kadanoff–Baym equations (KBEs). The time-convolution term in KBEs, which needs to be recalculated at each time step, makes it difficult to perform long-time numerical simulation. In this paper, we develop an operator-learning framework based on recurrent neural networks (RNNs) to address this challenge. We utilize RNNs to learn the nonlinear mapping between Green's functions and convolution integrals in KBEs. By using the learned operators as a surrogate model in the KBE solver, we obtain a general machine-learning scheme for predicting the dynamics of nonequilibrium Green's functions. Besides significant savings per each time step, the new methodology reduces the temporal computational complexity from O(N_t^3) to O(N_t) where N t is the number of steps taken in a simulation, thereby making it possible to study large many-body problems which are currently infeasible with conventional KBE solvers. Through various numerical examples, we demonstrate the effectiveness of the operator-learning based approach in providing accurate predictions of physical observables such as the reduced density matrix and time-resolved photoemission spectra. Moreover, our framework exhibits clear numerical convergence and can be easily parallelized, thereby facilitating many possible further developments and applications.},
  archive      = {J_MLST},
  author       = {Yuanran Zhu and Jia Yin and Cian C Reeves and Chao Yang and Vojtěch Vlček},
  doi          = {10.1088/2632-2153/ada99d},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015027},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Predicting nonequilibrium green’s function dynamics and photoemission spectra via nonlinear integral operator learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving detection of parkinson’s disease with acoustic feature optimization using particle swarm optimization and machine learning. <em>MLST</em>, <em>6</em>(1), 015026. (<a href='https://doi.org/10.1088/2632-2153/adadc3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson's disease (PD), characterized by motor impairments and tremors, also presents early-stage vocal abnormalities that hold diagnostic potential. Leveraging voice analysis and classification techniques, numerous studies explore the feasibility of early PD detection through automated systems. While several databases offer acoustic features for this purpose, their effectiveness largely depends on the classification methodology employed. This study aims to refine PD detection systems by introducing customized weighting to acoustic features, adjusting their significance based on their correlation with the disease and the classification algorithm utilized. The particle swarm optimization algorithm is employed for this purpose, with the Oxford PD dataset serving as the source data for training and validation. Performance evaluation encompasses four classification algorithms: support vector machine, Gradient Boosting (GB), k-nearest neighbors (KNN), and Naïve Bayes. A 5-fold cross-validation technique was adopted to evaluate the effectiveness of our method for PD detection. The results show that our approach significantly improves performance regardless of the classifier used, demonstrating its generalization capability. The KNN classifier surpasses state-of-the-art results, achieving an accuracy of 97.44% and a sensitivity of 98.02%.},
  archive      = {J_MLST},
  author       = {Elmoundher Hadjaidji and Mohamed Cherif Amara Korba and Khaled Khelil},
  doi          = {10.1088/2632-2153/adadc3},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015026},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Improving detection of parkinson’s disease with acoustic feature optimization using particle swarm optimization and machine learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparing AI versus optimization workflows for simulation-based inference of spatial-stochastic systems. <em>MLST</em>, <em>6</em>(1), 010502. (<a href='https://doi.org/10.1088/2632-2153/ada0a3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model parameter inference is a universal problem across science. This challenge is particularly pronounced in developmental biology, where faithful mechanistic descriptions require spatial-stochastic models with numerous parameters, yet quantitative empirical data often lack sufficient granularity due to experimental limitations. Parameterizing such complex models therefore necessitates methods that elaborate on classical Bayesian inference by incorporating notions of optimality and goal-orientation through low-dimensional objective functions that quantitatively encapsulate target system behavior. In this study, we contrast two such inference workflows and apply them to biophysically inspired spatial-stochastic models. Technically, both workflows employ simulation-based inference (SBI) methods: the first leverages a modern deep-learning technique known as sequential neural posterior estimation, while the second relies on a classical optimization technique called simulated annealing. We evaluate these workflows by inferring the parameters of two complementary models for the inner cell mass (ICM) lineage differentiation in the blastocyst-stage mouse embryo. This developmental biology system serves as a paradigmatic example of a highly robust and reproducible cell-fate proportioning process that self-organizes under strongly stochastic conditions, such as intrinsic biochemical noise and cell–cell signaling delays. Our results reveal that while both methods provide consistent model parameter estimates, the modern SBI workflow yields significantly richer inferred distributions at an equivalent computational cost. We identify the computational scenarios that favor the modern SBI method over its classical counterpart, and propose a plausible strategy to exploit the complementary strengths of both workflows for enhanced parameter space exploration.},
  archive      = {J_MLST},
  author       = {Michael Alexander Ramirez Sierra and Thomas R Sokolowski},
  doi          = {10.1088/2632-2153/ada0a3},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {010502},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Comparing AI versus optimization workflows for simulation-based inference of spatial-stochastic systems},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing privacy-aware machine learning on sensitive data via edge-based continual µ-training for personalized large models. <em>MLST</em>, <em>6</em>(1), 015025. (<a href='https://doi.org/10.1088/2632-2153/adaca3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces an innovative method for fine-tuning a large multi-label model for abnormality detection, utilizing a smaller trainer and advanced knowledge distillation techniques. It studies the effects of fine-tuning on various abnormalities, noting different improvements based on the Original Model's performance in specific tasks. The experimental setup, optimized for on-device inference and fine-tuning with limited computational resources, demonstrates moderate yet promising enhancements in model performance post-fine-tuning. Key insights from the study include the significance of aligning the µ -Trainer's behavior with the Original Model and the influence of hyper-parameters like batch size on fine-tuning outcomes. The research acknowledges limitations such as the limited exploration of loss functions in multi-label models and constraints in architectural design, suggesting potential avenues for future investigation. While the proposed Naive Continual Fine-tuning Process is in its early stages, we highlight this paper's potential model personalization on long-term data. Moreover, weight transfer in our system is exclusively for fine-tuning; hence, it improves user privacy protection by failing data reconstruction attempts from weights, like an issue with Federated learning models. Our on-device fine-tuning prevents the transferring of data or gradients from the edge of the network to their server. Despite modest performance improvements after fine-tuning, these working layers represent a small fraction (0.7%) of the total weights in the Original Model and 1.6% in the µ -Trainer. This study establishes a foundational framework for advancing personalized model adaptation, on-device inference and fine-tuning while emphasizing the importance of safeguarding data privacy in model development.},
  archive      = {J_MLST},
  author       = {Zhaojing Huang and Leping Yu and Luis Fernando Herbozo Contreras and Kamran Eshraghian and Nhan Duy Truong and Armin Nikpour and Omid Kavehei},
  doi          = {10.1088/2632-2153/adaca3},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015025},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Advancing privacy-aware machine learning on sensitive data via edge-based continual µ-training for personalized large models},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic black-box optimization using multi-fidelity score function estimator. <em>MLST</em>, <em>6</em>(1), 015024. (<a href='https://doi.org/10.1088/2632-2153/ad8e2b'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing parameters of physics-based simulators is crucial in the design process of engineering and scientific systems. This becomes particularly challenging when the simulator is stochastic, computationally expensive, black-box and when a high-dimensional vector of parameters needs to be optimized, as e.g. is the case in complex climate models that involve numerous interdependent variables and uncertain parameters. Many traditional optimization methods rely on gradient information, which is frequently unavailable in legacy black-box codes. To address these challenges, we present SCOUT-Nd ( S tochastic C onstrained O p t imization for N dimensions), a gradient-based algorithm that can be used on non-differentiable objectives. It can be combined with natural gradients in order to further enhance convergence properties. and it also incorporates multi-fidelity schemes and an adaptive selection of samples in order to minimize computational effort. We validate our approach using standard, benchmark problems, demonstrating its superior performance in parameter optimization compared to existing methods. Additionally, we showcase the algorithm's efficacy in a complex real-world application, i.e. the optimization of a wind farm layout.},
  archive      = {J_MLST},
  author       = {Atul Agrawal and Kislaya Ravi and Phaedon-Stelios Koutsourelakis and Hans-Joachim Bungartz},
  doi          = {10.1088/2632-2153/ad8e2b},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015024},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Stochastic black-box optimization using multi-fidelity score function estimator},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Density matrix emulation of quantum recurrent neural networks for multivariate time series prediction. <em>MLST</em>, <em>6</em>(1), 015023. (<a href='https://doi.org/10.1088/2632-2153/ad9431'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum recurrent neural networks (QRNNs) are robust candidates for modelling and predicting future values in multivariate time series. However, the effective implementation of some QRNN models is limited by the need for mid-circuit measurements. Those increase the requirements for quantum hardware, which in the current noisy intermediate-scale quantum era does not allow reliable computations. Emulation arises as the main near-term alternative to explore the potential of QRNNs, but existing quantum emulators are not dedicated to circuits with multiple intermediate measurements. In this context, we design a specific emulation method that relies on density matrix formalism. Using a compact tensor notation, we provide the mathematical formulation of the operator-sum representation involved. This allows us to show how the present and past information from a time series is transmitted through the circuit, and how to reduce the computational cost in every time step of the emulated network. In addition, we derive the analytical gradient and the Hessian of the network outputs with respect to its trainable parameters, which are needed when the outputs have stochastic noise due to hardware errors and a finite number of circuit shots (sampling). We finally test the presented methods using a hardware-efficient ansatz and four diverse datasets that include univariate and multivariate time series, with and without sampling noise. In addition, we compare the model with other existing quantum and classical approaches. Our results show how QRNNs can be trained with numerical and analytical gradients to make accurate predictions of future values by capturing non-trivial patterns of input series with different complexities.},
  archive      = {J_MLST},
  author       = {J D Viqueira and D Faílde and M M Juane and A Gómez and D Mera},
  doi          = {10.1088/2632-2153/ad9431},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015023},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Density matrix emulation of quantum recurrent neural networks for multivariate time series prediction},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beware of diffusion models for synthesizing medical images—a comparison with GANs in terms of memorizing brain MRI and chest x-ray images. <em>MLST</em>, <em>6</em>(1), 015022. (<a href='https://doi.org/10.1088/2632-2153/ad9a3a'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models were initially developed for text-to-image generation and are now being utilized to generate high quality synthetic images. Preceded by generative adversarial networks (GANs), diffusion models have shown impressive results using various evaluation metrics. However, commonly used metrics such as Frechet inception distance and inception score are not suitable for determining whether diffusion models are simply reproducing the training images. Here we train StyleGAN and a diffusion model, using BRATS20, BRATS21 and a chest x-ray (CXR) pneumonia dataset, to synthesize brain MRI and CXR images, and measure the correlation between the synthetic images and all training images. Our results show that diffusion models are more likely to memorize the training images, compared to StyleGAN, especially for small datasets and when using 2D slices from 3D volumes. Researchers should be careful when using diffusion models (and to some extent GANs) for medical imaging, if the final goal is to share the synthetic images.},
  archive      = {J_MLST},
  author       = {Muhammad Usman Akbar and Wuhao Wang and Anders Eklund},
  doi          = {10.1088/2632-2153/ad9a3a},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015022},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Beware of diffusion models for synthesizing medical images—a comparison with GANs in terms of memorizing brain MRI and chest x-ray images},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SymbolNet: Neural symbolic regression with adaptive dynamic pruning for compression. <em>MLST</em>, <em>6</em>(1), 015021. (<a href='https://doi.org/10.1088/2632-2153/adaad8'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compact symbolic expressions have been shown to be more efficient than neural network (NN) models in terms of resource consumption and inference speed when implemented on custom hardware such as field-programmable gate arrays (FPGAs), while maintaining comparable accuracy (Tsoi et al 2024 EPJ Web Conf. 295 09036). These capabilities are highly valuable in environments with stringent computational resource constraints, such as high-energy physics experiments at the CERN Large Hadron Collider. However, finding compact expressions for high-dimensional datasets remains challenging due to the inherent limitations of genetic programming (GP), the search algorithm of most symbolic regression (SR) methods. Contrary to GP, the NN approach to SR offers scalability to high-dimensional inputs and leverages gradient methods for faster equation searching. Common ways of constraining expression complexity often involve multistage pruning with fine-tuning, which can result in significant performance loss. In this work, we propose \tt{SymbolNet} , a NN approach to SR specifically designed as a model compression technique, aimed at enabling low-latency inference for high-dimensional inputs on custom hardware such as FPGAs. This framework allows dynamic pruning of model weights, input features, and mathematical operators in a single training process, where both training loss and expression complexity are optimized simultaneously. We introduce a sparsity regularization term for each pruning type, which can adaptively adjust its strength, leading to convergence at a target sparsity ratio. Unlike most existing SR methods that struggle with datasets containing more than \mathcal{O}(10) inputs, we demonstrate the effectiveness of our model on the LHC jet tagging task (16 inputs), MNIST (784 inputs), and SVHN (3072 inputs).},
  archive      = {J_MLST},
  author       = {Ho Fung Tsoi and Vladimir Loncar and Sridhara Dasu and Philip Harris},
  doi          = {10.1088/2632-2153/adaad8},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015021},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {SymbolNet: Neural symbolic regression with adaptive dynamic pruning for compression},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incorporating edge convolution and correlative self-attention into graph neural network for material properties prediction. <em>MLST</em>, <em>6</em>(1), 015020. (<a href='https://doi.org/10.1088/2632-2153/ad9fcf'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of material properties is a crucial challenge in the design of new materials. Traditional methods based on either trial-and-error experiments or large-scale density functional theory calculations are known to possess various limitations. Although recent machine learning (ML) methods have shed light on resolving this problem efficiently, the majority of ML models consider only the local atomic environment while ignoring the nonlocal correlations between atoms. Indeed, even the periodic patterns of the crystal structures are not seriously considered. Consequently, these issues lead to an insufficient understanding of the feature information of atoms and bonds. In this study, we propose a crystal graph convolutional neural network based on edge convolution (EdgeConv) and correlative self-attention, namely, EdgeConv-Graph attention neural network (GANN). This network is able to efficiently extract atomic and bonding feature information, while effectively learning the importance weights of all neighbouring nodes. Numerical experiments predicting the electronic structural properties of metal–organic frameworks show that the developed model achieves state-of-the-art performance. Moreover, the proposed model was applied to predict the heat capacity and thermal decomposition temperature of material, demonstrating the ability of this method to effectively generalise multiscale prediction tasks.},
  archive      = {J_MLST},
  author       = {Zexi Yang and Qi Yu and Yapeng Zhan and Jiying Liu},
  doi          = {10.1088/2632-2153/ad9fcf},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015020},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Incorporating edge convolution and correlative self-attention into graph neural network for material properties prediction},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An autoencoder for compressing angle-resolved photoemission spectroscopy data. <em>MLST</em>, <em>6</em>(1), 015019. (<a href='https://doi.org/10.1088/2632-2153/ada8f2'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Angle-resolved photoemission spectroscopy (ARPES) is a powerful experimental technique to determine the electronic structure of solids. Advances in light sources for ARPES experiments are currently leading to a vast increase of data acquisition rates and data quantity. On the other hand, access time to the most advanced ARPES instruments remains strictly limited, calling for fast, effective, and on-the-fly data analysis tools to exploit this time. In response to this need, we introduce ARPESNet, a versatile autoencoder network that efficiently summmarises and compresses ARPES datasets. We train ARPESNet on a large and varied dataset of 2-dimensional ARPES data extracted by cutting standard 3-dimensional ARPES datasets along random directions in k . To test the data representation capacity of ARPESNet, we compare k -means clustering quality between data compressed by ARPESNet, data compressed by discrete cosine transform, and raw data, at different noise levels. ARPESNet data excels in clustering quality despite its high compression ratio.},
  archive      = {J_MLST},
  author       = {Steinn Ýmir Ágústsson and Mohammad Ahsanul Haque and Thi Tam Truong and Marco Bianchi and Nikita Klyuchnikov and Davide Mottin and Panagiotis Karras and Philip Hofmann},
  doi          = {10.1088/2632-2153/ada8f2},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015019},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {An autoencoder for compressing angle-resolved photoemission spectroscopy data},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AtOMICS: A deep learning-based automated optomechanical intelligent coupling system for testing and characterization of silicon photonics chiplets. <em>MLST</em>, <em>6</em>(1), 015018. (<a href='https://doi.org/10.1088/2632-2153/adaa4d'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in silicon photonics promise to revolutionize modern technology by improving the performance of everyday devices in multiple fields (Thomson et al 2016 J. Opt. 18 073003). However, as the industry moves into a mass fabrication phase, the problem of adequate testing of integrated silicon photonics devices remains to be solved. A cost-efficient manner that reduces schedule risk needs to involve automated testing of multiple devices that share common characteristics such as input–output coupling mechanisms, but at the same time needs to be generalizable to various types of devices and scenarios. This paper presents a neural network-based automated system designed for in-plane fiber-chip-fiber testing, characterization, and active alignment of silicon photonic devices that use process-design-kit library edge couplers. The presented approach combines state-of-the-art computer vision techniques with time-series analysis, to control a testing setup that can process multiple devices and be quickly tuned to incorporate additional hardware. The system can operate at vacuum or atmospheric pressures and maintains stability for fairly long time periods in excess of a month.},
  archive      = {J_MLST},
  author       = {Jaime Gonzalo Flor Flores and Jim Solomon and Connor Nasseraddin and Talha Yerebakan and Andrey B Matsko and Chee Wei Wong},
  doi          = {10.1088/2632-2153/adaa4d},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015018},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {AtOMICS: A deep learning-based automated optomechanical intelligent coupling system for testing and characterization of silicon photonics chiplets},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causality-driven feature selection and domain adaptation for enhancing chemical foundation models in downstream tasks. <em>MLST</em>, <em>6</em>(1), 015017. (<a href='https://doi.org/10.1088/2632-2153/adabb1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in large foundation models have revealed impressive capabilities in mastering complex chemical language representations. These models undergo a task-agnostic learning phase, characterized by pre-training on extensive unlabeled corpora followed by fine-tuning on specific downstream tasks. This methodology reduces reliance on labeled data, facilitating data acquisition and broadening the scope of chemical language representation. However, real-world scenarios often pose challenges due to domain shift, a phenomenon where the data distribution in downstream tasks differs from that of the pre-training phase, potentially degrading model performance. To address this, we present a novel causal-based framework for feature selection and domain adaptation to enhance the performance of chemical foundation models on downstream tasks. Our approach employs a multi-stage feature selection method that identifies physico-chemical features based on their direct causal-effect over specific downstream properties. By employing Mordred descriptors and Markov blanket causal graphs, our approach provides insight into the causal relationships between features and target properties for prediction tasks. We evaluate our approach on various foundation model architectures and datasets, demonstrating performance improvements, which showcases the robustness and the agnostic nature of our approach.},
  archive      = {J_MLST},
  author       = {Eduardo Soares and Victor Yukio Shirasuna and Emilio Vital Brazil and Karen Fiorella Aquino Gutierrez and Renato Cerqueira and Dmitry Zubarev and Kristin Schmidt and Daniel P Sanders},
  doi          = {10.1088/2632-2153/adabb1},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015017},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Causality-driven feature selection and domain adaptation for enhancing chemical foundation models in downstream tasks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning configuration-dependent friction tensors in langevin heatbaths. <em>MLST</em>, <em>6</em>(1), 015016. (<a href='https://doi.org/10.1088/2632-2153/ada248'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamics of coarse-grained particle systems derived via the Mori–Zwanzig projection formalism commonly take the form of a (generalized) Langevin equation with configuration-dependent friction tensor and diffusion coefficient matrix. In this article, we introduce a class of equivariant representations of tensor-valued functions based on the Atomic Cluster Expansion framework that allows for efficient learning of such configuration-dependent friction tensors from data. Besides satisfying the correct equivariance properties with respect to the Euclidean group E(3), the resulting heat bath models satisfy a fluctuation-dissipation relation. We demonstrate the capabilities of the model approach by fitting a model of configuration-dependent tensorial electronic friction calculated from first principles that arises during reactive molecular dynamics at metal surfaces.},
  archive      = {J_MLST},
  author       = {Matthias Sachs and Wojciech G Stark and Reinhard J Maurer and Christoph Ortner},
  doi          = {10.1088/2632-2153/ada248},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015016},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine learning configuration-dependent friction tensors in langevin heatbaths},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep unsupervised clustering for prostate auto-segmentation with and without hydrogel spacer. <em>MLST</em>, <em>6</em>(1), 015015. (<a href='https://doi.org/10.1088/2632-2153/ada8f3'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction. Clinical datasets for training deep learning (DL) models often exhibit high levels of heterogeneity due to differences such as patient characteristics, new medical techniques, and physician preferences. In recent years, hydrogel spacers have been used in some prostate cancer patients receiving radiotherapy to separate the prostate and the rectum to better spare the rectum while achieving adequate dose coverage on the prostate. However, this substantially affects the computed tomography image appearance, which downstream reduced the contouring accuracy of auto-segmentation algorithms. This leads to highly heterogeneous dataset. Methods. To address this issue, we propose to identify underlying clusters within the dataset and use the cluster labels for segmentation. We collected a clinical dataset of 909 patients, including those with two types of hydrogel spacers and those without. First, we trained a DL model to locate the prostate and limit our field of view to the local area surrounding the prostate and rectum. We then used Uniform Manifold Approximation and Projection (UMAP) for dimensionality reduction and employed k-means clustering to assign each patient to a cluster. To leverage this clustered data, we propose a text-guided segmentation model, contrastive language and image pre-training (CLIP)-UNet, which encodes the cluster information using a text encoder and combines the encoded text information with image features for segmentation. Results. The UMAP results indicated up to three clusters within the dataset. CLIP-UNet with cluster information achieved a Dice score of 86.2% compared to 84.4% from the baseline UNet. Additionally, CLIP-UNet outperforms other state-of-the-art models with or without cluster information. Conclusion. Automatic clustering assisted by DL can reveal hidden data clusters in clinical datasets, and CLIP-UNet effectively utilizes clustered labels and achieves higher performance.},
  archive      = {J_MLST},
  author       = {Hengrui Zhao and Biling Wang and Michael Dohopolski and Ti Bai and Steve Jiang and Dan Nguyen},
  doi          = {10.1088/2632-2153/ada8f3},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015015},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Deep unsupervised clustering for prostate auto-segmentation with and without hydrogel spacer},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterizing out-of-distribution generalization of neural networks: Application to the disordered Su–Schrieffer–Heeger model. <em>MLST</em>, <em>6</em>(1), 015014. (<a href='https://doi.org/10.1088/2632-2153/ad9079'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) is a promising tool for the detection of phases of matter. However, ML models are also known for their black-box construction, which hinders understanding of what they learn from the data and makes their application to novel data risky. Moreover, the central challenge of ML is to ensure its good generalization abilities, i.e. good performance on data outside the training set. Here, we show how the informed use of an interpretability method called class activation mapping, and the analysis of the latent representation of the data with the principal component analysis can increase trust in predictions of a neural network (NN) trained to classify quantum phases. In particular, we show that we can ensure better out-of-distribution (OOD) generalization in the complex classification problem by choosing such an NN that, in the simplified version of the problem, learns a known characteristic of the phase. We also discuss the characteristics of the data representation learned by a network that are predictors of its good OOD generalization. We show this on an example of the topological Su–Schrieffer–Heeger model with and without disorder, which turned out to be surprisingly challenging for NNs trained in a supervised way. This work is an example of how the systematic use of interpretability methods can improve the performance of NNs in scientific problems.},
  archive      = {J_MLST},
  author       = {Kacper Cybiński and Marcin Płodzień and Michał Tomza and Maciej Lewenstein and Alexandre Dauphin and Anna Dawid},
  doi          = {10.1088/2632-2153/ad9079},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015014},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Characterizing out-of-distribution generalization of neural networks: Application to the disordered Su–Schrieffer–Heeger model},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep-learning-based canopy height model generation from sub-meter resolution panchromatic satellite imagery. <em>MLST</em>, <em>6</em>(1), 015013. (<a href='https://doi.org/10.1088/2632-2153/ada47e'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Canopy height models (CHMs) with sufficient resolution to distinguish individual trees are useful for a variety of applications. However, standard techniques to acquire such data, such as airborne lidar surveying, are often prohibitively expensive. Deep learning techniques for generating CHMs from high-resolution imagery are an attractive option to reduce costs. To date, success with these methods has been demonstrated using multichannel aerial photography and specialized satellite data products derived from multiple sensors, neither of which is commonly available at temporal resolutions finer than one year. Here we demonstrate a method to generate sub-meter resolution CHMs in three forests in California using a more abundant data source: sub-meter resolution, panchromatic satellite imagery from a single sensor. We show that phenology and species composition play important roles in model transferability; when trained using imagery from a single conifer forest in autumn, the model performs well on autumn imagery from a second conifer forest several hundred kilometers distant with no re-training. With modest additions to the training dataset, the same model generates minimally biased estimates of canopy height in both conifer and deciduous forests during multiple seasons. Because the model operates on satellite data with global coverage and a relatively short return interval, we propose its suitability to extrapolate tree-level canopy height data to remote regions and conduct high-temporal resolution monitoring of forest structure. We furthermore demonstrate the workflow's applicability to fire modeling by conducting simulations in forests populated by trees measured using both this approach and airborne lidar surveying. We find minimal differences in fire behavior relative to a baseline case in which only statistical distributions of tree height and crown area are known. This result underscores the value of forest structural information derived from our workflow for improving the fidelity of wildland fire simulations, among other ecological applications.},
  archive      = {J_MLST},
  author       = {Charles J Abolt and Javier E Santos and Adam L Atchley and Lucas Wells and Daithi Martin and Russell A Parsons and Rodman R Linn},
  doi          = {10.1088/2632-2153/ada47e},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015013},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Deep-learning-based canopy height model generation from sub-meter resolution panchromatic satellite imagery},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reinforcement learning approach to the design of quantum chains for optimal energy and state transfer. <em>MLST</em>, <em>6</em>(1), 015012. (<a href='https://doi.org/10.1088/2632-2153/ada71d'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a bottom–up approach, based on reinforcement learning, to the design of a chain achieving efficient excitation-transfer performances. We assume distance-dependent interactions among particles arranged in a chain under tight-binding conditions. Starting from two particles and a localised excitation, we gradually increase the number of constitutents of the system so as to improve the transfer probability. We formulate the problem of finding the optimal locations and numbers of particles as a Markov decision process: we use proximal policy optimization to find the optimal chain-building policies and the optimal chain configurations under different scenarios. We consider both the case in which the target is a sink connected to the end of the chain and the case in which the target is the right-most particle in the chain. We address the problem of disorder in the chain induced by particle positioning errors. We apply our methodology to a simplified model of a relevant physical platform, consisting of trapped ions. We are able to achieve extremely high excitation transfer in all cases, with different chain configurations and properties depending on the specific conditions.},
  archive      = {J_MLST},
  author       = {S Sgroi and G Zicari and A Imparato and M Paternostro},
  doi          = {10.1088/2632-2153/ada71d},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015012},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A reinforcement learning approach to the design of quantum chains for optimal energy and state transfer},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Laryngeal cancer diagnosis based on improved YOLOv8 algorithm. <em>MLST</em>, <em>6</em>(1), 015011. (<a href='https://doi.org/10.1088/2632-2153/ada2d9'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laryngeal cancer is the most common malignant tumor in the head and neck region. The larynx, also known as the voice box, plays a crucial role in voice production and ventilation. Enhancing the diagnosis and treatment of laryngeal cancer can significantly improve patients' prognosis and quality of life. Artificial intelligence (AI) technology shows promise as a valuable tool for diagnosing laryngeal cancer. It not only reduces the burden on endoscopists in interpreting images but also performs screening and diagnosis efficiently and accurately. However, due to the hidden and diverse nature of laryngeal cancer lesions, achieving accuracy and efficiency in AI-based diagnosis presents poses challenges. This study introduces an improved YOLOv8 algorithm named MSEC-YOLO, specifically designed for the detection and classification tasks of laryngeal cancer in endoscopic images. A novel multiscale enhanced convolution module has been introduced to improve the model's feature extraction capabilities for small-sized targets. Additionally, a tiny fully convolutional network architecture has been employed, reducing the number of model parameters and computational costs while maintaining or enhancing performance, which is crucial for real-time medical imaging analysis. The experiments utilized a real-world endoscopic image dataset from the hospital, and the results indicated that MSEC-YOLO outperformed the original YOLOv8 model and its multi-kernel versions across multiple evaluation metrics, especially in critical categories such as malignant tumors, polyps, and papillomas, demonstrating extremely high precision and recall rates.},
  archive      = {J_MLST},
  author       = {Xin Nie and Xueyan Zhang and Di Wang and Yuankun Liu and Lumin Xing and Wenjian Liu},
  doi          = {10.1088/2632-2153/ada2d9},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015011},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Laryngeal cancer diagnosis based on improved YOLOv8 algorithm},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic selectout and voting-based federated learning for enhanced medical image analysis. <em>MLST</em>, <em>6</em>(1), 015010. (<a href='https://doi.org/10.1088/2632-2153/ada0a6'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) is a promising technique for training machine learning models on distributed, privacy-aware datasets. Nevertheless, FL faces difficulties with agent/client participation, model performance, and the heterogeneous nature of networked data sources when it comes to distributed healthcare systems. When these agents work together in the system, it is imperative to tackle the complexities of distributed deep learning. We suggest a novel approach that uses a voting mechanism and dynamic SelectOut inside the FL framework to address these problems. Local medical imaging datasets frequently show diversity in distribution and data imbalances. In certain situations, traditional FL techniques like FedProx and federated averaging, which depend on data size to weight contributions, might not be the optimal choice. In order to improve parameter aggregation and client selection unpredictability and increase the model's adaptability to imbalanced and heterogeneous datasets, our proposed FedVoteNet model introduces SelectOut techniques based on voting methodology. Based on how much their local performance has improved from the last communication cycle, we arbitrarily remove clients. Additionally eliminated are clients whose model weights when combined with the global model adversely affect its performance. Our method is further enhanced by the inclusion of a voting mechanism. At the conclusion of each communication cycle, clients that improve both their local performance and their contribution to the global model are awarded higher voting values. This encourages more significant and effective contributions from clients by providing incentives for them to actively increase the diversity of their training data. We assess our approach on a dataset of medical images, including magnetic resonance imaging scans, and find that the FL model performs noticeably better (F1 Score = 0.968, Sensitivity = 0.977, Specificity = 0.945, and AUC = 0.950). The voting system and the dynamic SelectOut algorithms improve the convergence of the FL model and successfully handle the difficulties presented by uneven and heterogeneous datasets. To sum up, our proposed approach uses voting and dynamic SelectOut techniques to improve FL performance on a variety of uneven, distributed, and varied datasets. This strategy has a lot of potential to improve FL across a range of applications, especially those that prioritize data privacy, diversity, and performance.},
  archive      = {J_MLST},
  author       = {Saeed Iqbal and Adnan N Qureshi and Musaed Alhussein and Khursheed Aurangzeb and Atif Mahmood and Saaidal Razalli Bin Azzuhri},
  doi          = {10.1088/2632-2153/ada0a6},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015010},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Dynamic selectout and voting-based federated learning for enhanced medical image analysis},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rule4ml: An open-source tool for resource utilization and latency estimation for ML models on FPGA. <em>MLST</em>, <em>6</em>(1), 015009. (<a href='https://doi.org/10.1088/2632-2153/ada71c'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implementing machine learning (ML) models on field-programmable gate arrays (FPGAs) is becoming increasingly popular across various domains as a low-latency and low-power solution that helps manage large data rates generated by continuously improving detectors. However, developing ML models for FPGAs is time-consuming, as optimization requires synthesis to evaluate FPGA area and latency, making the process slow and repetitive. This paper introduces a novel method to predict the resource utilization and inference latency of neural networks (NNs) before their synthesis and implementation on FPGA. We leverage HLS4ML, a tool-flow that helps translate NNs into high-level synthesis (HLS) code, to synthesize a diverse dataset of NN architectures and train resource utilization and inference latency predictors. While HLS4ML requires full synthesis to obtain resource and latency insights, our method uses trained regression models for immediate pre-synthesis predictions. The prediction models estimate the usage of block RAM, digital signal processors, flip-flops, and look-Up tables, as well as the inference clock cycles. The predictors were evaluated on both synthetic and existing benchmark architectures and demonstrated high accuracy with R 2 scores ranging between 0.8 and 0.98 on the validation set and sMAPE values between 10% and 30%. Overall, our approach provides valuable preliminary insights, enabling users to quickly assess the feasibility and efficiency of NNs on FPGAs, accelerating the development and deployment processes. The open-source repository can be found at https://github.com/IMPETUS-UdeS/rule4ml , while the datasets are publicly available at https://borealisdata.ca/dataverse/rule4ml .},
  archive      = {J_MLST},
  author       = {Mohammad Mehdi Rahimifar and Hamza Ezzaoui Rahali and Audrey C Therrien},
  doi          = {10.1088/2632-2153/ada71c},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015009},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Rule4ml: An open-source tool for resource utilization and latency estimation for ML models on FPGA},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parameter uncertainties for imperfect surrogate models in the low-noise regime. <em>MLST</em>, <em>6</em>(1), 015008. (<a href='https://doi.org/10.1088/2632-2153/ad9fce'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian regression determines model parameters by minimizing the expected loss, an upper bound to the true generalization error. However, this loss ignores model form error, or misspecification, meaning parameter uncertainties are significantly underestimated and vanish in the large data limit. As misspecification is the main source of uncertainty for surrogate models of low-noise calculations, such as those arising in atomistic simulation, predictive uncertainties are systematically underestimated. We analyze the true generalization error of misspecified, near-deterministic surrogate models, a regime of broad relevance in science and engineering. We show that posterior parameter distributions must cover every training point to avoid a divergence in the generalization error and design a compatible ansatz which incurs minimal overhead for linear models. The approach is demonstrated on model problems before application to thousand-dimensional datasets in atomistic machine learning. Our efficient misspecification-aware scheme gives accurate prediction and bounding of test errors in terms of parameter uncertainties, allowing this important source of uncertainty to be incorporated in multi-scale computational workflows.},
  archive      = {J_MLST},
  author       = {Thomas D Swinburne and Danny Perez},
  doi          = {10.1088/2632-2153/ad9fce},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015008},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Parameter uncertainties for imperfect surrogate models in the low-noise regime},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Refinable modeling for unbinned SMEFT analyses. <em>MLST</em>, <em>6</em>(1), 015007. (<a href='https://doi.org/10.1088/2632-2153/ad9fd1'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present methods to estimate systematic uncertainties in unbinned large hadron collider (LHC) data analyses, focusing on constraining Wilson coefficients in the standard model effective field theory (SMEFT). Our approach also applies to broader parametric models of non-resonant phenomena beyond the standard model. By using machine-learned surrogates of the likelihood ratio, we extend well-established procedures from binned Poisson counting experiments to the unbinned case. This framework handles various theoretical, modeling, and experimental uncertainties, laying the foundation for future unbinned analyses at the LHC. We also introduce a tree-boosting algorithm that learns precise parametrizations of systematic effects, providing a robust, flexible alternative to neural networks for modeling systematics. We demonstrate this approach with an SMEFT analysis of highly energetic top quark pair production in proton–proton collisions.},
  archive      = {J_MLST},
  author       = {Robert Schöfbeck},
  doi          = {10.1088/2632-2153/ad9fd1},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015007},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Refinable modeling for unbinned SMEFT analyses},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automation of quantum dot measurement analysis via explainable machine learning. <em>MLST</em>, <em>6</em>(1), 015006. (<a href='https://doi.org/10.1088/2632-2153/ada087'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of quantum dot (QD) devices for quantum computing has necessitated more efficient and automated methods for device characterization and tuning. Many of the measurements acquired during the tuning process come in the form of images that need to be properly analyzed to guide the subsequent tuning steps. By design, features present in such images capture certain behaviors or states of the measured QD devices. When considered carefully, such features can aid the control and calibration of QD devices. An important example of such images are so-called triangle plots , which visually represent current flow and reveal characteristics important for QD device calibration. While image-based classification tools, such as convolutional neural networks (CNNs), can be used to verify whether a given measurement is good and thus warrants the initiation of the next phase of tuning, they do not provide any insights into how the device should be adjusted in the case of bad images. This is because CNNs sacrifice prediction and model intelligibility for high accuracy. To ameliorate this trade-off, a recent study introduced an image vectorization approach that relies on the Gabor wavelet transform (Schug et al 2024 Proc. XAI4Sci: Explainable Machine Learning for Sciences Workshop (AAAI 2024) (Vancouver, Canada) pp 1–6). Here we propose an alternative vectorization method that involves mathematical modeling of synthetic triangles to mimic the experimental data. Using explainable boosting machines, we show that this new method offers superior explainability of model prediction without sacrificing accuracy. This work demonstrates the feasibility and advantages of applying explainable machine learning techniques to the analysis of QD measurements, paving the way for further advances in automated and transparent QD device tuning.},
  archive      = {J_MLST},
  author       = {Daniel Schug and Tyler J Kovach and M A Wolfe and Jared Benson and Sanghyeok Park and J P Dodson and J Corrigan and M A Eriksson and Justyna P Zwolak},
  doi          = {10.1088/2632-2153/ada087},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015006},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Automation of quantum dot measurement analysis via explainable machine learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel dynamic machine learning-based explainable fusion monitoring: Application to industrial and chemical processes. <em>MLST</em>, <em>6</em>(1), 015005. (<a href='https://doi.org/10.1088/2632-2153/ada088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity and fusion dynamism of the modern industrial and chemical sectors have been increasing with the rapid progress of IR 4.0–5.0. The transformative characteristics of Industry 4.0–5.0 have not been fully explored in terms of the fundamental importance of explainability. Traditional monitoring techniques for automatic anomaly detection, identifying the potential variables, and root cause analysis for fault information are not intelligent enough to tackle the intricate problems of real-time practices in the industrial and chemical sectors. This study presents a novel dynamic machine learning based explainable fusion approach to address the issues of process monitoring in industrial and chemical process systems. The methodology aims to detect faults, identify their key causes and feature variables, and analyze the root path of fault propagation with the time and magnitude of one cause variable to another impact. This study proposed using a time domain multivariate granger-entropy-aided dynamic independent component analysis (DICA)—distributed canonical correlation analysis approach, incorporating the dynamics time wrapping supported time delay-signed directed graph. The proposed methodology utilized the application to industrial and chemical processes and verified using the continuous stirred tank reactor and Tennessee Eastman process as practical application benchmarks. The framework's validations and efficiency are evaluated using established techniques such as classic computed ICA and DICA as standard model scenarios. The outcomes and results showed that the newly developed strategy is preferable to previous approaches regarding explainability and robust detection and identification of the actual root causes with high FDRs and low FARs.},
  archive      = {J_MLST},
  author       = {Husnain Ali and Rizwan Safdar and Yuanqiang Zhou and Yuan Yao and Le Yao and Zheng Zhang and Weilong Ding and Furong Gao},
  doi          = {10.1088/2632-2153/ada088},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015005},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A novel dynamic machine learning-based explainable fusion monitoring: Application to industrial and chemical processes},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New parameterized quantum gates design and efficient gradient solving based on variational quantum classification algorithm. <em>MLST</em>, <em>6</em>(1), 015004. (<a href='https://doi.org/10.1088/2632-2153/ada0a4'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, variational quantum classification algorithms (VQCAs) generally rely on traditional optimization techniques such as Powell and SLSQP in the parameter optimization session. However, the performance of these methods shows limitations in practical applications. Although the parameter-shift rule can efficiently compute the parameter gradient with quantum circuits, it needs to run the quantum circuit twice repeatedly, which significantly reduces the computation efficiency. In order to overcome this challenge, this paper innovatively integrates the principle of unitary operation in quantum mechanics with the technical characteristics of superconducting quantum chips and elaborately designs some new parameterized quantum gates (PQGs). These PQGs strictly follow the rules of unitary operation, which ensures the stability and accuracy of quantum state evolution while realizing an efficient solution to the parameter gradient. Especially for the gradient calculation of a single qubit and single-angle PQGs, the new method can be completed with only a single quantum circuit run, which greatly improves the computation efficiency. Experimental validation on benchmark datasets such as breast cancer and iris shows that the method proposed in this paper exhibits excellent performance on quantum classification tasks. Compared with the parameter-shift rule, the computation efficiency of the new method is improved by 40%. And the classification accuracy, precision, and other key performance metrics are improved by an average of 5% in comparison with traditional optimization algorithms. This work not only enriches the methodology of quantum machine learning theoretically but also demonstrates its remarkable superiority in practical applications, which indicates that the method has great potential in scientific research and industrial applications.},
  archive      = {J_MLST},
  author       = {Xiaodong Ding and FuDong Liu and Weilong Wang and Yu Zhu and Yifan Hou and Yizhen Huang and Jinchen Xu and Zheng Shan},
  doi          = {10.1088/2632-2153/ada0a4},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015004},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {New parameterized quantum gates design and efficient gradient solving based on variational quantum classification algorithm},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymptotically stable data-driven koopman operator approximation with inputs using total extended DMD. <em>MLST</em>, <em>6</em>(1), 015003. (<a href='https://doi.org/10.1088/2632-2153/ada33b'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Koopman operator framework can be used to identify a data-driven model of a nonlinear system. Unfortunately, when the data is corrupted by noise, the identified model can be biased. Additionally, depending on the choice of lifting functions, the identified model can be unstable, even when the underlying system is asymptotically stable. This paper presents an approach to reduce the bias in an approximate Koopman model, and simultaneously ensure asymptotic stability, when using noisy data. Additionally, the proposed data-driven modeling approach is applicable to systems with inputs, such as a known forcing function or a control input. Specifically, bias is reduced by using a total least-squares, modified to accommodate inputs in addition to lifted inputs. To enforce asymptotic stability of the approximate Koopman model, linear matrix inequality constraints are augmented to the identification problem. The performance of the proposed method is then compared to the well-known extended dynamic mode decomposition (DMD) method and to the newly introduced forward–backward extended DMD method using a simulated Duffing oscillator dataset and experimental soft robot arm dataset.},
  archive      = {J_MLST},
  author       = {Louis Lortie and James Richard Forbes},
  doi          = {10.1088/2632-2153/ada33b},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015003},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Asymptotically stable data-driven koopman operator approximation with inputs using total extended DMD},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-adaptive physics-informed quantum machine learning for solving differential equations. <em>MLST</em>, <em>6</em>(1), 015002. (<a href='https://doi.org/10.1088/2632-2153/ada3ab'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chebyshev polynomials have shown significant promise as an efficient tool for both classical and quantum neural networks to solve linear and nonlinear differential equations (DEs). In this work, we adapt and generalize this framework in a quantum machine learning setting for a variety of problems, including the 2D Poisson's equation, second-order linear DE, system of DEs, nonlinear Duffing and Riccati equation. In particular, we propose in the quantum setting a modified Self-Adaptive Physics-Informed Neural Network approach, where self-adaptive weights are applied to problems with multi-objective loss functions. We further explore capturing correlations in our loss function using a quantum-correlated measurement, resulting in improved accuracy for initial value problems. We analyse also the use of entangling layers and their impact on the solution accuracy for second-order DEs. The results indicate a promising approach to the near-term evaluation of DEs on quantum devices.},
  archive      = {J_MLST},
  author       = {Abhishek Setty and Rasul Abdusalamov and Felix Motzoi},
  doi          = {10.1088/2632-2153/ada3ab},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015002},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Self-adaptive physics-informed quantum machine learning for solving differential equations},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerated development of multi-component alloys in discrete design space using bayesian multi-objective optimisation. <em>MLST</em>, <em>6</em>(1), 015001. (<a href='https://doi.org/10.1088/2632-2153/ada47d'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian optimisation (BO) protocols grounded in active learning (AL) principles have gained significant recognition for their ability to efficiently optimize black-box objective functions. This capability is critical for advancing autonomous and high-throughput materials design and discovery processes. However, the application of these protocols in materials science, particularly in the design of novel alloys with multiple targeted properties, remains constrained by computational complexity and the absence of reliable and robust acquisition functions for multiobjective optimisation. Recent advancements have demonstrated that expected hypervolume-based geometrical acquisition functions outperform other multiobjective optimisation algorithms, such as Thompson Sampling Efficient Multiobjective optimisation and pareto efficient global optimisation (parEGO), in both performance and speed. This study evaluates several leading multiobjective BO acquisition functions–namely, parallel expected hypervolume improvement (qEHVI), noisy qEHVI, parallel parEGO, and parallel noisy parEGO (qNparEGO)–in optimizing the physical properties of multi-component alloys. Our findings highlight the superior performance of the qEHVI acquisition function in identifying the optimal Pareto front across 1-, 2-, and 3-objective aluminum alloy optimisation problems, all within a constrained evaluation budget and reasonable computational cost. Furthermore, we explore the impact of various surrogate model optimisation methods from both computational cost and efficiency perspectives. Finally, we demonstrate the effectiveness of a pool-based AL protocol in expediting the discovery process by executing multiple computational and experimental campaigns in each iteration. This approach is particularly advantageous for deployment in massively parallel high-throughput synthesis facilities and advanced computing architectures.},
  archive      = {J_MLST},
  author       = {Osman Mamun and Markus Bause and Bhuiyan Shameem Mahmood Ebna Hai},
  doi          = {10.1088/2632-2153/ada47d},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {015001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Accelerated development of multi-component alloys in discrete design space using bayesian multi-objective optimisation},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models for causal hypothesis generation in science. <em>MLST</em>, <em>6</em>(1), 013001. (<a href='https://doi.org/10.1088/2632-2153/ada47f'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Towards the goal of understanding the causal structure underlying complex systems—such as the Earth, the climate, or the brain—integrating Large language models (LLMs) with data-driven and domain-expertise-driven approaches has the potential to become a game-changer, especially in data and expertise-limited scenarios. Debates persist around LLMs' causal reasoning capacities. However, rather than engaging in philosophical debates, we propose integrating LLMs into a scientific framework for causal hypothesis generation alongside expert knowledge and data. Our goals include formalizing LLMs as probabilistic imperfect experts, developing adaptive methods for causal hypothesis generation, and establishing universal benchmarks for comprehensive comparisons. Specifically, we introduce a spectrum of integration methods for experts, LLMs, and data-driven approaches. We review existing approaches for causal hypothesis generation and classify them within this spectrum. As an example, our hybrid (LLM + data) causal discovery algorithm illustrates ways for deeper integration. Characterizing imperfect experts along dimensions such as (1) reliability, (2) consistency, (3) uncertainty, and (4) content vs. reasoning are emphasized for developing adaptable methods. Lastly, we stress the importance of model-agnostic benchmarks.},
  archive      = {J_MLST},
  author       = {Kai-Hendrik Cohrs and Emiliano Diaz and Vasileios Sitokonstantinou and Gherardo Varando and Gustau Camps-Valls},
  doi          = {10.1088/2632-2153/ada47f},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {013001},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Large language models for causal hypothesis generation in science},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Are queries and keys always relevant? a case study on transformer wave functions. <em>MLST</em>, <em>6</em>(1), 010501. (<a href='https://doi.org/10.1088/2632-2153/ada1a0'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dot product attention mechanism, originally designed for natural language processing tasks, is a cornerstone of modern Transformers. It adeptly captures semantic relationships between word pairs in sentences by computing a similarity overlap between queries and keys. In this work, we explore the suitability of Transformers, focusing on their attention mechanisms, in the specific domain of the parametrization of variational wave functions to approximate ground states of quantum many-body spin Hamiltonians. Specifically, we perform numerical simulations on the two-dimensional J 1 – J 2 Heisenberg model, a common benchmark in the field of quantum many-body systems on lattice. By comparing the performance of standard attention mechanisms with a simplified version that excludes queries and keys, relying solely on positions, we achieve competitive results while reducing computational cost and parameter usage. Furthermore, through the analysis of the attention maps generated by standard attention mechanisms, we show that the attention weights become effectively input-independent at the end of the optimization. We support the numerical results with analytical calculations, providing physical insights of why queries and keys should be, in principle, omitted from the attention mechanism when studying large systems.},
  archive      = {J_MLST},
  author       = {Riccardo Rende and Luciano Loris Viteritti},
  doi          = {10.1088/2632-2153/ada1a0},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {1},
  pages        = {010501},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Are queries and keys always relevant? a case study on transformer wave functions},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transfer learning for multi-material classification of transition metal dichalcogenides with atomic force microscopy. <em>MLST</em>, <em>5</em>(4), 045081. (<a href='https://doi.org/10.1088/2632-2153/ada2da'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models based on atomic force microscopy enhance efficiency in inverse design and characterization of materials. However, the limited and imbalanced data of experimental materials that are typically available is a major challenge. Also important is the need to interpret trained models, which are normally complex enough to be uninterpretable by humans. Here, we present a systemic evaluation of transfer learning strategies to accommodate low-data scenarios in materials synthesis and a model latent feature analysis to draw connections to the human-interpretable characteristics of the samples. While we imagine this framework can be used in downstream analysis tasks such as quantitative characterization, we demonstrate the strategies on a multi-material classification task for which the ground truth labels are readily available. Our models show accurate predictions in five classes of transition metal dichalcogenides (TMDs) (MoS 2 , WS 2 , WSe 2 , MoSe 2 , and Mo-WSe 2 ) with up to 89% accuracy on held-out test samples. Analysis of the latent features reveals a correlation with physical characteristics such as grain density, Difference of Gaussian blob, and local variation. The transfer learning optimization modality and the exploration of the correlation between the latent and physical features provide important frameworks that can be applied to other classes of materials beyond TMDs to enhance the models' performance and explainability which can accelerate the inverse design of materials for technological applications.},
  archive      = {J_MLST},
  author       = {Isaiah A Moses and Wesley F Reinhart},
  doi          = {10.1088/2632-2153/ada2da},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {4},
  pages        = {045081},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Transfer learning for multi-material classification of transition metal dichalcogenides with atomic force microscopy},
  volume       = {5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Many-body expansion based machine learning models for octahedral transition metal complexes. <em>MLST</em>, <em>5</em>(4), 045080. (<a href='https://doi.org/10.1088/2632-2153/ad9f22'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based machine learning (ML) models for material properties show great potential to accelerate virtual high-throughput screening of large chemical spaces. However, in their simplest forms, graph-based models do not include any 3D information and are unable to distinguish stereoisomers such as those arising from different orderings of ligands around a metal center in coordination complexes. In this work we present a modification to revised autocorrelation descriptors, a molecular graph featurization method, for predicting spin state dependent properties of octahedral transition metal complexes (TMCs). Inspired by analytical semi-empirical models for TMCs, the new modeling strategy is based on the many-body expansion (MBE) and allows one to tune the captured stereoisomer information by changing the truncation order of the MBE. We present the necessary modifications to include this approach in two commonly used ML methods, kernel ridge regression and feed-forward neural networks. On a test set composed of all possible isomers of binary TMCs, the best MBE models achieve mean absolute errors (MAEs) of 2.75 kcal mol −1 on spin-splitting energies and 0.26 eV on frontier orbital energy gaps, a 30%–40% reduction in error compared to models based on our previous approach. We also observe improved generalization to previously unseen ligands where the best-performing models exhibit MAEs of 4.00 kcal mol −1 (i.e. a 0.73 kcal mol −1 reduction) on the spin-splitting energies and 0.53 eV (i.e. a 0.10 eV reduction) on the frontier orbital energy gaps. Because the new approach incorporates insights from electronic structure theory, such as ligand additivity relationships, these models exhibit systematic generalization from homoleptic to heteroleptic complexes, allowing for efficient screening of TMC search spaces.},
  archive      = {J_MLST},
  author       = {Ralf Meyer and Daniel B K Chu and Heather J Kulik},
  doi          = {10.1088/2632-2153/ad9f22},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {4},
  pages        = {045080},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Many-body expansion based machine learning models for octahedral transition metal complexes},
  volume       = {5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neuromorphic, physics-informed spiking neural network for molecular dynamics. <em>MLST</em>, <em>5</em>(4), 045079. (<a href='https://doi.org/10.1088/2632-2153/ada220'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molecular dynamics (MD) simulations are used across many fields from chemical science to engineering. In recent years, Scientific Machine Learning (Sci-ML) in MD attracted significant attention and has become a new direction of scientific research. However, effectively integrating Sci-ML with MD simulations remains challenging. Compliance with the physical principles, comparable performance to a numerical method, and integration of start-of-the-art ML architectures are top-concerned examples of those gaps. This work addresses these challenges by introducing, for the first time, the neuromorphic physics-informed spiking neural network (NP-SNN) architecture to solve Newton's equations of motion for MD systems. Unlike conventional Sci-ML methods that heavily rely on prior training data, NP-SNN performs without needing pre-existing data by embedding MD fundamentals directly into its learning process. It also leverages the enhanced representation of real biological neural systems through spiking neural network integration with molecular dynamic physical principles, offering greater efficiency compared to conventional AI algorithms. NP-SNN integrates three core components: (1) embedding MD principles directly into the training, (2) employing best practices for training physics-informed ML systems, and (3) utilizing a highly advanced and efficient SNN architecture. By integrating these core components, this proposed architecture proves its efficacy through testing across various molecular dynamics systems. In contrast to traditional MD numerical methods, NP-SNN is trained and deployed within a continuous time framework, effectively mitigating common issues related to time step stability. The results indicate that NP-SNN provides a robust Sci-ML framework that can make accurate predictions across diverse scientific molecular applications. This architecture accelerates and enhances molecular simulations, facilitating deeper insights into interactions and system dynamics at the molecular level. The proposed NP-SNN paves the way for foundational advancements across various domains of chemical and material sciences especially in energy, environment, and sustainability fields.},
  archive      = {J_MLST},
  author       = {Vuong Van Pham and Temoor Muther and Amirmasoud Kalantari Dahaghi},
  doi          = {10.1088/2632-2153/ada220},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {4},
  pages        = {045079},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Neuromorphic, physics-informed spiking neural network for molecular dynamics},
  volume       = {5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine and deep learning performance in out-of-distribution regressions. <em>MLST</em>, <em>5</em>(4), 045078. (<a href='https://doi.org/10.1088/2632-2153/ada221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) and deep learning (DL) models are gaining popularity due to their effectiveness in many computational tasks. These models are based on an intuitive, but frequently unsatisfied, assumption that the data used to train these models is well-representing the task at hand. This gives rise to the out-of-distribution (OOD) challenge which can cause an unexpected drop in the data-driven model's performance. In this study, we evaluate the performance of various ML and DL models in in-distribution (ID) versus OOD prediction. While the degradation in OOD performance is well acknowledged, to the best of our knowledge, this is one of the first studies to quantify it for various models on a large benchmark n = 15 real-world regression datasets. We extensively ( n \gt 40\,000 runs) compare the ID versus OOD performance of XGBoost, random forest, K-nearest-neighbors, support vector machine, and linear regression models, as well as AutoML models (Tree-based Pipeline Optimization Tool and AutoKeras). In addition, to tackle this challenge, we propose to integrate a symbolic regression (SR) as a feature engineering method model with an ML or DL model to improve its performance for OOD samples. Our results show that the incorporation of SR-derived features significantly enhances the predictive capabilities of both ML and DL models with 3.70% and 10.20%, on average, of the OOD samples, respectively, without reducing ID performance and in fact improving it to a slightly lower extent. As such, this method can help produce more generalized and robust data-driven models.},
  archive      = {J_MLST},
  author       = {Assaf Shmuel and Oren Glickman and Teddy Lazebnik},
  doi          = {10.1088/2632-2153/ada221},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {4},
  pages        = {045078},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine and deep learning performance in out-of-distribution regressions},
  volume       = {5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating machine learning models for supernova gravitational wave signal classification. <em>MLST</em>, <em>5</em>(4), 045077. (<a href='https://doi.org/10.1088/2632-2153/ada33a'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the potential of using gravitational wave (GW) signals from rotating core-collapse supernovae to probe the equation of state (EOS) of nuclear matter. By generating GW signals from simulations with various EOSs, we train machine learning models to classify them and evaluate their performance. Our study builds on previous work by examining how different machine learning models, parameters, and data preprocessing techniques impact classification accuracy. We test convolutional and recurrent neural networks, as well as six classical algorithms: random forest, support vector machines, naïve Bayes(NB), logistic regression, k -nearest neighbors, and eXtreme gradient boosting. All models, except NB, achieve over 90 per cent accuracy on our dataset. Additionally, we assess the impact of approximating the GW signal using the general relativistic effective potential (GREP) on EOS classification. We find that models trained on GREP data exhibit low classification accuracy. However, normalizing time by the peak signal frequency, which partially compensates for the absence of the time dilation effect in GREP, leads to a notable improvement in accuracy. Despite this, the accuracy does not exceed 70 per cent, suggesting that GREP lacks the precision necessary for EOS classification. Finally, our study has several limitations, including the omission of detector noise and the focus on a single progenitor mass model, which will be addressed in future works.},
  archive      = {J_MLST},
  author       = {Y Sultan Abylkairov and Matthew C Edwards and Daniil Orel and Ayan Mitra and Bekdaulet Shukirgaliyev and Ernazar Abdikamalov},
  doi          = {10.1088/2632-2153/ada33a},
  journal      = {Machine Learning: Science and Technology},
  month        = {1},
  number       = {4},
  pages        = {045077},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Evaluating machine learning models for supernova gravitational wave signal classification},
  volume       = {5},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
