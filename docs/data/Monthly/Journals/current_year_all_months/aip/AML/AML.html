<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AML</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aml">AML - 70</h2>
<ul>
<li><details>
<summary>
(2025). Building an affordable self-driving lab: Practical machine learning experiments for physics education using internet-of-things. <em>AML</em>, <em>3</em>(4), 046105. (<a href='https://doi.org/10.1063/5.0283529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) is transforming modern physics research, but practical, hands-on experience with ML techniques remains limited due to cost and complexity barriers. To address this gap, we introduce an affordable, autonomous, Internet-of-Things (IoT)-enabled experimental platform designed specifically for applied physics education. Utilizing an Arduino microcontroller, a customizable multi-wavelength light emitting diode array, and photosensors, our setup generates diverse, real-time optical datasets ideal for training and evaluating foundational ML algorithms, including traversal methods, Bayesian inference, and deep learning. The platform facilitates a closed-loop, self-driving experimental workflow, encompassing automated data collection, preprocessing, model training, and validation. Through systematic performance comparisons, we demonstrate the superior ability of deep learning to capture complex nonlinear relationships compared to traversal and Bayesian methods. At ∼$60, this open-source IoT platform provides an accessible, practical pathway for students to master advanced ML concepts, promoting deeper conceptual insights and essential technical skills required for the next generation of physicists and engineers.},
  archive      = {J_AML},
  author       = {Liu, Yang and Lei, Qianjie and He, Xiaolong and Xue, Yizhe and He, Kexin and Yang, Haitao and Wang, Yong and Zhang, Xian and Yang, Li and Zhou, Yichun and Hu, Ruiqi and Xie, Yong},
  doi          = {10.1063/5.0283529},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {046105},
  shortjournal = {APL Mach. Learn.},
  title        = {Building an affordable self-driving lab: Practical machine learning experiments for physics education using internet-of-things},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning chaotic dynamics with neuromorphic network dynamics. <em>AML</em>, <em>3</em>(4), 046104. (<a href='https://doi.org/10.1063/5.0285089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates how dynamical systems may be learned and modeled with a neuromorphic network, which is itself a dynamical system. The neuromorphic network used in this study is based on a complex electrical circuit comprised of memristive elements that produce neuro-synaptic nonlinear responses to input electrical signals. To determine how computation may be performed using the physics of the underlying system, the neuromorphic network was simulated and evaluated on the autonomous prediction of a multivariate chaotic time series, implemented with a reservoir computing framework. Through manipulating only input electrodes and voltages, optimal nonlinear dynamical responses were found when input voltages maximize the number of memristive components whose internal dynamics explore the entire dynamical range of the memristor model. Increasing the network coverage with the input electrodes was found to suppress other nonlinear responses that are less conducive to learning. These results provide valuable insights into how a physical neuromorphic network device can be feasibly optimized for learning complex dynamical systems using only external control parameters.},
  archive      = {J_AML},
  author       = {Xu, Yinhao and Gottwald, Georg A. and Kuncic, Zdenka},
  doi          = {10.1063/5.0285089},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {046104},
  shortjournal = {APL Mach. Learn.},
  title        = {Learning chaotic dynamics with neuromorphic network dynamics},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active deep kernel learning of molecular properties from structural embeddings. <em>AML</em>, <em>3</em>(4), 046103. (<a href='https://doi.org/10.1063/5.0282700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As vast databases of chemical identities become increasingly available, the challenge shifts to how we effectively explore and leverage these resources to study molecular properties. This paper presents an active learning approach for molecular discovery using deep kernel learning (DKL), demonstrated on the QM9 dataset. DKL links structural embeddings directly to properties, creating organized latent spaces that prioritize relevant property information. By iteratively recalculating embedding vectors in alignment with target properties, DKL uncovers concentrated maxima representing key molecular properties and reveals unexplored regions with potential for innovation. This approach underscores DKL’s potential in advancing molecular research and discovery.},
  archive      = {J_AML},
  author       = {Ghosh, Ayana and Ziatdinov, Maxim and Kalinin, Sergei V.},
  doi          = {10.1063/5.0282700},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {046103},
  shortjournal = {APL Mach. Learn.},
  title        = {Active deep kernel learning of molecular properties from structural embeddings},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From pulses to plasticity: Analytical tools for memristive synapse design. <em>AML</em>, <em>3</em>(4), 046102. (<a href='https://doi.org/10.1063/5.0289570'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuromorphic device design demands a clear understanding of the dynamics governing conductance modulation under external stimuli. Many synaptic memristors can be described by a quasi-linear model, where a memory variable relaxes between two limiting states. Here, we derive analytical expressions for the response of such systems to trains of voltage pulses, providing closed formulations for paired-pulse facilitation (PPF), convergent potentiation, and frequency-dependent gain. This approach predicts how the memory variable evolves toward stationary values determined by device and stimulation parameters, offering a compact alternative to numerical simulations. We experimentally validate the model using a nanofluidic memristor based on a nanoporous membrane, showing that the predicted convergence closely matches measured potentiation and that the analytical PPF trends reproduce experimental data. These results establish a unified framework for describing spike-driven plasticity and enable reliable cross-comparison of synaptic behavior across memristive systems, facilitating their integration into neuromorphic circuits.},
  archive      = {J_AML},
  author       = {Rivera-Sierra, Gonzalo and Bisquert, Juan},
  doi          = {10.1063/5.0289570},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {046102},
  shortjournal = {APL Mach. Learn.},
  title        = {From pulses to plasticity: Analytical tools for memristive synapse design},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning model of myofilament cooperative activation and cross-bridge cycling in cardiac muscle. <em>AML</em>, <em>3</em>(4), 046101. (<a href='https://doi.org/10.1063/5.0286557'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiac muscle contraction is driven by the cross-bridge cycle, where myosin heads generate force by cyclically attaching to and pulling on actin filaments using energy from ATP. Modeling this process is central to understanding cardiac sarcomere mechanics. In this study, we developed supervised machine learning (ML) models using artificial neural networks (ANNs) to simulate cross-bridge cycling and muscle behavior under isosarcometric, isometric, and isotonic conditions. Trained on synthetic data, the ANN captured nonlinear dependencies among calcium concentration, stiffness, sarcomere length, temperature, and force output. Error analysis through histograms and unity-line scatterplots validated prediction accuracy and identified underfitting and overfitting patterns. Comparisons across ANN architectures showed how hidden layer complexity affects model generalization. The present deep learning models accurately reproduced key physiological behaviors, including steady-state force–Ca 2+ relations, sarcomere length changes, and force–velocity relations, and matched theoretical results. This work demonstrates the potential of ML tools to enhance cardiac muscle modeling and exploit existing experimental datasets for improved prediction of cardiac muscle diseases.},
  archive      = {J_AML},
  author       = {Aboelkassem, Yasser},
  doi          = {10.1063/5.0286557},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {046101},
  shortjournal = {APL Mach. Learn.},
  title        = {Deep learning model of myofilament cooperative activation and cross-bridge cycling in cardiac muscle},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data integration and data fusion approaches in self-driving labs: A perspective. <em>AML</em>, <em>3</em>(4), 040901. (<a href='https://doi.org/10.1063/5.0283450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-driving laboratories (SDLs) are transforming materials discovery by combining automation, machine learning, and real-time feedback. Yet, their success depends on robust data integration and fusion methods capable of handling materials data that are heterogeneous, sparse, and multi-scale. Such data span theoretical models, simulations, and experimental techniques across diverse spatial and temporal scales, creating significant challenges for interoperability and analysis. This perspective reviews the state-of-the-art techniques, including knowledge graphs, structured pipelines, multimodal machine learning, and physics-informed models, that are enabling materials science and SDLs to unify and learn from disparate data sources, identify critical challenges, and propose forward-looking directions to enhance data readiness, interoperability, and predictive power in SDLs. We also highlight emerging methods such as transformer architectures, zero-shot learning, and real-time stream processing, and discuss the critical need for more scalable, interpretable, and adaptive solutions to fully realize autonomous materials innovation. By mapping out both the current landscape and future opportunities, we argue that next-generation data integration and fusion are not just enablers but essential pillars for achieving fully autonomous, adaptive, and intelligent SDL systems capable of addressing the complexities of hierarchical and multifunctional materials.},
  archive      = {J_AML},
  author       = {Gulyuk, Alexey V. and Abu Zaid, Nahed and Chirkova, Rada and Yingling, Yaroslava G.},
  doi          = {10.1063/5.0283450},
  journal      = {APL Machine Learning},
  month        = {12},
  number       = {4},
  pages        = {040901},
  shortjournal = {APL Mach. Learn.},
  title        = {Data integration and data fusion approaches in self-driving labs: A perspective},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Publisher’s note: “High precision machine learning force field development for BaTiO3 phase transitions, amorphous, and liquid structures” [APL mach. learn. 3, 036115 (2025)]. <em>AML</em>, <em>3</em>(3), 039902. (<a href='https://doi.org/10.1063/5.0300876'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AML},
  author       = {Chen, Po-Yen and Shibata, Kiyou and Mizoguchi, Teruyasu},
  doi          = {10.1063/5.0300876},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {039902},
  shortjournal = {APL Mach. Learn.},
  title        = {Publisher’s note: “High precision machine learning force field development for BaTiO3 phase transitions, amorphous, and liquid structures” [APL mach. learn. 3, 036115 (2025)]},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Erratum: “Brain-inspired learning in artificial neural networks: A review” [APL mach. learn. 2, 021501 (2024)]. <em>AML</em>, <em>3</em>(3), 039901. (<a href='https://doi.org/10.1063/5.0284616'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AML},
  author       = {Schmidgall, Samuel and Ziaei, Rojin and Achterberg, Jascha and Kirsch, Louis and Hajiseyedrazi, S. Pardis and Eshraghian, Jason},
  doi          = {10.1063/5.0284616},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {039901},
  shortjournal = {APL Mach. Learn.},
  title        = {Erratum: “Brain-inspired learning in artificial neural networks: A review” [APL mach. learn. 2, 021501 (2024)]},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mapping causal patterns in crystalline solid. <em>AML</em>, <em>3</em>(3), 036117. (<a href='https://doi.org/10.1063/5.0284465'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution of the atomic structures of the combinatorial library of Sm-substituted thin film BiFeO 3 along the phase transition boundary from the ferroelectric rhombohedral phase to the non-ferroelectric orthorhombic phase is explored using scanning transmission electron microscopy. Localized properties, including polarization, lattice parameter, and chemical composition, are parameterized from atomic-scale imaging, and their causal relationships are reconstructed using a linear non-Gaussian acyclic model. This approach is further extended to explore the spatial variability of the causal coupling using the sliding window transform method, which revealed that new causal relationships emerged at both the expected locations, such as domain walls and interfaces, and at additional regions forming clusters in the vicinity of the walls or spatially distributed features. While the exact physical origins of these relationships are unclear, they likely represent nanophase-separated regions in the morphotropic phase boundaries. Overall, we posit that an in-depth understanding of complex disordered materials away from thermodynamic equilibrium necessitates understanding not only the generative processes that can lead to observed microscopic states but also the causal links between multiple interacting subsystems.},
  archive      = {J_AML},
  author       = {Barakati, Kamyar and Nelson, Chris and Morozovska, Anna N. and Ziatdinov, Maxim A. and Eliseev, Eugene A. and Zhang, Xiaohang and Takeuchi, Ichiro and Kalinin, Sergei V.},
  doi          = {10.1063/5.0284465},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036117},
  shortjournal = {APL Mach. Learn.},
  title        = {Mapping causal patterns in crystalline solid},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed multi-fidelity surrogate modeling of fluid flow in porous media. <em>AML</em>, <em>3</em>(3), 036116. (<a href='https://doi.org/10.1063/5.0279064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the behavior of a fluid as it flows through porous media is critical for electrochemical devices and other scientific, industrial, and environmental applications. The main challenge lies in accurately capturing the complex, multi-scale fluid flow behavior through irregular porous microstructures, all while maintaining computational efficiency. In this paper, we introduce a multi-fidelity surrogate model that predicts the high-fidelity flow field state variables in explicit porous media microstructures with minimal computational cost. Our approach begins by collecting both low-fidelity and high-fidelity simulation data to train the surrogate model. The former low-fidelity data are obtained from numerical simulations of fluid flowing through macro-scale structures having homogenized effective material properties. On the other hand, the latter high-fidelity data include geometric details of the dehomogenized explicit porous media microstructure. This technique combines the detailed accuracy of high-fidelity data with the computational efficiency of low-fidelity data, thus enhancing the model performance. In addition, we integrate physics-informed neural networks into the surrogate modeling process, embedding physical laws derived from the Navier–Stokes equations that govern fluid flow. This multi-scale, multi-fidelity approach offers a precise and cost-effective solution for predicting the fluid flow velocity and pressure fields in the porous media. For relevant porous media fluid flow applications, we show a ∼ 1 0 3 × faster solution in terms of increased computational speed for a given model with reasonable representative accuracy of the solution, within a range of ∼5%–20% for velocity and ≤10% for pressure fields.},
  archive      = {J_AML},
  author       = {Behrou, Reza and Mansourifar, Hadi and Zhou, Yuqing and Wang, Siwen and Schmalenberg, Paul D. and Ling, Chen and Dede, Ercan M.},
  doi          = {10.1063/5.0279064},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036116},
  shortjournal = {APL Mach. Learn.},
  title        = {Physics-informed multi-fidelity surrogate modeling of fluid flow in porous media},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High precision machine learning force field development for BaTiO3 phase transitions, amorphous, and liquid structures. <em>AML</em>, <em>3</em>(3), 036115. (<a href='https://doi.org/10.1063/5.0268149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The phase transition behavior of BaTiO 3 (BTO) plays a crucial role in determining its material properties. However, studying these transitions typically requires large supercells to minimize constraints on atomic movements, significantly increasing computational time and cost. In this study, we developed a machine learning potential by fine-tuning the MACE-MP-0 model with a customized BTO database. The fine-tuned MACE model demonstrated high accuracy in reproducing the structural and dynamic characteristics of BTO systems. Notably, the model effectively represented changes in lattice constants and polarization during phase transitions (rhombohedral → orthorhombic → tetragonal → cubic). Furthermore, we employed the fine-tuned MACE model to investigate the melting point of BTO and subsequently generated liquid-phase and amorphous structures via thermal annealing, providing valuable insights into the high-temperature behavior of BTO.},
  archive      = {J_AML},
  author       = {Chen, Po-Yen and Shibata, Kiyou and Mizoguchi, Teruyasu},
  doi          = {10.1063/5.0268149},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036115},
  shortjournal = {APL Mach. Learn.},
  title        = {High precision machine learning force field development for BaTiO3 phase transitions, amorphous, and liquid structures},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revealing crystallographically distinct growth sectors in na-flux GaN via machine learning-assisted nanobeam x-ray diffraction analysis. <em>AML</em>, <em>3</em>(3), 036114. (<a href='https://doi.org/10.1063/5.0284122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gallium nitride (GaN) is widely used in optoelectronic and power devices, but structural defects limit its performance. To improve crystal quality, the multi-point seed technique and the flux film coated technique have been developed, enabling the growth of low-dislocation GaN wafers via the Na-flux method. However, the coalescence boundary (CB) region, formed by the fusion of multiple growth fronts, exhibits complex structural variations that remain insufficiently understood. In this study, we investigate the CB region of FFC-GaN using synchrotron-based nanobeam x-ray diffraction (nanoXRD). To analyze the high-dimensional diffraction data without prior labeling, we introduce an unsupervised machine learning framework that combines Uniform Manifold Approximation and Projection (UMAP) with agglomerative clustering. This approach identifies six crystallographically distinct clusters that align well with growth sectors inferred from cathodoluminescence imaging. By further applying the Kolmogorov–Smirnov test, we enhance the pixel-level interpretation of structural evolution during different growth stages of CB. Our results demonstrate, for the first time, that the combination of UMAP, clustering, and statistical testing enables direct, label-free crystallographic analysis of crystal growth sectors. This framework is believed to be generalizable to other high-dimensional experimental datasets, opening new avenues for uncovering hidden structural features in complex material systems.},
  archive      = {J_AML},
  author       = {Wu, Zhendong and Tohei, Tetsuya and Imanishi, Masayuki and Mori, Yusuke and Sumitani, Kazushi and Imai, Yasuhiko and Kimura, Shigeru and Sakai, Akira},
  doi          = {10.1063/5.0284122},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036114},
  shortjournal = {APL Mach. Learn.},
  title        = {Revealing crystallographically distinct growth sectors in na-flux GaN via machine learning-assisted nanobeam x-ray diffraction analysis},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ranking over regression for bayesian optimization and molecule selection. <em>AML</em>, <em>3</em>(3), 036113. (<a href='https://doi.org/10.1063/5.0272663'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian optimization (BO) has become an indispensable tool for autonomous decision-making across diverse applications from autonomous vehicle control to accelerated drug and materials discovery. With the growing interest in self-driving laboratories, BO of chemical systems is crucial for machine learning guided experimental planning. Typically, BO employs a regression surrogate model to predict the distribution of unseen parts of the search space. However, for the selection of molecules, picking the top candidates with respect to a distribution, the relative ordering of their properties may be more important than their exact values. In this paper, we introduce rank-based Bayesian optimization (RBO), which utilizes a ranking model as the surrogate. We present a comprehensive investigation of RBO’s optimization performance compared to conventional BO on various chemical datasets. Our results demonstrate similar or improved optimization performance using ranking models, particularly for datasets with rough structure–property landscapes and activity cliffs. Furthermore, we observe a high correlation between the surrogate ranking ability and BO performance, and this ability is maintained even at early iterations of BO optimization when using ranking surrogate models. We conclude that RBO is an effective alternative to regression-based BO, especially for optimizing novel chemical compounds.},
  archive      = {J_AML},
  author       = {Tom, Gary and Lo, Stanley and Corapi, Samantha and Aspuru-Guzik, Alán and Sanchez-Lengeling, Benjamin},
  doi          = {10.1063/5.0272663},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036113},
  shortjournal = {APL Mach. Learn.},
  title        = {Ranking over regression for bayesian optimization and molecule selection},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deciphering the small-angle scattering of polydisperse hard spheres using deep learning. <em>AML</em>, <em>3</em>(3), 036112. (<a href='https://doi.org/10.1063/5.0290589'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a deep learning approach for analyzing the scattering function of the polydisperse hard sphere system. We use a variational autoencoder-based neural network to learn the bidirectional mapping between the scattering function and the system parameters, including the volume fraction and polydispersity. Such that the trained model serves both as a generator that produces a scattering function from the system parameters and an inferrer that extracts system parameters from the scattering function. We first generate a scattering dataset by carrying out molecular dynamics simulations of the polydisperse hard spheres modeled by the truncated-shifted Lennard-Jones model, then analyze the scattering function dataset using singular value decomposition to confirm the feasibility of dimensional compression. Then, we split the dataset into training and testing sets and train our neural network on the training set only. Our generator model produces a scattering function with significantly higher accuracy compared to the traditional Percus–Yevick approximation and β correction, and the inferrer model can extract the volume fraction and polydispersity with much higher accuracy than traditional model functions.},
  archive      = {J_AML},
  author       = {Ding, Lijie and Do, Changwoo},
  doi          = {10.1063/5.0290589},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036112},
  shortjournal = {APL Mach. Learn.},
  title        = {Deciphering the small-angle scattering of polydisperse hard spheres using deep learning},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AutoSAS: A new human-aside-the-loop paradigm for automated SAS fitting for high throughput and autonomous experimentation. <em>AML</em>, <em>3</em>(3), 036111. (<a href='https://doi.org/10.1063/5.0271073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of artificial-intelligence driven autonomous experiments demands physics-based modeling and decision-making processes, not only to improve the accuracy of the experimental trajectory but also to increase trust by allowing transparent human-machine collaboration. High-quality structural characterization techniques (e.g., x ray, neutron, or static light scattering) are a particularly relevant example of this need: they provide invaluable information but are challenging to analyze without expert oversight. Here, we introduce AutoSAS, a novel framework for human-aside-the-loop automated data classification. AutoSAS leverages human-defined candidate models, high-throughput combinatorial fitting, and information-theoretic model selection to generate both classification results and quantitative structural descriptors. We implement AutoSAS in an open-source package designed for use with the Autonomous Formulation Laboratory for x-ray and neutron scattering-based optimization of multi-component liquid formulations. In a first application, we leveraged a set of expert defined candidate models to classify, refine the structure, and track transformations in a model injectable drug carrier system. We evaluated four model selection methods and benchmarked them against an optimized machine learning classifier, and the best approach was one that balanced quality of the fit and complexity of the model. AutoSAS not only corroborated the critical micelle concentration boundary identified in previous experiments but also discovered a second structural transition boundary not identified by the previous methods. These results demonstrate the potential of AutoSAS to enhance autonomous experimental workflows by providing robust, interpretable model selection, paving the way for more reliable and insightful structural characterization in complex formulations.},
  archive      = {J_AML},
  author       = {Sutherland, Duncan R. and Ford, Rachel and Liu, Yun and Martin, Tyler B. and Beaucage, Peter A.},
  doi          = {10.1063/5.0271073},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036111},
  shortjournal = {APL Mach. Learn.},
  title        = {AutoSAS: A new human-aside-the-loop paradigm for automated SAS fitting for high throughput and autonomous experimentation},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bidirectional adversarial autoencoders for high precision metasurface design. <em>AML</em>, <em>3</em>(3), 036110. (<a href='https://doi.org/10.1063/5.0284338'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been a critical part of designing inverse design methods that are computationally efficient and accurate. An example of this is the design of photonic metasurfaces by using their photoluminescent spectrum as the input data to predict their topology. One fundamental challenge of these systems is their ability to represent nonlinear relationships between sets of data that have different dimensionalities. Existing design methods often implement a conditional generative adversarial network in order to solve this problem, but in many cases, the solution is unable to generate structures that provide multiple peaks when validated. It is demonstrated that in response to the target spectrum, the bidirectional adversarial autoencoder is able to generate structures that provide multiple peaks on several occasions. As a result, the proposed model represents an important advance toward the generation of nonlinear photonic metasurfaces that can be used in advanced metasurface design.},
  archive      = {J_AML},
  author       = {Liu, Yuansan and Panisilvam, Jeygopi and Dower, Peter and Kim, Sejeong and Bailey, James},
  doi          = {10.1063/5.0284338},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036110},
  shortjournal = {APL Mach. Learn.},
  title        = {Bidirectional adversarial autoencoders for high precision metasurface design},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward autonomous materials synthesis via reaction–diffusion coupling. <em>AML</em>, <em>3</em>(3), 036109. (<a href='https://doi.org/10.1063/5.0267949'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous experimentation presents enormous opportunities for materials synthesis under far-from-equilibrium conditions due to the vast parameter space that can be controlled, the complexity of the emerging products, and the potential for machine learning to drive synthesis beyond traditional methods. This work presents important steps toward such autonomous materials synthesis via reaction–diffusion coupling. As a model system, we used the periodic precipitation of copper(II) hydroxide and targeted the synthesis of “Liesegang” precipitation bands with a well-defined spacing. Our workflow involved conducting high-throughput synthesis experiments, mapping the spatial distribution of the products as a function of initial reactant concentrations, and scalarizing the emerging patterns using empirical scaling laws. Subsequently, machine learning models were deployed to process the scalarized descriptors and inform the next round of experimental conditions in order to converge toward a target precipitation pattern, without human input. We anticipate that these results open pathways for autonomous materials synthesis via reaction–diffusion coupling to create complex products with user-defined chemistry, morphology, and spatial distribution within a reaction medium.},
  archive      = {J_AML},
  author       = {Ritchhart, Andrew and Allec, Sarah I. and Job, Heather M. and Butreddy, Pravalika and Ziatdinov, Maxim and Nakouzi, Elias},
  doi          = {10.1063/5.0267949},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036109},
  shortjournal = {APL Mach. Learn.},
  title        = {Toward autonomous materials synthesis via reaction–diffusion coupling},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Electronic structures of crystalline and amorphous GeSe and GeSbTe compounds using machine learning empirical pseudopotentials. <em>AML</em>, <em>3</em>(3), 036108. (<a href='https://doi.org/10.1063/5.0270774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The newly developed machine learning (ML) empirical pseudopotential (EP) method overcomes the poor transferability of the traditional EP method with the help of ML techniques while preserving its formal simplicity and computational efficiency. We apply the new method to binary and ternary systems such as GeSe and Ge-Sb-Te (GST) compounds, well-known materials for non-volatile phase-change memory and related technologies. Using a training set of ab initio electronic energy bands and rotation-covariant descriptors for various GeSe and GST compounds, we generate transferable EPs for Ge, Se, Sb, and Te. We demonstrate that the new ML model accurately reproduces the energy bands and wavefunctions of structures outside the training set, closely matching first-principle calculations. This accuracy is achieved with significantly lower computational costs due to the elimination of self-consistency iterations and the reduced size of the plane-wave basis set. Notably, the method maintains accuracy even for diverse local atomic environments, such as amorphous phases or larger systems not explicitly included in the training set.},
  archive      = {J_AML},
  author       = {Kang, Sungmo and Kim, Rokyeon and Han, Seungwu and Son, Young-Woo},
  doi          = {10.1063/5.0270774},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036108},
  shortjournal = {APL Mach. Learn.},
  title        = {Electronic structures of crystalline and amorphous GeSe and GeSbTe compounds using machine learning empirical pseudopotentials},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Limitations of theory-informed machine learning algorithms for the prediction and exploration of molecular properties: Solvation free energy as a case study. <em>AML</em>, <em>3</em>(3), 036107. (<a href='https://doi.org/10.1063/5.0282683'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant advancements in machine learning have accelerated and improved structure–property predictions for materials discovery. However, data are often scarce due to large parameter spaces consisting of chemistry, structure, synthesis, and processing variables. At small data limits, theory can be leveraged to inform machine learning (ML) models with domain knowledge and improve generalization. Here, we determine how the accuracy of first-principles calculations affects theory-informed ML predictions of the experimental solvation free energy Δ G solv e x p in both “small” (10 1 –10 2 ) and “large” (10 3 –10 4 ) data size limits. We compare several existing theory-informed techniques to a baseline (no theory) model: feature-informed, difference, and ratio. At small data limits, all theory-informed models exhibit lower RMSE, reducing training data size by more than 65% compared to the baseline model. With larger training set sizes and as theory prediction accuracy declines, the difference and ratio models exhibit larger errors than the baseline model, indicating negative transfer occurs. No negative transfer is observed in the feature-informed model; however, the model is unable to extrapolate outside of the known Δ G solv e x p distribution, whereas the difference and ratio models exhibit lower extrapolation error. Finally, we employ each model in an active learning algorithm and compare two exploration acquisition functions: maximum difference and maximum variance. Sampling with the maximum difference policy reduces RMSE and variance of the feature-informed model faster than maximum variance early in the exploration campaign, as it identifies label bounds in fewer iterations. Our findings highlight the balance between leveraging theory and relying on data-driven models in high-throughput materials discovery.},
  archive      = {J_AML},
  author       = {Ethier, Jeffrey G. and Paluch, Andrew S. and Varshney, Vikas},
  doi          = {10.1063/5.0282683},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036107},
  shortjournal = {APL Mach. Learn.},
  title        = {Limitations of theory-informed machine learning algorithms for the prediction and exploration of molecular properties: Solvation free energy as a case study},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial attacks on hybrid classical-quantum deep learning models for histopathological cancer detection. <em>AML</em>, <em>3</em>(3), 036106. (<a href='https://doi.org/10.1063/5.0270673'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyzed the application of quantum machine learning in histopathological cancer detection under adversarial attacks, demonstrating its potential to enhance diagnostic performance in adverse circumstances. Adversarial attacks are one of the major concerns in any image classification machine learning model and are responsible for perturbing the original input images, which, therefore, results in misclassification. To encounter this problem, we first developed the hybrid quantum transfer learning model by incorporating multiple transfer learning architectures such as ResNet-18, VGG-16, Inception-v3, and AlexNet with variational quantum circuits for histopathological cancer detection. Second, we introduced white-box adversarial attacks using the Fast Gradient Sign Method (FGSM) and DeepFool and projected gradient descent (PGD) methods in this model and evaluated each model’s performance against these adversarial attacks. We analyzed that the Hybrid Classical Quantum Deep Learning model (HCQ-DL) with ResNet-18 provides 78.05% accuracy compared to the Classical ResNet-18 model with the highest accuracy of 50.84% for FGSM attacks. Similarly, for DeepFool attacks, HCQ-DL with ResNet-18 performs 52.12% accurately compared to the Classical ResNet-18 model with the highest accuracy of 37.87% and for PGD attacks, HCQ-DL with ResNet-18 has 52.94% performance accuracy compared to the Classical Inception-V3 model with the highest accuracy of 32.05%. As a result, we observed that HCQ-DL models are more resilient to these adversarial attacks compared to classical deep learning models and show potential to achieve greater robustness when combined with additional defense techniques.},
  archive      = {J_AML},
  author       = {Baral, Biswaraj and Bhalgamiya, Bhavika and Majumder, Reek and Roy, Divya Dutta and Roy, Taposh Dutta},
  doi          = {10.1063/5.0270673},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036106},
  shortjournal = {APL Mach. Learn.},
  title        = {Adversarial attacks on hybrid classical-quantum deep learning models for histopathological cancer detection},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparative analysis of YOLOv8 and U-net image segmentation approaches for transmission electron micrographs of polycrystalline thin films. <em>AML</em>, <em>3</em>(3), 036105. (<a href='https://doi.org/10.1063/5.0274266'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metallic thin films offer a platform to experimentally study the dynamics of microstructural evolution, but the required transmission electron microscopy (TEM)-based imaging generates complex images that are challenging to segment and quantify. This work provides a comparative analysis of a new YOLOv8 model and an established U-Net model for bright-field TEM images of polycrystals, employing a framework leveraging physical observables to evaluate performance against two hand-traced benchmark datasets. This methodology obviates the comparison of large, diversely structured, and manually labeled datasets that are required to assess performance on a per-image/per-pixel basis. It is found that the YOLOv8 model, adapted for real-time instance segmentation, has up to 43× faster inferencing (NVIDIA GeForce RTX 4090) compared to U-Net and reconstructs hand-traced grain size distributions (GSDs) with excellent fidelity, finding mean diameter within 3% for grains near an optimal magnification; for grains that deviate from the optimal pixel-diameter, the size of small- (large)-diameter grains is systematically over- (under)-estimated. This is partially mitigated by including scale-aware augmentations during training. Moreover, when the bias is corrected post-inference by a rigid shift in distribution, the YOLOv8 model reproduces ground truth GSDs with exceptional fidelity, with statistical tests indicating <5% probability that the distributions are distinct. Based on ground truth data, calibration curves pertaining to this shift can be constructed for a given model. This issue is not present in the U-Net model’s results, indicating that for quantitative measurements where the true size of objects is of interest, special procedures must be implemented for YOLO-based models.},
  archive      = {J_AML},
  author       = {Patrick, Matthew J. and Field, Christopher R. and Grae, Lauren H. L. and Rickman, Jeffrey M. and Field, Kevin G. and Barmak, Katayun},
  doi          = {10.1063/5.0274266},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036105},
  shortjournal = {APL Mach. Learn.},
  title        = {A comparative analysis of YOLOv8 and U-net image segmentation approaches for transmission electron micrographs of polycrystalline thin films},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A materials map integrating experimental and computational data via graph-based machine learning for enhanced materials discovery. <em>AML</em>, <em>3</em>(3), 036104. (<a href='https://doi.org/10.1063/5.0274812'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Materials informatics (MI), emerging from the fusion of materials science and data science, has the potential to greatly accelerate material development and discovery. Although MI relies on data from both computational and experimental studies, their integration remains challenging. In our previous study, we addressed this challenge by training a machine learning model on experimental data and applying it to compositional entries in a computational database, thereby creating a unified dataset. In this study, we use these integrated datasets to construct material maps that visualize the relationships between material properties and structural features. The goal is to provide experimental researchers with a practical tool for exploring structurally similar compounds and thus their associated routes. We generate the materials map using the MatDeepLearn (MDL) framework, which represents crystal structures as graphs and employs deep learning for property prediction. Statistical analyses reveal that the MDL equipped with a message passing neural network (MPNN) architecture efficiently captures features related to the structural complexity of materials. Interestingly, this representational advantage does not always lead to higher accuracy in property prediction. We attribute this finding to the strong learning capacity of MPNN, which contributes primarily to the organization of data points within the materials map rather than to incremental gains in predictive precision.},
  archive      = {J_AML},
  author       = {Hashimoto, Y. and Jia, X. and Li, H. and Tomai, T.},
  doi          = {10.1063/5.0274812},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036104},
  shortjournal = {APL Mach. Learn.},
  title        = {A materials map integrating experimental and computational data via graph-based machine learning for enhanced materials discovery},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transfer learning-driven prediction of mechanical properties in membrane resonators. <em>AML</em>, <em>3</em>(3), 036103. (<a href='https://doi.org/10.1063/5.0275614'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We demonstrate the effectiveness of transfer learning for enhancing predictions of critical mechanical properties of membrane resonators. This approach benefits from robust pretrained features, which improve convergence and generalization even with large training datasets. By fine-tuning pretrained deep learning architectures—including VisionTransformer, ResNet152, and VGG19—we accurately predict eigenfrequencies, dilution coefficients, and buckling behaviors. Using a large dataset of 170 000 samples generated with COMSOL Multiphysics, our models capture complex physical phenomena, delivering performance comparable to traditional finite element methods but at significantly reduced computational cost. Specifically, eigenfrequency predictions across 15 eigenmodes consistently achieve low relative errors (1%–3%) with minimal variance. Dilution coefficient predictions remain accurate for lower eigenmodes, maintaining relative errors below 10% for the four lowest modes using static pruning thresholds. However, for higher modes, accuracy deteriorates—potentially due to the increased complexity and localized nature of higher-order mode shapes. In addition, our models exhibit robust performance in classifying membrane buckling behaviors in a binary setting, achieving over 95% accuracy.},
  archive      = {J_AML},
  author       = {Klint, John and Klint, Niphredil and Isacsson, Andreas},
  doi          = {10.1063/5.0275614},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036103},
  shortjournal = {APL Mach. Learn.},
  title        = {Transfer learning-driven prediction of mechanical properties in membrane resonators},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Noise-robust training of artificial neural networks using chemical reaction networks. <em>AML</em>, <em>3</em>(3), 036102. (<a href='https://doi.org/10.1063/5.0271766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks (NNs) can be implemented using chemical reaction networks (CRNs), where the concentrations of species act as inputs and outputs. In such biochemical computing, noise-robust computing is crucial due to the intrinsic and extrinsic noise present in chemical reactions. Previously suggested CRNs for feed-forward networks often utilized the rectified linear unit or discrete activation functions. However, one concern in this case is the discontinuities of the derivatives of those non-smooth functions, which can cause significant noise disruption during backpropagation. In this study, we propose CRNs that perform both feed-forward and training processes using smooth activation functions to avoid discontinuities in the backpropagation. All reactions occur in a single pot, and the reactions for training are bimolecular. Our case studies on the XOR, Iris, MNIST datasets, and a non-linear regression model demonstrate that computation via the CRN (i) maintains accuracy despite noise in the reaction rates and the concentration of species and (ii) is insensitive to the choice of the running time and the magnitude of the noise in comparison to NNs with a non-smooth activation function. This work presents a noise-robust NN and backpropagation implemented by CRNs, paving the way for more stable and efficient biochemical computing systems.},
  archive      = {J_AML},
  author       = {Kang, Sunghwa and Kim, Jinsu},
  doi          = {10.1063/5.0271766},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036102},
  shortjournal = {APL Mach. Learn.},
  title        = {Noise-robust training of artificial neural networks using chemical reaction networks},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A microstructural design framework using deep convolution-generative adversarial networks for predicting the behavior of CNT-PDMS systems. <em>AML</em>, <em>3</em>(3), 036101. (<a href='https://doi.org/10.1063/5.0272071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imaging techniques, such as scanning electron microscopy (SEM), are used to understand the morphology and microstructure of material systems. However, large datasets are needed to relate the microstructure and composition of the material system to overall behavior. Depending on the complexity and cost of the material system and imaging techniques, accurate datasets are difficult to obtain. Generative adversarial networks (GANs) can provide a framework to understand the relation between the morphology and microstructural behavior of material systems. Deep convolution GANs (DC-GANs) can be trained from experimentally characterized datasets to predict the morphology of various material systems. Hence, in this investigation, a limited dataset of 48 SEM images for PDMS with various weight fractions of carbon nanotubes (CNTs) was obtained and used to train a DC-GAN. Iterative image augmentation techniques were then used to accurately extend the limited dataset. SEM micrographs of CNT-PDMS were then generated from the trained DC-GAN to predict the morphology and microstructure for different magnifications and weight fractions of CNTs. Error analysis approaches based on generator and discriminator losses were used to assess the accuracy and reliability of the trained sets. This proposed approach provides a verifiable framework for training experimentally obtained SEM microstructural datasets of any dimension that can be trained to understand the behavior of CNT-polymer systems and to augment experimental imaging predictions.},
  archive      = {J_AML},
  author       = {Phillips, Matthew and Zikry, Mohammed},
  doi          = {10.1063/5.0272071},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {036101},
  shortjournal = {APL Mach. Learn.},
  title        = {A microstructural design framework using deep convolution-generative adversarial networks for predicting the behavior of CNT-PDMS systems},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hard way or hardware? taking the heat out of AI. <em>AML</em>, <em>3</em>(3), 030901. (<a href='https://doi.org/10.1063/5.0270385'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flurry of news worldwide surrounding the launch of DeepSeek’s artificial intelligence (AI) tool, operating at ∼5% of OpenAI’s GPT models, has drawn significant attention to global competitiveness in the AI field. Greater efficiency in software design to lower costs is of clear benefit to AI customers. It is also, however, critical to acknowledge the urgent need to sustain the otherwise continuous growth of compute power needed for AI systems and to reduce the energy consumption of AI systems, both of which are generally growing exponentially. Hardware has a critical role to play here. Thus, in addition to software progress, fundamental innovations across the hardware stack—from functional materials and novel devices to efficient system architectures and new computing paradigms—are pressing needs. Considering the ongoing climate crisis, we argue for the urgent need for accelerated and connected government- and industry-funded research and development in the hardware domain. We believe that the route to sustainable energy efficiency of compute systems requires closely linked efforts between academia and industry, starting with the most fundamental level of the AI system stack.},
  archive      = {J_AML},
  author       = {Jayakrishnan, Ampattu R. and Hellenbrand, Markus and Dixon, Sebastian and Mehonic, Adnan and Silva, José P. B. and MacManus-Driscoll, Judith L.},
  doi          = {10.1063/5.0270385},
  journal      = {APL Machine Learning},
  month        = {9},
  number       = {3},
  pages        = {030901},
  shortjournal = {APL Mach. Learn.},
  title        = {Hard way or hardware? taking the heat out of AI},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling turbulent and self-gravitating fluids with fourier neural operators. <em>AML</em>, <em>3</em>(2), 026118. (<a href='https://doi.org/10.1063/5.0263607'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Operators (NOs) are a leading method for surrogate modeling of partial differential equations. Unlike traditional neural networks, which approximate individual functions, NOs learn the mappings between function spaces. While NOs have been predominantly tested on simplified 1D and 2D problems, such as those explored in prior works, these studies fail to address the complexities of more realistic, high-dimensional, and high-dynamic range systems. Moreover, many real-world applications involve incomplete or noisy data, which has not been adequately explored in current NO literature. In this work, we present a novel application of NOs to astrophysical data, which involves high-dynamic range projections into an observational space. We train Fourier NO (FNO) models to predict the evolution of incomplete observational proxies with density variations spanning four orders of magnitude. We demonstrate that FNOs can predict the effects of unobserved dynamical variables. Our work lays the groundwork for future studies that forecast direct astronomical observables.},
  archive      = {J_AML},
  author       = {Poletti, Keith and Offner, Stella S. R. and Ward, Rachel A.},
  doi          = {10.1063/5.0263607},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026118},
  shortjournal = {APL Mach. Learn.},
  title        = {Modeling turbulent and self-gravitating fluids with fourier neural operators},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid quantum and in-memory computing for accelerating solving simon’s problem. <em>AML</em>, <em>3</em>(2), 026117. (<a href='https://doi.org/10.1063/5.0268483'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing and in-memory computing (IMC) are two emerging paradigms that hold promise for achieving breakthroughs in computing performance. Their combination for efficient algorithmic acceleration has been underexplored but holds significant potential. In this work, we present a novel hybrid quantum and IMC approach for accelerating solving the well-known Simon’s problem. While quantum algorithms can exponentially reduce the complexity of Simon’s problem, the overall computational complexity remains O ( n 3 ), which is imposed by the process of solving a system of linear equations in modulo 2 arithmetic (Mod-2 LEs). We have developed a logic IMC approach for solving Mod-2 LEs, where the core lies in the two-step XOR operation by the concept of a stateful neural network and the row SWAP operation based on a COPY gate design in the same framework. Thanks to the high parallelism of logic IMC with a resistive memory array, the complexity of this approach is reduced to O ( n 2 ). This hybrid computing approach is validated by performing a co-simulation of the quantum algorithm in a quantum information science kit and IMC with a simulation program with integrated circuit emphasis using an idealized resistive random-access memory behavioral model. This work represents the first attempt at integrating various emerging computing paradigms to achieve unprecedented computing speedups.},
  archive      = {J_AML},
  author       = {Miao, Zheng and Li, Yongxiang and Wang, Shiqing and Sun, Zhong},
  doi          = {10.1063/5.0268483},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026117},
  shortjournal = {APL Mach. Learn.},
  title        = {Hybrid quantum and in-memory computing for accelerating solving simon’s problem},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simulation and benchmarking of crossbar parasitic resistance models: Accuracy and performance comparison. <em>AML</em>, <em>3</em>(2), 026116. (<a href='https://doi.org/10.1063/5.0274233'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resistive crossbar arrays have been shown to enable the implementation of energy-efficient in-memory computing accelerators suitable for the diffusion of artificial neural networks (ANNs) at the edge. However, the effect of line parasitic resistances can degrade the performance of ANNs if not appropriately considered during the design of the accelerator and each time a new task is targeted. Poised by these limitations, several crossbar line parasitic resistance models have been proposed in the literature. However, a comparative study of the performance of these models is still missing. In this work, we compare and benchmark over a broad range of operating conditions several crossbar line parasitic resistance models from the literature. The results emphasize a practical trade-off: compact analytical models are fast but provide reliable estimates only for small (i.e., 32 × 32) array sizes; conversely, iterative numerical models require more computing time but are more accurate under all conditions. Thus, iterative methods remain indispensable for larger or more complex designs. In addition, the implications of using these models in line parasitic-aware training of the ANN are analyzed on an MNIST classification task. The results further indicate that despite providing a considerable speedup of the ANN training, analytical models preserve accuracy only when small crossbar tiles are used, highlighting the need for more dependable yet fast compact models.},
  archive      = {J_AML},
  author       = {Lambertini, Alessandro and Zanotti, Tommaso and Pavan, Paolo and Padovani, Andrea and Puglisi, Francesco Maria},
  doi          = {10.1063/5.0274233},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026116},
  shortjournal = {APL Mach. Learn.},
  title        = {Simulation and benchmarking of crossbar parasitic resistance models: Accuracy and performance comparison},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward intelligent control of MeV electrons and protons from kHz repetition rate ultra-intense laser interactions. <em>AML</em>, <em>3</em>(2), 026115. (<a href='https://doi.org/10.1063/5.0253529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultra-intense laser–matter interactions are often difficult to predict from first principles because of the complexity of plasma processes and the many degrees of freedom relating to the laser and target parameters. An important approach to controlling and optimizing ultra-intense laser interactions involves gathering large datasets and using these data to train statistical and machine learning models. In this paper, we describe experimental efforts to accelerate electrons and protons to ∼MeV energies with this goal in mind. These experiments involve a 1 kHz repetition rate ultra-intense laser system with ∼10 mJ per shot, a peak intensity near 5 × 10 18 W/cm 2 , and a “liquid leaf” target. Improvements to the data acquisition capabilities of this laser system greatly aided this investigation. Generally, we find that the trained models were very effective in controlling the numbers of MeV electrons ejected. The models were less successful at shifting the energy range of ejected electrons. Simultaneous control of the numbers of ∼MeV electrons and the energy range will be the subject of future experimentation using this platform.},
  archive      = {J_AML},
  author       = {Tamminga, Nathaniel and Feister, Scott and Frische, Kyle D. and Desai, Ronak and Snyder, Joseph and Felice, John J. and Smith, Joseph R. and Orban, Chris and Chowdhury, Enam A. and Dexter, Michael L. and Patnaik, Anil K.},
  doi          = {10.1063/5.0253529},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026115},
  shortjournal = {APL Mach. Learn.},
  title        = {Toward intelligent control of MeV electrons and protons from kHz repetition rate ultra-intense laser interactions},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective bayesian optimization of carbon nanotube yield and diameter control at synthesis. <em>AML</em>, <em>3</em>(2), 026114. (<a href='https://doi.org/10.1063/5.0267704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carbon nanotube (CNT) synthesis is a ripe area for autonomous experimentation. It is a high-dimensional problem, with both a large number of experimental inputs and critically important outputs, since different single-walled CNT (SWCNT) structures exhibit vastly different properties. In particular, the electronic properties of SWCNTs can vary from metallic to semiconducting based on the diameter and helical twist angle of the structure. Diameter selection has been achieved by post-growth purification at the expense of yield. We show results where both yield and selectivity are increased. This work presents the first multi-objective autonomous experimentation campaign for CNT synthesis, maximizing both overall CNT yield and diameter control. Many attempts at SWCNT diameter control do so via intensive engineering of the catalyst particles: composition, diameter, packing density, etc. Here, we begin with a disordered film of oxidized cobalt on a defective alumina support. By varying the thermodynamic conditions of the synthesis environment, we can control the size distribution and population dynamics of the emergent nanoparticle catalyst bed and, therefore, control the diameters of the resulting CNTs. Using this thermodynamic understanding, we identify regions of experimental space conducive to yield- and diameter control-optimized growth, demonstrating that, for the conditions tested here, these objectives are nearly independent, and with some exception at the extremes, arbitrary degrees of diameter control can be realized for all experimentally achieved yields. In addition, we show that this thermodynamic understanding of CNT catalyst behavior enables effective planning in a vast, information-poor environment, enabling diameter control beyond what might be expected, given the limitations of the in situ diameter characterization methods.},
  archive      = {J_AML},
  author       = {Waelder, R. and Kim, W. and Pitt, M. A. and Myung, J. I. and Maruyama, B.},
  doi          = {10.1063/5.0267704},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026114},
  shortjournal = {APL Mach. Learn.},
  title        = {Multi-objective bayesian optimization of carbon nanotube yield and diameter control at synthesis},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep photonic reservoir computer for nonlinear equalization of 16-level quadrature amplitude modulation signals. <em>AML</em>, <em>3</em>(2), 026113. (<a href='https://doi.org/10.1063/5.0253655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photonic reservoir computer (PRC) is a kind of real-time and adaptive recurrent neural network, where only weights in the readout layer require training. PRC is a promising tool to deal with the crucial issue of nonlinear equalization in optical fiber communications. Here, we theoretically present a deep PRC for the nonlinear equalization of coherent signals with the format of 16-level quadrature amplitude modulation (16-QAM). The deep PRC consists of cascading injection-locked Fabry–Perot lasers with optical feedback. Both the in-phase component and the quadrature component of the 16-QAM signals are injected simultaneously into the deep PRC in parallel, based on the wavelength multiplexing of Fabry–Perot lasers. It is demonstrated that the deep PRC exhibits strong capabilities for the nonlinearity compensation of coherent signals. The Q factor is improved by more than 1 dB for 16-QAM signals with launch powers above 10 dBm, associated with a bit rate of 240 Gbps and a transmission distance of 50 km.},
  archive      = {J_AML},
  author       = {Li, Rui-Qian and Shen, Yi-Wei and Niu, Zekun and Xu, Guozhi and Yu, Jingyi and He, Xuming and Yi, Lilin and Wang, Cheng},
  doi          = {10.1063/5.0253655},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026113},
  shortjournal = {APL Mach. Learn.},
  title        = {Deep photonic reservoir computer for nonlinear equalization of 16-level quadrature amplitude modulation signals},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-based melting congruency prediction of binary compounds using density functional theory-calculated formation energy. <em>AML</em>, <em>3</em>(2), 026112. (<a href='https://doi.org/10.1063/5.0247514'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the development of a machine-learning (ML) model for predicting the congruency of compound melts by utilizing a combination of density functional theory-calculated formation energies and a database of experimental melting reactions. Among the various ML models tested, the XGBoost model is found to be the most suitable. Therefore, the XGBoost model is trained with a labeled compound database to determine whether a compound melted congruently. Feature importance from the trained model is extracted and compared to identify descriptors crucial for predicting melting behavior. Notably, the change in slope of the DFT convex hull at the composition of the compound (i.e., the “convex hull sharpness”) exhibited significantly higher importance than the other features. The methodology employed in this study has the potential to enhance the design of alloy processing and can be applied to more complex higher-order alloys.},
  archive      = {J_AML},
  author       = {Choi, Youngwoo and Wolverton, Chris M. and Hong, Seungbum},
  doi          = {10.1063/5.0247514},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026112},
  shortjournal = {APL Mach. Learn.},
  title        = {Machine learning-based melting congruency prediction of binary compounds using density functional theory-calculated formation energy},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The evolving role of programming and LLMs in the development of self-driving laboratories. <em>AML</em>, <em>3</em>(2), 026111. (<a href='https://doi.org/10.1063/5.0266757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning and automation are transforming scientific research, yet the implementation of self-driving laboratories (SDLs) remains costly and complex, and it remains difficult to learn how to use these facilities. To address this, we introduce Claude-Light, a lightweight, remotely accessible instrument designed for prototyping automation algorithms and machine learning workflows. Claude-Light integrates a REST API, a Raspberry Pi-based control system, and an RGB LED with a photometer that measures ten spectral outputs, providing a controlled but realistic experimental environment. This device enables users to explore automation at multiple levels, from basic programming and experimental design to machine learning-driven optimization. We demonstrate the application of Claude-Light in structured automation approaches, including traditional scripting, statistical design of experiments, and active learning methods. In addition, we explore the role of large language models (LLMs) in laboratory automation, highlighting their use in instrument selection, structured data extraction, function calling, and code generation. While LLMs present new opportunities for streamlining automation, they also introduce challenges related to reproducibility, security, and reliability. We discuss strategies to mitigate these risks while leveraging LLMs for enhanced efficiency in self-driving laboratories. Claude-Light provides a practical and accessible platform for students and researchers to develop automation skills and test algorithms before deploying them in larger-scale SDLs. By lowering the barrier to entry for automation in scientific research, this tool facilitates broader adoption of AI-driven experimentation and fosters innovation in autonomous laboratories.},
  archive      = {J_AML},
  author       = {Kitchin, John R.},
  doi          = {10.1063/5.0266757},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026111},
  shortjournal = {APL Mach. Learn.},
  title        = {The evolving role of programming and LLMs in the development of self-driving laboratories},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A permutation-equivariant deep learning model for quantum state characterization. <em>AML</em>, <em>3</em>(2), 026110. (<a href='https://doi.org/10.1063/5.0258853'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The characterization of quantum states is a fundamental step of any application of quantum technologies. Nowadays, there exist several approaches addressing this problem, also based on machine and deep learning techniques. However, all these approaches usually require a number of measurements that scale exponentially with the number of parties composing the system. Threshold quantum state tomography (tQST) addresses this problem and, in some cases of interest, can significantly reduce the number of measurements. In this paper, we study how to combine a permutation-equivariant deep learning model with the tQST protocol. We test the model on quantum state tomography and purity estimation. Finally, we validate the robustness of the model to noise. We show results up to 4 qubits.},
  archive      = {J_AML},
  author       = {Maragnano, D. and Cusano, C. and Liscidini, M.},
  doi          = {10.1063/5.0258853},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026110},
  shortjournal = {APL Mach. Learn.},
  title        = {A permutation-equivariant deep learning model for quantum state characterization},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous energetic material damage simulator (HEDS): A deep learning approach to simulate damage–sensitivity linkages. <em>AML</em>, <em>3</em>(2), 026109. (<a href='https://doi.org/10.1063/5.0257683'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Damage in the microstructures of energetic materials (EMs), such as propellants and plastic bonded explosives (PBXs), can significantly alter their response to external loads. Both sensitization and desensitization can occur, causing concerns with safety and performance in the field; predictive models that connect damage and the sensitivity of EMs can enable design and provide confidence in their robustness and reliability. However, modeling of damage evolution is challenging for real microstructures of EMs; samples of damaged EMs are difficult to obtain, thereby hindering experiments and direct numerical simulations to determine the sensitivity of EMs at various stages of damage. Here, we develop an approach to generate synthetic, i.e., in silico produced, damaged microstructures for use in simulations to connect damage levels to sensitivity. The development of the present workflow to generate and impose varying levels of damage in microstructures, known as HEDS (Heterogeneous Energetic Material Damage Simulator), begins with a small set of images of damaged PBXs and combines a collection of deep neural network techniques to generate microstructures with varying levels of damage. By making the synthetic microstructures conform closely to those observed in available real, imaged microstructures, we develop an ensemble of damaged microstructures that can be used for in silico shock experiments. HEDS develops these microstructure ensembles as level set fields, which are directly employed in a sharp interface Eulerian hydrocode where shock simulations are performed to quantify the energy release rate from hotspot fields generated in the microstructure. These capabilities can be useful for the analysis and assessment of changes in the sensitivity of EMs and to design formulations that are less susceptible to damage-induced changes in sensitivity and performance.},
  archive      = {J_AML},
  author       = {Fang, Irene and Roy, Shobhan and Nguyen, Phong and Baek, Stephen and Udaykumar, H. S.},
  doi          = {10.1063/5.0257683},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026109},
  shortjournal = {APL Mach. Learn.},
  title        = {Heterogeneous energetic material damage simulator (HEDS): A deep learning approach to simulate damage–sensitivity linkages},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-aware isomorphic attention for adaptive dynamics in transformers. <em>AML</em>, <em>3</em>(2), 026108. (<a href='https://doi.org/10.1063/5.0256873'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an approach for modifying transformer architectures by integrating graph-aware relational reasoning into the attention mechanism, merging concepts from graph neural networks and language modeling. Building on the inherent connection between attention and graph theory, we reformulate the transformer’s attention mechanism as a graph operation and propose graph-aware isomorphic attention. This method leverages advanced graph modeling strategies, including Graph Isomorphism Networks (GINs), to enrich the representation of relational structures. Our approach improves the model’s ability to capture complex dependencies and generalize across tasks, as evidenced by a reduced generalization gap and improved learning performance. We expand the concept of graph-aware attention to introduce sparse-GIN-attention, a fine-tuning approach that enhances the adaptability of pre-trained foundational models with minimal computational overhead, endowing them with graph-aware capabilities. We show that the sparse-GIN-attention framework leverages compositional principles from category theory to align relational reasoning with sparsified graph structures while modeling hierarchical representation learning that bridges local interactions and global task objectives across diverse domains. Our results demonstrate that graph-aware attention mechanisms outperform traditional attention in both training efficiency and validation performance. These insights bridge graph theory and transformer architectures and uncover latent graph-like structures within traditional attention mechanisms, offering a new lens through which transformers can be optimized. By evolving transformers as hierarchical GIN models, we reveal their implicit capacity for graph-level relational reasoning with profound implications for foundational model development and applications in bioinformatics, materials science, language modeling, and beyond, setting the stage for interpretable and generalizable modeling strategies.},
  archive      = {J_AML},
  author       = {Buehler, Markus J.},
  doi          = {10.1063/5.0256873},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026108},
  shortjournal = {APL Mach. Learn.},
  title        = {Graph-aware isomorphic attention for adaptive dynamics in transformers},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scaling of hardware-compatible perturbative training algorithms. <em>AML</em>, <em>3</em>(2), 026107. (<a href='https://doi.org/10.1063/5.0258271'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we explore the capabilities of multiplexed gradient descent (MGD), a scalable and efficient perturbative zeroth-order training method for estimating the gradient of a loss function in hardware and training it via stochastic gradient descent. We extend the framework to include both weight and node perturbation and discuss the advantages and disadvantages of each approach. We investigate the time to train networks using MGD as a function of network size and task complexity. Previous research has suggested that perturbative training methods do not scale well to large problems since in these methods, the time to estimate the gradient scales linearly with the number of network parameters. However, in this work, we show that the time to reach a target accuracy—that is, actually solve the problem of interest—does not follow this undesirable linear scaling and in fact often decreases with network size. Furthermore, we demonstrate that MGD can be used to calculate a drop-in replacement for the gradient in stochastic gradient descent, and therefore, optimization accelerators such as momentum can be used alongside MGD, ensuring compatibility with existing machine learning practices. Our results indicate that MGD can efficiently train large networks on hardware, achieving accuracy comparable with backpropagation, thus presenting a practical solution for future neuromorphic computing systems.},
  archive      = {J_AML},
  author       = {Oripov, B. G. and Dienstfrey, A. and McCaughan, A. N. and Buckley, S. M.},
  doi          = {10.1063/5.0258271},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026107},
  shortjournal = {APL Mach. Learn.},
  title        = {Scaling of hardware-compatible perturbative training algorithms},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Symmetry constrained neural networks for detection and localization of damage in metal plates. <em>AML</em>, <em>3</em>(2), 026106. (<a href='https://doi.org/10.1063/5.0242345'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present paper is concerned with deep learning techniques applied to detection and localization of damage in a thin aluminum plate. We used data collected on a tabletop apparatus by mounting to the plate four piezoelectric transducers, each of which took turns to generate a Lamb wave that then traversed the region of interest before being received by the remaining three sensors. Upon training a neural network to analyze time-series data of the material response, which displayed damage-reflective features whenever the plate-guided waves interacted with a contact load, we achieved a model that detected with >99% accuracy in addition to a model that localized with 2.58 ± 0.12 mm mean distance error. For each task, the best-performing model was designed according to the inductive bias that our transducers were both similar and arranged in a square pattern on a nearly uniform plate.},
  archive      = {J_AML},
  author       = {Amarel, James and Rudolf, Christopher and Iliopoulos, Athanasios and Michopoulos, John G. and Smith, Leslie N.},
  doi          = {10.1063/5.0242345},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026106},
  shortjournal = {APL Mach. Learn.},
  title        = {Symmetry constrained neural networks for detection and localization of damage in metal plates},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time to failure prediction for MLCCs: A machine learning approach based on leakage current data. <em>AML</em>, <em>3</em>(2), 026105. (<a href='https://doi.org/10.1063/5.0262717'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of modern electronics poses challenges to the long-term reliability of multi-layer ceramic capacitors (MLCCs), especially under extreme conditions. While existing research mainly focuses on predicting the mean time to failure for MLCC populations, studies on predicting the time to failure (TTF) for individual capacitors are scarce. This study addresses this gap by developing a machine learning model to predict the TTF of individual MLCCs. Based on features extracted from leakage current curves and failure data generated via highly accelerated life testing, feature engineering and model optimization were applied to select a random forest model, achieving an R 2 of 0.8971. This approach enables real-time monitoring and prediction of individual capacitor failures, offering valuable insights for improving reliability, particularly in the predictive maintenance of critical systems.},
  archive      = {J_AML},
  author       = {Jiang, Tianyu and Qin, Jincheng and Zhang, Faqiang and Li, Mingcao and Yan, Xiaolian and Ma, Mingsheng and Li, Yongxiang and Liu, Zhifu},
  doi          = {10.1063/5.0262717},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026105},
  shortjournal = {APL Mach. Learn.},
  title        = {Time to failure prediction for MLCCs: A machine learning approach based on leakage current data},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accurate classification of materials with elEmBERT: Element embeddings for chemical benchmarks. <em>AML</em>, <em>3</em>(2), 026104. (<a href='https://doi.org/10.1063/5.0232529'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the elEmBERT model for chemical classification tasks. It is based on deep learning techniques, such as a multilayer encoder architecture. We demonstrate the opportunities offered by our approach on sets of organic, inorganic, and crystalline compounds. In particular, we developed and tested the model using the Materials Project and MoleculeNet benchmarks, which include crystal properties and drug design-related benchmarks. We also conduct an analysis of vector representations of chemical compounds, shedding light on the underlying patterns in structural data. Our model exhibits exceptional predictive capabilities and proves universally applicable to molecular and material datasets. For instance, on the Tox21 dataset, we achieved an average precision of 96%, surpassing the previously best result by 10%.},
  archive      = {J_AML},
  author       = {Shermukhamedov, Shokirbek and Mamurjonova, Dilorom and Probst, Michael},
  doi          = {10.1063/5.0232529},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026104},
  shortjournal = {APL Mach. Learn.},
  title        = {Accurate classification of materials with elEmBERT: Element embeddings for chemical benchmarks},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-driven model for optimized pulse programming of memristive devices. <em>AML</em>, <em>3</em>(2), 026103. (<a href='https://doi.org/10.1063/5.0251113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next-generation artificial intelligence (AI) hardware based on memristive devices offers a promising approach to reducing the increasingly large energy consumption of AI applications. However, programming memristive AI hardware to achieve a desired synaptic weight configuration remains challenging because it requires accurate and energy-efficient algorithms for selecting the optimal weight-update pulses. Here, we present a computationally efficient AI model for predicting the weight update of memristive devices and guiding device programming. The synaptic weight-update behavior of bilayer HfO 2 /TiO 2 memristive devices is characterized over a range of pulse parameters to provide experimental data for the AI model. Three different artificial neural network (ANN) configurations are trained and evaluated regarding the amount of training data required for accurate predictions and the computational costs. Finally, we apply the model to an antipulse weight-update process to demonstrate its performance. The results show that accurate and computationally inexpensive predictions are possible with comparatively few datasets and small ANNs. The normalized weight-update processes are predicted with accuracies comparable with larger model architectures but require only 896 floating point operations and 8.33 nJ per inference. This makes the model a promising candidate for integration into AI-driven device controllers as a precise and energy-efficient solution for memristive device programming.},
  archive      = {J_AML},
  author       = {Spetzler, Benjamin and Fritscher, Markus and Park, Seongae and Kim, Nayoun and Wenger, Christian and Ziegler, Martin},
  doi          = {10.1063/5.0251113},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026103},
  shortjournal = {APL Mach. Learn.},
  title        = {AI-driven model for optimized pulse programming of memristive devices},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting mechanical properties of polycrystalline nanopillars by interpretable machine learning. <em>AML</em>, <em>3</em>(2), 026102. (<a href='https://doi.org/10.1063/5.0242318'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models have proven to be powerful tools to discover links between microstructure and properties of materials, but the black box nature of the models limits the physical insights one might gain from them. Here, we study the relationship between the atomic structure and the elastic and plastic properties of polycrystalline tantalum nanopillars under uniaxial compression by means of interpretable machine learning. We first train a convolutional neural network using data from molecular dynamics simulations to learn the mapping from the sample-specific initial atomic structure to features of the stress–strain curve. The model is able to predict the values of the Young’s moduli of the pillars very well, resulting in slightly better predictions than those obtained from classical models (Voigt, Reuss, and Hill), as well as from a newly developed volume integral method. It also has some success in learning the yield stress values. Interpreting the network by employing the gradient-weighted class activation mapping method reveals a correlation between the resulting attention map and the local, grain orientation dependent Young’s moduli, showing that the predicted value of the global Young’s modulus is mainly determined by grains whose local Young’s moduli deviate significantly from the average. We also analyze the attention maps for the yield stress prediction and conclude that for the nanocrystalline samples at hand without pre-existing dislocations, grain boundaries tend to be responsible for reducing the yield stress.},
  archive      = {J_AML},
  author       = {Koivisto, Teemu and Mińkowski, Marcin and Laurson, Lasse},
  doi          = {10.1063/5.0242318},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026102},
  shortjournal = {APL Mach. Learn.},
  title        = {Predicting mechanical properties of polycrystalline nanopillars by interpretable machine learning},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CoNO: Complex neural operator for continous dynamical physical systems. <em>AML</em>, <em>3</em>(2), 026101. (<a href='https://doi.org/10.1063/5.0254013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural operators extend data-driven models to map between infinite-dimensional functional spaces. While these operators perform effectively in either the time or frequency domain, their performance may be limited when applied to non-stationary spatial or temporal signals whose frequency characteristics change with time. Here, we introduce a Complex Neural Operator (CoNO) that parameterizes the integral kernel using fractional Fourier transform, better representing non-stationary signals in a complex-valued domain. Theoretically, we prove the universal approximation capability of CoNO. We perform an extensive empirical evaluation of CoNO on seven challenging partial differential equations, including regular grids, structured meshes, and point clouds. Empirically, CoNO consistently attains a state-of-the-art performance, showcasing an average relative gain of 10.9%. Furthermore, CoNO exhibits superior performance, outperforming all other models in additional tasks, such as zero-shot super-resolution and robustness to noise. CoNO also exhibits the ability to learn from small amounts of data—giving the same performance as the next best model with just 60% of the training data. Altogether, CoNO presents a robust and superior model for modeling continuous dynamical systems, providing a fillip to scientific machine learning.},
  archive      = {J_AML},
  author       = {Tiwari, Karn and Krishnan, N. M. Anoop and P., Prathosh A.},
  doi          = {10.1063/5.0254013},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {026101},
  shortjournal = {APL Mach. Learn.},
  title        = {CoNO: Complex neural operator for continous dynamical physical systems},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mind the gap: Bridging the divide between AI aspirations and the reality of autonomous microscopy. <em>AML</em>, <em>3</em>(2), 020903. (<a href='https://doi.org/10.1063/5.0267699'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {What does materials science look like in the “Age of Artificial Intelligence?” Each material’s domain—synthesis, characterization, and modeling—has a different answer to this question, motivated by unique challenges and constraints. This work focuses on the tremendous potential of autonomous characterization within electron microscopy. We present our recent advancements in developing domain-aware, multimodal models for microscopy analysis capable of describing complex atomic systems. We then address the critical gap between the theoretical promise of autonomous microscopy and its current practical limitations, showcasing recent successes while highlighting the necessary developments to achieve robust, real-world autonomy.},
  archive      = {J_AML},
  author       = {Guinan, Grace and Salvador, Addison and Smeaton, Michelle A. and Glaws, Andrew and Egan, Hilary and Wyatt, Brian C. and Anasori, Babak and Fiedler, Kevin R. and Olszta, Matthew J. and Spurgeon, Steven R.},
  doi          = {10.1063/5.0267699},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {020903},
  shortjournal = {APL Mach. Learn.},
  title        = {Mind the gap: Bridging the divide between AI aspirations and the reality of autonomous microscopy},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can ferroelectric tunnel junction be a game changer as eNVM and in neuromorphic hardware?. <em>AML</em>, <em>3</em>(2), 020902. (<a href='https://doi.org/10.1063/5.0252822'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work highlights the advantages that ferroelectric tunnel junction (FTJ) memristors can bring to the non-volatile memory technology and in custom designed neuromorphic hardware. Advantages of FTJs not only come from the area-scalability, large on/off switching ratio, fast read and write operations, low-leakage, and high endurance but also from the reduced fabrication complexity and cost perspective. For neuromorphic hardware, depending on specific applications, such as non-volatile or volatile memory operations or programmable synaptic plasticity, specific stack structures can be designed with engineered depolarizing field that can provide flexibility of different time constants of programmed states. Integration of leaky-integrate-and-fire functionality in single-cell FTJs, utilizing accumulative switching and quick depolarizing properties of ferroelectric materials under certain conditions, can lead to an unprecedented reduction in electronic neuron circuit fabrication complexity, making dense integration of neurons and synapses possible on a single chip. The relatively low on current reported in complementary metal–oxide–semiconductor back-end compatible FTJs is a challenge for their fast readout, where innovations on stack and design architectures have shown promising solutions. Large-scale integration of FTJs in memory arrays is required to fully understand the game-changing potential of this technology.},
  archive      = {J_AML},
  author       = {Majumdar, Sayani},
  doi          = {10.1063/5.0252822},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {020902},
  shortjournal = {APL Mach. Learn.},
  title        = {Can ferroelectric tunnel junction be a game changer as eNVM and in neuromorphic hardware?},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memory technology enabling future computing systems. <em>AML</em>, <em>3</em>(2), 020901. (<a href='https://doi.org/10.1063/5.0253063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the astounding progress through Moore’s law has made possible the demonstrations of truly remarkable tasks of artificial intelligence (AI), the AI revolution is challenging the semiconductor technology itself. In fact, the achieved results are at the expense of an energy consumption orders of magnitude higher than the one of the human brain. Definitively, biology figures out a better way to process data. So, radically new approaches, in some way emulating the human mind, are essential for creating a more efficient next generation information technology. This work draws the directions that address the building of more efficient future computing systems, namely, (a) the memory and storage technology roadmap; (b) innovative interconnect systems between memory and logic devices; and (c) overcoming of the von Neumann computing paradigm.},
  archive      = {J_AML},
  author       = {Fantini, Paolo},
  doi          = {10.1063/5.0253063},
  journal      = {APL Machine Learning},
  month        = {6},
  number       = {2},
  pages        = {020901},
  shortjournal = {APL Mach. Learn.},
  title        = {Memory technology enabling future computing systems},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TOMFuN: A tensorized optical multimodal fusion network. <em>AML</em>, <em>3</em>(1), 016121. (<a href='https://doi.org/10.1063/5.0255883'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a real-size, single-shot, high-speed, and energy-efficient tensorized optical multimodal fusion network (TOMFuN) on an electro-photonic large-scale III–V-on-Si in-memory compute engine. The TOMFuN architecture leverages a memory-efficient and low-complexity self-attention for the embedding network for the text information and tensor-train and CANDECOMP/PARAFAC decompositions for compressing the model parameters in the large-scale fully connected layers. Compared to full-size counterparts, our proposed network maintains a compatible inference accuracy in multimodal sentiment analysis tasks while requiring 92.8× fewer model parameters and 51.3× fewer hardware resources. Furthermore, the impact of photonic device imperfections on the TOMFuN architecture is investigated. The simulation results show that noise-aware on-chip training exhibits superior robustness. Finally, chip performance analysis shows that our TOMFuN inference accelerator has 230.73 PetaOps computational speed, 6.51 TOPS/W power efficiency, and 2.7 µ s latency with the input dimensions of 1024.},
  archive      = {J_AML},
  author       = {Xiao, Xian and Zhao, Yequan and Yuan, Yuan and Kurczveil, Geza and Fiorentino, Marco and Beausoleil, Ray and Zhang, Zheng},
  doi          = {10.1063/5.0255883},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016121},
  shortjournal = {APL Mach. Learn.},
  title        = {TOMFuN: A tensorized optical multimodal fusion network},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polarization current-based reservoir computing utilizing an anti-ferroelectric-like HfZrO2 capacitor. <em>AML</em>, <em>3</em>(1), 016120. (<a href='https://doi.org/10.1063/5.0255149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have experimentally demonstrated the physical reservoir computing by employing the polarization switching current dynamics of an Hf 1−x Zr x O 2 (HZO)-based metal/ferroelectric/metal capacitor with Zr content x = 0, 0.5, and 0.75. The spatial distribution of the crystalline phase of an HZO film reveals that the tetragonal phase is a dominant crystal structure in the HZO film with [Zr] = 75%, resulting in anti-ferroelectric (AFE)-like double polarization switching. Analyses using t-distributed stochastic neighbor embedding (t-SNE) find that the AFE-HZO capacitor effectively transforms the 3-bit time-series input into eight different reservoir output states. In reservoir computing tasks, the AFE-HZO capacitor with [Zr] = 75% achieves improved computational capacities compared with the other MFM capacitors with [Zr] = 0% and 50%. The AFE-HZO capacitor can effectively diversify time-series input signals through dynamic double polarization switching, leading to a more sub-divided and dispersive weight distribution across the adjustable weights in the readout part of our RC system.},
  archive      = {J_AML},
  author       = {Min, Shin-Yi and Nako, Eishin and Nakane, Ryosho and Takenaka, Mitsuru and Toprasertpong, Kasidit and Takagi, Shinichi},
  doi          = {10.1063/5.0255149},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016120},
  shortjournal = {APL Mach. Learn.},
  title        = {Polarization current-based reservoir computing utilizing an anti-ferroelectric-like HfZrO2 capacitor},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic in-context learning with conversational models for data extraction and materials property prediction. <em>AML</em>, <em>3</em>(1), 016119. (<a href='https://doi.org/10.1063/5.0254406'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of natural language processing and large language models (LLMs) has revolutionized the extraction of data from unstructured scholarly papers. However, ensuring data trustworthiness remains a significant challenge. In this paper, we introduce PropertyExtractor , an open-source tool that leverages advanced conversational LLMs such as Google gemini-pro and OpenAI gpt-4 , blends zero-shot with few-shot in-context learning, and employs engineered prompts for the dynamic refinement of structured information hierarchies—enabling autonomous, efficient, scalable, and accurate identification, extraction, and verification of material property data. Our tests on material data demonstrate precision and recall that exceed 95% with an error rate of ∼9%, highlighting the effectiveness and versatility of the toolkit. Finally, databases for 2D material thicknesses, a critical parameter for device integration, and energy bandgap values are developed using PropertyExtractor . In particular, for the thickness database, the rapid evolution of the field has outpaced both experimental measurements and computational methods, creating a significant data gap. Our work addresses this gap and showcases the potential of PropertyExtractor as a reliable and efficient tool for the autonomous generation of various material property databases, advancing the field.},
  archive      = {J_AML},
  author       = {Ekuma, Chinedu E.},
  doi          = {10.1063/5.0254406},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016119},
  shortjournal = {APL Mach. Learn.},
  title        = {Dynamic in-context learning with conversational models for data extraction and materials property prediction},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic compact model for memory and threshold switching memristors. <em>AML</em>, <em>3</em>(1), 016118. (<a href='https://doi.org/10.1063/5.0255043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memristors are electron devices whose resistance changes according to the history of electrical signals applied to their two terminals. These resistance changes can remain for very long times or relax after a short time. Thus, memristors can be used as electronic synapses and neurons in artificial neural networks implemented in hardware. These fully memristive neuromorphic circuits are mainly intended for artificial intelligence applications. In this work, we explore the properties of a stochastic compact model for the electrical behavior of memristors in the two regimes of long-time (non-volatile) and short-time (volatile) memory for synapse and neuron functions, respectively. In the case of non-volatile memristors, we focus on potentiation/depression transients, programming energy, programming time, and power requirements for writing conductance weights in artificial network crossbars. As for volatile memristors, we consider the modeling of their behavior in the context of a leaky-integrate-and-fire neuron, demonstrating how the model captures the threshold activation function and the input signal frequency dependence.},
  archive      = {J_AML},
  author       = {Suñé, Jordi and Miranda, Enrique},
  doi          = {10.1063/5.0255043},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016118},
  shortjournal = {APL Mach. Learn.},
  title        = {Stochastic compact model for memory and threshold switching memristors},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A memristive computational neural network model for time-series processing. <em>AML</em>, <em>3</em>(1), 016117. (<a href='https://doi.org/10.1063/5.0255168'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we introduce a novel computational framework inspired by the physics of memristive devices and systems, which we embed into the context of Recurrent Neural Networks (RNNs) for time-series processing. Our proposed memristive-friendly neural network architecture leverages both the principles of Reservoir Computing (RC) and fully trainable RNNs, providing a versatile platform for sequence learning. We provide a mathematical analysis of the stability of the resulting neural network dynamics, identifying the role of crucial RC-based architectural hyper-parameters. Through numerical simulations, we demonstrate the effectiveness of the proposed approach across diverse regression and classification tasks, showcasing performance that is competitive with both traditional RC and fully trainable RNN systems. Our results highlight the scalability and adaptability of memristive-inspired computational architectures, offering a promising path toward efficient neuromorphic computing for complex sequence-based applications.},
  archive      = {J_AML},
  author       = {Pistolesi, Veronica and Ceni, Andrea and Milano, Gianluca and Ricciardi, Carlo and Gallicchio, Claudio},
  doi          = {10.1063/5.0255168},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016117},
  shortjournal = {APL Mach. Learn.},
  title        = {A memristive computational neural network model for time-series processing},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UniFIDES: Universal fractional integro-differential equations solver. <em>AML</em>, <em>3</em>(1), 016116. (<a href='https://doi.org/10.1063/5.0258122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of data-driven approaches for solving differential equations has led to numerous applications in science and engineering across many disciplines and remains a central focus of active scientific inquiry. However, a large body of natural phenomena incorporates memory effects that are best described via fractional integro-differential equations (FIDEs), in which the integral or differential operators accept non-integer orders. Addressing the challenges posed by nonlinear FIDEs is a recognized difficulty, necessitating the application of generic methods with immediate practical relevance. This work introduces the Universal Fractional Integro-Differential Equations Solver (UniFIDES), a comprehensive machine learning platform designed to expeditiously solve a variety of FIDEs in both forward and inverse directions, without the need for ad hoc manipulation of the equations. The effectiveness of UniFIDES is demonstrated through a collection of integer-order and fractional problems in science and engineering. Our results highlight UniFIDES’ ability to accurately solve a wide spectrum of integro-differential equations and offer the prospect of using machine learning platforms universally for discovering and describing dynamic and complex systems.},
  archive      = {J_AML},
  author       = {Saadat, Milad and Mangal, Deepak and Jamali, Safa},
  doi          = {10.1063/5.0258122},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016116},
  shortjournal = {APL Mach. Learn.},
  title        = {UniFIDES: Universal fractional integro-differential equations solver},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale simulation and machine learning facilitated design of two-dimensional nanomaterials-based tunnel field-effect transistors: A review. <em>AML</em>, <em>3</em>(1), 016115. (<a href='https://doi.org/10.1063/5.0240004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional transistors based on complementary metal–oxide–semiconductor and metal–oxide–semiconductor field-effect transistors are facing significant limitations as device scaling reaches the limits of Moore’s law. These limitations include increased leakage currents, pronounced short-channel effects, and quantum tunneling through the gate oxide, leading to higher power consumption and deviations from ideal behavior. Tunnel Field-Effect Transistors (TFETs) can overcome these challenges by utilizing the quantum tunneling of charge carriers to switch between on and off states and achieve a subthreshold swing below 60 mV/decade. This allows for lower power consumption, continued scaling, and improved performance in low-power applications. This review focuses on the design and operation of TFETs, emphasizing the optimization of device performance through material selection and advanced simulation techniques. The discussion will specifically address the use of two-dimensional materials in TFET design and explore simulation methods ranging from multi-scale approaches to machine learning-driven optimization.},
  archive      = {J_AML},
  author       = {Tsang, Chloe Isabella and Pu, Haihui and Chen, Junhong},
  doi          = {10.1063/5.0240004},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016115},
  shortjournal = {APL Mach. Learn.},
  title        = {Multiscale simulation and machine learning facilitated design of two-dimensional nanomaterials-based tunnel field-effect transistors: A review},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Environment model construction toward auto-tuning of quantum dot devices based on model-based reinforcement learning. <em>AML</em>, <em>3</em>(1), 016114. (<a href='https://doi.org/10.1063/5.0251336'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semiconductor quantum dots (QDs) are promising hosts for quantum computers because of their scalability. In order to expedite the development process, there is a strong need for fully automated tuning of QDs that allows for en masse characterization of newly fabricated devices and control over large-scale systems with appreciable variability. Machine learning has been actively explored as a means to this end; however, challenges remain in terms of versatility for different tasks and device types. In this study, we explore a model-based reinforcement learning (MBRL) approach: unlike traditional reinforcement learning techniques, the learning process of MBRL progresses by constructing a model for the environment, which is to be diverted for other tasks and/or devices, thereby minimizing time-consuming learning processes. Using pre-measured data, we construct an environment model and, despite the intrinsic sparse reward distribution of the QD system, demonstrate its suitability for MBRL by emulating the process of auto-tuning to a single QD region. Our results highlight the potential of MBRL for more generic QD auto-tuning techniques, providing a promising step toward fully automated QD tuning.},
  archive      = {J_AML},
  author       = {Kondo, Chihiro and Mizokuchi, Raisei and Yoneda, Jun and Kodera, Tetsuo},
  doi          = {10.1063/5.0251336},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016114},
  shortjournal = {APL Mach. Learn.},
  title        = {Environment model construction toward auto-tuning of quantum dot devices based on model-based reinforcement learning},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating the hyperparameter space of deep neural network models for reaction coordinates. <em>AML</em>, <em>3</em>(1), 016113. (<a href='https://doi.org/10.1063/5.0252631'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying reaction coordinates (RCs) is a key to understanding the mechanism of reactions in complex systems. Deep neural network (DNN) and machine learning approaches have become a powerful tool to find the RC. On the other hand, the hyperparameters that determine the DNN model structure can be highly flexible and are often selected intuitively and in a non-trivial and tedious manner. Furthermore, how the hyperparameter choice affects the RC quality remains obscure. Here, we explore the hyperparameter space by developing the hyperparameter tuning approach for the DNN model for RC and investigate how the parameter set affects the RC quality. The DNN model is built to predict the committor along the RC from various collective variables by minimizing the cross-entropy function; the hyperparameters are automatically determined using the Bayesian optimization method. The approach is applied to study the isomerization of alanine dipeptide in vacuum and in water, and the features that characterize the RC are extracted using the explainable AI (XAI) tools. The results show that the DNN models with diverse structures can describe the RC with similar accuracy, and furthermore, the features analyzed by XAI are highly similar. This indicates that the hyperparameter space is multimodal. The electrostatic potential from the solvent to the hydrogen H 18 plays an important role in the RC in water. The current study shows that the structure of the DNN models can be rather flexible, while the suitably optimized models share the same features; therefore, a common mechanism from the RC can be extracted.},
  archive      = {J_AML},
  author       = {Kawashima, Kyohei and Sato, Takumi and Okazaki, Kei-ichi and Kim, Kang and Matubayasi, Nobuyuki and Mori, Toshifumi},
  doi          = {10.1063/5.0252631},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016113},
  shortjournal = {APL Mach. Learn.},
  title        = {Investigating the hyperparameter space of deep neural network models for reaction coordinates},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Slim multi-scale convolutional autoencoder-based reduced-order models for interpretable features of a complex dynamical system. <em>AML</em>, <em>3</em>(1), 016112. (<a href='https://doi.org/10.1063/5.0244416'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, data-driven deep learning models have gained significant importance in the analysis of turbulent dynamical systems. Within the context of reduced-order models, convolutional autoencoders (CAEs) pose a universally applicable alternative to conventional approaches. They can learn nonlinear transformations directly from data, without prior knowledge of the system. However, the features generated by such models lack interpretability. Thus, the resulting model is a black-box that effectively reduces the complexity of the system but does not provide insights into the meaning of the latent features. To address this critical issue, we introduce a novel interpretable CAE approach for high-dimensional fluid flow data that maintains the reconstruction quality of conventional CAEs and allows for feature interpretation. Our method can be easily integrated into any existing CAE architecture with minor modifications of the training process. We compare our approach to Proper Orthogonal Decomposition (POD) and two existing methods for interpretable CAEs. We apply all methods to three different experimental turbulent Rayleigh–Bénard convection datasets with varying complexity. Our results show that the proposed method is lightweight, easy to train, and achieves relative reconstruction performance improvements of up to 6.4% over POD for 64 modes. The relative improvement increases to up to 229.8% as the number of modes decreases. In addition, our method delivers interpretable features similar to those of POD and is significantly less resource-intensive than existing CAE approaches, using less than 2% of the parameters. These approaches either trade interpretability for reconstruction performance or only provide interpretability to a limited extent.},
  archive      = {J_AML},
  author       = {Teutsch, Philipp and Pfeffer, Philipp and Sharifi Ghazijahani, Mohammad and Cierpka, Christian and Schumacher, Jörg and Mäder, Patrick},
  doi          = {10.1063/5.0244416},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016112},
  shortjournal = {APL Mach. Learn.},
  title        = {Slim multi-scale convolutional autoencoder-based reduced-order models for interpretable features of a complex dynamical system},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonideality-aware training makes memristive networks more robust to adversarial attacks. <em>AML</em>, <em>3</em>(1), 016111. (<a href='https://doi.org/10.1063/5.0241202'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks are now deployed in a wide number of areas, from object classification to natural language systems. Implementations using analog devices such as memristors promise better power efficiency, potentially bringing these applications to a greater number of environments. However, such systems suffer from more frequent device faults, and overall, their exposure to adversarial attacks has not been studied extensively. In this work, we investigate how nonideality-aware training—a common technique to deal with physical nonidealities—affects adversarial robustness. We find that adversarial robustness is significantly improved, even with limited knowledge of what nonidealities will be encountered during test time.},
  archive      = {J_AML},
  author       = {Joksas, Dovydas and Muñoz-González, Luis and Lupu, Emil and Mehonic, Adnan},
  doi          = {10.1063/5.0241202},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016111},
  shortjournal = {APL Mach. Learn.},
  title        = {Nonideality-aware training makes memristive networks more robust to adversarial attacks},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic dataset generation technique applied to data-driven automotive aerodynamics. <em>AML</em>, <em>3</em>(1), 016110. (<a href='https://doi.org/10.1063/5.0233367'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel strategy for generating datasets has been developed within the context of drag prediction for automotive geometries using neural networks. A primary challenge in this field is constructing a training database of sufficient size and diversity. Our method relies on a small number of initial data points and provides a recipe to systematically interpolate between them, generating an arbitrary number of samples at the desired quality. We tested this strategy using a representative automotive geometry and demonstrated that convolutional neural networks perform exceptionally well at predicting drag coefficients and surface pressures. Promising results were obtained in testing extrapolation performance. Our method can be applied to other problems of aerodynamic shape optimization.},
  archive      = {J_AML},
  author       = {Benjamin, Mark and Iaccarino, Gianluca},
  doi          = {10.1063/5.0233367},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016110},
  shortjournal = {APL Mach. Learn.},
  title        = {A systematic dataset generation technique applied to data-driven automotive aerodynamics},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Morphology reconstruction from experimental small-angle x-ray scattering patterns by physics-aware neural network. <em>AML</em>, <em>3</em>(1), 016109. (<a href='https://doi.org/10.1063/5.0246111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we developed a new methodology that can reconstruct the morphology from experimental small-angle x-ray scattering (SAXS) patterns directly without modeling by using a physics-aware neural network, SAXSNN. By incorporating the scattering physics of x rays into the network, SAXSNN could be trained to capture the complex mapping between the SAXS patterns in reciprocal space and the corresponding morphologies in real space in an unsupervised way. We demonstrated the performance of SAXSNN on the experimental SAXS patterns of semicrystalline and amorphous polymers, i.e., hard-elastic isotactic polypropylene (iPP) films and plasticized poly(vinyl butyral) (PVB). The morphologies reconstructed by SAXSNN are well consistent with our existing knowledge of the morphology of iPP films and PVB. The developed methodology here allows us to rapidly predict the morphologies for any given SAXS pattern without any in-prior phase information and, thus, provides an intuitive understanding of the microstructures of the measured samples. A real-time feedback of the morphologies of measured samples to SAXS beamline users at modern synchrotron radiation light sources will be feasible in the near future.},
  archive      = {J_AML},
  author       = {Zhao, Chenhao and Sun, Shenyang and Han, Xueqing and Zhu, Jianhe and Yu, Wancheng and Li, Liangbin},
  doi          = {10.1063/5.0246111},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016109},
  shortjournal = {APL Mach. Learn.},
  title        = {Morphology reconstruction from experimental small-angle x-ray scattering patterns by physics-aware neural network},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Confidence evaluation for feature selection in expanded feature space based on density of states. <em>AML</em>, <em>3</em>(1), 016108. (<a href='https://doi.org/10.1063/5.0245626'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In materials informatics, feature selection and model selection are utilized in the knowledge extraction process, and the confidence evaluation of the selection result is crucial for ensuring the reliability of the extracted knowledge. In this study, we propose a novel method to quantitatively evaluate the significance of low-dimensional models obtained from an expanded feature space using the density of states (DoS) for the evaluation metrics. This method allows us to compare the performance of the selected model to those of other models and evaluate its significance. We further propose an evaluation method for feature importance based on marginal posterior probabilities using the Bayesian model averaging (BMA) framework, which considers all models. We demonstrate the effectiveness of our proposed methods through their application to a crystal structure dataset. Our results show that the DoS analysis reveals the presence of a large number of models with a comparable performance with the best model reported in a previous research work. This suggests that knowledge extracted from a single selected model can be unreliable and that considering other models is crucial. We also show that the BMA-based feature importance evaluation provides valuable insights into the importance of features, highlighting both primary features and functional forms. In addition, we demonstrate that the LASSO + L0 method commonly used in existing research deteriorates the search space for model selection. Our findings suggest that our proposed methods provide valuable tools for assessing the significance of low-dimensional models and extracting knowledge from large-scale data in materials informatics.},
  archive      = {J_AML},
  author       = {Obinata, Koki and Igarashi, Yasuhiko and Nagata, Kenji and Sodeyama, Keitaro and Okada, Masato},
  doi          = {10.1063/5.0245626},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016108},
  shortjournal = {APL Mach. Learn.},
  title        = {Confidence evaluation for feature selection in expanded feature space based on density of states},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Entanglement engineering of optomechanical systems by reinforcement learning. <em>AML</em>, <em>3</em>(1), 016107. (<a href='https://doi.org/10.1063/5.0233470'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entanglement is fundamental to quantum information science and technology, yet controlling and manipulating entanglement—so-called entanglement engineering—for arbitrary quantum systems remains a formidable challenge. There are two difficulties: the fragility of quantum entanglement and its experimental characterization. We develop a model-free deep reinforcement-learning (RL) approach to entanglement engineering, in which feedback control together with weak continuous measurement and partial state observation is exploited to generate and maintain desired entanglement. We employ quantum optomechanical systems with linear or nonlinear photon–phonon interactions to demonstrate the workings of our machine-learning-based entanglement engineering protocol. In particular, the RL agent sequentially interacts with one or multiple parallel quantum optomechanical environments, collects trajectories, and updates the policy to maximize the accumulated reward to create and stabilize quantum entanglement over an arbitrary amount of time. The machine-learning-based model-free control principle is applicable to the entanglement engineering of experimental quantum systems in general.},
  archive      = {J_AML},
  author       = {Ye, Li-Li and Arenz, Christian and Lukens, Joseph M. and Lai, Ying-Cheng},
  doi          = {10.1063/5.0233470},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016107},
  shortjournal = {APL Mach. Learn.},
  title        = {Entanglement engineering of optomechanical systems by reinforcement learning},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning for quantitative dynamic fragmentation analysis. <em>AML</em>, <em>3</em>(1), 016106. (<a href='https://doi.org/10.1063/5.0233739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have developed an image-based convolutional neural network that is applicable for quantitative time-resolved measurements of the fragmentation behavior of opaque brittle materials using ultra-high speed optical imaging. This model extends previous work on the U-net model. Here we trained binary-, three-, and five-class models using supervised learning on experimentally measured dynamic fracture experiments on various opaque structural ceramic materials that were adhered on transparent polymer (polycarbonate or acrylic) backing materials. Full details of the experimental investigations are outside the scope of this manuscript, but briefly, several different ceramics were loaded using spatially and time-varying mechanical loads to induce inelastic deformation and fracture processes that were recorded at frequencies as high as 5 MHz using high-speed optical imaging. These experiments provided a rich and diverse dataset that includes many of the common fracture modes found in static and dynamic fractures, including cone cracking, median cracking, comminution, and combined complex failure modes that involve effectively simultaneous activation and propagation of multiple fragmentation modes. While the training data presented here were obtained from dynamic fragmentation experiments, this study is applicable to static loading of these materials as the crack speeds are on the order of 1–10 km/s regardless of the loading rate. We believe the methodologies presented here will be useful in quantifying the failure processes in structural materials for protection applications and can be used for direct validation of engineering models used in design.},
  archive      = {J_AML},
  author       = {Cazares, Erwin and Schuster, Brian E.},
  doi          = {10.1063/5.0233739},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016106},
  shortjournal = {APL Mach. Learn.},
  title        = {Deep learning for quantitative dynamic fragmentation analysis},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable recurrence graph network for stratifying RhoB texture dynamics in rectal cancer biopsies. <em>AML</em>, <em>3</em>(1), 016105. (<a href='https://doi.org/10.1063/5.0243636'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scalable recurrence graph network (SRGNet) is introduced in this paper to improve the accuracy of predicting five-year survival outcomes in rectal cancer patients by analyzing RhoB texture dynamics in biopsies. RhoB, a key biomarker assessed via immunohistochemistry, is crucial in predicting responses to radiotherapy (RT), but variability in staining techniques and tumor heterogeneity often complicate these assessments. SRGNet integrates spatial statistics, nonlinear dynamics, graph theory, and graph convolutional networks to address these challenges. In testing, SRGNet outperformed 10 pre-trained convolutional neural networks, achieving 88% accuracy in biopsies from RT patients, with 67% accuracy for predicting survival under five years and 100% accuracy for survival over five years, along with 100% precision, an F1 score of 0.80, and an AUC of 0.73. For non-RT patients, SRGNet attained 91% accuracy, 100% precision for survival over five years, an F1 score of 0.86, and an AUC of 0.82. These results demonstrate SRGNet’s potential to enhance the precision and reliability of survival predictions in rectal cancer patients, overcoming challenges of RhoB expression variability and tumor heterogeneity.},
  archive      = {J_AML},
  author       = {Pham, Tuan D.},
  doi          = {10.1063/5.0243636},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016105},
  shortjournal = {APL Mach. Learn.},
  title        = {Scalable recurrence graph network for stratifying RhoB texture dynamics in rectal cancer biopsies},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-scale-aware data augmentation for reduced-order models of high-dimensional flows. <em>AML</em>, <em>3</em>(1), 016104. (<a href='https://doi.org/10.1063/5.0213700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional autoencoders have proven to be an adequate tool to perform reduced-order modeling for high-dimensional nonlinear dynamical systems. Their goal is to reduce dimensionality strongly while preserving the most characteristic features of the system. Here, we show that these models rely sensitively on the completeness of the provided data. This is particularly challenging for fully turbulent flows with their coherent structures ranging from large-scale superstructures to dissipative eddies over orders of magnitude in time and space. As a result, an unrealistically large number of data snapshots would be required to properly cover all the essential dynamics, whereas the features on small time and length scales require only a small number of snapshots of the respective flow, especially the long lasting large-scale structures that are difficult to characterize either numerically or experimentally. We demonstrate for three types of flows that a missing representation of large-scale turbulent structures leads to failures in the training process. We suggest a method to mitigate this shortcoming. This includes the transformation of data samples to new large-scale structures, which enhance the data. Furthermore, we skip augmentations that are more detrimental to the model performance. We evaluate our method for three datasets, two from numerical simulations of turbulent Rayleigh–Bénard convection flows and one from laboratory experiment for the flow past an array of cylinders. We show that the method can substantially improve model utility for high-dimensional data. In this way, we avoid an intensive grid search through possible augmentation combinations without further knowledge about the underlying system.},
  archive      = {J_AML},
  author       = {Teutsch, Philipp and Ghazijahani, Mohammad Sharifi and Heyder, Florian and Cierpka, Christian and Schumacher, Jörg and Mäder, Patrick},
  doi          = {10.1063/5.0213700},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016104},
  shortjournal = {APL Mach. Learn.},
  title        = {Large-scale-aware data augmentation for reduced-order models of high-dimensional flows},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dislocation cartography: Representations and unsupervised classification of dislocation networks with unique fingerprints. <em>AML</em>, <em>3</em>(1), 016103. (<a href='https://doi.org/10.1063/5.0224710'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting structure in data is the first step to arrive at meaningful representations for systems. This is particularly challenging for evolving dislocation networks evolving as a consequence of plastic deformation of crystalline materials. Our study employs Isomap, a manifold learning technique, to show the intrinsic structure of high-dimensional dislocation density field data of dislocation structures resulting from different compression axes. Our maps provide a systematic framework for quantitatively comparing dislocation structures and offer unique fingerprints based on dislocation density fields. It represents a novel, unbiased approach that contributes to the quantitative classification of dislocation structures, which can be systematically extended using different representations of dislocation systems.},
  archive      = {J_AML},
  author       = {Udofia, Benjamin and Jogi, Tushar and Stricker, Markus},
  doi          = {10.1063/5.0224710},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016103},
  shortjournal = {APL Mach. Learn.},
  title        = {Dislocation cartography: Representations and unsupervised classification of dislocation networks with unique fingerprints},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of nonlinear behavior of viscoelastic damping in musical membranes using physics-informed self-organizing maps. <em>AML</em>, <em>3</em>(1), 016102. (<a href='https://doi.org/10.1063/5.0242985'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research offers a new analytical tool that unravels the nonlinear relation between the parameters of Viscoelastic Damping (VD) and the resulting frequency spectrum in musical membranes. Understanding how variations in VD parameters influence the resulting sounds is crucial for developing new tools for artistic expression and for designing musical instruments with distinct sound qualities. In the case of membranophones, the external damping is well understood, while the internal damping due to viscoelastic properties of materials remains unclear. In previous research, VD in musical membranes has been modeled using a Finite-Difference Time-Domain (FDTD) model. Nonetheless, analyzing the complex relationships between the large parameter space of the model and the nonlinear behavior of VD is a challenging task. This study addresses this analysis through physics-based machine learning. We employed a FDTD model of a viscoelastically damped membrane to create a physics-informed dataset, which we subsequently analyzed using Self-Organizing Maps (SOMs). Our findings reveal that the damping coefficient is the primary criterion when clustering the data. Furthermore, we found the internal structure of the cluster to depend on the rate of decay of the memory effect, i.e., the rate at which the energy introduced back into the system decreases. The study also demonstrates the benefits of using principal component analysis for the SOM initialization.},
  archive      = {J_AML},
  author       = {Martínez Orellanos, Cristhiam Fidel and Bader, Rolf},
  doi          = {10.1063/5.0242985},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016102},
  shortjournal = {APL Mach. Learn.},
  title        = {Analysis of nonlinear behavior of viscoelastic damping in musical membranes using physics-informed self-organizing maps},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficiency of machine learning optimizers and meta-optimization for nanophotonic inverse design tasks. <em>AML</em>, <em>3</em>(1), 016101. (<a href='https://doi.org/10.1063/5.0238444'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of deep learning has driven the proliferation and refinement of numerous non-convex optimization algorithms. Despite this growing array of options, the field of nanophotonic inverse design continues to rely heavily on quasi-Newton optimizers such as L-BFGS and basic momentum-based methods such as Adam. A systematic survey of these and other algorithms in the nanophotonics context remains lacking. Here, we compare 24 widely used machine learning optimizers on inverse design tasks. We study two prototypical nanophotonics inverse design problems—the mode splitter and wavelength demultiplexer—across various system sizes, using both hand-tuned and meta-learned hyperparameters. We find that Adam derivatives, as well as the Fromage optimizer, consistently outperform L-BFGS and standard gradient descent, regardless of system size. While meta-learning has a negligible-to-negative impact on Adam and Fromage, it significantly improves others, particularly AdaGrad derivatives and simple gradient descent, such that their performance is on par with Adam. In addition, we observe that the most effective optimizers exhibit the lowest correlation between initial and final performance. Our results and codebase (github.com/Ma-Lab-Cal/photonicsOptComp) provide a valuable framework for selecting and benchmarking optimizers in nanophotonic inverse design.},
  archive      = {J_AML},
  author       = {Morrison, Nathaniel and Ma, Eric Y.},
  doi          = {10.1063/5.0238444},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016101},
  shortjournal = {APL Mach. Learn.},
  title        = {Efficiency of machine learning optimizers and meta-optimization for nanophotonic inverse design tasks},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: The intersection of machine learning and physical sciences: Insights from the 2024 nobel prizes. <em>AML</em>, <em>3</em>(1), 010401. (<a href='https://doi.org/10.1063/5.0267892'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AML},
  author       = {Milano, Gianluca and Mehonic, Adnan},
  doi          = {10.1063/5.0267892},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {010401},
  shortjournal = {APL Mach. Learn.},
  title        = {Editorial: The intersection of machine learning and physical sciences: Insights from the 2024 nobel prizes},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). APL machine learning reviewer acknowledgment for 2024. <em>AML</em>, <em>3</em>(1), 010201. (<a href='https://doi.org/10.1063/5.0265450'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AML},
  author       = {Mehonic, Adnan},
  doi          = {10.1063/5.0265450},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {010201},
  shortjournal = {APL Mach. Learn.},
  title        = {APL machine learning reviewer acknowledgment for 2024},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
