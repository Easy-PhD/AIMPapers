<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ICAE</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="icae">ICAE - 27</h2>
<ul>
<li><details>
<summary>
(2025). Multiobjective cooperative multi-fitness in workflow scheduling problem. <em>ICAE</em>, <em>32</em>(4), 443--464. (<a href='https://doi.org/10.1177/10692509251363797'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimisation of scientific workflows in cloud environments presents considerable challenges, primarily due to the inherent trade-offs between makespan and energy consumption. To address this, we propose Multi-Objective Cooperative Multi-Fitness (MOCMF), a novel mechanism that significantly enhances multi-objective evolutionary algorithms through a unique cooperative evaluation and recoding strategy. Diverging from existing multi-decoder approaches, MOCMF’s core innovation lies in its collaborative framework: heuristic decoders work in tandem to support a baseline decoding function, providing expert solutions that guide the Lamarckian recoding of chromosomes. Furthermore, MOCMF extends this cooperative evaluation to a multi-objective setting, where each heuristic decoder focuses on optimising a specific objective, leading to the generation of multiple distinct solutions per chromosome. Experimental results on data-intensive workflow benchmarks show that MOCMF improves the average Hypervolume by 32% and Inverted Generational Distance by 42% compared to a standard NSGA-II implementation, and by 7% and 6% respectively compared to its mono-objective cooperative variants. The proposed mechanism is also generalisable and potentially applicable to other multi-objective problems beyond workflow scheduling.},
  archive      = {J_ICAE},
  author       = {Pablo Barredo and Jorge Puente},
  doi          = {10.1177/10692509251363797},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {11},
  number       = {4},
  pages        = {443--464},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Multiobjective cooperative multi-fitness in workflow scheduling problem},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph theory and its potential in the automatic detection of left bundle branch block. <em>ICAE</em>, <em>32</em>(4), 424--442. (<a href='https://doi.org/10.1177/10692509251362613'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate differentiation between Left Bundle Branch Block (LBBB) and its strict subtype (sLBBB) is essential for optimizing patient selection for Cardiac Resynchronization Therapy (CRT), yet remains clinically challenging. This study proposes and compares two graph-theory-based pipelines for automated classification of 12-lead electrocardiograms (ECGs) into Healthy, LBBB, and sLBBB categories. Functional connectivity graphs were constructed from inter-lead measures, including Pearson correlation, cross-correlation, and phase difference. The first approach combines Graph Signal Processing (GSP) with machine learning. Graph filtering was performed via spectral decomposition of the Laplacian matrix, selecting dominant eigenmodes and reconstructing signals through the inverse Graph Fourier Transform—integrating spatial and temporal features. The second approach converted connectivity matrices into grayscale images, classified using a Convolutional Neural Network (CNN), and incorporated Explainable AI (XAI) via Grad-CAM to visualize inter-lead interactions and enhance model transparency. The GSP-based method using phase difference and a Support Vector Machine achieved the highest performance (mean balanced accuracy = 0.8317 ), while the CNN-based approach with cross-correlation images reached 0.7646 , offering improved interpretability. Both methods distinguished pathological from healthy cases, but precise classification between LBBB and sLBBB remains challenging. These results highlight the complementary value of graph-based ECG analysis and support future hybrid models for CRT stratification.},
  archive      = {J_ICAE},
  author       = {Beatriz del Cisne Macas Ordóñez and Diego Vinicio Orellana Villavicencio and Marco Augusto Suing Ochoa and Jorge Enrique Carrión Gonzólez and María Paula Bonomini},
  doi          = {10.1177/10692509251362613},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {11},
  number       = {4},
  pages        = {424--442},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Graph theory and its potential in the automatic detection of left bundle branch block},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Text-driven online action detection. <em>ICAE</em>, <em>32</em>(4), 415--423. (<a href='https://doi.org/10.1177/10692509241308069'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting actions as they occur is essential for applications like video surveillance, autonomous driving, and human-robot interaction. Known as online action detection, this task requires classifying actions in streaming videos, handling background noise, and coping with incomplete actions. Transformer architectures are the current state-of-the-art, yet the potential of recent advancements in computer vision, particularly vision-language models (VLMs), remains largely untapped for this problem, partly due to high computational costs. In this paper, we introduce TOAD: A Text-driven Online Action Detection architecture that supports zero-shot and few-shot learning. TOAD leverages CLIP (Contrastive Language-Image Pretraining) textual embeddings, enabling efficient use of VLMs without significant computational overhead. Our model achieves 82.46% mAP on the THUMOS14 dataset, outperforming existing methods, and sets new baselines for zero-shot and few-shot performance on the THUMOS14 and TVSeries datasets.},
  archive      = {J_ICAE},
  author       = {Manuel Benavent-Lledo and David Mulero-Pérez and David Ortiz-Perez and Jose Garcia-Rodriguez},
  doi          = {10.1177/10692509241308069},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {11},
  number       = {4},
  pages        = {415--423},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Text-driven online action detection},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving the energy-aware flexible job shop problem using a memetic algorithm. <em>ICAE</em>, <em>32</em>(4), 397--414. (<a href='https://doi.org/10.1177/10692509251353343'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the flexible job shop problem with interval processing times. Minimising makespan is a well-known scheduling objective that is widely used in many sectors; however, energy efficiency is gaining more importance as climate change intensifies. In this work, we minimise the makespan and the total energy consumption using a lexicographic goal programming approach. A memetic algorithm that is composed of a genetic algorithm and a local search method is developed and tested to solve this problem. The results show that our approach manages to improve the best-known results.},
  archive      = {J_ICAE},
  author       = {Sezin Afşar and Jorge Puente and Juan José Palacios and Inés González-Rodríguez and Camino R Vela},
  doi          = {10.1177/10692509251353343},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {11},
  number       = {4},
  pages        = {397--414},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Solving the energy-aware flexible job shop problem using a memetic algorithm},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partially homomorphic framework for secure privacy-preserving ID creation. <em>ICAE</em>, <em>32</em>(4), 379--396. (<a href='https://doi.org/10.1177/10692509251342680'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Homomorphic encryption has seen limited application in real-world settings due to its high computational costs, which often impede practical use in latency-sensitive scenarios. Addressing this challenge, this research work presents an efficient, partially homomorphic encryption framework for privacy-preserving ID creation tailored to biometric applications, such as border control or access to secure restricted facilities. The proposed solution leverages the additive homomorphic properties of Paillier and Elliptic Curve ElGamal encryption schemes to encapsulate biometric data within a secure cryptographic layer, enabling rapid verification while minimizing computation and storage demands. Paillier encryption ensures robust security with maximal accuracy, while Elliptic Curve ElGamal optimizes for minimal ciphertext sizes, both meeting rigorous ISO biometric security standards. Experimental results demonstrate that the framework achieves high accuracy with reduced memory and bandwidth requirements, with encrypted IDs as compact as 4 KiB, making it suitable for scalable deployment. This research work represents a key advancement in homomorphic encryption applications, balancing privacy and efficiency without the usual overhead, and making it feasible for real-time biometric processing. In summary, this framework offers a pioneering solution in secure biometric verification, setting a new standard for privacy-preserving applications, positioning it as a promising model for future secure identification systems.},
  archive      = {J_ICAE},
  author       = {Nikola Hristov-Kalamov and Raúl Fernández-Ruiz and Cristina Conde and Agustín Álvarez-Marquina and Francisco Domínguez-Mateos and Pedro Gómez-Vilda and Daniel Palacios-Alonso},
  doi          = {10.1177/10692509251342680},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {11},
  number       = {4},
  pages        = {379--396},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Partially homomorphic framework for secure privacy-preserving ID creation},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simultaneous multi-step wind speed prediction on multiple farms using multi-task deep learning. <em>ICAE</em>, <em>32</em>(4), 366--378. (<a href='https://doi.org/10.1177/10692509251337224'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present the MUSONet model, which leverages information from different sources (in this case, wind farms) to perform a multi-step wind speed prediction. The main goal of this approach is improving the global prediction accuracy, specifically at longer prediction horizons. Thus, the proposed model is able to simultaneously predict the wind speed at three different prediction horizons ( 6 h, 12 h, and 24 h), across three different wind farms located in Spain. We also evaluate the performance of the presented methodology by considering three different activation functions for hidden neurons in the neural network: Sigmoid, ReLU, and ELUs+2L. The results show that the proposed multi-source approach improves the performance of the single-source counterpart for the longer prediction horizons ( 12 h and 24 h). In addition, the proposed multi-source method reduces by over 30 % the number of parameters compared to three single-source models (in this case, one model per wind farm), resulting in a simpler solution for the problem addressed and requiring much lower computational resources.},
  archive      = {J_ICAE},
  author       = {Rafael Ayllón-Gavilán and Antonio Manuel Gómez-Orellana and Víctor Manuel Vargas and David Guijo-Rubio and Jorge Pérez-Aracil and Sancho Salcedo-Sanz and Pedro Antonio Gutiérrez and César Hervás-Martínez},
  doi          = {10.1177/10692509251337224},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {11},
  number       = {4},
  pages        = {366--378},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Simultaneous multi-step wind speed prediction on multiple farms using multi-task deep learning},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding joint range of motion development in robotic learning. <em>ICAE</em>, <em>32</em>(4), 346--365. (<a href='https://doi.org/10.1177/10692509251335114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint Range of Motion (JROM) development has been shown to facilitate learning motor control in human beings. This developmental strategy has been applied in robotics to improve learning performance with different outcomes: sometimes it is favourable, others irrelevant, and others, even detrimental. The reasons that underpin this variability in the results are still not well understood. In this paper, we seek to better understand the principles underlying the application of JROM based morphological development to make its use more straightforward. To this end, empirical studies were carried out over two representative use cases: quadruped and bipedal robot morphologies learning to walk. Different parameters of the application of JROM development (morphological configuration, JROM developmental strategy, etc.) have been evaluated to elucidate their effects over learning. The results show that there are significant connections between the reduction of the motor space induced by JROM and the way the exploration and exploitation of the solution space is carried out by the learning algorithm, and the performance achieved. Through these connections, we have identified a set of conditions that must be satisfied for JROM development to be effective as a tool for learning improvement.},
  archive      = {J_ICAE},
  author       = {Martín Naya-Varela and Andrés Faiña and Alejandro Romero and Richard J. Duro},
  doi          = {10.1177/10692509251335114},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {11},
  number       = {4},
  pages        = {346--365},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Understanding joint range of motion development in robotic learning},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Introduction. <em>ICAE</em>, <em>32</em>(4), 345. (<a href='https://doi.org/10.1177/10692509251381071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ICAE},
  author       = {José Manuel Ferrández},
  doi          = {10.1177/10692509251381071},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {11},
  number       = {4},
  pages        = {345},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Introduction},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Models and tools for supporting sustainability assessment in systems engineering. <em>ICAE</em>, <em>32</em>(3), 326--342. (<a href='https://doi.org/10.1177/10692509251352461'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since several years, sustainability has become a very important challenge for our societies. Our lifestyles are in the process of making our planet uninhabitable because of the various impacts that we, as human beings, are inflicting on it. As part of these impacts, we focus on Complex Systems designed by humans. It is of uttermost importance to be able to analyze and design complex systems so that the sustainability features are taken into account. More specifically, the contribution of this article is to propose models and tools for the assessment of systems sustainability during the analysis and design phases. The analysis and design of systems may be difficult tasks. It is even more so for complex systems. Since decades, the System Engineering (SE) field has given birth to a family of systemic and multidisciplinary approaches for the design of systems. Among SE approaches, Model-Based System Engineering (MBSE) is a special kind of SE that relies on formalized models as first-class citizens deliverables for all analysis and design activities from requirements elicitation to final design and validation. SysML (Systems Modelling Language) is one of these MBSE approaches. SysML is a well-known, general purpose graphical systems modelling language that supports SE approaches. In addition, SysML allows its own language extension by the creation of new concepts and diagrams. This extension mechanism is known as Domain Specific Modelling Language (DSML). The contributions presented in this paper consist in the definition of an extension of SysML that provides models and tools in order to assess the sustainability of systems during analysis and design. This extension of SysML is based upon a technique, named profile, and proposes new modelling concepts for taking into consideration sustainability issues during systems engineering. Moreover, these new model elements are supported by software tools issued from the MBSE domain and allow the development of ad-hoc software tooling support.},
  archive      = {J_ICAE},
  author       = {Vincent Hilaire and Alexis Lalevée},
  doi          = {10.1177/10692509251352461},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {3},
  pages        = {326--342},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Models and tools for supporting sustainability assessment in systems engineering},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and implementation of an internet of things automatic solar shading system. <em>ICAE</em>, <em>32</em>(3), 309--325. (<a href='https://doi.org/10.1177/10692509251318454'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The implementation of energy-saving solutions becomes increasingly crucial as global energy reserves decline. The integration of automated solar shading systems not only improves living conditions, but also reduces energy costs. This work presents the design and implementation of an Internet of Things (IoT) automatic solar shading system. The developed solar shading includes custom-made louvers that are able to reflect the external light, while being transparent. Moreover, the system is equipped with a microcontroller and appropriate sensors that enable its automated operation based on measurements of the internal and external environmental conditions. A Raspberry Pi acts as a server, enabling the communication between the shading devices and the users, through an open-source home automation operating system (Home Assistant OS). The user-friendly interface, accessible via a web browser or a mobile application, provides essential data such as temperature, humidity, and device status. Alert notifications are sent when specific conditions are met. The overall system is enclosed in two 3D-printed units, ensuring its durability and easy integration into existing or new installations. In summary, this system combines the advantages of automatic solar shadings, including energy efficiency and improved occupant comfort, with smart features for remote control and monitoring through a user-friendly interface. The proposed system has been installed in a window of our laboratory, performing successfully in real-life conditions.},
  archive      = {J_ICAE},
  author       = {Georgia Stamou and Spyridon Angelopoulos and Nikolaos Stefanakis and Evangelos Hristoforou},
  doi          = {10.1177/10692509251318454},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {3},
  pages        = {309--325},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Design and implementation of an internet of things automatic solar shading system},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Digital shielding for cross-domain wi-fi signal adaptation using relativistic average generative adversarial network. <em>ICAE</em>, <em>32</em>(3), 292--308. (<a href='https://doi.org/10.1177/10692509251339913'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wi-Fi sensing exploits radio-frequency signals emitted by Wi-Fi devices to analyze environments, enabling tasks such as people tracking, intruder detection, and gesture recognition. Its growing diffusion is driven by the IEEE 802.11bf standard, which facilitates environmental monitoring, and the increasing demand for tools capable of penetrating obstacles while preserving privacy. However, the performance of Wi-Fi-based sensing solutions is influenced by the environment in which signals are acquired. This is critical when extracting spatial and temporal information from the surrounding scene, as such data reflect both environmental structure and interference sources. A main challenge is achieving generalization across domains, that is, ensuring consistent performance under varying conditions, such as different rooms or buildings, without significant accuracy loss. This paper presents a deep model for domain adaptation of Wi-Fi signals by simulating a digital shielding mechanism. The model is based on a Relativistic average Generative Adversarial Network (RaGAN), which mimics physical shielding to suppress domain-specific features while preserving signal integrity. Both the generator and discriminator use Bidirectional Long Short-Term Memory (Bi-LSTM) architectures, enabling modeling of waveform and time-dimension signal characteristics. To support training, an acrylic box lined with electromagnetic shielding fabric, replicating a Faraday cage, was constructed. Spectra from same-sized objects made of different materials were acquired both inside (domain-free) and outside (domain-dependent) the box. A multi-class Support Vector Machine (SVM), trained on shielded spectra and tested on RaGAN-denoised data, achieved 96 percent accuracy. The SVM also distinguished materials, suggesting a promising approach for security systems aimed at identifying the nature and composition of potentially dangerous objects.},
  archive      = {J_ICAE},
  author       = {Danilo Avola and Federica Bruni and Gian Luca Foresti and Daniele Pannone and Amedeo Ranaldi},
  doi          = {10.1177/10692509251339913},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {3},
  pages        = {292--308},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Digital shielding for cross-domain wi-fi signal adaptation using relativistic average generative adversarial network},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An automated workflow based on UAV imagery and deep learning methods for monitoring excavation area work. <em>ICAE</em>, <em>32</em>(3), 272--291. (<a href='https://doi.org/10.1177/10692509251340464'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement of Artificial Intelligence (AI) is transforming the construction sector, particularly in site monitoring and safety management. Real-time monitoring enables the automatic detection of work progress issues, anomalies, and hazardous situations. However, no existing Deep Learning (DL)-based system is specifically designed to utilize Unmanned Aerial Vehicles (UAVs) for excavation area monitoring. This study presents an automated workflow that integrates UAV imagery with DL architectures, featuring a 1D Convolutional Neural Network (1D-CNN) for classifying excavation work phases and a VGG16 network for detecting safety fences. These technologies are incorporated into a Decision Support System (DSS), which automates report generation and enhances decision-making by providing structured, data-driven insights. The system was validated in a real-world case study involving an oil and gas construction company, demonstrating its ability to streamline site management tasks and improve safety oversight. Compared to traditional monitoring methods, our approach leverages UAV technology and DL methodologies to provide higher accuracy, efficiency, and scalability in excavation site monitoring. This contribution supports the digital transformation of construction management, offering a practical and innovative solution for real-time progress tracking and compliance verification.},
  archive      = {J_ICAE},
  author       = {Riccardo Rosati and Matteo Fabiani and Roberto Pierdicca and Adriano Mancini},
  doi          = {10.1177/10692509251340464},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {3},
  pages        = {272--291},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {An automated workflow based on UAV imagery and deep learning methods for monitoring excavation area work},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cost-effective autonomous underwater system for small size object detection. <em>ICAE</em>, <em>32</em>(3), 258--271. (<a href='https://doi.org/10.1177/10692509251336668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to US National Oceanic and Atmospheric Administration (NOAA), we have only explored five percent of our world ocean. Among the ocean exploration tasks, underwater object detection is a multidisciplinary challenge that extends beyond engineering into fields such as oceanography, marine biology, and environmental science. Scientifically, it involves understanding the complex interactions between sound waves, light, and water, as well as the navigation dynamics within marine environments. The underwater environment presents unique physical challenges for object detection due to factors like light attenuation, turbidity, and the variability of acoustic propagation. This paper introduces a cost-effective autonomous underwater prototype for real-time detection, and localization of small underwater objects (e.g., archaeological artifacts, parts of infrastructures, wreckage debris, but also life forms like fishes, corals etc.) in shallow waters. The system combines object identification with autonomous navigation capabilities. It consists of an autonomous underwater vehicle equipped with sensors, cameras, and localization tools, as well as a ground control station for monitoring and intervention. In particular, we focus on a case study about detecting and reporting the locations of unexploded ordnance materials, contributing to the monitoring of underwater hazards in conflict-affected regions. Key contributions include the integration of a cost-effective autonomous remotely operated vehicle with sensors and software for real-time detection and localization of small underwater objects, as well as an annotated dataset of UXO images, usable as a benchmark.},
  archive      = {J_ICAE},
  author       = {Denis Tavaris and Leonardo Scandino and Gian Luca Foresti and Ivan Scagnetto},
  doi          = {10.1177/10692509251336668},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {3},
  pages        = {258--271},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {A cost-effective autonomous underwater system for small size object detection},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Segmentation networks for detecting overlapping screws in 3D and color images for industrial quality control. <em>ICAE</em>, <em>32</em>(3), 244--257. (<a href='https://doi.org/10.1177/10692509251328780'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores cost-effective, real-time strategies for bin picking in industrial quality control. An anomaly detection solution was developed for a screw production plant, utilizing machine vision and AI to identify overlapping screws as anomalies. Two improvements are proposed to a basic solution initially relying on a laser profiler for depth images. The first improvement applies a Convolutional Neural Network (CNN) to the laser profiler's output, and the second replaces the laser profiler with a camera that captures color images, applying a CNN to its output. The first improvement was tested with real laser profiler data using YOLOv8 and Mask R-CNN segmentation models. After achieving comparable results on the real dataset, the second improvement was tested on multiple synthetic datasets, simulating different scenarios, including setups with mixed screws. Results demonstrated that model performance on color images, represented in the RGB color space (red, green, and blue), was comparable to depth images, validating color cameras as an appropriate alternative. Since color cameras are cheaper and capture images faster, they are well-suited for high-speed quality control systems, offering significant cost and performance advantages. Code is available at: https://github.com/enmarchi/overlapping_screws_geneneration_code .},
  archive      = {J_ICAE},
  author       = {Enrico Marchi and Daniele Fornasier and Alberto Miorin and Gian Luca Foresti},
  doi          = {10.1177/10692509251328780},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {3},
  pages        = {244--257},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Segmentation networks for detecting overlapping screws in 3D and color images for industrial quality control},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gravity-constrained simultaneous localization and mapping for suppressing map warping in complex large-scale environments. <em>ICAE</em>, <em>32</em>(3), 229--243. (<a href='https://doi.org/10.1177/10692509251331372'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous Localization and Mapping (SLAM) serves as a foundational technology for autonomous systems operating within large-scale, complex environments. Traditional SLAM methodologies, however, are prone to altitude-axis distortions resulting from cumulative errors. To mitigate these issues, Gravity-Constrained SLAM (GC-SLAM) is introduced as a novel computational method that integrates gravity constraints and incremental optimisation to enhance mapping accuracy and computational efficiency. GC-SLAM incorporates a gravity constraint handling actor within the global optimisation algorithm, effectively reducing vertical-axis errors caused by accumulated drift during mapping. Furthermore, an incremental optimisation strategy is employed to manage the computational complexity associated with increasing map size. Performance evaluations of GC-SLAM are conducted on the KITTI dataset and large-scale environments, comparing its effectiveness against state-of-the-art SLAM-based algorithms, including FAST-LIO2, LIO-SAM (Lidar Inertial Odometry and SLAM), Lego-LOAM (Lightweight and Ground-optimised Lidar Odometry and Mapping), and A-LOAM (Advanced Lidar Odometry and Mapping). Experimental results demonstrate that GC-SLAM effectively suppresses vertical-axis distortions, significantly enhances localisation accuracy, and outperforms competing methods.},
  archive      = {J_ICAE},
  author       = {Kaiyi Xian and Duo Liu and Gexiang Zhang and Ferrante Neri and Song Chen},
  doi          = {10.1177/10692509251331372},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {8},
  number       = {3},
  pages        = {229--243},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Gravity-constrained simultaneous localization and mapping for suppressing map warping in complex large-scale environments},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing snake robot locomotion with decomposed gait pattern representation. <em>ICAE</em>, <em>32</em>(2), 196--225. (<a href='https://doi.org/10.1177/10692509251316676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents novel Gait Decomposition (GD) and Gait Parameter Gradient (GPG) methods for enhancing snake robot control and optimization. Snake robots face challenges in parameter tuning due to their complex dynamics and the need to preserve gait characteristics during control. GD fine-tunes gait parameters while maintaining their characteristics to prevent unintended changes during the application of serpenoid curves, typical in snake robots. A key feature of GD is the use of a motion matrix to represent joint movements, ensuring the preservation of gait characteristics. This methodology classifies the robot’s gait as a motion matrix, aiding in addressing the common challenge of parameter tuning in real-world scenarios. Furthermore, we introduce the GPG algorithm, designed to efficiently optimize gait parameters by adjusting both the curve function parameters and the motion matrix. Simulations validate the effectiveness of our methods, showing that the decomposed gait closely retains the original gait’s characteristics and achieves stable optimization under various conditions. Together, GD and GPG offer significant improvements in the control, adaptability, and practical deployment of snake robots, potentially expanding their applications across various domains.},
  archive      = {J_ICAE},
  author       = {Bongsub Song and Insung Ju and Dongwon Yun},
  doi          = {10.1177/10692509251316676},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {2},
  pages        = {196--225},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Optimizing snake robot locomotion with decomposed gait pattern representation},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-based hybrid convolutional-long short-term memory network for bridge pier hysteresis and backbone curves prediction. <em>ICAE</em>, <em>32</em>(2), 176--195. (<a href='https://doi.org/10.1177_10692509241301240'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a solution to the problem of automatically predicting hysteresis and backbone curves of bridge piers under seismic loads. The proposed solution utilizes a stacked hybrid Convolutional Neural Network-bidirectional Cuda Deep Neural Network Long Short Term Memory layer benefiting from the skip connections technique and incorporates a custom task-specific attention layer to enhance its performance. The proposed framework borrows the functional API provided by the Keras library in Python to construct a model taking into account horizontal and vertical ground accelerations, actuator loads in both horizontal and vertical directions, the effective pier height, the second moment of area, and the superstructure mass as input features. The deep learning model demands a substantial amount of data for effective training, validation, and testing. An error-sensitive analysis suggests that a comprehensive dataset should consist of a minimum of 12 sets of pier data for real-time hybrid simulations and 17 sets for cyclic experiments (10 for high-speed and seven for low-speed scenarios). This extensive dataset is deemed essential for the optimal performance of the model. The same deep learning framework and optimization of hyperparameters apply when training real-time hybrid simulations and conducting cyclic tests. After 5000 epochs, the proposed hybrid loss function, combining mean square and mean absolute errors, exhibits a steady and gradual decrease toward near-zero values within the datasets used for training and validation. Additionally, over 93% correlation exists between the predicted unseen time series responses and those derived from empirical measurements. Overall, the proposed deep learning model offers significant advantages, notably in terms of time and cost savings associated with experimental endeavors for new tests. By providing a rapid and accurate understanding of the hysteretic behavior of bridge piers, this model contributes to more efficient bridge design processes. Ultimately, it facilitates precision in design decisions, leading to enhanced accuracy and effectiveness in bridge engineering.},
  archive      = {J_ICAE},
  author       = {Omid Yazdanpanah and Minwoo Chang and Ensieh Ali Bakhshi},
  doi          = {10.1177_10692509241301240},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {2},
  pages        = {176--195},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Attention-based hybrid convolutional-long short-term memory network for bridge pier hysteresis and backbone curves prediction},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new methodology for monocular depth estimation with attention mechanisms. <em>ICAE</em>, <em>32</em>(2), 158--175. (<a href='https://doi.org/10.1177/10692509241301587'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth estimation from images is fundamental for autonomous navigation of robots, vehicles, drones, and integrating navigation aid systems for people with visual impairments. Despite the challenges of obtaining depth information from complex scenes, advancements in Deep Learning have opened new possibilities. Thus, this work introduces an approach based on recent Convolutional Neural Network architectures and attention mechanisms to enhance monocular image depth estimation, with potential applications in navigation aid systems for the visually impaired. The proposal focuses on implementing a Convolutional Neural Network model with an attention mechanism configuration that has not yet been tested in the literature, primarily integrating the Convolutional Block Attention Module and the Modified Global Context Network in the encoder and decoder, respectively. Unlike stereo camera-based systems, which require complex setups and image pairs, this model simplifies data collection and processing, although it still faces the challenge of requiring large datasets and significant computational capacity. However, it is experimentally possible to demonstrate that these limitations can be overcome by using reduced-resolution images and resizing techniques. The evaluation of the proposed model indicated satisfactory performance compared to state-of-the-art works that use images with resolutions identical to those in this work, validating the comparative tests. It presented an improvement in the Absolute Relative Error of 25.22% and 6.28% in relation to the Root Mean Squared Error. The results highlight the feasibility of conducting Deep Learning research, even with limited hardware resources.},
  archive      = {J_ICAE},
  author       = {Ricardo S Casado and Emerson C Pedrino},
  doi          = {10.1177/10692509241301587},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {2},
  pages        = {158--175},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {A new methodology for monocular depth estimation with attention mechanisms},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rapid simulation method for assessing seismic damage to building curtain walls on a regional scale using designed wind load capacity. <em>ICAE</em>, <em>32</em>(2), 143--157. (<a href='https://doi.org/10.3233/ICA-240746'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a rapid simulation method for assessing seismic damage to building curtain walls at a regional scale. Although the results are approximate, this approach enables quick evaluations, making it an important instrument for emergency responses during disaster situations. This method’s independence from numerical models is a noteworthy advantage. Unlike conventional approaches, it eliminates the need for structural analysis models when evaluating the seismic capacities of curtain walls regionally. Creating reliable structural analysis models is both time-consuming and labor-intensive, primarily due to the detailed design information they require. In contrast, the presented method leverages the wind load capacities for which curtain walls are designed. It is based on the core premise that most curtain walls, primarily designed for wind resistance, possess wind load capacities that could serve as substitutes for their seismic capacities, even if they are not explicitly designed for such seismic loads. To assess the method’s effectiveness, it was applied to seismic damage assessments across regions experiencing varying wind intensities: weak, moderate, and strong. The results suggest the likelihood of curtain walls sustaining seismic damage in regions with weak wind could be five times higher than in regions with strong wind. This underscores the importance of seismic design considerations for curtain walls. Moreover, the findings closely match the actual seismic damage assessment data from a region with a moderate to strong wind intensity.},
  archive      = {J_ICAE},
  author       = {Jun Su Park and Insub Choi and JunHee Kim and Hyo Seon Park},
  doi          = {10.3233/ICA-240746},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {2},
  pages        = {143--157},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Rapid simulation method for assessing seismic damage to building curtain walls on a regional scale using designed wind load capacity},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification and explanation of disinformation in wiki data streams. <em>ICAE</em>, <em>32</em>(2), 126--142. (<a href='https://doi.org/10.1177/10692509241306580'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media platforms, increasingly used as news sources for varied data analytics, have transformed how information is generated and disseminated. However, the unverified nature of this content raises concerns about trustworthiness and accuracy, potentially negatively impacting readers’ critical judgment due to disinformation. This work aims to contribute to the automatic data quality validation field, addressing the rapid growth of online content on wiki pages. Our scalable solution includes stream-based data processing with feature engineering, feature analysis and selection, stream-based classification, and real-time explanation of prediction outcomes. The explainability dashboard is designed for the general public, who may need more specialized knowledge to interpret the model’s prediction. Experimental results on two datasets attain approximately 90% values across all evaluation metrics, demonstrating robust and competitive performance compared to works in the literature. In summary, the system assists editors by reducing their effort and time in detecting disinformation.},
  archive      = {J_ICAE},
  author       = {Francisco de Arriba-Pérez and Silvia García-Méndez and Fátima Leal and Benedita Malheiro and Juan C Burguillo},
  doi          = {10.1177/10692509241306580},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {2},
  pages        = {126--142},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Identification and explanation of disinformation in wiki data streams},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evading model poisoning attacks in federated learning by a long-short-term-memory-based approach. <em>ICAE</em>, <em>32</em>(2), 111--125. (<a href='https://doi.org/10.1177/10692509241301588'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning is designed to build a global model from a set of local learning tasks carried out by several clients. Each client trains the global model on local data and sends back only the computed model updates. Although this approach preserves data privacy, several issues arise, and model poisoning is one of the most significant issues. According to this attack, a limited number of compromised clients cooperate to cause the corruption of the global model by sending back malicious model updates. A common countermeasure to model poisoning involves discarding model updates that differ from the majority more than a suitable threshold. However, several attacks still occur that elude this countermeasure, such as LIE attack, which aims to introduce an error in the model that is less than the threshold. In this paper, we propose a new approach to detect malicious updates that is based on the use of an LSTM network suitably built and trained. The experimental validation shows that our approach is able to disarm LIE and Fang attacks, which are the most effective in this context.},
  archive      = {J_ICAE},
  author       = {Marco Arazzi and Gianluca Lax and Antonino Nocera},
  doi          = {10.1177/10692509241301588},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {2},
  pages        = {111--125},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Evading model poisoning attacks in federated learning by a long-short-term-memory-based approach},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining deep learning methods and rule-based systems for automatic parking space detection. <em>ICAE</em>, <em>32</em>(1), 97--108. (<a href='https://doi.org/10.3233/ICA-240745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an Automatic Parking Space Detection (APSD) algorithm designed to reduce traffic in cities while offering an information system of available parking zones. The main aim of such a system lies in its ability to identify parking spaces in a distributed manner, achieved by installing multiple APSD systems across a fleet of vehicles. This fleet, during its regular operations, communicates the availability of parking spaces to a centralized information system. Our methodology employs a rule-based system that seamlessly integrates a variety of neural networks for different specific tasks. These tasks include depth estimation, road segmentation, and vehicle detection. This approach would fall into a modular category instead of an end-to-end solution, using the Málaga Urban Dataset in the experiments. We present a preliminary experiment for parameter settings and an ablation study to quantify each subsystem contribution to the results. The proposed system achieves a parking space detection F1 score of 0.726.},
  archive      = {J_ICAE},
  author       = {Susana P. De Luelmo and Francisco J. Garcia-Espinosa and Antonio S. Montemayor and Juan José Pantrigo},
  doi          = {10.3233/ICA-240745},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {2},
  number       = {1},
  pages        = {97--108},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Combining deep learning methods and rule-based systems for automatic parking space detection},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A parametric and feature-based CAD dataset to support human-computer interaction for advanced 3D shape learning. <em>ICAE</em>, <em>32</em>(1), 75--96. (<a href='https://doi.org/10.3233/ICA-240744'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D shape learning is an important research topic in computer vision, in which the datasets play a critical role. However, most of the existing 3D datasets use voxels, point clouds, mesh, and B-rep, which are not parametric and feature-based. Thus they can not support the generation of real-world engineering computer-aided design (CAD) models with complicated shape features. Furthermore, they are based on 3D geometry results without human-computer interaction (HCI) history. This work is the first to provide a full parametric and feature-based CAD dataset with a selection mechanism to support HCI in 3D learning. First, unlike existing datasets, mainly composed of simple features (typical sketch and extrude), we devise complicated engineering features, such as fillet, chamfer, mirror, pocket, groove, and revolve. Second, different from the monotonous combination of features, we invent a select mechanism to mimic how human focuses on and selects a particular topological entity. The proposed mechanism establishes the relationships among complicated engineering features, which fully express the design intention and design knowledge of human CAD engineers. Therefore, it can process advanced 3D features for real-world engineering shapes. The experiments show that the proposed dataset outperforms existing CAD datasets in both reconstruction and generation tasks. In quantitative experiment, the proposed dataset demonstrates better prediction accuracy than other parametric datasets. Furthermore, CAD models generated from the proposed dataset comply with semantics of the human CAD engineers and can be edited and redesigned via mainstream industrial CAD software.},
  archive      = {J_ICAE},
  author       = {Rubin Fan and Fazhi He and Yuxin Liu and Yupeng Song and Linkun Fan and Xiaohu Yan},
  doi          = {10.3233/ICA-240744},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {2},
  number       = {1},
  pages        = {75--96},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {A parametric and feature-based CAD dataset to support human-computer interaction for advanced 3D shape learning},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A high-level simulator for network-on-chip. <em>ICAE</em>, <em>32</em>(1), 57--73. (<a href='https://doi.org/10.3233/ICA-240743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a high-level simulator for Network-on-Chip (NoC), designed for many-core architectures, and integrated with the PlatEMO platform. The motivation for developing this tool arose from the need to evaluate the behavior of application mapping algorithms and the routing, both aspects are essential in the implementation and design of NoC architectures. This analysis underscored the importance of having effective NoC simulators as tools that allow for studying and comparing various network technologies while ensuring a controlled simulation environment. During this investigation and evaluation, some simulators, such as Noxim, NoCTweak, and NoCmap, among others, offered configurable parameters for application traffic, options to synthetically define topology and packet traffic patterns. Additionally, they include mapping options that optimize latency and energy consumption, routing algorithms, technological settings such as the CMOS process, and measurement options for evaluating performance metrics such as throughput and power usage. However, while these simulators meet detailed technical demands, they are mostly restricted to analyzing the low-level elements of the architecture, thus hindering quick and easy under- standing for non-specialists. This insight underscored the challenge in developing a tool that balances detailed analysis with a comprehensive learning perspective, considering the specific restrictions of each simulator analyzed. Experiments demonstrated the proposed simulator efficacy in handling algorithms like GA, PSO, and SA variant, and, surprisingly, revealed limitations of the XY algorithm in Mesh topologies, indicating the need for further investigation to confirm these findings. Future work will expand the simulator functionalities, incorporating a broader range of algorithms and performance metrics, to establish it as an indispensable tool for research and development in NoCs.},
  archive      = {J_ICAE},
  author       = {Paulo Cesar Donizeti Paris and Emerson Carlos Pedrino},
  doi          = {10.3233/ICA-240743},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {2},
  number       = {1},
  pages        = {57--73},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {A high-level simulator for network-on-chip},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A weakly supervised active learning framework for non-intrusive load monitoring. <em>ICAE</em>, <em>32</em>(1), 39--56. (<a href='https://doi.org/10.3233/ICA-240738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy efficiency is at a critical point now with rising energy prices and decarbonisation of the residential sector to meet the global NetZero agenda. Non-Intrusive Load Monitoring is a software-based technique to monitor individual appliances inside a building from a single aggregate meter reading and recent approaches are based on supervised deep learning. Such approaches are affected by practical constraints related to labelled data collection, particularly when a pre-trained model is deployed in an unknown target environment and needs to be adapted to the new data domain. In this case, transfer learning is usually adopted and the end-user is directly involved in the labelling process. Unlike previous literature, we propose a combined weakly supervised and active learning approach to reduce the quantity of data to be labelled and the end user effort in providing the labels. We demonstrate the efficacy of our method comparing it to a transfer learning approach based on weak supervision. Our method reduces the quantity of weakly annotated data required by up to 82.6–98.5% in four target domains while improving the appliance classification performance.},
  archive      = {J_ICAE},
  author       = {Giulia Tanoni and Tamara Sobot and Emanuele Principi and Vladimir Stankovic and Lina Stankovic and Stefano Squartini},
  doi          = {10.3233/ICA-240738},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {2},
  number       = {1},
  pages        = {39--56},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {A weakly supervised active learning framework for non-intrusive load monitoring},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label classification with imbalanced classes by fuzzy deep neural networks. <em>ICAE</em>, <em>32</em>(1), 25--38. (<a href='https://doi.org/10.3233/ICA-240736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification is an advantageous technique for managing uncertainty in classification problems where each data instance is associated with several labels simultaneously. Such situations are frequent in real-world scenarios, where decisions rely on imprecise or noisy data and adaptable classification methods are preferred. However, the problem of class imbalance represents a common characteristic of several multi-label datasets, in which the distribution of samples and their corresponding labels is non-uniform across the data space. In this paper, we propose a multi-label classification approach utilizing fuzzy logic in order to deal with the class imbalance problem. To eliminate the need for an expert to determine the logical rules of inference, deep neural networks are adopted, which have proven to be exceptionally effective for such problems. By combining both fuzzy inference systems and deep neural networks, the strengths and weaknesses of each approach can be mitigated. As a further development, a symbolic representation of time series is put in place to reduce data dimensionality and speed up the training procedure. This allows for more flexibility in model application, in particular with respect to time constraints arising from the causality of observed time series. Tests carried out on a multi-label classification dataset related to the current and voltage profiles of several household appliances show that the proposed model outperforms four baseline models for time series classification.},
  archive      = {J_ICAE},
  author       = {Federico Succetti and Antonello Rosato and Massimo Panella},
  doi          = {10.3233/ICA-240736},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {2},
  number       = {1},
  pages        = {25--38},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Multi-label classification with imbalanced classes by fuzzy deep neural networks},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient surface defect detection in industrial screen printing with minimized labeling effort. <em>ICAE</em>, <em>32</em>(1), 3--23. (<a href='https://doi.org/10.3233/ICA-240742'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As part of the evolving Industry 4.0 landscape, machine learning-based visual inspection plays a key role in enhancing production efficiency. Screen printing, a versatile and cost-effective manufacturing technique, is widely applied in industries like electronics, textiles, and automotive. However, the production of complex multilayered designs is error-prone, resulting in a variety of defect appearances and classes. These defects can be characterized as small in relation to large sample areas and weakly pronounced. Sufficient defect visualization and robust defect detection methods are essential to address these challenges, especially considering the permitted design variability. In this work, we present a novel automatic visual inspection system for surface defect detection on decorated foil plates. Customized optical modalities, integrated into a sequential inspection procedure, enable defect visualization of production-related defect classes. The introduced patch-wise defect detection methods, designed to leverage less labeled data, prove effective for industrial defect detection, meeting the given process requirements. In this context, we propose an industry-applicable and scalable data preprocessing workflow that minimizes the overall labeling effort while maintaining high detection performance, as known in supervised settings. Moreover, the presented methods, not relying on any labeled defective training data, outperformed a state-of-the-art unsupervised anomaly detection method in terms of defect detection performance and inference speed.},
  archive      = {J_ICAE},
  author       = {Paul Josef Krassnig and Matthias Haselmann and Michael Kremnitzer and Dieter Paul Gruber},
  doi          = {10.3233/ICA-240742},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {2},
  number       = {1},
  pages        = {3--23},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Efficient surface defect detection in industrial screen printing with minimized labeling effort},
  volume       = {32},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
