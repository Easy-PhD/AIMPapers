<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NN</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="nn">NN - 238</h2>
<ul>
<li><details>
<summary>
(2026). Corrigendum to “Multi-view spectral clustering algorithm based on bipartite graph and multi-feature similarity fusion” [Neural networks, 194 (2026), 108177]. <em>NN</em>, <em>195</em>, 108236. (<a href='https://doi.org/10.1016/j.neunet.2025.108236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  author       = {Shunyong Li and Kun Liu and Mengjiao Zheng and Liang Bai},
  doi          = {10.1016/j.neunet.2025.108236},
  journal      = {Neural Networks},
  month        = {3},
  pages        = {108236},
  shortjournal = {Neural Netw.},
  title        = {Corrigendum to “Multi-view spectral clustering algorithm based on bipartite graph and multi-feature similarity fusion” [Neural networks, 194 (2026), 108177]},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive frequency collaboration for remote sensing change detection. <em>NN</em>, <em>195</em>, 108234. (<a href='https://doi.org/10.1016/j.neunet.2025.108234'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods have recently begun exploiting frequency information to improve remote sensing change detection. However, they typically aggregate high- and low-frequency components for detection without explicitly distinguishing their respective roles, leading to a decline in performance. In particular, high-frequency components capture fine spatial details associated with object heterogeneity, potentially introducing spurious differences and interfering with accurate change detection. In contrast, low-frequency components maintain stable energy distributions and better preserve the global structure of land cover objects, thus benefiting the localization of actual changed objects. To overcome this issue, we propose an adaptive frequency collaboration network (AFCN) to construct change features from a frequency-domain perspective. To achieve frequency disentanglement, we design a position-specific low-pass filter that adaptively extracts the low-frequency component from the spatial feature. Inspired by the wavelet reconstruction principle, the high-frequency counterpart is obtained by subtracting the low-frequency part from the spatial feature. The low-frequency part is used to generate change features for locating changed objects. Meanwhile, the high-frequency part is employed to extract edge features that enhance spatial details through an auxiliary edge detection task. This auxiliary task contributes to more accurate and detail-preserving change detection. We evaluate AFCN on three benchmark datasets, including LEVIR-CD, PX-CLCD, and WHU-CD. Experimental results demonstrate that AFCN achieves state-of-the-art performance, with an intersection over union (IoU) of 85.30 %, 94.13 %, and 90.03 % on the three datasets, respectively.},
  archive      = {J_NN},
  author       = {Feng Zhou and Xinyu Zhang and Hui Shuai and Qingshan Liu and Renlong Hang},
  doi          = {10.1016/j.neunet.2025.108234},
  journal      = {Neural Networks},
  month        = {3},
  pages        = {108234},
  shortjournal = {Neural Netw.},
  title        = {Adaptive frequency collaboration for remote sensing change detection},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive decoupling learning system informed by the brain functional structure for EEG decoding. <em>NN</em>, <em>195</em>, 108228. (<a href='https://doi.org/10.1016/j.neunet.2025.108228'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuroscientific investigations have revealed the presence of regional pathway connections among functional brain areas, as well as the asymmetrical structural characteristics of the left and right hemispheres. These connections, along with their potential coupling relationships and strengths, significantly influence the representation of neuronal signals as recorded by electroencephalography (EEG) within the cerebral cortex. Therefore, there is an urgent necessity to develop data-driven approaches that can effectively decode latent feature representations from EEG data. In this regard, the current study presents a functional-structural adaptive decoupling learning framework (FS-AD), which is informed by cognitive insights into the functional structure of the brain and integrates local-global spatial representations to decode EEG patterns across various states. To accomplish this, we initially implemented a one-dimensional separable convolution module and designed a local-domain attention interaction layer to extract inter-channel interaction information for each region, thereby enabling the capture of fully connected regional pathways. Following this, we developed a global-local kernel-level fusion decoder (GKFD) to amalgamate multiple local-domain features and decode them through a global-domain connection layer. Furthermore, a cross-domain adaptive fusion decoder (CAFD) was meticulously crafted to dynamically identify the fully connected optimal cross-domain pathway and decode it via a local-domain connection layer. The primary aim of FS-AD is to excavate the connectivity patterns of different brain states to enhance the efficiency of EEG decoding. The results indicate that the proposed FS-AD learning system significantly surpasses existing competitive methods in EEG decoding tasks related to various brain states, including fatigue, emotion, and motor imagery. Importantly, this study elucidates the variations in coupling strength among brain regional pathway connections and their representation of brain activity, while also investigating the optimal regional pathways under distinct brain states. This study contributes to the advancement of universal brain decoding methodologies.},
  archive      = {J_NN},
  author       = {Pengrui Li and Maoqin Peng and Haokai Zhang and Shihong Liu and Dongrui Gao and Yun Qin and Dingming Wu and Tiejun Liu},
  doi          = {10.1016/j.neunet.2025.108228},
  journal      = {Neural Networks},
  month        = {3},
  pages        = {108228},
  shortjournal = {Neural Netw.},
  title        = {An adaptive decoupling learning system informed by the brain functional structure for EEG decoding},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-focus memory contrastive learning for active domain adaptation. <em>NN</em>, <em>195</em>, 108224. (<a href='https://doi.org/10.1016/j.neunet.2025.108224'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active Domain Adaptation (ADA) aims to significantly enhance model adaptation performance by labeling a small portion of target domain samples. While recent studies have focused exten sively on selecting target domain samples through active sampling strategies, the effective utilization of these selected samples remains underexplored. Most methods concentrate on identifying the most valuable target samples but fail to establish persistent mechanisms to propagate their knowledge throughout the adaptation process and hindering the ability of model to capture the intrinsic structure of the target domain, leading to the underutilization of valuable samples. Our study introduces a novel approach, Dual-Focus Memory Contrastive Learning for Active Domain Adaptation (DumDA), which aims to optimize the use of selected samples. DumDA achieves a more profound utilization of target domain samples by innovatively orchestrating memory-encoded historical features with real-time batch contrast through dual-focus alignment, which enhances the learning and alignment of sample selection. Additionally, DumDA incorporates a hybrid active selection strategy to select reconstructed samples in a class-balanced manner. Experimental results on multiple standard datasets demonstrate that DumDA significantly improves performance in domain adaptation tasks, showcasing its effectiveness and innovation.},
  archive      = {J_NN},
  author       = {Qing Tian and Junjie Pan and Yun Yang and Weihua Ou},
  doi          = {10.1016/j.neunet.2025.108224},
  journal      = {Neural Networks},
  month        = {3},
  pages        = {108224},
  shortjournal = {Neural Netw.},
  title        = {Dual-focus memory contrastive learning for active domain adaptation},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Privacy-preserving personalized federated prompt learning for vision-language models. <em>NN</em>, <em>195</em>, 108220. (<a href='https://doi.org/10.1016/j.neunet.2025.108220'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual-language models (VLMs) have shown great potential in capturing multimodal information. However, applying prompt learning to VLMs in a federated setting poses two major challenges. Firstly, the non-IID distribution of client data may significantly degrade model performance. Secondly, the transmission of prompts in plaintext may expose sensitive information of users. To address these issues, we propose Privacy-Preserving Personalized Federated Prompt Learning (PPFPL) for VLMs, which introduces a multi-metric personalization weighting algorithm to enhance prompt aggregation, enabling each client to better extract multimodal features while preserving strong generalization. Additionally, it ensures privacy protection against semi-honest servers by distributing sensitive information across two non-colluding entities, and neither of the servers can individually reconstruct the private data. Experimental results show that, under conditions of high heterogeneity, PPFPL improves local task accuracy by up to 9.12 % and achieves an average generalization performance gain of 4.32 % on unseen tasks, compared with standard prompt learning methods.},
  archive      = {J_NN},
  author       = {Yinan Wu and Yanli Ren and Zheng Guo and Mu Huang},
  doi          = {10.1016/j.neunet.2025.108220},
  journal      = {Neural Networks},
  month        = {3},
  pages        = {108220},
  shortjournal = {Neural Netw.},
  title        = {Privacy-preserving personalized federated prompt learning for vision-language models},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GA-ConvE: An APT attack prediction method based on combination of graph attention network and 2D convolution. <em>NN</em>, <em>195</em>, 108216. (<a href='https://doi.org/10.1016/j.neunet.2025.108216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {APT (Advanced Persistent Threat) attacks have become a significant challenge in the field of cybersecurity. Timely and accurate identification and prediction of APT attacks are crucial tasks. This paper proposes a new APT attack prediction method-GA-ConvE. By collecting APT threat intelligence and constructing an attack behavior knowledge graph, we classify and infer similar APT behaviors from a knowledge-based perspective, enabling effective prediction of APT attacks. To solve the problem in the classification module where some attack features are lost as the layers of the graph neural network increase, we propose a residual multi-layer graph attention network (RMultiGAT). Through this network leverages residual blocks, organizing and analyzing the data of multi-layer graph attention networks, we classify APT behaviors into different categories based on behavioral similarities. To tackle the challenges of large inference space, low prediction accuracy, and weak interpretability in the inference module, we introduce a joint prediction model combining graph attention networks and two-dimensional convolution (GA-ConvE). This model extracts behavioral features within each APT class and conducts targeted inferences for behaviors in each class, generating more precise embeddings, improving inference performance, thus realizing more accurate and interpretable predictions of APT attacks. Through Lots of experiments in real-world situations, the effectiveness of the GA-ConvE method in predicting APT attacks are validated. These research findings contribute to enhancing the real-time response capabilities against APT attacks.},
  archive      = {J_NN},
  author       = {Yazhou Du and Weiwu Ren and Wenjuan Li and Minyue Wang and Wanxiang Wang and Hewen Zhang and Mingqi Xia},
  doi          = {10.1016/j.neunet.2025.108216},
  journal      = {Neural Networks},
  month        = {3},
  pages        = {108216},
  shortjournal = {Neural Netw.},
  title        = {GA-ConvE: An APT attack prediction method based on combination of graph attention network and 2D convolution},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-view discrepancy-driven dynamic weighting for missing view completion in incomplete multi-view clustering. <em>NN</em>, <em>195</em>, 108211. (<a href='https://doi.org/10.1016/j.neunet.2025.108211'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete Multi-view Clustering (IMVC) aims to uncover the underlying shared clustering structure across different views in the presence of missing information from the views. While numerous view recovery strategies have been proposed to tackle this prominent and challenging problem, most overlook the noise introduced during data recovery, which inevitably degrades clustering performance. To mitigate this issue, we propose a novel dynamically weighted view completion method that leverages cross-view discrepancy information to enhance both view recovery quality and clustering performance. Specifically, we employ cross-view contrastive learning to learn cross-view consistency, which indirectly measures cross-view discrepancies. Since the noise introduced during view recovery is a primary source of cross-view discrepancies in the imputed data, we utilize the learned consistency features to construct a weight matrix that evaluates the quality of the recovered data. To further suppress external noise, both the imputed data and the weight matrix are fed back into the view completion process, refining the recovered views through an instance-level weighted view recovery loss. Additionally, by iteratively optimizing missing view completion and discrepancy learning, our dynamic weighting strategy progressively reduces noise and enhances clustering performance. Extensive experiments on multiple incomplete benchmark datasets demonstrate that our method outperforms state-of-the-art approaches in both missing view completion and clustering performance. The code is available at the following repository: https://anonymous.4open.science/r/DWMVC-2E5C .},
  archive      = {J_NN},
  author       = {Hang Gao and Zuosong Cai and Tao Liang and Cheng Liu and Ying Li and You Zhou and Wei Du},
  doi          = {10.1016/j.neunet.2025.108211},
  journal      = {Neural Networks},
  month        = {3},
  pages        = {108211},
  shortjournal = {Neural Netw.},
  title        = {Cross-view discrepancy-driven dynamic weighting for missing view completion in incomplete multi-view clustering},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Randomized deep hopfield network with multiple output layers for volatility time series forecasting. <em>NN</em>, <em>195</em>, 108207. (<a href='https://doi.org/10.1016/j.neunet.2025.108207'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Volatility forecasting plays a critical role in risk management and financial decision-making by facilitating the prediction of market fluctuations. However, the inherent complexity and irregular variations in volatility time series data present significant challenges for accurate modeling. This study proposes a novel ensemble deep randomized Hopfield network (edRHN) for volatility forecasting. The proposed network incorporates multiple stacked hidden layers with randomly generated parameters within a predefined range, which remains fixed while the output weights are determined using a closed-form solution. Each hidden layer representation contributes to training an output layer, and the aggregation of these output layers forms the final output. Technical indicators are used to identify market trends to allow more informed decision-making. The neuron pruning strategy and feature analysis are further used to eliminate noisy information and less relevant features from randomly generated features, optimizing network efficiency and performance. A comprehensive comparative study was conducted against various state-of-the-art models across ten diverse volatility time-series datasets. The experimental results highlight the superior predictive performance of the proposed model, as demonstrated by three error metrics and statistical tests.},
  archive      = {J_NN},
  author       = {Aryan Bhambu and Selvaraju Natarajan and Ponnuthurai Nagaratnam Suganthan},
  doi          = {10.1016/j.neunet.2025.108207},
  journal      = {Neural Networks},
  month        = {3},
  pages        = {108207},
  shortjournal = {Neural Netw.},
  title        = {Randomized deep hopfield network with multiple output layers for volatility time series forecasting},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stochastic style perturbation modelling for visible-infrared person re-identification with severely modality imbalance. <em>NN</em>, <em>195</em>, 108206. (<a href='https://doi.org/10.1016/j.neunet.2025.108206'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the challenge of data imbalance in visible-infrared person re-identification (VI-ReID). Previous studies often presuppose a uniform distribution of training data across various modalities, however, due to constraints such as device limitations, privacy concerns, and operational conditions, gathering nightime infrared modality data can be prohibitively expensive or even impossible. Consequently, the limited infrared (IR) modality data tend to be overshadowed by the more plentiful visible (RGB) modality data during the training, particularly in scenarios marked by significant imbalance. To counter this issue, we introduce the Co-Modality Balance Learning (CMBL) framework, designed to recalibrate the balance in cross-modality learning and enhance the extraction of discriminative features. Initially, we design a Stochastic Style Perturbation (SSP) module that dynamically generates IR modality samples within the deep feature space to emulate the characteristics of a balanced dataset. Subsequently, we develop a cross-distribution alignment loss, which enables a refined optimization of sparse modality features to improve their accuracy and robustness. Additionally, we propose the novel Class-Aware Contrast Similarity Learning (CACS) strategy, which capitalizes on latent feature consistency to boost intra-class compactness and inter-class separation. Our extensive empirical evaluations and ablation studies on two publicly available cross-modality datasets under imbalanced conditions underscore the efficacy of our approach, showcasing its ability to adeptly navigate the complexities of data imbalance in VI-ReID.},
  archive      = {J_NN},
  author       = {Haojie Liu and Zhiyong Li and Jianyang Gu and Mingyu Wang and Q. M Jonathan Wu and Wei Jiang},
  doi          = {10.1016/j.neunet.2025.108206},
  journal      = {Neural Networks},
  month        = {3},
  pages        = {108206},
  shortjournal = {Neural Netw.},
  title        = {Stochastic style perturbation modelling for visible-infrared person re-identification with severely modality imbalance},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Remote sensing object detection through hierarchical feature mining and multivariate head collaboration with knowledge distillation. <em>NN</em>, <em>195</em>, 108205. (<a href='https://doi.org/10.1016/j.neunet.2025.108205'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) is a proven technique for enhancing the performance of lightweight models in intelligent edge applications for remote sensing. However, existing KD approaches often fall short in fully leveraging the statistical information embedded within feature maps and tend to neglect the potential benefits of coupling multiple teacher–student detection heads. To overcome these limitations, this paper introduces a novel KD framework—Hierarchical Feature Mining and Multivariate Head Collaboration (HMKD)—designed to enhance lightweight model performance through effective information extraction and structural collaboration. The proposed method includes two key modules: Low-Level Feature Distillation for Distributed Information Mining (LFDIM) and High-Level Feature Distillation for Extraction of Channel Semantic Knowledge (HFECS). These modules target distinct feature layers to extract meaningful statistical information, effectively narrowing the information transfer gap between teacher and student models. Additionally, the Collaboration Distillation of Multivariate Head (CDMH) module is introduced to facilitate comprehensive interaction among multiple teacher–student detection heads. This module enables the concurrent transfer of both classification and regression knowledge, thereby addressing target conflicts and capturing latent relationships within region-based features. Extensive experiments on two publicly available remote sensing datasets, DOTA and DIOR, demonstrate that HMKD significantly improves detection performance across both single-stage and two-stage lightweight models. These results validate the method’s effectiveness and adaptability across diverse remote sensing scenarios.},
  archive      = {J_NN},
  author       = {Yantong Chen and Zhi Gao and Jingyu Yan and Yifan Liu},
  doi          = {10.1016/j.neunet.2025.108205},
  journal      = {Neural Networks},
  month        = {3},
  pages        = {108205},
  shortjournal = {Neural Netw.},
  title        = {Remote sensing object detection through hierarchical feature mining and multivariate head collaboration with knowledge distillation},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatiotemporal patterns in FitzHugh–Nagumo network and its application in image encryption. <em>NN</em>, <em>195</em>, 108204. (<a href='https://doi.org/10.1016/j.neunet.2025.108204'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The investigation on neuronal dynamics advances the understanding of remarkable characters of the brain. In this paper, we investigate the dynamics of the FitzHugh–Nagumo system from single neuron to neuronal network. The neuron exhibits the bursting, spiking and chaotic firing patterns, and the energy function is applied to analyze these patterns. The bursting firing mode has a higher energy oscillation than the chaotic firing pattern. In addition, the coupled FHN system is constructed by the electrical synaptic connection.The phase lock is obtained in the coupled system, and it plays an essential role in biological rhythms. In the grid-like FHN network, the energy diversity induces the target wave, and the spatiotemporal pattern appears with the transition between resting and exciting states. The complex spatial patterns show their valuable applications in the image encryption. Therefore, an encryption scheme is proposed based on the FHN network, and different tests indicate the encryption strategy has good secure performance. The strategy has a larger key space, and it saves more time due to its network structure. In addition, the scheme is implemented on the FPGA platform, and it further indicates the feasibility and parallelization of the proposed scheme. It sheds light on the image processing basing on the neuronal network.},
  archive      = {J_NN},
  author       = {Zhao Yao and Kehui Sun and Huihai Wang},
  doi          = {10.1016/j.neunet.2025.108204},
  journal      = {Neural Networks},
  month        = {3},
  pages        = {108204},
  shortjournal = {Neural Netw.},
  title        = {Spatiotemporal patterns in FitzHugh–Nagumo network and its application in image encryption},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). VLExpan: A visual-enhanced LLM framework with inductive and deductive policies for entity set expansion. <em>NN</em>, <em>195</em>, 108203. (<a href='https://doi.org/10.1016/j.neunet.2025.108203'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity Set Expansion (ESE) is a promising knowledge-acquisition task that aims to retrieve the entities sharing the same semantic class with a small seed entity set. Most existing methods employ a bootstrap framework to iteratively expand the seed entities based on a given corpus. However, these methods mainly focus on the textual information, which limits the model’s ability to perform fine-grained ESE and recall long-tail positive entities. In addition, the bootstrap framework suffers from the issue of error propagation. Hence, in this paper, we propose a Visual-enhanced LLM framework with inductive and deductive policies (VLExpan). Firstly, we introduce the visual information and iteratively expand the seed entities with a vision-language model. Secondly, we utilize the LLM to induce the class name of seed entities. Finally, we employ a deductive policy to refine the previous expansion with the class name and LLM. To evaluate the effectiveness of VLExpan, we conduct extensive experiments on a public dataset SE2 and our constructed dataset NERD-Img. Our method improves the average score of MAP@10, MAP@20 and MAP@50 by 3.36 % and 4.51 % respectively. The dataset and source code of this paper are available at https://github.com/Delicate2000/VLExpan .},
  archive      = {J_NN},
  author       = {Yinan Wu and Qianyi Dong and Jingping Liu and Tong Ruan},
  doi          = {10.1016/j.neunet.2025.108203},
  journal      = {Neural Networks},
  month        = {3},
  pages        = {108203},
  shortjournal = {Neural Netw.},
  title        = {VLExpan: A visual-enhanced LLM framework with inductive and deductive policies for entity set expansion},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FAST: Foreground-aware active self-training for domain adaptive object detection. <em>NN</em>, <em>195</em>, 108201. (<a href='https://doi.org/10.1016/j.neunet.2025.108201'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptive object detection (DAOD) aims to enable object detectors to perform well on an unlabeled target domain that differs from the source domain used for training. Among various approaches, mean-teacher self-training has emerged as a promising framework in DAOD. However, the noisy pseudo-labels generated by the teacher model constrain its potential for further performance improvements, making it challenging to achieve fully supervised performance. While annotating all target samples is prohibitively expensive, labeling a small subset is often acceptable. Active domain adaptation (ADA) therefore serves as promising way to alleviate this issue by selectively annotating the most informative target samples to maximize performance gains with minimal annotation cost. However, its application to DAOD remains underexplored. This paper proposes Foreground-aware Active Self-Training (FAST), establishing an effective framework for active DAOD. Specifically, FAST introduces two innovative sampling strategies: foreground diversity clustering sampling (FDCS) to maximize the diversity of selected foreground objects, and teacher-student discrepancy uncertainty sampling (TDUN) to identify samples with high prediction uncertainty. These strategies are implemented within a decoupled active learning paradigm that employs a dedicated sampling model to identify the most informative target samples. By incorporating the selected samples into the mean-teacher framework, FAST significantly improves detection performance on the target domain. Extensive experiments demonstrate that our method achieves superior performance across multiple DAOD datasets, showcasing its effectiveness in bridging the domain gap in challenging scenarios.},
  archive      = {J_NN},
  author       = {Dan Zhang and Hongmin Deng and Hailin Wang and Zhekai Du and Guisong Liu and Jingjing Li and Mao Ye},
  doi          = {10.1016/j.neunet.2025.108201},
  journal      = {Neural Networks},
  month        = {3},
  pages        = {108201},
  shortjournal = {Neural Netw.},
  title        = {FAST: Foreground-aware active self-training for domain adaptive object detection},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Explicit semantic guided bi-incomplete multi-modal hashing with label co-occurrence and label graph constraints. <em>NN</em>, <em>195</em>, 108198. (<a href='https://doi.org/10.1016/j.neunet.2025.108198'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal hashing offers advantages in large-scale multimedia retrieval by integrating multi-modal features and generating compact binary codes for efficient computation. However, existing methods often assume complete modalities and labels, overlooking scenarios with incomplete features and labels, especially under high missing rates. To address this challenge, we propose LaDiff-BIMH , an explicit semantic-guided bi-incomplete multi-modal hashing framework with label co-occurrence and label graph constraints. Unlike prior supervised, unsupervised, or semi-supervised methods, LaDiff-BIMH specifically learns hash codes for multi-modal data with bi-incompleteness in multi-modal features and labels within a unified framework. LaDiff-BIMH consists of three stages: 1) Label Graph Constrained Autoencoder based Modal Reconstruction exploits the similarity and co-occurrence of available labels, guiding feature reconstruction, enhancing semantic consistency of latent features, and improving computational efficiency. This process also guides pseudo label generation and completes missing category information. 2) Conditional DDPM based Incomplete Modal Completion combines pseudo labels and complete modal features to achieve high-quality completion of incomplete modal features, enhancing the intrinsic connections between heterogeneous modalities. and 3) Explicit Semantic guided Multi-modal Hash Learning generates a fused representation through adaptive weighted multi-modal fusion, designing a discriminative hash center and semantic supervision mechanism to enhance the semantic consistency and discriminability of the fused hash code. Experiments demonstrate the superiority of LaDiff-BIMH over state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Haoran Zhu and Xu Lu and Liang Zhang and Li Liu and Huaxiang Zhang},
  doi          = {10.1016/j.neunet.2025.108198},
  journal      = {Neural Networks},
  month        = {3},
  pages        = {108198},
  shortjournal = {Neural Netw.},
  title        = {Explicit semantic guided bi-incomplete multi-modal hashing with label co-occurrence and label graph constraints},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Newton–Puiseux analysis for interpretability and calibration of complex-valued neural networks. <em>NN</em>, <em>195</em>, 108172. (<a href='https://doi.org/10.1016/j.neunet.2025.108172'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex-valued neural networks (CVNNs) are particularly suitable for handling phase-sensitive signals, including electrocardiography (ECG), radar/sonar, and wireless in-phase/quadrature (I/Q) streams. Nevertheless, their interpretability and probability calibration remain insufficiently investigated. In this work, we present a Newton–Puiseux framework that examines the local decision geometry of a trained CVNN by (i) fitting a small, kink-aware polynomial surrogate to the logit difference in the vicinity of uncertain inputs, and (ii) factorizing this surrogate using Newton–Puiseux expansions to derive analytic branch descriptors, including exponents, multiplicities, and orientations. These descriptors provide phase-aligned directions that induce class flips in the original network and allow for a straightforward, multiplicity-guided temperature adjustment for improved calibration. We outline assumptions and diagnostic measures under which the surrogate proves informative and characterize potential failure modes arising from piecewise-holomorphic activations (e.g., modReLU). Our phase-aware analysis identifies sensitive directions and enhances Expected Calibration Error in two case studies beyond a controlled C 2 synthetic benchmark—namely, the MIT–BIH arrhythmia (ECG) dataset and RadioML 2016.10a (wireless modulation)—when compared to uncalibrated softmax and standard post-hoc baselines. We also present confidence intervals, non-parametric tests, and quantify sensitivity to inaccuracies in estimating branch multiplicity. Crucially, this method requires no modifications to the architecture and applies to any CVNN with complex logits transformed to real moduli.},
  archive      = {J_NN},
  author       = {Piotr Migus},
  doi          = {10.1016/j.neunet.2025.108172},
  journal      = {Neural Networks},
  month        = {3},
  pages        = {108172},
  shortjournal = {Neural Netw.},
  title        = {Newton–Puiseux analysis for interpretability and calibration of complex-valued neural networks},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UVENet: A novel end-to-end model for temporal consistency in underwater video enhancement. <em>NN</em>, <em>195</em>, 108170. (<a href='https://doi.org/10.1016/j.neunet.2025.108170'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep-sea submersibles collect extensive underwater data, supporting the study and exploration of marine ecosystems. Efficient processing and analysis of underwater images and videos are crucial for applications like ecological monitoring, resource assessment, and environmental conservation. These underwater visual tasks face significant challenges due to the effects of wavelength-dependent absorption and scattering, which lead to issues like color casts, blurred details, and low contrast. Despite significant advancements in underwater image enhancement (UIE), underwater video enhancement (UVE) remains underdeveloped. Traditional UVE methods that extend UIE techniques by independently enhancing each frame fail to address temporal consistency, leading to artifacts such as flickering. Constructing high-quality paired datasets for UVE is also a significant challenge, as obtaining both real underwater videos and corresponding ground truth videos is often impractical due to environmental limitations. To address these challenges, we introduce UVENet, a novel end-to-end UVE model that leverages multi-frame inputs and incorporates Feature Alignment and Aggregation Modules (FAAMs) to ensure effective spatial alignment and feature aggregation, thereby preserving temporal consistency. To support the training and evaluation of UVENet, we construct the first synthetic underwater video enhancement dataset (SUVE), which consists of 840 pairs of videos generated using underwater neural rendering (UWNR) technology. Extensive experiments on both synthetic and real underwater videos validate the effectiveness of our approach. Our code is available at https://github.com/ddz16/UVENet .},
  archive      = {J_NN},
  author       = {Huijie Guo and Dazhao Du and Hongwei Dong and Shouyou Huang and Changwen Zheng and Lingyu Si},
  doi          = {10.1016/j.neunet.2025.108170},
  journal      = {Neural Networks},
  month        = {3},
  pages        = {108170},
  shortjournal = {Neural Netw.},
  title        = {UVENet: A novel end-to-end model for temporal consistency in underwater video enhancement},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LMcast: A pretrained language model guided long-term memory transformer for precipitation nowcasting. <em>NN</em>, <em>195</em>, 108168. (<a href='https://doi.org/10.1016/j.neunet.2025.108168'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models are effective in precipitation nowcasting. However, rainfall systems, as chaotic evolving systems, entail significant uncertainty. Previous studies have addressed precipitation nowcasting tasks by utilizing current image information from the perspective of overall motion trends or local rainfall details. As lead time increases, effective information decreases, making it challenging for existing methods to capture the long-term trends in rainfall systems. Recent studies have revealed that large language models demonstrate excellent retrieval and generation capabilities. Therefore, by leveraging the strengths of large language models and using similar historical rainfall processes as prior knowledge, the issue of insufficient effective information can be skillfully resolved. In this paper, we propose LMcast, a precipitation nowcasting model that utilizes a long-term memory recall approach guided by pre-trained language models. LMcast leverages the pre-existing linguistic knowledge of language models to recall historical future rainfall information from a codebook storing historical rainfall data. Moreover, we design a special fusion architecture to help LMcast combine recalled historical long-term memory with current input-generated short-term memory to produce the final prediction. Extensive experimental results on four publicly available radar datasets demonstrate the effectiveness and superiority of our proposed model compared to state-of-the-art techniques.},
  archive      = {J_NN},
  author       = {Feifan Gao and Chuyao Luo and Guangbo Deng and Xutao Li and Baoquan Zhang and Demin Yu and Yunming Ye},
  doi          = {10.1016/j.neunet.2025.108168},
  journal      = {Neural Networks},
  month        = {3},
  pages        = {108168},
  shortjournal = {Neural Netw.},
  title        = {LMcast: A pretrained language model guided long-term memory transformer for precipitation nowcasting},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved latent diffusion-based IC-DGAN framework for high-resolution multi-feature and expression manipulation. <em>NN</em>, <em>194</em>, 108199. (<a href='https://doi.org/10.1016/j.neunet.2025.108199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression and multi-feature manipulation play a vital role in applications such as media entertainment and biometric forensics. However, existing approaches face significant challenges, including semantic inconsistency, sensitivity to pose and illumination variations, and high computational demands. To address these challenges, this study proposes an improved latent diffusion-based deep generative adversarial network (IC-DGAN) framework that integrates multiple generators and discriminators, K-means clustering, and constructive pre-training to achieve precise semantic multi-feature and facial expression manipulation. The framework leverages scale-invariant feature transform (SIFT) and latent diffusion models to autonomously disentangle and manipulate facial attributes, enabling synchronized decomposition across multiple levels and generating high-resolution, realistic portraits. By mapping facial portraits back to the latent space, IC-DGAN enables robust attribute editing—including age, gender, and expression—while minimizing visual distortions. Comprehensive evaluations on benchmark datasets, including CelebA-HQ, CAS-PEAL, and RafD, demonstrate that IC-DGAN outperforms state-of-the-art methods, reducing unintended portrait variations by 12.3 %, enhancing manipulation accuracy by 8.7 %, and achieving a Fréchet Inception Distance (FID) of 25.94—significantly surpassing existing benchmarks. These results underscore the framework’s potential for advancing high-fidelity facial editing, offering a robust solution to longstanding challenges.},
  archive      = {J_NN},
  author       = {Fakhar Abbas and Araz Taeihagh},
  doi          = {10.1016/j.neunet.2025.108199},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108199},
  shortjournal = {Neural Netw.},
  title        = {Improved latent diffusion-based IC-DGAN framework for high-resolution multi-feature and expression manipulation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Autonomous collision-avoiding for multi-UAVs in complex dynamic environments: An event-triggered PPO approach with LSTM-attention integration. <em>NN</em>, <em>194</em>, 108196. (<a href='https://doi.org/10.1016/j.neunet.2025.108196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The challenge of flocking collision avoidance lies in selecting the optimal strategy that balances decision-making intelligence and resource saving in a complex dynamic environment. Meanwhile, the design of the collision avoidance reward function for deep reinforcement learning (DRL) in this scenario may lack a quantitative basis. To overcome this challenge, this paper proposes an e vent- t riggered p roximal p olicy o ptimization (ETPPO) avoidance strategy by combining rewards from a dynamic model under ideal environments and DRL rewards. Firstly, this strategy incorporates the intermittent communication costs of event-triggered mechanisms (ETM) to achieve a balance between avoidance performance and communication resources. Secondly, a composite avoidance reward mechanism is designed, which combines the cost function based on dynamic model and obstacle avoidance reward based on DRL. The quality and rationality of reward function design in complex environments are improved. Then, to make full use of historical information and focus on task-related key status information, an LSTM-Attention (LA) fusion module combining long short-term memory (LSTM) and attention mechanisms is introduced, and the ETPPO-LA algorithm is constructed. The stability of the network and training efficiency of the algorithm are improved. Finally, the proposed algorithm is verified based on the Ros-Stage simulation platform, which shows the advantages in terms of accumulated rewards and avoidance success rate.},
  archive      = {J_NN},
  author       = {Chengqing Liang and Lei Liu and Jinde Cao and Xiaodi Li},
  doi          = {10.1016/j.neunet.2025.108196},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108196},
  shortjournal = {Neural Netw.},
  title        = {Autonomous collision-avoiding for multi-UAVs in complex dynamic environments: An event-triggered PPO approach with LSTM-attention integration},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interpretable facial landmark detection by multi-expert collaborative uncertainty-aware deep networks. <em>NN</em>, <em>194</em>, 108195. (<a href='https://doi.org/10.1016/j.neunet.2025.108195'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, heatmap regression-based methods have become a dominant approach in facial landmark detection (FLD), demonstrating impressive performance. However, these methods generally predict landmark coordinates by optimizing heatmaps based on a predefined Gaussian distribution, which disregards the estimation of landmark uncertainty and also constrain both detection accuracy and interpretability. Furthermore, these methods still face challenges with faces under large poses and heavy occlusions, as they struggle to model effective facial shape constraints. To overcome these challenges, we propose a Multi-Expert Collaborative Uncertainty-Aware Deep Network (MCUDN) to achieve more robust and interpretable FLD. Specifically, we propose an Uncertainty-Aware Regression (UAR) method that adaptively adjusts the contribution of different landmarks based on their uncertainty during regression. By penalizing landmarks with higher uncertainty, the UAR method dynamically controls the gradient of localization during training, resulting in more accurate landmark detection. Moreover, a novel Multi-Expert Collaborative Learning (MECL) model is developed to extract multi-dependency collaborative features, enhancing facial shape constraints through multi-expert collaboration. Experimental results on challenging benchmark datasets demonstrate that integrating the UAR method and MECL model within the MCUDN framework yields a synergistic effect, outperforming current state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Jun Wan and Hui Xi and Yuanzhi Yao and Hang Sun and Zhihui Lai and Jie Zhou},
  doi          = {10.1016/j.neunet.2025.108195},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108195},
  shortjournal = {Neural Netw.},
  title        = {Interpretable facial landmark detection by multi-expert collaborative uncertainty-aware deep networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Corrigendum to “MultiverseAD: Enhancing spatial-temporal synchronous attention networks with causal knowledge for multivariate time series anomaly detection” [Neural networks 192 (2025) 107903]. <em>NN</em>, <em>194</em>, 108193. (<a href='https://doi.org/10.1016/j.neunet.2025.108193'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NN},
  author       = {Xudong Jia and Niangxi Zhuang and Wei Peng and Baokang Zhao and Peng Xun and Haojie Li and Chiran Shen},
  doi          = {10.1016/j.neunet.2025.108193},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108193},
  shortjournal = {Neural Netw.},
  title        = {Corrigendum to “MultiverseAD: Enhancing spatial-temporal synchronous attention networks with causal knowledge for multivariate time series anomaly detection” [Neural networks 192 (2025) 107903]},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A continual test-time domain adaptation method for online machinery fault diagnosis under dynamic operating conditions. <em>NN</em>, <em>194</em>, 108192. (<a href='https://doi.org/10.1016/j.neunet.2025.108192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical industrial scenarios, monitoring data is collected in a streaming fashion under dynamic changes in operating conditions of mechanical systems, with continual covariate shift and label shift occurring in the collected data. Traditional transfer learning-based fault diagnosis methods typically involve pre-collecting substantial monitoring data for offline training and testing under static conditions. These approaches cannot adjust the model in real-time to continuous data shifts caused by dynamically changing conditions, resulting in a lack of adaptability and generalization. To overcome this practical challenge, a continual test-time domain adaptation (CTDA) approach with a teacher-student framework is developed for online machinery fault diagnosis under dynamic operating conditions in this study. Firstly, a class-balanced sampling mechanism is proposed to eliminate the impact of continual condition label shift by enforcing the model to learn from a uniform label distribution. Secondly, a joint positive-negative learning strategy is employed to guide model optimization and reduce the interference from pseudo-label noise. Lastly, the continual covariate shift is mitigated by performing the knowledge alignment between the teacher and student models. Comprehensive experiments on four rotating machinery datasets demonstrate that the proposed method improves average diagnosis accuracy by 3.78% in handling dynamic industrial streaming data compared to existing fault diagnosis methods.},
  archive      = {J_NN},
  author       = {Jinghui Tian and Yue Yu and Hamid Reza Karimi and Fei Gao and Jing Lin},
  doi          = {10.1016/j.neunet.2025.108192},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108192},
  shortjournal = {Neural Netw.},
  title        = {A continual test-time domain adaptation method for online machinery fault diagnosis under dynamic operating conditions},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive dendritic plasticity in brain-inspired dynamic neural networks for enhanced multi-timescale feature extraction. <em>NN</em>, <em>194</em>, 108191. (<a href='https://doi.org/10.1016/j.neunet.2025.108191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-inspired neural networks, drawing insights from biological neural systems, have emerged as a promising paradigm for temporal information processing due to their inherent neural dynamics. Spiking Neural Networks (SNNs) have gained extensive attention among existing brain-inspired neural models. However, they often struggle with capturing multi-timescale temporal features due to the static parameters across time steps and the low-precision spike activities. To this end, we propose a dynamic SNN with enhanced dendritic heterogeneity to enhance the multi-timescale feature extraction capability. We design a Leaky Integrate Modulation neuron model with Dendritic Heterogeneity (DH-LIM) that replaces traditional spike activities with a continuous modulation mechanism for preserving the nonlinear behaviors while enhancing the feature expression capability. We also introduce an Adaptive Dendritic Plasticity (ADP) mechanism that dynamically adjusts dendritic timing factors based on the frequency domain information of input signals, enabling the model to capture both rapid- and slow-changing temporal patterns. Extensive experiments on multiple datasets with rich temporal features demonstrate that our proposed method achieves excellent performance in processing complex temporal signals. These optimizations provide fresh solutions for optimizing the multi-timescale feature extraction capability of SNNs, showcasing its broad application potential.},
  archive      = {J_NN},
  author       = {Jiayi Mao and Hanle Zheng and Huifeng Yin and Hanxiao Fan and Lingrui Mei and Hao Guo and Yao Li and Jibin Wu and Jing Pei and Lei Deng},
  doi          = {10.1016/j.neunet.2025.108191},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108191},
  shortjournal = {Neural Netw.},
  title        = {Adaptive dendritic plasticity in brain-inspired dynamic neural networks for enhanced multi-timescale feature extraction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). WaveNet-SF: A hybrid network for retinal disease detection based on wavelet transform in spatial-frequency domain. <em>NN</em>, <em>194</em>, 108189. (<a href='https://doi.org/10.1016/j.neunet.2025.108189'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal diseases are a leading cause of vision impairment and blindness, with timely diagnosis being critical for effective treatment. Optical Coherence Tomography (OCT) has become a standard imaging modality for retinal disease diagnosis, but OCT images often suffer from issues such as speckle noise, complex lesion shapes, and varying lesion sizes, making interpretation challenging. In this paper, we propose a novel model, WaveNet-SF, to enhance retinal disease detection by integrating the spatial-domain and frequency-domain learning. The framework utilizes wavelet transforms to decompose OCT images into low- and high-frequency components, enabling the model to extract both global structural features and fine-grained details. To improve lesion detection, we introduce a Multi-Scale Wavelet Spatial Attention (MSW-SA) module, which enhances the model's focus on regions of interest at multiple scales. Additionally, a High-Frequency Feature Compensation (HFFC) block is incorporated to recover edge information lost during wavelet decomposition, suppress noise, and preserve fine details crucial for lesion detection. Our approach achieves state-of-the-art (SOTA) classification accuracies of 97.82 % and 99.58 % on the OCT-C8 and OCT2017 datasets, respectively, surpassing existing methods. These results demonstrate the efficacy of WaveNet-SF in addressing the challenges of OCT image analysis and its potential as a powerful tool for retinal disease diagnosis.},
  archive      = {J_NN},
  author       = {Jilan Cheng and Guoli Long and Zeyu Zhang and Zhenjia Qi and Hanyu Wang and Libin Lu and Shuihua Wang and Yudong Zhang and Jin Hong},
  doi          = {10.1016/j.neunet.2025.108189},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108189},
  shortjournal = {Neural Netw.},
  title        = {WaveNet-SF: A hybrid network for retinal disease detection based on wavelet transform in spatial-frequency domain},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DiffMixer: A prediction model based on mixing different frequency features. <em>NN</em>, <em>194</em>, 108188. (<a href='https://doi.org/10.1016/j.neunet.2025.108188'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is widely applied in fields such as energy and network security. Various prediction models based on Transformer and MLP architectures have been proposed. However, their performance may decline to varying degrees when applied to real-world sequences with significant non-stationarity. Traditional approaches generally adopt either stabilization or a combination of stabilization and non-stationarity compensation for prediction tasks. However, non-stationarity is a crucial attribute of time series; the former approach tends to eliminate useful non-stationary patterns, while the latter may inadequately capture non-stationary information. Therefore, we propose DiffMixer, which analyzes and predicts different frequencies in non-stationary time series. We use Variational Mode Decomposition (VMD) to obtain multiple frequency components of the sequence, Multi-scale Decomposition (MsD) to optimize the decomposition of downsampled sequences, and Improved Star Aggregate-Redistribute (iSTAR) to capture interdependencies between different frequency components. Additionally, we employ the Frequency domain Processing Block (FPB) to capture global features of different frequency components in the frequency domain, and Dual Dimension Fusion (DuDF) to fuse different frequency components in two dimensions, enhancing the predictive fit for various frequencies. Compared to previous state-of-the-art methods, DiffMixer reduces the Mean Squared Error (MSE), Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Symmetric Mean Absolute Percentage Error (SMAPE) by 24.5%, 12.3%, 13.5%, and 6.1%, respectively.},
  archive      = {J_NN},
  author       = {Shengcai Zhang and Huiju Yi and Fanchang Zeng and Xuan Zhang and Zhiying Fu and Dezhi An},
  doi          = {10.1016/j.neunet.2025.108188},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108188},
  shortjournal = {Neural Netw.},
  title        = {DiffMixer: A prediction model based on mixing different frequency features},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CEVG-RTNet: A real-time architecture for robust forest fire smoke detection in complex environments. <em>NN</em>, <em>194</em>, 108187. (<a href='https://doi.org/10.1016/j.neunet.2025.108187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forest fire smoke detection is crucial for early warning and emergency management, especially under complex environmental conditions such as low contrast, high transparency, background interference, low illumination, occlusion, and overlapping smoke sources. These factors significantly hinder detection accuracy in real-world scenarios. To address these challenges, we propose CEVG-RTNet, a real-time forest fire smoke detection architecture designed to enhance robustness under such complex conditions. CEVG-RTNet incorporates several novel components. The Spatial-Channel Priori Perceptual Convolution (SCPP-Conv) module improves the model's ability to localize smoke and perceive its morphology, even in low-contrast and high-transparency environments. The Hierarchical Residual Feature Alignment (HRFA) module addresses the challenge of multi-scale feature extraction by aligning local and large-scale smoke features through a residual-guided alignment strategy and multi-layer perceptron (MLP)-based aggregation. To further refine dynamic smoke detection, the Dynamic Recursive Feature Enhancement (DRFE) module applies recursive channel adaptive enhancement and cross-channel attention strategies. Additionally, Polygonal-Intersection over Union (PolyIoU) Loss, a novel loss function, is introduced to handle the morphological complexity of smoke regions. The architecture leverages a graph sparse attention mechanism to enhance accuracy without excessive computational cost. Experimental results demonstrate the effectiveness of CEVG-RTNet, with the variant CEVG-RTNet-n achieving 89.1% precision, 82.9% recall, mAP@0.5 of 89%, and mAP@0.5:0.95 of 58.9%. The model operates with 3.04M parameters, 6.6G FLOPs, and 99.42 FPS, showcasing its strong generalization, anti-interference capabilities, and suitability for complex forest fire smoke detection. The source code is available at: https://github.com/CNNanmuzi/CEVG-RTNet .},
  archive      = {J_NN},
  author       = {Jun Wang and Chunman Yan},
  doi          = {10.1016/j.neunet.2025.108187},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108187},
  shortjournal = {Neural Netw.},
  title        = {CEVG-RTNet: A real-time architecture for robust forest fire smoke detection in complex environments},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Autonomous spiking neural p systems with coupled neurons. <em>NN</em>, <em>194</em>, 108186. (<a href='https://doi.org/10.1016/j.neunet.2025.108186'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstracted from the way spiking neurons transmit and process information, spiking neural P systems (SNP systems) are becoming increasingly popular as the third generation of neural network models. To enhance the applicability and expandability of SNP systems, inspired by the biological mechanisms of cell-autonomous and synchronized neural activities, autonomous spiking neural P systems with coupled neurons (ACSNP systems) are developed. In ACSNP systems, synaptic channels connecting neurons are autonomously modified by applying the internal rules of neurons, including rules for creating/deleting synaptic channels. Additionally, certain groups of coupled neurons whose neural activities are synchronized are defined. To clarify the operational mechanisms of ACSNP systems, an example that systematically generates natural numbers is presented. The computational universality of ACSNP systems is further demonstrated by their capability to simulate the functionality of universal register machines in both number generation and number acceptance. A universal ACSNP system utilizing 55 neurons is also developed to compute function, highlighting its efficiency and advantage compared to other variants of SNP systems. An ACSNP system capable of generating uniform solutions for SAT problems is constructed, demonstrating the practical applicability of ACSNP systems.},
  archive      = {J_NN},
  author       = {Dongyi Li and Xiyu Liu and Yuzhen Zhao},
  doi          = {10.1016/j.neunet.2025.108186},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108186},
  shortjournal = {Neural Netw.},
  title        = {Autonomous spiking neural p systems with coupled neurons},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploiting gaussian agnostic representation learning with diffusion priors for enhanced infrared small target detection. <em>NN</em>, <em>194</em>, 108185. (<a href='https://doi.org/10.1016/j.neunet.2025.108185'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared small target detection (ISTD) plays a vital role in numerous practical applications. In pursuit of determining the performance boundaries, researchers employ large and expensive manual-labeling data for representation learning. Nevertheless, this approach renders the state-of-the-art ISTD methods highly fragile in real-world challenges. In this paper, we first study the variation in detection performance across several mainstream methods under various scarcity – namely, the absence of high-quality infrared data – that challenge the prevailing theories about practical ISTD. To address this concern, we introduce the Gaussian Agnostic Representation Learning. Specifically, we propose the Gaussian Group Squeezer, leveraging Gaussian sampling and compression for non-uniform quantization. By exploiting a diverse array of training samples, we enhance the resilience of ISTD models against various challenges. Then, we introduce two-stage diffusion models for real-world reconstruction. By aligning quantized signals closely with real-world distributions, we significantly elevate the quality and fidelity of the synthetic samples. Comparative evaluations against state-of-the-art detection methods in various scarcity scenarios demonstrate the efficacy of the proposed approach.},
  archive      = {J_NN},
  author       = {Junyao Li and Yahao Lu and Xingyuan Guo and Xiaoyu Xian and Tiantian Wang and Yukai Shi},
  doi          = {10.1016/j.neunet.2025.108185},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108185},
  shortjournal = {Neural Netw.},
  title        = {Exploiting gaussian agnostic representation learning with diffusion priors for enhanced infrared small target detection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Toward fair graph neural networks via dual-teacher knowledge distillation. <em>NN</em>, <em>194</em>, 108184. (<a href='https://doi.org/10.1016/j.neunet.2025.108184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have demonstrated strong performance in graph representation learning across various real-world applications. However, they often produce biased predictions caused by sensitive attributes, such as religion or gender, an issue that has been largely overlooked in existing methods. Recently, numerous studies have focused on reducing biases in GNNs. However, these approaches often rely on training with partial data (e.g., using either node features or graph structure alone), which can enhance fairness but frequently compromises model utility due to the limited utilization of available graph information. To address this trade-off, we propose an effective strategy to balance fairness and utility in knowledge distillation. Specifically, we introduce FairDTD, a novel Fair representation learning framework built on D ual- T eacher D istillation, leveraging a causal graph model to guide and optimize the design of the distillation process. In particular, FairDTD employs two fairness-oriented teacher models: a feature teacher and a structure teacher, to facilitate dual distillation, with the student model learning fairness knowledge from the teachers while also leveraging full data to mitigate utility loss. To enhance information transfer, we incorporate graph-level distillation to provide an indirect supplement of graph information during training, as well as a node-specific temperature module to improve the comprehensive transfer of fair knowledge. Experiments on diverse benchmark datasets demonstrate that FairDTD achieves optimal fairness while preserving high model utility, showcasing its effectiveness in fair representation learning for GNNs.},
  archive      = {J_NN},
  author       = {Chengyu Li and Debo Cheng and Guixian Zhang and Yi Li and Shichao Zhang},
  doi          = {10.1016/j.neunet.2025.108184},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108184},
  shortjournal = {Neural Netw.},
  title        = {Toward fair graph neural networks via dual-teacher knowledge distillation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Synchronization of reaction-diffusion delayed inertial memristive neural networks via adaptive pinning control. <em>NN</em>, <em>194</em>, 108183. (<a href='https://doi.org/10.1016/j.neunet.2025.108183'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The synchronization control problem of delayed inertial memristive neural networks (DIMNNs) with reaction-diffusion terms is addressed. First, by differential inclusions and a reduced-order approach to analyze the DIMNNs. Second, an adaptive pinning control method is introduced to achieve synchronization of drive-and-response systems. By applying inequality technology and Green’s Formula, a criterion is obtained to ensure the synchronization of DIMNNs with reaction-diffusion terms. Furthermore, the proposed control scheme requires fewer controlled nodes compared to the full-state feedback method, exhibits robustness against parameter uncertainties, and automatically adapts to varying network conditions. Finally, a numerical example is presented to confirm the theoretical results and demonstrate the effectiveness of the proposed approach.},
  archive      = {J_NN},
  author       = {Jiemei Zhao and Fenglin Wang},
  doi          = {10.1016/j.neunet.2025.108183},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108183},
  shortjournal = {Neural Netw.},
  title        = {Synchronization of reaction-diffusion delayed inertial memristive neural networks via adaptive pinning control},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Elevating adversarial robustness by contrastive multitasking defence in medical image segmentation. <em>NN</em>, <em>194</em>, 108182. (<a href='https://doi.org/10.1016/j.neunet.2025.108182'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although Deep Learning (DL)-based Medical Image Segmentation (MIS) models are critically important, adversarial attacks substantially diminish their efficacy. Such attacks subtly perturb inputs, causing the model to produce inaccurate predictions. This problem is more prevalent in medical images, as their intricate textures can mislead the model to focus on irrelevant regions, undermining performance and robustness. Thus, defending against adversarial attacks is crucial for a robust DL-based MIS model. While existing defences have proven effective in non-medical domains, their impact in medical domains remains limited. To bridge this gap, we propose a novel defence, CEASE ( C ontrastiv E Multit AS king D E fence), to significantly enhance the adversarial resilience of MIS models, delivering notable performance gain. CEASE exhibits contrastive learning, multitask learning, and their consolidation-based defence. Initially, we investigate the importance of contrastive learning in a DL-based MIS model. It leverages the observation that learning similar features for clean, adversarial, and augmented samples during training significantly enhances adversarial robustness. Subsequently, our proposed multitask learning-based defence provides generic feature representation and selects auxiliary tasks based on their weak relevance to the main task, improving model robustness. Eventually, we leverage the advantages of contrastive and multitask learning to propose their fusion-based defence. It employs contrastive learning specifically for MIS tasks and follows the proposed multitask model architecture. Experiments on publicly available datasets across several state-of-the-art MIS models reveal that CEASE surpasses the well-known defences by mitigating the efficacy of adversarial attacks up to 0% attack success rate on maximum average distortion with modest performance advancement.},
  archive      = {J_NN},
  author       = {Sneha Shukla and Puneet Gupta},
  doi          = {10.1016/j.neunet.2025.108182},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108182},
  shortjournal = {Neural Netw.},
  title        = {Elevating adversarial robustness by contrastive multitasking defence in medical image segmentation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Networks of hebbian networks: More is different. <em>NN</em>, <em>194</em>, 108181. (<a href='https://doi.org/10.1016/j.neunet.2025.108181'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The common thread behind the recent Nobel Prize in Physics to John Hopfield and those conferred to Giorgio Parisi in 2021 and Philip Anderson in 1977 is disorder . Quoting Philip Anderson: more is different . This principle has been extensively demonstrated in magnetic systems and spin glasses, and, in this work, we test its validity on Hopfield neural networks to show how an assembly of these models displays emergent capabilities that are not present at a single network level. Such an assembly is designed as a layered associative Hebbian network that, beyond accomplishing standard pattern recognition , spontaneously performs also pattern disentanglement . Namely, when inputted with a composite signal – e.g., a musical chord – it can return the single constituting elements – e.g., the notes making up the chord. Here, restricting to notes coded as Rademacher vectors and chords that are their mixtures (i.e., spurious states), we use tools borrowed from statistical mechanics of disordered systems to investigate this task, obtaining the conditions over the model control-parameters such that pattern disentanglement is successfully executed.},
  archive      = {J_NN},
  author       = {Elena Agliari and Andrea Alessandrelli and Adriano Barra and Martino Centonze and Federico Ricci-Tersenghi},
  doi          = {10.1016/j.neunet.2025.108181},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108181},
  shortjournal = {Neural Netw.},
  title        = {Networks of hebbian networks: More is different},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-level teacher assistant-based knowledge distillation framework with dynamic feedback for motor imagery EEG decoding. <em>NN</em>, <em>194</em>, 108180. (<a href='https://doi.org/10.1016/j.neunet.2025.108180'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has shown promise in motor imagery-based electroencephalogram (MI-EEG) decoding, a critical task in non-invasive brain-computer interfaces (BCIs). In response to the computational complexity of deep learning models to be deployed in practical BCI applications, knowledge distillation (KD) has emerged as a solution for model compression. However, vanilla KD methods struggle to effectively extract and transfer the abundant multi-level knowledge from MI-EEG signals under high compression ratios. This study proposes a novel knowledge distillation framework termed Motor Imagery Knowledge Distillation (MIKD), which compresses deep learning models for MI classification tasks while maintaining high performance. The MIKD framework consists of two key modules: (1) a multi-level teacher assistant knowledge distillation (ML-TAKD) module designed to extract and transfer local representations and global dependencies of MI-EEG signals from the complex teacher network to the much smaller student network, and (2) a dynamic feedback module that allows the teacher assistant to adjust its teaching strategy based on the student's learning progress. Extensive experiments on three public EEG datasets demonstrate that the MIKD framework achieves state-of-the-art performance. The proposed framework improves the baseline student model's accuracy by 6.61 %, 1.91 %, and 3.29 % on the three datasets, while reducing the model size by nearly 90 %.},
  archive      = {J_NN},
  author       = {Jinzhou Wu and Baoping Tang and Yi Wang and Cheng Li and Qichao Yang},
  doi          = {10.1016/j.neunet.2025.108180},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108180},
  shortjournal = {Neural Netw.},
  title        = {A multi-level teacher assistant-based knowledge distillation framework with dynamic feedback for motor imagery EEG decoding},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Uncertainty propagation in feed-forward neural network models. <em>NN</em>, <em>194</em>, 108178. (<a href='https://doi.org/10.1016/j.neunet.2025.108178'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop new uncertainty propagation methods for feed-forward neural network architectures with leaky ReLU activation functions subject to random perturbations in the input vectors. In particular, we derive analytical expressions for the probability density function (PDF) of the neural network output and its statistical moments as a function of the input uncertainty and the parameters of the network, i.e., weights and biases. A key finding is that an appropriate linearization of the leaky ReLU activation function yields accurate statistical results even for large perturbations in the input vectors. This can be attributed to the way information propagates through the network. We also propose new analytically tractable Gaussian copula surrogate models to approximate the full joint PDF of the neural network output. To validate our theoretical results, we conduct Monte Carlo simulations and a thorough error analysis on a multi-layer neural network representing a nonlinear integro-differential operator between two polynomial function spaces. Our findings demonstrate excellent agreement between the theoretical predictions and Monte Carlo simulations.},
  archive      = {J_NN},
  author       = {Jeremy Diamzon and Daniele Venturi},
  doi          = {10.1016/j.neunet.2025.108178},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108178},
  shortjournal = {Neural Netw.},
  title        = {Uncertainty propagation in feed-forward neural network models},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-view spectral clustering algorithm based on bipartite graph and multi-feature similarity fusion. <em>NN</em>, <em>194</em>, 108177. (<a href='https://doi.org/10.1016/j.neunet.2025.108177'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering remains a challenging task due to the heterogeneity and inconsistency across multiple views. Most esisting multi-view spectral clustering methods adopt a two-stage approch–constructing fused spectral embeddings matrix followed by k-means clustering–which often leads to information loss and suboptimal performance. Moreover, current graph and feature fusion strategies struggle to address view-specific discrepancies and label misalignment, while their high computational complexity hinders scalability to large datasets. To overcome these limitations, we propose a unified Multi-view Spectral Clustering algorithm based on Bipartite Graph and Multi-feature Similarity Fusion (BG-MFS). The proposed framework jointly integrates bipartite graph construction, multi-feature similarity fusion, and discrete clustering within a single optimization model, enabling mutual reinforcement among components. Furthermore, an entropy-based weighting mechanism is introduced to adaptively assess the contribution of each view. Extensive experiments demonstrate that BG-MFS consistently outperforms state-of-the-art methods in both clustering accuracy and computational efficiency.},
  archive      = {J_NN},
  author       = {Shunyong Li and Kun Liu and Mengjiao Zheng and Liang Bai},
  doi          = {10.1016/j.neunet.2025.108177},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108177},
  shortjournal = {Neural Netw.},
  title        = {Multi-view spectral clustering algorithm based on bipartite graph and multi-feature similarity fusion},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FTA2C: Achieving superior trade-off between accuracy and robustness in adversarial training. <em>NN</em>, <em>194</em>, 108176. (<a href='https://doi.org/10.1016/j.neunet.2025.108176'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks are notoriously vulnerable to adversarial perturbations, largely due to the presence of non-robust features that destabilize model performance. Traditional Adversarial Training (AT) methods on feature space typically operate on one part of features individually, resulting in the loss of useful information in them, and improve robustness at the expense of accuracy, making it difficult to optimize the inherent trade-off between the two. To address this challenge, we propose a novel plug-in method termed Feature Transformation Alignment and Compression (FTA2C). FTA2C comprises three key components. First, a compression network constrains the perturbation space to reduce the vulnerability of non-robust features. Second, a feature transformation network enhances the expressiveness of robust features. Third, an alignment mechanism enforces consistency between adversarial and natural samples in the robust feature space. The above mechanism achieves co-processing of the two parts of the feature. Additionally, we propose the Defense Efficiency Metric (DEM) to evaluate defense methods. DEM quantifies the trade-off between maintaining natural accuracy and enhancing adversarial robustness, offering a unified and interpretable standard for comparing defense strategies. Extensive experiments conducted on four benchmark datasets demonstrate that FTA2C significantly improvements robustness under the high-level accuracy, resulting in superior trade-off performance. Our code is available at https://github.com/HymanGao31/FTA2C .},
  archive      = {J_NN},
  author       = {Zhenghan Gao and Chengming Liu and Yucheng Shi and Xin Guo and Jing Xu and Hong Zhang and Lei Shi},
  doi          = {10.1016/j.neunet.2025.108176},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108176},
  shortjournal = {Neural Netw.},
  title        = {FTA2C: Achieving superior trade-off between accuracy and robustness in adversarial training},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Anchor point segmentation based multi-view clustering. <em>NN</em>, <em>194</em>, 108175. (<a href='https://doi.org/10.1016/j.neunet.2025.108175'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing bipartite graph based methods commonly learn a consistent anchor graph across multiple views utilizing various optimization techniques to determine clustering assignments, maintaining linear complexity w.r.t. the number of samples. Owing to their efficiency and effectiveness, these approaches have attracted significant attention. However, the inherent geometric relationship in which anchors and the raw data share common centroids remains under-explored, leaving room for potential improvements in algorithm efficiency. This relationship enables the use of anchors to efficiently learn clustering centroids. In this paper, we propose a novel multi-view clustering approach termed anchor point segmentation based multi-view clustering (APS-MVC). Specifically, we group the raw data by first assigning each data point to an anchor point, then to a centroid. This process is modeled as a two-step transition within a Markov chain, where the optimal centroids and the soft partition of anchors are learned simultaneously by encoding the graph structure information of the anchor points. Furthermore, the proposed APS-MVC effectively tackles the out-of-sample issue. The resultant optimization problem is solved efficiently, exhibiting square complexity w.r.t. the number of anchors. Experimental results on six benchmark datasets validate the effectiveness of the proposed method. The source code is available at: https://github.com/Wenhua-Dong/APS-MVC .},
  archive      = {J_NN},
  author       = {Wenhua Dong and Xiao-Jun Wu and Bo Fan},
  doi          = {10.1016/j.neunet.2025.108175},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108175},
  shortjournal = {Neural Netw.},
  title        = {Anchor point segmentation based multi-view clustering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Domain adaptive underwater object detection via complementary style-aware learning. <em>NN</em>, <em>194</em>, 108174. (<a href='https://doi.org/10.1016/j.neunet.2025.108174'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images from different underwater domains exhibit multi-style variations caused by water quality, lighting, and imaging devices. The domain gap caused by these variations, combined with limited annotated data in target domains, leads to degraded object detection performance in cross domain situations. Mean Teacher is an effective framework to address performance degradation caused by cross-domain discrepancies, but its effectiveness is constrained by the quality of pseudo-labels generated by the teacher model. To address this, we propose a complementary style-aware Mean Teacher (CSAMT) model. It constructs image pairs to facilitate style-aware learning, performs style-content disentanglement via WCT2, and leverages Discrete Wavelet Transform (DWT)’s band-separation properties to jointly model image-pair features across frequency and spatial domains. Additionally, a two-stage teacher-student region proposal alignment (TTRPA) strategy is introduced, which guides the model to assign higher attention weights to more effective regions and constructs a consistency loss for suboptimal supervision. Experiments across three domain adaptation benchmarks demonstrate state-of-the-art performance, with ablation studies validating the effectiveness of each component.},
  archive      = {J_NN},
  author       = {Xinmiao Gao and Miao Yang and Zhuoran Xie},
  doi          = {10.1016/j.neunet.2025.108174},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108174},
  shortjournal = {Neural Netw.},
  title        = {Domain adaptive underwater object detection via complementary style-aware learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). High-speed olfactory perception with adaptive load balancing based on a laser array reservoir computing architecture. <em>NN</em>, <em>194</em>, 108173. (<a href='https://doi.org/10.1016/j.neunet.2025.108173'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the front-end information acquisition module of intelligent olfactory systems, the inherent cross-sensitivity of gas sensors presents a significant technical challenge. While sensor-array-based architectures have been established as an effective solution to address this limitation, the requirements for real-time detection in gas identification and concentration quantification have introduced a new challenge: the intrinsic multi-channel information processing demands of array systems lead to a dramatic increase in computational complexity. In this work, we propose a photonic reservoir computing (RC) method for high-speed mixed gases olfactory perception, by leveraging the nonlinear mapping properties of semiconductor lasers and the inherent high-speed parallelism and low-energy characteristics of optical computing. A dimensional segmentation mechanism for multidimensional signals based on semiconductor laser arrays has been developed. By constructing a parallel PRC architecture, this mechanism enables distributed processing of multidimensional signals from gas sensor arrays, achieving adaptive matching between the number of activated lasers in the array and the internal feature dimensions required for computational load balancing. Numerical results indicate that the proposed system achieves high accuracy in gas classification tasks and concentration prediction performance comparable to current mainstream algorithms. This confirms the significant advantages of laser-array-based reservoirs in processing multivariable sensor data. The results provide a theoretical foundation for the development of physical RC systems oriented toward low-power rapid detection of mixed gases. With integration and miniaturization of photonic technologies, it is promising to build miniaturized brain-inspired computing systems with rapid inference capability and dynamic adaptability, thus contributing to the advancement of electronic nose technology.},
  archive      = {J_NN},
  author       = {Guizheng Guan and Bin Liu},
  doi          = {10.1016/j.neunet.2025.108173},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108173},
  shortjournal = {Neural Netw.},
  title        = {High-speed olfactory perception with adaptive load balancing based on a laser array reservoir computing architecture},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Output-based sampled-data control of signed networks via parametric lyapunov equations approach. <em>NN</em>, <em>194</em>, 108169. (<a href='https://doi.org/10.1016/j.neunet.2025.108169'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is dedicated to demonstrating the influence of leaders on followers in signed networks with antagonistic interactions, where leaders have their own dynamics and interact with other leaders in a strongly connected closed subgraph (SCCC). An output-based distributed sampled-data protocol is designed to comprehensively analyze and assess the impact exerted by leaders on followers, where a heterogeneous sampled-data state observer associated with each agent is developed. The sampled-data control gain is then explicitly calculated via the solutions of parametric Lyapunov equations, enabling more flexible sampling intervals than classical Lyapunov equations. It is demonstrated that leaders in the structurally balanced SCCCs will reach bipartite consensus, and all followers eventually fall within a region that is precisely delineated by the states of these leaders and their corresponding opposite states. For structurally unbalanced graphs, leaders in unbalanced SCCCs reach neutrality, while follower states depend only on leaders in balanced SCCCs. The validity of the theoretical results is verified through simulation tests.},
  archive      = {J_NN},
  author       = {Wenbing Zhang and Abuzar Hussein Mohammed Atitalla and Luyang Yu and Tingwen Huang},
  doi          = {10.1016/j.neunet.2025.108169},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108169},
  shortjournal = {Neural Netw.},
  title        = {Output-based sampled-data control of signed networks via parametric lyapunov equations approach},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EEG-CLIP: A transformer-based framework for EEG-guided image generation. <em>NN</em>, <em>194</em>, 108167. (<a href='https://doi.org/10.1016/j.neunet.2025.108167'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decoding visual perception from neural signals represents a fundamental step toward advanced brain-computer interfaces (BCIs), where functional magnetic resonance imaging (fMRI) has shown promising results despite practical constraints in deployment and costs. Electroencephalography (EEG), with its superior temporal resolution, portability, and cost-effectiveness, emerges as a promising alternative for real-time brain-computer interface (BCI) applications. While existing EEG-based approaches have advanced neural decoding capabilities, they remain constrained by inadequate architectural designs, limited reconstruction fidelity, and inconsistent evaluation protocols. To address these challenges, we present EEG-CLIP, a novel Transformer-based framework that systematically addresses each limitation: (1) We introduce a specialized EEG-ViT encoder that adeptly captures the spatial and temporal characteristics of EEG signals to augment model capacity, along with a Diffusion Prior Transformer architecture to approximate the image feature distribution. (2) We employ a dual-stage reconstruction pipeline that integrates class contrastive learning and pretrained diffusion models to enhance visual reconstruction quality. (3) We establish comprehensive evaluation protocols across multiple datasets. Our framework operates through two stages: first projecting EEG signals into CLIP image space via class contrastive learning and refining them into image priors, then reconstructing perceived images through a pretrained conditional diffusion model. Comprehensive empirical analysis, including temporal window sensitivity studies and regional brain activation visualization, demonstrates the framework’s robustness. We demonstrate through ablations that EEG-CLIP’s performance improvements over previous methods result from specialized architecture for EEG encoding and improved training techniques. Quantitative and qualitative evaluations on ThingsEEG and Brain2Image datasets establish EEG-CLIP’s state-of-the-art performance in both classification and reconstruction tasks, advancing neural signal-based visual decoding capabilities.},
  archive      = {J_NN},
  author       = {Xuhao Cao and Peiliang Gong and Liying Zhang and Daoqiang Zhang},
  doi          = {10.1016/j.neunet.2025.108167},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108167},
  shortjournal = {Neural Netw.},
  title        = {EEG-CLIP: A transformer-based framework for EEG-guided image generation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Autoencoder-based contrastive learning for next basket recommendation. <em>NN</em>, <em>194</em>, 108166. (<a href='https://doi.org/10.1016/j.neunet.2025.108166'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next Basket Recommendation (NBR) aims to predict the items in the next basket a user will interact with, based on the user’s basket interaction history. However, data sparsity has been a significant challenge in this area. Contrastive Learning (CL) leverages data augmentation and constructs contrastive losses to enhance the embeddings quality, thus effectively addressing the issue of data sparsity. However, the existing methods rely on adding information to basket embedding or segmenting baskets for contrastive learning, which tend to disrupt the original embedding and have limited applicability in the NBR scenarios with diverse data characteristics. To address the above problems, we propose a novel model called Autoencoder-based Contrastive learning for Next Basket Recommendation (AC-NBR). The proposed method mainly consists of three modules, namely AE-based Basket Augmentation, AE-based Contrastive Learning, and Next-Basket Predictor. In the first module, two different basket augmentation methods are designed to provide sufficient and diverse positive pairs for CL. Specifically, we leverage an encoder-decoder structure with appropriate Gaussian noise to extract key features. This process not only helps mitigate noise interference but also improves the robustness of the embedding representation. In addition, the mean and standard deviation of the embedding representation space are learned separately. Then, Gaussian sampling is performed and the sampled latent representation is reconstructed through the decoder to achieve basket augmentation. This approach preserves core information while enhancing the embedding’s diversity and adaptability. In the second module, based on the two basket augmentations and the initial basket embeddings, three sets of positive pairs are constructed for CL. In the third module, we first encode the optimized basket sequence through a Gated Recurrent Unit (GRU) and then employ two Multi-Layer Perceptrons (MLPs) to predict the items likely to be contained in the next basket, thereby obtaining the final prediction results. The effectiveness of AC-NBR is confirmed through comprehensive experiments on three real-world datasets.},
  archive      = {J_NN},
  author       = {Ling Huang and Zhe-Yuan Li and Xiao-Dong Huang and Yuefang Gao and Chang-Dong Wang and Philip S. Yu},
  doi          = {10.1016/j.neunet.2025.108166},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108166},
  shortjournal = {Neural Netw.},
  title        = {Autoencoder-based contrastive learning for next basket recommendation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Pattern-based learning and control for a class of sampled-data nonlinear systems. <em>NN</em>, <em>194</em>, 108165. (<a href='https://doi.org/10.1016/j.neunet.2025.108165'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial control processes, system dynamics and parameters often change over time. As a result, traditional control schemes designed for fixed environments struggle to handle complex, dynamic operating conditions. This paper focuses on pattern-based learning and control challenges in sampled-data systems under multiple operating scenarios. The proposed control strategy involves two identification phases followed by a recognition and control phase. In the first identification phase, sampled-data neural network (NN) controllers are designed for different control scenarios. Leveraging deterministic learning (DL) theory, the unknown internal dynamics of the system are accurately approximated by neural networks (NNs). Subsequently, a knowledge-based candidate controller library is constructed. In the second identification phase, the closed-loop system dynamics under the normal controller are precisely identified using a set of estimators. During the recognition and control phase, changes in control scenarios are rapidly and accurately detected by comparing current system dynamics with pre-constructed recognizers, based on the minimum residual principle. Subsequently, a suitable learning controller is selected to ensure system stability and high-performance control. Simulation studies demonstrate the validity of the proposed approach.},
  archive      = {J_NN},
  author       = {Qinchen Yang and Fukai Zhang and Cong Wang},
  doi          = {10.1016/j.neunet.2025.108165},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108165},
  shortjournal = {Neural Netw.},
  title        = {Pattern-based learning and control for a class of sampled-data nonlinear systems},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Necessary and sufficient knowledge enhanced collaborative logical reasoning in LLMs. <em>NN</em>, <em>194</em>, 108164. (<a href='https://doi.org/10.1016/j.neunet.2025.108164'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) learn massive knowledge through pre-training, and they have demonstrated strong reasoning capabilities by leveraging the knowledge. However, LLMs often make mistakes due to the failure of using necessary and sufficient knowledge. The inadequate utilization of sufficient knowledge will lead to the incorrect conclusions due to the lack of important evidence. Unnecessary knowledge may mislead the LLMs into generating false reasoning paths. To tackle the above challenges, we propose a collaborative logical reasoning framework called CLR. We first utilize deductive reasoning based on evidence retrieval to generate reasoning paths. Next, we use abductive reasoning based on knowledge attribution to identify the necessary conditions. Then we use necessary conditions to verify the correctness of reasoning paths and obtain reliable reasoning paths. Finally, we conduct reliable inductive reasoning to obtain the final reasoning conclusion. Therefore, CLR achieves the collaboration of multiple logical reasoning paradigms. Extensive experiments demonstrate that CLR outperforms a series of baselines on multiple datasets. It also performs well in error identification and self-correction. Our work contributes to remedy the inherent limitations of the logical reasoning paradigms in LLMs and lays the foundation for modeling human cognitive thinking.},
  archive      = {J_NN},
  author       = {Peng Wang and Xiao Ding and Kai Xiong and Bing Qin and Ting Liu},
  doi          = {10.1016/j.neunet.2025.108164},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108164},
  shortjournal = {Neural Netw.},
  title        = {Necessary and sufficient knowledge enhanced collaborative logical reasoning in LLMs},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). NaturalL2S: End-to-end high-quality multispeaker lip-to-speech synthesis with differential digital signal processing. <em>NN</em>, <em>194</em>, 108163. (<a href='https://doi.org/10.1016/j.neunet.2025.108163'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in visual speech recognition (VSR) have promoted progress in lip-to-speech synthesis, where pre-trained VSR models enhance the intelligibility of synthesized speech by providing valuable semantic information. The success achieved by cascade frameworks, which combine pseudo-VSR with pseudo-text-to-speech (TTS) or implicitly utilize the transcribed text, highlights the benefits of leveraging VSR models. However, these methods typically rely on mel-spectrograms as an intermediate representation, which may introduce a key bottleneck: the domain gap between synthetic mel-spectrograms, generated from inherently error-prone lip-to-speech mappings, and real mel-spectrograms used to train vocoders. This mismatch inevitably degrades synthesis quality. To bridge this gap, we propose Natural Lip-to-Speech (NaturalL2S), an end-to-end framework that jointly trains the vocoder with the acoustic inductive priors. Specifically, our architecture introduces a fundamental frequency (F0) predictor to explicitly model prosodic variations, where the predicted F0 contour drives a differentiable digital signal processing (DDSP) synthesizer to provide acoustic priors for subsequent refinement. Notably, the proposed system achieves satisfactory performance on speaker similarity without requiring explicit speaker embeddings. Both objective metrics and subjective listening tests demonstrate that NaturalL2S significantly enhances synthesized speech quality compared to existing state-of-the-art methods. Audio samples are available on our demonstration page: https://yifan-liang.github.io/NaturalL2S/ .},
  archive      = {J_NN},
  author       = {Yifan Liang and Fangkun Liu and Andong Li and Xiaodong Li and Chengyou Lei and Chengshi Zheng},
  doi          = {10.1016/j.neunet.2025.108163},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108163},
  shortjournal = {Neural Netw.},
  title        = {NaturalL2S: End-to-end high-quality multispeaker lip-to-speech synthesis with differential digital signal processing},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Linear convergence of proximal gradient method for linear sparse SVM. <em>NN</em>, <em>194</em>, 108162. (<a href='https://doi.org/10.1016/j.neunet.2025.108162'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the hinge loss function being non-strongly-convex and non-strongly smooth, we establish the linear rate of convergence for sparse linear support vector machines (SVM) up to its statistical accuracy. The algorithm we use is the proximal gradient method for composite functions, applied to a sequence of regularization parameters to compute the approximate solution path on a grid. Unlike works on loss functions that are strongly convex and strongly smooth, here we do not have linear convergence to the exact solution, but we can demonstrate linear convergence to the population truth up to the statistical error (in particular, we simultaneously consider numerical convergence and statistical convergence). For any regularization parameter in the chosen decreasing sequence, we show that the estimator is in a small neighborhood of the exact solution after O ( log s * ) iterations, where s * is the sparsity of the true coefficient in the model, and a total number of O ( log n ) stages (i.e., using a sequence of regularization parameters of length O ( log n ) ) are required to achieve the near-oracle statistical rate, with n the sample size.},
  archive      = {J_NN},
  author       = {Xiaoqi Jiao and Heng Lian and Jiamin Liu and Yingying Zhang},
  doi          = {10.1016/j.neunet.2025.108162},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108162},
  shortjournal = {Neural Netw.},
  title        = {Linear convergence of proximal gradient method for linear sparse SVM},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fine-tuning large language models in federated learning with fairness-aware prompt selection. <em>NN</em>, <em>194</em>, 108160. (<a href='https://doi.org/10.1016/j.neunet.2025.108160'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) require domain-specific fine-tuning for real-world deployment, yet face critical barriers of data privacy and computational constraints. Federated learning (FL) provides an indispensable solution by enabling collaborative tuning across distributed private data sources while preserving confidentiality. However, existing FL-LLM methods suffer from non-IID degradation, communication overhead, and fairness issues. To address these challenges, this paper proposes FedPSF-LLM, a novel FL framework integrating three core innovations: (1) the Prompt Selection Module (PSM) adaptively selects high-impact prompt parameters to reduce transmission costs; (2) the Dynamic Weighting Module (DWM) adjusts aggregation weights based on client contribution and data disparity; (3) the Attention-Based Bias Mitigation (ABM) corrects aggregation bias via alignment-aware reweighting. Extensive experiments on 10 NLP tasks and 4 LLMs demonstrate that FedPSF-LLM improves fairness while maintaining strong overall performance. Compared to state-of-the-art methods, it reduces accuracy variance by 52.1 %, improves worst-client accuracy by 8.6 %, and narrows small-large client performance gaps by 74.4 %, while maintaining 76.8 % global accuracy. These results demonstrate superiority over 8 baselines in both fairness metrics and communication efficiency, establishing a new paradigm for privacy-preserving and fairness-guaranteed LLM deployment in federated systems.},
  archive      = {J_NN},
  author       = {Yalan Jiang and Zhongliang Li and Bin Song},
  doi          = {10.1016/j.neunet.2025.108160},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108160},
  shortjournal = {Neural Netw.},
  title        = {Fine-tuning large language models in federated learning with fairness-aware prompt selection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A unified dual-view knowledge-guided sentiment interaction networks for aspect-based sentiment analysis. <em>NN</em>, <em>194</em>, 108159. (<a href='https://doi.org/10.1016/j.neunet.2025.108159'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis enables precise identification of sentiment-bearing entities and attributes in textual content, thereby delivering granular sentiment information for downstream applications. Recent research has focused on enhancing sentiment-syntactic dependencies through external knowledge and graph neural networks. However, effective augmentation of sequence semantics via external knowledge remains underexplored, and existing methods inadequately capture the complementary relationship between sentiment semantics and syntax. To address these limitations, we propose the Dual -view K nowledge G uided Sentiment I nteraction N etwork (Dual-KGIN). The core contribution of Dual-KGIN lies in the construction of a unified framework for enhancing both sentiment semantics and syntactic representations by integrating external knowledge and implementing hierarchical interactions. Specifically, Dual-KGIN designs an external knowledge-guided syntactic GCN module that uses external knowledge to refine adjacency dependencies and enhance syntactic feature learning. Secondly, we use external knowledge based on the original attention mechanism to augment sequence semantics. Finally, we propose a novel multi-level feature interaction module, which effectively enhances the interaction of different perspectives at multiple levels of sentiment knowledge to improve sentiment representation. Extensive experiments on benchmark ABSA datasets demonstrate Dual-KGIN’s superior aspect-specific sentiment identification capability. Ablation studies validate the efficacy of each component, highlighting Dual-KGIN’s ability to effectively harness knowledge and model feature interactions for state-of-the-art ABSA performance.},
  archive      = {J_NN},
  author       = {Xuejian Gao and Fang’ai Liu and Xuqiang Zhuang and Yujuan Zhang and Xiaohui Tian and Yuyu Dong and Hongda Yang},
  doi          = {10.1016/j.neunet.2025.108159},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108159},
  shortjournal = {Neural Netw.},
  title        = {A unified dual-view knowledge-guided sentiment interaction networks for aspect-based sentiment analysis},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Small sphere and large margin support tensor machines for imbalanced tensor data classification. <em>NN</em>, <em>194</em>, 108158. (<a href='https://doi.org/10.1016/j.neunet.2025.108158'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The small sphere and large margin approach (SSLM) is a representative learning algorithm for handling imbalanced data classification problems. However, it is only effective for the vector data, and not suitable for the tensor data. How to build a novel model for the imbalanced tensor data is a challenge. In this paper, a small sphere and large margin support tensor machine (SSLMSTM) is proposed by taking full advantage of the structural information of tensor data. Its basic idea is to construct two concentric hyperspheres, whose centers are represented by a rank-1 tensor. The small hypersphere captures as many normal training samples (positive samples) as possible, while most outliers (negative samples) are pushed out of the large hypersphere. It can obtained great performance by increasing the margin of two hyperspheres. Furthermore, we extend SSLMSTM to a higher rank R case, named HR-SSLMSTM. Above two models can be solved by CANDECOMP/PARAFAC decomposition and alternating iteration method. Experiments on multiple datasets are conducted to verify the validity of our proposed SSLMSTM and HR-SSLMSTM.},
  archive      = {J_NN},
  author       = {Hexuan Liu and Xiao Li and Yitian Xu},
  doi          = {10.1016/j.neunet.2025.108158},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108158},
  shortjournal = {Neural Netw.},
  title        = {Small sphere and large margin support tensor machines for imbalanced tensor data classification},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Consistency-regularized graph neural networks for molecular property prediction. <em>NN</em>, <em>194</em>, 108157. (<a href='https://doi.org/10.1016/j.neunet.2025.108157'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although graph neural networks (GNNs) have proven powerful in molecular property prediction tasks, they tend to underperform when trained on small datasets. Conventional data augmentation strategies are generally ineffective in this context, as simply perturbing molecular graphs can unintentionally alter their intrinsic properties. In this study, we propose a consistency-regularized graph neural network (CRGNN) method to better utilize molecular graph augmentation during training. We apply molecular graph augmentation to obtain strongly and weakly-augmented views for each molecular graph. By incorporating a consistency regularization loss into the learning objective, the GNN is encouraged to learn representations such that the strongly-augmented views of a molecular graph are mapped close to a weakly-augmented view of the same graph. In doing so, molecular graph augmentation can contribute to improving the prediction performance of the GNN while mitigating its negative effects. Through experimental evaluation on various molecular benchmark datasets, we demonstrate that the proposed method outperforms existing methods that leverage molecular graph augmentation, especially when the training dataset is smaller.},
  archive      = {J_NN},
  author       = {Jongmin Han and Seokho Kang},
  doi          = {10.1016/j.neunet.2025.108157},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108157},
  shortjournal = {Neural Netw.},
  title        = {Consistency-regularized graph neural networks for molecular property prediction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Counterfactual generation with joint causal representation for generative adversarial networks. <em>NN</em>, <em>194</em>, 108156. (<a href='https://doi.org/10.1016/j.neunet.2025.108156'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The black-box nature of Generative Adversarial Networks (GANs) hinders the controllable generation of images, particularly in semantic editing that involves making changes to multiple attributes. To address this problem, we propose a C ounterfactual G eneration model with J oint C ausal R epresentation( C G J C R ). The key ideas of C G J C R include utilizing classifier gradients as prior knowledge to learn counterfactual joint representations of semantics, using orthogonalization through continuously optimizing iterations to disentangle semantic representations, and constructing independent counterfactual representations and disentanglement modules for pre-trained GANs to implement counterfactual generation. We compare C G J C R with its competitors in Celeba dataset using a variety of metrics and intervention experiments. Finally, we empirically validate the effectiveness of generating and disentangling joint causal representations. The code is open-source and publicly available at .},
  archive      = {J_NN},
  author       = {Dianlong You and Chuan Lu and Zhijuan Wu and Xiaoyi Ge and Di Wu},
  doi          = {10.1016/j.neunet.2025.108156},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108156},
  shortjournal = {Neural Netw.},
  title        = {Counterfactual generation with joint causal representation for generative adversarial networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LLM-led vision-spectral fusion: A zero-shot approach to temporal fruit image classification. <em>NN</em>, <em>194</em>, 108155. (<a href='https://doi.org/10.1016/j.neunet.2025.108155'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A zero-shot multimodal framework for temporal image classification is proposed, targeting automated fruit quality assessment. The approach leverages large language models for expert-level semantic description generation, which guides zero-shot object detection and segmentation through GLIP and SAM models. Visual features and spectral data are fused to capture both external appearance and internal biochemical properties of fruits. Experiments on the newly constructed Avocado Freshness Temporal-Spectral dataset—comprising daily synchronized images and spectral measurements across the full spoilage lifecycle—demonstrate reductions in mean squared error by up to 33 % and mean absolute error by up to 17 % compared to established baselines. These results validate the effectiveness and generalizability of the framework for temporal image analysis in smart agriculture and food quality monitoring.},
  archive      = {J_NN},
  author       = {Huyu Wu and Bowen Jia and Xue–Ming Yuan},
  doi          = {10.1016/j.neunet.2025.108155},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108155},
  shortjournal = {Neural Netw.},
  title        = {LLM-led vision-spectral fusion: A zero-shot approach to temporal fruit image classification},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cascading size-dependent deep propagation (CADP): Addressing over-smoothing in graph few-shot dermatology classification. <em>NN</em>, <em>194</em>, 108154. (<a href='https://doi.org/10.1016/j.neunet.2025.108154'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs play a critical role in capturing complex data relationships, particularly in few-shot learning tasks. However, one of the major challenges in graph-based models, such as Graph Neural Networks (GNNs), is the issue of over-smoothing, which diminishes the discriminative power of node representations. This problem arises when GNNs aggregate information from too large a neighborhood, leading to homogenization of node features. To overcome this limitation, we propose Cascading Size-Dependent Deep Propagation (CADP) , a novel approach designed to mitigate over-smoothing in graph-based few-shot learning, with a particular focus on improving skin disease classification. The model constructs the graph by employing a convolutional neural network (CNN) to extract feature representations from a small set of support and query images, where the nodes represent the extracted features, and the edges reflect the similarity between them. To improve feature representation and prevent over-smoothing, the model decouples the feature propagation process from the neural network to avoid repeated nonlinear transformations that lead to over-smoothing, enabling deeper information flow while preserving discriminative features. Then the initial support labels are integrated with the early prediction labels of query images, which are generated by a Multi-Layer Perceptron (MLP). Furthermore, this aggregated data is optimized through deep label propagation, which leverages the underlying graph structure to enhance classification accuracy. The propagation depths are controlled by the hyperparameters K 1 and K 2 , which are determined based on graph size, to regulate how extensively features and labels are propagated. We evaluate our approach on three dermatology datasets: ISIC 2018, Derm7pt, and SD-198, achieving 78.3 %, 79.29 %, and 91.92 % accuracy, respectively, in the 2-way 5-shot setting. CADP outperforms existing methods on all datasets, demonstrating its effectiveness in skin disease classification.},
  archive      = {J_NN},
  author       = {Abdulrahman Noman and Zou Beiji and Chengzhang Zhu and Mohammed Al-Habib and Ahmed Alasri},
  doi          = {10.1016/j.neunet.2025.108154},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108154},
  shortjournal = {Neural Netw.},
  title        = {Cascading size-dependent deep propagation (CADP): Addressing over-smoothing in graph few-shot dermatology classification},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Progressive multi-branch video style transfer network via confidence reweighted projection. <em>NN</em>, <em>194</em>, 108153. (<a href='https://doi.org/10.1016/j.neunet.2025.108153'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving temporal consistency in video content poses a significant challenge for high-quality video styling. Unfortunately, current video style transfer techniques often amplify the differences between frames in the input video, leading to unsmooth transitions between the stylized video frames. This can lead to visual flickering and discontinuities over time. Besides, the lack of style consistency between video frames or between different modes can make the overall style of the video appear fragmented or unnatural. To address these issues, this paper introduces an innovative real-time, end-to-end model for video style transfer,named as Progressive Multi-Branch Video Style Transfer Network (PMBNet). The primary focus is on introducing a Multi-layer Branch Semantic Transformation Structure (MBSTS), which comprises a multi-scale feature extraction layer featuring a multi-parallel progressive sub-modules (MPP), as well as a multi-level feature fusion layer that includes multiple channel spatial attention sub-modules (CSA). Among them, the MPP sub-modules use progressively dilated convolutions to enlarge the receptive field and mitigate grid artifacts, enabling the model to capture temporal and spatial dependencies, improving temporal consistency and reducing flickering between frames. The CSA sub-modules fuse content and style features across branches, ensuring multi-scale extraction and consistent style application, which resolves style fragmentation and ensures smooth transitions and consistency across frames and video modes. Additionally, a confidence reweighted calculation is employed to choose a dominant pattern from several potential options, ensuring consistency in modal content structure and preserving perceptual quality. Comprehensive evaluation demonstrates that PMBNet surpasses the performance of current state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Kunbo Han and Hongyan Yin and Junpeng Tan and Chongzhi Gao and Chunmei Qing},
  doi          = {10.1016/j.neunet.2025.108153},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108153},
  shortjournal = {Neural Netw.},
  title        = {Progressive multi-branch video style transfer network via confidence reweighted projection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatial-spectral multi-order gated aggregation network with bidirectional interactive fusion for hyperspectral image classification. <em>NN</em>, <em>194</em>, 108152. (<a href='https://doi.org/10.1016/j.neunet.2025.108152'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, convolutional neural networks (CNNs) have made significant strides in hyperspectral image classification (HSIC) tasks by contextualizing the convolutional kernels as global as possible. However, as the kernel sizes increase, encoding multi-order feature interactions becomes less efficient. Furthermore, self-attention mechanisms and convolutional operations can only handle global and local features independently, resulting in overly complex or simplified interactions. To overcome these limitations, in this work, we propose a novel HSIC framework called the Spatial-Spectral Multi-order Gated Aggregation Network with Bidirectional Interaction Fusion (SS-MoGAN). The proposed SS-MoGAN method integrates simple yet powerful convolutions and gated aggregations into a compact module, facilitating efficient feature extraction and adaptive contextual processing. Specifically, the spatial aggregation (SpaAg) and spectral aggregation (SpeAg) blocks guide the model to explicitly capture the interactions between low- and high-order features within the spatial and spectral dimensions. The bidirectional interaction fusion (BIF) blocks further integrate structural information through a bidirectional cross-attention mechanism, enhancing the representation of fine-grained details. Extensive experiments on three hyperspectral benchmark datasets demonstrate that the proposed SS-MoGAN method outperforms other state-of-the-art methods in HSIC applications. The source code for this work is available at https://github.com/szq0816/SS-MoGAN_HSIC .},
  archive      = {J_NN},
  author       = {Mingzhu Tai and Zhenqiu Shu and Songze Tang and Zhengtao Yu},
  doi          = {10.1016/j.neunet.2025.108152},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108152},
  shortjournal = {Neural Netw.},
  title        = {Spatial-spectral multi-order gated aggregation network with bidirectional interactive fusion for hyperspectral image classification},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep adaptive fusion network with multimodal neuroimaging information for MDD diagnosis: An open data study. <em>NN</em>, <em>194</em>, 108151. (<a href='https://doi.org/10.1016/j.neunet.2025.108151'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuroimaging offers powerful evidence for the automated diagnosis of major depressive disorder (MDD). However, discrepancies across imaging modalities hinder the exploration of cross-modal interactions and the effective integration of complementary features. To address this challenge, we propose a supervised Deep Adaptive Fusion Network (DAFN) that fully leverages the complementarity of multimodal neuroimaging information for the diagnosis of MDD. Specifically, high- and low-frequency features are extracted from the images using a customized convolutional neural network and multi-head self-attention encoders, respectively. A modality weight adaptation module dynamically adjusts the contribution of each modality during training, while a progressive information reinforcement training strategy reinforces multimodal fusion features. Finally, the performance of the DAFN is evaluated on both the open-access dataset and the recruited dataset. The results demonstrate that DAFN achieves competitive performance in multimodal neuroimaging fusion for the diagnosis of MDD. The source code is available at: https://github.com/TTLi1996/DAFN .},
  archive      = {J_NN},
  author       = {Tongtong Li and Kai Li and Ziyang Zhao and Qi Sun and Xinyan Zhang and Zhijun Yao and Jiansong Zhou and Bin Hu},
  doi          = {10.1016/j.neunet.2025.108151},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108151},
  shortjournal = {Neural Netw.},
  title        = {Deep adaptive fusion network with multimodal neuroimaging information for MDD diagnosis: An open data study},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MSA-LR: Enhancing multi-scale temporal dynamics in multivariate time series forecasting with low-rank self-attention. <em>NN</em>, <em>194</em>, 108150. (<a href='https://doi.org/10.1016/j.neunet.2025.108150'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately forecasting multivariate time series requires effectively capturing intricate temporal dependencies across diverse scales. Existing deep learning models, while promising, often fall short in this regard. Recurrent architectures like LSTMs struggle with long-range dependencies crucial for multi-scale modeling, while standard Transformers, despite employing attention mechanisms, fail to explicitly differentiate the importance of distinct periodicities, treating all time steps within a fixed window with similar relevance. This limitation hinders their ability to leverage the rich hierarchical structure of real-world time series, particularly in long-term forecasting scenarios. This paper introduces MSA-LR (Multi-Scale Self-Attention with Low-Rank Approximation), a novel architecture explicitly designed to capture multi-scale temporal dynamics. MSA-LR leverages a learnable scale weight matrix and low-rank approximations to directly model the influence of different temporal granularities (e.g., hourly, daily, weekly). This approach not only allows for fine-grained control over multi-scale interactions but also significantly reduces computational complexity compared to standard self-attention, enabling efficient processing of long time series. Empirical evaluations on diverse datasets, including electricity load, traffic flow, and air quality, demonstrate that MSA-LR achieves competitive performance compared to state-of-the-art methods, exhibiting notable improvements in long-term forecasting accuracy. Further analysis reveals MSA-LR's ability to discern and leverage periodic patterns at various resolutions, confirming its effectiveness in capturing the rich multi-scale temporal structure of real-world time series data.},
  archive      = {J_NN},
  author       = {Jie Sun and Zhilin Sun and Zhongshan Chen and Mengyang Dong and Xiaozheng Wang and Changwei Chen and Hao Zheng and Xiangjun Zhao},
  doi          = {10.1016/j.neunet.2025.108150},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108150},
  shortjournal = {Neural Netw.},
  title        = {MSA-LR: Enhancing multi-scale temporal dynamics in multivariate time series forecasting with low-rank self-attention},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-head prediction and reconstruction with coarse-to-fine masks for visual reinforcement learning. <em>NN</em>, <em>194</em>, 108149. (<a href='https://doi.org/10.1016/j.neunet.2025.108149'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In situations of limited experience and high-dimensional input data, effective representation learning plays a vital role in enabling visual reinforcement learning (RL) to excel in diverse tasks. To better leverage the agent’s sampled trajectory during the training process, we introduce the DPRM approach, which involves a D ual-head P rediction and R econstruction task with coarse-to-fine M asks in RL. The DPRM method tackles these challenges through integration of coarse-to-fine masks with a dual-head prediction-reconstruction (DHPR) architecture, complemented by a coordinate-based spatial coding strategy (CSCS). The CSCS enhances the spatial information of the observation state, facilitating the capture of motion changes between continuous context states. Furthermore, the coarse-to-fine masks gradually refine, guiding the following DHPR model to learn essential features and semantics more effectively. Built on a transformer architecture, DHPR introduces a novel triplet input token comprising two consecutive actions paired with an observation state. This design facilitates bidirectional prediction of past and future states from temporal extremities while efficiently reconstructing masked latent features throughout state sequences. Experimental results on both multiple continuous control (DeepMind Control Suite benchmarks) and discrete control (Atari) tasks demonstrate that the DPRM algorithm significantly enhances performance, leading to higher reward accumulation and faster convergence. Code is available at here .},
  archive      = {J_NN},
  author       = {Yun Zhou and Yuqiang Wu and Qiaoyun Wu and Chunyu Tan and Shu Zhan and Richang Hong},
  doi          = {10.1016/j.neunet.2025.108149},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108149},
  shortjournal = {Neural Netw.},
  title        = {Dual-head prediction and reconstruction with coarse-to-fine masks for visual reinforcement learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PepHarmony: A multi-view contrastive learning framework for integrated sequence and structure-based peptide representation. <em>NN</em>, <em>194</em>, 108148. (<a href='https://doi.org/10.1016/j.neunet.2025.108148'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in protein language models have catalyzed significant progress in peptide sequence representation. Despite extensive exploration in this field, pre-trained models tailored for peptide-specific needs remain largely unaddressed due to the difficulty in capturing the complex and sometimes unstable structures of peptides. This study introduces a novel multi-view contrastive learning framework PepHarmony for the sequence-based peptide representation task. PepHarmony innovatively combines sequence- and structure-level information into a sequence-level encoding module through contrastive learning. We carefully select datasets from the Protein Data Bank and AlphaFold DB to encompass a broad spectrum of peptide sequences and structures. The experimental data highlights PepHarmony's exceptional capability in capturing the intricate relationship between peptide sequences and structures compared with the baseline and fine-tuned models. The robustness of our model is confirmed through extensive ablation studies, which emphasize the crucial roles of contrastive loss and strategic data sorting in enhancing predictive performance. The training strategies and the pre-trained PepHarmony model serve as helpful contributions to peptide representations, and offer valuable insights for future applications in peptide drug discovery and peptide engineering.},
  archive      = {J_NN},
  author       = {Ruochi Zhang and Haoran Wu and Chang Liu and Huaping Li and Yuqian Wu and Kewei Li and Yifan Wang and Yifan Deng and Jiahui Chen and Fengfeng Zhou and Xin Gao},
  doi          = {10.1016/j.neunet.2025.108148},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108148},
  shortjournal = {Neural Netw.},
  title        = {PepHarmony: A multi-view contrastive learning framework for integrated sequence and structure-based peptide representation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Lena-TRNN: Exploring energy flow for time series prediction. <em>NN</em>, <em>194</em>, 108147. (<a href='https://doi.org/10.1016/j.neunet.2025.108147'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We focus on exploring the inherent energy flow for time series prediction in this paper, i.e., we consider the inherent energy of time series data as a sequence measuring properties such as fluctuations, oscillations, and trends. Distinctive with main-stream methods that adopt complex architecture to capture the presentative data relation, this brand-new perspective allows us to better differentiate the underlying distribution of the time-series data. Concretely, we design a novel decoder-free architecture, L atent- en ergy- a ware Transformer Recurrent Neural Network (Lena-TRNN), for multivariate time series forecasting and imputation. The new network tends to assign low energy scores to the samples belonging to the in-distribution dataset, and high energy scores otherwise, which is in accordance with the law of natural change. Predicted samples can be readily obtained by iterating gradient-based optimization along the direction of energy minimization to explicitly learn the inherent energy flow. With the energy optimization modelling, our proposed method exhibits superior performance to many other competitive methods and attains state-of-the-art performance in many benchmark time series forecasting and imputation tasks. The code is available at https://github.com/PengleiGao/Lena-TRNN .},
  archive      = {J_NN},
  author       = {Penglei Gao and Rui Zhang and Xi Yang and Zhuang Qian and Kaizhu Huang},
  doi          = {10.1016/j.neunet.2025.108147},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108147},
  shortjournal = {Neural Netw.},
  title        = {Lena-TRNN: Exploring energy flow for time series prediction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reinforcement learning with formation energy feedback for material diffusion models. <em>NN</em>, <em>194</em>, 108146. (<a href='https://doi.org/10.1016/j.neunet.2025.108146'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models are emerging as foundation tools for the discovery of new materials with remarkable efficiency. Existing works introduce physical constraints during the generation process of diffusion models to improve the quality of the generated crystals. However, it is difficult to accurately capture the distribution of stable crystal material structures, given the complex periodic crystal structure and the limited available crystal material data, even with the incorporation of symmetries and other domain-specific knowledge. Thus, these models still struggle to achieve a high success rate in producing stable crystal materials. To further improve the stability of generative crystal materials, we propose a novel fine-tuning framework RLFEF. We formulate the material diffusion process as a Markov Decision Process with formation energy serving as rewards. Moreover, we prove that optimizing the expected return in reinforcement learning is equivalent to applying policy gradient updates to a diffusion model. Additionally, we prove that the fine-tuned model adheres to the unique symmetry of crystal materials. Extensive experiments are conducted on three real-world datasets. The results show that our model achieves state-of-the-art performance on most tasks related to property optimization, ab initio generation, crystal structure prediction, and material generation.},
  archive      = {J_NN},
  author       = {Jiao Huang and Qianli Xing and Jinglong Ji and Bo Yang},
  doi          = {10.1016/j.neunet.2025.108146},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108146},
  shortjournal = {Neural Netw.},
  title        = {Reinforcement learning with formation energy feedback for material diffusion models},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hölder network for improved adversarial robustness. <em>NN</em>, <em>194</em>, 108145. (<a href='https://doi.org/10.1016/j.neunet.2025.108145'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A small Lipschitz constant can help improve robustness and generalization by restricting the sensitivity of the model to input perturbations. However, overly aggressive constraints may also limit the network’s ability to approximate complex functions. In this paper, we propose the Hölder network, a novel architecture utilizing α -rectified power units ( α -RePU). This framework generalizes Lipschitz-constrained networks by enforcing α -Hölder continuity. We theoretically prove that α -RePU networks are universal approximators of Hölder continuous functions, thereby offering greater flexibility than models with hard Lipschitz constraints. Empirical results show that the Hölder network achieves comparable accuracy and superior adversarial robustness against a wide range of attacks (e.g., PGD and l ∞ ) on both image classification and tabular data benchmarks.},
  archive      = {J_NN},
  author       = {Dazhi Zhao and Haiyan Li and Qin Luo and Wenguang Hu},
  doi          = {10.1016/j.neunet.2025.108145},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108145},
  shortjournal = {Neural Netw.},
  title        = {Hölder network for improved adversarial robustness},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A one-layer recurrent neural network for robust linear programming subject to l∞ norm uncertainty. <em>NN</em>, <em>194</em>, 108144. (<a href='https://doi.org/10.1016/j.neunet.2025.108144'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust optimization problems subject to norm uncertainty appear in numerous applications in various fields such as engineering, logistics, and finance. Despite its importance, robust optimization algorithms face significant computational challenges for solving high-dimensional problems, limiting their practical use. This paper presents a neurodynamic approach to mitigate these challenges by transforming the robust linear programming to a non-smooth convex optimization through parameter elimination. A one-layer projection neural network with proven stability and convergence is proposed to solve the non-smooth optimization problem. The effectiveness of this approach is validated based on simulations of numerical examples and applications in reactor design and wastewater treatment.},
  archive      = {J_NN},
  author       = {Jin Hu and Keying Zhou and Jun Wang},
  doi          = {10.1016/j.neunet.2025.108144},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108144},
  shortjournal = {Neural Netw.},
  title        = {A one-layer recurrent neural network for robust linear programming subject to l∞ norm uncertainty},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Implicit graph neural networks with flexible propagation operators. <em>NN</em>, <em>194</em>, 108143. (<a href='https://doi.org/10.1016/j.neunet.2025.108143'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the capability to capture high-order information of nodes and reduce memory consumption, implicit graph neural networks have become an explored hotspot in recent years. However, these implicit graph neural networks are limited by the static topology, which makes it difficult to handle heterophilic graph-structured data. Furthermore, the existing methods inspired by optimization problem are limited by the explicit structure of graph neural networks, which makes it difficult to set an appropriate number of network layers to solve optimization problems. To address these issues, we propose an implicit graph neural network with flexible propagation operators in this paper. From the optimization objective function, we derive an implicit message passing formula with flexible propagation operators. Compared to the static operator, the proposed method that joints the dynamic semantic and topology of data is more applicable to heterophilic graphs. Moreover, the proposed model performs a fixed-point iterative process for the optimization of the objective function, which implicitly adjusts the number of network layers without requiring sufficient prior knowledge. Extensive experiment results demonstrate the superiority of the proposed model.},
  archive      = {J_NN},
  author       = {Yueyang Pi and Yang Huang and Yongquan Shi and Fuhai Chen and Shiping Wang},
  doi          = {10.1016/j.neunet.2025.108143},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108143},
  shortjournal = {Neural Netw.},
  title        = {Implicit graph neural networks with flexible propagation operators},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards out-of-distribution detection using gradient vectors. <em>NN</em>, <em>194</em>, 108142. (<a href='https://doi.org/10.1016/j.neunet.2025.108142'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deploying Deep Learning algorithms in the real world requires some care that is generally not considered in the training procedure. In real-world scenarios, where the input data cannot be controlled, it is important for a model to identify when a sample does not belong to any known class. This is accomplished using out-of-distribution (OOD) detection, a technique designed to distinguish unknown samples from those that belong to the in-distribution classes. These methods mainly rely on output or intermediate features to calculate OOD scores, but the gradient space is still under-explored for this task. In this work, we propose a new family of methods using gradient features, named GradVec, using the gradient space as input representation for different OOD detection methods. The main idea is that the model gradient presents, in a more informative way, the knowledge that a sample belongs to a known class, being able to distinguish it from other unknown ones. GradVec methods do not change the model training procedure and no additional data is needed to adjust the OOD detector, and it can be used on any pre-trained model. Our approach presents superior results in different scenarios for OOD detection in image classification and text classification, reducing FPR95 up to 26.67 % and 21.29 %, respectively.},
  archive      = {J_NN},
  author       = {Thiago Carvalho and Marley Vellasco and José Franco Amaral},
  doi          = {10.1016/j.neunet.2025.108142},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108142},
  shortjournal = {Neural Netw.},
  title        = {Towards out-of-distribution detection using gradient vectors},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Joint generative and alignment adversarial learning for robust incomplete multi-view clustering. <em>NN</em>, <em>194</em>, 108141. (<a href='https://doi.org/10.1016/j.neunet.2025.108141'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete multi-view clustering (IMVC) has become an area of increasing focus due to the frequent occurrence of missing views in real-world multi-view datasets. Traditional methods often address this by attempting to recover the missing views before clustering. However, these methods face two main limitations: (1) inadequate modeling of cross-view consistency, which weakens the relationships between views, especially with a high missing rate, and (2) limited capacity to generate realistic and diverse missing views, leading to suboptimal clustering results. To tackle these issues, we propose a novel framework, Joint Generative Adversarial Network and Alignment Adversarial (JGA-IMVC). Our framework leverages adversarial learning to simultaneously generate missing views and enforce consistency alignment across views, ensuring effective reconstruction of incomplete data while preserving underlying structural relationships. Extensive experiments on benchmark datasets with varying missing rates demonstrate that JGA-IMVC consistently outperforms current state-of-the-art methods. The model achieves improvements of 3 % to 5 % in key clustering metrics such as Accuracy, Normalized Mutual Information (NMI), and Adjusted Rand Index (ARI). JGA-IMVC excels under high missing conditions, confirming its robustness and generalization capabilities, providing a practical solution for incomplete multi-view clustering scenarios.},
  archive      = {J_NN},
  author       = {Yueyao Li and Bin Wu},
  doi          = {10.1016/j.neunet.2025.108141},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108141},
  shortjournal = {Neural Netw.},
  title        = {Joint generative and alignment adversarial learning for robust incomplete multi-view clustering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph-patchformer: Patch interaction transformer with adaptive graph learning for multivariate time series forecasting. <em>NN</em>, <em>194</em>, 108140. (<a href='https://doi.org/10.1016/j.neunet.2025.108140'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series (MTS) forecasting plays a pivotal role in the digitalization and intelligent development of modern society, while previous MTS forecasting methods based on deep learning often rely on capturing intra-series dependencies for modeling, neglecting the structural information within MTS and failing to consider inter-series local dynamic dependencies. Although some approaches utilize multi-scale representation learning to capture inter-series dynamic dependencies at different time scales, they still require additional multi-scale feature fusion modules to output the multi-scale representation of final forecasting results. In this paper, we propose a novel deep learning framework called Graph-Patchformer, which leverages structural encodings to reflect the structural information within MTS while capturing intra-series dependencies and inter-series local dynamic dependencies using the Patch Interaction Blocks we proposed. Specifically, Graph-Patchformer embeds structural encodings into MTS to reflect the inter-series relationships and temporal variations within the MTS. The embedded data is subsequently fed into the Patch Interaction Blocks through a patching operation. Within the Patch Interaction Blocks, the multi-head self-attention mechanism and adaptive graph learning module are employed to capture intra-series dependencies and inter-series local dynamic dependencies. In this way, Graph-Patchformer not only facilitates interactions between different patches within a single series but also enables cross-time-window interactions between patches of different series. The experimental results show that the Graph-Patchformer outperforms the state-of-the-art approaches and exhitits significant forecasting performance compared to several state-of-the-art methods across various real-world benchmark datasets. The code will be available at this repository: https://github.com/houchunyiPhd/Graph-Patchformer/tree/main},
  archive      = {J_NN},
  author       = {Chunyi Hou and Yongchuan Yu and Jinquan Ji and Siyao Zhang and Xumeng Shen and Jianzhuo Yan},
  doi          = {10.1016/j.neunet.2025.108140},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108140},
  shortjournal = {Neural Netw.},
  title        = {Graph-patchformer: Patch interaction transformer with adaptive graph learning for multivariate time series forecasting},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LLM-augmented entity alignment: An unsupervised and training-free framework. <em>NN</em>, <em>194</em>, 108139. (<a href='https://doi.org/10.1016/j.neunet.2025.108139'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity alignment (EA) is a fundamental task in knowledge graph (KG) integration, aiming to identify equivalent entities across different KGs for a unified and comprehensive representation. Recent advances have explored pre-trained language models (PLMs) to enhance the semantic understanding of entities, achieving notable improvements. However, existing methods face two major limitations. First, they rely heavily on human-annotated labels for training, leading to high computational costs and poor scalability. Second, some approaches use large language models (LLMs) to predict alignments in a multi-choice question format, but LLM outputs may deviate from expected formats, and predefined options may exclude correct matches, leading to suboptimal performance. To address these issues, we propose LEA, an LLM-augmented entity alignment framework that eliminates the need for labeled data and enhances robustness by mitigating information heterogeneity at both embedding and semantic levels. LEA first introduces an entity textualization module that transforms structural and textual information into a unified format, ensuring consistency and improving entity representations. It then leverages LLMs to enrich entity descriptions, enhancing semantic distinctiveness. Finally, these enriched descriptions are encoded into a shared embedding space, enabling efficient alignment through text retrieval techniques. To balance performance and computational cost, we further propose a selective augmentation strategy that prioritizes the most ambiguous entities for refinement. Experimental results on both homogeneous and heterogeneous KGs demonstrate that LEA outperforms existing models trained on 30 % labeled data, achieving a 30 % absolute improvement in Hit@1 score. As LLMs and text embedding models advance, LEA is expected to further enhance EA performance, providing a scalable and robust paradigm for practical applications. The code and dataset can be found at https://github.com/Longmeix/LEA .},
  archive      = {J_NN},
  author       = {Meixiu Long and Jiahai Wang and Junxiao Ma and Jianpeng Zhou and Siyuan Chen},
  doi          = {10.1016/j.neunet.2025.108139},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108139},
  shortjournal = {Neural Netw.},
  title        = {LLM-augmented entity alignment: An unsupervised and training-free framework},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Image restoration driven by dual-scale prior. <em>NN</em>, <em>194</em>, 108138. (<a href='https://doi.org/10.1016/j.neunet.2025.108138'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of advanced imaging technologies, the demand for high quality images in various fields has increased. However, image degradation due to noise, data loss, and other factors persistently hinder image quality. Image restoration (IR) is a critical task in computer vision, aiming to recover original images from degraded observations. Traditional non-learning prior based methods offer flexibility and interpretability but often yield sub-optimal results due to limited representational capacity. In contrast, learning prior based counterparts produce superior performance but suffer from over-fitting and poor generalization to unseen degradations. In this paper, we introduce a novel dual-scale prior (DSP) model that integrates the flexibility strength of non-learning prior with the representation power of learning-based prior. Specifically, the DSP model employs a group-scale physical prior, leveraging non-local self-similarity (NSS) for jointly sparse and low-rank approximation. And an image-scale bias-free deep denoising prior for capturing external characteristics. These dual-scale priors complement each other by effectively preserving edges and removing noise, demonstrating robustness across various types of degradation. We then present DSPIR, an effective IR method by incorporating DSP into existing maximum a posteriori (MAP) principle. DSPIR is solved by alternating minimization and alternating direction method of multipliers. Extensive evaluations on both synthetic and real data demonstrate that DSPIR achieves better performance in image denoising and inpainting compared to state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Weimin Yuan and Cai Meng and Xiangzhi Bai},
  doi          = {10.1016/j.neunet.2025.108138},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108138},
  shortjournal = {Neural Netw.},
  title        = {Image restoration driven by dual-scale prior},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph neural networks for fMRI functional brain networks: A survey. <em>NN</em>, <em>194</em>, 108137. (<a href='https://doi.org/10.1016/j.neunet.2025.108137'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of neuroimaging technologies, the development of deep learning-based models for the analysis of mental disorders has become an emerging consensus. Graphs, as a data and relationship representative, can abstract complex brain data, enabling us to systematically and precisely reveal key issues related to brain structure and function with the support of neuroimaging techniques. Graph neural networks (GNNs) provide new tools and methods for brain network analysis, allowing for a deeper exploration of the relationships between functional regions of the brain and potential functional patterns. Therefore, GNN-based methods for brain network analysis are gaining increasing attention. However, there is currently a lack of a comprehensive summary of the latest research approaches in this field from the perspective of computer science. This survey covers functional brain network analysis methods from different dimensions. In addition, for each method, we discuss the corresponding open challenges and unmet needs to identify the limitations and future directions of these methods in brain network research. Finally, to facilitate researchers in selecting and applying appropriate brain network datasets for experimentation and validation, we summarize the characteristics and sources of various brain network analysis datasets.},
  archive      = {J_NN},
  author       = {Jingye Tang and Tianqing Zhu and Wanlei Zhou and Wei Zhao},
  doi          = {10.1016/j.neunet.2025.108137},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108137},
  shortjournal = {Neural Netw.},
  title        = {Graph neural networks for fMRI functional brain networks: A survey},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). WideTopo: Improving foresight neural network pruning through training dynamics preservation and wide topologies exploration. <em>NN</em>, <em>194</em>, 108136. (<a href='https://doi.org/10.1016/j.neunet.2025.108136'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foresight neural network pruning methods have garnered significant attention due to their potential to save computational resources. Recent advancements in this field are predominantly categorized into saliency score-based and graph theory-based methods. The former assesses the sensitivity of pruning parameter connections concerning specific metrics, while the latter aims to identify sub-networks characterized by sparse yet highly connected graph structures. However, recent research suggests that relying exclusively on saliency scores may result in deep but narrow sub-networks, while graph theory-based methods may be unsuitable for neural networks requiring pre-trained parameters for initialization, particularly in transfer learning scenarios. We hypothesize that preserving the training dynamics of sub-networks during pruning, along with exploring network structures with wide topology, can facilitate the identification of structurally stable sub-networks with improved post-training performance. Motivated by this, we propose WideTopo, which integrates Neural Tangent Kernel (NTK) theory with Implicit Target Alignment (ITA) in neural networks to capture the training dynamics of sub-networks. Furthermore, it employs a density-aware saliency score decay strategy and a repeated mask restoration strategy to retain more effective nodes, thereby sustaining the width of each layer within the sub-networks. We conducted extensive validations using CNN-based and ViT-based models on representative image classification and semantic segmentation datasets under both random and pre-trained initialization settings. The effectiveness and applicability of our method have been validated on diverse network architectures at various model density rates, showing competitive post-training performance compared with other existing baselines. Our code is publicly available at https://github.com/Memoristor/WideTopo .},
  archive      = {J_NN},
  author       = {Changjian Deng and Jian Cheng and Yanzhou Su and Zeyu An and Zhiguo Yang and Ziying Xia and Yijie Zhang and Shiguang Wang},
  doi          = {10.1016/j.neunet.2025.108136},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108136},
  shortjournal = {Neural Netw.},
  title        = {WideTopo: Improving foresight neural network pruning through training dynamics preservation and wide topologies exploration},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DePoint: Improving rotation robustness of 3D point cloud analysis via decreasing entropy. <em>NN</em>, <em>194</em>, 108135. (<a href='https://doi.org/10.1016/j.neunet.2025.108135'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world scenarios, achieving rotation robustness in point cloud analysis is crucial due to the unpredictable orientations of 3D objects. While recent advancements in rotation robustness typically rely on auxiliary modules to align rotated objects, precisely aligning object orientations remains challenging given the vast space of possible rotations. In this work, we investigate the impact of rotation on point clouds, revealing that random rotations significantly increase the joint entropy of point clouds and semantic labels—a key factor leading to degraded model performance on rotated datasets. To address this issue, we introduce DePoint, a simple yet effective rotation enhancement method that decreases entropy by aligning the spatial distribution of rotated point cloud representations with semantic information. Specifically, a Siamese point cloud encoder processes differently oriented views of an object with a shared task head, ensuring semantic consistency in the learned representations. A minimal auxiliary classifier enforces linear separability into these representations. Notably, DePoint can be seamlessly integrated into existing point cloud models without introducing additional parameters during inference. Experimental results demonstrate that DePoint significantly enhances the rotation robustness of various point cloud models in 3D object classification and segmentation.},
  archive      = {J_NN},
  author       = {Lu Shi and Gaoyun An and Yigang Cen and Yansen Huang and Fei Gan},
  doi          = {10.1016/j.neunet.2025.108135},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108135},
  shortjournal = {Neural Netw.},
  title        = {DePoint: Improving rotation robustness of 3D point cloud analysis via decreasing entropy},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AAC-GS: Attention-aware adaptive codebook for gaussian splatting compression. <em>NN</em>, <em>194</em>, 108134. (<a href='https://doi.org/10.1016/j.neunet.2025.108134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Radiance Fields (NeRF) have demonstrated remarkable performance in the field of novel view synthesis (NVS). However, their high computational cost limits practical applicability. The 3D Gaussian Splatting (3DGS) method offers a significant improvement in rendering efficiency, enabling real-time rendering through its explicit representations. Nevertheless, its substantial storage requirements pose challenges for complex scenes and resource-constrained devices. Existing methods aim to achieve storage compression through redundant point pruning, spherical harmonics adjustment, and vector quantization. However, point pruning methods often compromise geometric details in complex structures, while vector quantization approaches fail to capture feature relationships effectively, resulting in texture degradation and geometric boundary blurring. Although anchor point representations partially address storage concerns, their sparse representation limits compression efficiency. These limitations become particularly evident in scenes with intricate textures and complex lighting conditions. To ensure optimal compression ratios while maintaining high fidelity in Gaussian scenarios, this paper proposes an Attention-Aware Adaptive Codebook Gaussian Splatting (AAC-GS) method for efficient storage compression. The approach dynamically adjusts the size of the codebook to optimize storage efficiency and incorporates an attention mechanism to capture feature contextual relationships, thereby enhancing reconstruction quality. Additionally, a Generative Adversarial Network (GAN) is employed to mitigate quantization losses, achieving a balance between compression rate and visual fidelity. Experimental results demonstrate that AAC-GS achieves an average compression ratio of approximately 40× while maintaining high reconstruction quality, showcasing its potential for multi-scene applications.},
  archive      = {J_NN},
  author       = {Fang Wan and Jianhang Zhang and Tianyu Li and Guangbo Lei and Li Xu and Zhiwei Ye},
  doi          = {10.1016/j.neunet.2025.108134},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108134},
  shortjournal = {Neural Netw.},
  title        = {AAC-GS: Attention-aware adaptive codebook for gaussian splatting compression},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive knowledge selection in dialogue systems: Accommodating diverse knowledge types, requirements, and generation models. <em>NN</em>, <em>194</em>, 108133. (<a href='https://doi.org/10.1016/j.neunet.2025.108133'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective knowledge-grounded dialogue systems rely heavily on accurate knowledge selection. This paper begins with an innovative new perspective that categorizes research on knowledge selection based on when knowledge is selected in relation to response generation: pre-, joint-, and post-selection. Among these, pre-selection is of great interest nowadays because they endeavor to provide sufficiently relevant knowledge inputs for downstream response generation models in advance. This reduces the burden of learning, adjusting, and interpreting for the subsequent response generation models, particularly for Large Language Models. Current knowledge pre-selection methods, however, still face three significant challenges: how to cope with different types of knowledge, adapt to the various knowledge requirements in different dialogue contexts, and adapt to different generation models. To resolve the above challenges, we propose ASK, an adaptive knowledge pre-selection method. It unifies various types of knowledge, scores their relevance and contribution to generating desired responses, and adapts the knowledge pool size to ensure the optimal amount is available for generation models. ASK is enhanced by leveraging rewards for selecting appropriate knowledge in both quality and quantity, through a reinforcement learning framework. We perform exhaustive experiments on two benchmarks (WoW and OpenDialKG) and get the following conclusions: 1) ASK has excellent knowledge selection capabilities on diverse knowledge types and requirements. 2) ASK significantly enhances the performance of various downstream generation models, including ChatGPT and GPT-4o. 3) The lightweight improvement of ASK saves 40 % of the computational consumption. Code is available at https://github.com/AnonymousCode32213/ASK .},
  archive      = {J_NN},
  author       = {Yao Zhang and Lang Qin and Zhongtian Bao and Hongru Liang and Jun Wang and Zhenglu Yang and Zhe Sun and Andrzej Cichocki},
  doi          = {10.1016/j.neunet.2025.108133},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108133},
  shortjournal = {Neural Netw.},
  title        = {Adaptive knowledge selection in dialogue systems: Accommodating diverse knowledge types, requirements, and generation models},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Self identity mapping. <em>NN</em>, <em>194</em>, 108132. (<a href='https://doi.org/10.1016/j.neunet.2025.108132'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regularization is essential in deep learning to enhance generalization and mitigate overfitting. However, conventional techniques often rely on heuristics, making them less reliable or effective across diverse settings. We propose Self Identity Mapping (SIM), a simple yet effective, data-intrinsic regularization framework that leverages an inverse mapping mechanism to enhance representation learning. By reconstructing the input from its transformed output, SIM reduces information loss during forward propagation and facilitates smoother gradient flow. To address computational inefficiencies, We instantiate SIM as ρ SIM by incorporating patch-level feature sampling and projection-based method to reconstruct latent features, effectively lowering complexity. As a model-agnostic, task-agnostic regularizer, SIM can be seamlessly integrated as a plug-and-play module, making it applicable to different network architectures and tasks. We extensively evaluate ρ SIM across three tasks: image classification, few-shot prompt learning, and domain generalization. Experimental results show consistent improvements over baseline methods, highlighting ρ SIM ’s ability to enhance representation learning across various tasks. We also demonstrate that ρ SIM is orthogonal to existing regularization methods, boosting their effectiveness. Moreover, our results confirm that ρ SIM effectively preserves semantic information and enhances performance in dense-to-dense tasks, such as semantic segmentation and image translation, as well as in non-visual domains including audio classification and time series anomaly detection.},
  archive      = {J_NN},
  author       = {Xiuding Cai and Yaoyao Zhu and Linjie Fu and Dong Miao and Yu Yao},
  doi          = {10.1016/j.neunet.2025.108132},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108132},
  shortjournal = {Neural Netw.},
  title        = {Self identity mapping},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Metacognition for unknown situations and environments (MUSE). <em>NN</em>, <em>194</em>, 108131. (<a href='https://doi.org/10.1016/j.neunet.2025.108131'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metacognition, defined as the awareness and regulation of one’s cognitive processes, is central to human adaptability in unknown situations. In contrast, current autonomous agents often struggle in novel environments due to their limited capacity for adaptation. We hypothesize that metacognition is a critical missing ingredient in autonomous agents for the cognitive flexibility needed to tackle unfamiliar challenges. Given the broad scope of metacognitive abilities, we focus on competence awareness and strategy selection. To this end, we propose the Metacognition for Unknown Situations and Environments (MUSE) framework to integrate metacognitive processes of self-assessment and self-regulation into autonomous agents. We present two implementations of MUSE: one based on world modeling and another leveraging large language models (LLMs). Our system continually learns to assess its competence on a given task and uses this self-assessment to guide iterative cycles of strategy selection. MUSE agents demonstrate high competence awareness and significant improvements in self-regulation for solving novel, out-of-distribution tasks more effectively compared to model-based reinforcement learning and purely prompt-based LLM agent approaches. This work highlights the promise of approaches inspired by cognitive and neural systems in enabling autonomous agents to adapt to new environments while mitigating the heavy reliance on extensive training data and large models for the current models.},
  archive      = {J_NN},
  author       = {Rodolfo Valiente and Praveen K. Pilly},
  doi          = {10.1016/j.neunet.2025.108131},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108131},
  shortjournal = {Neural Netw.},
  title        = {Metacognition for unknown situations and environments (MUSE)},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fixed-time learning-based optimal tracking control for robotic systems with prescribed performance constraints. <em>NN</em>, <em>194</em>, 108130. (<a href='https://doi.org/10.1016/j.neunet.2025.108130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a fixed-time learning-based dynamic event-triggered control framework to address the optimal tracking control problem in robotic systems with the prescribed performance constraints. In many practical scenarios, the states of robotic systems are often subject to performance constraints imposed by structural characteristics and task requirements. To address this issue, prescribed performance control (PPC) theory is employed to ensure performance state constraints and construct an unconstrained tracking error system. Subsequently, a critic-only adaptive dynamic programming (ADP) control framework is designed to approximate the optimal control law for the transformed unconstrained system. Furthermore, in the design of critic neural network (NN), a novel fixed-time convergence (FTC) weight update law based on concurrent learning (CL) techniques is proposed, which guarantees the fixed-time convergence of weight estimation error under relaxed persistent excitation (PE) condition. Throughout the controller design, a dynamic event-triggered mechanism is adopted to reduce the number of sampling instances and computational resources. Meanwhile, the stability of the closed-loop system under this mechanism is rigorously proven. Finally, the effectiveness of the proposed method is demonstrated through simulation results and comparative analysis.},
  archive      = {J_NN},
  author       = {Zhinan Peng and Xingyu Zhang and Zhuo Xia and Lin Hao and Linpu He and Hong Cheng},
  doi          = {10.1016/j.neunet.2025.108130},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108130},
  shortjournal = {Neural Netw.},
  title        = {Fixed-time learning-based optimal tracking control for robotic systems with prescribed performance constraints},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CSTSINR: Improving temporal continuity via convolutional structured implicit neural representations for time series anomaly detection. <em>NN</em>, <em>194</em>, 108129. (<a href='https://doi.org/10.1016/j.neunet.2025.108129'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection plays a crucial role in identifying significant deviations from expected behavior. Implicit Neural Representation (INR) has been explored for time series modeling due to its ability to learn continuous functions. The inherent spectral bias of INRs, which prioritizes low-frequency signal fitting, further enables the detection of high-frequency anomalies. However, current INR-based approaches demonstrate limited capability in representing complex temporal patterns, particularly when the normal data itself contains significant high-frequency components. To address these challenges, we propose CSTSINR, a novel anomaly detection model that integrates the structured feature map and convolutional mechanisms with the INR continuous function. By leveraging a structured feature map and convolutional layers, CSTSINR addresses the limitations of directive prediction of all parameters and point-wise query processing, providing improved modeling of temporal continuity and enhanced anomaly detection. Our extensive experiments demonstrate that CSTSINR outperforms existing state-of-the-art methods across ten benchmark datasets, highlighting its superior ability to detect anomalies, particularly in high-frequency or complex time series data.},
  archive      = {J_NN},
  author       = {Ke Liu and Mengxuan Li and Jiajun Bu and Hongwei Wang and Haishuai Wang},
  doi          = {10.1016/j.neunet.2025.108129},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108129},
  shortjournal = {Neural Netw.},
  title        = {CSTSINR: Improving temporal continuity via convolutional structured implicit neural representations for time series anomaly detection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MDSFD-net: Alzheimer’s disease diagnosis with missing modality via disentanglement learning and feature distillation. <em>NN</em>, <em>194</em>, 108128. (<a href='https://doi.org/10.1016/j.neunet.2025.108128'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal analysis can provide complementary information and significantly aid in the early diagnosis and intervention of Alzheimer’s Disease (AD). However, the issue of missing modalities presents a major challenge, as most methods that rely on complete multi-modal data become infeasible. The most advanced approaches to addressing missing modalities typically use generative models, but these often neglect the importance of modality-specific features, leading to biased predictions and poor performance. Inspired by this limitation, we propose a Modality Disentanglement and Specific Features Distillation Network (MDSFD-Net) for AD diagnosis with missing modality, which consists of a disentanglement-based imputation module (DI module) and a specific features distillation module (SFD module). In the DI module, we introduce a novel spatial-channel modality disentanglement learning scheme that is first used to disentangle modality-specific features, along with a shared constrain objective to learn modality-shared features, which are used for imputing missing modality features. To address the specific features of the missing modality, the SFD module is designed to transfer the specific features from complete modality in the teacher network to the incomplete modality in the student network. A regularized knowledge distillation (R-KD) mechanism is incorporated to mitigate the impact of incorrect predictions from the teacher network. By leveraging modality-shared features imputation and modality-specific features distillation, our model can effectively learn sufficient information for classification even if some modalities are missing. Extensive experiments on ADNI dataset demonstrate the superiority of our proposed MDSFD-Net over state-of-the-art methods in missing modality situations.},
  archive      = {J_NN},
  author       = {Nana Jia and Zhiao Zhang and Tong Jia},
  doi          = {10.1016/j.neunet.2025.108128},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108128},
  shortjournal = {Neural Netw.},
  title        = {MDSFD-net: Alzheimer’s disease diagnosis with missing modality via disentanglement learning and feature distillation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spiking neural networks for EEG signal analysis: From theory to practice. <em>NN</em>, <em>194</em>, 108127. (<a href='https://doi.org/10.1016/j.neunet.2025.108127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intricate and efficient information processing of the human brain, driven by spiking neural interactions, has led to the development of spiking neural networks (SNNs) as a cutting-edge neural network paradigm. Unlike traditional artificial neural networks (ANNs) that use continuous values, SNNs emulate the brain’s spiking mechanisms, offering enhanced temporal information processing and computational efficiency. This review addresses the critical gap between theoretical advancements and practical applications of SNNs in EEG signal analysis. We provide a comprehensive examination of recent SNN methodologies and their application to EEG signals, highlighting their potential benefits over conventional deep learning approaches. The review encompasses foundational knowledge of SNNs, detailed implementation strategies for EEG analysis, and challenges inherent to SNN-based methods. Practical guidance is provided through step-by-step instructions and accessible code available on GitHub, aimed at facilitating researchers’ adoption of these techniques. Additionally, we explore emerging trends and future research directions, emphasizing the potential of SNNs to advance brain-computer interfaces and neurofeedback systems. This paper serves as a valuable resource for bridging the gap between theoretical developments in SNNs and their practical implementation in EEG signal analysis.},
  archive      = {J_NN},
  author       = {Siqi Cai and Zheyuan Lin and Xiaoli Liu and Wenjie Wei and Shuai Wang and Malu Zhang and Tanja Schultz and Haizhou Li},
  doi          = {10.1016/j.neunet.2025.108127},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108127},
  shortjournal = {Neural Netw.},
  title        = {Spiking neural networks for EEG signal analysis: From theory to practice},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Energy-based diffusion generator for efficient sampling of boltzmann distributions. <em>NN</em>, <em>194</em>, 108126. (<a href='https://doi.org/10.1016/j.neunet.2025.108126'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sampling from Boltzmann distributions, particularly those tied to high dimensional and complex energy functions, poses a significant challenge in many fields. In this work, we present the Energy-Based Diffusion Generator (EDG), a novel approach that integrates ideas from variational autoencoders and diffusion models. EDG uses a decoder to generate Boltzmann-distributed samples from simple latent variables, and a diffusion-based encoder to estimate the Kullback-Leibler divergence to the target distribution. Notably, EDG is simulation-free, eliminating the need to solve ordinary or stochastic differential equations during training. Furthermore, by removing constraints such as bijectivity in the decoder, EDG allows for flexible network design. Through empirical evaluation, we demonstrate the superior performance of EDG across a variety of sampling tasks with complex target distributions, outperforming existing methods.},
  archive      = {J_NN},
  author       = {Yan Wang and Ling Guo and Hao Wu and Tao Zhou},
  doi          = {10.1016/j.neunet.2025.108126},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108126},
  shortjournal = {Neural Netw.},
  title        = {Energy-based diffusion generator for efficient sampling of boltzmann distributions},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TGSL: Trade-off graph structure learning via multifaceted graph information bottleneck. <em>NN</em>, <em>194</em>, 108125. (<a href='https://doi.org/10.1016/j.neunet.2025.108125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are prominent for their effectiveness in processing graph-structured data for semi-supervised node classification tasks. Most existing GNNs perform message passing directly based on the observed graph structure. However, in real-world scenarios, the observed structure is often suboptimal due to multiple factors, significantly degrading the performance of GNNs. To address this challenge, we first conduct an empirical analysis showing that different graph structures significantly impact empirical risk and classification performance. Motivated by our observations, we propose a novel method named T rade-off G raph S tructure L earning (TGSL), guided by the multifaceted Graph Information Bottleneck (GIB) principle based on Mutual Information (MI). The key idea behind TGSL is to learn a minimal sufficient graph structure that minimizes empirical risk while maintaining performance. Specifically, we introduce global feature augmentation to capture the structural roles of nodes, and global structure augmentation to uncover global relationships between nodes. The augmented graphs are then processed by structure estimators with different parameters for refinement and redefinition, respectively. Additionally, we innovatively leverage multifaceted GIB as the optimization objective by maximizing the MI between the labels and the representation derived from the final structure, while constraining the MI between this representation and that based on the redefined structures. This trade-off helps avoid capturing irrelevant information from the redefined structures and enhances the final representation for node classification. We conduct extensive experiments across a range of datasets under clean and attacked conditions. The results demonstrate the outstanding performance and robustness of TGSL over state-of-the-art baselines.},
  archive      = {J_NN},
  author       = {Shuangjie Li and Baoming Zhang and Jianqing Song and Gaoli Ruan and Chongjun Wang and Junyuan Xie},
  doi          = {10.1016/j.neunet.2025.108125},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108125},
  shortjournal = {Neural Netw.},
  title        = {TGSL: Trade-off graph structure learning via multifaceted graph information bottleneck},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improving few-shot relation classification with multi-scale hierarchical prototype learning. <em>NN</em>, <em>194</em>, 108124. (<a href='https://doi.org/10.1016/j.neunet.2025.108124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot relation classification aims to distinguish different relation classes from extremely limited annotated data. Most existing methods primarily use prototype networks to construct a prototypical representation, classifying the instance by comparing its similarity to each prototype. Despite achieving promising results, the prototypes derived solely from limited support instances are often inaccurate due to constraints in feature extraction capabilities. Moreover, they ignore the different hierarchical levels of relational information, which can provide more effective guidance for classification. In this paper, we propose a novel m ulti-sc a le hie r arch i cal pr o totype (Mario) learning method that captures relational interaction information at three levels: inter-set, inter-class and intra-class, enhancing the model’s understanding of global semantic information and helping it distinguish subtle differences between classes. Additionally, we incorporate relational descriptive information to reduce the impact of textual expression diversity, enabling the model to emulate the human cognitive process in understanding variation. Extensive experiments conduct on the FewRel dataset demonstrate the effectiveness of our proposed model. In particular, it achieves accuracy rates of 92.52 %/95.33 %/85.46 %/91.33 % under four common few-shot settings. Notably, in the critical 5-way and 10-way 1-shot settings, it outperforms the strongest baseline by 2.87 % and 4.29 %.},
  archive      = {J_NN},
  author       = {Haijia Bi and Lu Liu and Hai Cui and Shengyue Liu and Ridong Han and Jiayu Han and Tao Peng},
  doi          = {10.1016/j.neunet.2025.108124},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108124},
  shortjournal = {Neural Netw.},
  title        = {Improving few-shot relation classification with multi-scale hierarchical prototype learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Planning forward: Deep incremental hashing by gradually defrosting bits. <em>NN</em>, <em>194</em>, 108123. (<a href='https://doi.org/10.1016/j.neunet.2025.108123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep incremental hashing can generate hash codes incrementally for new classes, while keeping the existing ones unchanged. Existing methods typically allocate fixed code lengths to all classes, causing the entire Hamming space occupied by existing classes, thus failing to prepare models for future extensions. This significantly limits the ability to effectively accommodate new classes. Beyond that, it is inefficient in computation and storage to use all bits for encoding a few classes in the early sessions. This paper presents B it D efrosting Deep I ncremental H ashing (BDIH) to tackle these problems. Our key insight is to map the classes into a small subspace by freezing most hash bits during the first session, which reserves adequate space for future classes. This allows subsequent sessions to map new classes into progressively expanding subspaces by defrosting a portion of the frozen bits. Specifically, we propose a bit-defrosting code learning framework, which includes a bit-defrosting center generation part and a center-based bit-defrosting code learning part. The former part generates hash centers as learning objectives in expanding subspaces while the latter part learns globally discriminative hash codes with the guidance of hash centers and preserves the backward compatibility between the updated model and previously stored codes. As a result, our method achieves comparable performance on old classes using fewer bits while reserving more space for new ones. Extensive experiments demonstrate that BDIH outperforms existing methods regarding retrieval accuracy and storage efficiency in long-sequence incremental learning scenarios.},
  archive      = {J_NN},
  author       = {Qinghang Su and Dayan Wu and Chenming Wu and Bo Li and Weiping Wang},
  doi          = {10.1016/j.neunet.2025.108123},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108123},
  shortjournal = {Neural Netw.},
  title        = {Planning forward: Deep incremental hashing by gradually defrosting bits},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Contrastive learning unlocks geometric insights for dataset pruning. <em>NN</em>, <em>194</em>, 108122. (<a href='https://doi.org/10.1016/j.neunet.2025.108122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dataset pruning aims at selecting a subset of the data so that the model trained on the subset performs comparably to the one trained on the full dataset. In the era of big data, unsupervised pruning of the dataset can alleviate the issue of the expensive labeling process from the beginning. Existing methods sort and select instances by well-designed importance metrics, while the unsupervised ones commonly regard representation learning as a black box employed to get embeddings, with its properties remaining insufficiently explored for dataset pruning. In this study, we revisit self-supervised Contrastive Learning by observing the learned embedding manifold, introducing Curvature Estimation to characterize the geometrical properties of the manifold. The statistical results reveal that the embedding distribution of instances on manifold surfaces is not uniform. Based on this observation, we propose an unsupervised dataset pruning strategy by performing downsampling in geometric areas with high instance density, namely KITTY sampling. Extensive experiments demonstrate that our proposed methods have achieved leading performances on CV dataset pruning compared to the baselines. Code is available at https://github.com/Frostland12138/KITTY .},
  archive      = {J_NN},
  author       = {Hongjia Xu and Sheng Zhou and Zhuonan Zheng and Ning Ma and Jiawei Chen and Jiajun Bu},
  doi          = {10.1016/j.neunet.2025.108122},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108122},
  shortjournal = {Neural Netw.},
  title        = {Contrastive learning unlocks geometric insights for dataset pruning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tacit mechanism: Bridging pre-training of individuality to multi-agent adversarial coordination. <em>NN</em>, <em>194</em>, 108121. (<a href='https://doi.org/10.1016/j.neunet.2025.108121'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To tackle the multi-agent adversarial coordination problem, current multi-agent reinforcement learning (MARL) algorithms primarily depend on team-based rewards to update agent policies. However, they do not fully exploit the spatial relationships and their variant trends, thereby limiting overall performance. Inspired by human tactics, we propose the concept of tacit behavior to enhance the efficiency of multi-agent reinforcement learning through the refinement of the learning process. This paper introduces a novel two-phase framework to learn P re-trained T acit B ehavior for efficient multi-agent adversarial C oordination ( PTBC ). The framework consists of a tacit pre-training phase and a centralized adversarial training phase. For pre-training the tacit behaviors, we develop a pattern mechanism and a tacit mechanism to integrate spatial relationships among agents, which dynamically guide agents’ actions to gain spatial advantages for coordination. In the subsequent centralized adversarial training phase, we utilize the pre-trained network to enhance the formation of advantageous spatial positioning, achieving more efficient learning performance. Our experimental results in the predator-prey and StarCraft Multi-Agent Challenge (SMAC) environments demonstrate the effectiveness of our method through comparisons with several algorithms exhibiting distinct strengths. Additionally, by visualizing the agents’ performance in adversarial tasks, we validate that incorporating inter-agent relationships enables agents with pre-trained tacit behavior to achieve more advantageous coordination. Extensive ablation studies demonstrate the critical role of tacit guidance and the general applicability of the PTBC framework.},
  archive      = {J_NN},
  author       = {Shiqing Yao and Jiajun Chai and Haixin Yu and Yongzhe Chang and Tiantian Zhang and Yuanheng Zhu and Xueqian Wang},
  doi          = {10.1016/j.neunet.2025.108121},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108121},
  shortjournal = {Neural Netw.},
  title        = {Tacit mechanism: Bridging pre-training of individuality to multi-agent adversarial coordination},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Offline-to-online reinforcement learning with efficient unconstrained fine-tuning. <em>NN</em>, <em>194</em>, 108120. (<a href='https://doi.org/10.1016/j.neunet.2025.108120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning provides the capability to learn a policy only from pre-collected datasets, but its performance is often limited by the quality of the offline dataset and the coverage of the state-action space. Offline-to-online reinforcement learning is promising to address these limitations and achieve high sample efficiency by integrating the advantages of both offline and online learning paradigms. However, existing methods typically struggle to adapt to online learning and improve the performance of pre-trained policies due to the distributional shift and conservative training. To address these issues, we propose an efficient unconstrained fine-tuning framework that removes conservative constraints on the policy during fine-tuning, allowing thorough exploration of state-action pairs not covered by the offline data. This framework leverages three key techniques: dynamics representation learning, layer normalization, and increasing the update frequency of the value network to improve sample efficiency and mitigate value function estimation bias caused by the distributional shift. Dynamics representation learning accelerates fine-tuning by capturing meaningful features, layer normalization bounds Q -value to suppress catastrophic value function divergence, and increasing the update frequency of the value network enhances the sample efficiency and reduces value function estimation bias. Extensive experiments on the D4RL benchmark demonstrate that our algorithm outperforms state-of-the-art offline-to-online reinforcement learning algorithms across various tasks with minimal online interactions.},
  archive      = {J_NN},
  author       = {Jun Zheng and Runda Jia and Shaoning Liu and Ranmeng Lin and Dakuo He and Fuli Wang},
  doi          = {10.1016/j.neunet.2025.108120},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108120},
  shortjournal = {Neural Netw.},
  title        = {Offline-to-online reinforcement learning with efficient unconstrained fine-tuning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AutoSGRL: Automated framework construction for self-supervised graph representation learning. <em>NN</em>, <em>194</em>, 108119. (<a href='https://doi.org/10.1016/j.neunet.2025.108119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated machine learning (AutoML) is a promising solution for building a machine learning framework without human assistance and has attracted significant attention throughout the computational intelligence research community. Although there has been an emerging interest in graph neural architecture search, current research focuses on the specific design of semi-supervised or supervised graph neural networks. Motivated by this, we propose a novel method that enables the automatic construction of flexible self-supervised graph representation learning frameworks for the first time as far as we know, referred to as AutoSGRL. Based on existing self-supervised graph contrastive learning methods, AutoSGRL establishes a framework search space for self-supervised graph representation learning, which encompasses data augmentation strategies and proxy tasks for constructing graph contrastive learning frameworks, and the hyperparameters required for model training. Then, we implement an automatic search engine based on genetic algorithms, which constructs multiple self-supervised graph representation learning frameworks as the initial population. By simulating the process of biological evolution including selection, crossover, and mutation, the search engine iteratively evolves the population to identify high-performed frameworks and optimal hyperparameters. Empirical studies demonstrate that our AutoSGRL achieves comparative or even better performance than state-of-the-art manual-designed self-supervised graph representation learning methods and semi-supervised graph neural architecture search methods.},
  archive      = {J_NN},
  author       = {Yu Xie and Yu Chang and Ming Li and A.K. Qin and Xialei Zhang},
  doi          = {10.1016/j.neunet.2025.108119},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108119},
  shortjournal = {Neural Netw.},
  title        = {AutoSGRL: Automated framework construction for self-supervised graph representation learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation. <em>NN</em>, <em>194</em>, 108118. (<a href='https://doi.org/10.1016/j.neunet.2025.108118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vascular morphology plays a crucial role in diagnosing diseases such as diabetes, glaucoma, and hypertension, making accurate segmentation of retinal vessels essential for early intervention. Traditional segmentation methods assume that training and testing data share similar distributions, which can lead to poor performance on unseen domains due to domain shifts caused by variations in imaging devices and patient demographics. This paper presents a novel approach, DGSSA, for retinal vessel image segmentation that enhances model generalization by combining structural and stylistic augmentation strategies. We utilize a space colonization algorithm to generate diverse vascular-like structures that closely mimic actual retinal vessels, which are then used to generate pseudo-retinal images with an improved Pix2Pix model, allowing the segmentation model to learn a broader range of structure distributions. Additionally, we utilize PixMix to apply random photometric augmentations and introduce uncertainty perturbations, enriching the stylistic diversity of fundus images and further improving the model’s robustness and generalization across varying imaging conditions. Our framework, which employs a DeepLabv3+ model with a MobileNetV2 backbone as its segmentation network, has been rigorously evaluated on four challenging datasets—DRIVE, CHASEDB1, HRF, and STARE—achieving Dice Similarity Coefficient (DSC) of 78.45%, 78.62%, 72.66% and 82.17%, respectively, with an average DSC of 77.98%. These results demonstrate that our method surpasses existing approaches, validating its effectiveness and highlighting its potential for clinical application in automated retinal vessel analysis.},
  archive      = {J_NN},
  author       = {Bo Liu and Yudong Zhang and Shuihua Wang and Siyue Li and Jin Hong},
  doi          = {10.1016/j.neunet.2025.108118},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108118},
  shortjournal = {Neural Netw.},
  title        = {DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ToBaFu: Topology-based fusion model for classification of two-dimensional cancer images. <em>NN</em>, <em>194</em>, 108117. (<a href='https://doi.org/10.1016/j.neunet.2025.108117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical images play a pivotal role in disease diagnosis. Numerous studies on cancer image analysis focus on end-to-end deep neural networks, neglecting the analysis of global topological features in images. In cancer diagnosis, pathological images frequently display structures like holes or loops that are absent in healthy images, highlighting the benefits of topological analysis of images. In our study, we employ persistent homology (PH) to extract topological features from two-dimensional cancer images. Then, we propose a topology-based model (Topo) for image classification by implementing a shallow neural module following the feature extraction. More importantly, we integrate the Topo model with an end-to-end enhanced ResNet architecture to develop a novel topology-based fusion model (ToBaFu), aimed at enhancing diagnostic performance and model robustness. The proposed ToBaFu model achieves remarkable performance across three cancer image datasets: 99.98 % accuracy and F1-score on the LC-25000 lung and colon cancer histopathological dataset, 99.60 % accuracy and F1-score on the CRC-5000 colorectal cancer histological dataset, and 99.80 % accuracy with 99.83 % F1-score on the BUS-250 breast ultrasound dataset.},
  archive      = {J_NN},
  author       = {Yuqing Xing and Haodong Chen and Quan Zheng},
  doi          = {10.1016/j.neunet.2025.108117},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108117},
  shortjournal = {Neural Netw.},
  title        = {ToBaFu: Topology-based fusion model for classification of two-dimensional cancer images},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LCA-med: A lightweight cross-modal adaptive feature processing module for detecting imbalanced medical image distribution. <em>NN</em>, <em>194</em>, 108116. (<a href='https://doi.org/10.1016/j.neunet.2025.108116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data distribution discrepancy across datasets is one of the major obstacles hindering the improvement of the accuracy of cross-domain adaptive detection of medical images. To address this challenge, we propose a novel lightweight cross-modal adaptive detection module named LCA-Med (LCaM). The proposed module boasts a lightweight structure and a minimalistic parameter count, thereby facilitating its integration into the anterior segment of a diverse array of foundational and downstream networks. It is adept at serving as a feature preprocessor, proficiently extracting pertinent information regrading pathologies from a array of images (image modality) produced through varied medical imaging techniques, all guided by the input of prompts (text modality). We also propose a novel cross-modal medical image adaptive detection method, LCA-Med CNX (LCaM-CNX), and a novel cross-domain adaptive detection training paradigm that incorporates generated dataset groups, an attention module, and a meta-heuristic algorithm. Experimental results on six medical image datasets compared with ten state-of-the-art methods demonstrate that the LCaM-CNX trained following the proposed paradigm achieves the best performance on five datasets and competitive performance on the other dataset. Notably, our method outperforms the state-of-the-art methods more when the data distribution is more imbalanced.},
  archive      = {J_NN},
  author       = {Xiang Li and Long Lan and Husam Lahza and Shaowu Yang and Shuihua Wang and Yong Liang and Hudan Pan and Wenjing Yang and Hengzhu Liu and Yudong Zhang},
  doi          = {10.1016/j.neunet.2025.108116},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108116},
  shortjournal = {Neural Netw.},
  title        = {LCA-med: A lightweight cross-modal adaptive feature processing module for detecting imbalanced medical image distribution},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Counterfactual causal inference for robust visual question answering. <em>NN</em>, <em>194</em>, 108115. (<a href='https://doi.org/10.1016/j.neunet.2025.108115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question Answering (VQA) systems have seen remarkable progress with the incorporation of multimodal data. However, their performance is still hampered by biases ingrained in language and vision modalities, frequently resulting in subpar generalization. In this study, we introduce a novel counterfactual causal framework (CC-VQA). This framework utilizes Counterfactual Sample Synthesis (CSS) and causal inference to tackle cross-modality biases. Our approach innovatively employs a strategy based on causal graphs, which effectively disentangles spurious correlations in multimodal data. This ensures a balanced and precise multimodal reasoning process, enabling the model to make more accurate and unbiased decisions. Moreover, we propose a contrastive loss mechanism. By contrasting the embeddings of positive and negative samples, this mechanism significantly enhances the robustness of VQA models. Additionally, we develop a robust training strategy that improves both the visual-explainable and question-sensitive capabilities of these models. Our experimental evaluations on benchmark datasets, such as VQA-CP v2 and VQA v2, demonstrate substantial improvements in bias mitigation and overall accuracy. The proposed CC-VQA framework outperforms state-of-the-art methods, highlighting its effectiveness in enhancing the performance of VQA systems.},
  archive      = {J_NN},
  author       = {Wei Li and Zhixin Li and Fuyun Deng and Kun Zeng and Canlong Zhang},
  doi          = {10.1016/j.neunet.2025.108115},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108115},
  shortjournal = {Neural Netw.},
  title        = {Counterfactual causal inference for robust visual question answering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A domain-specific cross-lingual semantic alignment learning model for low-resource languages. <em>NN</em>, <em>194</em>, 108114. (<a href='https://doi.org/10.1016/j.neunet.2025.108114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-lingual semantic alignment models facilitate the sharing and utilization of multilingual domain-specific data (e.g., medical, legal), offering cost-effective solutions for improving low-resource language tasks. However, existing methods are challenged by parallel data scarcity, semantic space heterogeneity, morphological complexity, and weak robustness-particularly for agglutinative languages. Therefore, this paper proposes CLWKD, a cross-lingual mapping and knowledge distillation framework. CLWKD leverages domain-specific pretrained models from high-resource languages as teachers and integrates multi-granularity alignment matrices with limited parallel data to guide cross-lingual knowledge transfer. CLWKD jointly learns multi-granularity semantic alignment mapping matrices at the token, word, and sentence levels from general-domain data. It eases domain data scarcity and helps bridge structural gaps caused by morphological and syntactic differences. To alleviate data sparsity and out-of-vocabulary issues in agglutinative languages, multilingual embedding sharing and morphological segmentation strategies are introduced. To improve the stability of unsupervised mapping training, generator pretraining is introduced and further combined with high-confidence word and sentence pairs to optimize the mapping matrix.To preserve alignment with fewer parameters, a parameter recycling and embedding bottleneck design is adopted. Experiments across the medical, legal, and educational domains on Mongolian-Chinese and Korean-Chinese language pairs demonstrate the effectiveness of CLWKD in three cross-lingual tasks.},
  archive      = {J_NN},
  author       = {Yurong Wang and Min Lin and Qitu Hu and Shuangcheng Bai and Yanling Li and Longjie Bao},
  doi          = {10.1016/j.neunet.2025.108114},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108114},
  shortjournal = {Neural Netw.},
  title        = {A domain-specific cross-lingual semantic alignment learning model for low-resource languages},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Inference of hidden common driver dynamics by anisotropic self-organizing neural networks. <em>NN</em>, <em>194</em>, 108113. (<a href='https://doi.org/10.1016/j.neunet.2025.108113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the Anisotropic Self-Organizing Map (ASOM), a novel neural network-based approach for inferring hidden common drivers in nonlinear dynamical systems from observed time series. Grounded in topological theorems, our method integrates time-delay embedding, intrinsic dimension estimation, and a new anisotropic training scheme for Kohonen’s self-organizing map, enabling the precise decomposition of attractor manifolds into autonomous and shared components of the dynamics. We validated ASOM through simulations involving chaotic maps, where two driven systems were influenced by a hidden nonlinear driver. The inferred time series showed a strong correlation with the actual hidden common driver, unlike the observed systems. We further compared our reconstruction performance against several established methods for identifying shared features in time series, including PCA, kernel PCA, ICA, dynamical component analysis, canonical correlation analysis, deep canonical correlation analysis, traditional self-organizing map, and recent recurrence-based approaches. Our results demonstrate ASOM’s superior accuracy and robustness in recovering latent dynamics, providing a powerful tool for unsupervised learning of hidden causal structures in complex systems.},
  archive      = {J_NN},
  author       = {Zsigmond Benkő and Marcell Stippinger and Attila Bencze and Fülöp Bazsó and András Telcs and Zoltán Somogyvári},
  doi          = {10.1016/j.neunet.2025.108113},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108113},
  shortjournal = {Neural Netw.},
  title        = {Inference of hidden common driver dynamics by anisotropic self-organizing neural networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the theoretical expressive power of graph transformers for solving graph problems. <em>NN</em>, <em>194</em>, 108112. (<a href='https://doi.org/10.1016/j.neunet.2025.108112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Transformers have become the dominant neural architecture in the fields of natural language processing and computer vision. The generalization of Transformers to graphs, so-called Graph Transformers, have recently emerged as a promising alternative to the successful message passing Graph Neural Networks (MPNNs). While the expressive power of MPNNs has been intensively studied in the past years, that of Graph Transformers is still underexplored. Existing results mostly rely on the employed structural/positional encodings and not on the pure architecture itself. However, gaining an understanding of the strengths and limitations of Graph Transformers would be very useful both for the scientific community and the practitioners. In this paper, we derive a connection between Graph Transformers and the Congested clique , a popular model in distributed computing. This connection allows us to translate theoretical results for different graph problems from the latter to the former. We show that under certain conditions, Graph Transformers with depth 2 are Turing universal. We also show that there exist Graph Transformers that can solve problems which cannot be solved by MPNNs. We empirically investigate whether Graph Transformers and MPNNs with depth 2 can solve graph problems on some molecular datasets. Our results demonstrate that Graph Transformers can generally address the underlying tasks, while MPNNs are incapable of learning any information about the graph.},
  archive      = {J_NN},
  author       = {Giannis Nikolentzos and Dimitrios Kelesis and Michalis Vazirgiannis},
  doi          = {10.1016/j.neunet.2025.108112},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108112},
  shortjournal = {Neural Netw.},
  title        = {On the theoretical expressive power of graph transformers for solving graph problems},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A biologically plausible model of astrocyte-neuron networks in random and hub-driven connectivity. <em>NN</em>, <em>194</em>, 108111. (<a href='https://doi.org/10.1016/j.neunet.2025.108111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research studies in brain neural networks are highlighting the involvement of glial cells, in particular astrocytes, in synaptic modulation, memory formation, and neural synchronization, a role that has often been overlooked. Thus, theoretical models have begun incorporating astrocytes to better understand their functional impact. Additionally, the structural organization of neuron-neuron, astrocyte-neuron and astrocyte-astrocyte connections plays a crucial role in network dynamics. Starting from a recently published astrocyte-neuron network model with neuron-neuron random connectivity, we provide an extensive evaluation of this same model, focusing on astrocytic dynamics, neuron-astrocyte connectivity, and spatial distribution of inhibitory neurons. We propose refinements to the model with the aim of improving the biological plausibility of the above described characteristics of the model. To assess the interplay between astrocytes and network topology, we compare four configurations: neural networks with and without astrocytes, each under random and hub-driven connectivity. Simulations are conducted using the Brian2 simulator, providing insights into how astrocytes and structural heterogeneity jointly influence neural dynamics. Our findings contribute to a deeper understanding of neuron-glia interactions and the impact of network topology on astrocyte-neuron network dynamics. In particular, while finding an expected decrease of neural firing activity due to astrocyte calcium dynamics, we also found that hub-driven topology trigger a much higher firing rate with respect to the random topology, even having this last one a much higher number of neuron-neuron connections.},
  archive      = {J_NN},
  author       = {Giulia Salzano and Paolo Paradisi and Enrico Cataldo},
  doi          = {10.1016/j.neunet.2025.108111},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108111},
  shortjournal = {Neural Netw.},
  title        = {A biologically plausible model of astrocyte-neuron networks in random and hub-driven connectivity},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MAN-GNN: An interpretable biomarker architecture for neurodevelopmental disorders. <em>NN</em>, <em>194</em>, 108110. (<a href='https://doi.org/10.1016/j.neunet.2025.108110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurodevelopmental disorders exhibit highly similar behavioral characteristics in clinical assessments, heavily relying on subjective behavioral reports, leading to insufficient understanding of the neurobiological mechanisms behind inter-patient heterogeneity and symptom overlap between diseases. To address this issue, this study proposes a graph neural network framework that integrates neuroimaging data, focusing on three key problems: Firstly, enhance the nonlinear features in brain neural activity by introducing the Neurodynamics Rössler system. Transform raw static neural signals into simulated signals with nonlinear, temporal, and dynamic features, thereby more accurately reflecting the process of brain neural activity. Secondly, improve feature discrimination by integrating the spatial adjacency characteristics of local brain regions with the topological structure information of the global brain network to highlight key features. Thirdly, improve noise resistance and generalization ability. Introducing adaptive controllers and cross-site adversarial learning mechanisms, the interference of heterogeneous noise is effectively reduced. This study conducted experimental validation on data from neurodevelopmental disorders such as ADHD and ASD. The results indicate that this framework not only has advantages in classification accuracy but also possesses good interpretability, making it a promising tool for imaging biomarker research and auxiliary diagnosis.},
  archive      = {J_NN},
  author       = {Qiulei Han and Hongbiao Ye and Miaoshui Bai and Lili Wang and Yan Sun and Ze Song and Jian Zhao and Lijuan Shi and Zhejun Kuang},
  doi          = {10.1016/j.neunet.2025.108110},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108110},
  shortjournal = {Neural Netw.},
  title        = {MAN-GNN: An interpretable biomarker architecture for neurodevelopmental disorders},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). State-flipped control design for the stabilization of probabilistic boolean control networks. <em>NN</em>, <em>194</em>, 108109. (<a href='https://doi.org/10.1016/j.neunet.2025.108109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stabilization is a fundamental issue in modern control theory. In the past decades, significant efforts have been invested in deriving necessary and sufficient conditions for verifying the global stabilization of probabilistic Boolean control networks (PBCNs). However, systematic methods and general criteria for exploring the local stabilization and determining the domain of attraction of PBCNs are still lacking in the existing literature. Motivated by this research gap, this paper investigates the local state feedback stabilization of PBCNs, including local finite-time state feedback stabilization with probability one (FTSFS) and local state feedback stabilization in distribution (SFSD). Firstly, a sequence of reachable sets with probability one is constructed, based on which, the largest domain of attraction is derived for the FTSFS of PBCNs by designing the state feedback controllers. Secondly, by constructing a sequence of reachable sets with positive probability, the largest domain of attraction is determined for the SFSD of PBCNs. Finally, when the largest domain of attraction is not the whole state space, the state-flipped control is designed to achieve the global FTSFS or SFSD of PBCNs via the largest domain of attraction.},
  archive      = {J_NN},
  author       = {Xinrong Yang and Haitao Li},
  doi          = {10.1016/j.neunet.2025.108109},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108109},
  shortjournal = {Neural Netw.},
  title        = {State-flipped control design for the stabilization of probabilistic boolean control networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stability of large-scale probabilistic boolean networks via network aggregation. <em>NN</em>, <em>194</em>, 108108. (<a href='https://doi.org/10.1016/j.neunet.2025.108108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale probabilistic Boolean networks (LSPBNs) are a modeling tool used to simulate and analyze the dynamics of complex systems with uncertainty. However, due to its high computational complexity, previous research methods cannot be directly applied to study such systems. Inspired by network aggregation, this paper conducts network aggregation on LSPBNs to investigate its global stability with probability 1. It is worth mentioning that the stability conclusion proposed in this article holds for any form of network aggregation. First, the entire network is partitioned and the algebraic expressions for each subnetwork are given through the semi-tensor product of matrices. And then, a set of iterative formulas is constructed to describe and reflect the input-output coordination relationship among the subnetworks, and based on which, a sufficient condition for the global stability of LSPBNs is derived, greatly reducing computational complexity. The feasibilities of the proposed method and results are verified through examples.},
  archive      = {J_NN},
  author       = {Wen Liu and Shihua Fu and Jianjun Wang and Renato De Leone and Jianwei Xia},
  doi          = {10.1016/j.neunet.2025.108108},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108108},
  shortjournal = {Neural Netw.},
  title        = {Stability of large-scale probabilistic boolean networks via network aggregation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SPC: Self-supervised point cloud completion. <em>NN</em>, <em>194</em>, 108107. (<a href='https://doi.org/10.1016/j.neunet.2025.108107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape incompleteness is a common issue in point clouds acquired by depth sensors. Point cloud completion aims to restore partial point clouds to their complete form. However, most existing point cloud completion methods rely on complete point clouds or multi-view information of the same object during training, which is not practical for real-world scenarios with high information acquisition costs. To overcome the above limitation, a self-supervised point cloud completion (SPC) method is proposed, which uses the training set consisting of only a single partial point cloud for each object. Specifically, an autoencoder-like network architecture that includes a two-step strategy is developed. First, a compression-reconstruction strategy is proposed to enable the network to learn the representation of complete point clouds from existing knowledge. Then, considering the potential problem of overfitting in self-supervised training, a global enhancement strategy is further designed to maintain the positional coherence of predicted points. Comprehensive experiments are conducted on the ScanNet, MatterPort3D, KITTI, and ShapeNet datasets. On real-world datasets, the unidirectional Chamfer distance (UCD) and the unidirectional Hausdorff distance (UHD) of the method are reduced by an average of 2.3 and 2.4, respectively, compared to the state-of-the-art method. In addition to its excellent completion capabilities, the proposed method has a positive impact on downstream tasks. In point cloud classification, applying the proposed method improves classification accuracy by an average of 14 %. Extensive experimental results demonstrate that the proposed SPC has a high practical value.},
  archive      = {J_NN},
  author       = {Jie Song and Xing Wu and Junfeng Yao and Qi Zhang and Chenhao Shang and Quan Qian and Jun Song},
  doi          = {10.1016/j.neunet.2025.108107},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108107},
  shortjournal = {Neural Netw.},
  title        = {SPC: Self-supervised point cloud completion},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MINIGE-MNER: A multi-stage interaction network inspired by gene editing for multimodal named entity recognition. <em>NN</em>, <em>194</em>, 108106. (<a href='https://doi.org/10.1016/j.neunet.2025.108106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Named Entity Recognition (MNER) integrates complementary information from both text and images to identify named entities within text. However, existing methods face three key issues: imbalanced handling of modality noise, the cascading effect of semantic mismatch, and information loss resulting from the lack of text dominance. To address these issues, this paper proposes a M ulti-stage I nteraction N etwork I nspired by G ene E diting for MNER (MINIGE-MNER). The core innovations of this method include: A gene knockout module based on the variational information bottleneck, which removes inferior genes (modality noise) from the text, raw image, and generated image features. This approach retains the superior genes, achieving balanced filtering of modality noise. A determination of gene recombination sites module that maximizes the mutual information between superior genes across modalities, reducing the spatial distance between them and ensuring precise, fine-grained semantic alignment. This helps to prevent the cascading effect of semantic mismatch. A text-guided gene recombination module that implements a “text-dominant, vision-supplementary” cross-modal fusion paradigm. This module dynamically filters out visual noise unrelated to the text while avoiding excessive reliance on visual information that could obscure the unique contextual information of the text, effectively mitigating information loss. Experimental results show that MINIGE-MNER achieves F1 scores of 76.45 % and 88.67 % on the Twitter-2015 and Twitter-2017 datasets, respectively, outperforming existing state-of-the-art methods by 0.83 % and 0.42 %. In addition, this paper presents comprehensive experiments that demonstrate the superiority of MINIGE-MNER and the effectiveness of its individual modules.},
  archive      = {J_NN},
  author       = {Bo Kong and Shengquan Liu and Liruizhi Jia and Yi Liang and Dongfang Han and Xu Zhang},
  doi          = {10.1016/j.neunet.2025.108106},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108106},
  shortjournal = {Neural Netw.},
  title        = {MINIGE-MNER: A multi-stage interaction network inspired by gene editing for multimodal named entity recognition},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deceiving question-answering models: A hybrid word-level adversarial approach. <em>NN</em>, <em>194</em>, 108105. (<a href='https://doi.org/10.1016/j.neunet.2025.108105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning underpins most of the currently advanced natural language processing (NLP) tasks such as textual classification, neural machine translation (NMT), abstractive summarization and question-answering (QA). However, the robustness of the models, particularly QA models, against adversarial attacks is a critical concern that remains insufficiently explored. This paper introduces QA-Attack (Question Answering Attack), a novel word-level adversarial strategy that fools QA models. Our attention-based attack exploits the customized attention mechanism and deletion ranking strategy to identify and target specific words within contextual passages. It creates deceptive inputs by carefully choosing and substituting synonyms, preserving grammatical integrity while misleading the model to produce incorrect responses. Our approach demonstrates versatility across various question types, particularly when dealing with extensive long textual inputs. Extensive experiments on multiple benchmark datasets demonstrate that QA-Attack successfully deceives baseline QA models and surpasses existing adversarial techniques regarding success rate, semantics changes, BLEU score, fluency and grammar error rate.},
  archive      = {J_NN},
  author       = {Jiyao Li and Mingze Ni and Yongshun Gong and Wei Liu},
  doi          = {10.1016/j.neunet.2025.108105},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108105},
  shortjournal = {Neural Netw.},
  title        = {Deceiving question-answering models: A hybrid word-level adversarial approach},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A unified gradient regularization method for heterogeneous graph neural networks. <em>NN</em>, <em>194</em>, 108104. (<a href='https://doi.org/10.1016/j.neunet.2025.108104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous Graph Neural Networks (HGNNs) are advanced deep learning methods widely applied for learning representations of heterogeneous graphs. However, they face challenges such as over-smoothing and non-robustness. Existing methods can mitigate these issues by applying gradient regularization to one of the three information dimensions: node, edge, or propagation message. However, these methods have problems such as unstable training, difficulty in parameter convergence, and inadequate utilization of heterogeneous information. We propose a novel gradient regularization method called Grug, which iteratively applies regularization to the gradients derived from both node type and message matrix during the message-passing process. A detailed theoretical analysis demonstrates its advantages in Stability and Diversity. Notably, Grug potentially exceeds the theoretical upper bounds set by DropMessage. In addition, Grug offers a unified gradient regularization framework that integrates the existing dropping and adversarial training methods, and provides theoretical guidance for their further optimization in different data and tasks. We validate Grug through extensive experiments on six public datasets, showing significant improvements in performance and effectiveness.},
  archive      = {J_NN},
  author       = {Xiao Yang and Xuejiao Zhao and Zhiqi Shen},
  doi          = {10.1016/j.neunet.2025.108104},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108104},
  shortjournal = {Neural Netw.},
  title        = {A unified gradient regularization method for heterogeneous graph neural networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-level graph contrastive learning for community value prediction. <em>NN</em>, <em>194</em>, 108103. (<a href='https://doi.org/10.1016/j.neunet.2025.108103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community Value Prediction (CVP) is an important emerging task in the field of social commerce, which aims to predict the community values. However, due to the complex structure of communities and individuals, previous graph machine learning methods have struggled to adequately address this task. This study endeavors to bridge this gap by introducing a cross-level graph contrastive learning method called Cross-level Community Contrastive Learning (CCCL) to handle such subgraph-level tasks. Specifically, we generate two views that describe different levels of social connections, the augmented node-level graph and the community-level graph that is produced by graph coarsening. Subsequently, CCCL captures the mutual information between the two views through a cross-view contrastive loss. The learned embeddings utilize community and node information at various levels, making them capable of handling subgraph-level regression problems. To the best of our knowledge, CCCL is the first graph contrastive learning method that addresses the CVP problem. We theoretically show that CCCL maximizes a lower bound of the mutual information shared between node-view and community-view representations. Experimental results demonstrate that our proposed approach is highly effective for the CVP task, outperforming both end-to-end and self-supervised baselines. Furthermore, our model also exhibits robust resistance to edge perturbation attacks.},
  archive      = {J_NN},
  author       = {Wenjie Yang and Shengzhong Zhang and Zengfeng Huang},
  doi          = {10.1016/j.neunet.2025.108103},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108103},
  shortjournal = {Neural Netw.},
  title        = {Cross-level graph contrastive learning for community value prediction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Radiology report generation via visual-semantic ambivalence-aware network and focal self-critical sequence training. <em>NN</em>, <em>194</em>, 108102. (<a href='https://doi.org/10.1016/j.neunet.2025.108102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology report generation, which aims to provide accurate descriptions of both normal and abnormal regions, has been attracting growing research attention. Recently, despite considerable progress, data-driven deep-learning based models still face challenges in capturing and describing the abnormalities, due to the data bias problem. To address this problem, we propose to generate radiology reports via the Visual-Semantic Ambivalence-Aware Network (VSANet) and the Focal Self-Critical Sequence Training (FSCST). In detail, our VSANet follows the encoder-decoder framework. In the encoder part, we first deploy a multi-grained abnormality extractor and a visual extractor to capture both semantic and visual features from given images, and then introduce a Parameter Shared Dual-way Encoder (PSDwE) to delve into the inter- and intra-relationships among these features. In the decoder part, we propose the Visual-Semantic Ambivalence-Aware (VSA) module to generate the abnormality-aware visual features to mitigate the data bias problem. In implementation, our VSA introduces three sub-modules: Dual-way Attention (DwA), introduced to generate both the word-related visual and semantic features; Dual-way Attention on Attention (DwAoA), designed to mitigate redundant information; Score-based Feature Fusion (SFF), constructed to fuse the visual and semantic features in an ambivalence way. We further introduce the FSCST to enhance the overall performance of our VSANet by allocating more attention toward difficult samples. Experimental results demonstrate that our proposal achieves superior performance on various evaluation metrics. Source code have released at https://github.com/SKD-HPC/VSANet .},
  archive      = {J_NN},
  author       = {Xiulong Yi and You Fu and Enxu Bi and Jianguo Liang and Hao Zhang and Jianzhi Yu and Qianqian Li and Rong Hua and Rui Wang},
  doi          = {10.1016/j.neunet.2025.108102},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108102},
  shortjournal = {Neural Netw.},
  title        = {Radiology report generation via visual-semantic ambivalence-aware network and focal self-critical sequence training},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Discriminative representation learning via attention-enhanced contrastive learning for short text clustering. <em>NN</em>, <em>194</em>, 108101. (<a href='https://doi.org/10.1016/j.neunet.2025.108101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning has gained significant attention in short text clustering, yet it has an inherent drawback of mistakenly identifying samples from the same category as negatives and separating them in the feature space (i.e., the false negative separation problem). To generate discriminative representations for short text clustering, we propose a novel clustering method, called Discriminative Representation learning via A ttention- E nhanced C ontrastive L earning for Short Text Clustering ( AECL ). The AECL consists of two modules which are the contrastive learning module and the pseudo-label assisting module. Both modules utilize a sample-level attention mechanism to extract similarities between samples, based on which cross-sample features are aggregated to form a consistent representation for each sample. The contrastive learning module explores the similarity relationships and the consistent representations to form positive samples, effectively addressing the false negative separation issue, and the pseudo-label assisting module utilizes the consistent representations to produce reliable supervision information to assist the clustering task. Experimental results demonstrate that AECL outperforms state-of-the-art methods. The code is available at https://github.com/YZH0905/AECL-STC .},
  archive      = {J_NN},
  author       = {Zhihao Yao and Bo Li and Yufei Liao},
  doi          = {10.1016/j.neunet.2025.108101},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108101},
  shortjournal = {Neural Netw.},
  title        = {Discriminative representation learning via attention-enhanced contrastive learning for short text clustering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fixed/prescribed-time synchronization of state-dependent switching neural networks with stochastic disturbance and impulsive effects. <em>NN</em>, <em>194</em>, 108100. (<a href='https://doi.org/10.1016/j.neunet.2025.108100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the fixed-time synchronization (FXTS) and prescribed-time synchronization (PSTS) problems of state-dependent switching neural networks (SDSNNs) with stochastic disturbances and impulsive effects. By leveraging the average impulsive interval, comparison principle, and interval matrix methodology, this study advances a novel analytical framework. Departing from conventional approaches, we reformulate stochastic disturbed and impulsive SDSNNs as interval-parameter systems through rigorous interval matrix transformation. Consequently, we derive some sufficient conditions in the form of linear matrix inequalities (LMIs) to ensure the realization of FXTS and PSTS. Since impulsive effects can potentially compromise synchronization stability, careful controller design becomes critical. To address this challenge, we develop a unified proportional integral (PI) control framework. Through proper adjustment of its control parameters, this framework enables the system to achieve both FXTS and PSTS. Moreover, by reasonably configuring the relationship between the impulsive intensity and the prescribed time, the synchronization performance can be balanced. Finally, we demonstrate the effectiveness of the theoretical results through two examples.},
  archive      = {J_NN},
  author       = {Guici Chen and Houxuan Zhang and Shiping Wen and Junhao Hu and Leimin Wang},
  doi          = {10.1016/j.neunet.2025.108100},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108100},
  shortjournal = {Neural Netw.},
  title        = {Fixed/prescribed-time synchronization of state-dependent switching neural networks with stochastic disturbance and impulsive effects},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EKDSC: Long-tailed recognition based on expert knowledge distillation for specific categories. <em>NN</em>, <em>194</em>, 108099. (<a href='https://doi.org/10.1016/j.neunet.2025.108099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of long-tail visual recognition, the imbalance in data distribution leads to a significant performance gap between head and tail classes. Improving the tail-class performance and alleviating the decline in head class are two critical questions. Although many methods have proposed solutions for the former, most of them fall short in the latter. Introducing additional knowledge is a novel view to address the problem, however, how to attain useful knowledge and further transfer the knowledge to the target model is the core. This paper proposes a novel method called Expert Knowledge Distillation for Specific Categories (EKDSC). Firstly, we propose a kind of well-trained teacher model ensuring each expert concentrates on its specialized field while being less affected by other interference. Furthermore, the teacher model including three categories of experts: head, mid, and tail classes, is utilized to distill their specialized knowledge to the student model. Experimental results demonstrate that EKDSC effectively improves the accuracy of tail classes, and mitigates the common decreases of head classes’ performance. Our proposed method achieves a high accuracy, exceeding the current state-of-the-art (SOTA) by 1–5 % on benchmark datasets including the small-scale CIFAR-10 LT and CIFAR-100 LT. Furthermore, it demonstrates outstanding performance on large-scale datasets such as ImageNet-LT, iNaturalist 2018, and Places-LT.},
  archive      = {J_NN},
  author       = {Yaping Bai and Jinghua Li and Dehui Kong and Suqiao Yang and Baocai Yin},
  doi          = {10.1016/j.neunet.2025.108099},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108099},
  shortjournal = {Neural Netw.},
  title        = {EKDSC: Long-tailed recognition based on expert knowledge distillation for specific categories},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Weakly supervised multi-modal imitation learning from incompletely labeled demonstrations. <em>NN</em>, <em>194</em>, 108098. (<a href='https://doi.org/10.1016/j.neunet.2025.108098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal imitation learning enables the agent to learn demonstrations of multiple modes at the same time. However, as expert demonstrations in practice tend to have incomplete labels for behavior modes, most methods are inefficient. To address this issue, an approach capable of imitation learning from incompletely labeled expert demonstrations, referred to as Weakly Supervised Multi-modal Imitation Learning (WSMIL), is proposed. WSMIL incorporates weakly supervised learning into multi-modal imitation learning by adding a behavior mode classifier to the adversarial network, thus forming adversaries among three players (generator, classifier and discriminator). Both labeled and unlabeled data are fully utilized in this adversarial process where fake state-action-label pairs generated by the generator and the classifier try to deceive the discriminator that tries to identify them and limited labeled expert demonstrations. Additionally, in order to ensure the data distribution of classifier and generator individually to converge to the expert’s real distribution, three extra losses are employed, where simulated annealing behavioral cloning is also added to the generator network to improve the generalization of policy. Experiments show that WSMIL accurately distinguishes modes with incomplete modal labels in demonstrations, learns close to the expert standard for each mode, and is more stable than other multi-modal methods.},
  archive      = {J_NN},
  author       = {Sijia Gu and Fei Zhu},
  doi          = {10.1016/j.neunet.2025.108098},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108098},
  shortjournal = {Neural Netw.},
  title        = {Weakly supervised multi-modal imitation learning from incompletely labeled demonstrations},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hybrid aggregation strategy with double inverted residual blocks for lightweight salient object detection. <em>NN</em>, <em>194</em>, 108097. (<a href='https://doi.org/10.1016/j.neunet.2025.108097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lightweight salient object detection (SOD) is widely used in various downstream applications due to its low resource requirements and fast inference speed. The use of hybrid encoders offers the potential to achieve a better balance between efficiency and accuracy for SOD task. However, the aggregation of features from convolutional neural networks (CNNs) and transformers remains challenging, and most existing lightweight SOD models rarely explore the efficient aggregation of cross-architecture features derived from hybrid encoders. In this paper, we propose a hybrid aggregation strategy network (HASNet) that balances accuracy and efficiency for lightweight SOD by grouping and aggregating features to leverage salient information across different architectures. Specifically, the features obtained after hybrid encoder processing are divided into convolutional and transformer features for shallow and deep aggregation respectively. Deep aggregation uses the global inverted residual block (GIRB) to facilitate the transfer of salient information encoded within transformer features across various levels. Meanwhile, shallow aggregation uses the lightweight inverted residual block (LIRB) to efficiently integrate the spatial information inherent in convolutional features. The GIRB incorporates an efficient global operation to extract channel semantic information from the high-dimensional transformer features. The LIRB fuses low-level features by efficiently exploiting the spatial information in features at extremely low computational cost. Comprehensive experiments conducted across five datasets demonstrate that our HASNet significantly outperform existing methods in a thorough evaluation encompassing parameter sizes, inference speed, and accuracy. The source code will be publicly available at https://github.com/LitterMa-820/HASNet .},
  archive      = {J_NN},
  author       = {Jianhua Ma and Mingfeng Jiang and Xian Fang and Jiatong Chen and Yaming Wang and Guang Yang},
  doi          = {10.1016/j.neunet.2025.108097},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108097},
  shortjournal = {Neural Netw.},
  title        = {Hybrid aggregation strategy with double inverted residual blocks for lightweight salient object detection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing image restoration through learning context-rich and detail-accurate features. <em>NN</em>, <em>194</em>, 108096. (<a href='https://doi.org/10.1016/j.neunet.2025.108096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration aims to recover high-quality images from their degraded counterparts, necessitating a delicate balance between preserving spatial details and capturing contextual information. Although some methods attempt to address this trade-off, they tend to focus primarily on spatial features while overlooking the importance of understanding frequency variations. Moreover, these approaches commonly utilize skip connections–implemented via addition or concatenation–to fuse encoder and decoder features for improved restoration. However, since encoder features may still carry degradation artifacts, such direct fusion strategies risk introducing implicit noise, ultimately hindering restoration performance. In this paper, we present a multi-scale design that optimally balances these competing objectives, seamlessly integrating spatial and frequency domain knowledge to selectively recover the most informative information. Specifically, we develop a hybrid scale frequency selection block (HSFSBlock), which not only captures multi-scale information from the spatial domain, but also selects the most informative components for image restoration in the frequency domain. Furthermore, to mitigate the inherent noise introduced by skip connections employing only addition or concatenation, we introduce a skip connection attention mechanism (SCAM) to selectively determines the information that should propagate through skip connections. The resulting tightly interlinked architecture, named as LCDNet. Extensive experiments conducted across diverse image restoration tasks showcase that our model attains performance levels that are either superior or comparable to those of state-of-the-art algorithms. The code and the pre-trained models are released at https://github.com/Tombs98/LCDNet .},
  archive      = {J_NN},
  author       = {Hu Gao and Xiaoning Lei and Depeng Dang},
  doi          = {10.1016/j.neunet.2025.108096},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108096},
  shortjournal = {Neural Netw.},
  title        = {Enhancing image restoration through learning context-rich and detail-accurate features},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). La-LoRA: Parameter-efficient fine-tuning with layer-wise adaptive low-rank adaptation. <em>NN</em>, <em>194</em>, 108095. (<a href='https://doi.org/10.1016/j.neunet.2025.108095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameter-efficient fine-tuning (PEFT) has emerged as a critical paradigm for adapting large pre-trained models to downstream tasks, offering a balance between computational efficiency and model performance. Among these methods, Low-Rank Adaptation (LoRA) has gained significant popularity due to its efficiency; it freezes the pre-trained weights and decomposes the incremental matrices into two trainable low-rank matrices. However, a critical limitation of LoRA lies in its uniform rank assignment across all layers, which fails to account for the heterogeneous importance of different layers in contributing to task performance, potentially resulting in suboptimal adaptation. To address this limitation, we propose Layer-wise Adaptive Low-Rank Adaptation (La-LoRA), a novel approach that dynamically allocates rank to each layer based on Dynamic Contribution-Driven Parameter Budget (DCDPB) and Truncated Norm Weighted Dynamic Rank Allocation (TNW-DRA) during training. By treating each layer as an independent unit and progressively adjusting its rank allocation, La-LoRA ensures optimal model performance while maintaining computational efficiency and adapting to the complexity of diverse tasks. We conducted extensive experiments across multiple tasks and models to evaluate the effectiveness of La-LoRA. The results demonstrate that La-LoRA consistently outperforms existing benchmarks, validating its effectiveness in diverse scenarios.},
  archive      = {J_NN},
  author       = {Jiancheng Gu and Jiabin Yuan and Jiyuan Cai and Xianfa Zhou and Lili Fan},
  doi          = {10.1016/j.neunet.2025.108095},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108095},
  shortjournal = {Neural Netw.},
  title        = {La-LoRA: Parameter-efficient fine-tuning with layer-wise adaptive low-rank adaptation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-level dynamic heterogeneous graph network for video question answering. <em>NN</em>, <em>194</em>, 108094. (<a href='https://doi.org/10.1016/j.neunet.2025.108094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Video Question Answering (VideoQA) has garnered considerable research interest as a pivotal task within the realm of vision-language understanding. However, existing Video Question Answering datasets often lack sufficient entity and event information. Thus, the Vision Language Models (VLMs) struggle to complete intricate grounding and reasoning among multi-modal entities or events and heavily rely on language short-cut or irrelevant visual context. To address these challenges, we make improvements from both data and model perspectives. In terms of VideoQA data, we focus on supplementing the missing specific entities and events with the proposed event and entity augmentation strategies. Based on the augmented data, we propose a Dual-Level Dynamic Heterogeneous Graph Network (DDHG) for Video Question Answering. DDHG incorporates transformer layers to capture the dynamic temporal-spatial changes of visual entities. Then, DDHG establishes multi-modal semantic grounding ability between vision and text with entity-level and event-level heterogeneous graphs. Finally, the Dual-level Cross-modal Interaction Module integrates the dual-level features to predict correct answers. Our method not only significantly outperforms existing VideoQA models on two complex event-based benchmark datasets (Causal-VidQA and NExT-QA) but also demonstrates superior event content prediction ability over several state-of-the-art approaches.},
  archive      = {J_NN},
  author       = {Zefan Zhang and Yanhui Li and Weiqi Zhang and Tian Bai},
  doi          = {10.1016/j.neunet.2025.108094},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108094},
  shortjournal = {Neural Netw.},
  title        = {Dual-level dynamic heterogeneous graph network for video question answering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HMT-DTI: Hierarchical meta-path learning with transformer for drug–target interaction prediction. <em>NN</em>, <em>194</em>, 108093. (<a href='https://doi.org/10.1016/j.neunet.2025.108093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug–target interaction (DTI) prediction plays a crucial role in drug discovery and repurposing by efficiently and accurately identifying potential therapeutic targets. Existing methods face challenges in capturing high-order semantic relationships in heterogeneous graphs and effectively integrating multi-meta-path information while also suffering from low computational efficiency. To address these challenges, a pre-computation-style hierarchical meta-path learning framework named HMT-DTI is proposed. HMT-DTI can effectively capture rich semantic information about drugs and targets while ensuring high computational efficiency. Specifically, during the pre-collection stage, HMT-DTI employs a Transformer-based message passing mechanism to evaluate neighbors’ importance and adaptively collect meta-path information. The incorporation of even-relation propagation reduces redundant iterations and improves efficiency. During training, HMT-DTI adopts a hierarchical knowledge extraction strategy to evaluate the importance of multi-hop neighbors and different meta-path patterns, capturing fine-grained semantic representations of drugs and targets. HMT-DTI is evaluated on three heterogeneous biological datasets and compared with several state-of-the-art methods. The results demonstrate the superiority of HMT-DTI in DTI prediction.},
  archive      = {J_NN},
  author       = {Dianlei Gao and Fei Zhu},
  doi          = {10.1016/j.neunet.2025.108093},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108093},
  shortjournal = {Neural Netw.},
  title        = {HMT-DTI: Hierarchical meta-path learning with transformer for drug–target interaction prediction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On training networks of monostable multivibrator timer neurons. <em>NN</em>, <em>194</em>, 108092. (<a href='https://doi.org/10.1016/j.neunet.2025.108092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important bottleneck in present-day neuromorphic hardware is its reliance on synaptic addition, which limits the achievable degree of parallelization and thus processing throughput. We present a network of monostable multivibrator timers, whose synaptic inputs are simply OR-ed together, thus mitigating the synaptic addition bottleneck. Monostable multivibrators are simple timers which are easily implemented using counters in digital hardware and can be interpreted as non biologically-inspired spiking neurons. We show how fully binarized event-driven recurrent networks of monostable multivibrators can be trained to solve classification tasks. Our training algorithm resolves temporally overlapping input events. We demonstrate our approach on the MNIST handwritten digits, Google Soli radar gestures, IBM DVS128 gestures and Yin-Yang classification tasks. The estimated energy consumption for the MNIST handwritten digits task, excluding the final linear readout layer, is 855pJ per inference for a test accuracy of 98.61 % for a reconfigurable network of 500 units, when mapped to the TSMC HPC+ 28 nm process.},
  archive      = {J_NN},
  author       = {Lars Keuninckx and Matthias Hartmann and Paul Detterer and Ali Safa and Wout Mommen and Ilja Ocket},
  doi          = {10.1016/j.neunet.2025.108092},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108092},
  shortjournal = {Neural Netw.},
  title        = {On training networks of monostable multivibrator timer neurons},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-modal orthogonal fusion network via cross-layer guidance for alzheimer’s disease diagnosis. <em>NN</em>, <em>194</em>, 108091. (<a href='https://doi.org/10.1016/j.neunet.2025.108091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal neuroimaging techniques are widely employed for the accurate diagnosis of Alzheimer’s Disease (AD). Existing fusion methods typically focus on capturing semantic correlations between modalities through feature-level interactions. However, they fail to suppress redundant cross-modal information, resulting in sub-optimal multi-modal representation. Moreover, these methods ignore subject-specific differences in modality contributions. To address these challenges, we propose a novel Multi-modal Orthogonal Fusion Network via cross-layer guidance (MOFNet) to effectively fuse multi-modal information for AD diagnosis. We first design a Cross-layer Guidance Interaction module (CGI), leveraging high-level features to guide the learning of low-level features, thereby enhancing the fine-grained representations on disease-relevant regions. Then, we introduce a Multi-modal Orthogonal Compensation module (MOC) to realize bidirectional interaction between modalities. MOC encourages each modality to compensate for its limitations by learning orthogonal components from other modalities. Finally, a Feature Enhancement Fusion module (FEF) is developed to adaptively fuse multi-modal features based on the contributions of different modalities. Extensive experiments on the ADNI dataset demonstrate that MOFNet achieves superior performance in AD classification tasks.},
  archive      = {J_NN},
  author       = {Yumiao Zhao and Bo Jiang and Yuan Chen and Ye Luo and Jin Tang},
  doi          = {10.1016/j.neunet.2025.108091},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108091},
  shortjournal = {Neural Netw.},
  title        = {Multi-modal orthogonal fusion network via cross-layer guidance for alzheimer’s disease diagnosis},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ClickAttention: Click region similarity guided interactive segmentation. <em>NN</em>, <em>194</em>, 108090. (<a href='https://doi.org/10.1016/j.neunet.2025.108090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive segmentation algorithms based on click points have attracted significant attention from researchers in recent years. However, most existing methods rely on sparse click maps as model inputs to segment specific target objects. These clicks primarily affect local regions, limiting the model’s ability to focus on the entire target object and often resulting in a higher number of required clicks. Additionally, many current algorithms struggle to balance performance and efficiency effectively. To address these challenges, we propose a click attention algorithm that expands the influence of positive clicks by leveraging the similarity between positively-clicked regions and the entire input. We further introduce a discriminative affinity loss to reduce attention coupling between positive and negative click regions, minimizing accuracy degradation caused by mutual interference. On the DAVIS dataset, our method achieves a 2 % performance gain (NoC@90) over the state-of-the-art SimpleClick-ViT-L, while using only 15.6 % of its parameters. Extensive experiments demonstrate that our approach outperforms existing methods and achieves state-of-the-art performance with fewer parameters. Data and code are published.},
  archive      = {J_NN},
  author       = {Long Xu and Yongquan Chen and Shanghong Li and Junkang Chen and Ziyuan Tang},
  doi          = {10.1016/j.neunet.2025.108090},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108090},
  shortjournal = {Neural Netw.},
  title        = {ClickAttention: Click region similarity guided interactive segmentation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A vision-language model for multitask classification of memes. <em>NN</em>, <em>194</em>, 108089. (<a href='https://doi.org/10.1016/j.neunet.2025.108089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of social media and online memes has led to an increasing demand for automated systems that can analyse and classify multimodal data, particularly in online forums. Memes blend text and graphics to express complicated ideas, sometimes containing emotions, satire, or inappropriate material. Memes often represent cultural prejudices such as objectification, sexism, and bigotry, making it difficult for artificial intelligence to classify these components. Our solution is the vision-language model ViT-BERT CAMT (cross-attention multitask), which is intended for multitask meme categorization. Our model uses a linear self-attentive fusion mechanism to combine vision transformer (ViT) features for image analysis and bidirectional encoder representations from transformers (BERT) for text interpretation. In this way, we can see how text and images relate to space and meaning. We tested the ViT-BERT CAMT on two difficult datasets: the SemEval 2020 Memotion dataset, which contains a multilabel classification of sentiment, sarcasm, and offensiveness in memes, and the MIMIC dataset, which focuses on detecting sexism, objectification, and prejudice. The findings show that the ViT-BERT CAMT achieves good accuracy on both datasets and outperforms many current baselines in multitask settings. These results highlight the importance of combined image-text modelling for correctly deciphering nuanced meanings in memes, particularly when spotting abusive and discriminatory content. By improving multimodal categorization algorithms, this study helps better monitor and comprehend online conversation.},
  archive      = {J_NN},
  author       = {Md. Mithun Hossain and Md. Shakil Hossain and M.F. Mridha and Nilanjan Dey},
  doi          = {10.1016/j.neunet.2025.108089},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108089},
  shortjournal = {Neural Netw.},
  title        = {A vision-language model for multitask classification of memes},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-view learning meets state-space model: A dynamical system perspective. <em>NN</em>, <em>194</em>, 108088. (<a href='https://doi.org/10.1016/j.neunet.2025.108088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning exploits the complementary nature of multiple modalities to enhance performance across diverse tasks. While deep learning has significantly advanced these fields by enabling sophisticated modeling of intra-view and cross-view interactions, many existing approaches still rely on heuristic architectures and lack a principled framework to capture the dynamic evolution of feature representations. This limitation hampers interpretability and theoretical understanding. To address these challenges, this paper introduces the Multi-view State-Space Model (MvSSM), which formulates multi-view representation learning as a continuous-time dynamical system inspired by control theory. In this framework, view-specific features are treated as external inputs, and a shared latent representation evolves as the internal system state, driven by learnable dynamics. This formulation unifies feature integration and label prediction within a single interpretable model, enabling theoretical analysis of system stability and representational transitions. Two variants, MvSSM-Lap and MvSSM-iLap, are further developed using Laplace and inverse Laplace transformations to derive system dynamics representations. These solutions exhibit structural similarities to graph convolution operations in deep networks, supporting efficient feature propagation and theoretical interpretability. Experiments on benchmark datasets such as IAPR-TC12, and ESP demonstrate the effectiveness of the proposed method, achieving up to 4.31 % improvement in accuracy and 4.27 % in F1-score over existing state-of-the-art approaches.},
  archive      = {J_NN},
  author       = {Weibin Chen and Ying Zou and Zhiyong Xu and Li Xu and Shiping Wang},
  doi          = {10.1016/j.neunet.2025.108088},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108088},
  shortjournal = {Neural Netw.},
  title        = {Multi-view learning meets state-space model: A dynamical system perspective},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph convolutional network with adaptive grouping aggregation strategy. <em>NN</em>, <em>194</em>, 108086. (<a href='https://doi.org/10.1016/j.neunet.2025.108086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of graph convolutional networks (GCNs) with naive aggregation functions on nodes has reached the bottleneck, rendering a gap between practice and theoretical expressity. Some learning-based aggregation strategies have been proposed to improve the performance. However, few of them focus on how these strategies affect the expressity and evaluate their performance in an equal experimental setting. In this paper, we point out that the generated features lack discrimination because naive aggregation functions cannot retain sufficient node information, largely leading to the performance gap. Accordingly, a novel Adaptive Grouping Aggregation (AGA) strategy is proposed to remedy this drawback. Inspired by the label histogram in the Weisfeiler-Lehman (WL) Test, this strategy assigns each node to a unique group to retain more node information, which is proven to have a strictly more powerful expressity. In this work setting, the nodes are grouped according to a modified Student’s t-Distribution between node features and a set of learnable group labels, where the Gumbel Softmax is employed to implement this strategy in an end-to-end trainable pipeline. As a result, such a design can generate more discriminative features and offer a plug-in module in most architectures. Extensive experiments have been conducted on several benchmarks to compare our method with other aggregation strategies. The proposed method improves the performance in all control groups of all benchmarks and achieves the best result in most cases. Additional ablation studies and comparisons with state-of-the-art methods on the large-scale benchmark also indicate the superiority of our method.},
  archive      = {J_NN},
  author       = {Ruixiang Wang and Chunxia Zhang and Chunhong Pan},
  doi          = {10.1016/j.neunet.2025.108086},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108086},
  shortjournal = {Neural Netw.},
  title        = {Graph convolutional network with adaptive grouping aggregation strategy},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-driven optimization of collaborative multi-agent via case learning and curiosity. <em>NN</em>, <em>194</em>, 108083. (<a href='https://doi.org/10.1016/j.neunet.2025.108083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent Deep Reinforcement Learning(MADRL) faces significant challenges in exploration-exploitation trade-off during training, particularly when learning collaborative behaviors through continuous environment interactions. Current exploration methods generally rely on unbiased randomized policy, which makes the policy optimization process lack of goal-directed, resulting in a large number of low signal-to-noise ratio transitions collected in the experience replay buffer, which seriously affects the learning efficiency and policy convergence stability of MADRL. To address the above research challenges, We propose the Case-Enhanced Random Network Distillation Exploration for Centralized Training and Decentralized Execution(CERE-CTDE) paradigm. Our innovation lies in the novel integration of Random Network Distillation(RND) and Case-Based Reasoning(CBR): RND provides intrinsic motivation to enhance exploration and overcome sparse rewards, while CBR enables goal-directed exploitation by leveraging historical case to guide agent action selection. This dual mechanism creates a dynamic equilibrium between exploring novel policy and exploiting proven case, effectively preventing premature convergence. We incorporate the CERE into two categories of MADRL methods based on the CTDE paradigm. The performance of us is assessed and validated with 2 methods focused on exploration using 13 confrontation scenarios in the StarCraft Multi-Agent Challenge(SMAC). The experimental results demonstrate: a 17.97 % statistically significant improvement in win rate on complex battlefields compared to baseline performance in simple scenarios; effective enhancement of policy exploration-exploitation and mitigation of partial sparse reward problems through intrinsic motivation and CBR-guided action sampling; and superior capability in escaping local optima while maintaining learning efficiency. The framework’s robustness is further validated by its consistent performance across different SMAC scenarios with varying difficulty levels.},
  archive      = {J_NN},
  author       = {Ruizhu Chen and Rong Fei and Junhuai Li and Aimin Li and Yalin Miao and Lili Wu and Zhiming Chen},
  doi          = {10.1016/j.neunet.2025.108083},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108083},
  shortjournal = {Neural Netw.},
  title        = {Dual-driven optimization of collaborative multi-agent via case learning and curiosity},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive behavior with stable synapses. <em>NN</em>, <em>194</em>, 108082. (<a href='https://doi.org/10.1016/j.neunet.2025.108082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavioral changes in animals and humans, triggered by errors or verbal instructions, can occur extremely rapidly. While learning theories typically attribute improvements in performance to synaptic plasticity, recent findings suggest that such fast adaptations may instead result from dynamic reconfiguration of the networks involved without changes to synaptic weights. Recently, similar capabilities have been observed in transformers, foundational architecture in machine learning widely used in applications such as natural language and image processing. Transformers are capable of in-context learning, the ability to adapt and acquire new information dynamically within the context of the task or environment they are currently engaged in, without changing their parameters. We argue that this property may stem from gain modulation–a feature widely observed in biological networks, such as pyramidal neurons through input segregation and dendritic amplification. We propose a constructive approach to induce in-context learning in an architecture composed of recurrent networks with gain modulation, demonstrating abilities inaccessible to standard networks. In particular, we show that, such architecture can dynamically implement standard gradient-based by encoding weight changes in the activity of another network. We argue that, while these algorithms are traditionally associated with synaptic plasticity, their reliance on non-local terms suggests that they may be more naturally realized in the brain at the level of neural circuits. We demonstrate that we can extend our approach to temporal tasks and reinforcement learning. We further validate our approach in a MuJoCo ant navigation task, showcasing a neuromorphic control paradigm via real-time network reconfiguration.},
  archive      = {J_NN},
  author       = {Cristiano Capone and Luca Falorsi},
  doi          = {10.1016/j.neunet.2025.108082},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108082},
  shortjournal = {Neural Netw.},
  title        = {Adaptive behavior with stable synapses},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Disentangled self-supervised video camouflaged object detection and salient object detection. <em>NN</em>, <em>194</em>, 108077. (<a href='https://doi.org/10.1016/j.neunet.2025.108077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video tasks play an important role in multimedia fields. In various video tasks, such as video camouflaged/salient object detection (VCOD/VSOD), motion and context information are two important aspects. Despite the fact that many existing works have already achieved promising results in VCOD and VSOD tasks, they still have limitations when it comes to leveraging motion and context information. In this paper, we propose a new disentangled perspective to treat motion and context information in VCOD and VSOD tasks. Our proposed model can respectively utilize context and motion information in ContextNet and MotionNet, without conflicting with each other as there can be biases between these two types of information in certain circumstances. Moreover, we further explore how to apply disentangled perspective in the self-supervised manner, which can reduce annotation costs. Specifically, we first design a self-supervised adaptive frame routing mechanism to determine whether each video frame belongs to ContextNet or MotionNet. Then we design a cross-supervision for ContextNet and MotionNet to train these two segmentation networks in self-supervised mechanism. In experiments, our proposed self-supervised disentangled model consistently outperforms state-of-the-art unsupervised methods on VCOD and VSOD datasets.},
  archive      = {J_NN},
  author       = {Haoke Xiao and Lv Tang and Bo Li and Zhiming Luo and Shaozi Li},
  doi          = {10.1016/j.neunet.2025.108077},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108077},
  shortjournal = {Neural Netw.},
  title        = {Disentangled self-supervised video camouflaged object detection and salient object detection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Design, analysis and verification of noise-tolerant and overshoot-free recurrent neural network. <em>NN</em>, <em>194</em>, 108075. (<a href='https://doi.org/10.1016/j.neunet.2025.108075'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A kind of recurrent neural network (RNN) specialized in solving time-varying problems has wide applications in various fields, where the RNN with integral terms (RNN-IT) as a state-of-art method plays an important role in rejecting noise. However, the RNN-IT always experiences overshoot phenomenon when suppressing noise, which greatly affects the convergence time. In order to overcome the above disadvantage of the RNN-IT, this paper proposes a noise-tolerant and overshoot-free recurrent neural network (NORNN) by designing a time-varying additional term, which can flexibly compensate errors and avoid accumulation, thereby resisting noise and eliminating overshoot. Furthermore, the convergence time of the NORNN is obviously improved, which means that the NORNN can effectively and quickly address time-varying problems even when the noise disturbed. Two theorems and a corollary analyze the convergence, noise-tolerance, and overshoot-free properties of the proposed NORNN. Meanwhile, simulation experiments on solving the time-varying matrix inversion problem and the trajectory tracking of the RPRR manipulator also verify its excellent performance.},
  archive      = {J_NN},
  author       = {Lei Jia and Tiandong Zheng and Yujie Wu and Yiwei Li},
  doi          = {10.1016/j.neunet.2025.108075},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108075},
  shortjournal = {Neural Netw.},
  title        = {Design, analysis and verification of noise-tolerant and overshoot-free recurrent neural network},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). WPDA: Frequency-based backdoor attack with wavelet packet decomposition. <em>NN</em>, <em>194</em>, 108074. (<a href='https://doi.org/10.1016/j.neunet.2025.108074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work explores backdoor attack, which is an emerging security threat against deep neural networks (DNNs). The adversary aims to inject a backdoor into the model by manipulating a portion of training samples, such that the backdoor could be activated by a particular trigger to make a target prediction at inference. Currently, existing backdoor attacks often require moderate or high poisoning ratios to achieve the desired attack performance, but making them susceptible to some advanced backdoor defenses ( e . g . , poisoned sample detection). One possible solution to this dilemma is enhancing the attack performance at low poisoning ratios, which has been rarely studied due to its high challenge. To achieve this goal, we propose an innovative frequency-based backdoor attack via wavelet packet decomposition (WPD), which could finely decompose the original image into multiple sub-spectrograms with semantic information. It facilitates us to accurately identify the most critical frequency regions to effectively insert the trigger into the victim image, such that the trigger information could be sufficiently learned to form the backdoor. The proposed attack stands out for its exceptional effectiveness, stealthiness, and resistance at an extremely low poisoning ratio. Notably, it achieves the 98.12 % attack success rate on CIFAR-10 with an extremely low poisoning ratio of 0.004 % ( i.e. , only 2 poisoned samples among 50,000 training samples), and bypasses several advanced backdoor defenses. Besides, we provide more extensive experiments to demonstrate the efficacy of the proposed method, as well as in-depth analyses to explain its underlying mechanism.},
  archive      = {J_NN},
  author       = {Zhengyao Song and Yongqiang Li and Danni Yuan and Li Liu and Shaokui Wei and Baoyuan Wu},
  doi          = {10.1016/j.neunet.2025.108074},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108074},
  shortjournal = {Neural Netw.},
  title        = {WPDA: Frequency-based backdoor attack with wavelet packet decomposition},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DA-MoE: Addressing depth-sensitivity in graph-level analysis through mixture of experts. <em>NN</em>, <em>194</em>, 108064. (<a href='https://doi.org/10.1016/j.neunet.2025.108064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are gaining popularity for processing graph data. In real-world scenarios, graph data within the same dataset can vary significantly in scale. This variability leads to depth-sensitivity, where the optimal depth of GNN layers depends on the scale of the graph data. Empirically, fewer layers are sufficient for message passing in smaller graphs, while larger graphs typically require deeper networks to capture long-range dependencies and global features. However, existing methods generally use a fixed number of GNN layers to generate representations for all graphs, overlooking the depth-sensitivity issue in graph data. To address this challenge, we propose the depth adaptive mixture of expert (DA-MoE) method, which incorporates two main improvements to GNN backbone: 1) DA-MoE employs different GNN layers, each considered an expert with its own parameters. Such a design allows the model to flexibly aggregate information at different scales, effectively addressing the depth-sensitivity issue in graph data. 2) DA-MoE utilizes GNN to capture the structural information instead of the linear projections in the gating network. Thus, the gating network enables the model to capture complex patterns and dependencies within the data. By leveraging these improvements, each expert in DA-MoE specifically learns distinct graph patterns at different scales. Furthermore, comprehensive experiments on the TU dataset and open graph benchmark (OGB) have shown that DA-MoE consistently surpasses existing baselines on various tasks, including graph, node, and link-level analyses. The code are available at https://github.com/Celin-Yao/DA-MoE .},
  archive      = {J_NN},
  author       = {Zelin Yao and Mukun Chen and Chuang Liu and Xianke Meng and Yibing Zhan and Jia Wu and Shirui Pan and Huiting Xu and Wenbin Hu},
  doi          = {10.1016/j.neunet.2025.108064},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108064},
  shortjournal = {Neural Netw.},
  title        = {DA-MoE: Addressing depth-sensitivity in graph-level analysis through mixture of experts},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic graph representation learning with disentangled information bottleneck. <em>NN</em>, <em>194</em>, 108056. (<a href='https://doi.org/10.1016/j.neunet.2025.108056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic graph representation learning recently garnered enormous research attention. Despite the notable successes of existing methods, they usually characterize dynamic graphs as a perceptual whole and learn dynamic graph representations within an entangled feature space, which overlook different temporal dependencies inherent in the data. Specifically, the evolution of dynamic graphs is usually decided by a dichotomy in properties: time-invariant properties and time-varying properties. Existing holistic works fail to distinguish these temporal properties and may suffer suboptimal performance in downstream tasks. To tackle this problem, we propose to learn macro-disentangled dynamic graph representations based on the Information Bottleneck theory, leading to a novel dynamic graph representation learning method, Disentangled Dynamic Graph Information Bottleneck (DDGIB). Our DDGIB explicitly embeds the dynamic graphs into a time-invariant representation space and a time-varying representation space. The time-invariant representation space encapsulates stable properties across the temporal span of dynamic graphs, whereas the time-varying representation space encapsulates time-fluctuating properties. The macro disentanglement on the temporal dependencies facilitates the representations’ performance on downstream tasks. Furthermore, we theoretically prove the sufficiency and macro disentanglement of DDGIB. The sufficiency demonstrates that DDGIB can achieve sufficient representations for any possible downstream tasks, while the macro disentanglement certifies that DDGIB can embed the different temporal properties into their corresponding temporal representation space. Extensive experimental results on various datasets and downstream tasks demonstrate the superiority of our method.},
  archive      = {J_NN},
  author       = {Jihong Wang and Yuxin Bai and Chunqiang Zhu and Hao Qian and Ziqi Liu and Minnan Luo},
  doi          = {10.1016/j.neunet.2025.108056},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108056},
  shortjournal = {Neural Netw.},
  title        = {Dynamic graph representation learning with disentangled information bottleneck},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tailoring knowledge for empowered cooperative actions in multi-agent reinforcement learning. <em>NN</em>, <em>194</em>, 108023. (<a href='https://doi.org/10.1016/j.neunet.2025.108023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavioral diversity emerges as a crucial factor for achieving effective collaboration in Multi-Agent Reinforcement Learning (MARL). Current methods often use partial parameter sharing, such as sharing the same representation layer, to balance behavioral diversity and algorithmic scalability. However, this approach ignores that different agents need different decision knowledge, causing training conflicts and knowledge redundancy. To solve these, we propose Tailoring Knowledge for Empowered Cooperative Actions in Multi-Agent Reinforcement Learning (TKCA). Specially, we employ a set of Knowledge Encoders to encode different environment types of knowledge and utilize a Knowledge Selector network to assist each agent in decision-making by selecting the corresponding knowledge. We evaluated TKCA in challenging StarCraftII micromanagement games and Google Research Football games, and the results demonstrate the superior performance of TKCA.},
  archive      = {J_NN},
  author       = {Hu Fu and Yihua Tan and Hao Chen and Pengyi Li},
  doi          = {10.1016/j.neunet.2025.108023},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108023},
  shortjournal = {Neural Netw.},
  title        = {Tailoring knowledge for empowered cooperative actions in multi-agent reinforcement learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic scale position embedding for cross-modal representation learning. <em>NN</em>, <em>193</em>, 108087. (<a href='https://doi.org/10.1016/j.neunet.2025.108087'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a novel approach to capture temporal information in videos across multiple scales for cross-modal learning. As videos naturally encapsulate semantic information of diverse durations, existing methods that primarily depend on fine- and coarse-grained contrastive learning may fail to fully capture the inherent semantic information. To bridge this gap, we propose Dynamic Scale Position Embedding (DSPE), a novel approach that enables a single transformer to interpret videos at various temporal scales through dynamic adjustment of temporal position embedding. In contrast to conventional multi-scale methods that aggregate video clips, DSPE maintains the distinct features of each clip, thus preserving semantic integrity and enhancing semantic content comprehension. Based on this, we present an efficient multi-scale temporal encoder designed to adeptly capture temporal information across a broad spectrum from fine to coarse granularity. Comprehensive experiments across four datasets–MSR-VTT, LSMDC, MSVD, and ActivityNet-Captions–and two distinct tasks–text-video retrieval and video-captioning–with consistent performance improvements highlight the significance of the presented multi-scale approach.},
  archive      = {J_NN},
  author       = {Jungkyoo Shin and Sungmin Kang and Yoonsik Cho and Eunwoo Kim},
  doi          = {10.1016/j.neunet.2025.108087},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108087},
  shortjournal = {Neural Netw.},
  title        = {Dynamic scale position embedding for cross-modal representation learning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Lightweight local and global granularity selection optimization network for single image super-resolution. <em>NN</em>, <em>193</em>, 108085. (<a href='https://doi.org/10.1016/j.neunet.2025.108085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, neural networks that combine local and global granularity features have made significant progress in single image super-resolution (SISR). However, when dealing with local granularity, these models often fuse features from coarse to fine in a linear manner, which leads to redundant feature representations and inefficient information extraction. Additionally, global granularity feature extraction is often compromised by the interference of irrelevant features that reduce the model’s ability to effectively capture global dependencies, ultimately affecting reconstruction quality. In this paper, a lightweight local and global granularity selection optimization network-LGGSONet is proposed to enhance the capability of feature extraction. First, we present a local granularity selection module (LGSM), which applies a novel nonlinear convolution method to dynamically fuse multi-scale features and adaptively select effective information. Next, we design a global granularity optimization module (GGOM), which uses global transposed attention for feature extraction while dynamically filtering out irrelevant spatial fine-grained features. Then, we construct a mixed granularity transformer block (MGTB), combining LGSM and GGOM. Finally, MGTB is integrated into the mixed granularity residual transformer group (MGRTG) to simplify network training. Extensive experiments show that LGGSONet based on MGRTG achieves a PSNR improvement of 0.30 dB over other advanced lightweight methods while maintaining fewer parameters and computational costs.},
  archive      = {J_NN},
  author       = {Zhihao Peng and Mang Hu and Xinyuan Qi and Sheng Wu and Qianqian Xia and Jianga Shang and Linquan Yang},
  doi          = {10.1016/j.neunet.2025.108085},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108085},
  shortjournal = {Neural Netw.},
  title        = {Lightweight local and global granularity selection optimization network for single image super-resolution},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Revisiting DIRE: Towards universal AI-generated image detection. <em>NN</em>, <em>193</em>, 108084. (<a href='https://doi.org/10.1016/j.neunet.2025.108084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of generative models has improved image quality and made image synthesis widely accessible, raising concerns about content credibility. To address this issue, we propose a method called Universal Reconstruction Residual Analysis ( UR 2 EA ) for detecting synthetic images. Our study reveals that, when GAN- and diffusion-generated images are reconstructed by pre-trained diffusion models, they exhibit significant differences in reconstruction error compared to real images: GAN-generated images show lower reconstruction quality than real images, whereas diffusion-generated images are more accurately reconstructed. We leverage these residual maps as a universal prior to training a model for detecting synthetic images. In addition, we introduce a Multi-scale Channel and Window Attention (MCWA) module to extract fine-grained features from residual maps across multiple scales, capturing both local and global details. To facilitate the exploration of diverse detection methods, we constructed a new UniversalForensics dataset, which includes various representations of synthetic images generated by 30 different models. Compared to the best-performing baselines, our method improves average accuracy by 3.3 % and precision by 1.6 %, achieving state-of-the-art results.},
  archive      = {J_NN},
  author       = {Huanqi Lin and Jinghui Qin and Xiaoqi Wu and Tianshui Chen and Zhijing Yang},
  doi          = {10.1016/j.neunet.2025.108084},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108084},
  shortjournal = {Neural Netw.},
  title        = {Revisiting DIRE: Towards universal AI-generated image detection},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GoFormer: A GoLPP inspired transformer for functional brain graph learning and classification. <em>NN</em>, <em>193</em>, 108081. (<a href='https://doi.org/10.1016/j.neunet.2025.108081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph has a great potential in modelling the complex relationship among data, and learning a high-quality graph usually plays a critical role in many downstream tasks. In 2010, we proposed the graph-optimized locality preserving projections (GoLPP) that was the first work to learn graphs adaptively with the dimensionality reduction task, exhibiting a better performance than the methods based on predefined graphs. Recently, the graph learning is re-highlighted partially due to the popularity of Transformer that leverages the self-attention mechanism to model the relationship between tokens by an updatable graph. Despite its great success, Transformer has a weak inductive bias and needs to be trained on large-scale datasets. For some practical scenarios such as intelligent medicine, however, it is difficult to collect sufficient data to support the training of Transformer. By revisiting GoLPP, we have an interesting finding that its iterative process between the graph and projection matrix precisely corresponds to the working mechanism of self-attention modules in Transformer, which inspires us to design a novel method, namely GoFormer, towards getting the best from both worlds. Specifically, GoFormer not only inherits the power of Transformer for handling the sequence data in an end-to-end form, but also balances the parsimonious principle by integrating the parameter updating and sharing mechanism implicitly involved in GoLPP. Compared with Transformer, GoFormer can mitigate the risk of overfitting and has a better interpretability for medical applications. To evaluate its effectiveness, we use GoFormer to learn and classify brain graphs based on functional magnetic resonance imaging (fMRI) data for the early diagnosis of neurological disorders. Experimental results demonstrate that GoFormer outperforms the baseline and state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Mengxue Pang and Lina Zhou and Xueying Yao and Jun Yang and Jinshan Zhang and Yining Zhang and Limei Zhang and Lishan Qiao},
  doi          = {10.1016/j.neunet.2025.108081},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108081},
  shortjournal = {Neural Netw.},
  title        = {GoFormer: A GoLPP inspired transformer for functional brain graph learning and classification},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic network compression via probabilistic channel pruning. <em>NN</em>, <em>193</em>, 108080. (<a href='https://doi.org/10.1016/j.neunet.2025.108080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network compression problems have been extensively studied to overcome the limitations of compute-intensive deep learning models. Most of the state-of-the-art solutions in this context are based on network pruning that identify and remove unimportant weights, filters or channels. However, existing methods often lack actual speedup or require complex pruning criteria and additional training (fine-tuning) overhead. To address these limitations, we develop probability-based connectivity module that determines the connection of each channel to the next layer. Our connectivity module enables to dynamically activate and deactivate channel connections during training, and hence, does not necessitate fine-tuning of the pruned model. We show that the convolution decomposition, which decomposes convolution with connectivity module and depth-wise convolution can effectively induce sparsity, resulting in 52.76 %, 46.05 % reduction of parameter counts, with even boosting accuracy (+0.19 %, + 0.3 %) compared to baseline architectures in ResNet-56, VGG-19 Models. We also introduce resource-aware regularization that exploits the probabilistic activation of connectivity module in order to control the level of compression. We show that our method achieves comparable level of compression and accuracy to the state-of-the-art pruning methods.},
  archive      = {J_NN},
  author       = {Kwanhee Lee and Hyang-Won Lee},
  doi          = {10.1016/j.neunet.2025.108080},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108080},
  shortjournal = {Neural Netw.},
  title        = {Dynamic network compression via probabilistic channel pruning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hardware friendly deep reservoir computing. <em>NN</em>, <em>193</em>, 108079. (<a href='https://doi.org/10.1016/j.neunet.2025.108079'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reservoir Computing (RC) is a popular approach for modeling dynamical Recurrent Neural Networks, featured by a fixed (i.e., untrained) recurrent reservoir layer. In this paper, we introduce a novel design strategy for deep RC neural networks that is especially suitable to neuromorphic hardware implementations. From the topological perspective, the introduced model presents a multi-level architecture with ring reservoir topology and one-to-one inter-reservoir connections. The proposed design also considers hardware-friendly nonlinearity and noise modeling in the reservoir update equations. We demonstrate the introduced hardware-friendly deep RC architecture in electronic hardware, showing the promising processing capabilities on learning tasks that require both nonlinear computation and short-term memory. Additionally, we validate the effectiveness of the introduced approach on several time-series classification tasks, showing its competitive performance compared to its shallow counterpart, conventional, as well as more recent RC systems. These results emphasize the advantages of the proposed deep architecture for both practical hardware-friendly environments and broader machine learning applications.},
  archive      = {J_NN},
  author       = {Claudio Gallicchio and Miguel C. Soriano},
  doi          = {10.1016/j.neunet.2025.108079},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108079},
  shortjournal = {Neural Netw.},
  title        = {Hardware friendly deep reservoir computing},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning global-view correlation for salient object detection in 3D point clouds. <em>NN</em>, <em>193</em>, 108078. (<a href='https://doi.org/10.1016/j.neunet.2025.108078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object detection (SOD) in point clouds has been an emerging research topic aimed at extracting most visually attractive objects from 3D point cloud representations. The inherent irregularity and unorderness of 3D point clouds complicate salient object detection, for it is hard to learn regular salient patterns like in 2D images. Meanwhile, existing methods typically focus on per-point context aggregation, while overlooking the scene-level global-view correlation crucial for saliency prediction. In this paper, we explore SOD in point clouds and introduce a novel approach that capitalizes on a comprehensive understanding of global-view 3D scenes. Our proposed method, the Saliency Filtration Network (SFN), meticulously refines saliency representations by isolating them from the common scene-dependent global-view correlations. Most importantly, SFN is characterized by a two-stage strategy, which involves aggregating long-range context information and purify saliency from globally scene-common correlations. To achieve this, we introduce the Residual Relation-aware Transformer module (RRT), which considers human visual perception to exploit global-view context dependencies. Additionally, we propose the Global Bilinear Correlation based Filtration module (GBCF) to perform saliency purification from global-view correlations. GBCF establishes dense correlations between global space and channel descriptors, which are then leveraged to properly purify saliency representations. Experimental evaluations on the PCSOD benchmark demonstrate that our proposed method achieves state-of-the-art accuracy and significantly outperforms other compared methods.},
  archive      = {J_NN},
  author       = {Kan Huang and Nannan Li and Zhijing Xu},
  doi          = {10.1016/j.neunet.2025.108078},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108078},
  shortjournal = {Neural Netw.},
  title        = {Learning global-view correlation for salient object detection in 3D point clouds},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A semi-looped functional for sampled-data synchronization of delayed neural networks considering communication delay. <em>NN</em>, <em>193</em>, 108076. (<a href='https://doi.org/10.1016/j.neunet.2025.108076'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the master-slave synchronization of delayed neural networks (DNNs) using a sampled-data controller with a communication delay. First, a novel semi-looped functional is constructed to incorporate more system information and to feature more relaxed constraints, particularly the negative-definite condition on its derivatives. Second, two zero-value equations are constructed to fully coordinate the relationships among the system information introduced by the proposed functional, thereby providing greater flexibility in synchronization controller design. As a result, the synchronization criterion with reduced conservatism is derived by employing these techniques. This criterion allows for the design of a sampled-data synchronization controller for DNNs that accommodates larger sampling intervals, thus reducing communication and computational burdens. Finally, three widely used numerical examples illustrate the effectiveness and superiority of the proposed criterion.},
  archive      = {J_NN},
  author       = {Yun-Hao An and Xing-Chen Shangguan and Hong-Zhang Wang and Yu-Fei Peng and Yun-Fan Liu and Chuan-Ke Zhang},
  doi          = {10.1016/j.neunet.2025.108076},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108076},
  shortjournal = {Neural Netw.},
  title        = {A semi-looped functional for sampled-data synchronization of delayed neural networks considering communication delay},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantity versus diversity: Influence of data on detecting EEG pathology with advanced ML models. <em>NN</em>, <em>193</em>, 108073. (<a href='https://doi.org/10.1016/j.neunet.2025.108073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the impact of quantity and diversity of data on the performance of various machine-learning models for detecting general EEG pathology. We utilized an EEG dataset of 2993 recordings from Temple University Hospital and a dataset of 55,787 recordings from Elmiko Biosignals sp. z o.o. The latter contains data from 39 hospitals and a diverse patient set with varied conditions. Thus, we introduce the Elmiko dataset – the largest publicly available EEG corpus. Our findings show that small and consistent datasets enable a wide range of models to achieve high accuracy; however, variations in pathological conditions, recording protocols, and labeling standards lead to significant performance degradation. Nonetheless, increasing the number of available recordings improves predictive accuracy and may even compensate for data diversity, particularly in neural networks based on attention mechanism or transformer architecture. A meta-model that combined these networks with a gradient-boosting approach using handcrafted features demonstrated superior performance across varied datasets.},
  archive      = {J_NN},
  author       = {Martyna Poziomska and Marian Dovgialo and Przemysław Olbratowski and Paweł Niedbalski and Paweł Ogniewski and Joanna Zych and Jacek Rogala and Jarosław Żygierewicz},
  doi          = {10.1016/j.neunet.2025.108073},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108073},
  shortjournal = {Neural Netw.},
  title        = {Quantity versus diversity: Influence of data on detecting EEG pathology with advanced ML models},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). From external to internal: Step-wise feature enhancement network for image-text retrieval. <em>NN</em>, <em>193</em>, 108072. (<a href='https://doi.org/10.1016/j.neunet.2025.108072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-Text Retrieval (ITR) is a challenging task due to the inherent inconsistency in feature representations across different modalities, commonly referred to as the “heterogeneity gap”. To bridge this gap, establishing stronger associations between images and texts by capturing semantic cues as comprehensively as possible is an effective approach. However, existing ITR methods cannot completely capture semantic cues derived from a large-scale image-text corpus beyond a single image-text pair. Therefore, we propose a two-layer Step-wise Feature Enhancement (SFE) Network to establish a semantic propagation pathway, guiding semantic information flow progressively from the external layer to the internal layer. In Step 1, External Semantic Cues (ESC) are captured from visual and textual semantic concepts based on patch-level, instance-level, and neighbor-level co-occurrences within an image-text corpus. Then, visual and textual features are enhanced in the external layer with ESC by mining co-occurrences at the patch, instance, and neighbor levels. Note that Instance-level and Neighbor-level co-occurrence belong to cross-modal ESC, which can significantly facilitate modality interaction in the external layer. In step 2, SFE first fuses semantic information propagated from step 1, and then enhances visual and textual features in the internal layer by mining Internal Semantic Cues (ISC) through cross-modal context. Specifically, visual and textual features are concatenated with their corresponding cross-modal contextual features to further enhance modality interaction within the internal layer. Experimental results demonstrate the superiority of the proposed SFE network over state-of-the-art ITR methods.},
  archive      = {J_NN},
  author       = {Jingyao Wang and Zheng Liu and Shanshan Gao and Junhao Xu and Changhao Li},
  doi          = {10.1016/j.neunet.2025.108072},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108072},
  shortjournal = {Neural Netw.},
  title        = {From external to internal: Step-wise feature enhancement network for image-text retrieval},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning from history for personalized federated learning. <em>NN</em>, <em>193</em>, 108071. (<a href='https://doi.org/10.1016/j.neunet.2025.108071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized Federated Learning (pFL) has received extensive attentions, due to its ability to effectively process non-IID data distributed among different clients. However, most of the existing pFL methods focus on the collaboration between global and local models to enrich the personalization process, but ignoring a lot of valuable historical information, which represents the unique learning trajectory of each client. In this paper, we propose a pFL method called FedLFH, which introduces a tracking variable that allows each client to preserve historical information to facilitate personalization. We set up a global feature extractor and a personalized feature extractor for each client, to achieve the effective transfer of knowledge between the global model and the personalized model integrated with historical information. To evaluate the effectiveness, we set up exhaustive experiments on various benchmark datasets. The results show that our method outperforms twelve state-of-the-art methods with different experimental settings.},
  archive      = {J_NN},
  author       = {Yingxun Fu and Shulan Yin and Li Ma and Jie Liu},
  doi          = {10.1016/j.neunet.2025.108071},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108071},
  shortjournal = {Neural Netw.},
  title        = {Learning from history for personalized federated learning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mitigating low-frequency bias: Feature recalibration and frequency attention regularization for adversarial robustness. <em>NN</em>, <em>193</em>, 108070. (<a href='https://doi.org/10.1016/j.neunet.2025.108070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring the robustness of deep neural networks against adversarial attacks remains a fundamental challenge in computer vision. While adversarial training (AT) has emerged as a promising defense strategy, our analysis reveals a critical limitation: AT-trained models exhibit a bias toward low-frequency features while neglecting high-frequency components. This bias is particularly concerning as each frequency component carries distinct and crucial information: low-frequency features encode fundamental structural patterns, while high-frequency features capture intricate details and textures. To address this limitation, we propose High-Frequency Feature Disentanglement and Recalibration (HFDR), a novel module that strategically separates and recalibrates frequency-specific features to capture latent semantic cues. We further introduce frequency attention regularization to harmonize feature extraction across the frequency spectrum and mitigate the inherent low-frequency bias of AT. Extensive experiments on CIFAR-10, CIFAR-100, and ImageNet-1K demonstrate that HFDR consistently enhances adversarial robustness. It achieves a 2.89 % gain on CIFAR-100 with WRN34-10, and improves robustness by 3.09 % on ImageNet-1K, with a 4.89 % gain on ViT-B against AutoAttack. These results highlight the method’s adaptability to both convolutional and transformer-based architectures. Code is available at https://github.com/KejiaZhang-Robust/HFDR .},
  archive      = {J_NN},
  author       = {Kejia Zhang and Juanjuan Weng and Yuanzheng Cai and Shaozi Li and Zhiming Luo},
  doi          = {10.1016/j.neunet.2025.108070},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108070},
  shortjournal = {Neural Netw.},
  title        = {Mitigating low-frequency bias: Feature recalibration and frequency attention regularization for adversarial robustness},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual aggregation based joint-modal similarity hashing for cross-modal retrieval. <em>NN</em>, <em>193</em>, 108069. (<a href='https://doi.org/10.1016/j.neunet.2025.108069'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal hashing aims to leverage hashing functions to map multimodal data into a unified low-dimensional space, realizing efficient cross-modal retrieval. In particular, unsupervised cross-modal hashing methods attract significant attention for not needing external label information. However, in the field of unsupervised cross-modal hashing, there are several pressing issues to address: (1) how to facilitate semantic alignment between modalities, and (2) how to effectively capture the intrinsic relationships between data, thereby constructing a more reliable affinity matrix to assist in the learning of hash codes. In this paper, Dual Aggregation-Based Joint-modal Similarity Hashing (DAJSH) is proposed to overcome these challenges. To enhance cross-modal semantic alignment, we employ a Transformer encoder to fuse image and text features and introduce a contrastive loss to optimize cross-modal consistency. Additionally, for constructing a more reliable affinity matrix to assist hash code learning, we propose a dual-aggregation affinity matrix construction scheme. This scheme integrates intra-modal cosine similarity and Euclidean distance while incorporating cross-modal similarity, thereby maximally preserving cross-modal semantic information. Experimental results demonstrate that our method achieves performance improvements of 1.9 % ∼ 5.1 %, 0.9 % ∼ 5.8 % and 0.6 % ∼ 2.6 % over state-of-the-art approaches on the MIR Flickr, NUS-WIDE and MS COCO benchmark datasets, respectively.},
  archive      = {J_NN},
  author       = {Le Xu and Jun Yin},
  doi          = {10.1016/j.neunet.2025.108069},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108069},
  shortjournal = {Neural Netw.},
  title        = {Dual aggregation based joint-modal similarity hashing for cross-modal retrieval},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Large-margin softmax loss using synthetic virtual class. <em>NN</em>, <em>193</em>, 108068. (<a href='https://doi.org/10.1016/j.neunet.2025.108068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary challenge of large-margin learning lies in designing classifiers with strong discriminative power. Although existing large margin methods have achieved success in various classification tasks, they often suffer from weak task generalization and imbalanced handling of easy and hard samples. In this paper, we propose a margin adaptive synthetic virtual Softmax loss (SV-Softmax), which dynamically generates virtual prototypes by synthesizing embedded features and their corresponding prototypes. These virtual prototypes can adaptively adjust the margin based on the spatial distribution of embedded features, promoting the proximity of embedded features to their corresponding prototypes and creating clear and discriminative decision boundaries. Furthermore, we introduce a virtual prototype insertion strategy based on hard sample mining, where different synthesis strategies are applied to correctly and incorrectly classified samples, emphasizing the importance of hard samples. SV-Softmax is plug-and-play with minimal computational complexity, without requiring feature or weight normalization nor relying on task-specific hyperparameter tuning. Extensive comparative experiments on multiple visual classification and face recognition datasets demonstrate that SV-Softmax achieves competitive or superior performance compared to nine state-of-the-art methods. The code available at: https://github.com/10zhou/SV-Softmax .},
  archive      = {J_NN},
  author       = {Jiuzhou Chen and Xiangyang Huang and Shudong Zhang},
  doi          = {10.1016/j.neunet.2025.108068},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108068},
  shortjournal = {Neural Netw.},
  title        = {Large-margin softmax loss using synthetic virtual class},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TATrack: Target-oriented adaptive vision transformer for UAV tracking. <em>NN</em>, <em>193</em>, 108067. (<a href='https://doi.org/10.1016/j.neunet.2025.108067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) tracking requires accurate target localization from aerial top-down perspectives while operating under the computational constraints of aerial platforms. Current mainstream UAV trackers, constrained by the limited resources, predominantly employ lightweight Convolutional Neural Network (CNN) extractor, coupled with an appearance-based fusion mechanism. The absence of comprehensive target perception significantly constrains the balance between tracking accuracy and computational efficiency. To address this, we propose a target-oriented adaptive vision transformer for UAV tracking, named TATrack. TATrack utilizes a novel efficient transformer model, TA-ViT, to perform joint feature modeling and interaction under the orientation of the target. Specifically, TA-ViT employs an adaptive scoring suspension mechanism, wherein redundant network layers are bypassed when all token scores meet the suspension criteria, thereby enhancing inference speed. Moreover, positional information is utilized as a spatial-temporal prompt to enhance appearance-matching quality over time. By introducing location priors, we strengthen the visual perception of the target, which improves the target orientation and temporal continuity of the predicted position. Extensive experiments conducted across five UAV tracking benchmarks demonstrate that our method achieves an optimal balance between computational efficiency and tracking accuracy. The code will be available publicly.},
  archive      = {J_NN},
  author       = {Wenkang Zhang and Tianyang Xu and Fei Xie and Jinhui Wu and Wankou Yang},
  doi          = {10.1016/j.neunet.2025.108067},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108067},
  shortjournal = {Neural Netw.},
  title        = {TATrack: Target-oriented adaptive vision transformer for UAV tracking},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Auction-guided model diffusion for communication-efficient federated learning on non-IID data. <em>NN</em>, <em>193</em>, 108066. (<a href='https://doi.org/10.1016/j.neunet.2025.108066'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 6G mobile communication systems, various AI-based network functions and applications have been standardized. Federated learning (FL) is adopted as the core learning architecture for 6G systems to avoid privacy leakage from mobile user data. However, in FL, users with non-independent and identically distributed (non-IID) datasets can deteriorate the performance of the global model because the convergence direction of the gradient for each dataset is different, thereby inducing a weight divergence problem. To address this problem, we propose a novel diffusion strategy for machine learning (ML) models (FedDif) to maximize the performance of the global model with non-IID data. FedDif enables the local model to learn different distributions before parameter aggregation by passing the local models to users via device-to-device communication. Furthermore, we theoretically demonstrate that FedDif can circumvent the weight-divergence problem. Based on this theory, we propose a communication-efficient diffusion strategy for ML models that can determine the trade-off between learning performance and communication cost using auction theory. The experimental results show that FedDif improves the top-1 test accuracy by up to 20.07 %p and reduces communication costs by up to 45.27 % compared to FedAvg.},
  archive      = {J_NN},
  author       = {Seyoung Ahn and Soohyeong Kim and Yongseok Kwon and Jiseung Youn and Joohan Park and Sunghyun Cho},
  doi          = {10.1016/j.neunet.2025.108066},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108066},
  shortjournal = {Neural Netw.},
  title        = {Auction-guided model diffusion for communication-efficient federated learning on non-IID data},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dormant key: Unlocking universal adversarial control in text-to-image models. <em>NN</em>, <em>193</em>, 108065. (<a href='https://doi.org/10.1016/j.neunet.2025.108065'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-Image (T2I) diffusion models have gained significant traction due to their remarkable image generation capabilities, raising growing concerns over the security risks associated with their use. Prior studies have shown that malicious users can subtly modify prompts to produce visually misleading or Not-Safe-For-Work (NSFW) content, even bypassing existing safety filters. Existing adversarial attacks are often optimized for specific prompts, limiting their generalizability, and their text-space perturbations are easily detectable by current defenses. To address these limitations, we propose a universal adversarial attack framework called dormant key. It appends a transferable suffix that can be appended as a “plug-in” to any text input to guide the generated image toward a specific target. To ensure robustness across diverse prompts, we introduce a novel hierarchical gradient aggregation strategy that stabilizes optimization over prompt batches. This enables efficient learning of universal perturbations in the text space, improving both attack transferability and imperceptibility. Experimental results show that our method effectively balances attack performance and stealth. In NSFW generation tasks, it bypasses major safety mechanisms, including keyword filtering, semantic analysis, and text classifiers, and achieves over 18 % improvement in success rate over baselines.},
  archive      = {J_NN},
  author       = {Jingqi Hu and Li Li and Hanzhou Wu and Huixin Luo and Xinpeng Zhang},
  doi          = {10.1016/j.neunet.2025.108065},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108065},
  shortjournal = {Neural Netw.},
  title        = {Dormant key: Unlocking universal adversarial control in text-to-image models},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data-free knowledge distillation via text-noise fusion and dynamic adversarial temperature. <em>NN</em>, <em>193</em>, 108061. (<a href='https://doi.org/10.1016/j.neunet.2025.108061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-Free Knowledge Distillation (DFKD) have achieved significant breakthroughs, enabling the effective transfer of knowledge from teacher neural networks to student neural networks without reliance on original data. However, a significant challenge faced by existing methods that attempt to generate samples from random noise is that the noise lacks meaningful information, such as class-specific semantic information. Consequently, the absence of meaningful information makes it difficult for the generator to map this noise to the ground-truth data distribution, resulting in the generation of low-quality training samples. In addition, existing methods typically employ a fixed temperature for adversarial training of the generator, which limits the diversity in the difficulty of the synthesized data. In this paper, we propose Text-Noise Fusion and Dynamic Adversarial Temperature method (TNFDAT), a novel method that combines random noise with meaningful class-specific text embeddings (CSTE) as input and implements dynamic adjustment of the adversarial training temperature for the generator. In addition, we introduce an adaptive sample weighting strategy to enhance the effectiveness of knowledge distillation. CSTE is developed based on a pre-trained language model, and its significance lies in its ability to capture meaningful inter-class information, thereby enabling the generation of high-quality samples. Simultaneously, the dynamic adversarial temperature module effectively alleviates the issue of insufficient diversity in synthesized samples by precisely modulating the generator’s temperature during adversarial training, playing a key role in enhancing sample diversity. Through continuous and dynamic temperature adjustment of the generator in the adversarial training, thereby significantly improving the overall diversity of the synthesized samples. At the knowledge distillation stage, We determine the distillation weights of the synthesized samples based on the information entropy of the output from both teacher and student networks. By differentiating the contributions of different synthesized samples during the distillation process, we effectively enhance the generalization ability of the knowledge distillation framework and improve the robustness of the student network. Experiments demonstrate that our method outperforms the state-of-the-art methods across various benchmarks and pairs of teachers and students.},
  archive      = {J_NN},
  author       = {Deheng Zeng and Zhengyang Wu and Yunwen Chen and Zhenhua Huang},
  doi          = {10.1016/j.neunet.2025.108061},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108061},
  shortjournal = {Neural Netw.},
  title        = {Data-free knowledge distillation via text-noise fusion and dynamic adversarial temperature},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EpilepsyFM: A domain-specific foundation model for epileptic representation learning using EEG signals. <em>NN</em>, <em>193</em>, 108060. (<a href='https://doi.org/10.1016/j.neunet.2025.108060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy with its complex seizure mechanisms and diverse clinical manifestations, presents numerous challenges for clinical diagnosis and treatment, while electroencephalography (EEG) plays a crucial and irreplaceable role in its diagnosis. Although general-purpose foundation models have demonstrated some capability in knowledge processing, they still face challenges in capturing specific disease features and dealing with data scarcity in highly specialized domains such as epilepsy. To address these issues, we propose a domain-specific foundation model for epilepsy-EpilepsyFM, designed to learn generalized representations of epilepsy to support various downstream tasks. EpilepsyFM utilizes self-supervised pre-training, integrating clinical EEG data from top-tier hospital neurosurgery departments with large-scale public datasets such as TUH EEG Corpus, covering a variety of patient conditions to enhance the model’s representation capacity. The model employs a discrete neural tokenizer to construct a domain-specific neural codebook for epilepsy and proposes a brain region masking strategy based on the mechanisms of clustered neuronal discharges during seizures, allowing for more effective capture of the spatiotemporal features of seizures. Furthermore, EpilepsyFM integrates temporal, spectral, and spatial encoding modules to fully exploit the multidimensional propagation patterns of epilepsy. Experimental results show that EpilepsyFM achieves state-of-the-art performance in six downstream tasks, including seizure detection, seizure type detection, short- and long-term signal forecasting, frequency-phase forecasting, anti-seizure medication efficacy analysis, and radiofrequency thermocoagulation surgery analysis, demonstrating outstanding generalization ability and broad clinical application potential.},
  archive      = {J_NN},
  author       = {Zhuoyi Li and Ning Zhu and Yifan Chen and Beibei Chen and Qiufeng Dong and Lin Gan and Shijie Zhao and Zhiqiang Yan and Tuo Zhang},
  doi          = {10.1016/j.neunet.2025.108060},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108060},
  shortjournal = {Neural Netw.},
  title        = {EpilepsyFM: A domain-specific foundation model for epileptic representation learning using EEG signals},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A spatial-frequency hybrid restoration network for JPEG compressed image deblurring. <em>NN</em>, <em>193</em>, 108059. (<a href='https://doi.org/10.1016/j.neunet.2025.108059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image deblurring and compression-artifact removal are both ill-posed inverse problems in low-level vision tasks. So far, although numerous image deblurring and compression-artifact removal methods have been proposed respectively, the research for explicit handling blur and compression-artifact coexisting degradation image (BCDI) is rare. In the BCDI, image contents will be damaged more seriously, especially for edges and texture details. Therefore, the restoration of the BCDI is a more severe ill-posed inverse problem, and deep mining of local and global feature information is critical for effective BCDI restoration. To this end, we propose a spatial-frequency hybrid restoration network (SFHRN) for explicit and effective joint-photographic-experts-group (JPEG) compressed BCDI restoration. Specifically, according to the nature of JPEG compression artifacts, we propose a spatial-frequency hybrid block (SFHB), which includes a dual-branch structure and an information screening strategy (ISS). First, for the dual-branch structure, we design a patch-level channel attention branch (PCAB) and a pixel-level global attention branch (PGAB) to fully exploit local context information in the spatial domain and mine the global feature information in the frequency domain respectively. Secondly, we design a simple and effective information screening strategy (ISS) to discriminatively determine which pixels and channels should be retained and enhanced in frequency and spatial domains respectively for latent clear image restoration. Finally, for the first time, we build the blur and compression-artifact coexisting degradation datasets by adding various degrees of JPEG compression-artifact into existing benchmark deblurring datasets, e.g. GoPro and HIDE, named as GoPro-Compressed and HIDE-Compressed respectively. Extensive experiments demonstrate the superiority of our proposed SFHRN in terms of both performance and computational cost.},
  archive      = {J_NN},
  author       = {Shu Tang and Hanwen Zhang and Xinbo Gao and Shuli Yang and Jiaxu Leng and Zengdan Pan and Hao Tian},
  doi          = {10.1016/j.neunet.2025.108059},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108059},
  shortjournal = {Neural Netw.},
  title        = {A spatial-frequency hybrid restoration network for JPEG compressed image deblurring},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Region-guided attack on the segment anything model. <em>NN</em>, <em>193</em>, 108058. (<a href='https://doi.org/10.1016/j.neunet.2025.108058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Segment Anything Model (SAM) is a cornerstone of image segmentation, demonstrating exceptional performance across various applications, particularly in autonomous driving and medical imaging, where precise segmentation is crucial. However, SAM is vulnerable to adversarial attacks that can significantly impair its functionality through minor input perturbations. Traditional techniques, such as FGSM and PGD, are often ineffective in segmentation tasks due to their reliance on global perturbations that overlook spatial nuances. Recent methods like Attack-SAM-K and UAD have begun to address these challenges, but they frequently depend on external cues and do not fully leverage the structural interdependencies within segmentation processes. This limitation underscores the need for a novel adversarial strategy that exploits the unique characteristics of segmentation tasks. In response, we introduce the Region-Guided Attack (RGA), designed specifically for SAM. RGA utilizes a Region-Guided Map (RGM) to manipulate segmented regions, enabling targeted perturbations that fragment large segments and expand smaller ones, resulting in erroneous outputs from SAM. Our experiments demonstrate that RGA achieves high success rates in both white-box and black-box scenarios, emphasizing the need for robust defenses against such sophisticated attacks. Our codes are available at https://github.com/AbeLiuXL/RGA .},
  archive      = {J_NN},
  author       = {Xiaoliang Liu and Furao Shen and Jian Zhao},
  doi          = {10.1016/j.neunet.2025.108058},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108058},
  shortjournal = {Neural Netw.},
  title        = {Region-guided attack on the segment anything model},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Inter-modality feature prediction through multimodal fusion for 3D shape defect detection. <em>NN</em>, <em>193</em>, 108057. (<a href='https://doi.org/10.1016/j.neunet.2025.108057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D shape defect detection plays an important role in autonomous industrial inspection. However, accurate detection of anomalies remains challenging due to the complexity of multimodal sensor data, especially when both color and structural information are required. In this work, we propose a lightweight inter-modality feature prediction framework that effectively utilizes multimodal fused features from the inputs of RGB, depth and point clouds for efficient 3D shape defect detection. Our proposed framework consists of three main key components: 1) Modality-specific pre-trained feature extractor networks, 2) Multi-level Adaptive Dual-Modal Gated Fusion (ADMGF) module that effectively combines the RGB and depth features to obtain rich spatial and contextual information. 3) A lightweight inter-modal feature prediction network that utilizes the fused RGB-Depth features to predict the corresponding point cloud features and vice versa, forming a bidirectional learning mechanism through tri-modal inputs. Our model eliminates the need for large memory banks or pixel-level reconstructions. Comprehensive experiments on the MVTec3D-AD and Eyecandies datasets showed significant improvements in performance over the state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Mujtaba Asad and Waqar Azeem and Hafiz Tayyab Mustafa and Yuming Fang and Jie Yang and Yifan Zuo and Wei Liu},
  doi          = {10.1016/j.neunet.2025.108057},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108057},
  shortjournal = {Neural Netw.},
  title        = {Inter-modality feature prediction through multimodal fusion for 3D shape defect detection},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FA-GCL: Feature-augmented graph contrastive learning method. <em>NN</em>, <em>193</em>, 108045. (<a href='https://doi.org/10.1016/j.neunet.2025.108045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning seeks to improve the efficacy of graph representation learning by comparing various graph representations. Existing approaches predominantly rely on node attributes or structural information for contrastive analysis. However, in real-world applications, node attribute information can be incomplete or entirely absent, while structure-enhancement methods often generate false positive samples. To mitigate these issues, we propose a feature augmentation-based graph contrastive learning method (FA-GCL) that enhances the accuracy and robustness of graph representations. Specifically, our approach first implements a dynamic dropout-based feature augmentation technique, which adjusts dropout rates dynamically using a triangular wave function, thereby significantly improving model performance. Additionally, we introduce two complementary feature augmentation methods based on singular value decomposition: a theoretically rigorous full SVD approach and a computationally efficient randomized projection-based SVD method that achieves linear complexity while preserving spectral properties. Both methods add controlled noise to singular values and reconstruct features to create high-quality augmented samples. Comprehensive experiments were conducted on twelve widely used graph datasets. The results indicate that FA-GCL consistently outperforms baseline methods in node classification, node clustering, and graph classification tasks.},
  archive      = {J_NN},
  author       = {Long Xu and Honghui Chen},
  doi          = {10.1016/j.neunet.2025.108045},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108045},
  shortjournal = {Neural Netw.},
  title        = {FA-GCL: Feature-augmented graph contrastive learning method},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploring the white matter disruptions for schizophrenia based on convolutional ensemble kernel randomized network. <em>NN</em>, <em>193</em>, 108044. (<a href='https://doi.org/10.1016/j.neunet.2025.108044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Schizophrenia (SZ) is characterized by cognitive impairments and widespread structural brain alterations. The potential adaptability of convolutional neural networks (CNN) to identify the complex and extensive brain alterations associated with SZ relies on its automatic feature learning capability. Structural magnetic resonance imaging (sMRI) is a non-invasive technique for investigating disruptions related to white matter (WM), grey matter (GM), and cerebrospinal fluid (CSF) of brain regions. We proposed an intrinsic CNN ensemble of kernel ridge regression-based random vector functional link (KRR-RVFL) architecture to explore the WM disruptions for SZ. In this approach, we have integrated an eight-layer CNN into five different KRR-RVFL classifiers for feature extraction and classification. The classifiers’ outputs are averaged and fed to the final KRR-RVFL classifier for final classification. The KRR-RVFL classifier enhances stability and robustness by addressing non-linearity limitations in the standard RVFL network. The proposed CNN ensemble KRR-RVFL outperforms other classifiers with 97.33 % accuracy for the WM region, showing significant disruptions compared to GM and CSF. Furthermore, we calculated the correlation coefficient between tissue volumes and the scale of symptoms for GM and WM. According to the results, tissue volume for WM is reduced more than GM for SZ. The proposed model assists clinicians in exploring the role of WM disruptions for accurate diagnosis of SZ.},
  archive      = {J_NN},
  author       = {S.A. Varaprasad and Tripti Goel and M. Tanveer},
  doi          = {10.1016/j.neunet.2025.108044},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108044},
  shortjournal = {Neural Netw.},
  title        = {Exploring the white matter disruptions for schizophrenia based on convolutional ensemble kernel randomized network},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tangency portfolios using graph neural networks. <em>NN</em>, <em>193</em>, 108043. (<a href='https://doi.org/10.1016/j.neunet.2025.108043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to modern portfolio theory, the weights of tangency portfolios are solely determined by the expected returns and the covariance matrix of asset returns. However, estimating expected returns and the covariance matrix poses significant challenges, especially when the number of assets is large. Considering the supply-demand relationships between companies issuing stocks, we propose that incorporating industry chain relationships can enhance the accurate estimation of the covariance matrix. Specifically, we present a method that employs Graph Neural Networks (GNNs) to estimate tangency portfolio weights by aggregating stock features based on the industry chain graph and using the aggregated features to estimate the expected returns and the covariance matrix. In addition to incorporating additional industry information, we propose two strategies to enhance the efficiency of estimation: 1) Calculating the dynamic modularity of the stock relationship graph using aggregated node features and constraining the estimated correlations to exhibit a clustered structure by minimizing modularity. 2) Adding a historical ranking regularization to the expected returns. We validate our approach on two daily stock datasets, demonstrating that our method effectively predicts portfolio returns and Sharpe ratios.},
  archive      = {J_NN},
  author       = {Bin Liu and Haolong Li and Linshuang Kang},
  doi          = {10.1016/j.neunet.2025.108043},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108043},
  shortjournal = {Neural Netw.},
  title        = {Tangency portfolios using graph neural networks},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-perspective decoupling network for kidney tumor segmentation on CT images. <em>NN</em>, <em>193</em>, 108042. (<a href='https://doi.org/10.1016/j.neunet.2025.108042'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key challenges in kidney tumor segmentation include unpredictable location, high similarity among objects, and variability in boundaries. Existing approaches mostly handle these challenges from an object-agnostic perspective or a single decoupling perspective, which limits their ability to address all the aforementioned challenges. To tackle these problems, we propose a Dual-perspective Decoupling Network (DDNet), which consists of the Dual-perspective Decoupling Module (DDM) and the Edge Refinement Module (ERM). The DDM decouples features from two perspectives: body/edge decoupling and inter-object decoupling. In order to decouple the body and edge, we propose the Multi-scale Decoupling Branch (MDB), which employs multi-scale convolutions to increase the receptive field and improve object localization by aggregating objects toward the center. It then decouples the body and boundary. The Object Decoupling Branch (ODB) employs prediction maps to perform self-attention and selectively decouples background, kidney, and tumor to enhance the final body part segmentation. In order to make full use of the decoupled boundary information from the MDB, the ERM utilizes boundary features derived from the MDB to effectively guide the encoder’s low-level features to overcome boundary variability and generate more precise boundaries. We evaluate DDNet on two different public kidney tumor segmentation datasets (KiTS19 and KiTS21) and a clinical dataset, called KAT-Seg. Compared to eleven other state-of-the-art segmentation methods, our DDNet yields the best Dice score of 86.08 %, 85.45 % and 88.03 % on KiTS19, KiTS21 and KAT-Seg, respectively, which is at least 1.63 %, 0.72 % and 1.72 % higher than the other methods.},
  archive      = {J_NN},
  author       = {Xinya Gan and Sheng Zhu and Yuan Zhang and Zhiqiang Wang and Xiongjun Ye and Kai Hu and Xieping Gao},
  doi          = {10.1016/j.neunet.2025.108042},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108042},
  shortjournal = {Neural Netw.},
  title        = {Dual-perspective decoupling network for kidney tumor segmentation on CT images},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stabilization of delayed stochastic reaction-diffusion cohen-grossberg neural networks via variable gain intermittent boundary control. <em>NN</em>, <em>193</em>, 108041. (<a href='https://doi.org/10.1016/j.neunet.2025.108041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel variable gain intermittent boundary control (VGIBC) approach for stabilizing delayed stochastic reaction-diffusion Cohen-Grossberg neural networks (SRDCGNN). In contrast to traditional constant gain intermittent boundary control (CGIBC) methods, the proposed VGIBC framework dynamically adjusts the control gain based on the operational duration within each control cycle, thereby improving adaptability to variations in work interval lengths. The time-varying control gain is designed using a piecewise interpolation method across work intervals, defined by a finite set of static gain matrices. To address the switching dynamics of the intermittently controlled neural networks and exploit the flexibility offered by the dynamic control gain, a piecewise Lyapunov function is employed to fit the dynamic structure of the control gain. By applying distinct Razumikhin-based solution estimation techniques: one tailored to active control periods and the other to rest periods, new mean square intermittent stabilization criteria are derived that show reduced conservatism compared to CGIBC-based results. The optimal control gain function is determined by solving a convex optimization procedure that minimizes the control rate at a given level of gain norm limitation. The efficacy of the proposed VGIBC strategy is validated through two numerical examples.},
  archive      = {J_NN},
  author       = {Yili Wang and Wu-Hua Chen and Shuning Niu and Xiaoyun Lu},
  doi          = {10.1016/j.neunet.2025.108041},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108041},
  shortjournal = {Neural Netw.},
  title        = {Stabilization of delayed stochastic reaction-diffusion cohen-grossberg neural networks via variable gain intermittent boundary control},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploring the mechanical behavior of friction material composites using artificial intelligence. <em>NN</em>, <em>193</em>, 108040. (<a href='https://doi.org/10.1016/j.neunet.2025.108040'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of artificial intelligence techniques is becoming increasingly valuable for several areas of knowledge, allowing to extract information, predict patterns, work with complex problems, and generate solutions that would not be achievable by other techniques without an extremely high computational cost or else, numerous physical experiments, with high execution costs and which often do not achieve the desired result. In this work, artificial intelligence (AI) was used to create mathematical models for four properties of friction material composites from an extensive database containing the chemical composition and the respective mechanical properties. An algorithm capable of predicting mechanical results of friction materials based on chemical composition, optimizing an existing composition, and proposing new (previously non-existent) compositions was proposed based on the desired values of each mechanical property. The algorithm combines rule-based instructions, neural networks, and particle swarm optimization. Physical samples based on the algorithm’s prediction were produced, making it possible to assess the predictive power of the models and further understand the need for improvements in the tool built for predicting new friction materials. The root mean square error (RMSE) of predictions from multilinear models was significantly higher than those from artificial neural networks when predicting results of non-existent previous compositions. The smallest observed increase in RMSE was 20.9 %, while the largest was 90.2 %. On average, the RMSE for multilinear models was 48.6 % larger, highlighting the superior accuracy of neural network predictions from previously non-existent compositions.},
  archive      = {J_NN},
  author       = {D. Matté and C.A. Perottoni},
  doi          = {10.1016/j.neunet.2025.108040},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108040},
  shortjournal = {Neural Netw.},
  title        = {Exploring the mechanical behavior of friction material composites using artificial intelligence},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). State-space modeling in long sequence processing: A survey on recurrence in the transformer era. <em>NN</em>, <em>193</em>, 108039. (<a href='https://doi.org/10.1016/j.neunet.2025.108039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively learning from sequential data is a longstanding goal of Artificial Intelligence, especially in the case of long sequences. From the dawn of Machine Learning, several researchers have pursued algorithms and architectures capable of processing sequences of patterns, retaining information about past inputs while still leveraging future data, without losing precious long-term dependencies and correlations. While such an ultimate goal is inspired by the human hallmark of continuous real-time processing of sensory information, several solutions have simplified the learning paradigm by artificially limiting the processed context or dealing with sequences of limited length, given in advance. These solutions were further emphasized by the ubiquity of Transformers, which initially overshadowed the role of Recurrent Neural Nets. However, recurrent networks are currently experiencing a strong recent revival due to the growing popularity of (deep) State-Space models and novel instances of large-context Transformers, which are both based on recurrent computations that aim to go beyond several limits of currently ubiquitous technologies. The fast development of Large Language Models has renewed the interest in efficient solutions to process data over time. This survey provides an in-depth summary of the latest approaches that are based on recurrent models for sequential data processing. A complete taxonomy of recent trends in architectural and algorithmic solutions is reported and discussed, guiding researchers in this appealing research field. The emerging picture suggests that there is room for exploring novel routes, constituted by learning algorithms that depart from the standard Backpropagation Through Time, towards a more realistic scenario where patterns are effectively processed online, leveraging local-forward computations, and opening new directions for research on this topic.},
  archive      = {J_NN},
  author       = {Matteo Tiezzi and Michele Casoni and Alessandro Betti and Marco Gori and Stefano Melacci},
  doi          = {10.1016/j.neunet.2025.108039},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108039},
  shortjournal = {Neural Netw.},
  title        = {State-space modeling in long sequence processing: A survey on recurrence in the transformer era},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Heterogeneity-aware high-efficiency federated learning with hybrid synchronous-asynchronous splitting strategy. <em>NN</em>, <em>193</em>, 108038. (<a href='https://doi.org/10.1016/j.neunet.2025.108038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) offers a promising privacy-preserving framework for collaborative global model training without exposing local private data. However, system heterogeneity in FL causes the straggler issue, where resource-limited edge devices delay global model aggregation. Existing approaches, such as asynchronous mechanisms or kick-out methods, primarily focus on optimizing model convergence efficiency but often overlook edge resource constraints, potentially resulting in model bias toward high-performance devices or omission of critical data. To cope with this, we propose HA-HEFL, a novel Heterogeneity-Aware High-Efficiency Federated Learning framework to balance training efficiency, model accuracy, and resource consumption. HA-HEFL features a resource-aware adaptive model customization mechanism that dynamically tailors suitable model architectures based on device capabilities using neuron-level profiling and priority-based selection methods. Additionally, HA-HEFL employs a hybrid synchronous-asynchronous split training strategy, dividing into synchronous edge feature extraction and asynchronous global classifier updates based on knowledge distillation, thereby enhancing training efficiency and model performance. A baseline-prioritized weighted aggregation scheme is adopted to further ensure balanced global model updates. Extensive experiments on three real-world datasets demonstrate that HA-HEFL significantly improves convergence speed, model accuracy, and reduces network traffic compared to state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Zijian Li and Boyuan Li and Kunyu Zhang and Bingcai Wei and Hongbo Liu and Zihan Chen and Xinqiang Xie and Tony Q.S. Quek},
  doi          = {10.1016/j.neunet.2025.108038},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108038},
  shortjournal = {Neural Netw.},
  title        = {Heterogeneity-aware high-efficiency federated learning with hybrid synchronous-asynchronous splitting strategy},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PathTGSeg: The pathologic image segmentation of breast cancer via template matching and graphic calculation. <em>NN</em>, <em>193</em>, 108037. (<a href='https://doi.org/10.1016/j.neunet.2025.108037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pathologic image analysis is important for providing fundamental references for the clinical diagnosis of breast cancer. Although many methods have achieved outstanding performance in the pathologic image segmentation of breast cancer, there are still two issues limiting further development in this task. First, diverse and complex appearances exist within the observed scope for the same type of breast cancer. Second, inconsistent distribution and ambiguous borders of cancer tissues also pose challenges to obtaining accurate diagnoses of tumor regions. Therefore, to address these issues, this work proposes a template and graphic visual transformer network to perform pathologic image segmentation of breast cancer. The template visual transformer introduces a novel segmentation pattern that leverages templates selected from typical cases of breast cancer to locate cancer lesions by comparing the similarity between the templates and latent regions. Meanwhile, the graphic visual transformer builds graphical features to describe the distribution relationships of cancer lesions more accurately. Extensive experiments conducted on BIS5k and other zero-shot datasets show that our method not only achieves more robust performance on pathologic images of breast cancer when pretrained on data of the same type, but also demonstrates great potential on zero-shot pathologic images.},
  archive      = {J_NN},
  author       = {Junjie Li and Kaixiang Yan and Chuandong Guo},
  doi          = {10.1016/j.neunet.2025.108037},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108037},
  shortjournal = {Neural Netw.},
  title        = {PathTGSeg: The pathologic image segmentation of breast cancer via template matching and graphic calculation},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MSG: Stealing data from pruned neural networks via malicious sparsity guidance. <em>NN</em>, <em>193</em>, 108036. (<a href='https://doi.org/10.1016/j.neunet.2025.108036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread adoption of machine learning cloud platforms, concerns over potential privacy risks in model training algorithms have grown. Attackers can exploit these platforms by deploying malicious algorithms to execute correlation value encoding attacks (CVEA). This attack mainly leverages the model’s huge capacity for memorization, covertly embedding training data into the model’s parameters. Once the model is published, attackers can extract these parameters and recover sensitive data. In this paper, we empirically demonstrate for the first time that common model pruning techniques significantly diminish the effectiveness and stealthiness of CVEA, as they reduce redundant parameters. We further propose a new pruning-resistant parameter encoding attack via Malicious Sparsity Guidance (MSG), which strategically embeds data into a selected subset of model parameters while actively guiding the pruning process. Specifically, MSG manipulates parameter importance during training to increase the likelihood that the parameters carrying embedded information are preserved after pruning. To further enhance stealthiness, we integrate knowledge transfer, allowing the encoded model to maintain high prediction accuracy before and after pruning. Comprehensive experiments across seven datasets and five model architectures demonstrate that MSG enables attackers to extract high-quality training data before and after model pruning. Moreover, knowledge transfer significantly narrows the accuracy gap between the pruned and unpruned encoded models, making the attack more inconspicuous.},
  archive      = {J_NN},
  author       = {Jing Shang and Jian Wang and Kailun Wang and Nan Jiang and Jiqiang Liu},
  doi          = {10.1016/j.neunet.2025.108036},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108036},
  shortjournal = {Neural Netw.},
  title        = {MSG: Stealing data from pruned neural networks via malicious sparsity guidance},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-graph clustering via multi-modal topological manifold learning. <em>NN</em>, <em>193</em>, 108035. (<a href='https://doi.org/10.1016/j.neunet.2025.108035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view spectral clustering has drawn widespread interest in light of its sufficiency of exploring hidden structure details among samples. However, most existing approaches merely concentrate on constructing similarity graph by computing the geometric distance among any two samples using the Euclidean formula, which limits their ability to accurately measure the relationship with far apart but high similarity. Moreover, they implement integration step in the similarity graph construction stage in which the early fusion results in information loss. To solve these problems, we develop a novel multi-view clustering method, namely, Multi-graph Clustering via Multi-modal Topological Manifold Learning (MC_MTML). Specifically, the initial affinity graphs are firstly generated by employing K-Nearest Neighbor (KNN) algorithm. Then, learning similarity matrices by introducing the topological manifold learning mechanism. Finally, the common consensus representation of spectral embedding is derived from the similarity matrixes which can not merely incorporate the consensus structure knowledge from all view features but also reduce the information loss. An efficient alternate iterating algorithm is developed to resolve the resulting optimization issue. The experiments are conducted on a toy data set and five multi-view data sets. Extensive experimental results demonstrate the effectiveness of proposed MC_MTML algorithm comparing with eight state-of-the-art multi-view clustering methods.},
  archive      = {J_NN},
  author       = {Shaojun Shi and Canyu Zhang and Jiahao Zhao and Feiping Nie},
  doi          = {10.1016/j.neunet.2025.108035},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108035},
  shortjournal = {Neural Netw.},
  title        = {Multi-graph clustering via multi-modal topological manifold learning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Scalable and effective negative sample generation for hyperedge prediction. <em>NN</em>, <em>193</em>, 108034. (<a href='https://doi.org/10.1016/j.neunet.2025.108034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypergraphs have demonstrated their superiority in modeling complex systems compared to traditional graphs by directly capturing the interactions among multiple entities. Hyperedge prediction, which aims to predict unobserved potential hyperedges, is a fundamental task in hypergraph analysis. A critical component in hyperedge prediction is the sampling of informative negative hyperedges from significantly larger candidate negative sets, compared to traditional graphs, to enhance model training efficacy. Most existing methods utilize predefined heuristics to sample negative hyperedges, resulting in limited generalizability due to their reliance on these predefined rules. The new state-of-the-art in this field is generation-based methods, which treat negative sampling as a generative task. Nevertheless, current generation-based approaches are not scalable to large hypergraphs . Additionally, diffusion models have demonstrated superior performance in numerous generative tasks, yet their potential application in the generation of negative hyperedges remains unexplored. However, the adaptation of diffusion models to this specific task presents challenges due to: (1) diffusion models are inherently designed to generate high-quality positive samples, which are well-defined, as opposed to negative samples; (2) diffusion models are traditionally employed in continuous space, whereas negative sampling for hyperedge prediction operates in discrete space. To address these complexities, we introduce SEHP (Scalable and Effective Negative Sample Generation for Hyperedge Prediction), which employs a conditional diffusion model to iteratively generate and refine negative hyperedges, thereby advancing them towards the decision boundary to improve model performance. SEHP further enhances scalability by effectively sampling sub-hypergraphs, integrating global structural information into the diffusion model for batch training. Extensive experiments conducted on real-world datasets demonstrate that SEHP surpasses existing state-of-the-art methods in both prediction accuracy and scalability. The code of our paper is available at https://github.com/SLQu/SEHP},
  archive      = {J_NN},
  author       = {Shilin Qu and Weiqing Wang and Yuan-Fang Li and Quoc Viet Hung Nguyen and Hongzhi Yin},
  doi          = {10.1016/j.neunet.2025.108034},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108034},
  shortjournal = {Neural Netw.},
  title        = {Scalable and effective negative sample generation for hyperedge prediction},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Finite-time and fixed-time self-triggered synchronization of stochastic memristive neural networks and applications in secure communication. <em>NN</em>, <em>193</em>, 108033. (<a href='https://doi.org/10.1016/j.neunet.2025.108033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic characteristics of memristive neural networks (MNNs) can be affected by multiple environmental factors. With that in mind, this paper simultaneously considers the comprehensive effects of stochastic disturbance, external input and actuator hysteresis on the MNNs. Firstly, the driving-response stochastic MNNs (SMNNs) subjected to external inputs and hysteresis are introduced, along with a class of secure communication schemes constructed based on this system. Next, definitions of asymptotically, finite-time, and fixed-time synchronization in probability for the considered system are proposed. Following, some synchronization strategies are given by using the self-triggered control method and Lyapunov stability theories. The designed controllers can ensure the finite-/fixed-time synchronization in probability of the SMNNs, as well as the asymptotically synchronization of the secure communication system. Finally, three simulations and comparative experiments demonstrate the proposed strategies’ effectiveness.},
  archive      = {J_NN},
  author       = {Mingxin Wang and Song Zhu and Weiwei Luo and Zhen Zhang},
  doi          = {10.1016/j.neunet.2025.108033},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108033},
  shortjournal = {Neural Netw.},
  title        = {Finite-time and fixed-time self-triggered synchronization of stochastic memristive neural networks and applications in secure communication},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Broad learning system via adaptive maximum weighted correntropy. <em>NN</em>, <em>193</em>, 108032. (<a href='https://doi.org/10.1016/j.neunet.2025.108032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broad Learning System (BLS) is widely used in various regression problems due to its simple structure and strong generalization ability. The standard optimized method for BLS is sensitive to the noise and outliers since it uses the Minimum Mean Square Error (MMSE) criterion, which may decrease the model’s accuracy. As a solution, an Adaptive Maximum Weighted Correntropy - based BLS (AMWC-BLS) is proposed in this paper. Firstly, an adaptive maximum weighted correntropy criterion is presented to improve the performance and generalization ability of the model. Then, the AMWC-BLS is establised by embedding the AMWC criterion into the BLS. The proposed AMWC-BLS model can adjust its output weights facing the distinct characteristics of the input data and optimizing local data features. Hence, the AMWC-BLS model is able to better withstand the effects of outliers and noise and improve the robustness. Finally, the robustness and effectiveness of AMWC-BLS are demonstrated through the experiments on regression datasets.},
  archive      = {J_NN},
  author       = {Yijing Wang and Lijie Wang and Tao Chen},
  doi          = {10.1016/j.neunet.2025.108032},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108032},
  shortjournal = {Neural Netw.},
  title        = {Broad learning system via adaptive maximum weighted correntropy},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Complexity of brain-like signals in self-organised nanoscale networks. <em>NN</em>, <em>193</em>, 108031. (<a href='https://doi.org/10.1016/j.neunet.2025.108031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The biological brain is comprised of a complex, interconnected, self-assembled network of neurons and synapses. This network enables efficient and accurate information processing, unsurpassed by any other known computational system. Percolating networks of nanoparticles (PNNs) are complex, interconnected, self-assembled systems that exhibit many emergent brain-like characteristics. Notably, neuron-like spiking patterns from PNNs have been shown to be critical, similar to signals from the cortex. PNNs are therefore an appealing candidate for neuromorphic computational systems. Here, the inherent complexity of the patterns of switching events generated by PNNs is explored using several different measures. We begin by defining qualitative measures of spatial, temporal, and spatio-temporal complexity, and then investigate a quantitative measure of complexity that was developed for analysis of patterns of spikes from neurons in the cortex. We discuss adaptations of the method that are required for data from the electronic devices of interest and the impact of various pre-processing procedures on the analysis. Through these measures, it is shown that the neuron-like spiking patterns from PNNs are indeed complex and are clearly distinct from random and ordered data.},
  archive      = {J_NN},
  author       = {Jamie K. Steel and Ford Wagner and Edoardo Galli and Susant K. Acharya and Joshua B. Mallinson and Philip J. Bones and Matthew D. Arnold and Simon A. Brown},
  doi          = {10.1016/j.neunet.2025.108031},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108031},
  shortjournal = {Neural Netw.},
  title        = {Complexity of brain-like signals in self-organised nanoscale networks},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GIMS: Image matching system based on adaptive graph construction and graph neural network. <em>NN</em>, <em>193</em>, 108030. (<a href='https://doi.org/10.1016/j.neunet.2025.108030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature-based image matching has extensive applications in computer vision. Keypoints detected in images can be naturally represented as graph structures, and Graph Neural Networks (GNNs) have been shown to outperform traditional deep learning techniques. Consequently, the paradigm of image matching via GNNs has gained significant prominence in recent academic research. In this paper, we first introduce an innovative adaptive graph construction method that utilizes a filtering mechanism based on distance and dynamic threshold similarity. This method dynamically adjusts the criteria for incorporating new vertices based on the characteristics of existing vertices, allowing for the construction of more precise and robust graph structures while avoiding redundancy. We further combine the vertex processing capabilities of GNNs with the global awareness capabilities of Transformers to enhance the model’s representation of spatial and feature information within graph structures. This hybrid model provides a deeper understanding of the interrelationships between vertices and their contributions to the matching process. Additionally, we employ the Sinkhorn algorithm to iteratively solve for optimal matching results. Finally, we validate our system using extensive image datasets and conduct comprehensive comparative experiments. Experimental results demonstrate that our system achieves an average improvement of 3.8 × – 40.3 × in overall matching performance. Additionally, the number of vertices and edges significantly impacts training efficiency and memory usage; therefore, we employ multi-GPU technology to accelerate the training process. Our code is available at https://github.com/songxf1024/GIMS .},
  archive      = {J_NN},
  author       = {Xianfeng Song and Yi Zou and Zheng Shi and Zheng Liu},
  doi          = {10.1016/j.neunet.2025.108030},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108030},
  shortjournal = {Neural Netw.},
  title        = {GIMS: Image matching system based on adaptive graph construction and graph neural network},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the application of neural networks for structured domains to fMRI data. <em>NN</em>, <em>193</em>, 108029. (<a href='https://doi.org/10.1016/j.neunet.2025.108029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional Magnetic Resonance Imaging (fMRI) provides spatio-temporal maps of brain activity; however, extracting the rich information they contain is challenging. Traditional approaches use only summary statistics, losing details that might be hidden in the complex temporal dynamics. Deep neural networks are emerging as an apt solution in this context, given their ability to handle vast amounts of structured data. In this paper, we consider two widely studied fMRI datasets: the Human Connectome Project for connectome fingerprinting, and ABIDE for autism classification. We aim to understand how handling the temporal and spatial dimensions could influence the performance of the models and their interpretability. Specifically, we compare neural network models with architectural biases toward temporal, spatial, or combined spatio-temporal features. The results of our analysis show that existing methods exploiting the spatial dimension, or spatio-temporal hybrids, are not competitive with simpler ones considering the temporal dimension only, such as LSTM. Additionally, we propose a contrastive learning approach for connectome fingerprinting, enabling robust individual identification without requiring access to all subjects during training. Our findings suggest that explicit graph modeling of the interaction between brain regions introduces complexity without improving performance, thereby challenging current trends.},
  archive      = {J_NN},
  author       = {Giovanni Donghi and Luca Pasa and Michele De Filippo De Grazia and Alberto Testolin and Marco Zorzi and Alessandro Sperduti and Nicolò Navarin},
  doi          = {10.1016/j.neunet.2025.108029},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108029},
  shortjournal = {Neural Netw.},
  title        = {On the application of neural networks for structured domains to fMRI data},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Beyond single perspective bias: Fusing personalized and common preferences for comprehensive personal preference learning. <em>NN</em>, <em>193</em>, 108028. (<a href='https://doi.org/10.1016/j.neunet.2025.108028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recommendation systems, Graph Convolutional Network (GCN)-based models are generally influenced by popular items. Over-emphasizing these items can lead to a single-perspective bias that overshadows the learning of the user’s personalized preferences. Therefore, existing GCN-based models usually suppress information from popular items. However, as popular items with rich interactions contain the user’s common preference information, such approaches may introduce another single-perspective bias that neglects the learning of the user’s common preferences. Contrary to the prevailing assumption, we argue that personalized and common preferences are not mutually exclusive. Thus, we propose P&CGCN to collaboratively fuse them within a unified framework. This unified framework includes two parts: intra-layer aggregation and inter-layer combination. Specifically, in intra-layer aggregation, we design P&C degree to quantify the manifestation of personal preferences in each item, adaptively discerning whether it reflects personalized or common preferences without explicit separation. The P&C degree-based intra-layer aggregation guides context-aware integration of both preference aspects at each layer. In inter-layer combination, we design P&C depth to quantify the importance of each layer. The P&C depth-based inter-layer combination systematically prioritizes shallow-layer personalized preference signals while strategically leveraging deep-layer common preference signals. Comparative experiments on four real-world datasets demonstrate the performance and efficiency of P&CGCN. In particular, on sparse large datasets, the performance of P&CGCN has improved by around 20 % compared to LightGCN, with at least a 2x speedup in training efficiency.},
  archive      = {J_NN},
  author       = {JiaXin Wu and Guangxiong Chen and Chenglong Pang and Jie Zhao and Eric W.K. See-To},
  doi          = {10.1016/j.neunet.2025.108028},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108028},
  shortjournal = {Neural Netw.},
  title        = {Beyond single perspective bias: Fusing personalized and common preferences for comprehensive personal preference learning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mitigating spectral bias in neural operators via high-frequency scaling for physical systems. <em>NN</em>, <em>193</em>, 108027. (<a href='https://doi.org/10.1016/j.neunet.2025.108027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural operators have emerged as powerful surrogates for modeling complex physical problems. However, they suffer from spectral bias making them oblivious to high-frequency modes, which are present in multiscale physical systems. Therefore, they tend to produce over-smoothed solutions, which is particularly problematic in modeling turbulence and for systems with intricate patterns and sharp gradients such as multi-phase flow systems. In this work, we introduce a new approach named high-frequency scaling (HFS) to mitigate spectral bias in convolutional-based neural operators. By integrating HFS with proper variants of UNet, we demonstrate a higher prediction accuracy by mitigating spectral bias in single and two-phase flow problems. Unlike Fourier-based techniques, HFS is directly applied to the latent space, thus eliminating the computational cost associated with the Fourier transform. Additionally, we investigate alternative spectral bias mitigation through a diffusion model conditioned on neural operators. While the diffusion model integrated with the standard neural operator may still suffer from significant errors, these errors are substantially reduced when the diffusion model is integrated with a HFS-enhanced neural operator.},
  archive      = {J_NN},
  author       = {Siavash Khodakarami and Vivek Oommen and Aniruddha Bora and George Em Karniadakis},
  doi          = {10.1016/j.neunet.2025.108027},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108027},
  shortjournal = {Neural Netw.},
  title        = {Mitigating spectral bias in neural operators via high-frequency scaling for physical systems},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Raw event-based adversarial attacks for spiking neural networks with configurable latencies. <em>NN</em>, <em>193</em>, 108026. (<a href='https://doi.org/10.1016/j.neunet.2025.108026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) and data from Dynamic Vision Sensors (DVSs) offer energy-efficient solutions for edge devices with limited battery life. The input latencies of event data to SNNs are critical for energy savings, and reducing these latencies through configurable parameters is essential. However, security concerns, particularly adversarial attacks on SNNs, are increasingly significant. While most existing research primarily focuses on attacking event sequences, which may not always be accessible, attacks on raw event streams with configurable latencies remain underexplored due to challenges such as extreme sparsity and the complexity of discrete optimization. This paper proposes a novel adversarial attack method on raw event streams with configurable latencies. To address sparsity and discrete optimization, we smooth the optimization by converting binary spikes into continuous values. Furthermore, we introduce an adaptively stochastic strategy for sampling attacking latencies. We apply regularization terms to maintain sparsity and ensure adversarial samples resemble raw event streams while approximating the target label. Extensive experiments on datasets such as N-MNIST, CIFAR10-DVS, N-Caltech-101, and Gesture-DVS demonstrate that our method consistently outperforms existing approaches, achieving higher attack success rates (ASR) across various latencies. Ablation studies validate the effectiveness of our contributions and highlight the impact of latency on the generation of adversarial samples.},
  archive      = {J_NN},
  author       = {Xiao Du and Wanli Shi and Xiaohan Zhao and Yang Cao and Bin Gu and Tieru Wu},
  doi          = {10.1016/j.neunet.2025.108026},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108026},
  shortjournal = {Neural Netw.},
  title        = {Raw event-based adversarial attacks for spiking neural networks with configurable latencies},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Backdoor samples detection based on perturbation discrepancy consistency in pre-trained language models. <em>NN</em>, <em>193</em>, 108025. (<a href='https://doi.org/10.1016/j.neunet.2025.108025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of unvetted third-party and internet data renders pre-trained models susceptible to backdoor attacks. Detecting backdoor samples is critical to prevent backdoor activation during inference or injection during training. However, existing detection methods often require the defender to have access to the poisoned models, extra clean samples, or significant computational resources to detect backdoor samples, limiting their practicality. To address this limitation, we propose a backdoor sample detection method based on perturbatio N discr E pancy consis T ency E valuation (NETE). This is a novel detection method that can be used both pre-training and post-training phases. In the detection process, it only requires an off-the-shelf pre-trained model to compute the log probability of samples and an automated function based on a mask-filling strategy to generate perturbations. Our method is based on the interesting phenomenon that the change in perturbation discrepancy for backdoor samples is smaller than that for clean samples. Based on this phenomenon, we use curvature to measure the discrepancy in log probabilities between different perturbed samples and input samples, thereby evaluating the consistency of the perturbation discrepancy to determine whether the input sample is a backdoor sample. Experiments conducted on four typical backdoor attacks and five types of large language model backdoor attacks demonstrate that our detection strategy outperforms existing zero-shot black-box detection methods.},
  archive      = {J_NN},
  author       = {Zuquan Peng and Jianming Fu and Lixin Zou and Li Zheng and Yanzhen Ren and Guojun Peng},
  doi          = {10.1016/j.neunet.2025.108025},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108025},
  shortjournal = {Neural Netw.},
  title        = {Backdoor samples detection based on perturbation discrepancy consistency in pre-trained language models},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MSFI: Multi-timescale spatio-temporal features integration in spiking neural networks. <em>NN</em>, <em>193</em>, 108024. (<a href='https://doi.org/10.1016/j.neunet.2025.108024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic vision sensors (DVS) asynchronously encode the polarity of brightness changes with high temporal resolution and a wide dynamic range, making them ideal for capturing temporal information. Spiking neural networks (SNNs) are well-suited for handling such event streams due to their inherent temporal information processing capability. However, existing SNNs only transmit membrane potential across timesteps, neglecting spatial dependencies and failing to extract complex temporal features. To overcome this limitation, we propose a novel plug-and-play module, the Multi-timescale Spatio-temporal Features Integration (MSFI) module. MSFI is specifically designed to extract various spatiotemporal features and fuse them with the original spiking features to enhance the representative capabilities of SNNs. MSFI comprises the Short-term Spatio-temporal Module (SSM) and the Long-term Spatio-temporal Module (LSM), which extract short-term and long-term spatio-temporal features. Our proposed MSFI improves the performance of SNNs on several neuromorphic and static datasets, including CIFAR10-DVS, DVS128 Gesture, DVS128 Gait, CIFAR10/100, and ImageNet datasets. Experimental results on these datasets show that our MSFI significantly outperforms the baselines. Our codes are available at https://github.com/dfxue/MSFI},
  archive      = {J_NN},
  author       = {Dengfeng Xue and Wenjuan Li and Chunfeng Yuan and Haowei Liu and Man Yao and Wei Liu and Li Yang and Bing Li and Weiming Hu and Haoliang Sun and Zhetao Li},
  doi          = {10.1016/j.neunet.2025.108024},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108024},
  shortjournal = {Neural Netw.},
  title        = {MSFI: Multi-timescale spatio-temporal features integration in spiking neural networks},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DSPy-based neural-symbolic pipeline to enhance spatial reasoning in LLMs. <em>NN</em>, <em>193</em>, 108022. (<a href='https://doi.org/10.1016/j.neunet.2025.108022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial reasoning is crucial for Large Language Models (LLMs) but remains a persistent challenge. Existing neural-symbolic approaches offer partial solutions but suffer from inflexible design and limited effectiveness. We present a neural-symbolic framework that integrates LLMs with Answer Set Programming (ASP) through an iterative feedback loop, enabling precise and reliable refinement of generated logic programs. Evaluated on two benchmark datasets across multiple reasoning tasks and LLMs, our DSPy-based pipeline achieves 82–93 % and 71–80 % accuracy, surpassing direct prompting, Chain-of-Thought, and a two-stage “Facts+Rules” method by up to 43 % and 25 %, respectively. The lightweight “Facts+Rules” alternative we proposed also improves baseline performance by 9–27 % while reducing computational overhead. Key innovations driving these gains include (1) modular separation of semantic parsing and logical reasoning, (2) iterative error-handling feedback between LLMs and ASP solvers, and (3) domain-specific symbolic representations for efficient reasoning. The system offers strong interpretability and generalizability, allowing application across diverse and complex tasks. Moreover, our proposed system could substantially advance AI architectures capable of human-like, multi-component reasoning, contributing to the development of artificial general intelligence.},
  archive      = {J_NN},
  author       = {Rong Wang and Kun Sun},
  doi          = {10.1016/j.neunet.2025.108022},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108022},
  shortjournal = {Neural Netw.},
  title        = {DSPy-based neural-symbolic pipeline to enhance spatial reasoning in LLMs},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MIIGAN: Mambas make strong GAN for infrared image generation. <em>NN</em>, <em>193</em>, 108021. (<a href='https://doi.org/10.1016/j.neunet.2025.108021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collecting infrared images on-site is the most direct and realistic approach. However, it is costly, and due to varying environmental conditions, replicating the same conditions for comparative experiments is challenging. This presents significant obstacles for research in infrared technology. To target this issue, we propose MIIGAN, a Visible-to-Infrared Image Generation model that achieves SOTA performance. MIIGAN employs a GAN based on U-Net, with Mamba blocks serving as the core module to improve generation quality. Additionally, we develop a Spatial and Channel Attention Module (SCAM) and integrate it into the skip connections of U-Net to enhance feature extraction. We also design a Dual-encoder combining Transformer and Mamba to improve the discriminator’s performance. Furthermore, we introduce the Difference and Product learning Module (DPM) into the Dual-encoder to enhance differential and consistency feature extraction. Finally, we integrate multi-layer feature differential and consistency losses into the objective function of the discriminator, providing comprehensive pixel-level feedback across multiple scales. We conduct extensive comparative and ablation studies across four datasets and perform downstream object detection tasks on the generated infrared images to validate MIIGAN’s performance. The source code is available at https://github.com/wangfc0913/miigan.git .},
  archive      = {J_NN},
  author       = {Fuchao Wang and Huaici Zhao and Yuhuai Peng and Jian Fang and Pengfei Liu and Ronghua Zhang},
  doi          = {10.1016/j.neunet.2025.108021},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108021},
  shortjournal = {Neural Netw.},
  title        = {MIIGAN: Mambas make strong GAN for infrared image generation},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GMSR: Gradient-integrated mamba for spectral reconstruction from RGB images. <em>NN</em>, <em>193</em>, 108020. (<a href='https://doi.org/10.1016/j.neunet.2025.108020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mainstream approaches to spectral reconstruction primarily focus on Convolution- and Transformer-based architectures. However, CNN methods fall short in handling long-range dependencies, whereas Transformers are constrained by computational efficiency limitations. Therefore, constructing a efficient spectral reconstruction network while ensuring the quality of reconstructed hyperspectral images (HSIs) has become a major challenge. Recent breakthroughs in the state-space model (e.g., Mamba) have attracted significant attention from natural language processing to vision tasks due to its near-linear computational efficiency and superior performance, prompting our investigation into its potential for spectral reconstruction problems. To this end, we introduce the Gradient-integrated Mamba for Spectral Reconstruction from RGB Images, dubbed GMSR-Net. GMSR-Net is a lightweight model characterized by a global receptive field and linear computational complexity. Its core comprises multiple stacked Gradient Mamba (GM) blocks, each featuring a tri-branch structure. Building upon the efficient global feature representation from the Mamba, we further innovatively propose spatial gradient attention and spectral gradient attention to guide the reconstruction of spatial and spectral cues. GMSR-Net demonstrates a significant accuracy-efficiency trade-off, achieving state-of-the-art performance while markedly reducing the number of parameters and computational burdens. Compared to existing approaches, GMSR-Net slashes parameters and FLOPs by substantial margins of 8 times and 20 times, respectively. Code is available at https://github.com/wxy11-27/GMSR .},
  archive      = {J_NN},
  author       = {Xinying Wang and Zhixiong Huang and Sifan Zhang and Jiawen Zhu and Paolo Gamba and Lin Feng},
  doi          = {10.1016/j.neunet.2025.108020},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108020},
  shortjournal = {Neural Netw.},
  title        = {GMSR: Gradient-integrated mamba for spectral reconstruction from RGB images},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Visual reinforcement learning via sequential consistency preserved policy contrast from optimal transport view. <em>NN</em>, <em>193</em>, 108019. (<a href='https://doi.org/10.1016/j.neunet.2025.108019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data inefficiency has long posed a significant challenge in the application of visual reinforcement learning methods to complex scenarios. To address this issue, recent studies have incorporated representation learning mechanisms to extract discriminative features by introducing auxiliary objectives that contrast pixel observations . However, our investigations suggest that these representations may not sufficiently capture the essential information for effective decision-making and could potentially impede policy learning. To tackle these limitations, we propose a novel methodology termed CoCo (sequential Co nsistency preserved policy Co ntrast). Unlike existing approaches, CoCo emphasizes the capture of invariant policy-based discriminative features by performing policy contrast across multiple distorted views of observations. Accordingly, we determine that there exists a certain intrinsic heterogeneity between policy and observation, since policy establishes an explicit distribution characteristic rather than a plain tensor. To this end, we propose to model the policy contrast as an optimal transport problem and further perform the alignment of policy distributions during contrastive learning. Subsequently, we introduce an inverse consistency-weighting mechanism designed to accentuate the differences between views while maintaining semantic integrity. We establish the theoretical optimality of our proposed method through an information-theoretic analysis and demonstrate its practical effectiveness via comprehensive evaluation across diverse data efficiency benchmarks, where CoCo consistently outperforms existing approaches.},
  archive      = {J_NN},
  author       = {Zehua Zang and Jiangmeng Li and Chuxiong Sun and Rui Wang and Lixiang Liu and Fuchun Sun},
  doi          = {10.1016/j.neunet.2025.108019},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108019},
  shortjournal = {Neural Netw.},
  title        = {Visual reinforcement learning via sequential consistency preserved policy contrast from optimal transport view},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Pseudo-distribution elite critics: Enhancing accuracy in reinforcement learning value estimation. <em>NN</em>, <em>193</em>, 108018. (<a href='https://doi.org/10.1016/j.neunet.2025.108018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning has succeeded significantly in developing intelligent agents capable of adeptly navigating complex environments, yet it often encounters limitations due to persistent biases in state-action value estimation. To address this challenge, we introduce the Pseudo-distribution Elite Critics (PEC), an innovative framework designed to enhance sample efficiency and effectively balance overestimation and underestimation biases in Q-value approximations. PEC revolves around the innovative concept of pseudo-distribution representation, which enriches Q-value approximations with distributional characteristics, capturing nuanced variations in Q-values without increasing the number of critics, leading to more refined and precise estimations. This framework is further enhanced by two critical components: an uncertainty measurement that accurately identifies the most reliable critic for Temporal Difference target computation and a trimmed mean technique that adeptly balances optimistic and pessimistic biases in Temporal Difference target. Empirical studies across various benchmark scenarios validate the statistical significance of PEC and its superior performance over existing methodologies.},
  archive      = {J_NN},
  author       = {Yujia Zhang and Lin Li and Wei Wei and Jianguo Wu and Jiye Liang},
  doi          = {10.1016/j.neunet.2025.108018},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108018},
  shortjournal = {Neural Netw.},
  title        = {Pseudo-distribution elite critics: Enhancing accuracy in reinforcement learning value estimation},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rethinking softmax in incremental learning. <em>NN</em>, <em>193</em>, 108017. (<a href='https://doi.org/10.1016/j.neunet.2025.108017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mitigating catastrophic forgetting remains a fundamental challenge in incremental learning. This paper identifies a key limitation of the widely used softmax cross-entropy loss: the non-identifiability inherent in the standard softmax cross-entropy distillation loss. To address this issue, we propose two complementary strategies: (1) adopting an imbalance-invariant distillation loss to mitigate the adverse effect of imbalanced weights during distillation, and (2) regularizing the original prediction/distillation loss with shift-sensitive alternatives, which render the optimization problem identifiable and proactively prevent imbalance from arising. These strategies form the foundation of five novel approaches that can be seamlessly integrated into existing distillation-based incremental learning frameworks such as LWF, LWM, and LUCIR. We validate the effectiveness of our approaches through extensive numerical experiments, demonstrating consistent improvements in predictive accuracy and substantial reductions in forgetting. For example, in a 10-task incremental learning setting on CIFAR-100, our methods improve the average accuracy of three widely used approaches - LWF, LWM, and LUCIR - by 11.8 %, 11.5 %, and 12.8 %, respectively, while reducing their average forgetting rates by 16.5 %, 16.8 %, and 13.8 %, respectively. Our code is publicly available at https://github.com/nexais/RethinkSoftmax .},
  archive      = {J_NN},
  author       = {Zheng Zhai and Jiali Zhang and Haiyu Wang and Mingxin Wu and Keshun Yang and Xiaoyan Qiao and Qiang Sun},
  doi          = {10.1016/j.neunet.2025.108017},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108017},
  shortjournal = {Neural Netw.},
  title        = {Rethinking softmax in incremental learning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive metric for knowledge distillation by deep bregman divergence. <em>NN</em>, <em>193</em>, 108016. (<a href='https://doi.org/10.1016/j.neunet.2025.108016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) makes it possible to deploy high-accuracy models on devices with limited resources and is an effective means of achieving lightweight models. With the advancement of technology, the methods of knowledge distillation are also continuously developing and improving to adapt to different application scenarios and needs. To facilitate the transfer of knowledge from larger networks to smaller and lighter networks, KD has been employed to bridge the gap in probability outputs or middle-layer representations between teacher and student networks. Unlike the consistent probability outputs observed between teacher and student networks, the middle-layer representations exhibit significant variations in both structure and distribution. Traditional metrics such as Euclidean distance or MSE treat all intermediate features uniformly and do not adapt to the heterogeneous characteristics of feature distributions across different layers or models. These fixed metrics often fail to account for the spatial, semantic, and statistical variations between teacher and student networks. To address this limitation, we propose using a parameterized and adaptive metric based on deep Bregman divergence. This divergence function is learned from data, enabling the measurement to adjust to the underlying feature distributions at different layers, leading to more effective and robust knowledge transfer. Importantly, our method can also serve as a complementary enhancement ( i.e. , x+Bregman) to almost all other KD methods focused on distilling probability outputs. Extensive experiments demonstrate that our approach outperforms many existing KD methods, achieving superior performance across diverse datasets and network models.},
  archive      = {J_NN},
  author       = {Tongtong Yuan and Zixuan Xu and Bo Liu and Yinan Tang},
  doi          = {10.1016/j.neunet.2025.108016},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108016},
  shortjournal = {Neural Netw.},
  title        = {Adaptive metric for knowledge distillation by deep bregman divergence},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UTN: Unsupervised optical flow estimation network based on transformer. <em>NN</em>, <em>193</em>, 108015. (<a href='https://doi.org/10.1016/j.neunet.2025.108015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the aim of enabling unsupervised optical flow estimation, we propose a scalable framework based on a transformer and a feature pyramid network (FPN). Central to our approach is the incorporation of a transformer-CNN based structure within the encoder, designed to capture global and local dependency features from input image pairs—a crucial element for precise pixel-wise flow estimation. Subsequently, we integrate a normalized cross-correlation module (NCCM) and an attention-based intermediate flow estimation (AIFE) module into the FPN-based decoder. The NCCM enhances the decoder's focus on the saliency of shared foreground objects through correlation operations, while the AIFE refines flow estimation using an auxiliary positional mask and intermediate flow matrix. Furthermore, we propose a static optical flow loss, providing a distinct training clue that effectively boosts flow accuracy. Comprehensive experiments, including comparisons with state-of-the-art methods and ablation studies, were conducted across benchmark datasets such as FlyingChairs, MPI-Sintel, KITTI-2012, and KITTI-2015. Notably, our method achieved substantial performance gains. For instance, on the MPI-Sintel dataset, we observed a reduction in End-Point-Error (EPE) of 24.27 % on the clean dataset and 28.01 % on the final dataset compared to ARFlow. Ablation studies corroborated the efficacy of the NCCM, AIFE, and static optical flow loss in enhancing estimation accuracy.},
  archive      = {J_NN},
  author       = {Xiaochen Liu and Tao Zhang and Mingming Liu},
  doi          = {10.1016/j.neunet.2025.108015},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108015},
  shortjournal = {Neural Netw.},
  title        = {UTN: Unsupervised optical flow estimation network based on transformer},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ITSEF: Inception-based two-stage ensemble framework for p300 detection. <em>NN</em>, <em>193</em>, 108014. (<a href='https://doi.org/10.1016/j.neunet.2025.108014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the problems of low signal-to-noise ratio, significant individual differences between subjects, and class imbalance in P300-based brain-computer interface (BCI), this paper proposes a novel Inception-based two-stage ensemble framework (ITSEF) to improve detection accuracy. Firstly, an Inception-based convolutional neural network (ICNN) is designed to extract multi-scale features and conduct cross-channel learning. In addition, a two-stage ensemble framework (TSEF) combined with a pre-training and fine-tuning strategy is developed, aiming to enhance the classification performance of the minority class and improve the generalization ability of the model. The framework comprises a conventional learning branch and a re-balancing branch, each based on an ICNN pre-trained with a different loss function. The prediction results of both branches are dynamically weighted by a cumulative learning strategy, so that the model gradually shifts its learning focus from the majority class to the minority class, comprehensively improving the identification ability for both classes. Experimental results on two datasets, Dataset II of BCI Competition III and BCIAUT-P300, demonstrate that the proposed ITSEF achieves state-of-the-art performance in the P300 classification task, with average classification accuracies of 86.16 % and 92.13 %, respectively. Compared with the existing state-of-the-art methods, the ITSEF achieves improvements of 4.61 % and 1.01 % on the two datasets, respectively. Furthermore, it exhibits significant improvements compared to baseline models and widely used class re-balancing strategies. The proposed ITSEF method provides an innovative deep learning framework for P300 signal analysis and has application potential in the field of P300-BCI.},
  archive      = {J_NN},
  author       = {Wenjun Hu and Dingguo Zhang and Wanzhong Chen},
  doi          = {10.1016/j.neunet.2025.108014},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108014},
  shortjournal = {Neural Netw.},
  title        = {ITSEF: Inception-based two-stage ensemble framework for p300 detection},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multivariate distribution fitting for GANs via introducing variable correlations. <em>NN</em>, <em>193</em>, 108013. (<a href='https://doi.org/10.1016/j.neunet.2025.108013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mode collapse is a major unsolved problem in generative adversarial networks. In this study, we base our proposal on the distribution fitting method and explore methods to suppress mode collapse for multivariate data. We incorporate the covariance constraints that enforce similar linear correlations among the variables. This approach may mitigate the nonuniform sampling issue more effectively for multivariate data, thereby suppressing mode collapse. For images, we also offer a scheme for incorporating covariances by utilizing the difference matrices. The method could handle images better since it considers the distances between pixels and possesses a better tolerance for errors like offsets. The proposed methods inherit the benefits of the distribution fitting method, which circumvents reliance on regularization or network modules, enhancing compatibility and facilitating its practical application. Experiments demonstrate the effectiveness and competitive performance of the proposed method.},
  archive      = {J_NN},
  author       = {Yanxiang Gong and Feiyang Sun and Xin Ma},
  doi          = {10.1016/j.neunet.2025.108013},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108013},
  shortjournal = {Neural Netw.},
  title        = {Multivariate distribution fitting for GANs via introducing variable correlations},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel span and syntax enhanced large language model based framework for fine-grained sentiment analysis. <em>NN</em>, <em>193</em>, 108012. (<a href='https://doi.org/10.1016/j.neunet.2025.108012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained aspect-based sentiment analysis requires language models to identify aspect entities and the corresponding sentiment information in the input text content. Transformer-based pre-trained large language models have demonstrated remarkable performance on various challenging natural language processing tasks. However, large language models face limitations in explicitly modelling syntactic relationships and effectively capturing local nuances between terms in the text content, which constrains their capability in fine-grained aspect-based sentiment analysis. We propose a novel span and syntax enhanced joint learning framework based on the latest large language model. The framework incorporates three key components, including the span-aware attention mechanism, the contextual Transformer, and the syntax-aware Transformer, which examine in parallel to generate span-aware features, contextual features, and syntax-aware features, respectively. The three dimensions of analyzed features are dynamically fused in the feature aggregation module, resulting in a combined feature for aspect entity recognition and sentiment classification. To the best of our knowledge, this study represents the pioneering effort to comprehensively leverage span-aware, contextual, and syntax-aware characteristics to augment large language models in addressing the fine-grained aspect-based sentiment analysis task. Experimental results on publicly available benchmark datasets validate the effectiveness of the architecture compared to state-of-the-art baseline competitors.},
  archive      = {J_NN},
  author       = {Haochen Zou and Yongli Wang and Anqi Huang},
  doi          = {10.1016/j.neunet.2025.108012},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108012},
  shortjournal = {Neural Netw.},
  title        = {A novel span and syntax enhanced large language model based framework for fine-grained sentiment analysis},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multimodal self-supervised retinal vessel segmentation. <em>NN</em>, <em>193</em>, 108011. (<a href='https://doi.org/10.1016/j.neunet.2025.108011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic segmentation of retinal vessels from retinography images is crucial for timely clinical diagnosis. However, the high cost and specialized expertise required for annotating medical images often result in limited labeled datasets, which constrains the full potential of deep learning methods. Recent advances in self-supervised pretraining using unlabeled data have shown significant benefits for downstream tasks. Recognizing that multimodal feature fusion can substantially enhance retinal vessel segmentation accuracy, this paper introduces a novel self-supervised pretraining framework that leverages pairs of unlabeled multimodal fundus images to generate supervisory signals. The core idea is to exploit the complementary differences between the two modalities to construct a multimodal feature fusion map containing vessel information, achieved through Vision Transformer encoding and correlation filtering. Instance-level discriminative features are then learned under the guidance of INFOMAX loss, and the learned knowledge is transferred to a supervised vessel segmentation network. Extensive experiments show that our approach achieves state-of-the-art results among unsupervised methods and remains competitive with supervised baselines while greatly reducing annotation requirements.},
  archive      = {J_NN},
  author       = {Pengshuai Yin and Jingqi Zhang and Huichou Huang and Ruirui Liu and Yanxia Liu and Qingyao Wu and F. Richard Yu},
  doi          = {10.1016/j.neunet.2025.108011},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108011},
  shortjournal = {Neural Netw.},
  title        = {Multimodal self-supervised retinal vessel segmentation},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semi-LLIE: Semi-supervised contrastive learning with mamba-based low-light enhancement. <em>NN</em>, <em>193</em>, 108010. (<a href='https://doi.org/10.1016/j.neunet.2025.108010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in low-light image enhancement (LLIE) have achieved impressive progress. However, the scarcity of paired data has emerged as a significant obstacle to further advancements. In this work, we propose Semi-LLIE, a novel semi-supervised framework that introduces unpaired low- and normal-light images into model training via the mean-teacher paradigm. While the mean-teacher framework is promising, directly applying it to LLIE faces two key challenges. Firstly, pixel-wise consistency losses are insufficient for transferring realistic illumination distribution from the teacher to the student model. Secondly, existing image enhancement backbones are not well-suited for integration with semi-supervised learning to restore fine-grained details in dark regions. To address these challenges, we propose a semantic-aware contrastive loss which leverages vision-language representations to align illumination semantics and achieve accurate illumination distribution equalization, thereby improving color naturalness in enhanced images. In addition, we design a Mamba-based low-light image enhancement backbone with a multi-scale feature learning scheme that enhance global-local pixel dependency modeling for improved detail restoration. In addition, we propose a novel RAM-based perceptive loss is further introduced to guide texture enhancement at semantic level. The experimental results indicate that our Semi-LLIE surpasses existing methods in both quantitative and qualitative metrics. The code and models are available at https://github.com/guanguanboy/Semi-LLIE .},
  archive      = {J_NN},
  author       = {Guanlin Li and Ke Zhang and Ting Wang and Ming Li and Bin Zhao and Xuelong Li},
  doi          = {10.1016/j.neunet.2025.108010},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108010},
  shortjournal = {Neural Netw.},
  title        = {Semi-LLIE: Semi-supervised contrastive learning with mamba-based low-light enhancement},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AutoProfile: Automated profiling in deep learning-based side-channel analysis. <em>NN</em>, <em>193</em>, 108009. (<a href='https://doi.org/10.1016/j.neunet.2025.108009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Side-channel analysis (SCA) capitalizes on unintentionally leaked information to extract sensitive data from cryptographic systems. Over recent years, the side-channel community has exhibited a notable surge in interest towards deep learning (DL) techniques. However, the challenge of constructing appropriate networks has been highlighted. This paper presents a novel methodology named AutoProfile to enhance the efficacy of DL-based profiling attack on robust cryptographic system. AutoProfile customizes two core components of Bayesian optimization for SCA: the modeling strategy and acquisition function. The performance of AutoProfile is assessed on publicly available datasets that consist of real side-channel measurements. The experimental results showcase substantial improvements over the state-of-the-art method, achieving an average performance enhancement of 78.4 %. Notably, for more robust targets that employ a combination of masking, random delay and key variation countermeasures, AutoProfile delivers the most significant performance boost. It reduces the number of traces required from the thousands, as typically needed by state-of-the-art methods, to merely dozens to break the targets. Furthermore, the experiments show that AutoProfile is notably faster than baseline methods in identifying effective networks over all tested SCA datasets.},
  archive      = {J_NN},
  author       = {Yimeng Chen and Bo Wang and Changshan Su and Ao Li and Gen Li and Yuxing Tang and An Wang},
  doi          = {10.1016/j.neunet.2025.108009},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108009},
  shortjournal = {Neural Netw.},
  title        = {AutoProfile: Automated profiling in deep learning-based side-channel analysis},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatial-frequency domain aggregation upsampling for pan-sharpening. <em>NN</em>, <em>193</em>, 108007. (<a href='https://doi.org/10.1016/j.neunet.2025.108007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pan-sharpening, fusing high-resolution panchromatic (PAN) images with low-resolution multispectral (LRMS) to generate high-resolution multispectral (HRMS) images, is critical for enhancing remote sensing image quality. Despite significant advancements in deep learning methods, research on the image upsampling process remains limited. Existing approaches either fail to effectively utilize the information from PAN images or struggle to balance spectral and spatial information, thereby constraining the performance of these models. To alleviate these problems, we propose a novel Spatial-Frequency Domain Aggregation Upsampling (SFAU) method. Our method consists of three core modules: the Dual-Domain Nonlinear Fusion (DDNF), Region-Specific Attention Mechanism (RSAM), and Adaptive Feature Fusion Gate (AFFG). The DDNF module integrates Frequency-Aware Feature Aggregation (FAFA) and Spatial Domain Enhancement techniques, enabling the capture of high-frequency features while refining local structural details. The RSAM module adaptively refines feature representations and preserves spatial-spectral correlations. Finally, the AFFG module effectively combines the outputs from the DDNF and RSAM modules, ensuring a balanced integration of spatial and spectral information. Extensive experiments demonstrate that our method outperforms other popular upsampling techniques and significantly enhances the performance of many leading pan-sharpening models, particularly in high-contrast and spectrally complex regions. Additionally, our approach shows strong generalization in real-world scenarios, highlighting its potential for practical remote sensing applications. Code is available at https://github.com/zacianfans/SFAU .},
  archive      = {J_NN},
  author       = {Yilong Liu and Kai Sun and Yuan Liu and Junying Hu and Junmin Liu and Jiangshe Zhang},
  doi          = {10.1016/j.neunet.2025.108007},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108007},
  shortjournal = {Neural Netw.},
  title        = {Spatial-frequency domain aggregation upsampling for pan-sharpening},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DyFiLM: A framework to handle the distribution shifts on dynamic graphs with hypernetworks. <em>NN</em>, <em>193</em>, 108006. (<a href='https://doi.org/10.1016/j.neunet.2025.108006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic graph representation learning has garnered increasing attention since dynamic graphs can accurately reflect the changes and evolutionary processes in the real world. Existing approaches typically train a fixed model to capture temporal patterns and then utilize the fixed model to infer future evolution. They assume that the dynamic graph evolves with the same law over time. While the underlying data generation distribution of graphs may shift over time and introduce new evolution patterns. To resolve this challenge, we propose a learning-to-learn framework entitled Dy namic F eature-wise L inear M odulation (DyFiLM), which employs a hypermodel to adjust the representation learning model to change with the distribution shifts. By employing a hypermodel to directly modulate the representation learning model based on time-varying input data, our framework captures evolutionary patterns from diverse time and expresses them through the modulation. Training both hypermodel and representation learning model in a distribution-shifting environment endows the framework with the capability for cross-distribution generalization. We apply our proposed framework to three different models and conduct extensive experiments on four datasets to verify the effectiveness of DyFiLM. The experimental results demonstrate that the DyFiLM achieves significant improvements compared with related approaches.},
  archive      = {J_NN},
  author       = {Fuyuan Ma and Yuhan Wang and Shixuan Ma and Yongzhen Li and Xin Wang and Ying Wang},
  doi          = {10.1016/j.neunet.2025.108006},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108006},
  shortjournal = {Neural Netw.},
  title        = {DyFiLM: A framework to handle the distribution shifts on dynamic graphs with hypernetworks},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tempered fractional gradient descent: Theory, algorithms, and robust learning applications. <em>NN</em>, <em>193</em>, 108005. (<a href='https://doi.org/10.1016/j.neunet.2025.108005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces Tempered Fractional Gradient Descent (TFGD), a novel optimization framework that synergizes fractional calculus with exponential tempering to enhance gradient-based learning. Traditional gradient descent methods often suffer from oscillatory updates and slow convergence in high-dimensional, noisy landscapes. TFGD addresses these limitations by incorporating a tempered memory mechanism, where historical gradients are weighted by fractional coefficients | w j | = ( α j ) and exponentially decayed via a tempering parameter λ . Theoretical analysis establishes TFGD’s convergence guarantees: in convex settings, it achieves an O ( 1 / K ) rate with alignment coefficient d α , λ = ( 1 − e − λ ) − α , while stochastic variants attain O ( 1 / k α ) error decay. The algorithm maintains O ( n ) time complexity equivalent to SGD, with memory overhead scaling as O ( d / λ ) for parameter dimension d . Empirical validation demonstrates TFGD’s superiority across diverse benchmarks: 98.25 % accuracy on Breast Cancer Wisconsin (vs. 92.11 % SGD), 99.1 % on MNIST (vs. 99.0 % Adam), and 95.83 % on noisy digits (vs. 75.83 % SGD). TFGD converges 2 × faster than SGD in medical classification tasks and exhibits smoother optimization trajectories in non-convex settings (MNIST autoencoder). The tempered memory mechanism proves particularly effective where feature correlations benefit from stable gradient averaging, while hyperparameter analysis reveals optimal operating regimes ( α = 0.6 − 0.7 , λ = 0.3 − 0.5 ) for noisy data. These results position TFGD as a robust alternative to conventional optimizers in both theoretical and applied machine learning.},
  archive      = {J_NN},
  author       = {Omar Naifar},
  doi          = {10.1016/j.neunet.2025.108005},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108005},
  shortjournal = {Neural Netw.},
  title        = {Tempered fractional gradient descent: Theory, algorithms, and robust learning applications},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Synchronization of neural networks with and without disturbance input via control lyapunov function. <em>NN</em>, <em>193</em>, 108004. (<a href='https://doi.org/10.1016/j.neunet.2025.108004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on the control Lyapunov function (CLF) for a class of neural networks, both with and without disturbance input. First, we design an exponential controller using the quadratic program-based CLF (QP-CLF) method to address the drive-response synchronization of a class of neural networks. Second, we propose a robust controller based on the robust QP-CLF approach to ensure the input-to-state stability (ISS) of the closed-loop system, even in the presence of external disturbances or system uncertainties. Finally, we present two numerical examples to demonstrate the effectiveness of the proposed QP-CLF and robust QP-CLF methods, highlighting their capability to maintain stability and synchronization in both ideal and disturbed conditions. These examples provide valuable insights into the practical applicability of the proposed control strategies.},
  archive      = {J_NN},
  author       = {Yuting Cao and Linhao Zhao and Shiping Wen and Tingwen Huang},
  doi          = {10.1016/j.neunet.2025.108004},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108004},
  shortjournal = {Neural Netw.},
  title        = {Synchronization of neural networks with and without disturbance input via control lyapunov function},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). One-step bipartite graph cut: A normalized formulation and its application to scalable subspace clustering. <em>NN</em>, <em>193</em>, 108003. (<a href='https://doi.org/10.1016/j.neunet.2025.108003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bipartite graph structure has shown its promising ability in facilitating the subspace clustering and spectral clustering algorithms for large-scale datasets. To avoid the post-processing via k -means during the bipartite graph partitioning, the constrained Laplacian rank (CLR) is often utilized for constraining the number of connected components (i.e., clusters) in the bipartite graph, which, however, neglects the distribution (or normalization) of these connected components and may lead to imbalanced or even ill clusters. Despite the significant success of normalized cut (Ncut) in general graphs, it remains an open problem how to enforce a one-step normalized cut for bipartite graphs, especially with linear-time complexity. In this paper, we first characterize a novel one-step bipartite graph cut (OBCut) criterion with normalized constraints, and theoretically prove its equivalence to a trace maximization problem. Then, we extend this cut criterion to a scalable subspace clustering approach, where adaptive anchor learning, bipartite graph learning, and one-step normalized bipartite graph partitioning are simultaneously modeled in a unified objective function, and an alternating optimization algorithm is further designed to solve it in linear time. Experiments on a variety of general and large-scale datasets demonstrate the effectiveness and scalability of our approach. Code available: https://github.com/huangdonghere/OBCut .},
  archive      = {J_NN},
  author       = {Si-Guo Fang and Dong Huang and Chang-Dong Wang and Jian-Huang Lai},
  doi          = {10.1016/j.neunet.2025.108003},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108003},
  shortjournal = {Neural Netw.},
  title        = {One-step bipartite graph cut: A normalized formulation and its application to scalable subspace clustering},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IDMM-IDS: An efficient and robust intrusion detection system for the IoT based on the inverted dirichlet mixture model. <em>NN</em>, <em>193</em>, 108002. (<a href='https://doi.org/10.1016/j.neunet.2025.108002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) has permeated all facets of modern life, offering revolutionary applications from smart homes to industrial automation. However, the widespread adoption of IoT systems has amplified security vulnerabilities, necessitating robust intrusion detection systems (IDSs) to protect these devices. Traditional IDS solutions often face challenges in resource-constrained IoT environments due to high computational demands and limited adaptability to emerging threats. To address these issues, this paper proposes IDMM-IDS, an efficient and robust IDS tailored for IoT contexts. By utilizing the inverted Dirichlet mixture model (IDMM) and extended stochastic variational inference (ESVI), our IDMM-IDS models complex network traffic with minimal computational overhead. Additionally, a novel cluster-based oversampling technique is integrated to address class imbalance, enhancing the detection of minority class threats without introducing noise. Extensive evaluations on three public datasets-UNSW-NB15, WSN-DS, and WUSTL-IIOT-2021-demonstrate that IDMM-IDS outperforms most existing methods in detection performance while significantly reducing training and decision times, making it well-suited for resource-constrained IoT environments.},
  archive      = {J_NN},
  author       = {Wenda He and Xiangrui Cai and Yiying Yu and Yuping Lai and Xiaojie Yuan},
  doi          = {10.1016/j.neunet.2025.108002},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108002},
  shortjournal = {Neural Netw.},
  title        = {IDMM-IDS: An efficient and robust intrusion detection system for the IoT based on the inverted dirichlet mixture model},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Prediction of cancer drug response based on heterogeneous graph neural networks and multi-omics data. <em>NN</em>, <em>193</em>, 108001. (<a href='https://doi.org/10.1016/j.neunet.2025.108001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precision prediction of cancer drug response remains a critical challenge in personalized medicine. With ongoing advancements in related research, substantial amounts of cell line omics data and drug feature information have been accumulated, offering valuable resources for investigating cancer drug responses. However, effectively integrating these multi-omics features and constructing accurate and interpretable network-based prediction models remain challenging. To address these issues, we propose GraphTCDR, a model based on heterogeneous graph neural networks and multi-omics data that can accurately predict cancer drug responses. The specific workflow of GraphTCDR is as follows: First, a cell line-drug heterogeneous network is constructed, using multi-omics data and drug features as node attributes. Next, node feature learning is conducted on the heterogeneous network. Finally, the learned features are fed into fully connected layers to predict IC50 values. Extensive experiments on the PRISM database demonstrate that GraphTCDR outperforms existing state-of-the-art methods across all evaluation metrics. Compared with the current best-performing model, GraphTCDR achieves improvements of 3.60 % in PCC, 4.30 % in SCC, 6.50 % in R 2 , and a 1.60 % reduction in RMSE. The reliability of GraphTCDR’s predictions on unlabeled samples is also validated. Moreover, GraphTCDR maintains stable performance even when the amount of training data is reduced, unlike other algorithms, indicating superior robustness. GraphTCDR offers a novel approach to drug response prediction and has significant implications for advancing personalized cancer therapy.},
  archive      = {J_NN},
  author       = {Junming Zhang and Shuwen Xiong and Yugui Xu and Yongqing Zhang},
  doi          = {10.1016/j.neunet.2025.108001},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108001},
  shortjournal = {Neural Netw.},
  title        = {Prediction of cancer drug response based on heterogeneous graph neural networks and multi-omics data},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RefSAM: Efficiently adapting segmenting anything model for referring video object segmentation. <em>NN</em>, <em>193</em>, 108000. (<a href='https://doi.org/10.1016/j.neunet.2025.108000'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Segment Anything Model (SAM) has gained significant attention for its impressive performance in image segmentation. However, it lacks proficiency in referring video object segmentation (RVOS) due to the need for precise user-interactive prompts and a limited understanding of different modalities, such as language and vision. This paper presents the RefSAM model, which explores the potential of SAM for RVOS by incorporating multi-view information from diverse modalities and successive frames at different timestamps in an online manner. Our proposed approach adapts the original SAM model to enhance cross-modality learning by employing a lightweight Cross-Modal MLP that projects the text embedding of the referring expression into sparse and dense embeddings, serving as user-interactive prompts. Additionally, we have introduced the hierarchical dense attention module to fuse hierarchical visual semantic information with sparse embeddings to obtain fine-grained dense embeddings, and an implicit tracking module to generate a tracking token and provide historical information for the mask decoder. Furthermore, we employ a parameter-efficient tuning strategy to align and fuse the language and vision features effectively. Through comprehensive ablation studies, we demonstrate our model’s practical and effective design choices. Extensive experiments conducted on Refer-Youtube-VOS, Ref-DAVIS17, and three referring image segmentation datasets validate the superiority and effectiveness of our RefSAM model over existing methods. The code and models will be publicly available at https://github.com/LancasterLi/RefSAM and Papers with Code 1,2 .},
  archive      = {J_NN},
  author       = {Yonglin Li and Jing Zhang and Xiao Teng and Haoyu Zhang and Xinwang Liu and Long Lan},
  doi          = {10.1016/j.neunet.2025.108000},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108000},
  shortjournal = {Neural Netw.},
  title        = {RefSAM: Efficiently adapting segmenting anything model for referring video object segmentation},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Manod: A multi-modal anomaly detection framework for distributed system. <em>NN</em>, <em>193</em>, 107999. (<a href='https://doi.org/10.1016/j.neunet.2025.107999'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed infrastructure has been widely deployed in large-scale software systems in recent years to meet the growing demand for applications, due to its scalability and resource-sharing characteristics. Accurately predicting and identifying anomalies is critical to ensure the stable and reliable running of complex distributed systems. System abnormalities can often be reflected through key performance indicators and logs. Metrics provide quantitative measures of system performance and operational status, while logs record various events that occur in the system. Current approaches typically rely on a single data source to detect anomalies, which may lead to false positives and limit the accuracy of failure detection. A combination of these two data modalities can provide a comprehensive view of the system behavior. In this work, we propose a semi-supervised fault detection method, Manod, to monitor the health state of the system based on multimodal data. To obtain the discriminative representations, it employs a graph-based hierarchical encoding approach and leverages pre-trained language models for modeling metrics and logs, respectively. Then, it adopts a novel gated attention fusion method to integrate heterogeneous information. Extensive experiments on two datasets validate the effectiveness of our proposed Manod. It achieves F1-scores of 0.870 and 0.934 on one simulation dataset (D1) and one real-world dataset (D2), respectively, and significantly outperforms all baseline models. This demonstrates its capacity in mitigating both false positives and false negatives.},
  archive      = {J_NN},
  author       = {Wen Liu and Degang Sun and Haitian Yang and Yan Wang and Weiqing Huang},
  doi          = {10.1016/j.neunet.2025.107999},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107999},
  shortjournal = {Neural Netw.},
  title        = {Manod: A multi-modal anomaly detection framework for distributed system},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel twin parametric-margin support vector machine with capped asymmetric elastic net loss. <em>NN</em>, <em>193</em>, 107998. (<a href='https://doi.org/10.1016/j.neunet.2025.107998'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machine (SVM) is a widely used classifier, including hinge-SVM and twin parametric-margin support vector machine (TPWSVM). TPWSVM constructs two nonparallel hyperplanes by solving two smaller quadratic programming problems, demonstrating efficiency on large-scale datasets. However, conventional TPWSVM relies on hinge loss, leading to sensitivity to noise and instability under resampling. To overcome these drawbacks, we propose a novel capped asymmetric elastic net twin parametric-margin support vector machine (CaEN-TPMSVM), integrating capped asymmetric elastic net loss within the TPWSVM framework. Our method generalizes TPWSVM, improves noise robustness, and achieves a fourfold acceleration in training speed relative to standard SVM. Theoretical analysis demonstrates its convergence and stability properties. Empirical studies on synthetic and ten UCI datasets confirm its superior classification accuracy and computational efficiency.},
  archive      = {J_NN},
  author       = {Jianping Fu and Hu Yang},
  doi          = {10.1016/j.neunet.2025.107998},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107998},
  shortjournal = {Neural Netw.},
  title        = {A novel twin parametric-margin support vector machine with capped asymmetric elastic net loss},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enabling generalized zero-shot learning towards unseen domains by intrinsic learning from redundant LLM semantics. <em>NN</em>, <em>193</em>, 107997. (<a href='https://doi.org/10.1016/j.neunet.2025.107997'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized zero-shot learning (GZSL) focuses on recognizing seen and unseen classes against domain shift problem where data of unseen classes may be misclassified as seen classes. However, existing GZSL is still limited to seen domains. In the current work, we study cross-domain GZSL (CDGZSL) which addresses GZSL towards unseen domains. Different from existing GZSL methods, CDGZSL constructs a common feature space across domains and acquires the corresponding intrinsic semantics shared among domains to transfer from seen to unseen domains. Considering the information asymmetry problem caused by redundant class semantics annotated with large language models (LLMs), we present Meta Domain Alignment Semantic Refinement (MDASR). Technically, MDASR consists of two parts: Inter-class similarity alignment, which eliminates the non-intrinsic semantics not shared across all domains under the guidance of inter-class feature relationships, and unseen-class meta generation, which preserves intrinsic semantics to maintain connectivity between seen and unseen classes by simulating feature generation. MDASR effectively aligns the redundant semantic space with the common feature space, mitigating the information asymmetry in CDGZSL. The effectiveness of MDASR is demonstrated on two public datasets, Office-Home and Mini-DomainNet, as well as on a self-constructed multi-domain rare animal dataset. We have shared the LLM-based semantics for these datasets as a benchmark.},
  archive      = {J_NN},
  author       = {Jiaqi Yue and Chunhui Zhao and Jiancheng Zhao and Biao Huang},
  doi          = {10.1016/j.neunet.2025.107997},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107997},
  shortjournal = {Neural Netw.},
  title        = {Enabling generalized zero-shot learning towards unseen domains by intrinsic learning from redundant LLM semantics},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Large language modeling of hallucinatory problem mitigation based on the wheel of emotions. <em>NN</em>, <em>193</em>, 107996. (<a href='https://doi.org/10.1016/j.neunet.2025.107996'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have demonstrated remarkable generative capabilities across a wide range of natural language processing tasks. However, the frequent occurrence of hallucinations—outputs that appear plausible but are factually incorrect or logically inconsistent—poses a significant challenge to the reliability and practical utility of these models. This paper proposes a novel Emotion-Augmented Inference (EAI) method based on the Wheel of Emotions, aiming to mitigate hallucinations in multimodal generation tasks involving LLMs. EAI integrates two core mechanisms: visual-contrastive decoding and affective textual symbolization, which jointly enable the perception, regulation, and reconstruction of emotional signals during generation. These mechanisms enhance emotional coherence and semantic reliability in the model's outputs. Experimental results on two multimodal datasets, MSCOCO and GQA, show that EAI achieves improvements of 4%–8 % over baseline models in terms of key metrics such as accuracy, precision, recall, and F1-score. Additionally, under three emotional contexts—neutral (S1), positive (S2), and negative (S3)—EAI demonstrates particularly strong performance in hallucination suppression. In the S3 condition, accuracy improves by 5.48% and 2.23% compared to S1 and S2, respectively. These findings also indicate that EAI enhances the ability to manage emotion and maintain textual coherence. In summary, EAI not only stabilizes hallucination suppression in multimodal generation but also provides a new perspective for interpreting the emotional states embedded in LLM outputs. The proposed method offers a promising direction for building more trustworthy, controllable, and human-centered AI systems.},
  archive      = {J_NN},
  author       = {Zhenyu Wang and Jianmin Wang and Zenan Lu and Fang You},
  doi          = {10.1016/j.neunet.2025.107996},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107996},
  shortjournal = {Neural Netw.},
  title        = {Large language modeling of hallucinatory problem mitigation based on the wheel of emotions},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hypothesis spaces for deep learning. <em>NN</em>, <em>193</em>, 107995. (<a href='https://doi.org/10.1016/j.neunet.2025.107995'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a hypothesis space for deep learning based on deep neural networks (DNNs). By treating a DNN as a function of two variables—the input variable and the parameter variable—we consider the set of DNNs where the parameter variable belongs to a space of weight matrices and biases determined by a prescribed depth and layer widths. To construct a Banach space of functions of the input variable, we take the weak* closure of the linear span of this DNN set. We prove that the resulting Banach space is a reproducing kernel Banach space (RKBS) and explicitly construct its reproducing kernel. Furthermore, we investigate two learning models—regularized learning and the minimum norm interpolation (MNI) problem—within the RKBS framework by establishing representer theorems. These theorems reveal that the solutions to these learning problems can be expressed as a finite sum of kernel expansions based on training data.},
  archive      = {J_NN},
  author       = {Rui Wang and Yuesheng Xu and Mingsong Yan},
  doi          = {10.1016/j.neunet.2025.107995},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107995},
  shortjournal = {Neural Netw.},
  title        = {Hypothesis spaces for deep learning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reduced storage direct tensor ring decomposition for convolutional neural networks compression. <em>NN</em>, <em>193</em>, 107994. (<a href='https://doi.org/10.1016/j.neunet.2025.107994'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are among the most widely used machine learning models for computer vision tasks, such as image classification. To improve the efficiency of CNNs, many compression approaches have been developed. Low-rank methods approximate the original convolutional kernel with a sequence of smaller convolutional kernels, leading to reduced storage and time complexities. In this study, we propose a novel low-rank CNN compression method that is based on reduced storage direct tensor ring decomposition (RSDTR). The proposed method offers a higher circular mode permutation flexibility, and it is characterized by large parameter and FLOPS compression rates, while preserving a good classification accuracy of the compressed network. The experiments, performed on the CIFAR-10 and ImageNet datasets, clearly demonstrate the efficiency of RSDTR in comparison to other state-of-the-art CNN compression approaches.},
  archive      = {J_NN},
  author       = {Mateusz Gabor and Rafał Zdunek},
  doi          = {10.1016/j.neunet.2025.107994},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107994},
  shortjournal = {Neural Netw.},
  title        = {Reduced storage direct tensor ring decomposition for convolutional neural networks compression},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A prompt-aware knowledge-tuning framework for histopathology subtype classification with scarce annotation. <em>NN</em>, <em>193</em>, 107993. (<a href='https://doi.org/10.1016/j.neunet.2025.107993'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence can assist pathologists in diagnosing histopathology subtypes, enabling precision medicine and improving survival rates. Many approaches employ multi-scale models or combine knowledge to implement subtype diagnosis. However, they fail to identify explicit features most relevant to subtypes adaptively, resulting model relying heavily on extensive annotation. Moreover, knowledge is qualitatively represented by coarse-grained methods, such as using 0 or 1 to indicate negative or positive samples. However, they cannot be quantitatively described with a fine-grained process, such as with a probability of 0.23 or 0.81. In this paper, we propose a prompt-aware knowledge-tuning model called PAKT for subtype classification, which provides an adaptive feature generation while representing knowledge quantitatively with scarce annotation. Specifically, we design a prompt-aware module that adaptively predicts multi-scale histological probabilities. The pre-trained encoder can leverage vision prompts to obtain explicit features without extensive annotation. Furthermore, a knowledge-tuning module is constructed to provide sensible diagnostic processes. The trainable weight matrix can quantitatively represent diagnosis knowledge, reflecting the influence of different histological probabilities on subtypes. PAKT performs better than state-of-the-art methods in diagnosing subtypes, achieving an average performance improvement of over 10 %, as evidenced by extensive experimentation on both public and in-house datasets, thus validating its effectiveness. Moreover, its complexity is significantly reduced without losing performance compared with baselines. Code: https://github.com/Dennis-YB/PAKT.git},
  archive      = {J_NN},
  author       = {Bo Yu and Jiuman Song and Lele Cong and Xianling Cong and Jouke Dijkstra and Philip S. Yu and Hechang Chen},
  doi          = {10.1016/j.neunet.2025.107993},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107993},
  shortjournal = {Neural Netw.},
  title        = {A prompt-aware knowledge-tuning framework for histopathology subtype classification with scarce annotation},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unified auxiliary restoration network for robust multimodal 3D object detection in adverse conditions. <em>NN</em>, <em>193</em>, 107992. (<a href='https://doi.org/10.1016/j.neunet.2025.107992'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion of LiDAR and camera sensors offers remarkable results in multimodal 3D object detection with enhanced performance. However, existing fusion methods are primarily designed considering ideal data, ignoring the practical challenges of sensor specification and environmental variations encountered in autonomous driving. Thus, these methods often exhibit a significant performance degradation when faced with adverse conditions, such as sparse point cloud and inclement weather. To address these multiple adverse conditions simultaneously, we present the first attempt to apply auxiliary restoration networks in multimodal 3D object detection. These networks restore degraded point cloud and image, ensuring the primary multimodal detection network obtains higher quality features in a unified form. Especially, we propose a spherical domain point upsampler based on bilateral point generation and an adjustment network with a horizontal alignment block. Additionally, for efficient fusion with restored point cloud and image, we suggest a graph detector with a unified loss function, including auxiliary, contrastive, and difficulty losses. The experimental results demonstrate that the proposed approach prevents a performance decline in adverse conditions and outperforms state-of-the-art methods. The source code with pretrained weights for the proposed model is available at https://github.com/jhyoon964/auxphere .},
  archive      = {J_NN},
  author       = {Jae Hyun Yoon and Jong Won Jung and Seok Bong Yoo},
  doi          = {10.1016/j.neunet.2025.107992},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107992},
  shortjournal = {Neural Netw.},
  title        = {Unified auxiliary restoration network for robust multimodal 3D object detection in adverse conditions},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Joint noise detection and l2,p-norm metric in least squares twin SVM for robust multiclass classification. <em>NN</em>, <em>193</em>, 107991. (<a href='https://doi.org/10.1016/j.neunet.2025.107991'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The least squares twin support vector machine (LSTSVM) serves as a foundational framework for binary classification and is widely applied in statistical learning due to its solid theoretical foundation. It also plays a crucial role in advancing research in multiclass classification. However, the presence of noise in real-world datasets often leads to substantial performance degradation, compromising the reliability and generalizability of this model. Given the ubiquitous presence of noise, its influence on the learning of classification hyperplanes warrants rigorous attention. In this paper, we propose a robust multiclass classification model grounded in LSTSVM, designed to mitigate the influence of noisy data. The proposed framework replaces the conventional squared L 2 -norm with the more robust L 2 , p -norm ( 0 < p ≤ 2 ), which enhances resilience against noise. Furthermore, we introduce an innovative noise detection mechanism with a transparent physical interpretation, whereby a probabilistic weight is assigned to each sample to quantify its likelihood of being a normal observation. Specifically, normal samples receive a weight of 1, whereas suspected noisy samples receive a weight of 0. To solve the resulting non-convex optimization problem efficiently, we develop an iterative algorithm that adaptively penalizes normal samples exhibiting substantial errors. The convergence property of the algorithm is rigorously analyzed and theoretically supported. Moreover, the model is extended to semi-supervised learning, enabling the effective exploitation of both a limited set of labeled samples and the structural information inherent in numerous unlabeled samples. Finally, extensive experiments on benchmark and image datasets under varying noise levels demonstrate that the proposed approach consistently outperforms existing methods in terms of classification accuracy and robustness, validating its practical effectiveness in noisy multiclass settings.},
  archive      = {J_NN},
  author       = {Chao Yuan and Xiaoyuan Xu and Farshad Arvin and Huiyu Mu and Haiyang Li and Jigen Peng},
  doi          = {10.1016/j.neunet.2025.107991},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107991},
  shortjournal = {Neural Netw.},
  title        = {Joint noise detection and l2,p-norm metric in least squares twin SVM for robust multiclass classification},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GraphGuard: An adaptive approach for restoring accuracy in backdoor-compromised GNNs. <em>NN</em>, <em>193</em>, 107990. (<a href='https://doi.org/10.1016/j.neunet.2025.107990'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backdoor attacks present a significant threat to the reliability of machine learning models, including Graph Neural Networks (GNNs), by embedding triggers that manipulate model behavior. While many existing defenses focus on identifying these vulnerabilities, few address restoring model accuracy after an attack. This paper introduces a method for restoring the original accuracy of GNNs affected by backdoor attacks, a task complicated by the complex structure of graph data. Our approach combines advanced filtering and augmentation techniques that enhance the GNN’s resilience against hidden triggers. The filtering mechanisms remove suspicious data points to minimize the influence of poisoned inputs, while augmentation introduces controlled variation to strengthen the model against backdoor triggers. To optimize restoration, we present an adaptive framework that adjusts the balance between filtering and augmentation based on model sensitivity and attack severity, reducing both false positives and negatives. Additionally, we incorporate Explainable AI (XAI) techniques to improve the interpretability of the model’s decision-making process, enabling transparent detection and understanding of backdoor triggers. Results demonstrate that our method achieves an average accuracy restoration of 97–99 % across various backdoor attack scenarios, providing an effective solution to maintain the performance and integrity of GNNs in sensitive applications.},
  archive      = {J_NN},
  author       = {Adil Ahmad and Anwar Shah and Waleed Alnumay and Bahar Ali},
  doi          = {10.1016/j.neunet.2025.107990},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107990},
  shortjournal = {Neural Netw.},
  title        = {GraphGuard: An adaptive approach for restoring accuracy in backdoor-compromised GNNs},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Pay more attention to the robustness of LLMs on adversarial prompt for instruction data mining. <em>NN</em>, <em>193</em>, 107989. (<a href='https://doi.org/10.1016/j.neunet.2025.107989'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instruction tuning has emerged as a paramount method for tailoring the behaviors of LLMs. Recent studies have unveiled the potential for LLMs to achieve high performance through fine-tuning with a limited quantity of high-quality instruction data. Instruction-Following Difficulty is one of the most representative approaches in instruction data mining, which involves selecting samples where LLMs fail to generate response that align with the provided instructions as the high-quality instruction data. Building upon this approach, we further investigate how the robustness of LLMs to adversarial prompts influences the selection of high-quality instruction data. This paper proposes a pioneering framework of high-quality instruction data mining for instruction tuning, focusing on the impact of LLMs’ robustness on adversarial prompts. Our notable innovation is to generate adversarial instruction data by attacking the prompts associated with instruction samples. Then, we introduce an Adversarial Instruction-Following Difficulty (AIFD) metric, which utilizes complete instruction sample pairs to identify samples with high adversarial instruction difficulty as high-quality instruction data. Apart from it, to address cases where LLM responses deviate from user intent, we further introduce a novel Adversarial Instruction Output Embedding Consistency (AIOEC) method that relies solely on instruction prompts to mine high-quality online instruction data. We conduct extensive experiments on two benchmark datasets to assess the performance. The experimental results serve to underscore the effectiveness of our proposed two methods. Moreover, the results underscore the critical practical significance of considering the robustness of LLMs on adversarial prompts for instruction data mining.},
  archive      = {J_NN},
  author       = {Qiang Wang and Dawei Feng and Xu Zhang and Ao Shen and Yang Xu and Bo Ding and Huaimin Wang},
  doi          = {10.1016/j.neunet.2025.107989},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107989},
  shortjournal = {Neural Netw.},
  title        = {Pay more attention to the robustness of LLMs on adversarial prompt for instruction data mining},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adapformer: Adaptive channel management for multivariate time series forecasting. <em>NN</em>, <em>193</em>, 107988. (<a href='https://doi.org/10.1016/j.neunet.2025.107988'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multivariate time series forecasting (MTSF), accurately modeling the intricate dependencies among multiple variables remains a significant challenge due to the inherent limitations of traditional approaches. Most existing models adopt either channel-independent (CI) or channel-dependent (CD) strategies, each presenting distinct drawbacks. CI methods fail to leverage the potential insights from inter-channel interactions, resulting in models that may not fully exploit the underlying statistical dependencies present in the data. Conversely, CD approaches often incorporate too much extraneous information, risking model overfitting and predictive inefficiency. To address these issues, we introduce the Adaptive Forecasting Transformer ( Adapformer ), an advanced Transformer-based framework that merges the benefits of CI and CD methodologies through effective channel management. The core of Adapformer lies in its dual-stage encoder-decoder architecture, which includes the A daptive C hannel E nhancer ( ACE ) for enriching embedding processes and the A daptive C hannel F orecaster ( ACF ) for refining the predictions. ACE enhances token representations by selectively incorporating essential dependencies, while ACF streamlines the decoding process by focusing on the most relevant covariates, substantially reducing noise and redundancy. Our rigorous testing on diverse datasets shows that Adapformer achieves superior performance over existing models, enhancing both predictive accuracy and computational efficiency, thus making it state-of-the-art in MTSF.},
  archive      = {J_NN},
  author       = {Yuchen Luo and Xinyu Li and Liuhua Peng and Mingming Gong},
  doi          = {10.1016/j.neunet.2025.107988},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107988},
  shortjournal = {Neural Netw.},
  title        = {Adapformer: Adaptive channel management for multivariate time series forecasting},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-site brain disease identification based on tensor decomposition and personalized federated learning. <em>NN</em>, <em>193</em>, 107987. (<a href='https://doi.org/10.1016/j.neunet.2025.107987'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain diseases significantly impact physical and mental health, making the development of models to identify biomarkers for early diagnosis essential. However, building high-quality models typically relies on large-scale datasets, while the privacy-sensitive nature of medical data often restricts its sharing and utilization. Multi-site studies provide a potential solution by integrating data from various sources, yet existing methods frequently neglect site-specific private features, such as demographic information. Therefore, in this paper, we propose a simple yet effective framework based on Tensor Decomposition and Personalized Federated Learning (TDPFL) for multi-site brain disease recognition, while protecting these private features. On the central server, we designed a dual feature aggregation module to facilitate efficient knowledge sharing among sites. On the client side, we introduced a personalized branch to safeguard private information ( i.e. , age, gender, and education) and developed a tensor decomposition module to extract features from subjects’ brain scan data. Furthermore, we developed a dynamic prototype aggregation module to monitor evolving brain features over time. This mechanism enhances the model’s capacity to capture these dynamics, thereby improving classification and prediction accuracy. Experiments on two publicly available rs-fMRI datasets across six sites showed that TDPFL outperformed baseline methods with a 4 % improvement in average classification accuracy. Additionally, we identified site-specific brain disease-related biomarkers, offering novel insights into early diagnosis. Code is available at https://github.com/ChaojunZ/TDPFL.git},
  archive      = {J_NN},
  author       = {Chaojun Zhang and Jing Yang and Yuan Gao and Xiangli Yang and Shaojun Zou and Jieming Yang},
  doi          = {10.1016/j.neunet.2025.107987},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107987},
  shortjournal = {Neural Netw.},
  title        = {Multi-site brain disease identification based on tensor decomposition and personalized federated learning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Recurrent stochastic configuration networks with block increments. <em>NN</em>, <em>193</em>, 107986. (<a href='https://doi.org/10.1016/j.neunet.2025.107986'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent stochastic configuration networks (RSCNs) have shown promise in modelling nonlinear dynamic systems with order uncertainty due to their advantages of easy implementation, less human intervention, and strong approximation capability. This paper develops the original RSCNs with block increments, termed block RSCNs (BRSCNs), to further enhance the learning capacity and efficiency of the network. BRSCNs can simultaneously add multiple reservoir nodes (subreservoirs) during the construction. Each subreservoir is configured with a unique structure in the light of a supervisory mechanism, ensuring the universal approximation property. The reservoir feedback matrix is appropriately scaled to guarantee the echo state property of the network. Furthermore, the output weights are updated online using a projection algorithm, and the persistent excitation conditions that facilitate parameter convergence are also established. Numerical results over a time series prediction, a nonlinear system identification task, and two industrial data predictive analyses demonstrate that the proposed BRSCN performs favourably in terms of modelling efficiency, learning, and generalization performance, highlighting their significant potential for coping with complex dynamics.},
  archive      = {J_NN},
  author       = {Dianhui Wang and Gang Dang},
  doi          = {10.1016/j.neunet.2025.107986},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107986},
  shortjournal = {Neural Netw.},
  title        = {Recurrent stochastic configuration networks with block increments},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SPD-updater: Symmetric positive definite manifold geometry based temporal updating for visual object tracking. <em>NN</em>, <em>193</em>, 107985. (<a href='https://doi.org/10.1016/j.neunet.2025.107985'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual object tracking has witnessed continuous advances in recent years along with the exciting developments in backbone networks. In general, all advanced solutions adhere to the template-based tracking framework, which exhibits powerful representative capacity gained via offline training. However, when the target undergoes appearance changes or occlusion, the tracker, which relies on a fixed template defined in the initial frame, struggles to locate it accurately in such complex situations. To achieve online adaptation, recent studies have introduced dynamic templates. Typically, the adopted solution is to compute reliability scores in the traditional Euclidean space to assess the confidence of the dynamic template. However, the Euclidean metric is unreliable to some extent in high-dimensional feature spaces, potentially resulting in a negative impact by involving incorrect dynamic templates. To overcome this problem, we exploit the compact geometric representation capacity of the Symmetric Positive Definite (SPD) manifold to design a novel score prediction module for the tracker update (SPD-Updater). By switching to an SPD manifold metric, we obtain a more accurate and stable dynamic template, thereby enhancing the model capacity to handle complex situations. To validate the reliability of manifold metric in tracking models, we conduct experiments with trackers using different backbones. The experimental results on LaSOT, GOT-10k, TrackingNet, and UAV123 demonstrate the effectiveness of our approach, reflecting the merit of the SPD metric in online tracking adaptation.},
  archive      = {J_NN},
  author       = {Jinglin Zhou and Tianyang Xu and Xuefeng Zhu and Xiao-Jun Wu and Josef Kittler},
  doi          = {10.1016/j.neunet.2025.107985},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107985},
  shortjournal = {Neural Netw.},
  title        = {SPD-updater: Symmetric positive definite manifold geometry based temporal updating for visual object tracking},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DRG: A dual relational graph framework for course recommendation. <em>NN</em>, <em>193</em>, 107984. (<a href='https://doi.org/10.1016/j.neunet.2025.107984'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The course recommendation system is a core application of recommendation technology in the educational field. Its significance lies in accurately matching users’ interests and needs while providing valuable feedback to instructors, thereby fostering continuous improvement in teaching quality. Various techniques have been proposed for this purpose, with Large Language Models (LLMs) demonstrating significant potential in course recommendation tasks. However, the issue of data sparsity remains a critical bottleneck that limits the accuracy of the recommendation. In this study, we propose a Dual Relationship Graph (DRG) framework that addresses data sparsity by modeling both course-course and user-course relationships through a dual-graph structure. Specifically, DRG constructs two relational graphs: a course-based graph built using LLM-based semantic reasoning, collaborative filtering, clustering, and association rule mining; and a user-based graph constructed via collaborative filtering and LLM-based preference inference. These graphs are integrated into a unified recommendation pipeline through joint graph learning and collaborative reasoning. The enhanced interaction graphs significantly alleviated sparsity, increasing link coverage by 37.88 % and 12.67 % on the two datasets, respectively. Notably, DRG is designed as a plug-and-play module, compatible with both traditional models and LLM-based recommendation systems. Experimental results show that our DRG excels in task ranking across two benchmark datasets, significantly enhancing traditional recommendation models and LLM-based methods. Moreover, DRG’s dual relationship graph consistently outperforms single relationship approaches, underscoring the importance of multi-perspective integration in course recommendation systems. By unifying dual-perspective graph modeling with LLM-driven semantic understanding, DRG provides a scalable and effective solution for personalized course recommendation in sparse educational environments. The code and datasets will be made available at https://github.com/WHCK1102/DRG .},
  archive      = {J_NN},
  author       = {Yong Ouyang and Zhen Ye and Lingyu Chen and Huanwen Wang and Yawen Zeng},
  doi          = {10.1016/j.neunet.2025.107984},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107984},
  shortjournal = {Neural Netw.},
  title        = {DRG: A dual relational graph framework for course recommendation},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning in PINNs: Phase transition, diffusion equilibrium, and generalization. <em>NN</em>, <em>193</em>, 107983. (<a href='https://doi.org/10.1016/j.neunet.2025.107983'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the learning dynamics of fully-connected neural networks through the lens of the neural gradient signal-to-noise ratio (SNR), examining the behavior of first-order optimizers in non-convex objectives. By interpreting the drift/diffusion phases as proposed in the information bottleneck theory, we identify a third phase termed “diffusion equilibrium” (DE), a stable training phase characterized by highly-ordered neural gradients across the sample space. This phase is marked by an abrupt (first-order) transition, where sample-wise gradients align (SNR increases), and stable optimizer convergence. Moreover, we find that when homogeneous residuals are also met across the sample space during the DE phase, this leads to better generalization, as the optimization steps are equally sensitive to each sample. Based on this observation, we propose a sample-wise re-weighting scheme, which considerably improves the residual homogeneity and generalization in quadratic loss functions, by targeting the problematic samples with large residuals and vanishing gradients. Finally, we explore the information compression phenomenon, pinpointing a significant saturation-induced compression of activations at the DE phase transition, driven by the sample-wise gradient directional alignment. Interestingly, it is during the saturation of activations that the model converges, with deeper layers experiencing negligible information loss. Supported by experimental examples on physics-informed neural networks (PINNs), which highlight the critical role of gradient agreement due to their inherent PDE-based interdependence of samples, our findings suggest that when both sample-wise gradients and residuals transition in an ordered state, this leads to faster convergence and better generalization. Identifying these phase transitions could improve deep learning optimization strategies, enhancing physics-informed methods and overall machine learning performance.},
  archive      = {J_NN},
  author       = {Sokratis J. Anagnostopoulos and Juan Diego Toscano and Nikolaos Stergiopulos and George Em Karniadakis},
  doi          = {10.1016/j.neunet.2025.107983},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107983},
  shortjournal = {Neural Netw.},
  title        = {Learning in PINNs: Phase transition, diffusion equilibrium, and generalization},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-channel hierarchical interactive learning for the prediction of protein-ligand binding affinity. <em>NN</em>, <em>193</em>, 107982. (<a href='https://doi.org/10.1016/j.neunet.2025.107982'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein-ligand binding affinity (PLBA) is a crucial metric in drug screening for identifying potential candidate compounds. In recent years, deep learning-based methods have used representation learning to model interactions within protein-ligand complexes, demonstrating great promise in affinity prediction tasks. Existing studies have considered both intramolecular (covalent) and intermolecular (non-covalent) interactions to some extent. However, these interactions are often treated as independent features, lacking explicit hierarchical dependency modeling, which may lead to insufficient representation of interaction information and ultimately limit the accuracy of affinity predictions. To address this issue, we propose a novel approach—Dual-channel Hierarchical Interactive Learning (DHIL)—to achieve a more comprehensive modeling of protein-ligand interactions. DHIL employs a dual-channel encoding structure to simultaneously learn intramolecular and intermolecular interactions, ensuring the completeness of interaction features. Additionally, we design a hierarchical interactive learning paradigm to facilitate information exchange between these two interaction types at multiple levels, promoting their collaborative modeling. This mechanism mimics the local-to-global working principles of biological systems, enabling a more detailed and holistic representation of protein-ligand interactions. We conduct extensive and comprehensive experiments on a diverse set of benchmark datasets, rigorously evaluating the effectiveness of DHIL. The results demonstrate that DHIL significantly improves PLBA prediction accuracy, outperforming existing methods and further validating its potential in drug discovery and screening tasks. Nevertheless, the proposed framework introduces notable computational overhead due to multi-scale graph construction and cross-level message passing. It also exhibits sensitivity to the quality of input 3D binding conformations, which may affect its robustness in practical applications. These limitations suggest future directions for improving model efficiency and generalizability. To facilitate reproducibility and further research, the complete source code of DHIL has been released at: https://github.com/WZY-0814/DHIL .},
  archive      = {J_NN},
  author       = {Zheyu Wu and Huifang Ma and Bin Deng and Zhixin Li and Liang Chang},
  doi          = {10.1016/j.neunet.2025.107982},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107982},
  shortjournal = {Neural Netw.},
  title        = {Dual-channel hierarchical interactive learning for the prediction of protein-ligand binding affinity},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tensorized anchor alignment for incomplete multi-view clustering. <em>NN</em>, <em>193</em>, 107981. (<a href='https://doi.org/10.1016/j.neunet.2025.107981'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete Multi-View Clustering (IMVC) focuses on uncovering the consensus and complementary information present in datasets with multiple incomplete views. However, existing IMVC methods face several limitations. First, many approaches exhibit high computational complexity. Second, anchor misalignment across views remains a challenge. Third, high-order correlations among views are often overlooked. To address these challenges, the paper introduces a novel framework called Tensorized Anchor Alignment for Incomplete Multi-view Clustering (TAA-IMC). Specifically, the view-specific anchor graphs are constructed to reduce computational complexity while preserving the diversity of information among views. Then, to mitigate the issue of anchor misalignment, a binary alignment matrix is introduced, ensuring proper correspondence between anchors across different views. Moreover, the aligned anchor graphs are integrated into a tensor representation with a low-rank constraint, enabling the extraction of high-order correlation information. Finally, the proposed TAA-IMC is solved using an alternating update method, showcasing efficiency through memory and time complexity analyses. Extensive comparative experiments conducted on seven benchmark datasets validate the efficiency and superiority of TAA-IMC over state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Yiran Cai and Hangjun Che and Wei Guo and Baicheng Pan and Man-Fai Leung},
  doi          = {10.1016/j.neunet.2025.107981},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107981},
  shortjournal = {Neural Netw.},
  title        = {Tensorized anchor alignment for incomplete multi-view clustering},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Symmetrical bidirectional knowledge alignment for zero-shot sketch-based image retrieval. <em>NN</em>, <em>193</em>, 107980. (<a href='https://doi.org/10.1016/j.neunet.2025.107980'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of zero-shot sketch-based image retrieval (ZS-SBIR), which aims to use sketches from unseen categories as queries to match the images of the same category. Due to the large cross-modality discrepancy, ZS-SBIR is still a challenging task and mimics realistic zero-shot scenarios. The key is to leverage transferable knowledge from the pre-trained model to improve generalizability. Existing researchers often utilize the simple fine-tuning training strategy or knowledge distillation from a teacher model with fixed parameters, lacking efficient bidirectional knowledge alignment between student and teacher models simultaneously for better generalization. In this paper, we propose a novel Symmetrical Bidirectional Knowledge Alignment for zero-shot sketch-based image retrieval (SBKA). The symmetrical bidirectional knowledge alignment learning framework is designed to effectively learn mutual rich discriminative information between teacher and student models to achieve the goal of knowledge alignment. Instead of the former one-to-one cross-modality matching in the testing stage, a one-to-many cluster cross-modality matching method is proposed to leverage the inherent relationship of intra-class images to reduce the adverse effects of the existing modality gap. Experiments on several representative ZS-SBIR datasets (Sketchy Ext dataset, TU-Berlin Ext dataset and QuickDraw Ext dataset) prove the proposed algorithm can achieve superior performance compared with state-of-the-art methods. The source code is publicly available at https://github.com/zermatt-luo/SBKA .},
  archive      = {J_NN},
  author       = {Decheng Liu and Xu Luo and Chunlei Peng and Nannan Wang and Ruimin Hu and Xinbo Gao},
  doi          = {10.1016/j.neunet.2025.107980},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107980},
  shortjournal = {Neural Netw.},
  title        = {Symmetrical bidirectional knowledge alignment for zero-shot sketch-based image retrieval},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing feature discrimination with pseudo-labels for foundation model in segmentation of 3D medical images. <em>NN</em>, <em>193</em>, 107979. (<a href='https://doi.org/10.1016/j.neunet.2025.107979'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Development of medical image segmentation foundation models relies on large-scale samples. However, it is more time-consuming to annotate 3D medical images than 2D natural images, making it challenging to collect sufficient annotated samples. While pseudo-labeling offers a potential solution to expand the annotated dataset, it may introduce noisy labels that can create systematic biases, particularly affecting the segmentation performance of smaller anatomical structures. To this end, we propose a pseudo-label enriched segmentation framework (PESF), which integrates confidence filtering and perturbation-based curriculum learning. To begin with, our pseudo-labeling approach applies a well-pretrained foundation model to generate pseudo-labels for previously unannotated organ categories, effectively expanding the number of classes in the original dataset. Subsequently, we develop a confidence-based filtering mechanism, leveraging a feature extraction module combined with a confidence prediction module to quantitatively assess and filter out low-quality pseudo-labels, thereby minimizing the detrimental effects of noisy pseudo-labels on the model’s optimization. Furthermore, a progressive sampling strategy that integrates curriculum learning with Gaussian random perturbations is proposed, systematically introducing training samples from simpler to more complex cases, thereby enhancing the model’s generalization capability across organs of varying shapes and sizes. Additionally, our theoretical analysis reveals that incorporating these extra pseudo-labeled classes strengthens feature discrimination by increasing the angular margins between class decision boundaries in the embedding space. Experimental results demonstrate that PESF achieves a 6.8% improvement in the overall average Dice Similarity Coefficient (DSC) compared to the baseline SAM-Med3D on (Amos, FLARE22, WORD, BTCV), with particularly gains in challenging anatomical structures such as the pancreas and esophagus. The code is available at https://github.com/lonezhizi/PESF .},
  archive      = {J_NN},
  author       = {Ge Jin and Qian Zhang and Yong Cheng and Ming Xu and Yingwen Zhu and De Yu and Yongqi Yuan and Juncheng Li and Jun Shi},
  doi          = {10.1016/j.neunet.2025.107979},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107979},
  shortjournal = {Neural Netw.},
  title        = {Enhancing feature discrimination with pseudo-labels for foundation model in segmentation of 3D medical images},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Gabor-enhanced physics-informed neural networks for fast simulations of acoustic wavefields. <em>NN</em>, <em>193</em>, 107978. (<a href='https://doi.org/10.1016/j.neunet.2025.107978'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-Informed Neural Networks (PINNs) have gained attention for solving partial differential equations, including the scattered Helmholtz equation, due to their flexibility and mesh-free formulation. However, their performance suffers from low-frequency bias, particularly in high-frequency wavefield simulations, limiting convergence speed and accuracy. To address this, we propose a novel and simplified PINN framework that incorporates explicit, trainable Gabor basis functions to efficiently capture the localized and oscillatory nature of wavefields. Unlike previous Gabor-based PINNs that rely on multiplicative filters or auxiliary networks to learn Gabor parameters, our approach redefines the network’s task as learning a nonlinear mapping from input coordinates to a custom Gabor coordinate system, where a Gabor function captures the dominant oscillatory behavior of the wavefield. This formulation absorbs the effect of two Gabor parameters into the learned mapping, reducing computational complexity and eliminating the need for manual tuning of hyperparameters. We also present an efficient formulation for incorporating a Perfectly Matched Layer (PML) into the training by deriving real-valued loss components and introducing an analytical expression for the background wavefield. Numerical experiments on various velocity models show that our Gabor-PINN achieves faster convergence, higher accuracy, and greater robustness to architectural design and initialization compared to both traditional PINNs and prior Gabor-based methods. The improvement lies not in adding architectural complexity—as is common in enhanced PINNs—but in absorbing this complexity into the learned coordinate transformation, making the method both simpler and more effective. Our implementation is publicly available to support reproducibility and future research.},
  archive      = {J_NN},
  author       = {Mohammad Mahdi Abedi and David Pardo and Tariq Alkhalifah},
  doi          = {10.1016/j.neunet.2025.107978},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107978},
  shortjournal = {Neural Netw.},
  title        = {Gabor-enhanced physics-informed neural networks for fast simulations of acoustic wavefields},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning instrumental variable representation for debiasing in recommender systems. <em>NN</em>, <em>193</em>, 107977. (<a href='https://doi.org/10.1016/j.neunet.2025.107977'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are essential for filtering content to match user preferences. However, traditional recommender systems often suffer from biases inherent in the data, such as popularity bias. These biases, particularly those stemming from latent confounders, can result in inaccurate recommendations and reduce both the diversity and effectiveness of the system. Existing debiasing methods for recommender systems, however, either fail to account for latent confounders or rely on predefined instrumental variables (IVs). To address this research gap, we propose a novel causality-based recommendation algorithm, D ata-driven IV representation learning for debiasing in R ecommender S ystem (DIVRS), which enables the learning of IV representation directly from user-item interaction data. By leveraging the learned IV representation, DIVRS decomposes user behaviour into causal and confounding relationships to address potential bias in recommender systems. Additionally, we introduce Orthogonal Promotion Regularisation (OPR) for DIVRS to address the problem that Graph Convolutional Networks (GCNs) amplify bias. We also propose a variant of GCNs for DIVRS, called DIVRS-GCN. Experimental results on the Douban-Movie and Movielens-10M datasets demonstrate that both DIVRS and DIVRS-GCN effectively mitigate confounding bias while outperform the state-of-the-art methods in recommendation performance. For example, on both datasets, our DIVRS and DIVRS-GCN improve Recall@20 by up to 10.98 %. This validates their effectiveness and robustness. Our approaches improve recommendation accuracy while delivering more balanced and diverse suggestions, effectively addressing the limitations of existing IV-based recommender systems.},
  archive      = {J_NN},
  author       = {Zhirong Huang and Shichao Zhang and Debo Cheng and Jiuyong Li and Lin Liu and Guangquan Lu and Guixian Zhang},
  doi          = {10.1016/j.neunet.2025.107977},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107977},
  shortjournal = {Neural Netw.},
  title        = {Learning instrumental variable representation for debiasing in recommender systems},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing signed graph neural networks through curriculum-based training. <em>NN</em>, <em>193</em>, 107975. (<a href='https://doi.org/10.1016/j.neunet.2025.107975'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Signed graphs are powerful models for representing complex relations with both positive and negative connections. Recently, Signed Graph Neural Networks (SGNNs) have emerged as potent tools for analyzing such graphs. To our knowledge, no prior research has been conducted on devising a training plan specifically for SGNNs. The prevailing training approach feeds samples (edges) to models in a random order, resulting in equal contributionsfrom each sample during the training process, but fails to account for varying learning difficulties based on the graph’s structure. We contend that SGNNs can benefit from a curriculum that progresses from easy to difficult, similar to human learning. The main challenge is evaluating the difficulty of edges in a signed graph. Weaddress this by theoretically analyzing the difficulty of SGNNs in learning adequate representations for edges in unbalanced cycles and propose a lightweight difficulty measurer. This forms the basis for our innovative C urriculum representation learning framework for S igned G raphs, referred to as CSG . The process involves using the measurer to assign difficulty scores to training samples, adjusting their order using a scheduler and training the SGNN model accordingly. We empirically our approach on six real-world signed graph datasets. Our method demonstrates remarkable results, enhancing the accuracy of popular SGNN models by up to 23.7 % and showing a reduction of 8.4 % in standard deviation, enhancing model stability. Our implementation is available in PyTorch ( https://github.com/Alex-Zeyu/CSG ).},
  archive      = {J_NN},
  author       = {Zeyu Zhang and Lu Li and Xingyu Ji and Kaiqi Zhao and Xiaofeng Zhu and Philip S. Yu and Jiawei Li and Maojun Wang},
  doi          = {10.1016/j.neunet.2025.107975},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107975},
  shortjournal = {Neural Netw.},
  title        = {Enhancing signed graph neural networks through curriculum-based training},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Granular ball twin support vector machine with universum data. <em>NN</em>, <em>193</em>, 107974. (<a href='https://doi.org/10.1016/j.neunet.2025.107974'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machines often underperform when limited to labelled target class data and demonstrate sensitivity to noise and outliers. To address these limitations, we propose the Granular Ball Twin Support Vector Machine with Universum Data (GBU-TSVM), which uniquely integrates Universum samples with granular ball computing in the TSVM framework. Unlike conventional TSVMs representing data as points in feature space, the proposed GBU-TSVM models instances as hyperballs, significantly improving robustness against noise while enhancing computational efficiency. Granular representation enables effective data grouping, reducing processing complexity while preserving critical structural information. Incorporating Universum data, consisting of samples outside the target classes, provides additional contextual information that refines decision boundaries and improves generalization. Experiments on UCI benchmark datasets demonstrate GBU-TSVM’s superior performance, measured in terms of accuracy and training time. It achieves 92.38 % accuracy on the Molec Biol Promoter dataset under optimal conditions and maintains 89.17 % accuracy even with 20 % noise contamination. It consistently outperforms baseline models such as GBSVM, TSVM, GBTSVM, Pin-GTSVM, and UTSVM. These results establish GBU-TSVM as an advanced framework for robust classification in challenging data environments.},
  archive      = {J_NN},
  author       = {M.A. Ganaie and Vrushank Ahire},
  doi          = {10.1016/j.neunet.2025.107974},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107974},
  shortjournal = {Neural Netw.},
  title        = {Granular ball twin support vector machine with universum data},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hypergraph node representation learning with one-stage message passing. <em>NN</em>, <em>193</em>, 107973. (<a href='https://doi.org/10.1016/j.neunet.2025.107973'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypergraphs as an expressive and general structure have attracted considerable attention from various research domains. Most existing hypergraph node representation learning techniques are based on graph neural networks, and thus adopt the two-stage message passing paradigm (i.e. node → hyperedge → node). This paradigm only focuses on local information propagation and does not effectively take into account global information, resulting in less optimal representations. Our theoretical analysis of representative two-stage message passing methods shows that, mathematically, they model different ways of local message passing through hyperedges, and can be unified into one-stage message passing (i.e. node → node). However, they still only model local information. Motivated by this theoretical analysis, we propose a novel one-stage message passing paradigm to model both global and local information propagation for hypergraphs. We integrate this paradigm into HGraphormer, a Transformer-based framework for hypergraph node representation learning. HGraphormer injects the hypergraph structure information (local information) into Transformers (global information) by combining the attention matrix and hypergraph Laplacian. Extensive experiments demonstrate that HGraphormer outperforms recent hypergraph learning methods on five representative benchmark datasets on the semi-supervised hypernode classification task, setting new state-of-the-art performance, with accuracy improvements between 2.52 % and 6.70 %. Our code and datasets are available. 1},
  archive      = {J_NN},
  author       = {Shilin Qu and Weiqing Wang and Yuan-Fang Li and Xin Zhou and Fajie Yuan},
  doi          = {10.1016/j.neunet.2025.107973},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107973},
  shortjournal = {Neural Netw.},
  title        = {Hypergraph node representation learning with one-stage message passing},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-view parallel convolutional network for organ segmentation in mediastinal region on CT images. <em>NN</em>, <em>193</em>, 107972. (<a href='https://doi.org/10.1016/j.neunet.2025.107972'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In lung CT images, mediastinal organ segmentation is crucial for localizing different mediastinal regions. However, existing medical image segmentation methods exhibit significant limitations in modeling the diverse topological structures of organs, sensitivity to intra-class morphological variations, and inter-class feature differentiation. To address these limitations, we propose a novel multi-view parallel convolutional network (MVPCNet), built on an efficient U-shaped encoder-decoder framework. The shallow and deep information encoders are respectively composed of alternating multi-view parallel convolution module (MVPM) and the dual-path backbone structure (DPBS) at different scales. MVPM is designed as a parallel convolutional structure to enhance the model’s ability to capture complex structural features, enabling complementary extraction of morphological and detailed features. DPBS comprises the efficient dual-channel bottleneck structures (EDC-BS) and the region fusion small-kernel deformable attention mechanism (RF-SKDA). EDC-BS employs a branched convolutional architecture, effectively reducing computational complexity while ensuring accurate recognition of the same organ across varying morphologies. RF-SKDA captures the spatial structural information of different organs by combining regional and global average pooling, and further extracts organ-specific morphological features through the deformable convolutions. The decoder utilizes lightweight parameterization through depthwise separable convolutions and integrates multi-scale features during the decoding process. Experimental results demonstrate that MVPCNet achieves an average Dice Coefficient of 90.59 % and an mIoU of 82.80 % on mediastinal organ dataset. With a parameter size of only 8.21 MB, it outperforms advanced medical segmentation algorithms and classical lightweight semantic segmentation models.},
  archive      = {J_NN},
  author       = {Yining Xie and Wei Zhou and Jiayi Ma and Fengjiao Wang and Jing Zhao},
  doi          = {10.1016/j.neunet.2025.107972},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107972},
  shortjournal = {Neural Netw.},
  title        = {Multi-view parallel convolutional network for organ segmentation in mediastinal region on CT images},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Domain-aware self-prompting for cross-domain sequential recommendations with natural language explanations. <em>NN</em>, <em>193</em>, 107969. (<a href='https://doi.org/10.1016/j.neunet.2025.107969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain sequential recommendation faces persistent challenges in addressing domain shift, data sparsity, and the trade-off between performance, efficiency, and explainability. Existing methods often struggle with inefficient cross-domain adaptation or fail to generate coherent explanations that bridge user preferences across domains. To overcome these limitations, we propose Domain-Aware Self-Prompting (DASP) , a novel framework that integrates cross-domain recommendation with natural language explanation generation. DASP introduces three key innovations: (1) a domain-invariant self-prompt generator that captures shared user preferences via contrastive alignment across domains; (2) lightweight domain adapters with meta-learned initialization for parameter-efficient adaptation to target domains; and (3) a cross-domain explanation generator that grounds recommendations in semantically aligned multi-domain prompts using large language models. Extensive experiments on Amazon Movie-Book and Food-Kitchen datasets demonstrate DASP’s superiority, achieving 10.7 % and 10.5 % improvements in HR@10 and NDCG@10 over state-of-the-art baselines on the Movie-Book dataset, while reducing training time by 54 % compared to full large language models fine-tuning approaches. Qualitative and quantitative analyses validate DASP’s ability to generate interpretable explanations that link cross-domain preferences, offering a scalable and trustworthy solution for cross-domain sequential recommendation. Our work bridges critical gaps in efficiency, adaptability, and explainability for real-world multi-domain recommendation systems.},
  archive      = {J_NN},
  author       = {Tesfaye Fenta Boka and Zhendong Niu and Tekie Tsegay Tewolde and Ramadhani Duma},
  doi          = {10.1016/j.neunet.2025.107969},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107969},
  shortjournal = {Neural Netw.},
  title        = {Domain-aware self-prompting for cross-domain sequential recommendations with natural language explanations},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive spatial feature extraction and graphical feature awareness for robust point cloud registration. <em>NN</em>, <em>193</em>, 107966. (<a href='https://doi.org/10.1016/j.neunet.2025.107966'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years Transformers have achieved significant success in the field of 3D vision due to their inherent advantages in capturing global correlations between features. However, this can be a drawback in point cloud registration, especially in scenes with low overlap rates, where a large number of non-overlapping points can lead to ineffective or even negative attention allocation. Moreover, existing RANSAC-based registration estimators usually require a large number of iterations to obtain acceptable results, resulting in significant computational overhead. To address the above issues, we propose LDGR, which achieves robust registration in low overlap scenarios by utilizing a feature extractor with adaptive receptive fields and graphical feature awareness. Firstly, we proposed a 3D convolutional method with an adaptive receptive field named Adaptive Point Convolution (APConv) as the feature extractor. Its distinguishing feature is that the receptive field of the convolutional kernel is obtained through learning, which enables it to more flexibly handle irregular and unordered point clouds, thereby extracting richer and more diverse point features. Furthermore, to overcome the dilemma in cases of low overlap, we improved the transformer with rich local geometric information embedding and graphical feature awareness. This ensures that the model focuses more on the local spatial structure and features of the points during low overlap registration. Additionally, we propose a registration evaluator with local diffusion to global (LDGR). Compared to traditional RANSAC, it achieves comparable registration quality without requiring numerous iterative computations. Finally, we conducted several experiments on publicly available datasets such as 3DMatch and 3DLoMatch, KITTI odometry, ModelNet and ModelLoNet to validate the effectiveness of our method. We achieve optimal results in all four tests on ModelNet and ModelLoNet, significantly outperforming current state-of-the-art methods. Results on the challenging 3DMatch and 3DLoMatch datasets demonstrate the robustness of our method, with our inlier ratio substantially outperforming current state-of-the-art methods. Our experiments on the KITTI dataset demonstrate that LDGR performs no worse than RANSAC, while not requiring a large number of iterations.},
  archive      = {J_NN},
  author       = {Yilin Chen and Yang Mei and Tao Lu and Lu Zou and Xiangyun Liao and Fazhi He},
  doi          = {10.1016/j.neunet.2025.107966},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107966},
  shortjournal = {Neural Netw.},
  title        = {Adaptive spatial feature extraction and graphical feature awareness for robust point cloud registration},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Major depressive disorder detection via temporal-frequency-spatial transformer with sub-domain knowledge alignment using EEG. <em>NN</em>, <em>193</em>, 107965. (<a href='https://doi.org/10.1016/j.neunet.2025.107965'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Major Depressive Disorder (MDD) is a common mental illness that seriously jeopardizes the physical and mental health of patients. Accurate detection of MDD is crucial for treatment. Currently, there are significant differences in the EEG signals of each MDD patient, leading to lower accuracy of cross-subject MDD detection. Transformer-based methods have been used by scholars to detect MDD using electroencephalogram (EEG) data, but these methods often neglect the frequency features, focusing primarily on global domain adaptation (DA) while ignoring sub-domain alignment, resulting in loss of fine-grained discriminative information. To address this, we incorporate fine-grained frequency features to improve sub-domain alignment in DA rather than relying solely on global feature alignment. Building on the above analysis, we propose the TFST-SDKA model, a temporal-frequency-spatial Transformer (TFST) integrated with a sub-domain knowledge alignment (SDKA) method for MDD detection. The SDKA module classifies subjects into distinct sub-domains based on their labels by extracting fine-grained discriminative information from each subject. This process helps bridge the gap between source and target domains, enhancing the model’s generalization. In addition, we propose a frequency attention (FA) mechanism, which uses discrete cosine transform (DCT) to convert EEG feature maps into the frequency domain. The FA extracts multiple frequency information of EEG signals associated with MDD and combines these frequency data to enhance the model’s representational capability. As a result, the TFST-SDKA model improves EEG feature representation and aligns source and target domain features. Extensive experiments conducted on the MODMA and PRED+CT datasets demonstrate that our proposed TFST-SDKA model outperforms state-of-the-art (SOTA) methods in MDD detection tasks. Specifically, our method exceeds the SOTA methods by 1.42 % on the MODMA dataset and 1.16 % on the PRED+CT dataset in terms of accuracy.},
  archive      = {J_NN},
  author       = {Chen-Yang Xu and Fei-Yi Fan and Li-Xuan Zhao and Li-Cheng Jin and Yong-Hui Zhang and Qing-Hao Meng},
  doi          = {10.1016/j.neunet.2025.107965},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107965},
  shortjournal = {Neural Netw.},
  title        = {Major depressive disorder detection via temporal-frequency-spatial transformer with sub-domain knowledge alignment using EEG},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic graph transformation with multi-task learning for enhanced spatio-temporal traffic prediction. <em>NN</em>, <em>193</em>, 107963. (<a href='https://doi.org/10.1016/j.neunet.2025.107963'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic prediction plays an essential role in intelligent transportation systems by supporting urban traffic management and public safety. A major challenge lies in addressing both the limitations of static assumptions and the inherent complexity they introduce when modeling dynamic and heterogeneous traffic systems. Traditional methods often simplify complex spatio-temporal data into a single-dimensional framework, potentially overlooking intricate node interactions and detailed network characteristics. This fundamental challenge manifests primarily in single-task approaches. When extended to multi-task learning scenarios, the complexity and limitations of this modeling challenge becomes more pronounced. To address these issues, this paper introduce a novel framework, Dynamic Graph Transformation with Multi-Task Learning (DGT-MTL) for spatio-temporal traffic prediction. DGT-MTL features a dynamic adjacency matrix generation module that balances static stability with dynamic flexibility. Additionally, it employs a multi-scale graph learning module to effectively capture fine-grained, latent features. An adaptive multi-task learning module is incorporated to uncover hidden correlations and dynamic relationships between road segments. Experiments conducted across six standard benchmarks demonstrate DGT-MTL’s superior performance compared to contemporary approaches, achieving over 15 % improvements in both ROC-AUC and F1 score metrics. Further experiments demonstrate its effectiveness and robustness in handling complex traffic prediction.},
  archive      = {J_NN},
  author       = {Nana Bu and Zongtao Duan and Wen Dang and Jianxun Zhao},
  doi          = {10.1016/j.neunet.2025.107963},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107963},
  shortjournal = {Neural Netw.},
  title        = {Dynamic graph transformation with multi-task learning for enhanced spatio-temporal traffic prediction},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A spiking network model of the cerebellum for predicting movements with diverse complex spikes. <em>NN</em>, <em>193</em>, 107962. (<a href='https://doi.org/10.1016/j.neunet.2025.107962'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smooth and coordinated motor control is believed to be achieved through prediction by forward models in the cerebellum, which generate predicted movements from motor commands. These models are acquired via supervised learning, where instruction signals, originating from the inferior olive and represented as complex spikes (CSs) in Purkinje cells, guide learning. Previous studies show that CSs represent a wide variety of motor- and nonmotor-related activities, but how this diversity contributes to forward model acquisition remains unclear. We hypothesized that predicted movements are learned through the combination of various types of CSs. To test this, we developed a spiking network model of the cerebellum as a supervised learning machine, using instruction signals based on Ca 2+ imaging data from a self-initiated lever-pull task in mice. While individual signals did not fully represent lever movements, the combination of Purkinje cell activities, trained by different instruction signals, allowed neurons in the cerebellar nucleus to represent lever trajectory. Additionally, the same set of instruction signals trained the model to generate different movement trajectories. We further confirmed that a mouse musculoskeletal model successfully reproduced lever-pulling movements. These findings suggest that forward models in the cerebellum are achieved through a combination of diverse CSs with different spatiotemporal profiles, providing an over-complete basis for movement prediction.},
  archive      = {J_NN},
  author       = {Tomohiro Mitsuhashi and Yusuke Kuniyoshi and Koji Ikezoe and Kazuo Kitamura and Tadashi Yamazaki},
  doi          = {10.1016/j.neunet.2025.107962},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107962},
  shortjournal = {Neural Netw.},
  title        = {A spiking network model of the cerebellum for predicting movements with diverse complex spikes},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Counting with ease: Class-agnostic counting via one-shot detection across diverse domains. <em>NN</em>, <em>193</em>, 107961. (<a href='https://doi.org/10.1016/j.neunet.2025.107961'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class-agnostic counting is increasingly prevalent in industrial and agricultural applications. However, most deployable methods rely on density maps, which (1) struggle with background interference in complex scenes, and (2) fail to provide precise object locations, limiting downstream usability. The advancement of class-agnostic counting is hindered by suboptimal model designs and the lack of datasets with bounding box annotations. While some studies explore text-guided methods using multimodal models, they remain impractical for edge deployment and are beyond our study’s scope. To address these limitations, we diverge from traditional counting paradigms and propose a novel Class-Agnostic Counting and Localization (CACAL) framework, which performs accurate object counting and localization using a single query image-streamlining the process for real-world use. First, we introduce a Sampling-Aware Feature Enhancement module to improve feature discriminability and mitigate confusion in shared-encoder settings. Second, we design a Split-and-Assemble Feature Matching strategy to produce structurally-aware similarity maps, boosting performance in cluttered and occluded scenarios. To further advance the field, we introduce the LOCO dataset, a large-scale benchmark with both point and bounding box annotations across industrial, agricultural, and daily-life domains. CACAL consistently outperforms existing methods across multiple benchmarks and demonstrates strong generalization across diverse domains. Our dataset will be released at: https://github.com/imMid-Star/CACAL.},
  archive      = {J_NN},
  author       = {Zhongxing Peng and Bohui Guo and Shugong Xu},
  doi          = {10.1016/j.neunet.2025.107961},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107961},
  shortjournal = {Neural Netw.},
  title        = {Counting with ease: Class-agnostic counting via one-shot detection across diverse domains},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Focusing on pedestrians like human for clothes changing person re-identification. <em>NN</em>, <em>193</em>, 107960. (<a href='https://doi.org/10.1016/j.neunet.2025.107960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current approaches focus mainly on the design of networks to learn key identity features from local body components for clothes-changing person re-identification (CC-ReID). In this paper, we propose a humanoid focus-inspired image augmentation (HFIA) method, which is intuitive image processing rather than a sophisticated network architecture designed to enhance local nuances of pedestrian images. Based on pedestrian silhouettes, we roughly divide a pedestrian image into five body components, that is, head-shoulder, upper left torso, upper right torso, lower left torso, and lower right torso. The HFIA has two key designs to deal with these components: the central emphasis strategy (CES) and the component continuity processing (CCP). For each component, leveraging the natural tendency of human visual attention towards central regions, the CES constructs an enlargement grid, where the closer the center, the greater the enlargement. To maintain the continuity of assembly, the CCP performs an overall alignment of component centers, that is, all components share the same normalized vertical coordinate and the left and right torsos have mirrored horizontal coordinates. Furthermore, the CCP implements a smoothing post-processing to uniformly erase the discontinuity between the head-shoulder, upper left torso, and upper right torso. Experiments show the state-of-the-art performance of HFIA.},
  archive      = {J_NN},
  author       = {Wenjie Pan and Jianqing Zhu and Xiaolin Cui and Huanqiang Zeng and Yibing Zhan},
  doi          = {10.1016/j.neunet.2025.107960},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107960},
  shortjournal = {Neural Netw.},
  title        = {Focusing on pedestrians like human for clothes changing person re-identification},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Concept-enhanced heterogeneous graph network for fact verification. <em>NN</em>, <em>193</em>, 107959. (<a href='https://doi.org/10.1016/j.neunet.2025.107959'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fact verification is extremely challenging in natural language processing tasks, requiring the retrieval of multiple evidence sentences from trustworthy corpora to ascertain the accuracy of a given claim. Although the current methods have achieved satisfactory performance, many of them ignore multi-granularity information or fail to fully leverage multi-granularity information, and lack inherent concept information. To tackle the issues, we propose the Concept-Enhanced Heterogeneous Graph Network (Concept-HGN) for fact verification. First, our Concept-HGN model constructs a heterogeneous graph to aggregate clues from the scattered text across multiple evidence sentences. By building different heterogeneous nodes into an integral unified graph, this hierarchical node granularity enables Concept-HGN to be more effectively applied to fact verification tasks. Then, Concept-HGN leverages the intrinsic concepts of entities from YAGO, guiding fact verification and boosting the fact verification performance. We conducted performance evaluation experiments on the FEVER and UKP Snopes datasets. On the FEVER dataset, our proposed Concept-HGN model achieved 80.26 % and 77.68 % on LA and FS, respectively. On the UKP Snopes dataset, the accuracy and macro F1 also reached 65.7 % and 61.9 %, respectively. The experimental results on these datasets indicate that the Concept-HGN model proposed in this paper outperforms the baseline models and achieves state-of-the-art performance on the task of fact verification.},
  archive      = {J_NN},
  author       = {Zhendong Chen and Lejian Liao and Siu Cheung Hui and Heyan Huang},
  doi          = {10.1016/j.neunet.2025.107959},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107959},
  shortjournal = {Neural Netw.},
  title        = {Concept-enhanced heterogeneous graph network for fact verification},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). C3aptioner: Improving change captioning by leveraging momentum cross-view and cross-modality contrastive learning. <em>NN</em>, <em>193</em>, 107957. (<a href='https://doi.org/10.1016/j.neunet.2025.107957'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary goal of change captioning is to identify subtle visual differences between two similar images and express them in natural language. Existing research has been significantly influenced by the task of vision change detection and has mainly concentrated on the identification and description of visual changes. However, we contend that an effective change captioner should go beyond mere detection and description of what has changed. Two additional aspects are crucial: 1) retaining significant and unique semantic elements that persist across both images, and 2) forging a robust link between visual cues and their concomitant descriptive linguistic elements. This paper addresses these challenges by presenting the C 3 aptioner, which seamlessly incorporates dual momentum contrastive learning objectives into change captioning. Our model architecture consists of intra-image and inter-image Transformer encoders for visual feature extraction, complemented by unimodal language and multimodal decoders. Specifically, we introduce a cross-view contrastive learning objective to capture essential invariant features by aligning cross-view representations with a momentum-updated queue of negative samples, addressing the challenge of viewpoint variations. Additionally, our cross-modality contrastive learning objective aligns and interacts visual and textual modalities using a separate momentum-maintained queue, resolving the modality gap that hampers existing methods. This dual contrastive approach enables C 3 aptioner to model both changed and unchanged elements while establishing strong vision-language correspondence, resulting in more contextually rich and human-like descriptions. Extensive experiments across five distinct datasets confirm that our approach achieves state-of-the-art performance, with particularly significant improvements in challenging scenarios involving extreme viewpoint changes. Source code is available at https://github.com/DenglinGo/C-3aptioner .},
  archive      = {J_NN},
  author       = {Lin Deng and Borui Kang and Yuzhong Zhong and Maoning Wang and Jianwei Zhang},
  doi          = {10.1016/j.neunet.2025.107957},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107957},
  shortjournal = {Neural Netw.},
  title        = {C3aptioner: Improving change captioning by leveraging momentum cross-view and cross-modality contrastive learning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CausalCOMRL: Context-based offline meta-reinforcement learning with causal representation. <em>NN</em>, <em>193</em>, 107955. (<a href='https://doi.org/10.1016/j.neunet.2025.107955'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context-based offline meta-reinforcement learning (OMRL) methods have achieved appealing success by leveragingpre-collected offline datasets to develop task representations that guide policy learning. However, current context-based OMRL methods often introduce spurious correlations, where task components are incorrectly correlated due to confounders. These correlations can degrade policy performance when the confounders in the test taskdiffer from those in the training task. To address this problem, we propose CausalCOMRL, a context-based OMRL method that integrates causal representation learning. This approach uncovers causal relationships among the task components and incorporates the causal relationships into task representations, enhancing the generalizability of RL agents. We further improve the distinction of task representations from different tasks by using mutual information optimization and contrastive learning. Utilizing these causal task representations, we employSAC to optimize policies on meta-RL benchmarks. Experimental results show that CausalCOMRL achieves better performance than other methods on most benchmarks.},
  archive      = {J_NN},
  author       = {Zhengzhe Zhang and Wenjia Meng and Haoliang Sun and Gang Pan},
  doi          = {10.1016/j.neunet.2025.107955},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107955},
  shortjournal = {Neural Netw.},
  title        = {CausalCOMRL: Context-based offline meta-reinforcement learning with causal representation},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Structure-preserving contrastive graph clustering with dual-channel label alignment. <em>NN</em>, <em>193</em>, 107954. (<a href='https://doi.org/10.1016/j.neunet.2025.107954'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past few years have witnessed the rapid development of contrastive graph clustering (CGC). Although a series of achievements have been made, there still remain two challenging problems in the literature. First, previous works typically generate different views via some pre-defined graph augmentation strategies, but inappropriate augmentations may alter the latent semantics of the original data. Second, they often overlook the discriminative unsupervised information when constructing positive and negative sample pairs, resulting in compromised clustering performance. Third, some of them are restricted to only static neighborhood connections for contrastive learning, which neglect the dynamical structural relationship via robust neighboring graph learning. To cope with these issues, this paper proposes a Structure-preserving Contrastive Graph Clustering approach with Dual-channel Label Alignment (SCGC-DLA). In terms of the high-and-low frequency issues, the low-pass and hybrid graph filters are designed for generating two views of reliable augmentations, which can supply rich and complementary information to each other. Further, we construct a structure-preserving matrix, which is derived from the edge betweenness centrality (EBC) perspective design and allows us to efficiently capture the topological relationships among different embedding representations. Under the guidance of the non-dominated sorting theory, the clustering distribution information of dual-channel is used to construct high-confidence pseudo labels. Especially, the generated high-confidence pseudo labels are aligned with latent semantic labels. Finally, the overall network is guided by a self-supervised learning scheme and therefore the final clustering could be obtained. Substantial results on five benchmarks prove the robustness and effectiveness of our approach compared to several state-of-the-arts.},
  archive      = {J_NN},
  author       = {Guang-Yu Zhang and Yan-Di Huang and Dong Huang and Chang-Dong Wang and Yang Liu and Enbo Huang},
  doi          = {10.1016/j.neunet.2025.107954},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107954},
  shortjournal = {Neural Netw.},
  title        = {Structure-preserving contrastive graph clustering with dual-channel label alignment},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). C3GAN: A brain-inspired memory consolidation for class-incremental learning. <em>NN</em>, <em>193</em>, 107952. (<a href='https://doi.org/10.1016/j.neunet.2025.107952'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human cognition excels in lifelong learning, seamlessly acquiring, retaining, and transferring knowledge. In contrast, deep neural networks suffer from catastrophic forgetting, where training on new tasks rapidly erases previously acquired knowledge. In the human brain, memory reactivation is crucial for preserving memories over time. Similarly, generative replay in artificial neural networks shows potential for addressing forgetting by reactivating learned representations. However, existing generative replay techniques struggle with complex tasks and high-dimensional data, as they shift the burden from the task-solving network to the generative network, which is also prone to catastrophic forgetting. In this paper, we propose C3GAN , a brain-inspired model that combines C ontrastive C lustering and C onditional G enerative A dversarial N etworks to emulate the memory consolidation processes of the brain. C3GAN uses contrastive class structuring to consolidate recent memories, mimicking hippocampal functions, and incorporates a conditional generative adversarial network to facilitate long-term knowledge storage, akin to the prefrontal cortex. Additionally, an amygdala-inspired module enhances selective replay of indistinguishable classes by prioritizing memory that is emotionally salient, similar to the amygdala’s role in strengthening the retention of significant experiences. C3GAN achieves state-of-the-art performance on class-incremental learning benchmarks without raw data, providing a novel solution for lifelong memory retention in artificial systems.},
  archive      = {J_NN},
  author       = {Lin Xiong and Tao Wang and Fuqing Zhang and Kangwen Zhu and Hailing Xiong},
  doi          = {10.1016/j.neunet.2025.107952},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107952},
  shortjournal = {Neural Netw.},
  title        = {C3GAN: A brain-inspired memory consolidation for class-incremental learning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Knowledge-distillation based personalized federated learning with distribution constraints. <em>NN</em>, <em>193</em>, 107951. (<a href='https://doi.org/10.1016/j.neunet.2025.107951'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized federated learning PFL seeks to develop models that are tailored to the unique data distributions of individual clients. While some methods rely on a global server model to guide personalization, more recent methods focus on directly learn personalized models. Among these, leveraging inter-client correlations has become a widely adopted strategy for personalized model generation. PFedGraph exemplifies this by constructing client relationships based on model similarity for personalized model aggregation, achieving outstanding personalized performance. However, pFedgraph overlooks category distribution information, a critical aspect reflecting data distribution heterogeneity, although it has been extensively applied in machine learning and federated learning tasks. Category distribution can serve as a direct and informative metric for measuring inter-client data divergence. Furthermore, pFedGraph underutilizes global knowledge derived from diverse client datasets, limiting its personalized ability. To address these limitations, we incorporate category distribution constraints into the computation of client-specific aggregation weights, enabling the generation of personalized models enriched with distribution-aware information. Additionally, to mitigate the risk of overfitting to local data and enhance the use of global knowledge, we align the outputs of personalized models with those of the global model, which is obtained through the classical federated averaging algorithm, to effectively transfer shared global knowledge to personalized models. The proposed method consistently outperforms state-of-the-art approaches across diverse data types and distribution scenarios, demonstrating its effectiveness.},
  archive      = {J_NN},
  author       = {Ziyang Zhang and Chang Mu and Kailing Guo and Xiang Tian and Xiangmin Xu},
  doi          = {10.1016/j.neunet.2025.107951},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107951},
  shortjournal = {Neural Netw.},
  title        = {Knowledge-distillation based personalized federated learning with distribution constraints},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing robustness of spiking neural networks through retina-like coding and memory-based neurons. <em>NN</em>, <em>193</em>, 107950. (<a href='https://doi.org/10.1016/j.neunet.2025.107950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) are emerging as a promising alternative to traditional artificial neural networks (ANNs), offering advantages such as lower power consumption and biological interpretability. Despite recent progress in training SNNs and their performance in computer vision tasks, there remains a question of SNN robustness to corrupted images in real-world scenarios. To address this problem, we introduce CIFAR10-C and IMAGENET-C datasets from the ANN field as benchmarks and further propose novel methods to improve SNN corruption robustness. Specifically, we propose a retina-like coding to simulate dynamic human visual perception, providing a foundation for extracting robust features through varied temporal input. Meanwhile, we introduce a memory-based spiking neuron (MSN) that integrates memory units to learn robust features, along with a parallel version (MPSN) to facilitate parallel computing and achieve superior performance. Experimental results demonstrate that our method improves SNN recognition accuracy and robustness, achieving average accuracies of 87.04 % on the CIFAR10-C dataset and 40.37 the IMAGENET-C dataset, surpassing the state-of-the-art SNN method’s 85.95 % and 39.11 %, respectively. These findings highlight the potential of our approach to enhance the robustness of SNNs in real-world scenarios. Our codes will be released in https://github.com/JiaHongZ/Retina-MPSN .},
  archive      = {J_NN},
  author       = {Jiahong Zhang and Kexin Wang and Man Yao and Han Xu and Peng Zhou and Bo Xu and Guoqi Li},
  doi          = {10.1016/j.neunet.2025.107950},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107950},
  shortjournal = {Neural Netw.},
  title        = {Enhancing robustness of spiking neural networks through retina-like coding and memory-based neurons},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). G-NeuroDAVIS: A generative model for data visualization through a generalized embedding. <em>NN</em>, <em>193</em>, 107948. (<a href='https://doi.org/10.1016/j.neunet.2025.107948'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visualizing high-dimensional datasets through a generalized embedding has been a longstanding challenge. Several methods have been proposed for this purpose, but they have yet to generate a generalized embedding that not only reveals the hidden patterns present in the data but also generates realistic high-dimensional samples from it. Motivated by this aspect, in this article, a novel generative model called G-NeuroDAVIS has been developed, which is capable of visualizing high-dimensional data through a generalized embedding and thereby generating new samples. The model leverages advanced generative techniques to produce high-quality embedding that captures the underlying structure of the data more effectively compared with the existing methods. G-NeuroDAVIS can be trained in both supervised and unsupervised settings. We have rigorously evaluated our model through a series of experiments, demonstrating superior performance in several downstream tasks, which highlights the effectiveness of the learned representations. Results of an interpolation experiment reflect a smooth and meaningful transition in the generated images across various paths, which in turn depict preservation of underlying data structure. Furthermore, the conditional sample generation capability of the model has been described through both qualitative and quantitative assessments, revealing a marked improvement in generating realistic and diverse samples. G-NeuroDAVIS has outperformed Variational Autoencoder (VAE) significantly in terms of embedding quality and downstream tasks like classification. Moreover, the superior sample generation capability of G-NeuroDAVIS has been demonstrated against VAE, Deep Convolutional Generative Adversarial Network (DCGAN), Denoising Diffusion Probabilistic Models (DDPM), and Autoencoder (AE)-guided Real-valued Non-Volume Preserving (RealNVP). These results highlight the efficacy of G-NeuroDAVIS to serve as a robust tool in various applications that demand high-quality data generation and representation learning.},
  archive      = {J_NN},
  author       = {Chayan Maitra and Rajat K. De},
  doi          = {10.1016/j.neunet.2025.107948},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107948},
  shortjournal = {Neural Netw.},
  title        = {G-NeuroDAVIS: A generative model for data visualization through a generalized embedding},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic reinforcement learning for actors. <em>NN</em>, <em>193</em>, 107895. (<a href='https://doi.org/10.1016/j.neunet.2025.107895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In reinforcement learning (RL), as well as in generative AI, stochastic selection is insufficient for achieving human-like flexible balancing between irregularity and rationality (or exploration and exploitation ), even with a temperature parameter. Dynamic RL, proposed in this paper, brings about a major qualitative shift in RL, including exploration , from static to dynamic. It learns chaotic system dynamics that generate actions inherently containing deterministic, state-dependent exploration. Dynamic RL learns the global dynamics using a local index called sensitivity , which measures how much the input neighborhood contracts or expands into the corresponding output neighborhood through each neuron’s processing. While Sensitivity Adjustment Learning (SAL) prevents excessive convergence of the dynamics, Sensitivity-controlled Reinforcement Learning (SRL) modulates them — to converge more to improve reproducibility around better state transitions with positive TD error, and to diverge more to enhance exploration around worse transitions with negative TD error. Here, Dynamic RL is applied only to the actor in an Actor-Critic framework. It was tested on two dynamic tasks, functioning effectively without external exploration noise or backward computation through time. Dynamic RL demonstrated excellent adaptability to unfamiliar situations with chaotic dynamics flexibly controlled, although some issues remain. Drawing parallels and contrasts between exploration and thinking , it is hypothesized that exploration grows into thinking through learning but autonomously resumes in ongoing adverse situations. A mechanism to achieve this process using Dynamic RL is also suggested. Finally, despite being presumptuous, the author urges researchers to stop advancing this research due to its potentially fatal risks , aiming to encourage discussion.},
  archive      = {J_NN},
  author       = {Katsunari Shibata},
  doi          = {10.1016/j.neunet.2025.107895},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107895},
  shortjournal = {Neural Netw.},
  title        = {Dynamic reinforcement learning for actors},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A new local time-decoupled squared wasserstein-2 method for training stochastic neural networks to reconstruct uncertain parameters in dynamical systems. <em>NN</em>, <em>193</em>, 107893. (<a href='https://doi.org/10.1016/j.neunet.2025.107893'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose and analyze a new local time-decoupled squared Wasserstein-2 method for reconstructing the distribution of unknown parameters in dynamical systems from a finite number of observed temporal trajectories. Specifically, we show that a stochastic neural network model, which can be effectively trained by minimizing our proposed local time-decoupled squared Wasserstein-2 loss function, is an effective model for approximating the distribution of uncertain model parameters in dynamical systems. Through several numerical examples, we showcase the effectiveness of our proposed method in reconstructing the distribution of parameters in different dynamical systems.},
  archive      = {J_NN},
  author       = {Mingtao Xia and Qijing Shen and Philip K. Maini and Eamonn A. Gaffney and Alex Mogilner},
  doi          = {10.1016/j.neunet.2025.107893},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107893},
  shortjournal = {Neural Netw.},
  title        = {A new local time-decoupled squared wasserstein-2 method for training stochastic neural networks to reconstruct uncertain parameters in dynamical systems},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
