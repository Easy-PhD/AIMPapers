<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NN</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="nn">NN - 152</h2>
<ul>
<li><details>
<summary>
(2026). AAC-GS: Attention-aware adaptive codebook for gaussian splatting compression. <em>NN</em>, <em>194</em>, 108134. (<a href='https://doi.org/10.1016/j.neunet.2025.108134'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Radiance Fields (NeRF) have demonstrated remarkable performance in the field of novel view synthesis (NVS). However, their high computational cost limits practical applicability. The 3D Gaussian Splatting (3DGS) method offers a significant improvement in rendering efficiency, enabling real-time rendering through its explicit representations. Nevertheless, its substantial storage requirements pose challenges for complex scenes and resource-constrained devices. Existing methods aim to achieve storage compression through redundant point pruning, spherical harmonics adjustment, and vector quantization. However, point pruning methods often compromise geometric details in complex structures, while vector quantization approaches fail to capture feature relationships effectively, resulting in texture degradation and geometric boundary blurring. Although anchor point representations partially address storage concerns, their sparse representation limits compression efficiency. These limitations become particularly evident in scenes with intricate textures and complex lighting conditions. To ensure optimal compression ratios while maintaining high fidelity in Gaussian scenarios, this paper proposes an Attention-Aware Adaptive Codebook Gaussian Splatting (AAC-GS) method for efficient storage compression. The approach dynamically adjusts the size of the codebook to optimize storage efficiency and incorporates an attention mechanism to capture feature contextual relationships, thereby enhancing reconstruction quality. Additionally, a Generative Adversarial Network (GAN) is employed to mitigate quantization losses, achieving a balance between compression rate and visual fidelity. Experimental results demonstrate that AAC-GS achieves an average compression ratio of approximately 40× while maintaining high reconstruction quality, showcasing its potential for multi-scene applications.},
  archive      = {J_NN},
  author       = {Fang Wan and Jianhang Zhang and Tianyu Li and Guangbo Lei and Li Xu and Zhiwei Ye},
  doi          = {10.1016/j.neunet.2025.108134},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108134},
  shortjournal = {Neural Netw.},
  title        = {AAC-GS: Attention-aware adaptive codebook for gaussian splatting compression},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fixed-time learning-based optimal tracking control for robotic systems with prescribed performance constraints. <em>NN</em>, <em>194</em>, 108130. (<a href='https://doi.org/10.1016/j.neunet.2025.108130'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a fixed-time learning-based dynamic event-triggered control framework to address the optimal tracking control problem in robotic systems with the prescribed performance constraints. In many practical scenarios, the states of robotic systems are often subject to performance constraints imposed by structural characteristics and task requirements. To address this issue, prescribed performance control (PPC) theory is employed to ensure performance state constraints and construct an unconstrained tracking error system. Subsequently, a critic-only adaptive dynamic programming (ADP) control framework is designed to approximate the optimal control law for the transformed unconstrained system. Furthermore, in the design of critic neural network (NN), a novel fixed-time convergence (FTC) weight update law based on concurrent learning (CL) techniques is proposed, which guarantees the fixed-time convergence of weight estimation error under relaxed persistent excitation (PE) condition. Throughout the controller design, a dynamic event-triggered mechanism is adopted to reduce the number of sampling instances and computational resources. Meanwhile, the stability of the closed-loop system under this mechanism is rigorously proven. Finally, the effectiveness of the proposed method is demonstrated through simulation results and comparative analysis.},
  archive      = {J_NN},
  author       = {Zhinan Peng and Xingyu Zhang and Zhuo Xia and Lin Hao and Linpu He and Hong Cheng},
  doi          = {10.1016/j.neunet.2025.108130},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108130},
  shortjournal = {Neural Netw.},
  title        = {Fixed-time learning-based optimal tracking control for robotic systems with prescribed performance constraints},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MDSFD-net: Alzheimer’s disease diagnosis with missing modality via disentanglement learning and feature distillation. <em>NN</em>, <em>194</em>, 108128. (<a href='https://doi.org/10.1016/j.neunet.2025.108128'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal analysis can provide complementary information and significantly aid in the early diagnosis and intervention of Alzheimer’s Disease (AD). However, the issue of missing modalities presents a major challenge, as most methods that rely on complete multi-modal data become infeasible. The most advanced approaches to addressing missing modalities typically use generative models, but these often neglect the importance of modality-specific features, leading to biased predictions and poor performance. Inspired by this limitation, we propose a Modality Disentanglement and Specific Features Distillation Network (MDSFD-Net) for AD diagnosis with missing modality, which consists of a disentanglement-based imputation module (DI module) and a specific features distillation module (SFD module). In the DI module, we introduce a novel spatial-channel modality disentanglement learning scheme that is first used to disentangle modality-specific features, along with a shared constrain objective to learn modality-shared features, which are used for imputing missing modality features. To address the specific features of the missing modality, the SFD module is designed to transfer the specific features from complete modality in the teacher network to the incomplete modality in the student network. A regularized knowledge distillation (R-KD) mechanism is incorporated to mitigate the impact of incorrect predictions from the teacher network. By leveraging modality-shared features imputation and modality-specific features distillation, our model can effectively learn sufficient information for classification even if some modalities are missing. Extensive experiments on ADNI dataset demonstrate the superiority of our proposed MDSFD-Net over state-of-the-art methods in missing modality situations.},
  archive      = {J_NN},
  author       = {Nana Jia and Zhiao Zhang and Tong Jia},
  doi          = {10.1016/j.neunet.2025.108128},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108128},
  shortjournal = {Neural Netw.},
  title        = {MDSFD-net: Alzheimer’s disease diagnosis with missing modality via disentanglement learning and feature distillation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spiking neural networks for EEG signal analysis: From theory to practice. <em>NN</em>, <em>194</em>, 108127. (<a href='https://doi.org/10.1016/j.neunet.2025.108127'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intricate and efficient information processing of the human brain, driven by spiking neural interactions, has led to the development of spiking neural networks (SNNs) as a cutting-edge neural network paradigm. Unlike traditional artificial neural networks (ANNs) that use continuous values, SNNs emulate the brain’s spiking mechanisms, offering enhanced temporal information processing and computational efficiency. This review addresses the critical gap between theoretical advancements and practical applications of SNNs in EEG signal analysis. We provide a comprehensive examination of recent SNN methodologies and their application to EEG signals, highlighting their potential benefits over conventional deep learning approaches. The review encompasses foundational knowledge of SNNs, detailed implementation strategies for EEG analysis, and challenges inherent to SNN-based methods. Practical guidance is provided through step-by-step instructions and accessible code available on GitHub, aimed at facilitating researchers’ adoption of these techniques. Additionally, we explore emerging trends and future research directions, emphasizing the potential of SNNs to advance brain-computer interfaces and neurofeedback systems. This paper serves as a valuable resource for bridging the gap between theoretical developments in SNNs and their practical implementation in EEG signal analysis.},
  archive      = {J_NN},
  author       = {Siqi Cai and Zheyuan Lin and Xiaoli Liu and Wenjie Wei and Shuai Wang and Malu Zhang and Tanja Schultz and Haizhou Li},
  doi          = {10.1016/j.neunet.2025.108127},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108127},
  shortjournal = {Neural Netw.},
  title        = {Spiking neural networks for EEG signal analysis: From theory to practice},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TGSL: Trade-off graph structure learning via multifaceted graph information bottleneck. <em>NN</em>, <em>194</em>, 108125. (<a href='https://doi.org/10.1016/j.neunet.2025.108125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are prominent for their effectiveness in processing graph-structured data for semi-supervised node classification tasks. Most existing GNNs perform message passing directly based on the observed graph structure. However, in real-world scenarios, the observed structure is often suboptimal due to multiple factors, significantly degrading the performance of GNNs. To address this challenge, we first conduct an empirical analysis showing that different graph structures significantly impact empirical risk and classification performance. Motivated by our observations, we propose a novel method named T rade-off G raph S tructure L earning (TGSL), guided by the multifaceted Graph Information Bottleneck (GIB) principle based on Mutual Information (MI). The key idea behind TGSL is to learn a minimal sufficient graph structure that minimizes empirical risk while maintaining performance. Specifically, we introduce global feature augmentation to capture the structural roles of nodes, and global structure augmentation to uncover global relationships between nodes. The augmented graphs are then processed by structure estimators with different parameters for refinement and redefinition, respectively. Additionally, we innovatively leverage multifaceted GIB as the optimization objective by maximizing the MI between the labels and the representation derived from the final structure, while constraining the MI between this representation and that based on the redefined structures. This trade-off helps avoid capturing irrelevant information from the redefined structures and enhances the final representation for node classification. We conduct extensive experiments across a range of datasets under clean and attacked conditions. The results demonstrate the outstanding performance and robustness of TGSL over state-of-the-art baselines.},
  archive      = {J_NN},
  author       = {Shuangjie Li and Baoming Zhang and Jianqing Song and Gaoli Ruan and Chongjun Wang and Junyuan Xie},
  doi          = {10.1016/j.neunet.2025.108125},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108125},
  shortjournal = {Neural Netw.},
  title        = {TGSL: Trade-off graph structure learning via multifaceted graph information bottleneck},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improving few-shot relation classification with multi-scale hierarchical prototype learning. <em>NN</em>, <em>194</em>, 108124. (<a href='https://doi.org/10.1016/j.neunet.2025.108124'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot relation classification aims to distinguish different relation classes from extremely limited annotated data. Most existing methods primarily use prototype networks to construct a prototypical representation, classifying the instance by comparing its similarity to each prototype. Despite achieving promising results, the prototypes derived solely from limited support instances are often inaccurate due to constraints in feature extraction capabilities. Moreover, they ignore the different hierarchical levels of relational information, which can provide more effective guidance for classification. In this paper, we propose a novel m ulti-sc a le hie r arch i cal pr o totype (Mario) learning method that captures relational interaction information at three levels: inter-set, inter-class and intra-class, enhancing the model’s understanding of global semantic information and helping it distinguish subtle differences between classes. Additionally, we incorporate relational descriptive information to reduce the impact of textual expression diversity, enabling the model to emulate the human cognitive process in understanding variation. Extensive experiments conduct on the FewRel dataset demonstrate the effectiveness of our proposed model. In particular, it achieves accuracy rates of 92.52 %/95.33 %/85.46 %/91.33 % under four common few-shot settings. Notably, in the critical 5-way and 10-way 1-shot settings, it outperforms the strongest baseline by 2.87 % and 4.29 %.},
  archive      = {J_NN},
  author       = {Haijia Bi and Lu Liu and Hai Cui and Shengyue Liu and Ridong Han and Jiayu Han and Tao Peng},
  doi          = {10.1016/j.neunet.2025.108124},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108124},
  shortjournal = {Neural Netw.},
  title        = {Improving few-shot relation classification with multi-scale hierarchical prototype learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Planning forward: Deep incremental hashing by gradually defrosting bits. <em>NN</em>, <em>194</em>, 108123. (<a href='https://doi.org/10.1016/j.neunet.2025.108123'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep incremental hashing can generate hash codes incrementally for new classes, while keeping the existing ones unchanged. Existing methods typically allocate fixed code lengths to all classes, causing the entire Hamming space occupied by existing classes, thus failing to prepare models for future extensions. This significantly limits the ability to effectively accommodate new classes. Beyond that, it is inefficient in computation and storage to use all bits for encoding a few classes in the early sessions. This paper presents B it D efrosting Deep I ncremental H ashing (BDIH) to tackle these problems. Our key insight is to map the classes into a small subspace by freezing most hash bits during the first session, which reserves adequate space for future classes. This allows subsequent sessions to map new classes into progressively expanding subspaces by defrosting a portion of the frozen bits. Specifically, we propose a bit-defrosting code learning framework, which includes a bit-defrosting center generation part and a center-based bit-defrosting code learning part. The former part generates hash centers as learning objectives in expanding subspaces while the latter part learns globally discriminative hash codes with the guidance of hash centers and preserves the backward compatibility between the updated model and previously stored codes. As a result, our method achieves comparable performance on old classes using fewer bits while reserving more space for new ones. Extensive experiments demonstrate that BDIH outperforms existing methods regarding retrieval accuracy and storage efficiency in long-sequence incremental learning scenarios.},
  archive      = {J_NN},
  author       = {Qinghang Su and Dayan Wu and Chenming Wu and Bo Li and Weiping Wang},
  doi          = {10.1016/j.neunet.2025.108123},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108123},
  shortjournal = {Neural Netw.},
  title        = {Planning forward: Deep incremental hashing by gradually defrosting bits},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Offline-to-online reinforcement learning with efficient unconstrained fine-tuning. <em>NN</em>, <em>194</em>, 108120. (<a href='https://doi.org/10.1016/j.neunet.2025.108120'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline reinforcement learning provides the capability to learn a policy only from pre-collected datasets, but its performance is often limited by the quality of the offline dataset and the coverage of the state-action space. Offline-to-online reinforcement learning is promising to address these limitations and achieve high sample efficiency by integrating the advantages of both offline and online learning paradigms. However, existing methods typically struggle to adapt to online learning and improve the performance of pre-trained policies due to the distributional shift and conservative training. To address these issues, we propose an efficient unconstrained fine-tuning framework that removes conservative constraints on the policy during fine-tuning, allowing thorough exploration of state-action pairs not covered by the offline data. This framework leverages three key techniques: dynamics representation learning, layer normalization, and increasing the update frequency of the value network to improve sample efficiency and mitigate value function estimation bias caused by the distributional shift. Dynamics representation learning accelerates fine-tuning by capturing meaningful features, layer normalization bounds Q -value to suppress catastrophic value function divergence, and increasing the update frequency of the value network enhances the sample efficiency and reduces value function estimation bias. Extensive experiments on the D4RL benchmark demonstrate that our algorithm outperforms state-of-the-art offline-to-online reinforcement learning algorithms across various tasks with minimal online interactions.},
  archive      = {J_NN},
  author       = {Jun Zheng and Runda Jia and Shaoning Liu and Ranmeng Lin and Dakuo He and Fuli Wang},
  doi          = {10.1016/j.neunet.2025.108120},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108120},
  shortjournal = {Neural Netw.},
  title        = {Offline-to-online reinforcement learning with efficient unconstrained fine-tuning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AutoSGRL: Automated framework construction for self-supervised graph representation learning. <em>NN</em>, <em>194</em>, 108119. (<a href='https://doi.org/10.1016/j.neunet.2025.108119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated machine learning (AutoML) is a promising solution for building a machine learning framework without human assistance and has attracted significant attention throughout the computational intelligence research community. Although there has been an emerging interest in graph neural architecture search, current research focuses on the specific design of semi-supervised or supervised graph neural networks. Motivated by this, we propose a novel method that enables the automatic construction of flexible self-supervised graph representation learning frameworks for the first time as far as we know, referred to as AutoSGRL. Based on existing self-supervised graph contrastive learning methods, AutoSGRL establishes a framework search space for self-supervised graph representation learning, which encompasses data augmentation strategies and proxy tasks for constructing graph contrastive learning frameworks, and the hyperparameters required for model training. Then, we implement an automatic search engine based on genetic algorithms, which constructs multiple self-supervised graph representation learning frameworks as the initial population. By simulating the process of biological evolution including selection, crossover, and mutation, the search engine iteratively evolves the population to identify high-performed frameworks and optimal hyperparameters. Empirical studies demonstrate that our AutoSGRL achieves comparative or even better performance than state-of-the-art manual-designed self-supervised graph representation learning methods and semi-supervised graph neural architecture search methods.},
  archive      = {J_NN},
  author       = {Yu Xie and Yu Chang and Ming Li and A.K. Qin and Xialei Zhang},
  doi          = {10.1016/j.neunet.2025.108119},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108119},
  shortjournal = {Neural Netw.},
  title        = {AutoSGRL: Automated framework construction for self-supervised graph representation learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation. <em>NN</em>, <em>194</em>, 108118. (<a href='https://doi.org/10.1016/j.neunet.2025.108118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vascular morphology plays a crucial role in diagnosing diseases such as diabetes, glaucoma, and hypertension, making accurate segmentation of retinal vessels essential for early intervention. Traditional segmentation methods assume that training and testing data share similar distributions, which can lead to poor performance on unseen domains due to domain shifts caused by variations in imaging devices and patient demographics. This paper presents a novel approach, DGSSA, for retinal vessel image segmentation that enhances model generalization by combining structural and stylistic augmentation strategies. We utilize a space colonization algorithm to generate diverse vascular-like structures that closely mimic actual retinal vessels, which are then used to generate pseudo-retinal images with an improved Pix2Pix model, allowing the segmentation model to learn a broader range of structure distributions. Additionally, we utilize PixMix to apply random photometric augmentations and introduce uncertainty perturbations, enriching the stylistic diversity of fundus images and further improving the model’s robustness and generalization across varying imaging conditions. Our framework, which employs a DeepLabv3+ model with a MobileNetV2 backbone as its segmentation network, has been rigorously evaluated on four challenging datasets—DRIVE, CHASEDB1, HRF, and STARE—achieving Dice Similarity Coefficient (DSC) of 78.45%, 78.62%, 72.66% and 82.17%, respectively, with an average DSC of 77.98%. These results demonstrate that our method surpasses existing approaches, validating its effectiveness and highlighting its potential for clinical application in automated retinal vessel analysis.},
  archive      = {J_NN},
  author       = {Bo Liu and Yudong Zhang and Shuihua Wang and Siyue Li and Jin Hong},
  doi          = {10.1016/j.neunet.2025.108118},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108118},
  shortjournal = {Neural Netw.},
  title        = {DGSSA: Domain generalization with structural and stylistic augmentation for retinal vessel segmentation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LCA-med: A lightweight cross-modal adaptive feature processing module for detecting imbalanced medical image distribution. <em>NN</em>, <em>194</em>, 108116. (<a href='https://doi.org/10.1016/j.neunet.2025.108116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data distribution discrepancy across datasets is one of the major obstacles hindering the improvement of the accuracy of cross-domain adaptive detection of medical images. To address this challenge, we propose a novel lightweight cross-modal adaptive detection module named LCA-Med (LCaM). The proposed module boasts a lightweight structure and a minimalistic parameter count, thereby facilitating its integration into the anterior segment of a diverse array of foundational and downstream networks. It is adept at serving as a feature preprocessor, proficiently extracting pertinent information regrading pathologies from a array of images (image modality) produced through varied medical imaging techniques, all guided by the input of prompts (text modality). We also propose a novel cross-modal medical image adaptive detection method, LCA-Med CNX (LCaM-CNX), and a novel cross-domain adaptive detection training paradigm that incorporates generated dataset groups, an attention module, and a meta-heuristic algorithm. Experimental results on six medical image datasets compared with ten state-of-the-art methods demonstrate that the LCaM-CNX trained following the proposed paradigm achieves the best performance on five datasets and competitive performance on the other dataset. Notably, our method outperforms the state-of-the-art methods more when the data distribution is more imbalanced.},
  archive      = {J_NN},
  author       = {Xiang Li and Long Lan and Husam Lahza and Shaowu Yang and Shuihua Wang and Yong Liang and Hudan Pan and Wenjing Yang and Hengzhu Liu and Yudong Zhang},
  doi          = {10.1016/j.neunet.2025.108116},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108116},
  shortjournal = {Neural Netw.},
  title        = {LCA-med: A lightweight cross-modal adaptive feature processing module for detecting imbalanced medical image distribution},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Counterfactual causal inference for robust visual question answering. <em>NN</em>, <em>194</em>, 108115. (<a href='https://doi.org/10.1016/j.neunet.2025.108115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question Answering (VQA) systems have seen remarkable progress with the incorporation of multimodal data. However, their performance is still hampered by biases ingrained in language and vision modalities, frequently resulting in subpar generalization. In this study, we introduce a novel counterfactual causal framework (CC-VQA). This framework utilizes Counterfactual Sample Synthesis (CSS) and causal inference to tackle cross-modality biases. Our approach innovatively employs a strategy based on causal graphs, which effectively disentangles spurious correlations in multimodal data. This ensures a balanced and precise multimodal reasoning process, enabling the model to make more accurate and unbiased decisions. Moreover, we propose a contrastive loss mechanism. By contrasting the embeddings of positive and negative samples, this mechanism significantly enhances the robustness of VQA models. Additionally, we develop a robust training strategy that improves both the visual-explainable and question-sensitive capabilities of these models. Our experimental evaluations on benchmark datasets, such as VQA-CP v2 and VQA v2, demonstrate substantial improvements in bias mitigation and overall accuracy. The proposed CC-VQA framework outperforms state-of-the-art methods, highlighting its effectiveness in enhancing the performance of VQA systems.},
  archive      = {J_NN},
  author       = {Wei Li and Zhixin Li and Fuyun Deng and Kun Zeng and Canlong Zhang},
  doi          = {10.1016/j.neunet.2025.108115},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108115},
  shortjournal = {Neural Netw.},
  title        = {Counterfactual causal inference for robust visual question answering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Inference of hidden common driver dynamics by anisotropic self-organizing neural networks. <em>NN</em>, <em>194</em>, 108113. (<a href='https://doi.org/10.1016/j.neunet.2025.108113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the Anisotropic Self-Organizing Map (ASOM), a novel neural network-based approach for inferring hidden common drivers in nonlinear dynamical systems from observed time series. Grounded in topological theorems, our method integrates time-delay embedding, intrinsic dimension estimation, and a new anisotropic training scheme for Kohonen’s self-organizing map, enabling the precise decomposition of attractor manifolds into autonomous and shared components of the dynamics. We validated ASOM through simulations involving chaotic maps, where two driven systems were influenced by a hidden nonlinear driver. The inferred time series showed a strong correlation with the actual hidden common driver, unlike the observed systems. We further compared our reconstruction performance against several established methods for identifying shared features in time series, including PCA, kernel PCA, ICA, dynamical component analysis, canonical correlation analysis, deep canonical correlation analysis, traditional self-organizing map, and recent recurrence-based approaches. Our results demonstrate ASOM’s superior accuracy and robustness in recovering latent dynamics, providing a powerful tool for unsupervised learning of hidden causal structures in complex systems.},
  archive      = {J_NN},
  author       = {Zsigmond Benkő and Marcell Stippinger and Attila Bencze and Fülöp Bazsó and András Telcs and Zoltán Somogyvári},
  doi          = {10.1016/j.neunet.2025.108113},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108113},
  shortjournal = {Neural Netw.},
  title        = {Inference of hidden common driver dynamics by anisotropic self-organizing neural networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the theoretical expressive power of graph transformers for solving graph problems. <em>NN</em>, <em>194</em>, 108112. (<a href='https://doi.org/10.1016/j.neunet.2025.108112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Transformers have become the dominant neural architecture in the fields of natural language processing and computer vision. The generalization of Transformers to graphs, so-called Graph Transformers, have recently emerged as a promising alternative to the successful message passing Graph Neural Networks (MPNNs). While the expressive power of MPNNs has been intensively studied in the past years, that of Graph Transformers is still underexplored. Existing results mostly rely on the employed structural/positional encodings and not on the pure architecture itself. However, gaining an understanding of the strengths and limitations of Graph Transformers would be very useful both for the scientific community and the practitioners. In this paper, we derive a connection between Graph Transformers and the Congested clique , a popular model in distributed computing. This connection allows us to translate theoretical results for different graph problems from the latter to the former. We show that under certain conditions, Graph Transformers with depth 2 are Turing universal. We also show that there exist Graph Transformers that can solve problems which cannot be solved by MPNNs. We empirically investigate whether Graph Transformers and MPNNs with depth 2 can solve graph problems on some molecular datasets. Our results demonstrate that Graph Transformers can generally address the underlying tasks, while MPNNs are incapable of learning any information about the graph.},
  archive      = {J_NN},
  author       = {Giannis Nikolentzos and Dimitrios Kelesis and Michalis Vazirgiannis},
  doi          = {10.1016/j.neunet.2025.108112},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108112},
  shortjournal = {Neural Netw.},
  title        = {On the theoretical expressive power of graph transformers for solving graph problems},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MAN-GNN: An interpretable biomarker architecture for neurodevelopmental disorders. <em>NN</em>, <em>194</em>, 108110. (<a href='https://doi.org/10.1016/j.neunet.2025.108110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurodevelopmental disorders exhibit highly similar behavioral characteristics in clinical assessments, heavily relying on subjective behavioral reports, leading to insufficient understanding of the neurobiological mechanisms behind inter-patient heterogeneity and symptom overlap between diseases. To address this issue, this study proposes a graph neural network framework that integrates neuroimaging data, focusing on three key problems: Firstly, enhance the nonlinear features in brain neural activity by introducing the Neurodynamics Rössler system. Transform raw static neural signals into simulated signals with nonlinear, temporal, and dynamic features, thereby more accurately reflecting the process of brain neural activity. Secondly, improve feature discrimination by integrating the spatial adjacency characteristics of local brain regions with the topological structure information of the global brain network to highlight key features. Thirdly, improve noise resistance and generalization ability. Introducing adaptive controllers and cross-site adversarial learning mechanisms, the interference of heterogeneous noise is effectively reduced. This study conducted experimental validation on data from neurodevelopmental disorders such as ADHD and ASD. The results indicate that this framework not only has advantages in classification accuracy but also possesses good interpretability, making it a promising tool for imaging biomarker research and auxiliary diagnosis.},
  archive      = {J_NN},
  author       = {Qiulei Han and Hongbiao Ye and Miaoshui Bai and Lili Wang and Yan Sun and Ze Song and Jian Zhao and Lijuan Shi and Zhejun Kuang},
  doi          = {10.1016/j.neunet.2025.108110},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108110},
  shortjournal = {Neural Netw.},
  title        = {MAN-GNN: An interpretable biomarker architecture for neurodevelopmental disorders},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). State-flipped control design for the stabilization of probabilistic boolean control networks. <em>NN</em>, <em>194</em>, 108109. (<a href='https://doi.org/10.1016/j.neunet.2025.108109'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stabilization is a fundamental issue in modern control theory. In the past decades, significant efforts have been invested in deriving necessary and sufficient conditions for verifying the global stabilization of probabilistic Boolean control networks (PBCNs). However, systematic methods and general criteria for exploring the local stabilization and determining the domain of attraction of PBCNs are still lacking in the existing literature. Motivated by this research gap, this paper investigates the local state feedback stabilization of PBCNs, including local finite-time state feedback stabilization with probability one (FTSFS) and local state feedback stabilization in distribution (SFSD). Firstly, a sequence of reachable sets with probability one is constructed, based on which, the largest domain of attraction is derived for the FTSFS of PBCNs by designing the state feedback controllers. Secondly, by constructing a sequence of reachable sets with positive probability, the largest domain of attraction is determined for the SFSD of PBCNs. Finally, when the largest domain of attraction is not the whole state space, the state-flipped control is designed to achieve the global FTSFS or SFSD of PBCNs via the largest domain of attraction.},
  archive      = {J_NN},
  author       = {Xinrong Yang and Haitao Li},
  doi          = {10.1016/j.neunet.2025.108109},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108109},
  shortjournal = {Neural Netw.},
  title        = {State-flipped control design for the stabilization of probabilistic boolean control networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stability of large-scale probabilistic boolean networks via network aggregation. <em>NN</em>, <em>194</em>, 108108. (<a href='https://doi.org/10.1016/j.neunet.2025.108108'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale probabilistic Boolean networks (LSPBNs) are a modeling tool used to simulate and analyze the dynamics of complex systems with uncertainty. However, due to its high computational complexity, previous research methods cannot be directly applied to study such systems. Inspired by network aggregation, this paper conducts network aggregation on LSPBNs to investigate its global stability with probability 1. It is worth mentioning that the stability conclusion proposed in this article holds for any form of network aggregation. First, the entire network is partitioned and the algebraic expressions for each subnetwork are given through the semi-tensor product of matrices. And then, a set of iterative formulas is constructed to describe and reflect the input-output coordination relationship among the subnetworks, and based on which, a sufficient condition for the global stability of LSPBNs is derived, greatly reducing computational complexity. The feasibilities of the proposed method and results are verified through examples.},
  archive      = {J_NN},
  author       = {Wen Liu and Shihua Fu and Jianjun Wang and Renato De Leone and Jianwei Xia},
  doi          = {10.1016/j.neunet.2025.108108},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108108},
  shortjournal = {Neural Netw.},
  title        = {Stability of large-scale probabilistic boolean networks via network aggregation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SPC: Self-supervised point cloud completion. <em>NN</em>, <em>194</em>, 108107. (<a href='https://doi.org/10.1016/j.neunet.2025.108107'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape incompleteness is a common issue in point clouds acquired by depth sensors. Point cloud completion aims to restore partial point clouds to their complete form. However, most existing point cloud completion methods rely on complete point clouds or multi-view information of the same object during training, which is not practical for real-world scenarios with high information acquisition costs. To overcome the above limitation, a self-supervised point cloud completion (SPC) method is proposed, which uses the training set consisting of only a single partial point cloud for each object. Specifically, an autoencoder-like network architecture that includes a two-step strategy is developed. First, a compression-reconstruction strategy is proposed to enable the network to learn the representation of complete point clouds from existing knowledge. Then, considering the potential problem of overfitting in self-supervised training, a global enhancement strategy is further designed to maintain the positional coherence of predicted points. Comprehensive experiments are conducted on the ScanNet, MatterPort3D, KITTI, and ShapeNet datasets. On real-world datasets, the unidirectional Chamfer distance (UCD) and the unidirectional Hausdorff distance (UHD) of the method are reduced by an average of 2.3 and 2.4, respectively, compared to the state-of-the-art method. In addition to its excellent completion capabilities, the proposed method has a positive impact on downstream tasks. In point cloud classification, applying the proposed method improves classification accuracy by an average of 14 %. Extensive experimental results demonstrate that the proposed SPC has a high practical value.},
  archive      = {J_NN},
  author       = {Jie Song and Xing Wu and Junfeng Yao and Qi Zhang and Chenhao Shang and Quan Qian and Jun Song},
  doi          = {10.1016/j.neunet.2025.108107},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108107},
  shortjournal = {Neural Netw.},
  title        = {SPC: Self-supervised point cloud completion},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MINIGE-MNER: A multi-stage interaction network inspired by gene editing for multimodal named entity recognition. <em>NN</em>, <em>194</em>, 108106. (<a href='https://doi.org/10.1016/j.neunet.2025.108106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Named Entity Recognition (MNER) integrates complementary information from both text and images to identify named entities within text. However, existing methods face three key issues: imbalanced handling of modality noise, the cascading effect of semantic mismatch, and information loss resulting from the lack of text dominance. To address these issues, this paper proposes a M ulti-stage I nteraction N etwork I nspired by G ene E diting for MNER (MINIGE-MNER). The core innovations of this method include: A gene knockout module based on the variational information bottleneck, which removes inferior genes (modality noise) from the text, raw image, and generated image features. This approach retains the superior genes, achieving balanced filtering of modality noise. A determination of gene recombination sites module that maximizes the mutual information between superior genes across modalities, reducing the spatial distance between them and ensuring precise, fine-grained semantic alignment. This helps to prevent the cascading effect of semantic mismatch. A text-guided gene recombination module that implements a “text-dominant, vision-supplementary” cross-modal fusion paradigm. This module dynamically filters out visual noise unrelated to the text while avoiding excessive reliance on visual information that could obscure the unique contextual information of the text, effectively mitigating information loss. Experimental results show that MINIGE-MNER achieves F1 scores of 76.45 % and 88.67 % on the Twitter-2015 and Twitter-2017 datasets, respectively, outperforming existing state-of-the-art methods by 0.83 % and 0.42 %. In addition, this paper presents comprehensive experiments that demonstrate the superiority of MINIGE-MNER and the effectiveness of its individual modules.},
  archive      = {J_NN},
  author       = {Bo Kong and Shengquan Liu and Liruizhi Jia and Yi Liang and Dongfang Han and Xu Zhang},
  doi          = {10.1016/j.neunet.2025.108106},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108106},
  shortjournal = {Neural Netw.},
  title        = {MINIGE-MNER: A multi-stage interaction network inspired by gene editing for multimodal named entity recognition},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deceiving question-answering models: A hybrid word-level adversarial approach. <em>NN</em>, <em>194</em>, 108105. (<a href='https://doi.org/10.1016/j.neunet.2025.108105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning underpins most of the currently advanced natural language processing (NLP) tasks such as textual classification, neural machine translation (NMT), abstractive summarization and question-answering (QA). However, the robustness of the models, particularly QA models, against adversarial attacks is a critical concern that remains insufficiently explored. This paper introduces QA-Attack (Question Answering Attack), a novel word-level adversarial strategy that fools QA models. Our attention-based attack exploits the customized attention mechanism and deletion ranking strategy to identify and target specific words within contextual passages. It creates deceptive inputs by carefully choosing and substituting synonyms, preserving grammatical integrity while misleading the model to produce incorrect responses. Our approach demonstrates versatility across various question types, particularly when dealing with extensive long textual inputs. Extensive experiments on multiple benchmark datasets demonstrate that QA-Attack successfully deceives baseline QA models and surpasses existing adversarial techniques regarding success rate, semantics changes, BLEU score, fluency and grammar error rate.},
  archive      = {J_NN},
  author       = {Jiyao Li and Mingze Ni and Yongshun Gong and Wei Liu},
  doi          = {10.1016/j.neunet.2025.108105},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108105},
  shortjournal = {Neural Netw.},
  title        = {Deceiving question-answering models: A hybrid word-level adversarial approach},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A unified gradient regularization method for heterogeneous graph neural networks. <em>NN</em>, <em>194</em>, 108104. (<a href='https://doi.org/10.1016/j.neunet.2025.108104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous Graph Neural Networks (HGNNs) are advanced deep learning methods widely applied for learning representations of heterogeneous graphs. However, they face challenges such as over-smoothing and non-robustness. Existing methods can mitigate these issues by applying gradient regularization to one of the three information dimensions: node, edge, or propagation message. However, these methods have problems such as unstable training, difficulty in parameter convergence, and inadequate utilization of heterogeneous information. We propose a novel gradient regularization method called Grug, which iteratively applies regularization to the gradients derived from both node type and message matrix during the message-passing process. A detailed theoretical analysis demonstrates its advantages in Stability and Diversity. Notably, Grug potentially exceeds the theoretical upper bounds set by DropMessage. In addition, Grug offers a unified gradient regularization framework that integrates the existing dropping and adversarial training methods, and provides theoretical guidance for their further optimization in different data and tasks. We validate Grug through extensive experiments on six public datasets, showing significant improvements in performance and effectiveness.},
  archive      = {J_NN},
  author       = {Xiao Yang and Xuejiao Zhao and Zhiqi Shen},
  doi          = {10.1016/j.neunet.2025.108104},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108104},
  shortjournal = {Neural Netw.},
  title        = {A unified gradient regularization method for heterogeneous graph neural networks},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-level graph contrastive learning for community value prediction. <em>NN</em>, <em>194</em>, 108103. (<a href='https://doi.org/10.1016/j.neunet.2025.108103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community Value Prediction (CVP) is an important emerging task in the field of social commerce, which aims to predict the community values. However, due to the complex structure of communities and individuals, previous graph machine learning methods have struggled to adequately address this task. This study endeavors to bridge this gap by introducing a cross-level graph contrastive learning method called Cross-level Community Contrastive Learning (CCCL) to handle such subgraph-level tasks. Specifically, we generate two views that describe different levels of social connections, the augmented node-level graph and the community-level graph that is produced by graph coarsening. Subsequently, CCCL captures the mutual information between the two views through a cross-view contrastive loss. The learned embeddings utilize community and node information at various levels, making them capable of handling subgraph-level regression problems. To the best of our knowledge, CCCL is the first graph contrastive learning method that addresses the CVP problem. We theoretically show that CCCL maximizes a lower bound of the mutual information shared between node-view and community-view representations. Experimental results demonstrate that our proposed approach is highly effective for the CVP task, outperforming both end-to-end and self-supervised baselines. Furthermore, our model also exhibits robust resistance to edge perturbation attacks.},
  archive      = {J_NN},
  author       = {Wenjie Yang and Shengzhong Zhang and Zengfeng Huang},
  doi          = {10.1016/j.neunet.2025.108103},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108103},
  shortjournal = {Neural Netw.},
  title        = {Cross-level graph contrastive learning for community value prediction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Radiology report generation via visual-semantic ambivalence-aware network and focal self-critical sequence training. <em>NN</em>, <em>194</em>, 108102. (<a href='https://doi.org/10.1016/j.neunet.2025.108102'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiology report generation, which aims to provide accurate descriptions of both normal and abnormal regions, has been attracting growing research attention. Recently, despite considerable progress, data-driven deep-learning based models still face challenges in capturing and describing the abnormalities, due to the data bias problem. To address this problem, we propose to generate radiology reports via the Visual-Semantic Ambivalence-Aware Network (VSANet) and the Focal Self-Critical Sequence Training (FSCST). In detail, our VSANet follows the encoder-decoder framework. In the encoder part, we first deploy a multi-grained abnormality extractor and a visual extractor to capture both semantic and visual features from given images, and then introduce a Parameter Shared Dual-way Encoder (PSDwE) to delve into the inter- and intra-relationships among these features. In the decoder part, we propose the Visual-Semantic Ambivalence-Aware (VSA) module to generate the abnormality-aware visual features to mitigate the data bias problem. In implementation, our VSA introduces three sub-modules: Dual-way Attention (DwA), introduced to generate both the word-related visual and semantic features; Dual-way Attention on Attention (DwAoA), designed to mitigate redundant information; Score-based Feature Fusion (SFF), constructed to fuse the visual and semantic features in an ambivalence way. We further introduce the FSCST to enhance the overall performance of our VSANet by allocating more attention toward difficult samples. Experimental results demonstrate that our proposal achieves superior performance on various evaluation metrics. Source code have released at https://github.com/SKD-HPC/VSANet .},
  archive      = {J_NN},
  author       = {Xiulong Yi and You Fu and Enxu Bi and Jianguo Liang and Hao Zhang and Jianzhi Yu and Qianqian Li and Rong Hua and Rui Wang},
  doi          = {10.1016/j.neunet.2025.108102},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108102},
  shortjournal = {Neural Netw.},
  title        = {Radiology report generation via visual-semantic ambivalence-aware network and focal self-critical sequence training},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Discriminative representation learning via attention-enhanced contrastive learning for short text clustering. <em>NN</em>, <em>194</em>, 108101. (<a href='https://doi.org/10.1016/j.neunet.2025.108101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrastive learning has gained significant attention in short text clustering, yet it has an inherent drawback of mistakenly identifying samples from the same category as negatives and separating them in the feature space (i.e., the false negative separation problem). To generate discriminative representations for short text clustering, we propose a novel clustering method, called Discriminative Representation learning via A ttention- E nhanced C ontrastive L earning for Short Text Clustering ( AECL ). The AECL consists of two modules which are the contrastive learning module and the pseudo-label assisting module. Both modules utilize a sample-level attention mechanism to extract similarities between samples, based on which cross-sample features are aggregated to form a consistent representation for each sample. The contrastive learning module explores the similarity relationships and the consistent representations to form positive samples, effectively addressing the false negative separation issue, and the pseudo-label assisting module utilizes the consistent representations to produce reliable supervision information to assist the clustering task. Experimental results demonstrate that AECL outperforms state-of-the-art methods. The code is available at https://github.com/YZH0905/AECL-STC .},
  archive      = {J_NN},
  author       = {Zhihao Yao and Bo Li and Yufei Liao},
  doi          = {10.1016/j.neunet.2025.108101},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108101},
  shortjournal = {Neural Netw.},
  title        = {Discriminative representation learning via attention-enhanced contrastive learning for short text clustering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fixed/prescribed-time synchronization of state-dependent switching neural networks with stochastic disturbance and impulsive effects. <em>NN</em>, <em>194</em>, 108100. (<a href='https://doi.org/10.1016/j.neunet.2025.108100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the fixed-time synchronization (FXTS) and prescribed-time synchronization (PSTS) problems of state-dependent switching neural networks (SDSNNs) with stochastic disturbances and impulsive effects. By leveraging the average impulsive interval, comparison principle, and interval matrix methodology, this study advances a novel analytical framework. Departing from conventional approaches, we reformulate stochastic disturbed and impulsive SDSNNs as interval-parameter systems through rigorous interval matrix transformation. Consequently, we derive some sufficient conditions in the form of linear matrix inequalities (LMIs) to ensure the realization of FXTS and PSTS. Since impulsive effects can potentially compromise synchronization stability, careful controller design becomes critical. To address this challenge, we develop a unified proportional integral (PI) control framework. Through proper adjustment of its control parameters, this framework enables the system to achieve both FXTS and PSTS. Moreover, by reasonably configuring the relationship between the impulsive intensity and the prescribed time, the synchronization performance can be balanced. Finally, we demonstrate the effectiveness of the theoretical results through two examples.},
  archive      = {J_NN},
  author       = {Guici Chen and Houxuan Zhang and Shiping Wen and Junhao Hu and Leimin Wang},
  doi          = {10.1016/j.neunet.2025.108100},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108100},
  shortjournal = {Neural Netw.},
  title        = {Fixed/prescribed-time synchronization of state-dependent switching neural networks with stochastic disturbance and impulsive effects},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EKDSC: Long-tailed recognition based on expert knowledge distillation for specific categories. <em>NN</em>, <em>194</em>, 108099. (<a href='https://doi.org/10.1016/j.neunet.2025.108099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of long-tail visual recognition, the imbalance in data distribution leads to a significant performance gap between head and tail classes. Improving the tail-class performance and alleviating the decline in head class are two critical questions. Although many methods have proposed solutions for the former, most of them fall short in the latter. Introducing additional knowledge is a novel view to address the problem, however, how to attain useful knowledge and further transfer the knowledge to the target model is the core. This paper proposes a novel method called Expert Knowledge Distillation for Specific Categories (EKDSC). Firstly, we propose a kind of well-trained teacher model ensuring each expert concentrates on its specialized field while being less affected by other interference. Furthermore, the teacher model including three categories of experts: head, mid, and tail classes, is utilized to distill their specialized knowledge to the student model. Experimental results demonstrate that EKDSC effectively improves the accuracy of tail classes, and mitigates the common decreases of head classes’ performance. Our proposed method achieves a high accuracy, exceeding the current state-of-the-art (SOTA) by 1–5 % on benchmark datasets including the small-scale CIFAR-10 LT and CIFAR-100 LT. Furthermore, it demonstrates outstanding performance on large-scale datasets such as ImageNet-LT, iNaturalist 2018, and Places-LT.},
  archive      = {J_NN},
  author       = {Yaping Bai and Jinghua Li and Dehui Kong and Suqiao Yang and Baocai Yin},
  doi          = {10.1016/j.neunet.2025.108099},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108099},
  shortjournal = {Neural Netw.},
  title        = {EKDSC: Long-tailed recognition based on expert knowledge distillation for specific categories},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Weakly supervised multi-modal imitation learning from incompletely labeled demonstrations. <em>NN</em>, <em>194</em>, 108098. (<a href='https://doi.org/10.1016/j.neunet.2025.108098'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal imitation learning enables the agent to learn demonstrations of multiple modes at the same time. However, as expert demonstrations in practice tend to have incomplete labels for behavior modes, most methods are inefficient. To address this issue, an approach capable of imitation learning from incompletely labeled expert demonstrations, referred to as Weakly Supervised Multi-modal Imitation Learning (WSMIL), is proposed. WSMIL incorporates weakly supervised learning into multi-modal imitation learning by adding a behavior mode classifier to the adversarial network, thus forming adversaries among three players (generator, classifier and discriminator). Both labeled and unlabeled data are fully utilized in this adversarial process where fake state-action-label pairs generated by the generator and the classifier try to deceive the discriminator that tries to identify them and limited labeled expert demonstrations. Additionally, in order to ensure the data distribution of classifier and generator individually to converge to the expert’s real distribution, three extra losses are employed, where simulated annealing behavioral cloning is also added to the generator network to improve the generalization of policy. Experiments show that WSMIL accurately distinguishes modes with incomplete modal labels in demonstrations, learns close to the expert standard for each mode, and is more stable than other multi-modal methods.},
  archive      = {J_NN},
  author       = {Sijia Gu and Fei Zhu},
  doi          = {10.1016/j.neunet.2025.108098},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108098},
  shortjournal = {Neural Netw.},
  title        = {Weakly supervised multi-modal imitation learning from incompletely labeled demonstrations},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hybrid aggregation strategy with double inverted residual blocks for lightweight salient object detection. <em>NN</em>, <em>194</em>, 108097. (<a href='https://doi.org/10.1016/j.neunet.2025.108097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lightweight salient object detection (SOD) is widely used in various downstream applications due to its low resource requirements and fast inference speed. The use of hybrid encoders offers the potential to achieve a better balance between efficiency and accuracy for SOD task. However, the aggregation of features from convolutional neural networks (CNNs) and transformers remains challenging, and most existing lightweight SOD models rarely explore the efficient aggregation of cross-architecture features derived from hybrid encoders. In this paper, we propose a hybrid aggregation strategy network (HASNet) that balances accuracy and efficiency for lightweight SOD by grouping and aggregating features to leverage salient information across different architectures. Specifically, the features obtained after hybrid encoder processing are divided into convolutional and transformer features for shallow and deep aggregation respectively. Deep aggregation uses the global inverted residual block (GIRB) to facilitate the transfer of salient information encoded within transformer features across various levels. Meanwhile, shallow aggregation uses the lightweight inverted residual block (LIRB) to efficiently integrate the spatial information inherent in convolutional features. The GIRB incorporates an efficient global operation to extract channel semantic information from the high-dimensional transformer features. The LIRB fuses low-level features by efficiently exploiting the spatial information in features at extremely low computational cost. Comprehensive experiments conducted across five datasets demonstrate that our HASNet significantly outperform existing methods in a thorough evaluation encompassing parameter sizes, inference speed, and accuracy. The source code will be publicly available at https://github.com/LitterMa-820/HASNet .},
  archive      = {J_NN},
  author       = {Jianhua Ma and Mingfeng Jiang and Xian Fang and Jiatong Chen and Yaming Wang and Guang Yang},
  doi          = {10.1016/j.neunet.2025.108097},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108097},
  shortjournal = {Neural Netw.},
  title        = {Hybrid aggregation strategy with double inverted residual blocks for lightweight salient object detection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing image restoration through learning context-rich and detail-accurate features. <em>NN</em>, <em>194</em>, 108096. (<a href='https://doi.org/10.1016/j.neunet.2025.108096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration aims to recover high-quality images from their degraded counterparts, necessitating a delicate balance between preserving spatial details and capturing contextual information. Although some methods attempt to address this trade-off, they tend to focus primarily on spatial features while overlooking the importance of understanding frequency variations. Moreover, these approaches commonly utilize skip connections–implemented via addition or concatenation–to fuse encoder and decoder features for improved restoration. However, since encoder features may still carry degradation artifacts, such direct fusion strategies risk introducing implicit noise, ultimately hindering restoration performance. In this paper, we present a multi-scale design that optimally balances these competing objectives, seamlessly integrating spatial and frequency domain knowledge to selectively recover the most informative information. Specifically, we develop a hybrid scale frequency selection block (HSFSBlock), which not only captures multi-scale information from the spatial domain, but also selects the most informative components for image restoration in the frequency domain. Furthermore, to mitigate the inherent noise introduced by skip connections employing only addition or concatenation, we introduce a skip connection attention mechanism (SCAM) to selectively determines the information that should propagate through skip connections. The resulting tightly interlinked architecture, named as LCDNet. Extensive experiments conducted across diverse image restoration tasks showcase that our model attains performance levels that are either superior or comparable to those of state-of-the-art algorithms. The code and the pre-trained models are released at https://github.com/Tombs98/LCDNet .},
  archive      = {J_NN},
  author       = {Hu Gao and Xiaoning Lei and Depeng Dang},
  doi          = {10.1016/j.neunet.2025.108096},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108096},
  shortjournal = {Neural Netw.},
  title        = {Enhancing image restoration through learning context-rich and detail-accurate features},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). La-LoRA: Parameter-efficient fine-tuning with layer-wise adaptive low-rank adaptation. <em>NN</em>, <em>194</em>, 108095. (<a href='https://doi.org/10.1016/j.neunet.2025.108095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameter-efficient fine-tuning (PEFT) has emerged as a critical paradigm for adapting large pre-trained models to downstream tasks, offering a balance between computational efficiency and model performance. Among these methods, Low-Rank Adaptation (LoRA) has gained significant popularity due to its efficiency; it freezes the pre-trained weights and decomposes the incremental matrices into two trainable low-rank matrices. However, a critical limitation of LoRA lies in its uniform rank assignment across all layers, which fails to account for the heterogeneous importance of different layers in contributing to task performance, potentially resulting in suboptimal adaptation. To address this limitation, we propose Layer-wise Adaptive Low-Rank Adaptation (La-LoRA), a novel approach that dynamically allocates rank to each layer based on Dynamic Contribution-Driven Parameter Budget (DCDPB) and Truncated Norm Weighted Dynamic Rank Allocation (TNW-DRA) during training. By treating each layer as an independent unit and progressively adjusting its rank allocation, La-LoRA ensures optimal model performance while maintaining computational efficiency and adapting to the complexity of diverse tasks. We conducted extensive experiments across multiple tasks and models to evaluate the effectiveness of La-LoRA. The results demonstrate that La-LoRA consistently outperforms existing benchmarks, validating its effectiveness in diverse scenarios.},
  archive      = {J_NN},
  author       = {Jiancheng Gu and Jiabin Yuan and Jiyuan Cai and Xianfa Zhou and Lili Fan},
  doi          = {10.1016/j.neunet.2025.108095},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108095},
  shortjournal = {Neural Netw.},
  title        = {La-LoRA: Parameter-efficient fine-tuning with layer-wise adaptive low-rank adaptation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-level dynamic heterogeneous graph network for video question answering. <em>NN</em>, <em>194</em>, 108094. (<a href='https://doi.org/10.1016/j.neunet.2025.108094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Video Question Answering (VideoQA) has garnered considerable research interest as a pivotal task within the realm of vision-language understanding. However, existing Video Question Answering datasets often lack sufficient entity and event information. Thus, the Vision Language Models (VLMs) struggle to complete intricate grounding and reasoning among multi-modal entities or events and heavily rely on language short-cut or irrelevant visual context. To address these challenges, we make improvements from both data and model perspectives. In terms of VideoQA data, we focus on supplementing the missing specific entities and events with the proposed event and entity augmentation strategies. Based on the augmented data, we propose a Dual-Level Dynamic Heterogeneous Graph Network (DDHG) for Video Question Answering. DDHG incorporates transformer layers to capture the dynamic temporal-spatial changes of visual entities. Then, DDHG establishes multi-modal semantic grounding ability between vision and text with entity-level and event-level heterogeneous graphs. Finally, the Dual-level Cross-modal Interaction Module integrates the dual-level features to predict correct answers. Our method not only significantly outperforms existing VideoQA models on two complex event-based benchmark datasets (Causal-VidQA and NExT-QA) but also demonstrates superior event content prediction ability over several state-of-the-art approaches.},
  archive      = {J_NN},
  author       = {Zefan Zhang and Yanhui Li and Weiqi Zhang and Tian Bai},
  doi          = {10.1016/j.neunet.2025.108094},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108094},
  shortjournal = {Neural Netw.},
  title        = {Dual-level dynamic heterogeneous graph network for video question answering},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HMT-DTI: Hierarchical meta-path learning with transformer for drug–target interaction prediction. <em>NN</em>, <em>194</em>, 108093. (<a href='https://doi.org/10.1016/j.neunet.2025.108093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug–target interaction (DTI) prediction plays a crucial role in drug discovery and repurposing by efficiently and accurately identifying potential therapeutic targets. Existing methods face challenges in capturing high-order semantic relationships in heterogeneous graphs and effectively integrating multi-meta-path information while also suffering from low computational efficiency. To address these challenges, a pre-computation-style hierarchical meta-path learning framework named HMT-DTI is proposed. HMT-DTI can effectively capture rich semantic information about drugs and targets while ensuring high computational efficiency. Specifically, during the pre-collection stage, HMT-DTI employs a Transformer-based message passing mechanism to evaluate neighbors’ importance and adaptively collect meta-path information. The incorporation of even-relation propagation reduces redundant iterations and improves efficiency. During training, HMT-DTI adopts a hierarchical knowledge extraction strategy to evaluate the importance of multi-hop neighbors and different meta-path patterns, capturing fine-grained semantic representations of drugs and targets. HMT-DTI is evaluated on three heterogeneous biological datasets and compared with several state-of-the-art methods. The results demonstrate the superiority of HMT-DTI in DTI prediction.},
  archive      = {J_NN},
  author       = {Dianlei Gao and Fei Zhu},
  doi          = {10.1016/j.neunet.2025.108093},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108093},
  shortjournal = {Neural Netw.},
  title        = {HMT-DTI: Hierarchical meta-path learning with transformer for drug–target interaction prediction},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-modal orthogonal fusion network via cross-layer guidance for alzheimer’s disease diagnosis. <em>NN</em>, <em>194</em>, 108091. (<a href='https://doi.org/10.1016/j.neunet.2025.108091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal neuroimaging techniques are widely employed for the accurate diagnosis of Alzheimer’s Disease (AD). Existing fusion methods typically focus on capturing semantic correlations between modalities through feature-level interactions. However, they fail to suppress redundant cross-modal information, resulting in sub-optimal multi-modal representation. Moreover, these methods ignore subject-specific differences in modality contributions. To address these challenges, we propose a novel Multi-modal Orthogonal Fusion Network via cross-layer guidance (MOFNet) to effectively fuse multi-modal information for AD diagnosis. We first design a Cross-layer Guidance Interaction module (CGI), leveraging high-level features to guide the learning of low-level features, thereby enhancing the fine-grained representations on disease-relevant regions. Then, we introduce a Multi-modal Orthogonal Compensation module (MOC) to realize bidirectional interaction between modalities. MOC encourages each modality to compensate for its limitations by learning orthogonal components from other modalities. Finally, a Feature Enhancement Fusion module (FEF) is developed to adaptively fuse multi-modal features based on the contributions of different modalities. Extensive experiments on the ADNI dataset demonstrate that MOFNet achieves superior performance in AD classification tasks.},
  archive      = {J_NN},
  author       = {Yumiao Zhao and Bo Jiang and Yuan Chen and Ye Luo and Jin Tang},
  doi          = {10.1016/j.neunet.2025.108091},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108091},
  shortjournal = {Neural Netw.},
  title        = {Multi-modal orthogonal fusion network via cross-layer guidance for alzheimer’s disease diagnosis},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ClickAttention: Click region similarity guided interactive segmentation. <em>NN</em>, <em>194</em>, 108090. (<a href='https://doi.org/10.1016/j.neunet.2025.108090'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interactive segmentation algorithms based on click points have attracted significant attention from researchers in recent years. However, most existing methods rely on sparse click maps as model inputs to segment specific target objects. These clicks primarily affect local regions, limiting the model’s ability to focus on the entire target object and often resulting in a higher number of required clicks. Additionally, many current algorithms struggle to balance performance and efficiency effectively. To address these challenges, we propose a click attention algorithm that expands the influence of positive clicks by leveraging the similarity between positively-clicked regions and the entire input. We further introduce a discriminative affinity loss to reduce attention coupling between positive and negative click regions, minimizing accuracy degradation caused by mutual interference. On the DAVIS dataset, our method achieves a 2 % performance gain (NoC@90) over the state-of-the-art SimpleClick-ViT-L, while using only 15.6 % of its parameters. Extensive experiments demonstrate that our approach outperforms existing methods and achieves state-of-the-art performance with fewer parameters. Data and code are published.},
  archive      = {J_NN},
  author       = {Long Xu and Yongquan Chen and Shanghong Li and Junkang Chen and Ziyuan Tang},
  doi          = {10.1016/j.neunet.2025.108090},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108090},
  shortjournal = {Neural Netw.},
  title        = {ClickAttention: Click region similarity guided interactive segmentation},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A vision-language model for multitask classification of memes. <em>NN</em>, <em>194</em>, 108089. (<a href='https://doi.org/10.1016/j.neunet.2025.108089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of social media and online memes has led to an increasing demand for automated systems that can analyse and classify multimodal data, particularly in online forums. Memes blend text and graphics to express complicated ideas, sometimes containing emotions, satire, or inappropriate material. Memes often represent cultural prejudices such as objectification, sexism, and bigotry, making it difficult for artificial intelligence to classify these components. Our solution is the vision-language model ViT-BERT CAMT (cross-attention multitask), which is intended for multitask meme categorization. Our model uses a linear self-attentive fusion mechanism to combine vision transformer (ViT) features for image analysis and bidirectional encoder representations from transformers (BERT) for text interpretation. In this way, we can see how text and images relate to space and meaning. We tested the ViT-BERT CAMT on two difficult datasets: the SemEval 2020 Memotion dataset, which contains a multilabel classification of sentiment, sarcasm, and offensiveness in memes, and the MIMIC dataset, which focuses on detecting sexism, objectification, and prejudice. The findings show that the ViT-BERT CAMT achieves good accuracy on both datasets and outperforms many current baselines in multitask settings. These results highlight the importance of combined image-text modelling for correctly deciphering nuanced meanings in memes, particularly when spotting abusive and discriminatory content. By improving multimodal categorization algorithms, this study helps better monitor and comprehend online conversation.},
  archive      = {J_NN},
  author       = {Md. Mithun Hossain and Md. Shakil Hossain and M.F. Mridha and Nilanjan Dey},
  doi          = {10.1016/j.neunet.2025.108089},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108089},
  shortjournal = {Neural Netw.},
  title        = {A vision-language model for multitask classification of memes},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-view learning meets state-space model: A dynamical system perspective. <em>NN</em>, <em>194</em>, 108088. (<a href='https://doi.org/10.1016/j.neunet.2025.108088'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning exploits the complementary nature of multiple modalities to enhance performance across diverse tasks. While deep learning has significantly advanced these fields by enabling sophisticated modeling of intra-view and cross-view interactions, many existing approaches still rely on heuristic architectures and lack a principled framework to capture the dynamic evolution of feature representations. This limitation hampers interpretability and theoretical understanding. To address these challenges, this paper introduces the Multi-view State-Space Model (MvSSM), which formulates multi-view representation learning as a continuous-time dynamical system inspired by control theory. In this framework, view-specific features are treated as external inputs, and a shared latent representation evolves as the internal system state, driven by learnable dynamics. This formulation unifies feature integration and label prediction within a single interpretable model, enabling theoretical analysis of system stability and representational transitions. Two variants, MvSSM-Lap and MvSSM-iLap, are further developed using Laplace and inverse Laplace transformations to derive system dynamics representations. These solutions exhibit structural similarities to graph convolution operations in deep networks, supporting efficient feature propagation and theoretical interpretability. Experiments on benchmark datasets such as IAPR-TC12, and ESP demonstrate the effectiveness of the proposed method, achieving up to 4.31 % improvement in accuracy and 4.27 % in F1-score over existing state-of-the-art approaches.},
  archive      = {J_NN},
  author       = {Weibin Chen and Ying Zou and Zhiyong Xu and Li Xu and Shiping Wang},
  doi          = {10.1016/j.neunet.2025.108088},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108088},
  shortjournal = {Neural Netw.},
  title        = {Multi-view learning meets state-space model: A dynamical system perspective},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph convolutional network with adaptive grouping aggregation strategy. <em>NN</em>, <em>194</em>, 108086. (<a href='https://doi.org/10.1016/j.neunet.2025.108086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of graph convolutional networks (GCNs) with naive aggregation functions on nodes has reached the bottleneck, rendering a gap between practice and theoretical expressity. Some learning-based aggregation strategies have been proposed to improve the performance. However, few of them focus on how these strategies affect the expressity and evaluate their performance in an equal experimental setting. In this paper, we point out that the generated features lack discrimination because naive aggregation functions cannot retain sufficient node information, largely leading to the performance gap. Accordingly, a novel Adaptive Grouping Aggregation (AGA) strategy is proposed to remedy this drawback. Inspired by the label histogram in the Weisfeiler-Lehman (WL) Test, this strategy assigns each node to a unique group to retain more node information, which is proven to have a strictly more powerful expressity. In this work setting, the nodes are grouped according to a modified Student’s t-Distribution between node features and a set of learnable group labels, where the Gumbel Softmax is employed to implement this strategy in an end-to-end trainable pipeline. As a result, such a design can generate more discriminative features and offer a plug-in module in most architectures. Extensive experiments have been conducted on several benchmarks to compare our method with other aggregation strategies. The proposed method improves the performance in all control groups of all benchmarks and achieves the best result in most cases. Additional ablation studies and comparisons with state-of-the-art methods on the large-scale benchmark also indicate the superiority of our method.},
  archive      = {J_NN},
  author       = {Ruixiang Wang and Chunxia Zhang and Chunhong Pan},
  doi          = {10.1016/j.neunet.2025.108086},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108086},
  shortjournal = {Neural Netw.},
  title        = {Graph convolutional network with adaptive grouping aggregation strategy},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive behavior with stable synapses. <em>NN</em>, <em>194</em>, 108082. (<a href='https://doi.org/10.1016/j.neunet.2025.108082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavioral changes in animals and humans, triggered by errors or verbal instructions, can occur extremely rapidly. While learning theories typically attribute improvements in performance to synaptic plasticity, recent findings suggest that such fast adaptations may instead result from dynamic reconfiguration of the networks involved without changes to synaptic weights. Recently, similar capabilities have been observed in transformers, foundational architecture in machine learning widely used in applications such as natural language and image processing. Transformers are capable of in-context learning, the ability to adapt and acquire new information dynamically within the context of the task or environment they are currently engaged in, without changing their parameters. We argue that this property may stem from gain modulation–a feature widely observed in biological networks, such as pyramidal neurons through input segregation and dendritic amplification. We propose a constructive approach to induce in-context learning in an architecture composed of recurrent networks with gain modulation, demonstrating abilities inaccessible to standard networks. In particular, we show that, such architecture can dynamically implement standard gradient-based by encoding weight changes in the activity of another network. We argue that, while these algorithms are traditionally associated with synaptic plasticity, their reliance on non-local terms suggests that they may be more naturally realized in the brain at the level of neural circuits. We demonstrate that we can extend our approach to temporal tasks and reinforcement learning. We further validate our approach in a MuJoCo ant navigation task, showcasing a neuromorphic control paradigm via real-time network reconfiguration.},
  archive      = {J_NN},
  author       = {Cristiano Capone and Luca Falorsi},
  doi          = {10.1016/j.neunet.2025.108082},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108082},
  shortjournal = {Neural Netw.},
  title        = {Adaptive behavior with stable synapses},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Disentangled self-supervised video camouflaged object detection and salient object detection. <em>NN</em>, <em>194</em>, 108077. (<a href='https://doi.org/10.1016/j.neunet.2025.108077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video tasks play an important role in multimedia fields. In various video tasks, such as video camouflaged/salient object detection (VCOD/VSOD), motion and context information are two important aspects. Despite the fact that many existing works have already achieved promising results in VCOD and VSOD tasks, they still have limitations when it comes to leveraging motion and context information. In this paper, we propose a new disentangled perspective to treat motion and context information in VCOD and VSOD tasks. Our proposed model can respectively utilize context and motion information in ContextNet and MotionNet, without conflicting with each other as there can be biases between these two types of information in certain circumstances. Moreover, we further explore how to apply disentangled perspective in the self-supervised manner, which can reduce annotation costs. Specifically, we first design a self-supervised adaptive frame routing mechanism to determine whether each video frame belongs to ContextNet or MotionNet. Then we design a cross-supervision for ContextNet and MotionNet to train these two segmentation networks in self-supervised mechanism. In experiments, our proposed self-supervised disentangled model consistently outperforms state-of-the-art unsupervised methods on VCOD and VSOD datasets.},
  archive      = {J_NN},
  author       = {Haoke Xiao and Lv Tang and Bo Li and Zhiming Luo and Shaozi Li},
  doi          = {10.1016/j.neunet.2025.108077},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108077},
  shortjournal = {Neural Netw.},
  title        = {Disentangled self-supervised video camouflaged object detection and salient object detection},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). WPDA: Frequency-based backdoor attack with wavelet packet decomposition. <em>NN</em>, <em>194</em>, 108074. (<a href='https://doi.org/10.1016/j.neunet.2025.108074'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work explores backdoor attack, which is an emerging security threat against deep neural networks (DNNs). The adversary aims to inject a backdoor into the model by manipulating a portion of training samples, such that the backdoor could be activated by a particular trigger to make a target prediction at inference. Currently, existing backdoor attacks often require moderate or high poisoning ratios to achieve the desired attack performance, but making them susceptible to some advanced backdoor defenses ( e . g . , poisoned sample detection). One possible solution to this dilemma is enhancing the attack performance at low poisoning ratios, which has been rarely studied due to its high challenge. To achieve this goal, we propose an innovative frequency-based backdoor attack via wavelet packet decomposition (WPD), which could finely decompose the original image into multiple sub-spectrograms with semantic information. It facilitates us to accurately identify the most critical frequency regions to effectively insert the trigger into the victim image, such that the trigger information could be sufficiently learned to form the backdoor. The proposed attack stands out for its exceptional effectiveness, stealthiness, and resistance at an extremely low poisoning ratio. Notably, it achieves the 98.12 % attack success rate on CIFAR-10 with an extremely low poisoning ratio of 0.004 % ( i.e. , only 2 poisoned samples among 50,000 training samples), and bypasses several advanced backdoor defenses. Besides, we provide more extensive experiments to demonstrate the efficacy of the proposed method, as well as in-depth analyses to explain its underlying mechanism.},
  archive      = {J_NN},
  author       = {Zhengyao Song and Yongqiang Li and Danni Yuan and Li Liu and Shaokui Wei and Baoyuan Wu},
  doi          = {10.1016/j.neunet.2025.108074},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108074},
  shortjournal = {Neural Netw.},
  title        = {WPDA: Frequency-based backdoor attack with wavelet packet decomposition},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DA-MoE: Addressing depth-sensitivity in graph-level analysis through mixture of experts. <em>NN</em>, <em>194</em>, 108064. (<a href='https://doi.org/10.1016/j.neunet.2025.108064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are gaining popularity for processing graph data. In real-world scenarios, graph data within the same dataset can vary significantly in scale. This variability leads to depth-sensitivity, where the optimal depth of GNN layers depends on the scale of the graph data. Empirically, fewer layers are sufficient for message passing in smaller graphs, while larger graphs typically require deeper networks to capture long-range dependencies and global features. However, existing methods generally use a fixed number of GNN layers to generate representations for all graphs, overlooking the depth-sensitivity issue in graph data. To address this challenge, we propose the depth adaptive mixture of expert (DA-MoE) method, which incorporates two main improvements to GNN backbone: 1) DA-MoE employs different GNN layers, each considered an expert with its own parameters. Such a design allows the model to flexibly aggregate information at different scales, effectively addressing the depth-sensitivity issue in graph data. 2) DA-MoE utilizes GNN to capture the structural information instead of the linear projections in the gating network. Thus, the gating network enables the model to capture complex patterns and dependencies within the data. By leveraging these improvements, each expert in DA-MoE specifically learns distinct graph patterns at different scales. Furthermore, comprehensive experiments on the TU dataset and open graph benchmark (OGB) have shown that DA-MoE consistently surpasses existing baselines on various tasks, including graph, node, and link-level analyses. The code are available at https://github.com/Celin-Yao/DA-MoE .},
  archive      = {J_NN},
  author       = {Zelin Yao and Mukun Chen and Chuang Liu and Xianke Meng and Yibing Zhan and Jia Wu and Shirui Pan and Huiting Xu and Wenbin Hu},
  doi          = {10.1016/j.neunet.2025.108064},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108064},
  shortjournal = {Neural Netw.},
  title        = {DA-MoE: Addressing depth-sensitivity in graph-level analysis through mixture of experts},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic graph representation learning with disentangled information bottleneck. <em>NN</em>, <em>194</em>, 108056. (<a href='https://doi.org/10.1016/j.neunet.2025.108056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic graph representation learning recently garnered enormous research attention. Despite the notable successes of existing methods, they usually characterize dynamic graphs as a perceptual whole and learn dynamic graph representations within an entangled feature space, which overlook different temporal dependencies inherent in the data. Specifically, the evolution of dynamic graphs is usually decided by a dichotomy in properties: time-invariant properties and time-varying properties. Existing holistic works fail to distinguish these temporal properties and may suffer suboptimal performance in downstream tasks. To tackle this problem, we propose to learn macro-disentangled dynamic graph representations based on the Information Bottleneck theory, leading to a novel dynamic graph representation learning method, Disentangled Dynamic Graph Information Bottleneck (DDGIB). Our DDGIB explicitly embeds the dynamic graphs into a time-invariant representation space and a time-varying representation space. The time-invariant representation space encapsulates stable properties across the temporal span of dynamic graphs, whereas the time-varying representation space encapsulates time-fluctuating properties. The macro disentanglement on the temporal dependencies facilitates the representations’ performance on downstream tasks. Furthermore, we theoretically prove the sufficiency and macro disentanglement of DDGIB. The sufficiency demonstrates that DDGIB can achieve sufficient representations for any possible downstream tasks, while the macro disentanglement certifies that DDGIB can embed the different temporal properties into their corresponding temporal representation space. Extensive experimental results on various datasets and downstream tasks demonstrate the superiority of our method.},
  archive      = {J_NN},
  author       = {Jihong Wang and Yuxin Bai and Chunqiang Zhu and Hao Qian and Ziqi Liu and Minnan Luo},
  doi          = {10.1016/j.neunet.2025.108056},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108056},
  shortjournal = {Neural Netw.},
  title        = {Dynamic graph representation learning with disentangled information bottleneck},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tailoring knowledge for empowered cooperative actions in multi-agent reinforcement learning. <em>NN</em>, <em>194</em>, 108023. (<a href='https://doi.org/10.1016/j.neunet.2025.108023'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavioral diversity emerges as a crucial factor for achieving effective collaboration in Multi-Agent Reinforcement Learning (MARL). Current methods often use partial parameter sharing, such as sharing the same representation layer, to balance behavioral diversity and algorithmic scalability. However, this approach ignores that different agents need different decision knowledge, causing training conflicts and knowledge redundancy. To solve these, we propose Tailoring Knowledge for Empowered Cooperative Actions in Multi-Agent Reinforcement Learning (TKCA). Specially, we employ a set of Knowledge Encoders to encode different environment types of knowledge and utilize a Knowledge Selector network to assist each agent in decision-making by selecting the corresponding knowledge. We evaluated TKCA in challenging StarCraftII micromanagement games and Google Research Football games, and the results demonstrate the superior performance of TKCA.},
  archive      = {J_NN},
  author       = {Hu Fu and Yihua Tan and Hao Chen and Pengyi Li},
  doi          = {10.1016/j.neunet.2025.108023},
  journal      = {Neural Networks},
  month        = {2},
  pages        = {108023},
  shortjournal = {Neural Netw.},
  title        = {Tailoring knowledge for empowered cooperative actions in multi-agent reinforcement learning},
  volume       = {194},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic scale position embedding for cross-modal representation learning. <em>NN</em>, <em>193</em>, 108087. (<a href='https://doi.org/10.1016/j.neunet.2025.108087'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a novel approach to capture temporal information in videos across multiple scales for cross-modal learning. As videos naturally encapsulate semantic information of diverse durations, existing methods that primarily depend on fine- and coarse-grained contrastive learning may fail to fully capture the inherent semantic information. To bridge this gap, we propose Dynamic Scale Position Embedding (DSPE), a novel approach that enables a single transformer to interpret videos at various temporal scales through dynamic adjustment of temporal position embedding. In contrast to conventional multi-scale methods that aggregate video clips, DSPE maintains the distinct features of each clip, thus preserving semantic integrity and enhancing semantic content comprehension. Based on this, we present an efficient multi-scale temporal encoder designed to adeptly capture temporal information across a broad spectrum from fine to coarse granularity. Comprehensive experiments across four datasets–MSR-VTT, LSMDC, MSVD, and ActivityNet-Captions–and two distinct tasks–text-video retrieval and video-captioning–with consistent performance improvements highlight the significance of the presented multi-scale approach.},
  archive      = {J_NN},
  author       = {Jungkyoo Shin and Sungmin Kang and Yoonsik Cho and Eunwoo Kim},
  doi          = {10.1016/j.neunet.2025.108087},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108087},
  shortjournal = {Neural Netw.},
  title        = {Dynamic scale position embedding for cross-modal representation learning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Lightweight local and global granularity selection optimization network for single image super-resolution. <em>NN</em>, <em>193</em>, 108085. (<a href='https://doi.org/10.1016/j.neunet.2025.108085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, neural networks that combine local and global granularity features have made significant progress in single image super-resolution (SISR). However, when dealing with local granularity, these models often fuse features from coarse to fine in a linear manner, which leads to redundant feature representations and inefficient information extraction. Additionally, global granularity feature extraction is often compromised by the interference of irrelevant features that reduce the model’s ability to effectively capture global dependencies, ultimately affecting reconstruction quality. In this paper, a lightweight local and global granularity selection optimization network-LGGSONet is proposed to enhance the capability of feature extraction. First, we present a local granularity selection module (LGSM), which applies a novel nonlinear convolution method to dynamically fuse multi-scale features and adaptively select effective information. Next, we design a global granularity optimization module (GGOM), which uses global transposed attention for feature extraction while dynamically filtering out irrelevant spatial fine-grained features. Then, we construct a mixed granularity transformer block (MGTB), combining LGSM and GGOM. Finally, MGTB is integrated into the mixed granularity residual transformer group (MGRTG) to simplify network training. Extensive experiments show that LGGSONet based on MGRTG achieves a PSNR improvement of 0.30 dB over other advanced lightweight methods while maintaining fewer parameters and computational costs.},
  archive      = {J_NN},
  author       = {Zhihao Peng and Mang Hu and Xinyuan Qi and Sheng Wu and Qianqian Xia and Jianga Shang and Linquan Yang},
  doi          = {10.1016/j.neunet.2025.108085},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108085},
  shortjournal = {Neural Netw.},
  title        = {Lightweight local and global granularity selection optimization network for single image super-resolution},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Revisiting DIRE: Towards universal AI-generated image detection. <em>NN</em>, <em>193</em>, 108084. (<a href='https://doi.org/10.1016/j.neunet.2025.108084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of generative models has improved image quality and made image synthesis widely accessible, raising concerns about content credibility. To address this issue, we propose a method called Universal Reconstruction Residual Analysis ( UR 2 EA ) for detecting synthetic images. Our study reveals that, when GAN- and diffusion-generated images are reconstructed by pre-trained diffusion models, they exhibit significant differences in reconstruction error compared to real images: GAN-generated images show lower reconstruction quality than real images, whereas diffusion-generated images are more accurately reconstructed. We leverage these residual maps as a universal prior to training a model for detecting synthetic images. In addition, we introduce a Multi-scale Channel and Window Attention (MCWA) module to extract fine-grained features from residual maps across multiple scales, capturing both local and global details. To facilitate the exploration of diverse detection methods, we constructed a new UniversalForensics dataset, which includes various representations of synthetic images generated by 30 different models. Compared to the best-performing baselines, our method improves average accuracy by 3.3 % and precision by 1.6 %, achieving state-of-the-art results.},
  archive      = {J_NN},
  author       = {Huanqi Lin and Jinghui Qin and Xiaoqi Wu and Tianshui Chen and Zhijing Yang},
  doi          = {10.1016/j.neunet.2025.108084},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108084},
  shortjournal = {Neural Netw.},
  title        = {Revisiting DIRE: Towards universal AI-generated image detection},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GoFormer: A GoLPP inspired transformer for functional brain graph learning and classification. <em>NN</em>, <em>193</em>, 108081. (<a href='https://doi.org/10.1016/j.neunet.2025.108081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph has a great potential in modelling the complex relationship among data, and learning a high-quality graph usually plays a critical role in many downstream tasks. In 2010, we proposed the graph-optimized locality preserving projections (GoLPP) that was the first work to learn graphs adaptively with the dimensionality reduction task, exhibiting a better performance than the methods based on predefined graphs. Recently, the graph learning is re-highlighted partially due to the popularity of Transformer that leverages the self-attention mechanism to model the relationship between tokens by an updatable graph. Despite its great success, Transformer has a weak inductive bias and needs to be trained on large-scale datasets. For some practical scenarios such as intelligent medicine, however, it is difficult to collect sufficient data to support the training of Transformer. By revisiting GoLPP, we have an interesting finding that its iterative process between the graph and projection matrix precisely corresponds to the working mechanism of self-attention modules in Transformer, which inspires us to design a novel method, namely GoFormer, towards getting the best from both worlds. Specifically, GoFormer not only inherits the power of Transformer for handling the sequence data in an end-to-end form, but also balances the parsimonious principle by integrating the parameter updating and sharing mechanism implicitly involved in GoLPP. Compared with Transformer, GoFormer can mitigate the risk of overfitting and has a better interpretability for medical applications. To evaluate its effectiveness, we use GoFormer to learn and classify brain graphs based on functional magnetic resonance imaging (fMRI) data for the early diagnosis of neurological disorders. Experimental results demonstrate that GoFormer outperforms the baseline and state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Mengxue Pang and Lina Zhou and Xueying Yao and Jun Yang and Jinshan Zhang and Yining Zhang and Limei Zhang and Lishan Qiao},
  doi          = {10.1016/j.neunet.2025.108081},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108081},
  shortjournal = {Neural Netw.},
  title        = {GoFormer: A GoLPP inspired transformer for functional brain graph learning and classification},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic network compression via probabilistic channel pruning. <em>NN</em>, <em>193</em>, 108080. (<a href='https://doi.org/10.1016/j.neunet.2025.108080'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network compression problems have been extensively studied to overcome the limitations of compute-intensive deep learning models. Most of the state-of-the-art solutions in this context are based on network pruning that identify and remove unimportant weights, filters or channels. However, existing methods often lack actual speedup or require complex pruning criteria and additional training (fine-tuning) overhead. To address these limitations, we develop probability-based connectivity module that determines the connection of each channel to the next layer. Our connectivity module enables to dynamically activate and deactivate channel connections during training, and hence, does not necessitate fine-tuning of the pruned model. We show that the convolution decomposition, which decomposes convolution with connectivity module and depth-wise convolution can effectively induce sparsity, resulting in 52.76 %, 46.05 % reduction of parameter counts, with even boosting accuracy (+0.19 %, + 0.3 %) compared to baseline architectures in ResNet-56, VGG-19 Models. We also introduce resource-aware regularization that exploits the probabilistic activation of connectivity module in order to control the level of compression. We show that our method achieves comparable level of compression and accuracy to the state-of-the-art pruning methods.},
  archive      = {J_NN},
  author       = {Kwanhee Lee and Hyang-Won Lee},
  doi          = {10.1016/j.neunet.2025.108080},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108080},
  shortjournal = {Neural Netw.},
  title        = {Dynamic network compression via probabilistic channel pruning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hardware friendly deep reservoir computing. <em>NN</em>, <em>193</em>, 108079. (<a href='https://doi.org/10.1016/j.neunet.2025.108079'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reservoir Computing (RC) is a popular approach for modeling dynamical Recurrent Neural Networks, featured by a fixed (i.e., untrained) recurrent reservoir layer. In this paper, we introduce a novel design strategy for deep RC neural networks that is especially suitable to neuromorphic hardware implementations. From the topological perspective, the introduced model presents a multi-level architecture with ring reservoir topology and one-to-one inter-reservoir connections. The proposed design also considers hardware-friendly nonlinearity and noise modeling in the reservoir update equations. We demonstrate the introduced hardware-friendly deep RC architecture in electronic hardware, showing the promising processing capabilities on learning tasks that require both nonlinear computation and short-term memory. Additionally, we validate the effectiveness of the introduced approach on several time-series classification tasks, showing its competitive performance compared to its shallow counterpart, conventional, as well as more recent RC systems. These results emphasize the advantages of the proposed deep architecture for both practical hardware-friendly environments and broader machine learning applications.},
  archive      = {J_NN},
  author       = {Claudio Gallicchio and Miguel C. Soriano},
  doi          = {10.1016/j.neunet.2025.108079},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108079},
  shortjournal = {Neural Netw.},
  title        = {Hardware friendly deep reservoir computing},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning global-view correlation for salient object detection in 3D point clouds. <em>NN</em>, <em>193</em>, 108078. (<a href='https://doi.org/10.1016/j.neunet.2025.108078'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object detection (SOD) in point clouds has been an emerging research topic aimed at extracting most visually attractive objects from 3D point cloud representations. The inherent irregularity and unorderness of 3D point clouds complicate salient object detection, for it is hard to learn regular salient patterns like in 2D images. Meanwhile, existing methods typically focus on per-point context aggregation, while overlooking the scene-level global-view correlation crucial for saliency prediction. In this paper, we explore SOD in point clouds and introduce a novel approach that capitalizes on a comprehensive understanding of global-view 3D scenes. Our proposed method, the Saliency Filtration Network (SFN), meticulously refines saliency representations by isolating them from the common scene-dependent global-view correlations. Most importantly, SFN is characterized by a two-stage strategy, which involves aggregating long-range context information and purify saliency from globally scene-common correlations. To achieve this, we introduce the Residual Relation-aware Transformer module (RRT), which considers human visual perception to exploit global-view context dependencies. Additionally, we propose the Global Bilinear Correlation based Filtration module (GBCF) to perform saliency purification from global-view correlations. GBCF establishes dense correlations between global space and channel descriptors, which are then leveraged to properly purify saliency representations. Experimental evaluations on the PCSOD benchmark demonstrate that our proposed method achieves state-of-the-art accuracy and significantly outperforms other compared methods.},
  archive      = {J_NN},
  author       = {Kan Huang and Nannan Li and Zhijing Xu},
  doi          = {10.1016/j.neunet.2025.108078},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108078},
  shortjournal = {Neural Netw.},
  title        = {Learning global-view correlation for salient object detection in 3D point clouds},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A semi-looped functional for sampled-data synchronization of delayed neural networks considering communication delay. <em>NN</em>, <em>193</em>, 108076. (<a href='https://doi.org/10.1016/j.neunet.2025.108076'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the master-slave synchronization of delayed neural networks (DNNs) using a sampled-data controller with a communication delay. First, a novel semi-looped functional is constructed to incorporate more system information and to feature more relaxed constraints, particularly the negative-definite condition on its derivatives. Second, two zero-value equations are constructed to fully coordinate the relationships among the system information introduced by the proposed functional, thereby providing greater flexibility in synchronization controller design. As a result, the synchronization criterion with reduced conservatism is derived by employing these techniques. This criterion allows for the design of a sampled-data synchronization controller for DNNs that accommodates larger sampling intervals, thus reducing communication and computational burdens. Finally, three widely used numerical examples illustrate the effectiveness and superiority of the proposed criterion.},
  archive      = {J_NN},
  author       = {Yun-Hao An and Xing-Chen Shangguan and Hong-Zhang Wang and Yu-Fei Peng and Yun-Fan Liu and Chuan-Ke Zhang},
  doi          = {10.1016/j.neunet.2025.108076},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108076},
  shortjournal = {Neural Netw.},
  title        = {A semi-looped functional for sampled-data synchronization of delayed neural networks considering communication delay},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantity versus diversity: Influence of data on detecting EEG pathology with advanced ML models. <em>NN</em>, <em>193</em>, 108073. (<a href='https://doi.org/10.1016/j.neunet.2025.108073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the impact of quantity and diversity of data on the performance of various machine-learning models for detecting general EEG pathology. We utilized an EEG dataset of 2993 recordings from Temple University Hospital and a dataset of 55,787 recordings from Elmiko Biosignals sp. z o.o. The latter contains data from 39 hospitals and a diverse patient set with varied conditions. Thus, we introduce the Elmiko dataset – the largest publicly available EEG corpus. Our findings show that small and consistent datasets enable a wide range of models to achieve high accuracy; however, variations in pathological conditions, recording protocols, and labeling standards lead to significant performance degradation. Nonetheless, increasing the number of available recordings improves predictive accuracy and may even compensate for data diversity, particularly in neural networks based on attention mechanism or transformer architecture. A meta-model that combined these networks with a gradient-boosting approach using handcrafted features demonstrated superior performance across varied datasets.},
  archive      = {J_NN},
  author       = {Martyna Poziomska and Marian Dovgialo and Przemysław Olbratowski and Paweł Niedbalski and Paweł Ogniewski and Joanna Zych and Jacek Rogala and Jarosław Żygierewicz},
  doi          = {10.1016/j.neunet.2025.108073},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108073},
  shortjournal = {Neural Netw.},
  title        = {Quantity versus diversity: Influence of data on detecting EEG pathology with advanced ML models},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). From external to internal: Step-wise feature enhancement network for image-text retrieval. <em>NN</em>, <em>193</em>, 108072. (<a href='https://doi.org/10.1016/j.neunet.2025.108072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-Text Retrieval (ITR) is a challenging task due to the inherent inconsistency in feature representations across different modalities, commonly referred to as the “heterogeneity gap”. To bridge this gap, establishing stronger associations between images and texts by capturing semantic cues as comprehensively as possible is an effective approach. However, existing ITR methods cannot completely capture semantic cues derived from a large-scale image-text corpus beyond a single image-text pair. Therefore, we propose a two-layer Step-wise Feature Enhancement (SFE) Network to establish a semantic propagation pathway, guiding semantic information flow progressively from the external layer to the internal layer. In Step 1, External Semantic Cues (ESC) are captured from visual and textual semantic concepts based on patch-level, instance-level, and neighbor-level co-occurrences within an image-text corpus. Then, visual and textual features are enhanced in the external layer with ESC by mining co-occurrences at the patch, instance, and neighbor levels. Note that Instance-level and Neighbor-level co-occurrence belong to cross-modal ESC, which can significantly facilitate modality interaction in the external layer. In step 2, SFE first fuses semantic information propagated from step 1, and then enhances visual and textual features in the internal layer by mining Internal Semantic Cues (ISC) through cross-modal context. Specifically, visual and textual features are concatenated with their corresponding cross-modal contextual features to further enhance modality interaction within the internal layer. Experimental results demonstrate the superiority of the proposed SFE network over state-of-the-art ITR methods.},
  archive      = {J_NN},
  author       = {Jingyao Wang and Zheng Liu and Shanshan Gao and Junhao Xu and Changhao Li},
  doi          = {10.1016/j.neunet.2025.108072},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108072},
  shortjournal = {Neural Netw.},
  title        = {From external to internal: Step-wise feature enhancement network for image-text retrieval},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning from history for personalized federated learning. <em>NN</em>, <em>193</em>, 108071. (<a href='https://doi.org/10.1016/j.neunet.2025.108071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized Federated Learning (pFL) has received extensive attentions, due to its ability to effectively process non-IID data distributed among different clients. However, most of the existing pFL methods focus on the collaboration between global and local models to enrich the personalization process, but ignoring a lot of valuable historical information, which represents the unique learning trajectory of each client. In this paper, we propose a pFL method called FedLFH, which introduces a tracking variable that allows each client to preserve historical information to facilitate personalization. We set up a global feature extractor and a personalized feature extractor for each client, to achieve the effective transfer of knowledge between the global model and the personalized model integrated with historical information. To evaluate the effectiveness, we set up exhaustive experiments on various benchmark datasets. The results show that our method outperforms twelve state-of-the-art methods with different experimental settings.},
  archive      = {J_NN},
  author       = {Yingxun Fu and Shulan Yin and Li Ma and Jie Liu},
  doi          = {10.1016/j.neunet.2025.108071},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108071},
  shortjournal = {Neural Netw.},
  title        = {Learning from history for personalized federated learning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mitigating low-frequency bias: Feature recalibration and frequency attention regularization for adversarial robustness. <em>NN</em>, <em>193</em>, 108070. (<a href='https://doi.org/10.1016/j.neunet.2025.108070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring the robustness of deep neural networks against adversarial attacks remains a fundamental challenge in computer vision. While adversarial training (AT) has emerged as a promising defense strategy, our analysis reveals a critical limitation: AT-trained models exhibit a bias toward low-frequency features while neglecting high-frequency components. This bias is particularly concerning as each frequency component carries distinct and crucial information: low-frequency features encode fundamental structural patterns, while high-frequency features capture intricate details and textures. To address this limitation, we propose High-Frequency Feature Disentanglement and Recalibration (HFDR), a novel module that strategically separates and recalibrates frequency-specific features to capture latent semantic cues. We further introduce frequency attention regularization to harmonize feature extraction across the frequency spectrum and mitigate the inherent low-frequency bias of AT. Extensive experiments on CIFAR-10, CIFAR-100, and ImageNet-1K demonstrate that HFDR consistently enhances adversarial robustness. It achieves a 2.89 % gain on CIFAR-100 with WRN34-10, and improves robustness by 3.09 % on ImageNet-1K, with a 4.89 % gain on ViT-B against AutoAttack. These results highlight the method’s adaptability to both convolutional and transformer-based architectures. Code is available at https://github.com/KejiaZhang-Robust/HFDR .},
  archive      = {J_NN},
  author       = {Kejia Zhang and Juanjuan Weng and Yuanzheng Cai and Shaozi Li and Zhiming Luo},
  doi          = {10.1016/j.neunet.2025.108070},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108070},
  shortjournal = {Neural Netw.},
  title        = {Mitigating low-frequency bias: Feature recalibration and frequency attention regularization for adversarial robustness},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual aggregation based joint-modal similarity hashing for cross-modal retrieval. <em>NN</em>, <em>193</em>, 108069. (<a href='https://doi.org/10.1016/j.neunet.2025.108069'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal hashing aims to leverage hashing functions to map multimodal data into a unified low-dimensional space, realizing efficient cross-modal retrieval. In particular, unsupervised cross-modal hashing methods attract significant attention for not needing external label information. However, in the field of unsupervised cross-modal hashing, there are several pressing issues to address: (1) how to facilitate semantic alignment between modalities, and (2) how to effectively capture the intrinsic relationships between data, thereby constructing a more reliable affinity matrix to assist in the learning of hash codes. In this paper, Dual Aggregation-Based Joint-modal Similarity Hashing (DAJSH) is proposed to overcome these challenges. To enhance cross-modal semantic alignment, we employ a Transformer encoder to fuse image and text features and introduce a contrastive loss to optimize cross-modal consistency. Additionally, for constructing a more reliable affinity matrix to assist hash code learning, we propose a dual-aggregation affinity matrix construction scheme. This scheme integrates intra-modal cosine similarity and Euclidean distance while incorporating cross-modal similarity, thereby maximally preserving cross-modal semantic information. Experimental results demonstrate that our method achieves performance improvements of 1.9 % ∼ 5.1 %, 0.9 % ∼ 5.8 % and 0.6 % ∼ 2.6 % over state-of-the-art approaches on the MIR Flickr, NUS-WIDE and MS COCO benchmark datasets, respectively.},
  archive      = {J_NN},
  author       = {Le Xu and Jun Yin},
  doi          = {10.1016/j.neunet.2025.108069},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108069},
  shortjournal = {Neural Netw.},
  title        = {Dual aggregation based joint-modal similarity hashing for cross-modal retrieval},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Large-margin softmax loss using synthetic virtual class. <em>NN</em>, <em>193</em>, 108068. (<a href='https://doi.org/10.1016/j.neunet.2025.108068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary challenge of large-margin learning lies in designing classifiers with strong discriminative power. Although existing large margin methods have achieved success in various classification tasks, they often suffer from weak task generalization and imbalanced handling of easy and hard samples. In this paper, we propose a margin adaptive synthetic virtual Softmax loss (SV-Softmax), which dynamically generates virtual prototypes by synthesizing embedded features and their corresponding prototypes. These virtual prototypes can adaptively adjust the margin based on the spatial distribution of embedded features, promoting the proximity of embedded features to their corresponding prototypes and creating clear and discriminative decision boundaries. Furthermore, we introduce a virtual prototype insertion strategy based on hard sample mining, where different synthesis strategies are applied to correctly and incorrectly classified samples, emphasizing the importance of hard samples. SV-Softmax is plug-and-play with minimal computational complexity, without requiring feature or weight normalization nor relying on task-specific hyperparameter tuning. Extensive comparative experiments on multiple visual classification and face recognition datasets demonstrate that SV-Softmax achieves competitive or superior performance compared to nine state-of-the-art methods. The code available at: https://github.com/10zhou/SV-Softmax .},
  archive      = {J_NN},
  author       = {Jiuzhou Chen and Xiangyang Huang and Shudong Zhang},
  doi          = {10.1016/j.neunet.2025.108068},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108068},
  shortjournal = {Neural Netw.},
  title        = {Large-margin softmax loss using synthetic virtual class},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TATrack: Target-oriented adaptive vision transformer for UAV tracking. <em>NN</em>, <em>193</em>, 108067. (<a href='https://doi.org/10.1016/j.neunet.2025.108067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) tracking requires accurate target localization from aerial top-down perspectives while operating under the computational constraints of aerial platforms. Current mainstream UAV trackers, constrained by the limited resources, predominantly employ lightweight Convolutional Neural Network (CNN) extractor, coupled with an appearance-based fusion mechanism. The absence of comprehensive target perception significantly constrains the balance between tracking accuracy and computational efficiency. To address this, we propose a target-oriented adaptive vision transformer for UAV tracking, named TATrack. TATrack utilizes a novel efficient transformer model, TA-ViT, to perform joint feature modeling and interaction under the orientation of the target. Specifically, TA-ViT employs an adaptive scoring suspension mechanism, wherein redundant network layers are bypassed when all token scores meet the suspension criteria, thereby enhancing inference speed. Moreover, positional information is utilized as a spatial-temporal prompt to enhance appearance-matching quality over time. By introducing location priors, we strengthen the visual perception of the target, which improves the target orientation and temporal continuity of the predicted position. Extensive experiments conducted across five UAV tracking benchmarks demonstrate that our method achieves an optimal balance between computational efficiency and tracking accuracy. The code will be available publicly.},
  archive      = {J_NN},
  author       = {Wenkang Zhang and Tianyang Xu and Fei Xie and Jinhui Wu and Wankou Yang},
  doi          = {10.1016/j.neunet.2025.108067},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108067},
  shortjournal = {Neural Netw.},
  title        = {TATrack: Target-oriented adaptive vision transformer for UAV tracking},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Auction-guided model diffusion for communication-efficient federated learning on non-IID data. <em>NN</em>, <em>193</em>, 108066. (<a href='https://doi.org/10.1016/j.neunet.2025.108066'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 6G mobile communication systems, various AI-based network functions and applications have been standardized. Federated learning (FL) is adopted as the core learning architecture for 6G systems to avoid privacy leakage from mobile user data. However, in FL, users with non-independent and identically distributed (non-IID) datasets can deteriorate the performance of the global model because the convergence direction of the gradient for each dataset is different, thereby inducing a weight divergence problem. To address this problem, we propose a novel diffusion strategy for machine learning (ML) models (FedDif) to maximize the performance of the global model with non-IID data. FedDif enables the local model to learn different distributions before parameter aggregation by passing the local models to users via device-to-device communication. Furthermore, we theoretically demonstrate that FedDif can circumvent the weight-divergence problem. Based on this theory, we propose a communication-efficient diffusion strategy for ML models that can determine the trade-off between learning performance and communication cost using auction theory. The experimental results show that FedDif improves the top-1 test accuracy by up to 20.07 %p and reduces communication costs by up to 45.27 % compared to FedAvg.},
  archive      = {J_NN},
  author       = {Seyoung Ahn and Soohyeong Kim and Yongseok Kwon and Jiseung Youn and Joohan Park and Sunghyun Cho},
  doi          = {10.1016/j.neunet.2025.108066},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108066},
  shortjournal = {Neural Netw.},
  title        = {Auction-guided model diffusion for communication-efficient federated learning on non-IID data},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dormant key: Unlocking universal adversarial control in text-to-image models. <em>NN</em>, <em>193</em>, 108065. (<a href='https://doi.org/10.1016/j.neunet.2025.108065'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-Image (T2I) diffusion models have gained significant traction due to their remarkable image generation capabilities, raising growing concerns over the security risks associated with their use. Prior studies have shown that malicious users can subtly modify prompts to produce visually misleading or Not-Safe-For-Work (NSFW) content, even bypassing existing safety filters. Existing adversarial attacks are often optimized for specific prompts, limiting their generalizability, and their text-space perturbations are easily detectable by current defenses. To address these limitations, we propose a universal adversarial attack framework called dormant key. It appends a transferable suffix that can be appended as a “plug-in” to any text input to guide the generated image toward a specific target. To ensure robustness across diverse prompts, we introduce a novel hierarchical gradient aggregation strategy that stabilizes optimization over prompt batches. This enables efficient learning of universal perturbations in the text space, improving both attack transferability and imperceptibility. Experimental results show that our method effectively balances attack performance and stealth. In NSFW generation tasks, it bypasses major safety mechanisms, including keyword filtering, semantic analysis, and text classifiers, and achieves over 18 % improvement in success rate over baselines.},
  archive      = {J_NN},
  author       = {Jingqi Hu and Li Li and Hanzhou Wu and Huixin Luo and Xinpeng Zhang},
  doi          = {10.1016/j.neunet.2025.108065},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108065},
  shortjournal = {Neural Netw.},
  title        = {Dormant key: Unlocking universal adversarial control in text-to-image models},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data-free knowledge distillation via text-noise fusion and dynamic adversarial temperature. <em>NN</em>, <em>193</em>, 108061. (<a href='https://doi.org/10.1016/j.neunet.2025.108061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-Free Knowledge Distillation (DFKD) have achieved significant breakthroughs, enabling the effective transfer of knowledge from teacher neural networks to student neural networks without reliance on original data. However, a significant challenge faced by existing methods that attempt to generate samples from random noise is that the noise lacks meaningful information, such as class-specific semantic information. Consequently, the absence of meaningful information makes it difficult for the generator to map this noise to the ground-truth data distribution, resulting in the generation of low-quality training samples. In addition, existing methods typically employ a fixed temperature for adversarial training of the generator, which limits the diversity in the difficulty of the synthesized data. In this paper, we propose Text-Noise Fusion and Dynamic Adversarial Temperature method (TNFDAT), a novel method that combines random noise with meaningful class-specific text embeddings (CSTE) as input and implements dynamic adjustment of the adversarial training temperature for the generator. In addition, we introduce an adaptive sample weighting strategy to enhance the effectiveness of knowledge distillation. CSTE is developed based on a pre-trained language model, and its significance lies in its ability to capture meaningful inter-class information, thereby enabling the generation of high-quality samples. Simultaneously, the dynamic adversarial temperature module effectively alleviates the issue of insufficient diversity in synthesized samples by precisely modulating the generator’s temperature during adversarial training, playing a key role in enhancing sample diversity. Through continuous and dynamic temperature adjustment of the generator in the adversarial training, thereby significantly improving the overall diversity of the synthesized samples. At the knowledge distillation stage, We determine the distillation weights of the synthesized samples based on the information entropy of the output from both teacher and student networks. By differentiating the contributions of different synthesized samples during the distillation process, we effectively enhance the generalization ability of the knowledge distillation framework and improve the robustness of the student network. Experiments demonstrate that our method outperforms the state-of-the-art methods across various benchmarks and pairs of teachers and students.},
  archive      = {J_NN},
  author       = {Deheng Zeng and Zhengyang Wu and Yunwen Chen and Zhenhua Huang},
  doi          = {10.1016/j.neunet.2025.108061},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108061},
  shortjournal = {Neural Netw.},
  title        = {Data-free knowledge distillation via text-noise fusion and dynamic adversarial temperature},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EpilepsyFM: A domain-specific foundation model for epileptic representation learning using EEG signals. <em>NN</em>, <em>193</em>, 108060. (<a href='https://doi.org/10.1016/j.neunet.2025.108060'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy with its complex seizure mechanisms and diverse clinical manifestations, presents numerous challenges for clinical diagnosis and treatment, while electroencephalography (EEG) plays a crucial and irreplaceable role in its diagnosis. Although general-purpose foundation models have demonstrated some capability in knowledge processing, they still face challenges in capturing specific disease features and dealing with data scarcity in highly specialized domains such as epilepsy. To address these issues, we propose a domain-specific foundation model for epilepsy-EpilepsyFM, designed to learn generalized representations of epilepsy to support various downstream tasks. EpilepsyFM utilizes self-supervised pre-training, integrating clinical EEG data from top-tier hospital neurosurgery departments with large-scale public datasets such as TUH EEG Corpus, covering a variety of patient conditions to enhance the model’s representation capacity. The model employs a discrete neural tokenizer to construct a domain-specific neural codebook for epilepsy and proposes a brain region masking strategy based on the mechanisms of clustered neuronal discharges during seizures, allowing for more effective capture of the spatiotemporal features of seizures. Furthermore, EpilepsyFM integrates temporal, spectral, and spatial encoding modules to fully exploit the multidimensional propagation patterns of epilepsy. Experimental results show that EpilepsyFM achieves state-of-the-art performance in six downstream tasks, including seizure detection, seizure type detection, short- and long-term signal forecasting, frequency-phase forecasting, anti-seizure medication efficacy analysis, and radiofrequency thermocoagulation surgery analysis, demonstrating outstanding generalization ability and broad clinical application potential.},
  archive      = {J_NN},
  author       = {Zhuoyi Li and Ning Zhu and Yifan Chen and Beibei Chen and Qiufeng Dong and Lin Gan and Shijie Zhao and Zhiqiang Yan and Tuo Zhang},
  doi          = {10.1016/j.neunet.2025.108060},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108060},
  shortjournal = {Neural Netw.},
  title        = {EpilepsyFM: A domain-specific foundation model for epileptic representation learning using EEG signals},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A spatial-frequency hybrid restoration network for JPEG compressed image deblurring. <em>NN</em>, <em>193</em>, 108059. (<a href='https://doi.org/10.1016/j.neunet.2025.108059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image deblurring and compression-artifact removal are both ill-posed inverse problems in low-level vision tasks. So far, although numerous image deblurring and compression-artifact removal methods have been proposed respectively, the research for explicit handling blur and compression-artifact coexisting degradation image (BCDI) is rare. In the BCDI, image contents will be damaged more seriously, especially for edges and texture details. Therefore, the restoration of the BCDI is a more severe ill-posed inverse problem, and deep mining of local and global feature information is critical for effective BCDI restoration. To this end, we propose a spatial-frequency hybrid restoration network (SFHRN) for explicit and effective joint-photographic-experts-group (JPEG) compressed BCDI restoration. Specifically, according to the nature of JPEG compression artifacts, we propose a spatial-frequency hybrid block (SFHB), which includes a dual-branch structure and an information screening strategy (ISS). First, for the dual-branch structure, we design a patch-level channel attention branch (PCAB) and a pixel-level global attention branch (PGAB) to fully exploit local context information in the spatial domain and mine the global feature information in the frequency domain respectively. Secondly, we design a simple and effective information screening strategy (ISS) to discriminatively determine which pixels and channels should be retained and enhanced in frequency and spatial domains respectively for latent clear image restoration. Finally, for the first time, we build the blur and compression-artifact coexisting degradation datasets by adding various degrees of JPEG compression-artifact into existing benchmark deblurring datasets, e.g. GoPro and HIDE, named as GoPro-Compressed and HIDE-Compressed respectively. Extensive experiments demonstrate the superiority of our proposed SFHRN in terms of both performance and computational cost.},
  archive      = {J_NN},
  author       = {Shu Tang and Hanwen Zhang and Xinbo Gao and Shuli Yang and Jiaxu Leng and Zengdan Pan and Hao Tian},
  doi          = {10.1016/j.neunet.2025.108059},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108059},
  shortjournal = {Neural Netw.},
  title        = {A spatial-frequency hybrid restoration network for JPEG compressed image deblurring},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Region-guided attack on the segment anything model. <em>NN</em>, <em>193</em>, 108058. (<a href='https://doi.org/10.1016/j.neunet.2025.108058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Segment Anything Model (SAM) is a cornerstone of image segmentation, demonstrating exceptional performance across various applications, particularly in autonomous driving and medical imaging, where precise segmentation is crucial. However, SAM is vulnerable to adversarial attacks that can significantly impair its functionality through minor input perturbations. Traditional techniques, such as FGSM and PGD, are often ineffective in segmentation tasks due to their reliance on global perturbations that overlook spatial nuances. Recent methods like Attack-SAM-K and UAD have begun to address these challenges, but they frequently depend on external cues and do not fully leverage the structural interdependencies within segmentation processes. This limitation underscores the need for a novel adversarial strategy that exploits the unique characteristics of segmentation tasks. In response, we introduce the Region-Guided Attack (RGA), designed specifically for SAM. RGA utilizes a Region-Guided Map (RGM) to manipulate segmented regions, enabling targeted perturbations that fragment large segments and expand smaller ones, resulting in erroneous outputs from SAM. Our experiments demonstrate that RGA achieves high success rates in both white-box and black-box scenarios, emphasizing the need for robust defenses against such sophisticated attacks. Our codes are available at https://github.com/AbeLiuXL/RGA .},
  archive      = {J_NN},
  author       = {Xiaoliang Liu and Furao Shen and Jian Zhao},
  doi          = {10.1016/j.neunet.2025.108058},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108058},
  shortjournal = {Neural Netw.},
  title        = {Region-guided attack on the segment anything model},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Inter-modality feature prediction through multimodal fusion for 3D shape defect detection. <em>NN</em>, <em>193</em>, 108057. (<a href='https://doi.org/10.1016/j.neunet.2025.108057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D shape defect detection plays an important role in autonomous industrial inspection. However, accurate detection of anomalies remains challenging due to the complexity of multimodal sensor data, especially when both color and structural information are required. In this work, we propose a lightweight inter-modality feature prediction framework that effectively utilizes multimodal fused features from the inputs of RGB, depth and point clouds for efficient 3D shape defect detection. Our proposed framework consists of three main key components: 1) Modality-specific pre-trained feature extractor networks, 2) Multi-level Adaptive Dual-Modal Gated Fusion (ADMGF) module that effectively combines the RGB and depth features to obtain rich spatial and contextual information. 3) A lightweight inter-modal feature prediction network that utilizes the fused RGB-Depth features to predict the corresponding point cloud features and vice versa, forming a bidirectional learning mechanism through tri-modal inputs. Our model eliminates the need for large memory banks or pixel-level reconstructions. Comprehensive experiments on the MVTec3D-AD and Eyecandies datasets showed significant improvements in performance over the state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Mujtaba Asad and Waqar Azeem and Hafiz Tayyab Mustafa and Yuming Fang and Jie Yang and Yifan Zuo and Wei Liu},
  doi          = {10.1016/j.neunet.2025.108057},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108057},
  shortjournal = {Neural Netw.},
  title        = {Inter-modality feature prediction through multimodal fusion for 3D shape defect detection},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FA-GCL: Feature-augmented graph contrastive learning method. <em>NN</em>, <em>193</em>, 108045. (<a href='https://doi.org/10.1016/j.neunet.2025.108045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph contrastive learning seeks to improve the efficacy of graph representation learning by comparing various graph representations. Existing approaches predominantly rely on node attributes or structural information for contrastive analysis. However, in real-world applications, node attribute information can be incomplete or entirely absent, while structure-enhancement methods often generate false positive samples. To mitigate these issues, we propose a feature augmentation-based graph contrastive learning method (FA-GCL) that enhances the accuracy and robustness of graph representations. Specifically, our approach first implements a dynamic dropout-based feature augmentation technique, which adjusts dropout rates dynamically using a triangular wave function, thereby significantly improving model performance. Additionally, we introduce two complementary feature augmentation methods based on singular value decomposition: a theoretically rigorous full SVD approach and a computationally efficient randomized projection-based SVD method that achieves linear complexity while preserving spectral properties. Both methods add controlled noise to singular values and reconstruct features to create high-quality augmented samples. Comprehensive experiments were conducted on twelve widely used graph datasets. The results indicate that FA-GCL consistently outperforms baseline methods in node classification, node clustering, and graph classification tasks.},
  archive      = {J_NN},
  author       = {Long Xu and Honghui Chen},
  doi          = {10.1016/j.neunet.2025.108045},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108045},
  shortjournal = {Neural Netw.},
  title        = {FA-GCL: Feature-augmented graph contrastive learning method},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploring the white matter disruptions for schizophrenia based on convolutional ensemble kernel randomized network. <em>NN</em>, <em>193</em>, 108044. (<a href='https://doi.org/10.1016/j.neunet.2025.108044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Schizophrenia (SZ) is characterized by cognitive impairments and widespread structural brain alterations. The potential adaptability of convolutional neural networks (CNN) to identify the complex and extensive brain alterations associated with SZ relies on its automatic feature learning capability. Structural magnetic resonance imaging (sMRI) is a non-invasive technique for investigating disruptions related to white matter (WM), grey matter (GM), and cerebrospinal fluid (CSF) of brain regions. We proposed an intrinsic CNN ensemble of kernel ridge regression-based random vector functional link (KRR-RVFL) architecture to explore the WM disruptions for SZ. In this approach, we have integrated an eight-layer CNN into five different KRR-RVFL classifiers for feature extraction and classification. The classifiers’ outputs are averaged and fed to the final KRR-RVFL classifier for final classification. The KRR-RVFL classifier enhances stability and robustness by addressing non-linearity limitations in the standard RVFL network. The proposed CNN ensemble KRR-RVFL outperforms other classifiers with 97.33 % accuracy for the WM region, showing significant disruptions compared to GM and CSF. Furthermore, we calculated the correlation coefficient between tissue volumes and the scale of symptoms for GM and WM. According to the results, tissue volume for WM is reduced more than GM for SZ. The proposed model assists clinicians in exploring the role of WM disruptions for accurate diagnosis of SZ.},
  archive      = {J_NN},
  author       = {S.A. Varaprasad and Tripti Goel and M. Tanveer},
  doi          = {10.1016/j.neunet.2025.108044},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108044},
  shortjournal = {Neural Netw.},
  title        = {Exploring the white matter disruptions for schizophrenia based on convolutional ensemble kernel randomized network},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tangency portfolios using graph neural networks. <em>NN</em>, <em>193</em>, 108043. (<a href='https://doi.org/10.1016/j.neunet.2025.108043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to modern portfolio theory, the weights of tangency portfolios are solely determined by the expected returns and the covariance matrix of asset returns. However, estimating expected returns and the covariance matrix poses significant challenges, especially when the number of assets is large. Considering the supply-demand relationships between companies issuing stocks, we propose that incorporating industry chain relationships can enhance the accurate estimation of the covariance matrix. Specifically, we present a method that employs Graph Neural Networks (GNNs) to estimate tangency portfolio weights by aggregating stock features based on the industry chain graph and using the aggregated features to estimate the expected returns and the covariance matrix. In addition to incorporating additional industry information, we propose two strategies to enhance the efficiency of estimation: 1) Calculating the dynamic modularity of the stock relationship graph using aggregated node features and constraining the estimated correlations to exhibit a clustered structure by minimizing modularity. 2) Adding a historical ranking regularization to the expected returns. We validate our approach on two daily stock datasets, demonstrating that our method effectively predicts portfolio returns and Sharpe ratios.},
  archive      = {J_NN},
  author       = {Bin Liu and Haolong Li and Linshuang Kang},
  doi          = {10.1016/j.neunet.2025.108043},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108043},
  shortjournal = {Neural Netw.},
  title        = {Tangency portfolios using graph neural networks},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-perspective decoupling network for kidney tumor segmentation on CT images. <em>NN</em>, <em>193</em>, 108042. (<a href='https://doi.org/10.1016/j.neunet.2025.108042'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key challenges in kidney tumor segmentation include unpredictable location, high similarity among objects, and variability in boundaries. Existing approaches mostly handle these challenges from an object-agnostic perspective or a single decoupling perspective, which limits their ability to address all the aforementioned challenges. To tackle these problems, we propose a Dual-perspective Decoupling Network (DDNet), which consists of the Dual-perspective Decoupling Module (DDM) and the Edge Refinement Module (ERM). The DDM decouples features from two perspectives: body/edge decoupling and inter-object decoupling. In order to decouple the body and edge, we propose the Multi-scale Decoupling Branch (MDB), which employs multi-scale convolutions to increase the receptive field and improve object localization by aggregating objects toward the center. It then decouples the body and boundary. The Object Decoupling Branch (ODB) employs prediction maps to perform self-attention and selectively decouples background, kidney, and tumor to enhance the final body part segmentation. In order to make full use of the decoupled boundary information from the MDB, the ERM utilizes boundary features derived from the MDB to effectively guide the encoder’s low-level features to overcome boundary variability and generate more precise boundaries. We evaluate DDNet on two different public kidney tumor segmentation datasets (KiTS19 and KiTS21) and a clinical dataset, called KAT-Seg. Compared to eleven other state-of-the-art segmentation methods, our DDNet yields the best Dice score of 86.08 %, 85.45 % and 88.03 % on KiTS19, KiTS21 and KAT-Seg, respectively, which is at least 1.63 %, 0.72 % and 1.72 % higher than the other methods.},
  archive      = {J_NN},
  author       = {Xinya Gan and Sheng Zhu and Yuan Zhang and Zhiqiang Wang and Xiongjun Ye and Kai Hu and Xieping Gao},
  doi          = {10.1016/j.neunet.2025.108042},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108042},
  shortjournal = {Neural Netw.},
  title        = {Dual-perspective decoupling network for kidney tumor segmentation on CT images},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stabilization of delayed stochastic reaction-diffusion cohen-grossberg neural networks via variable gain intermittent boundary control. <em>NN</em>, <em>193</em>, 108041. (<a href='https://doi.org/10.1016/j.neunet.2025.108041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel variable gain intermittent boundary control (VGIBC) approach for stabilizing delayed stochastic reaction-diffusion Cohen-Grossberg neural networks (SRDCGNN). In contrast to traditional constant gain intermittent boundary control (CGIBC) methods, the proposed VGIBC framework dynamically adjusts the control gain based on the operational duration within each control cycle, thereby improving adaptability to variations in work interval lengths. The time-varying control gain is designed using a piecewise interpolation method across work intervals, defined by a finite set of static gain matrices. To address the switching dynamics of the intermittently controlled neural networks and exploit the flexibility offered by the dynamic control gain, a piecewise Lyapunov function is employed to fit the dynamic structure of the control gain. By applying distinct Razumikhin-based solution estimation techniques: one tailored to active control periods and the other to rest periods, new mean square intermittent stabilization criteria are derived that show reduced conservatism compared to CGIBC-based results. The optimal control gain function is determined by solving a convex optimization procedure that minimizes the control rate at a given level of gain norm limitation. The efficacy of the proposed VGIBC strategy is validated through two numerical examples.},
  archive      = {J_NN},
  author       = {Yili Wang and Wu-Hua Chen and Shuning Niu and Xiaoyun Lu},
  doi          = {10.1016/j.neunet.2025.108041},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108041},
  shortjournal = {Neural Netw.},
  title        = {Stabilization of delayed stochastic reaction-diffusion cohen-grossberg neural networks via variable gain intermittent boundary control},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploring the mechanical behavior of friction material composites using artificial intelligence. <em>NN</em>, <em>193</em>, 108040. (<a href='https://doi.org/10.1016/j.neunet.2025.108040'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of artificial intelligence techniques is becoming increasingly valuable for several areas of knowledge, allowing to extract information, predict patterns, work with complex problems, and generate solutions that would not be achievable by other techniques without an extremely high computational cost or else, numerous physical experiments, with high execution costs and which often do not achieve the desired result. In this work, artificial intelligence (AI) was used to create mathematical models for four properties of friction material composites from an extensive database containing the chemical composition and the respective mechanical properties. An algorithm capable of predicting mechanical results of friction materials based on chemical composition, optimizing an existing composition, and proposing new (previously non-existent) compositions was proposed based on the desired values of each mechanical property. The algorithm combines rule-based instructions, neural networks, and particle swarm optimization. Physical samples based on the algorithm’s prediction were produced, making it possible to assess the predictive power of the models and further understand the need for improvements in the tool built for predicting new friction materials. The root mean square error (RMSE) of predictions from multilinear models was significantly higher than those from artificial neural networks when predicting results of non-existent previous compositions. The smallest observed increase in RMSE was 20.9 %, while the largest was 90.2 %. On average, the RMSE for multilinear models was 48.6 % larger, highlighting the superior accuracy of neural network predictions from previously non-existent compositions.},
  archive      = {J_NN},
  author       = {D. Matté and C.A. Perottoni},
  doi          = {10.1016/j.neunet.2025.108040},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108040},
  shortjournal = {Neural Netw.},
  title        = {Exploring the mechanical behavior of friction material composites using artificial intelligence},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). State-space modeling in long sequence processing: A survey on recurrence in the transformer era. <em>NN</em>, <em>193</em>, 108039. (<a href='https://doi.org/10.1016/j.neunet.2025.108039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively learning from sequential data is a longstanding goal of Artificial Intelligence, especially in the case of long sequences. From the dawn of Machine Learning, several researchers have pursued algorithms and architectures capable of processing sequences of patterns, retaining information about past inputs while still leveraging future data, without losing precious long-term dependencies and correlations. While such an ultimate goal is inspired by the human hallmark of continuous real-time processing of sensory information, several solutions have simplified the learning paradigm by artificially limiting the processed context or dealing with sequences of limited length, given in advance. These solutions were further emphasized by the ubiquity of Transformers, which initially overshadowed the role of Recurrent Neural Nets. However, recurrent networks are currently experiencing a strong recent revival due to the growing popularity of (deep) State-Space models and novel instances of large-context Transformers, which are both based on recurrent computations that aim to go beyond several limits of currently ubiquitous technologies. The fast development of Large Language Models has renewed the interest in efficient solutions to process data over time. This survey provides an in-depth summary of the latest approaches that are based on recurrent models for sequential data processing. A complete taxonomy of recent trends in architectural and algorithmic solutions is reported and discussed, guiding researchers in this appealing research field. The emerging picture suggests that there is room for exploring novel routes, constituted by learning algorithms that depart from the standard Backpropagation Through Time, towards a more realistic scenario where patterns are effectively processed online, leveraging local-forward computations, and opening new directions for research on this topic.},
  archive      = {J_NN},
  author       = {Matteo Tiezzi and Michele Casoni and Alessandro Betti and Marco Gori and Stefano Melacci},
  doi          = {10.1016/j.neunet.2025.108039},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108039},
  shortjournal = {Neural Netw.},
  title        = {State-space modeling in long sequence processing: A survey on recurrence in the transformer era},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Heterogeneity-aware high-efficiency federated learning with hybrid synchronous-asynchronous splitting strategy. <em>NN</em>, <em>193</em>, 108038. (<a href='https://doi.org/10.1016/j.neunet.2025.108038'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) offers a promising privacy-preserving framework for collaborative global model training without exposing local private data. However, system heterogeneity in FL causes the straggler issue, where resource-limited edge devices delay global model aggregation. Existing approaches, such as asynchronous mechanisms or kick-out methods, primarily focus on optimizing model convergence efficiency but often overlook edge resource constraints, potentially resulting in model bias toward high-performance devices or omission of critical data. To cope with this, we propose HA-HEFL, a novel Heterogeneity-Aware High-Efficiency Federated Learning framework to balance training efficiency, model accuracy, and resource consumption. HA-HEFL features a resource-aware adaptive model customization mechanism that dynamically tailors suitable model architectures based on device capabilities using neuron-level profiling and priority-based selection methods. Additionally, HA-HEFL employs a hybrid synchronous-asynchronous split training strategy, dividing into synchronous edge feature extraction and asynchronous global classifier updates based on knowledge distillation, thereby enhancing training efficiency and model performance. A baseline-prioritized weighted aggregation scheme is adopted to further ensure balanced global model updates. Extensive experiments on three real-world datasets demonstrate that HA-HEFL significantly improves convergence speed, model accuracy, and reduces network traffic compared to state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Zijian Li and Boyuan Li and Kunyu Zhang and Bingcai Wei and Hongbo Liu and Zihan Chen and Xinqiang Xie and Tony Q.S. Quek},
  doi          = {10.1016/j.neunet.2025.108038},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108038},
  shortjournal = {Neural Netw.},
  title        = {Heterogeneity-aware high-efficiency federated learning with hybrid synchronous-asynchronous splitting strategy},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PathTGSeg: The pathologic image segmentation of breast cancer via template matching and graphic calculation. <em>NN</em>, <em>193</em>, 108037. (<a href='https://doi.org/10.1016/j.neunet.2025.108037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pathologic image analysis is important for providing fundamental references for the clinical diagnosis of breast cancer. Although many methods have achieved outstanding performance in the pathologic image segmentation of breast cancer, there are still two issues limiting further development in this task. First, diverse and complex appearances exist within the observed scope for the same type of breast cancer. Second, inconsistent distribution and ambiguous borders of cancer tissues also pose challenges to obtaining accurate diagnoses of tumor regions. Therefore, to address these issues, this work proposes a template and graphic visual transformer network to perform pathologic image segmentation of breast cancer. The template visual transformer introduces a novel segmentation pattern that leverages templates selected from typical cases of breast cancer to locate cancer lesions by comparing the similarity between the templates and latent regions. Meanwhile, the graphic visual transformer builds graphical features to describe the distribution relationships of cancer lesions more accurately. Extensive experiments conducted on BIS5k and other zero-shot datasets show that our method not only achieves more robust performance on pathologic images of breast cancer when pretrained on data of the same type, but also demonstrates great potential on zero-shot pathologic images.},
  archive      = {J_NN},
  author       = {Junjie Li and Kaixiang Yan and Chuandong Guo},
  doi          = {10.1016/j.neunet.2025.108037},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108037},
  shortjournal = {Neural Netw.},
  title        = {PathTGSeg: The pathologic image segmentation of breast cancer via template matching and graphic calculation},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MSG: Stealing data from pruned neural networks via malicious sparsity guidance. <em>NN</em>, <em>193</em>, 108036. (<a href='https://doi.org/10.1016/j.neunet.2025.108036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread adoption of machine learning cloud platforms, concerns over potential privacy risks in model training algorithms have grown. Attackers can exploit these platforms by deploying malicious algorithms to execute correlation value encoding attacks (CVEA). This attack mainly leverages the model’s huge capacity for memorization, covertly embedding training data into the model’s parameters. Once the model is published, attackers can extract these parameters and recover sensitive data. In this paper, we empirically demonstrate for the first time that common model pruning techniques significantly diminish the effectiveness and stealthiness of CVEA, as they reduce redundant parameters. We further propose a new pruning-resistant parameter encoding attack via Malicious Sparsity Guidance (MSG), which strategically embeds data into a selected subset of model parameters while actively guiding the pruning process. Specifically, MSG manipulates parameter importance during training to increase the likelihood that the parameters carrying embedded information are preserved after pruning. To further enhance stealthiness, we integrate knowledge transfer, allowing the encoded model to maintain high prediction accuracy before and after pruning. Comprehensive experiments across seven datasets and five model architectures demonstrate that MSG enables attackers to extract high-quality training data before and after model pruning. Moreover, knowledge transfer significantly narrows the accuracy gap between the pruned and unpruned encoded models, making the attack more inconspicuous.},
  archive      = {J_NN},
  author       = {Jing Shang and Jian Wang and Kailun Wang and Nan Jiang and Jiqiang Liu},
  doi          = {10.1016/j.neunet.2025.108036},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108036},
  shortjournal = {Neural Netw.},
  title        = {MSG: Stealing data from pruned neural networks via malicious sparsity guidance},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-graph clustering via multi-modal topological manifold learning. <em>NN</em>, <em>193</em>, 108035. (<a href='https://doi.org/10.1016/j.neunet.2025.108035'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view spectral clustering has drawn widespread interest in light of its sufficiency of exploring hidden structure details among samples. However, most existing approaches merely concentrate on constructing similarity graph by computing the geometric distance among any two samples using the Euclidean formula, which limits their ability to accurately measure the relationship with far apart but high similarity. Moreover, they implement integration step in the similarity graph construction stage in which the early fusion results in information loss. To solve these problems, we develop a novel multi-view clustering method, namely, Multi-graph Clustering via Multi-modal Topological Manifold Learning (MC_MTML). Specifically, the initial affinity graphs are firstly generated by employing K-Nearest Neighbor (KNN) algorithm. Then, learning similarity matrices by introducing the topological manifold learning mechanism. Finally, the common consensus representation of spectral embedding is derived from the similarity matrixes which can not merely incorporate the consensus structure knowledge from all view features but also reduce the information loss. An efficient alternate iterating algorithm is developed to resolve the resulting optimization issue. The experiments are conducted on a toy data set and five multi-view data sets. Extensive experimental results demonstrate the effectiveness of proposed MC_MTML algorithm comparing with eight state-of-the-art multi-view clustering methods.},
  archive      = {J_NN},
  author       = {Shaojun Shi and Canyu Zhang and Jiahao Zhao and Feiping Nie},
  doi          = {10.1016/j.neunet.2025.108035},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108035},
  shortjournal = {Neural Netw.},
  title        = {Multi-graph clustering via multi-modal topological manifold learning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Scalable and effective negative sample generation for hyperedge prediction. <em>NN</em>, <em>193</em>, 108034. (<a href='https://doi.org/10.1016/j.neunet.2025.108034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypergraphs have demonstrated their superiority in modeling complex systems compared to traditional graphs by directly capturing the interactions among multiple entities. Hyperedge prediction, which aims to predict unobserved potential hyperedges, is a fundamental task in hypergraph analysis. A critical component in hyperedge prediction is the sampling of informative negative hyperedges from significantly larger candidate negative sets, compared to traditional graphs, to enhance model training efficacy. Most existing methods utilize predefined heuristics to sample negative hyperedges, resulting in limited generalizability due to their reliance on these predefined rules. The new state-of-the-art in this field is generation-based methods, which treat negative sampling as a generative task. Nevertheless, current generation-based approaches are not scalable to large hypergraphs . Additionally, diffusion models have demonstrated superior performance in numerous generative tasks, yet their potential application in the generation of negative hyperedges remains unexplored. However, the adaptation of diffusion models to this specific task presents challenges due to: (1) diffusion models are inherently designed to generate high-quality positive samples, which are well-defined, as opposed to negative samples; (2) diffusion models are traditionally employed in continuous space, whereas negative sampling for hyperedge prediction operates in discrete space. To address these complexities, we introduce SEHP (Scalable and Effective Negative Sample Generation for Hyperedge Prediction), which employs a conditional diffusion model to iteratively generate and refine negative hyperedges, thereby advancing them towards the decision boundary to improve model performance. SEHP further enhances scalability by effectively sampling sub-hypergraphs, integrating global structural information into the diffusion model for batch training. Extensive experiments conducted on real-world datasets demonstrate that SEHP surpasses existing state-of-the-art methods in both prediction accuracy and scalability. The code of our paper is available at https://github.com/SLQu/SEHP},
  archive      = {J_NN},
  author       = {Shilin Qu and Weiqing Wang and Yuan-Fang Li and Quoc Viet Hung Nguyen and Hongzhi Yin},
  doi          = {10.1016/j.neunet.2025.108034},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108034},
  shortjournal = {Neural Netw.},
  title        = {Scalable and effective negative sample generation for hyperedge prediction},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Finite-time and fixed-time self-triggered synchronization of stochastic memristive neural networks and applications in secure communication. <em>NN</em>, <em>193</em>, 108033. (<a href='https://doi.org/10.1016/j.neunet.2025.108033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic characteristics of memristive neural networks (MNNs) can be affected by multiple environmental factors. With that in mind, this paper simultaneously considers the comprehensive effects of stochastic disturbance, external input and actuator hysteresis on the MNNs. Firstly, the driving-response stochastic MNNs (SMNNs) subjected to external inputs and hysteresis are introduced, along with a class of secure communication schemes constructed based on this system. Next, definitions of asymptotically, finite-time, and fixed-time synchronization in probability for the considered system are proposed. Following, some synchronization strategies are given by using the self-triggered control method and Lyapunov stability theories. The designed controllers can ensure the finite-/fixed-time synchronization in probability of the SMNNs, as well as the asymptotically synchronization of the secure communication system. Finally, three simulations and comparative experiments demonstrate the proposed strategies’ effectiveness.},
  archive      = {J_NN},
  author       = {Mingxin Wang and Song Zhu and Weiwei Luo and Zhen Zhang},
  doi          = {10.1016/j.neunet.2025.108033},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108033},
  shortjournal = {Neural Netw.},
  title        = {Finite-time and fixed-time self-triggered synchronization of stochastic memristive neural networks and applications in secure communication},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Broad learning system via adaptive maximum weighted correntropy. <em>NN</em>, <em>193</em>, 108032. (<a href='https://doi.org/10.1016/j.neunet.2025.108032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broad Learning System (BLS) is widely used in various regression problems due to its simple structure and strong generalization ability. The standard optimized method for BLS is sensitive to the noise and outliers since it uses the Minimum Mean Square Error (MMSE) criterion, which may decrease the model’s accuracy. As a solution, an Adaptive Maximum Weighted Correntropy - based BLS (AMWC-BLS) is proposed in this paper. Firstly, an adaptive maximum weighted correntropy criterion is presented to improve the performance and generalization ability of the model. Then, the AMWC-BLS is establised by embedding the AMWC criterion into the BLS. The proposed AMWC-BLS model can adjust its output weights facing the distinct characteristics of the input data and optimizing local data features. Hence, the AMWC-BLS model is able to better withstand the effects of outliers and noise and improve the robustness. Finally, the robustness and effectiveness of AMWC-BLS are demonstrated through the experiments on regression datasets.},
  archive      = {J_NN},
  author       = {Yijing Wang and Lijie Wang and Tao Chen},
  doi          = {10.1016/j.neunet.2025.108032},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108032},
  shortjournal = {Neural Netw.},
  title        = {Broad learning system via adaptive maximum weighted correntropy},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Complexity of brain-like signals in self-organised nanoscale networks. <em>NN</em>, <em>193</em>, 108031. (<a href='https://doi.org/10.1016/j.neunet.2025.108031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The biological brain is comprised of a complex, interconnected, self-assembled network of neurons and synapses. This network enables efficient and accurate information processing, unsurpassed by any other known computational system. Percolating networks of nanoparticles (PNNs) are complex, interconnected, self-assembled systems that exhibit many emergent brain-like characteristics. Notably, neuron-like spiking patterns from PNNs have been shown to be critical, similar to signals from the cortex. PNNs are therefore an appealing candidate for neuromorphic computational systems. Here, the inherent complexity of the patterns of switching events generated by PNNs is explored using several different measures. We begin by defining qualitative measures of spatial, temporal, and spatio-temporal complexity, and then investigate a quantitative measure of complexity that was developed for analysis of patterns of spikes from neurons in the cortex. We discuss adaptations of the method that are required for data from the electronic devices of interest and the impact of various pre-processing procedures on the analysis. Through these measures, it is shown that the neuron-like spiking patterns from PNNs are indeed complex and are clearly distinct from random and ordered data.},
  archive      = {J_NN},
  author       = {Jamie K. Steel and Ford Wagner and Edoardo Galli and Susant K. Acharya and Joshua B. Mallinson and Philip J. Bones and Matthew D. Arnold and Simon A. Brown},
  doi          = {10.1016/j.neunet.2025.108031},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108031},
  shortjournal = {Neural Netw.},
  title        = {Complexity of brain-like signals in self-organised nanoscale networks},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GIMS: Image matching system based on adaptive graph construction and graph neural network. <em>NN</em>, <em>193</em>, 108030. (<a href='https://doi.org/10.1016/j.neunet.2025.108030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature-based image matching has extensive applications in computer vision. Keypoints detected in images can be naturally represented as graph structures, and Graph Neural Networks (GNNs) have been shown to outperform traditional deep learning techniques. Consequently, the paradigm of image matching via GNNs has gained significant prominence in recent academic research. In this paper, we first introduce an innovative adaptive graph construction method that utilizes a filtering mechanism based on distance and dynamic threshold similarity. This method dynamically adjusts the criteria for incorporating new vertices based on the characteristics of existing vertices, allowing for the construction of more precise and robust graph structures while avoiding redundancy. We further combine the vertex processing capabilities of GNNs with the global awareness capabilities of Transformers to enhance the model’s representation of spatial and feature information within graph structures. This hybrid model provides a deeper understanding of the interrelationships between vertices and their contributions to the matching process. Additionally, we employ the Sinkhorn algorithm to iteratively solve for optimal matching results. Finally, we validate our system using extensive image datasets and conduct comprehensive comparative experiments. Experimental results demonstrate that our system achieves an average improvement of 3.8 × – 40.3 × in overall matching performance. Additionally, the number of vertices and edges significantly impacts training efficiency and memory usage; therefore, we employ multi-GPU technology to accelerate the training process. Our code is available at https://github.com/songxf1024/GIMS .},
  archive      = {J_NN},
  author       = {Xianfeng Song and Yi Zou and Zheng Shi and Zheng Liu},
  doi          = {10.1016/j.neunet.2025.108030},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108030},
  shortjournal = {Neural Netw.},
  title        = {GIMS: Image matching system based on adaptive graph construction and graph neural network},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the application of neural networks for structured domains to fMRI data. <em>NN</em>, <em>193</em>, 108029. (<a href='https://doi.org/10.1016/j.neunet.2025.108029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional Magnetic Resonance Imaging (fMRI) provides spatio-temporal maps of brain activity; however, extracting the rich information they contain is challenging. Traditional approaches use only summary statistics, losing details that might be hidden in the complex temporal dynamics. Deep neural networks are emerging as an apt solution in this context, given their ability to handle vast amounts of structured data. In this paper, we consider two widely studied fMRI datasets: the Human Connectome Project for connectome fingerprinting, and ABIDE for autism classification. We aim to understand how handling the temporal and spatial dimensions could influence the performance of the models and their interpretability. Specifically, we compare neural network models with architectural biases toward temporal, spatial, or combined spatio-temporal features. The results of our analysis show that existing methods exploiting the spatial dimension, or spatio-temporal hybrids, are not competitive with simpler ones considering the temporal dimension only, such as LSTM. Additionally, we propose a contrastive learning approach for connectome fingerprinting, enabling robust individual identification without requiring access to all subjects during training. Our findings suggest that explicit graph modeling of the interaction between brain regions introduces complexity without improving performance, thereby challenging current trends.},
  archive      = {J_NN},
  author       = {Giovanni Donghi and Luca Pasa and Michele De Filippo De Grazia and Alberto Testolin and Marco Zorzi and Alessandro Sperduti and Nicolò Navarin},
  doi          = {10.1016/j.neunet.2025.108029},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108029},
  shortjournal = {Neural Netw.},
  title        = {On the application of neural networks for structured domains to fMRI data},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Beyond single perspective bias: Fusing personalized and common preferences for comprehensive personal preference learning. <em>NN</em>, <em>193</em>, 108028. (<a href='https://doi.org/10.1016/j.neunet.2025.108028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recommendation systems, Graph Convolutional Network (GCN)-based models are generally influenced by popular items. Over-emphasizing these items can lead to a single-perspective bias that overshadows the learning of the user’s personalized preferences. Therefore, existing GCN-based models usually suppress information from popular items. However, as popular items with rich interactions contain the user’s common preference information, such approaches may introduce another single-perspective bias that neglects the learning of the user’s common preferences. Contrary to the prevailing assumption, we argue that personalized and common preferences are not mutually exclusive. Thus, we propose P&CGCN to collaboratively fuse them within a unified framework. This unified framework includes two parts: intra-layer aggregation and inter-layer combination. Specifically, in intra-layer aggregation, we design P&C degree to quantify the manifestation of personal preferences in each item, adaptively discerning whether it reflects personalized or common preferences without explicit separation. The P&C degree-based intra-layer aggregation guides context-aware integration of both preference aspects at each layer. In inter-layer combination, we design P&C depth to quantify the importance of each layer. The P&C depth-based inter-layer combination systematically prioritizes shallow-layer personalized preference signals while strategically leveraging deep-layer common preference signals. Comparative experiments on four real-world datasets demonstrate the performance and efficiency of P&CGCN. In particular, on sparse large datasets, the performance of P&CGCN has improved by around 20 % compared to LightGCN, with at least a 2x speedup in training efficiency.},
  archive      = {J_NN},
  author       = {JiaXin Wu and Guangxiong Chen and Chenglong Pang and Jie Zhao and Eric W.K. See-To},
  doi          = {10.1016/j.neunet.2025.108028},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108028},
  shortjournal = {Neural Netw.},
  title        = {Beyond single perspective bias: Fusing personalized and common preferences for comprehensive personal preference learning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mitigating spectral bias in neural operators via high-frequency scaling for physical systems. <em>NN</em>, <em>193</em>, 108027. (<a href='https://doi.org/10.1016/j.neunet.2025.108027'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural operators have emerged as powerful surrogates for modeling complex physical problems. However, they suffer from spectral bias making them oblivious to high-frequency modes, which are present in multiscale physical systems. Therefore, they tend to produce over-smoothed solutions, which is particularly problematic in modeling turbulence and for systems with intricate patterns and sharp gradients such as multi-phase flow systems. In this work, we introduce a new approach named high-frequency scaling (HFS) to mitigate spectral bias in convolutional-based neural operators. By integrating HFS with proper variants of UNet, we demonstrate a higher prediction accuracy by mitigating spectral bias in single and two-phase flow problems. Unlike Fourier-based techniques, HFS is directly applied to the latent space, thus eliminating the computational cost associated with the Fourier transform. Additionally, we investigate alternative spectral bias mitigation through a diffusion model conditioned on neural operators. While the diffusion model integrated with the standard neural operator may still suffer from significant errors, these errors are substantially reduced when the diffusion model is integrated with a HFS-enhanced neural operator.},
  archive      = {J_NN},
  author       = {Siavash Khodakarami and Vivek Oommen and Aniruddha Bora and George Em Karniadakis},
  doi          = {10.1016/j.neunet.2025.108027},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108027},
  shortjournal = {Neural Netw.},
  title        = {Mitigating spectral bias in neural operators via high-frequency scaling for physical systems},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Raw event-based adversarial attacks for spiking neural networks with configurable latencies. <em>NN</em>, <em>193</em>, 108026. (<a href='https://doi.org/10.1016/j.neunet.2025.108026'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) and data from Dynamic Vision Sensors (DVSs) offer energy-efficient solutions for edge devices with limited battery life. The input latencies of event data to SNNs are critical for energy savings, and reducing these latencies through configurable parameters is essential. However, security concerns, particularly adversarial attacks on SNNs, are increasingly significant. While most existing research primarily focuses on attacking event sequences, which may not always be accessible, attacks on raw event streams with configurable latencies remain underexplored due to challenges such as extreme sparsity and the complexity of discrete optimization. This paper proposes a novel adversarial attack method on raw event streams with configurable latencies. To address sparsity and discrete optimization, we smooth the optimization by converting binary spikes into continuous values. Furthermore, we introduce an adaptively stochastic strategy for sampling attacking latencies. We apply regularization terms to maintain sparsity and ensure adversarial samples resemble raw event streams while approximating the target label. Extensive experiments on datasets such as N-MNIST, CIFAR10-DVS, N-Caltech-101, and Gesture-DVS demonstrate that our method consistently outperforms existing approaches, achieving higher attack success rates (ASR) across various latencies. Ablation studies validate the effectiveness of our contributions and highlight the impact of latency on the generation of adversarial samples.},
  archive      = {J_NN},
  author       = {Xiao Du and Wanli Shi and Xiaohan Zhao and Yang Cao and Bin Gu and Tieru Wu},
  doi          = {10.1016/j.neunet.2025.108026},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108026},
  shortjournal = {Neural Netw.},
  title        = {Raw event-based adversarial attacks for spiking neural networks with configurable latencies},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Backdoor samples detection based on perturbation discrepancy consistency in pre-trained language models. <em>NN</em>, <em>193</em>, 108025. (<a href='https://doi.org/10.1016/j.neunet.2025.108025'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of unvetted third-party and internet data renders pre-trained models susceptible to backdoor attacks. Detecting backdoor samples is critical to prevent backdoor activation during inference or injection during training. However, existing detection methods often require the defender to have access to the poisoned models, extra clean samples, or significant computational resources to detect backdoor samples, limiting their practicality. To address this limitation, we propose a backdoor sample detection method based on perturbatio N discr E pancy consis T ency E valuation (NETE). This is a novel detection method that can be used both pre-training and post-training phases. In the detection process, it only requires an off-the-shelf pre-trained model to compute the log probability of samples and an automated function based on a mask-filling strategy to generate perturbations. Our method is based on the interesting phenomenon that the change in perturbation discrepancy for backdoor samples is smaller than that for clean samples. Based on this phenomenon, we use curvature to measure the discrepancy in log probabilities between different perturbed samples and input samples, thereby evaluating the consistency of the perturbation discrepancy to determine whether the input sample is a backdoor sample. Experiments conducted on four typical backdoor attacks and five types of large language model backdoor attacks demonstrate that our detection strategy outperforms existing zero-shot black-box detection methods.},
  archive      = {J_NN},
  author       = {Zuquan Peng and Jianming Fu and Lixin Zou and Li Zheng and Yanzhen Ren and Guojun Peng},
  doi          = {10.1016/j.neunet.2025.108025},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108025},
  shortjournal = {Neural Netw.},
  title        = {Backdoor samples detection based on perturbation discrepancy consistency in pre-trained language models},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MSFI: Multi-timescale spatio-temporal features integration in spiking neural networks. <em>NN</em>, <em>193</em>, 108024. (<a href='https://doi.org/10.1016/j.neunet.2025.108024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic vision sensors (DVS) asynchronously encode the polarity of brightness changes with high temporal resolution and a wide dynamic range, making them ideal for capturing temporal information. Spiking neural networks (SNNs) are well-suited for handling such event streams due to their inherent temporal information processing capability. However, existing SNNs only transmit membrane potential across timesteps, neglecting spatial dependencies and failing to extract complex temporal features. To overcome this limitation, we propose a novel plug-and-play module, the Multi-timescale Spatio-temporal Features Integration (MSFI) module. MSFI is specifically designed to extract various spatiotemporal features and fuse them with the original spiking features to enhance the representative capabilities of SNNs. MSFI comprises the Short-term Spatio-temporal Module (SSM) and the Long-term Spatio-temporal Module (LSM), which extract short-term and long-term spatio-temporal features. Our proposed MSFI improves the performance of SNNs on several neuromorphic and static datasets, including CIFAR10-DVS, DVS128 Gesture, DVS128 Gait, CIFAR10/100, and ImageNet datasets. Experimental results on these datasets show that our MSFI significantly outperforms the baselines. Our codes are available at https://github.com/dfxue/MSFI},
  archive      = {J_NN},
  author       = {Dengfeng Xue and Wenjuan Li and Chunfeng Yuan and Haowei Liu and Man Yao and Wei Liu and Li Yang and Bing Li and Weiming Hu and Haoliang Sun and Zhetao Li},
  doi          = {10.1016/j.neunet.2025.108024},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108024},
  shortjournal = {Neural Netw.},
  title        = {MSFI: Multi-timescale spatio-temporal features integration in spiking neural networks},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DSPy-based neural-symbolic pipeline to enhance spatial reasoning in LLMs. <em>NN</em>, <em>193</em>, 108022. (<a href='https://doi.org/10.1016/j.neunet.2025.108022'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial reasoning is crucial for Large Language Models (LLMs) but remains a persistent challenge. Existing neural-symbolic approaches offer partial solutions but suffer from inflexible design and limited effectiveness. We present a neural-symbolic framework that integrates LLMs with Answer Set Programming (ASP) through an iterative feedback loop, enabling precise and reliable refinement of generated logic programs. Evaluated on two benchmark datasets across multiple reasoning tasks and LLMs, our DSPy-based pipeline achieves 82–93 % and 71–80 % accuracy, surpassing direct prompting, Chain-of-Thought, and a two-stage “Facts+Rules” method by up to 43 % and 25 %, respectively. The lightweight “Facts+Rules” alternative we proposed also improves baseline performance by 9–27 % while reducing computational overhead. Key innovations driving these gains include (1) modular separation of semantic parsing and logical reasoning, (2) iterative error-handling feedback between LLMs and ASP solvers, and (3) domain-specific symbolic representations for efficient reasoning. The system offers strong interpretability and generalizability, allowing application across diverse and complex tasks. Moreover, our proposed system could substantially advance AI architectures capable of human-like, multi-component reasoning, contributing to the development of artificial general intelligence.},
  archive      = {J_NN},
  author       = {Rong Wang and Kun Sun},
  doi          = {10.1016/j.neunet.2025.108022},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108022},
  shortjournal = {Neural Netw.},
  title        = {DSPy-based neural-symbolic pipeline to enhance spatial reasoning in LLMs},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MIIGAN: Mambas make strong GAN for infrared image generation. <em>NN</em>, <em>193</em>, 108021. (<a href='https://doi.org/10.1016/j.neunet.2025.108021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collecting infrared images on-site is the most direct and realistic approach. However, it is costly, and due to varying environmental conditions, replicating the same conditions for comparative experiments is challenging. This presents significant obstacles for research in infrared technology. To target this issue, we propose MIIGAN, a Visible-to-Infrared Image Generation model that achieves SOTA performance. MIIGAN employs a GAN based on U-Net, with Mamba blocks serving as the core module to improve generation quality. Additionally, we develop a Spatial and Channel Attention Module (SCAM) and integrate it into the skip connections of U-Net to enhance feature extraction. We also design a Dual-encoder combining Transformer and Mamba to improve the discriminator’s performance. Furthermore, we introduce the Difference and Product learning Module (DPM) into the Dual-encoder to enhance differential and consistency feature extraction. Finally, we integrate multi-layer feature differential and consistency losses into the objective function of the discriminator, providing comprehensive pixel-level feedback across multiple scales. We conduct extensive comparative and ablation studies across four datasets and perform downstream object detection tasks on the generated infrared images to validate MIIGAN’s performance. The source code is available at https://github.com/wangfc0913/miigan.git .},
  archive      = {J_NN},
  author       = {Fuchao Wang and Huaici Zhao and Yuhuai Peng and Jian Fang and Pengfei Liu and Ronghua Zhang},
  doi          = {10.1016/j.neunet.2025.108021},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108021},
  shortjournal = {Neural Netw.},
  title        = {MIIGAN: Mambas make strong GAN for infrared image generation},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GMSR: Gradient-integrated mamba for spectral reconstruction from RGB images. <em>NN</em>, <em>193</em>, 108020. (<a href='https://doi.org/10.1016/j.neunet.2025.108020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mainstream approaches to spectral reconstruction primarily focus on Convolution- and Transformer-based architectures. However, CNN methods fall short in handling long-range dependencies, whereas Transformers are constrained by computational efficiency limitations. Therefore, constructing a efficient spectral reconstruction network while ensuring the quality of reconstructed hyperspectral images (HSIs) has become a major challenge. Recent breakthroughs in the state-space model (e.g., Mamba) have attracted significant attention from natural language processing to vision tasks due to its near-linear computational efficiency and superior performance, prompting our investigation into its potential for spectral reconstruction problems. To this end, we introduce the Gradient-integrated Mamba for Spectral Reconstruction from RGB Images, dubbed GMSR-Net. GMSR-Net is a lightweight model characterized by a global receptive field and linear computational complexity. Its core comprises multiple stacked Gradient Mamba (GM) blocks, each featuring a tri-branch structure. Building upon the efficient global feature representation from the Mamba, we further innovatively propose spatial gradient attention and spectral gradient attention to guide the reconstruction of spatial and spectral cues. GMSR-Net demonstrates a significant accuracy-efficiency trade-off, achieving state-of-the-art performance while markedly reducing the number of parameters and computational burdens. Compared to existing approaches, GMSR-Net slashes parameters and FLOPs by substantial margins of 8 times and 20 times, respectively. Code is available at https://github.com/wxy11-27/GMSR .},
  archive      = {J_NN},
  author       = {Xinying Wang and Zhixiong Huang and Sifan Zhang and Jiawen Zhu and Paolo Gamba and Lin Feng},
  doi          = {10.1016/j.neunet.2025.108020},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108020},
  shortjournal = {Neural Netw.},
  title        = {GMSR: Gradient-integrated mamba for spectral reconstruction from RGB images},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Visual reinforcement learning via sequential consistency preserved policy contrast from optimal transport view. <em>NN</em>, <em>193</em>, 108019. (<a href='https://doi.org/10.1016/j.neunet.2025.108019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data inefficiency has long posed a significant challenge in the application of visual reinforcement learning methods to complex scenarios. To address this issue, recent studies have incorporated representation learning mechanisms to extract discriminative features by introducing auxiliary objectives that contrast pixel observations . However, our investigations suggest that these representations may not sufficiently capture the essential information for effective decision-making and could potentially impede policy learning. To tackle these limitations, we propose a novel methodology termed CoCo (sequential Co nsistency preserved policy Co ntrast). Unlike existing approaches, CoCo emphasizes the capture of invariant policy-based discriminative features by performing policy contrast across multiple distorted views of observations. Accordingly, we determine that there exists a certain intrinsic heterogeneity between policy and observation, since policy establishes an explicit distribution characteristic rather than a plain tensor. To this end, we propose to model the policy contrast as an optimal transport problem and further perform the alignment of policy distributions during contrastive learning. Subsequently, we introduce an inverse consistency-weighting mechanism designed to accentuate the differences between views while maintaining semantic integrity. We establish the theoretical optimality of our proposed method through an information-theoretic analysis and demonstrate its practical effectiveness via comprehensive evaluation across diverse data efficiency benchmarks, where CoCo consistently outperforms existing approaches.},
  archive      = {J_NN},
  author       = {Zehua Zang and Jiangmeng Li and Chuxiong Sun and Rui Wang and Lixiang Liu and Fuchun Sun},
  doi          = {10.1016/j.neunet.2025.108019},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108019},
  shortjournal = {Neural Netw.},
  title        = {Visual reinforcement learning via sequential consistency preserved policy contrast from optimal transport view},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Pseudo-distribution elite critics: Enhancing accuracy in reinforcement learning value estimation. <em>NN</em>, <em>193</em>, 108018. (<a href='https://doi.org/10.1016/j.neunet.2025.108018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning has succeeded significantly in developing intelligent agents capable of adeptly navigating complex environments, yet it often encounters limitations due to persistent biases in state-action value estimation. To address this challenge, we introduce the Pseudo-distribution Elite Critics (PEC), an innovative framework designed to enhance sample efficiency and effectively balance overestimation and underestimation biases in Q-value approximations. PEC revolves around the innovative concept of pseudo-distribution representation, which enriches Q-value approximations with distributional characteristics, capturing nuanced variations in Q-values without increasing the number of critics, leading to more refined and precise estimations. This framework is further enhanced by two critical components: an uncertainty measurement that accurately identifies the most reliable critic for Temporal Difference target computation and a trimmed mean technique that adeptly balances optimistic and pessimistic biases in Temporal Difference target. Empirical studies across various benchmark scenarios validate the statistical significance of PEC and its superior performance over existing methodologies.},
  archive      = {J_NN},
  author       = {Yujia Zhang and Lin Li and Wei Wei and Jianguo Wu and Jiye Liang},
  doi          = {10.1016/j.neunet.2025.108018},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108018},
  shortjournal = {Neural Netw.},
  title        = {Pseudo-distribution elite critics: Enhancing accuracy in reinforcement learning value estimation},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rethinking softmax in incremental learning. <em>NN</em>, <em>193</em>, 108017. (<a href='https://doi.org/10.1016/j.neunet.2025.108017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mitigating catastrophic forgetting remains a fundamental challenge in incremental learning. This paper identifies a key limitation of the widely used softmax cross-entropy loss: the non-identifiability inherent in the standard softmax cross-entropy distillation loss. To address this issue, we propose two complementary strategies: (1) adopting an imbalance-invariant distillation loss to mitigate the adverse effect of imbalanced weights during distillation, and (2) regularizing the original prediction/distillation loss with shift-sensitive alternatives, which render the optimization problem identifiable and proactively prevent imbalance from arising. These strategies form the foundation of five novel approaches that can be seamlessly integrated into existing distillation-based incremental learning frameworks such as LWF, LWM, and LUCIR. We validate the effectiveness of our approaches through extensive numerical experiments, demonstrating consistent improvements in predictive accuracy and substantial reductions in forgetting. For example, in a 10-task incremental learning setting on CIFAR-100, our methods improve the average accuracy of three widely used approaches - LWF, LWM, and LUCIR - by 11.8 %, 11.5 %, and 12.8 %, respectively, while reducing their average forgetting rates by 16.5 %, 16.8 %, and 13.8 %, respectively. Our code is publicly available at https://github.com/nexais/RethinkSoftmax .},
  archive      = {J_NN},
  author       = {Zheng Zhai and Jiali Zhang and Haiyu Wang and Mingxin Wu and Keshun Yang and Xiaoyan Qiao and Qiang Sun},
  doi          = {10.1016/j.neunet.2025.108017},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108017},
  shortjournal = {Neural Netw.},
  title        = {Rethinking softmax in incremental learning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive metric for knowledge distillation by deep bregman divergence. <em>NN</em>, <em>193</em>, 108016. (<a href='https://doi.org/10.1016/j.neunet.2025.108016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) makes it possible to deploy high-accuracy models on devices with limited resources and is an effective means of achieving lightweight models. With the advancement of technology, the methods of knowledge distillation are also continuously developing and improving to adapt to different application scenarios and needs. To facilitate the transfer of knowledge from larger networks to smaller and lighter networks, KD has been employed to bridge the gap in probability outputs or middle-layer representations between teacher and student networks. Unlike the consistent probability outputs observed between teacher and student networks, the middle-layer representations exhibit significant variations in both structure and distribution. Traditional metrics such as Euclidean distance or MSE treat all intermediate features uniformly and do not adapt to the heterogeneous characteristics of feature distributions across different layers or models. These fixed metrics often fail to account for the spatial, semantic, and statistical variations between teacher and student networks. To address this limitation, we propose using a parameterized and adaptive metric based on deep Bregman divergence. This divergence function is learned from data, enabling the measurement to adjust to the underlying feature distributions at different layers, leading to more effective and robust knowledge transfer. Importantly, our method can also serve as a complementary enhancement ( i.e. , x+Bregman) to almost all other KD methods focused on distilling probability outputs. Extensive experiments demonstrate that our approach outperforms many existing KD methods, achieving superior performance across diverse datasets and network models.},
  archive      = {J_NN},
  author       = {Tongtong Yuan and Zixuan Xu and Bo Liu and Yinan Tang},
  doi          = {10.1016/j.neunet.2025.108016},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108016},
  shortjournal = {Neural Netw.},
  title        = {Adaptive metric for knowledge distillation by deep bregman divergence},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UTN: Unsupervised optical flow estimation network based on transformer. <em>NN</em>, <em>193</em>, 108015. (<a href='https://doi.org/10.1016/j.neunet.2025.108015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the aim of enabling unsupervised optical flow estimation, we propose a scalable framework based on a transformer and a feature pyramid network (FPN). Central to our approach is the incorporation of a transformer-CNN based structure within the encoder, designed to capture global and local dependency features from input image pairs—a crucial element for precise pixel-wise flow estimation. Subsequently, we integrate a normalized cross-correlation module (NCCM) and an attention-based intermediate flow estimation (AIFE) module into the FPN-based decoder. The NCCM enhances the decoder's focus on the saliency of shared foreground objects through correlation operations, while the AIFE refines flow estimation using an auxiliary positional mask and intermediate flow matrix. Furthermore, we propose a static optical flow loss, providing a distinct training clue that effectively boosts flow accuracy. Comprehensive experiments, including comparisons with state-of-the-art methods and ablation studies, were conducted across benchmark datasets such as FlyingChairs, MPI-Sintel, KITTI-2012, and KITTI-2015. Notably, our method achieved substantial performance gains. For instance, on the MPI-Sintel dataset, we observed a reduction in End-Point-Error (EPE) of 24.27 % on the clean dataset and 28.01 % on the final dataset compared to ARFlow. Ablation studies corroborated the efficacy of the NCCM, AIFE, and static optical flow loss in enhancing estimation accuracy.},
  archive      = {J_NN},
  author       = {Xiaochen Liu and Tao Zhang and Mingming Liu},
  doi          = {10.1016/j.neunet.2025.108015},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108015},
  shortjournal = {Neural Netw.},
  title        = {UTN: Unsupervised optical flow estimation network based on transformer},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ITSEF: Inception-based two-stage ensemble framework for p300 detection. <em>NN</em>, <em>193</em>, 108014. (<a href='https://doi.org/10.1016/j.neunet.2025.108014'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the problems of low signal-to-noise ratio, significant individual differences between subjects, and class imbalance in P300-based brain-computer interface (BCI), this paper proposes a novel Inception-based two-stage ensemble framework (ITSEF) to improve detection accuracy. Firstly, an Inception-based convolutional neural network (ICNN) is designed to extract multi-scale features and conduct cross-channel learning. In addition, a two-stage ensemble framework (TSEF) combined with a pre-training and fine-tuning strategy is developed, aiming to enhance the classification performance of the minority class and improve the generalization ability of the model. The framework comprises a conventional learning branch and a re-balancing branch, each based on an ICNN pre-trained with a different loss function. The prediction results of both branches are dynamically weighted by a cumulative learning strategy, so that the model gradually shifts its learning focus from the majority class to the minority class, comprehensively improving the identification ability for both classes. Experimental results on two datasets, Dataset II of BCI Competition III and BCIAUT-P300, demonstrate that the proposed ITSEF achieves state-of-the-art performance in the P300 classification task, with average classification accuracies of 86.16 % and 92.13 %, respectively. Compared with the existing state-of-the-art methods, the ITSEF achieves improvements of 4.61 % and 1.01 % on the two datasets, respectively. Furthermore, it exhibits significant improvements compared to baseline models and widely used class re-balancing strategies. The proposed ITSEF method provides an innovative deep learning framework for P300 signal analysis and has application potential in the field of P300-BCI.},
  archive      = {J_NN},
  author       = {Wenjun Hu and Dingguo Zhang and Wanzhong Chen},
  doi          = {10.1016/j.neunet.2025.108014},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108014},
  shortjournal = {Neural Netw.},
  title        = {ITSEF: Inception-based two-stage ensemble framework for p300 detection},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multivariate distribution fitting for GANs via introducing variable correlations. <em>NN</em>, <em>193</em>, 108013. (<a href='https://doi.org/10.1016/j.neunet.2025.108013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mode collapse is a major unsolved problem in generative adversarial networks. In this study, we base our proposal on the distribution fitting method and explore methods to suppress mode collapse for multivariate data. We incorporate the covariance constraints that enforce similar linear correlations among the variables. This approach may mitigate the nonuniform sampling issue more effectively for multivariate data, thereby suppressing mode collapse. For images, we also offer a scheme for incorporating covariances by utilizing the difference matrices. The method could handle images better since it considers the distances between pixels and possesses a better tolerance for errors like offsets. The proposed methods inherit the benefits of the distribution fitting method, which circumvents reliance on regularization or network modules, enhancing compatibility and facilitating its practical application. Experiments demonstrate the effectiveness and competitive performance of the proposed method.},
  archive      = {J_NN},
  author       = {Yanxiang Gong and Feiyang Sun and Xin Ma},
  doi          = {10.1016/j.neunet.2025.108013},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108013},
  shortjournal = {Neural Netw.},
  title        = {Multivariate distribution fitting for GANs via introducing variable correlations},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel span and syntax enhanced large language model based framework for fine-grained sentiment analysis. <em>NN</em>, <em>193</em>, 108012. (<a href='https://doi.org/10.1016/j.neunet.2025.108012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained aspect-based sentiment analysis requires language models to identify aspect entities and the corresponding sentiment information in the input text content. Transformer-based pre-trained large language models have demonstrated remarkable performance on various challenging natural language processing tasks. However, large language models face limitations in explicitly modelling syntactic relationships and effectively capturing local nuances between terms in the text content, which constrains their capability in fine-grained aspect-based sentiment analysis. We propose a novel span and syntax enhanced joint learning framework based on the latest large language model. The framework incorporates three key components, including the span-aware attention mechanism, the contextual Transformer, and the syntax-aware Transformer, which examine in parallel to generate span-aware features, contextual features, and syntax-aware features, respectively. The three dimensions of analyzed features are dynamically fused in the feature aggregation module, resulting in a combined feature for aspect entity recognition and sentiment classification. To the best of our knowledge, this study represents the pioneering effort to comprehensively leverage span-aware, contextual, and syntax-aware characteristics to augment large language models in addressing the fine-grained aspect-based sentiment analysis task. Experimental results on publicly available benchmark datasets validate the effectiveness of the architecture compared to state-of-the-art baseline competitors.},
  archive      = {J_NN},
  author       = {Haochen Zou and Yongli Wang and Anqi Huang},
  doi          = {10.1016/j.neunet.2025.108012},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108012},
  shortjournal = {Neural Netw.},
  title        = {A novel span and syntax enhanced large language model based framework for fine-grained sentiment analysis},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multimodal self-supervised retinal vessel segmentation. <em>NN</em>, <em>193</em>, 108011. (<a href='https://doi.org/10.1016/j.neunet.2025.108011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic segmentation of retinal vessels from retinography images is crucial for timely clinical diagnosis. However, the high cost and specialized expertise required for annotating medical images often result in limited labeled datasets, which constrains the full potential of deep learning methods. Recent advances in self-supervised pretraining using unlabeled data have shown significant benefits for downstream tasks. Recognizing that multimodal feature fusion can substantially enhance retinal vessel segmentation accuracy, this paper introduces a novel self-supervised pretraining framework that leverages pairs of unlabeled multimodal fundus images to generate supervisory signals. The core idea is to exploit the complementary differences between the two modalities to construct a multimodal feature fusion map containing vessel information, achieved through Vision Transformer encoding and correlation filtering. Instance-level discriminative features are then learned under the guidance of INFOMAX loss, and the learned knowledge is transferred to a supervised vessel segmentation network. Extensive experiments show that our approach achieves state-of-the-art results among unsupervised methods and remains competitive with supervised baselines while greatly reducing annotation requirements.},
  archive      = {J_NN},
  author       = {Pengshuai Yin and Jingqi Zhang and Huichou Huang and Ruirui Liu and Yanxia Liu and Qingyao Wu and F. Richard Yu},
  doi          = {10.1016/j.neunet.2025.108011},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108011},
  shortjournal = {Neural Netw.},
  title        = {Multimodal self-supervised retinal vessel segmentation},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semi-LLIE: Semi-supervised contrastive learning with mamba-based low-light enhancement. <em>NN</em>, <em>193</em>, 108010. (<a href='https://doi.org/10.1016/j.neunet.2025.108010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in low-light image enhancement (LLIE) have achieved impressive progress. However, the scarcity of paired data has emerged as a significant obstacle to further advancements. In this work, we propose Semi-LLIE, a novel semi-supervised framework that introduces unpaired low- and normal-light images into model training via the mean-teacher paradigm. While the mean-teacher framework is promising, directly applying it to LLIE faces two key challenges. Firstly, pixel-wise consistency losses are insufficient for transferring realistic illumination distribution from the teacher to the student model. Secondly, existing image enhancement backbones are not well-suited for integration with semi-supervised learning to restore fine-grained details in dark regions. To address these challenges, we propose a semantic-aware contrastive loss which leverages vision-language representations to align illumination semantics and achieve accurate illumination distribution equalization, thereby improving color naturalness in enhanced images. In addition, we design a Mamba-based low-light image enhancement backbone with a multi-scale feature learning scheme that enhance global-local pixel dependency modeling for improved detail restoration. In addition, we propose a novel RAM-based perceptive loss is further introduced to guide texture enhancement at semantic level. The experimental results indicate that our Semi-LLIE surpasses existing methods in both quantitative and qualitative metrics. The code and models are available at https://github.com/guanguanboy/Semi-LLIE .},
  archive      = {J_NN},
  author       = {Guanlin Li and Ke Zhang and Ting Wang and Ming Li and Bin Zhao and Xuelong Li},
  doi          = {10.1016/j.neunet.2025.108010},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108010},
  shortjournal = {Neural Netw.},
  title        = {Semi-LLIE: Semi-supervised contrastive learning with mamba-based low-light enhancement},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AutoProfile: Automated profiling in deep learning-based side-channel analysis. <em>NN</em>, <em>193</em>, 108009. (<a href='https://doi.org/10.1016/j.neunet.2025.108009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Side-channel analysis (SCA) capitalizes on unintentionally leaked information to extract sensitive data from cryptographic systems. Over recent years, the side-channel community has exhibited a notable surge in interest towards deep learning (DL) techniques. However, the challenge of constructing appropriate networks has been highlighted. This paper presents a novel methodology named AutoProfile to enhance the efficacy of DL-based profiling attack on robust cryptographic system. AutoProfile customizes two core components of Bayesian optimization for SCA: the modeling strategy and acquisition function. The performance of AutoProfile is assessed on publicly available datasets that consist of real side-channel measurements. The experimental results showcase substantial improvements over the state-of-the-art method, achieving an average performance enhancement of 78.4 %. Notably, for more robust targets that employ a combination of masking, random delay and key variation countermeasures, AutoProfile delivers the most significant performance boost. It reduces the number of traces required from the thousands, as typically needed by state-of-the-art methods, to merely dozens to break the targets. Furthermore, the experiments show that AutoProfile is notably faster than baseline methods in identifying effective networks over all tested SCA datasets.},
  archive      = {J_NN},
  author       = {Yimeng Chen and Bo Wang and Changshan Su and Ao Li and Gen Li and Yuxing Tang and An Wang},
  doi          = {10.1016/j.neunet.2025.108009},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108009},
  shortjournal = {Neural Netw.},
  title        = {AutoProfile: Automated profiling in deep learning-based side-channel analysis},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatial-frequency domain aggregation upsampling for pan-sharpening. <em>NN</em>, <em>193</em>, 108007. (<a href='https://doi.org/10.1016/j.neunet.2025.108007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pan-sharpening, fusing high-resolution panchromatic (PAN) images with low-resolution multispectral (LRMS) to generate high-resolution multispectral (HRMS) images, is critical for enhancing remote sensing image quality. Despite significant advancements in deep learning methods, research on the image upsampling process remains limited. Existing approaches either fail to effectively utilize the information from PAN images or struggle to balance spectral and spatial information, thereby constraining the performance of these models. To alleviate these problems, we propose a novel Spatial-Frequency Domain Aggregation Upsampling (SFAU) method. Our method consists of three core modules: the Dual-Domain Nonlinear Fusion (DDNF), Region-Specific Attention Mechanism (RSAM), and Adaptive Feature Fusion Gate (AFFG). The DDNF module integrates Frequency-Aware Feature Aggregation (FAFA) and Spatial Domain Enhancement techniques, enabling the capture of high-frequency features while refining local structural details. The RSAM module adaptively refines feature representations and preserves spatial-spectral correlations. Finally, the AFFG module effectively combines the outputs from the DDNF and RSAM modules, ensuring a balanced integration of spatial and spectral information. Extensive experiments demonstrate that our method outperforms other popular upsampling techniques and significantly enhances the performance of many leading pan-sharpening models, particularly in high-contrast and spectrally complex regions. Additionally, our approach shows strong generalization in real-world scenarios, highlighting its potential for practical remote sensing applications. Code is available at https://github.com/zacianfans/SFAU .},
  archive      = {J_NN},
  author       = {Yilong Liu and Kai Sun and Yuan Liu and Junying Hu and Junmin Liu and Jiangshe Zhang},
  doi          = {10.1016/j.neunet.2025.108007},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108007},
  shortjournal = {Neural Netw.},
  title        = {Spatial-frequency domain aggregation upsampling for pan-sharpening},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DyFiLM: A framework to handle the distribution shifts on dynamic graphs with hypernetworks. <em>NN</em>, <em>193</em>, 108006. (<a href='https://doi.org/10.1016/j.neunet.2025.108006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic graph representation learning has garnered increasing attention since dynamic graphs can accurately reflect the changes and evolutionary processes in the real world. Existing approaches typically train a fixed model to capture temporal patterns and then utilize the fixed model to infer future evolution. They assume that the dynamic graph evolves with the same law over time. While the underlying data generation distribution of graphs may shift over time and introduce new evolution patterns. To resolve this challenge, we propose a learning-to-learn framework entitled Dy namic F eature-wise L inear M odulation (DyFiLM), which employs a hypermodel to adjust the representation learning model to change with the distribution shifts. By employing a hypermodel to directly modulate the representation learning model based on time-varying input data, our framework captures evolutionary patterns from diverse time and expresses them through the modulation. Training both hypermodel and representation learning model in a distribution-shifting environment endows the framework with the capability for cross-distribution generalization. We apply our proposed framework to three different models and conduct extensive experiments on four datasets to verify the effectiveness of DyFiLM. The experimental results demonstrate that the DyFiLM achieves significant improvements compared with related approaches.},
  archive      = {J_NN},
  author       = {Fuyuan Ma and Yuhan Wang and Shixuan Ma and Yongzhen Li and Xin Wang and Ying Wang},
  doi          = {10.1016/j.neunet.2025.108006},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108006},
  shortjournal = {Neural Netw.},
  title        = {DyFiLM: A framework to handle the distribution shifts on dynamic graphs with hypernetworks},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tempered fractional gradient descent: Theory, algorithms, and robust learning applications. <em>NN</em>, <em>193</em>, 108005. (<a href='https://doi.org/10.1016/j.neunet.2025.108005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces Tempered Fractional Gradient Descent (TFGD), a novel optimization framework that synergizes fractional calculus with exponential tempering to enhance gradient-based learning. Traditional gradient descent methods often suffer from oscillatory updates and slow convergence in high-dimensional, noisy landscapes. TFGD addresses these limitations by incorporating a tempered memory mechanism, where historical gradients are weighted by fractional coefficients | w j | = ( α j ) and exponentially decayed via a tempering parameter λ . Theoretical analysis establishes TFGD’s convergence guarantees: in convex settings, it achieves an O ( 1 / K ) rate with alignment coefficient d α , λ = ( 1 − e − λ ) − α , while stochastic variants attain O ( 1 / k α ) error decay. The algorithm maintains O ( n ) time complexity equivalent to SGD, with memory overhead scaling as O ( d / λ ) for parameter dimension d . Empirical validation demonstrates TFGD’s superiority across diverse benchmarks: 98.25 % accuracy on Breast Cancer Wisconsin (vs. 92.11 % SGD), 99.1 % on MNIST (vs. 99.0 % Adam), and 95.83 % on noisy digits (vs. 75.83 % SGD). TFGD converges 2 × faster than SGD in medical classification tasks and exhibits smoother optimization trajectories in non-convex settings (MNIST autoencoder). The tempered memory mechanism proves particularly effective where feature correlations benefit from stable gradient averaging, while hyperparameter analysis reveals optimal operating regimes ( α = 0.6 − 0.7 , λ = 0.3 − 0.5 ) for noisy data. These results position TFGD as a robust alternative to conventional optimizers in both theoretical and applied machine learning.},
  archive      = {J_NN},
  author       = {Omar Naifar},
  doi          = {10.1016/j.neunet.2025.108005},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108005},
  shortjournal = {Neural Netw.},
  title        = {Tempered fractional gradient descent: Theory, algorithms, and robust learning applications},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Synchronization of neural networks with and without disturbance input via control lyapunov function. <em>NN</em>, <em>193</em>, 108004. (<a href='https://doi.org/10.1016/j.neunet.2025.108004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on the control Lyapunov function (CLF) for a class of neural networks, both with and without disturbance input. First, we design an exponential controller using the quadratic program-based CLF (QP-CLF) method to address the drive-response synchronization of a class of neural networks. Second, we propose a robust controller based on the robust QP-CLF approach to ensure the input-to-state stability (ISS) of the closed-loop system, even in the presence of external disturbances or system uncertainties. Finally, we present two numerical examples to demonstrate the effectiveness of the proposed QP-CLF and robust QP-CLF methods, highlighting their capability to maintain stability and synchronization in both ideal and disturbed conditions. These examples provide valuable insights into the practical applicability of the proposed control strategies.},
  archive      = {J_NN},
  author       = {Yuting Cao and Linhao Zhao and Shiping Wen and Tingwen Huang},
  doi          = {10.1016/j.neunet.2025.108004},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108004},
  shortjournal = {Neural Netw.},
  title        = {Synchronization of neural networks with and without disturbance input via control lyapunov function},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). One-step bipartite graph cut: A normalized formulation and its application to scalable subspace clustering. <em>NN</em>, <em>193</em>, 108003. (<a href='https://doi.org/10.1016/j.neunet.2025.108003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bipartite graph structure has shown its promising ability in facilitating the subspace clustering and spectral clustering algorithms for large-scale datasets. To avoid the post-processing via k -means during the bipartite graph partitioning, the constrained Laplacian rank (CLR) is often utilized for constraining the number of connected components (i.e., clusters) in the bipartite graph, which, however, neglects the distribution (or normalization) of these connected components and may lead to imbalanced or even ill clusters. Despite the significant success of normalized cut (Ncut) in general graphs, it remains an open problem how to enforce a one-step normalized cut for bipartite graphs, especially with linear-time complexity. In this paper, we first characterize a novel one-step bipartite graph cut (OBCut) criterion with normalized constraints, and theoretically prove its equivalence to a trace maximization problem. Then, we extend this cut criterion to a scalable subspace clustering approach, where adaptive anchor learning, bipartite graph learning, and one-step normalized bipartite graph partitioning are simultaneously modeled in a unified objective function, and an alternating optimization algorithm is further designed to solve it in linear time. Experiments on a variety of general and large-scale datasets demonstrate the effectiveness and scalability of our approach. Code available: https://github.com/huangdonghere/OBCut .},
  archive      = {J_NN},
  author       = {Si-Guo Fang and Dong Huang and Chang-Dong Wang and Jian-Huang Lai},
  doi          = {10.1016/j.neunet.2025.108003},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108003},
  shortjournal = {Neural Netw.},
  title        = {One-step bipartite graph cut: A normalized formulation and its application to scalable subspace clustering},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). IDMM-IDS: An efficient and robust intrusion detection system for the IoT based on the inverted dirichlet mixture model. <em>NN</em>, <em>193</em>, 108002. (<a href='https://doi.org/10.1016/j.neunet.2025.108002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) has permeated all facets of modern life, offering revolutionary applications from smart homes to industrial automation. However, the widespread adoption of IoT systems has amplified security vulnerabilities, necessitating robust intrusion detection systems (IDSs) to protect these devices. Traditional IDS solutions often face challenges in resource-constrained IoT environments due to high computational demands and limited adaptability to emerging threats. To address these issues, this paper proposes IDMM-IDS, an efficient and robust IDS tailored for IoT contexts. By utilizing the inverted Dirichlet mixture model (IDMM) and extended stochastic variational inference (ESVI), our IDMM-IDS models complex network traffic with minimal computational overhead. Additionally, a novel cluster-based oversampling technique is integrated to address class imbalance, enhancing the detection of minority class threats without introducing noise. Extensive evaluations on three public datasets-UNSW-NB15, WSN-DS, and WUSTL-IIOT-2021-demonstrate that IDMM-IDS outperforms most existing methods in detection performance while significantly reducing training and decision times, making it well-suited for resource-constrained IoT environments.},
  archive      = {J_NN},
  author       = {Wenda He and Xiangrui Cai and Yiying Yu and Yuping Lai and Xiaojie Yuan},
  doi          = {10.1016/j.neunet.2025.108002},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108002},
  shortjournal = {Neural Netw.},
  title        = {IDMM-IDS: An efficient and robust intrusion detection system for the IoT based on the inverted dirichlet mixture model},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Prediction of cancer drug response based on heterogeneous graph neural networks and multi-omics data. <em>NN</em>, <em>193</em>, 108001. (<a href='https://doi.org/10.1016/j.neunet.2025.108001'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precision prediction of cancer drug response remains a critical challenge in personalized medicine. With ongoing advancements in related research, substantial amounts of cell line omics data and drug feature information have been accumulated, offering valuable resources for investigating cancer drug responses. However, effectively integrating these multi-omics features and constructing accurate and interpretable network-based prediction models remain challenging. To address these issues, we propose GraphTCDR, a model based on heterogeneous graph neural networks and multi-omics data that can accurately predict cancer drug responses. The specific workflow of GraphTCDR is as follows: First, a cell line-drug heterogeneous network is constructed, using multi-omics data and drug features as node attributes. Next, node feature learning is conducted on the heterogeneous network. Finally, the learned features are fed into fully connected layers to predict IC50 values. Extensive experiments on the PRISM database demonstrate that GraphTCDR outperforms existing state-of-the-art methods across all evaluation metrics. Compared with the current best-performing model, GraphTCDR achieves improvements of 3.60 % in PCC, 4.30 % in SCC, 6.50 % in R 2 , and a 1.60 % reduction in RMSE. The reliability of GraphTCDR’s predictions on unlabeled samples is also validated. Moreover, GraphTCDR maintains stable performance even when the amount of training data is reduced, unlike other algorithms, indicating superior robustness. GraphTCDR offers a novel approach to drug response prediction and has significant implications for advancing personalized cancer therapy.},
  archive      = {J_NN},
  author       = {Junming Zhang and Shuwen Xiong and Yugui Xu and Yongqing Zhang},
  doi          = {10.1016/j.neunet.2025.108001},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108001},
  shortjournal = {Neural Netw.},
  title        = {Prediction of cancer drug response based on heterogeneous graph neural networks and multi-omics data},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RefSAM: Efficiently adapting segmenting anything model for referring video object segmentation. <em>NN</em>, <em>193</em>, 108000. (<a href='https://doi.org/10.1016/j.neunet.2025.108000'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Segment Anything Model (SAM) has gained significant attention for its impressive performance in image segmentation. However, it lacks proficiency in referring video object segmentation (RVOS) due to the need for precise user-interactive prompts and a limited understanding of different modalities, such as language and vision. This paper presents the RefSAM model, which explores the potential of SAM for RVOS by incorporating multi-view information from diverse modalities and successive frames at different timestamps in an online manner. Our proposed approach adapts the original SAM model to enhance cross-modality learning by employing a lightweight Cross-Modal MLP that projects the text embedding of the referring expression into sparse and dense embeddings, serving as user-interactive prompts. Additionally, we have introduced the hierarchical dense attention module to fuse hierarchical visual semantic information with sparse embeddings to obtain fine-grained dense embeddings, and an implicit tracking module to generate a tracking token and provide historical information for the mask decoder. Furthermore, we employ a parameter-efficient tuning strategy to align and fuse the language and vision features effectively. Through comprehensive ablation studies, we demonstrate our model’s practical and effective design choices. Extensive experiments conducted on Refer-Youtube-VOS, Ref-DAVIS17, and three referring image segmentation datasets validate the superiority and effectiveness of our RefSAM model over existing methods. The code and models will be publicly available at https://github.com/LancasterLi/RefSAM and Papers with Code 1,2 .},
  archive      = {J_NN},
  author       = {Yonglin Li and Jing Zhang and Xiao Teng and Haoyu Zhang and Xinwang Liu and Long Lan},
  doi          = {10.1016/j.neunet.2025.108000},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {108000},
  shortjournal = {Neural Netw.},
  title        = {RefSAM: Efficiently adapting segmenting anything model for referring video object segmentation},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Manod: A multi-modal anomaly detection framework for distributed system. <em>NN</em>, <em>193</em>, 107999. (<a href='https://doi.org/10.1016/j.neunet.2025.107999'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed infrastructure has been widely deployed in large-scale software systems in recent years to meet the growing demand for applications, due to its scalability and resource-sharing characteristics. Accurately predicting and identifying anomalies is critical to ensure the stable and reliable running of complex distributed systems. System abnormalities can often be reflected through key performance indicators and logs. Metrics provide quantitative measures of system performance and operational status, while logs record various events that occur in the system. Current approaches typically rely on a single data source to detect anomalies, which may lead to false positives and limit the accuracy of failure detection. A combination of these two data modalities can provide a comprehensive view of the system behavior. In this work, we propose a semi-supervised fault detection method, Manod, to monitor the health state of the system based on multimodal data. To obtain the discriminative representations, it employs a graph-based hierarchical encoding approach and leverages pre-trained language models for modeling metrics and logs, respectively. Then, it adopts a novel gated attention fusion method to integrate heterogeneous information. Extensive experiments on two datasets validate the effectiveness of our proposed Manod. It achieves F1-scores of 0.870 and 0.934 on one simulation dataset (D1) and one real-world dataset (D2), respectively, and significantly outperforms all baseline models. This demonstrates its capacity in mitigating both false positives and false negatives.},
  archive      = {J_NN},
  author       = {Wen Liu and Degang Sun and Haitian Yang and Yan Wang and Weiqing Huang},
  doi          = {10.1016/j.neunet.2025.107999},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107999},
  shortjournal = {Neural Netw.},
  title        = {Manod: A multi-modal anomaly detection framework for distributed system},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel twin parametric-margin support vector machine with capped asymmetric elastic net loss. <em>NN</em>, <em>193</em>, 107998. (<a href='https://doi.org/10.1016/j.neunet.2025.107998'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machine (SVM) is a widely used classifier, including hinge-SVM and twin parametric-margin support vector machine (TPWSVM). TPWSVM constructs two nonparallel hyperplanes by solving two smaller quadratic programming problems, demonstrating efficiency on large-scale datasets. However, conventional TPWSVM relies on hinge loss, leading to sensitivity to noise and instability under resampling. To overcome these drawbacks, we propose a novel capped asymmetric elastic net twin parametric-margin support vector machine (CaEN-TPMSVM), integrating capped asymmetric elastic net loss within the TPWSVM framework. Our method generalizes TPWSVM, improves noise robustness, and achieves a fourfold acceleration in training speed relative to standard SVM. Theoretical analysis demonstrates its convergence and stability properties. Empirical studies on synthetic and ten UCI datasets confirm its superior classification accuracy and computational efficiency.},
  archive      = {J_NN},
  author       = {Jianping Fu and Hu Yang},
  doi          = {10.1016/j.neunet.2025.107998},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107998},
  shortjournal = {Neural Netw.},
  title        = {A novel twin parametric-margin support vector machine with capped asymmetric elastic net loss},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enabling generalized zero-shot learning towards unseen domains by intrinsic learning from redundant LLM semantics. <em>NN</em>, <em>193</em>, 107997. (<a href='https://doi.org/10.1016/j.neunet.2025.107997'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized zero-shot learning (GZSL) focuses on recognizing seen and unseen classes against domain shift problem where data of unseen classes may be misclassified as seen classes. However, existing GZSL is still limited to seen domains. In the current work, we study cross-domain GZSL (CDGZSL) which addresses GZSL towards unseen domains. Different from existing GZSL methods, CDGZSL constructs a common feature space across domains and acquires the corresponding intrinsic semantics shared among domains to transfer from seen to unseen domains. Considering the information asymmetry problem caused by redundant class semantics annotated with large language models (LLMs), we present Meta Domain Alignment Semantic Refinement (MDASR). Technically, MDASR consists of two parts: Inter-class similarity alignment, which eliminates the non-intrinsic semantics not shared across all domains under the guidance of inter-class feature relationships, and unseen-class meta generation, which preserves intrinsic semantics to maintain connectivity between seen and unseen classes by simulating feature generation. MDASR effectively aligns the redundant semantic space with the common feature space, mitigating the information asymmetry in CDGZSL. The effectiveness of MDASR is demonstrated on two public datasets, Office-Home and Mini-DomainNet, as well as on a self-constructed multi-domain rare animal dataset. We have shared the LLM-based semantics for these datasets as a benchmark.},
  archive      = {J_NN},
  author       = {Jiaqi Yue and Chunhui Zhao and Jiancheng Zhao and Biao Huang},
  doi          = {10.1016/j.neunet.2025.107997},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107997},
  shortjournal = {Neural Netw.},
  title        = {Enabling generalized zero-shot learning towards unseen domains by intrinsic learning from redundant LLM semantics},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Large language modeling of hallucinatory problem mitigation based on the wheel of emotions. <em>NN</em>, <em>193</em>, 107996. (<a href='https://doi.org/10.1016/j.neunet.2025.107996'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have demonstrated remarkable generative capabilities across a wide range of natural language processing tasks. However, the frequent occurrence of hallucinations—outputs that appear plausible but are factually incorrect or logically inconsistent—poses a significant challenge to the reliability and practical utility of these models. This paper proposes a novel Emotion-Augmented Inference (EAI) method based on the Wheel of Emotions, aiming to mitigate hallucinations in multimodal generation tasks involving LLMs. EAI integrates two core mechanisms: visual-contrastive decoding and affective textual symbolization, which jointly enable the perception, regulation, and reconstruction of emotional signals during generation. These mechanisms enhance emotional coherence and semantic reliability in the model's outputs. Experimental results on two multimodal datasets, MSCOCO and GQA, show that EAI achieves improvements of 4%–8 % over baseline models in terms of key metrics such as accuracy, precision, recall, and F1-score. Additionally, under three emotional contexts—neutral (S1), positive (S2), and negative (S3)—EAI demonstrates particularly strong performance in hallucination suppression. In the S3 condition, accuracy improves by 5.48% and 2.23% compared to S1 and S2, respectively. These findings also indicate that EAI enhances the ability to manage emotion and maintain textual coherence. In summary, EAI not only stabilizes hallucination suppression in multimodal generation but also provides a new perspective for interpreting the emotional states embedded in LLM outputs. The proposed method offers a promising direction for building more trustworthy, controllable, and human-centered AI systems.},
  archive      = {J_NN},
  author       = {Zhenyu Wang and Jianmin Wang and Zenan Lu and Fang You},
  doi          = {10.1016/j.neunet.2025.107996},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107996},
  shortjournal = {Neural Netw.},
  title        = {Large language modeling of hallucinatory problem mitigation based on the wheel of emotions},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hypothesis spaces for deep learning. <em>NN</em>, <em>193</em>, 107995. (<a href='https://doi.org/10.1016/j.neunet.2025.107995'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a hypothesis space for deep learning based on deep neural networks (DNNs). By treating a DNN as a function of two variables—the input variable and the parameter variable—we consider the set of DNNs where the parameter variable belongs to a space of weight matrices and biases determined by a prescribed depth and layer widths. To construct a Banach space of functions of the input variable, we take the weak* closure of the linear span of this DNN set. We prove that the resulting Banach space is a reproducing kernel Banach space (RKBS) and explicitly construct its reproducing kernel. Furthermore, we investigate two learning models—regularized learning and the minimum norm interpolation (MNI) problem—within the RKBS framework by establishing representer theorems. These theorems reveal that the solutions to these learning problems can be expressed as a finite sum of kernel expansions based on training data.},
  archive      = {J_NN},
  author       = {Rui Wang and Yuesheng Xu and Mingsong Yan},
  doi          = {10.1016/j.neunet.2025.107995},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107995},
  shortjournal = {Neural Netw.},
  title        = {Hypothesis spaces for deep learning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reduced storage direct tensor ring decomposition for convolutional neural networks compression. <em>NN</em>, <em>193</em>, 107994. (<a href='https://doi.org/10.1016/j.neunet.2025.107994'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are among the most widely used machine learning models for computer vision tasks, such as image classification. To improve the efficiency of CNNs, many compression approaches have been developed. Low-rank methods approximate the original convolutional kernel with a sequence of smaller convolutional kernels, leading to reduced storage and time complexities. In this study, we propose a novel low-rank CNN compression method that is based on reduced storage direct tensor ring decomposition (RSDTR). The proposed method offers a higher circular mode permutation flexibility, and it is characterized by large parameter and FLOPS compression rates, while preserving a good classification accuracy of the compressed network. The experiments, performed on the CIFAR-10 and ImageNet datasets, clearly demonstrate the efficiency of RSDTR in comparison to other state-of-the-art CNN compression approaches.},
  archive      = {J_NN},
  author       = {Mateusz Gabor and Rafał Zdunek},
  doi          = {10.1016/j.neunet.2025.107994},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107994},
  shortjournal = {Neural Netw.},
  title        = {Reduced storage direct tensor ring decomposition for convolutional neural networks compression},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A prompt-aware knowledge-tuning framework for histopathology subtype classification with scarce annotation. <em>NN</em>, <em>193</em>, 107993. (<a href='https://doi.org/10.1016/j.neunet.2025.107993'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence can assist pathologists in diagnosing histopathology subtypes, enabling precision medicine and improving survival rates. Many approaches employ multi-scale models or combine knowledge to implement subtype diagnosis. However, they fail to identify explicit features most relevant to subtypes adaptively, resulting model relying heavily on extensive annotation. Moreover, knowledge is qualitatively represented by coarse-grained methods, such as using 0 or 1 to indicate negative or positive samples. However, they cannot be quantitatively described with a fine-grained process, such as with a probability of 0.23 or 0.81. In this paper, we propose a prompt-aware knowledge-tuning model called PAKT for subtype classification, which provides an adaptive feature generation while representing knowledge quantitatively with scarce annotation. Specifically, we design a prompt-aware module that adaptively predicts multi-scale histological probabilities. The pre-trained encoder can leverage vision prompts to obtain explicit features without extensive annotation. Furthermore, a knowledge-tuning module is constructed to provide sensible diagnostic processes. The trainable weight matrix can quantitatively represent diagnosis knowledge, reflecting the influence of different histological probabilities on subtypes. PAKT performs better than state-of-the-art methods in diagnosing subtypes, achieving an average performance improvement of over 10 %, as evidenced by extensive experimentation on both public and in-house datasets, thus validating its effectiveness. Moreover, its complexity is significantly reduced without losing performance compared with baselines. Code: https://github.com/Dennis-YB/PAKT.git},
  archive      = {J_NN},
  author       = {Bo Yu and Jiuman Song and Lele Cong and Xianling Cong and Jouke Dijkstra and Philip S. Yu and Hechang Chen},
  doi          = {10.1016/j.neunet.2025.107993},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107993},
  shortjournal = {Neural Netw.},
  title        = {A prompt-aware knowledge-tuning framework for histopathology subtype classification with scarce annotation},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unified auxiliary restoration network for robust multimodal 3D object detection in adverse conditions. <em>NN</em>, <em>193</em>, 107992. (<a href='https://doi.org/10.1016/j.neunet.2025.107992'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion of LiDAR and camera sensors offers remarkable results in multimodal 3D object detection with enhanced performance. However, existing fusion methods are primarily designed considering ideal data, ignoring the practical challenges of sensor specification and environmental variations encountered in autonomous driving. Thus, these methods often exhibit a significant performance degradation when faced with adverse conditions, such as sparse point cloud and inclement weather. To address these multiple adverse conditions simultaneously, we present the first attempt to apply auxiliary restoration networks in multimodal 3D object detection. These networks restore degraded point cloud and image, ensuring the primary multimodal detection network obtains higher quality features in a unified form. Especially, we propose a spherical domain point upsampler based on bilateral point generation and an adjustment network with a horizontal alignment block. Additionally, for efficient fusion with restored point cloud and image, we suggest a graph detector with a unified loss function, including auxiliary, contrastive, and difficulty losses. The experimental results demonstrate that the proposed approach prevents a performance decline in adverse conditions and outperforms state-of-the-art methods. The source code with pretrained weights for the proposed model is available at https://github.com/jhyoon964/auxphere .},
  archive      = {J_NN},
  author       = {Jae Hyun Yoon and Jong Won Jung and Seok Bong Yoo},
  doi          = {10.1016/j.neunet.2025.107992},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107992},
  shortjournal = {Neural Netw.},
  title        = {Unified auxiliary restoration network for robust multimodal 3D object detection in adverse conditions},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Joint noise detection and l2,p-norm metric in least squares twin SVM for robust multiclass classification. <em>NN</em>, <em>193</em>, 107991. (<a href='https://doi.org/10.1016/j.neunet.2025.107991'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The least squares twin support vector machine (LSTSVM) serves as a foundational framework for binary classification and is widely applied in statistical learning due to its solid theoretical foundation. It also plays a crucial role in advancing research in multiclass classification. However, the presence of noise in real-world datasets often leads to substantial performance degradation, compromising the reliability and generalizability of this model. Given the ubiquitous presence of noise, its influence on the learning of classification hyperplanes warrants rigorous attention. In this paper, we propose a robust multiclass classification model grounded in LSTSVM, designed to mitigate the influence of noisy data. The proposed framework replaces the conventional squared L 2 -norm with the more robust L 2 , p -norm ( 0 < p ≤ 2 ), which enhances resilience against noise. Furthermore, we introduce an innovative noise detection mechanism with a transparent physical interpretation, whereby a probabilistic weight is assigned to each sample to quantify its likelihood of being a normal observation. Specifically, normal samples receive a weight of 1, whereas suspected noisy samples receive a weight of 0. To solve the resulting non-convex optimization problem efficiently, we develop an iterative algorithm that adaptively penalizes normal samples exhibiting substantial errors. The convergence property of the algorithm is rigorously analyzed and theoretically supported. Moreover, the model is extended to semi-supervised learning, enabling the effective exploitation of both a limited set of labeled samples and the structural information inherent in numerous unlabeled samples. Finally, extensive experiments on benchmark and image datasets under varying noise levels demonstrate that the proposed approach consistently outperforms existing methods in terms of classification accuracy and robustness, validating its practical effectiveness in noisy multiclass settings.},
  archive      = {J_NN},
  author       = {Chao Yuan and Xiaoyuan Xu and Farshad Arvin and Huiyu Mu and Haiyang Li and Jigen Peng},
  doi          = {10.1016/j.neunet.2025.107991},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107991},
  shortjournal = {Neural Netw.},
  title        = {Joint noise detection and l2,p-norm metric in least squares twin SVM for robust multiclass classification},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GraphGuard: An adaptive approach for restoring accuracy in backdoor-compromised GNNs. <em>NN</em>, <em>193</em>, 107990. (<a href='https://doi.org/10.1016/j.neunet.2025.107990'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backdoor attacks present a significant threat to the reliability of machine learning models, including Graph Neural Networks (GNNs), by embedding triggers that manipulate model behavior. While many existing defenses focus on identifying these vulnerabilities, few address restoring model accuracy after an attack. This paper introduces a method for restoring the original accuracy of GNNs affected by backdoor attacks, a task complicated by the complex structure of graph data. Our approach combines advanced filtering and augmentation techniques that enhance the GNN’s resilience against hidden triggers. The filtering mechanisms remove suspicious data points to minimize the influence of poisoned inputs, while augmentation introduces controlled variation to strengthen the model against backdoor triggers. To optimize restoration, we present an adaptive framework that adjusts the balance between filtering and augmentation based on model sensitivity and attack severity, reducing both false positives and negatives. Additionally, we incorporate Explainable AI (XAI) techniques to improve the interpretability of the model’s decision-making process, enabling transparent detection and understanding of backdoor triggers. Results demonstrate that our method achieves an average accuracy restoration of 97–99 % across various backdoor attack scenarios, providing an effective solution to maintain the performance and integrity of GNNs in sensitive applications.},
  archive      = {J_NN},
  author       = {Adil Ahmad and Anwar Shah and Waleed Alnumay and Bahar Ali},
  doi          = {10.1016/j.neunet.2025.107990},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107990},
  shortjournal = {Neural Netw.},
  title        = {GraphGuard: An adaptive approach for restoring accuracy in backdoor-compromised GNNs},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Pay more attention to the robustness of LLMs on adversarial prompt for instruction data mining. <em>NN</em>, <em>193</em>, 107989. (<a href='https://doi.org/10.1016/j.neunet.2025.107989'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instruction tuning has emerged as a paramount method for tailoring the behaviors of LLMs. Recent studies have unveiled the potential for LLMs to achieve high performance through fine-tuning with a limited quantity of high-quality instruction data. Instruction-Following Difficulty is one of the most representative approaches in instruction data mining, which involves selecting samples where LLMs fail to generate response that align with the provided instructions as the high-quality instruction data. Building upon this approach, we further investigate how the robustness of LLMs to adversarial prompts influences the selection of high-quality instruction data. This paper proposes a pioneering framework of high-quality instruction data mining for instruction tuning, focusing on the impact of LLMs’ robustness on adversarial prompts. Our notable innovation is to generate adversarial instruction data by attacking the prompts associated with instruction samples. Then, we introduce an Adversarial Instruction-Following Difficulty (AIFD) metric, which utilizes complete instruction sample pairs to identify samples with high adversarial instruction difficulty as high-quality instruction data. Apart from it, to address cases where LLM responses deviate from user intent, we further introduce a novel Adversarial Instruction Output Embedding Consistency (AIOEC) method that relies solely on instruction prompts to mine high-quality online instruction data. We conduct extensive experiments on two benchmark datasets to assess the performance. The experimental results serve to underscore the effectiveness of our proposed two methods. Moreover, the results underscore the critical practical significance of considering the robustness of LLMs on adversarial prompts for instruction data mining.},
  archive      = {J_NN},
  author       = {Qiang Wang and Dawei Feng and Xu Zhang and Ao Shen and Yang Xu and Bo Ding and Huaimin Wang},
  doi          = {10.1016/j.neunet.2025.107989},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107989},
  shortjournal = {Neural Netw.},
  title        = {Pay more attention to the robustness of LLMs on adversarial prompt for instruction data mining},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adapformer: Adaptive channel management for multivariate time series forecasting. <em>NN</em>, <em>193</em>, 107988. (<a href='https://doi.org/10.1016/j.neunet.2025.107988'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multivariate time series forecasting (MTSF), accurately modeling the intricate dependencies among multiple variables remains a significant challenge due to the inherent limitations of traditional approaches. Most existing models adopt either channel-independent (CI) or channel-dependent (CD) strategies, each presenting distinct drawbacks. CI methods fail to leverage the potential insights from inter-channel interactions, resulting in models that may not fully exploit the underlying statistical dependencies present in the data. Conversely, CD approaches often incorporate too much extraneous information, risking model overfitting and predictive inefficiency. To address these issues, we introduce the Adaptive Forecasting Transformer ( Adapformer ), an advanced Transformer-based framework that merges the benefits of CI and CD methodologies through effective channel management. The core of Adapformer lies in its dual-stage encoder-decoder architecture, which includes the A daptive C hannel E nhancer ( ACE ) for enriching embedding processes and the A daptive C hannel F orecaster ( ACF ) for refining the predictions. ACE enhances token representations by selectively incorporating essential dependencies, while ACF streamlines the decoding process by focusing on the most relevant covariates, substantially reducing noise and redundancy. Our rigorous testing on diverse datasets shows that Adapformer achieves superior performance over existing models, enhancing both predictive accuracy and computational efficiency, thus making it state-of-the-art in MTSF.},
  archive      = {J_NN},
  author       = {Yuchen Luo and Xinyu Li and Liuhua Peng and Mingming Gong},
  doi          = {10.1016/j.neunet.2025.107988},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107988},
  shortjournal = {Neural Netw.},
  title        = {Adapformer: Adaptive channel management for multivariate time series forecasting},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-site brain disease identification based on tensor decomposition and personalized federated learning. <em>NN</em>, <em>193</em>, 107987. (<a href='https://doi.org/10.1016/j.neunet.2025.107987'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain diseases significantly impact physical and mental health, making the development of models to identify biomarkers for early diagnosis essential. However, building high-quality models typically relies on large-scale datasets, while the privacy-sensitive nature of medical data often restricts its sharing and utilization. Multi-site studies provide a potential solution by integrating data from various sources, yet existing methods frequently neglect site-specific private features, such as demographic information. Therefore, in this paper, we propose a simple yet effective framework based on Tensor Decomposition and Personalized Federated Learning (TDPFL) for multi-site brain disease recognition, while protecting these private features. On the central server, we designed a dual feature aggregation module to facilitate efficient knowledge sharing among sites. On the client side, we introduced a personalized branch to safeguard private information ( i.e. , age, gender, and education) and developed a tensor decomposition module to extract features from subjects’ brain scan data. Furthermore, we developed a dynamic prototype aggregation module to monitor evolving brain features over time. This mechanism enhances the model’s capacity to capture these dynamics, thereby improving classification and prediction accuracy. Experiments on two publicly available rs-fMRI datasets across six sites showed that TDPFL outperformed baseline methods with a 4 % improvement in average classification accuracy. Additionally, we identified site-specific brain disease-related biomarkers, offering novel insights into early diagnosis. Code is available at https://github.com/ChaojunZ/TDPFL.git},
  archive      = {J_NN},
  author       = {Chaojun Zhang and Jing Yang and Yuan Gao and Xiangli Yang and Shaojun Zou and Jieming Yang},
  doi          = {10.1016/j.neunet.2025.107987},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107987},
  shortjournal = {Neural Netw.},
  title        = {Multi-site brain disease identification based on tensor decomposition and personalized federated learning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Recurrent stochastic configuration networks with block increments. <em>NN</em>, <em>193</em>, 107986. (<a href='https://doi.org/10.1016/j.neunet.2025.107986'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent stochastic configuration networks (RSCNs) have shown promise in modelling nonlinear dynamic systems with order uncertainty due to their advantages of easy implementation, less human intervention, and strong approximation capability. This paper develops the original RSCNs with block increments, termed block RSCNs (BRSCNs), to further enhance the learning capacity and efficiency of the network. BRSCNs can simultaneously add multiple reservoir nodes (subreservoirs) during the construction. Each subreservoir is configured with a unique structure in the light of a supervisory mechanism, ensuring the universal approximation property. The reservoir feedback matrix is appropriately scaled to guarantee the echo state property of the network. Furthermore, the output weights are updated online using a projection algorithm, and the persistent excitation conditions that facilitate parameter convergence are also established. Numerical results over a time series prediction, a nonlinear system identification task, and two industrial data predictive analyses demonstrate that the proposed BRSCN performs favourably in terms of modelling efficiency, learning, and generalization performance, highlighting their significant potential for coping with complex dynamics.},
  archive      = {J_NN},
  author       = {Dianhui Wang and Gang Dang},
  doi          = {10.1016/j.neunet.2025.107986},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107986},
  shortjournal = {Neural Netw.},
  title        = {Recurrent stochastic configuration networks with block increments},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SPD-updater: Symmetric positive definite manifold geometry based temporal updating for visual object tracking. <em>NN</em>, <em>193</em>, 107985. (<a href='https://doi.org/10.1016/j.neunet.2025.107985'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual object tracking has witnessed continuous advances in recent years along with the exciting developments in backbone networks. In general, all advanced solutions adhere to the template-based tracking framework, which exhibits powerful representative capacity gained via offline training. However, when the target undergoes appearance changes or occlusion, the tracker, which relies on a fixed template defined in the initial frame, struggles to locate it accurately in such complex situations. To achieve online adaptation, recent studies have introduced dynamic templates. Typically, the adopted solution is to compute reliability scores in the traditional Euclidean space to assess the confidence of the dynamic template. However, the Euclidean metric is unreliable to some extent in high-dimensional feature spaces, potentially resulting in a negative impact by involving incorrect dynamic templates. To overcome this problem, we exploit the compact geometric representation capacity of the Symmetric Positive Definite (SPD) manifold to design a novel score prediction module for the tracker update (SPD-Updater). By switching to an SPD manifold metric, we obtain a more accurate and stable dynamic template, thereby enhancing the model capacity to handle complex situations. To validate the reliability of manifold metric in tracking models, we conduct experiments with trackers using different backbones. The experimental results on LaSOT, GOT-10k, TrackingNet, and UAV123 demonstrate the effectiveness of our approach, reflecting the merit of the SPD metric in online tracking adaptation.},
  archive      = {J_NN},
  author       = {Jinglin Zhou and Tianyang Xu and Xuefeng Zhu and Xiao-Jun Wu and Josef Kittler},
  doi          = {10.1016/j.neunet.2025.107985},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107985},
  shortjournal = {Neural Netw.},
  title        = {SPD-updater: Symmetric positive definite manifold geometry based temporal updating for visual object tracking},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DRG: A dual relational graph framework for course recommendation. <em>NN</em>, <em>193</em>, 107984. (<a href='https://doi.org/10.1016/j.neunet.2025.107984'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The course recommendation system is a core application of recommendation technology in the educational field. Its significance lies in accurately matching users’ interests and needs while providing valuable feedback to instructors, thereby fostering continuous improvement in teaching quality. Various techniques have been proposed for this purpose, with Large Language Models (LLMs) demonstrating significant potential in course recommendation tasks. However, the issue of data sparsity remains a critical bottleneck that limits the accuracy of the recommendation. In this study, we propose a Dual Relationship Graph (DRG) framework that addresses data sparsity by modeling both course-course and user-course relationships through a dual-graph structure. Specifically, DRG constructs two relational graphs: a course-based graph built using LLM-based semantic reasoning, collaborative filtering, clustering, and association rule mining; and a user-based graph constructed via collaborative filtering and LLM-based preference inference. These graphs are integrated into a unified recommendation pipeline through joint graph learning and collaborative reasoning. The enhanced interaction graphs significantly alleviated sparsity, increasing link coverage by 37.88 % and 12.67 % on the two datasets, respectively. Notably, DRG is designed as a plug-and-play module, compatible with both traditional models and LLM-based recommendation systems. Experimental results show that our DRG excels in task ranking across two benchmark datasets, significantly enhancing traditional recommendation models and LLM-based methods. Moreover, DRG’s dual relationship graph consistently outperforms single relationship approaches, underscoring the importance of multi-perspective integration in course recommendation systems. By unifying dual-perspective graph modeling with LLM-driven semantic understanding, DRG provides a scalable and effective solution for personalized course recommendation in sparse educational environments. The code and datasets will be made available at https://github.com/WHCK1102/DRG .},
  archive      = {J_NN},
  author       = {Yong Ouyang and Zhen Ye and Lingyu Chen and Huanwen Wang and Yawen Zeng},
  doi          = {10.1016/j.neunet.2025.107984},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107984},
  shortjournal = {Neural Netw.},
  title        = {DRG: A dual relational graph framework for course recommendation},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning in PINNs: Phase transition, diffusion equilibrium, and generalization. <em>NN</em>, <em>193</em>, 107983. (<a href='https://doi.org/10.1016/j.neunet.2025.107983'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the learning dynamics of fully-connected neural networks through the lens of the neural gradient signal-to-noise ratio (SNR), examining the behavior of first-order optimizers in non-convex objectives. By interpreting the drift/diffusion phases as proposed in the information bottleneck theory, we identify a third phase termed “diffusion equilibrium” (DE), a stable training phase characterized by highly-ordered neural gradients across the sample space. This phase is marked by an abrupt (first-order) transition, where sample-wise gradients align (SNR increases), and stable optimizer convergence. Moreover, we find that when homogeneous residuals are also met across the sample space during the DE phase, this leads to better generalization, as the optimization steps are equally sensitive to each sample. Based on this observation, we propose a sample-wise re-weighting scheme, which considerably improves the residual homogeneity and generalization in quadratic loss functions, by targeting the problematic samples with large residuals and vanishing gradients. Finally, we explore the information compression phenomenon, pinpointing a significant saturation-induced compression of activations at the DE phase transition, driven by the sample-wise gradient directional alignment. Interestingly, it is during the saturation of activations that the model converges, with deeper layers experiencing negligible information loss. Supported by experimental examples on physics-informed neural networks (PINNs), which highlight the critical role of gradient agreement due to their inherent PDE-based interdependence of samples, our findings suggest that when both sample-wise gradients and residuals transition in an ordered state, this leads to faster convergence and better generalization. Identifying these phase transitions could improve deep learning optimization strategies, enhancing physics-informed methods and overall machine learning performance.},
  archive      = {J_NN},
  author       = {Sokratis J. Anagnostopoulos and Juan Diego Toscano and Nikolaos Stergiopulos and George Em Karniadakis},
  doi          = {10.1016/j.neunet.2025.107983},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107983},
  shortjournal = {Neural Netw.},
  title        = {Learning in PINNs: Phase transition, diffusion equilibrium, and generalization},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-channel hierarchical interactive learning for the prediction of protein-ligand binding affinity. <em>NN</em>, <em>193</em>, 107982. (<a href='https://doi.org/10.1016/j.neunet.2025.107982'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein-ligand binding affinity (PLBA) is a crucial metric in drug screening for identifying potential candidate compounds. In recent years, deep learning-based methods have used representation learning to model interactions within protein-ligand complexes, demonstrating great promise in affinity prediction tasks. Existing studies have considered both intramolecular (covalent) and intermolecular (non-covalent) interactions to some extent. However, these interactions are often treated as independent features, lacking explicit hierarchical dependency modeling, which may lead to insufficient representation of interaction information and ultimately limit the accuracy of affinity predictions. To address this issue, we propose a novel approach—Dual-channel Hierarchical Interactive Learning (DHIL)—to achieve a more comprehensive modeling of protein-ligand interactions. DHIL employs a dual-channel encoding structure to simultaneously learn intramolecular and intermolecular interactions, ensuring the completeness of interaction features. Additionally, we design a hierarchical interactive learning paradigm to facilitate information exchange between these two interaction types at multiple levels, promoting their collaborative modeling. This mechanism mimics the local-to-global working principles of biological systems, enabling a more detailed and holistic representation of protein-ligand interactions. We conduct extensive and comprehensive experiments on a diverse set of benchmark datasets, rigorously evaluating the effectiveness of DHIL. The results demonstrate that DHIL significantly improves PLBA prediction accuracy, outperforming existing methods and further validating its potential in drug discovery and screening tasks. Nevertheless, the proposed framework introduces notable computational overhead due to multi-scale graph construction and cross-level message passing. It also exhibits sensitivity to the quality of input 3D binding conformations, which may affect its robustness in practical applications. These limitations suggest future directions for improving model efficiency and generalizability. To facilitate reproducibility and further research, the complete source code of DHIL has been released at: https://github.com/WZY-0814/DHIL .},
  archive      = {J_NN},
  author       = {Zheyu Wu and Huifang Ma and Bin Deng and Zhixin Li and Liang Chang},
  doi          = {10.1016/j.neunet.2025.107982},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107982},
  shortjournal = {Neural Netw.},
  title        = {Dual-channel hierarchical interactive learning for the prediction of protein-ligand binding affinity},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tensorized anchor alignment for incomplete multi-view clustering. <em>NN</em>, <em>193</em>, 107981. (<a href='https://doi.org/10.1016/j.neunet.2025.107981'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete Multi-View Clustering (IMVC) focuses on uncovering the consensus and complementary information present in datasets with multiple incomplete views. However, existing IMVC methods face several limitations. First, many approaches exhibit high computational complexity. Second, anchor misalignment across views remains a challenge. Third, high-order correlations among views are often overlooked. To address these challenges, the paper introduces a novel framework called Tensorized Anchor Alignment for Incomplete Multi-view Clustering (TAA-IMC). Specifically, the view-specific anchor graphs are constructed to reduce computational complexity while preserving the diversity of information among views. Then, to mitigate the issue of anchor misalignment, a binary alignment matrix is introduced, ensuring proper correspondence between anchors across different views. Moreover, the aligned anchor graphs are integrated into a tensor representation with a low-rank constraint, enabling the extraction of high-order correlation information. Finally, the proposed TAA-IMC is solved using an alternating update method, showcasing efficiency through memory and time complexity analyses. Extensive comparative experiments conducted on seven benchmark datasets validate the efficiency and superiority of TAA-IMC over state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Yiran Cai and Hangjun Che and Wei Guo and Baicheng Pan and Man-Fai Leung},
  doi          = {10.1016/j.neunet.2025.107981},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107981},
  shortjournal = {Neural Netw.},
  title        = {Tensorized anchor alignment for incomplete multi-view clustering},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Symmetrical bidirectional knowledge alignment for zero-shot sketch-based image retrieval. <em>NN</em>, <em>193</em>, 107980. (<a href='https://doi.org/10.1016/j.neunet.2025.107980'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of zero-shot sketch-based image retrieval (ZS-SBIR), which aims to use sketches from unseen categories as queries to match the images of the same category. Due to the large cross-modality discrepancy, ZS-SBIR is still a challenging task and mimics realistic zero-shot scenarios. The key is to leverage transferable knowledge from the pre-trained model to improve generalizability. Existing researchers often utilize the simple fine-tuning training strategy or knowledge distillation from a teacher model with fixed parameters, lacking efficient bidirectional knowledge alignment between student and teacher models simultaneously for better generalization. In this paper, we propose a novel Symmetrical Bidirectional Knowledge Alignment for zero-shot sketch-based image retrieval (SBKA). The symmetrical bidirectional knowledge alignment learning framework is designed to effectively learn mutual rich discriminative information between teacher and student models to achieve the goal of knowledge alignment. Instead of the former one-to-one cross-modality matching in the testing stage, a one-to-many cluster cross-modality matching method is proposed to leverage the inherent relationship of intra-class images to reduce the adverse effects of the existing modality gap. Experiments on several representative ZS-SBIR datasets (Sketchy Ext dataset, TU-Berlin Ext dataset and QuickDraw Ext dataset) prove the proposed algorithm can achieve superior performance compared with state-of-the-art methods. The source code is publicly available at https://github.com/zermatt-luo/SBKA .},
  archive      = {J_NN},
  author       = {Decheng Liu and Xu Luo and Chunlei Peng and Nannan Wang and Ruimin Hu and Xinbo Gao},
  doi          = {10.1016/j.neunet.2025.107980},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107980},
  shortjournal = {Neural Netw.},
  title        = {Symmetrical bidirectional knowledge alignment for zero-shot sketch-based image retrieval},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing feature discrimination with pseudo-labels for foundation model in segmentation of 3D medical images. <em>NN</em>, <em>193</em>, 107979. (<a href='https://doi.org/10.1016/j.neunet.2025.107979'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Development of medical image segmentation foundation models relies on large-scale samples. However, it is more time-consuming to annotate 3D medical images than 2D natural images, making it challenging to collect sufficient annotated samples. While pseudo-labeling offers a potential solution to expand the annotated dataset, it may introduce noisy labels that can create systematic biases, particularly affecting the segmentation performance of smaller anatomical structures. To this end, we propose a pseudo-label enriched segmentation framework (PESF), which integrates confidence filtering and perturbation-based curriculum learning. To begin with, our pseudo-labeling approach applies a well-pretrained foundation model to generate pseudo-labels for previously unannotated organ categories, effectively expanding the number of classes in the original dataset. Subsequently, we develop a confidence-based filtering mechanism, leveraging a feature extraction module combined with a confidence prediction module to quantitatively assess and filter out low-quality pseudo-labels, thereby minimizing the detrimental effects of noisy pseudo-labels on the model’s optimization. Furthermore, a progressive sampling strategy that integrates curriculum learning with Gaussian random perturbations is proposed, systematically introducing training samples from simpler to more complex cases, thereby enhancing the model’s generalization capability across organs of varying shapes and sizes. Additionally, our theoretical analysis reveals that incorporating these extra pseudo-labeled classes strengthens feature discrimination by increasing the angular margins between class decision boundaries in the embedding space. Experimental results demonstrate that PESF achieves a 6.8% improvement in the overall average Dice Similarity Coefficient (DSC) compared to the baseline SAM-Med3D on (Amos, FLARE22, WORD, BTCV), with particularly gains in challenging anatomical structures such as the pancreas and esophagus. The code is available at https://github.com/lonezhizi/PESF .},
  archive      = {J_NN},
  author       = {Ge Jin and Qian Zhang and Yong Cheng and Ming Xu and Yingwen Zhu and De Yu and Yongqi Yuan and Juncheng Li and Jun Shi},
  doi          = {10.1016/j.neunet.2025.107979},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107979},
  shortjournal = {Neural Netw.},
  title        = {Enhancing feature discrimination with pseudo-labels for foundation model in segmentation of 3D medical images},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Gabor-enhanced physics-informed neural networks for fast simulations of acoustic wavefields. <em>NN</em>, <em>193</em>, 107978. (<a href='https://doi.org/10.1016/j.neunet.2025.107978'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-Informed Neural Networks (PINNs) have gained attention for solving partial differential equations, including the scattered Helmholtz equation, due to their flexibility and mesh-free formulation. However, their performance suffers from low-frequency bias, particularly in high-frequency wavefield simulations, limiting convergence speed and accuracy. To address this, we propose a novel and simplified PINN framework that incorporates explicit, trainable Gabor basis functions to efficiently capture the localized and oscillatory nature of wavefields. Unlike previous Gabor-based PINNs that rely on multiplicative filters or auxiliary networks to learn Gabor parameters, our approach redefines the network’s task as learning a nonlinear mapping from input coordinates to a custom Gabor coordinate system, where a Gabor function captures the dominant oscillatory behavior of the wavefield. This formulation absorbs the effect of two Gabor parameters into the learned mapping, reducing computational complexity and eliminating the need for manual tuning of hyperparameters. We also present an efficient formulation for incorporating a Perfectly Matched Layer (PML) into the training by deriving real-valued loss components and introducing an analytical expression for the background wavefield. Numerical experiments on various velocity models show that our Gabor-PINN achieves faster convergence, higher accuracy, and greater robustness to architectural design and initialization compared to both traditional PINNs and prior Gabor-based methods. The improvement lies not in adding architectural complexity—as is common in enhanced PINNs—but in absorbing this complexity into the learned coordinate transformation, making the method both simpler and more effective. Our implementation is publicly available to support reproducibility and future research.},
  archive      = {J_NN},
  author       = {Mohammad Mahdi Abedi and David Pardo and Tariq Alkhalifah},
  doi          = {10.1016/j.neunet.2025.107978},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107978},
  shortjournal = {Neural Netw.},
  title        = {Gabor-enhanced physics-informed neural networks for fast simulations of acoustic wavefields},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Learning instrumental variable representation for debiasing in recommender systems. <em>NN</em>, <em>193</em>, 107977. (<a href='https://doi.org/10.1016/j.neunet.2025.107977'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are essential for filtering content to match user preferences. However, traditional recommender systems often suffer from biases inherent in the data, such as popularity bias. These biases, particularly those stemming from latent confounders, can result in inaccurate recommendations and reduce both the diversity and effectiveness of the system. Existing debiasing methods for recommender systems, however, either fail to account for latent confounders or rely on predefined instrumental variables (IVs). To address this research gap, we propose a novel causality-based recommendation algorithm, D ata-driven IV representation learning for debiasing in R ecommender S ystem (DIVRS), which enables the learning of IV representation directly from user-item interaction data. By leveraging the learned IV representation, DIVRS decomposes user behaviour into causal and confounding relationships to address potential bias in recommender systems. Additionally, we introduce Orthogonal Promotion Regularisation (OPR) for DIVRS to address the problem that Graph Convolutional Networks (GCNs) amplify bias. We also propose a variant of GCNs for DIVRS, called DIVRS-GCN. Experimental results on the Douban-Movie and Movielens-10M datasets demonstrate that both DIVRS and DIVRS-GCN effectively mitigate confounding bias while outperform the state-of-the-art methods in recommendation performance. For example, on both datasets, our DIVRS and DIVRS-GCN improve Recall@20 by up to 10.98 %. This validates their effectiveness and robustness. Our approaches improve recommendation accuracy while delivering more balanced and diverse suggestions, effectively addressing the limitations of existing IV-based recommender systems.},
  archive      = {J_NN},
  author       = {Zhirong Huang and Shichao Zhang and Debo Cheng and Jiuyong Li and Lin Liu and Guangquan Lu and Guixian Zhang},
  doi          = {10.1016/j.neunet.2025.107977},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107977},
  shortjournal = {Neural Netw.},
  title        = {Learning instrumental variable representation for debiasing in recommender systems},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing signed graph neural networks through curriculum-based training. <em>NN</em>, <em>193</em>, 107975. (<a href='https://doi.org/10.1016/j.neunet.2025.107975'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Signed graphs are powerful models for representing complex relations with both positive and negative connections. Recently, Signed Graph Neural Networks (SGNNs) have emerged as potent tools for analyzing such graphs. To our knowledge, no prior research has been conducted on devising a training plan specifically for SGNNs. The prevailing training approach feeds samples (edges) to models in a random order, resulting in equal contributionsfrom each sample during the training process, but fails to account for varying learning difficulties based on the graph’s structure. We contend that SGNNs can benefit from a curriculum that progresses from easy to difficult, similar to human learning. The main challenge is evaluating the difficulty of edges in a signed graph. Weaddress this by theoretically analyzing the difficulty of SGNNs in learning adequate representations for edges in unbalanced cycles and propose a lightweight difficulty measurer. This forms the basis for our innovative C urriculum representation learning framework for S igned G raphs, referred to as CSG . The process involves using the measurer to assign difficulty scores to training samples, adjusting their order using a scheduler and training the SGNN model accordingly. We empirically our approach on six real-world signed graph datasets. Our method demonstrates remarkable results, enhancing the accuracy of popular SGNN models by up to 23.7 % and showing a reduction of 8.4 % in standard deviation, enhancing model stability. Our implementation is available in PyTorch ( https://github.com/Alex-Zeyu/CSG ).},
  archive      = {J_NN},
  author       = {Zeyu Zhang and Lu Li and Xingyu Ji and Kaiqi Zhao and Xiaofeng Zhu and Philip S. Yu and Jiawei Li and Maojun Wang},
  doi          = {10.1016/j.neunet.2025.107975},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107975},
  shortjournal = {Neural Netw.},
  title        = {Enhancing signed graph neural networks through curriculum-based training},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Granular ball twin support vector machine with universum data. <em>NN</em>, <em>193</em>, 107974. (<a href='https://doi.org/10.1016/j.neunet.2025.107974'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machines often underperform when limited to labelled target class data and demonstrate sensitivity to noise and outliers. To address these limitations, we propose the Granular Ball Twin Support Vector Machine with Universum Data (GBU-TSVM), which uniquely integrates Universum samples with granular ball computing in the TSVM framework. Unlike conventional TSVMs representing data as points in feature space, the proposed GBU-TSVM models instances as hyperballs, significantly improving robustness against noise while enhancing computational efficiency. Granular representation enables effective data grouping, reducing processing complexity while preserving critical structural information. Incorporating Universum data, consisting of samples outside the target classes, provides additional contextual information that refines decision boundaries and improves generalization. Experiments on UCI benchmark datasets demonstrate GBU-TSVM’s superior performance, measured in terms of accuracy and training time. It achieves 92.38 % accuracy on the Molec Biol Promoter dataset under optimal conditions and maintains 89.17 % accuracy even with 20 % noise contamination. It consistently outperforms baseline models such as GBSVM, TSVM, GBTSVM, Pin-GTSVM, and UTSVM. These results establish GBU-TSVM as an advanced framework for robust classification in challenging data environments.},
  archive      = {J_NN},
  author       = {M.A. Ganaie and Vrushank Ahire},
  doi          = {10.1016/j.neunet.2025.107974},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107974},
  shortjournal = {Neural Netw.},
  title        = {Granular ball twin support vector machine with universum data},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hypergraph node representation learning with one-stage message passing. <em>NN</em>, <em>193</em>, 107973. (<a href='https://doi.org/10.1016/j.neunet.2025.107973'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypergraphs as an expressive and general structure have attracted considerable attention from various research domains. Most existing hypergraph node representation learning techniques are based on graph neural networks, and thus adopt the two-stage message passing paradigm (i.e. node → hyperedge → node). This paradigm only focuses on local information propagation and does not effectively take into account global information, resulting in less optimal representations. Our theoretical analysis of representative two-stage message passing methods shows that, mathematically, they model different ways of local message passing through hyperedges, and can be unified into one-stage message passing (i.e. node → node). However, they still only model local information. Motivated by this theoretical analysis, we propose a novel one-stage message passing paradigm to model both global and local information propagation for hypergraphs. We integrate this paradigm into HGraphormer, a Transformer-based framework for hypergraph node representation learning. HGraphormer injects the hypergraph structure information (local information) into Transformers (global information) by combining the attention matrix and hypergraph Laplacian. Extensive experiments demonstrate that HGraphormer outperforms recent hypergraph learning methods on five representative benchmark datasets on the semi-supervised hypernode classification task, setting new state-of-the-art performance, with accuracy improvements between 2.52 % and 6.70 %. Our code and datasets are available. 1},
  archive      = {J_NN},
  author       = {Shilin Qu and Weiqing Wang and Yuan-Fang Li and Xin Zhou and Fajie Yuan},
  doi          = {10.1016/j.neunet.2025.107973},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107973},
  shortjournal = {Neural Netw.},
  title        = {Hypergraph node representation learning with one-stage message passing},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-view parallel convolutional network for organ segmentation in mediastinal region on CT images. <em>NN</em>, <em>193</em>, 107972. (<a href='https://doi.org/10.1016/j.neunet.2025.107972'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In lung CT images, mediastinal organ segmentation is crucial for localizing different mediastinal regions. However, existing medical image segmentation methods exhibit significant limitations in modeling the diverse topological structures of organs, sensitivity to intra-class morphological variations, and inter-class feature differentiation. To address these limitations, we propose a novel multi-view parallel convolutional network (MVPCNet), built on an efficient U-shaped encoder-decoder framework. The shallow and deep information encoders are respectively composed of alternating multi-view parallel convolution module (MVPM) and the dual-path backbone structure (DPBS) at different scales. MVPM is designed as a parallel convolutional structure to enhance the model’s ability to capture complex structural features, enabling complementary extraction of morphological and detailed features. DPBS comprises the efficient dual-channel bottleneck structures (EDC-BS) and the region fusion small-kernel deformable attention mechanism (RF-SKDA). EDC-BS employs a branched convolutional architecture, effectively reducing computational complexity while ensuring accurate recognition of the same organ across varying morphologies. RF-SKDA captures the spatial structural information of different organs by combining regional and global average pooling, and further extracts organ-specific morphological features through the deformable convolutions. The decoder utilizes lightweight parameterization through depthwise separable convolutions and integrates multi-scale features during the decoding process. Experimental results demonstrate that MVPCNet achieves an average Dice Coefficient of 90.59 % and an mIoU of 82.80 % on mediastinal organ dataset. With a parameter size of only 8.21 MB, it outperforms advanced medical segmentation algorithms and classical lightweight semantic segmentation models.},
  archive      = {J_NN},
  author       = {Yining Xie and Wei Zhou and Jiayi Ma and Fengjiao Wang and Jing Zhao},
  doi          = {10.1016/j.neunet.2025.107972},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107972},
  shortjournal = {Neural Netw.},
  title        = {Multi-view parallel convolutional network for organ segmentation in mediastinal region on CT images},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Domain-aware self-prompting for cross-domain sequential recommendations with natural language explanations. <em>NN</em>, <em>193</em>, 107969. (<a href='https://doi.org/10.1016/j.neunet.2025.107969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain sequential recommendation faces persistent challenges in addressing domain shift, data sparsity, and the trade-off between performance, efficiency, and explainability. Existing methods often struggle with inefficient cross-domain adaptation or fail to generate coherent explanations that bridge user preferences across domains. To overcome these limitations, we propose Domain-Aware Self-Prompting (DASP) , a novel framework that integrates cross-domain recommendation with natural language explanation generation. DASP introduces three key innovations: (1) a domain-invariant self-prompt generator that captures shared user preferences via contrastive alignment across domains; (2) lightweight domain adapters with meta-learned initialization for parameter-efficient adaptation to target domains; and (3) a cross-domain explanation generator that grounds recommendations in semantically aligned multi-domain prompts using large language models. Extensive experiments on Amazon Movie-Book and Food-Kitchen datasets demonstrate DASP’s superiority, achieving 10.7 % and 10.5 % improvements in HR@10 and NDCG@10 over state-of-the-art baselines on the Movie-Book dataset, while reducing training time by 54 % compared to full large language models fine-tuning approaches. Qualitative and quantitative analyses validate DASP’s ability to generate interpretable explanations that link cross-domain preferences, offering a scalable and trustworthy solution for cross-domain sequential recommendation. Our work bridges critical gaps in efficiency, adaptability, and explainability for real-world multi-domain recommendation systems.},
  archive      = {J_NN},
  author       = {Tesfaye Fenta Boka and Zhendong Niu and Tekie Tsegay Tewolde and Ramadhani Duma},
  doi          = {10.1016/j.neunet.2025.107969},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107969},
  shortjournal = {Neural Netw.},
  title        = {Domain-aware self-prompting for cross-domain sequential recommendations with natural language explanations},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive spatial feature extraction and graphical feature awareness for robust point cloud registration. <em>NN</em>, <em>193</em>, 107966. (<a href='https://doi.org/10.1016/j.neunet.2025.107966'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years Transformers have achieved significant success in the field of 3D vision due to their inherent advantages in capturing global correlations between features. However, this can be a drawback in point cloud registration, especially in scenes with low overlap rates, where a large number of non-overlapping points can lead to ineffective or even negative attention allocation. Moreover, existing RANSAC-based registration estimators usually require a large number of iterations to obtain acceptable results, resulting in significant computational overhead. To address the above issues, we propose LDGR, which achieves robust registration in low overlap scenarios by utilizing a feature extractor with adaptive receptive fields and graphical feature awareness. Firstly, we proposed a 3D convolutional method with an adaptive receptive field named Adaptive Point Convolution (APConv) as the feature extractor. Its distinguishing feature is that the receptive field of the convolutional kernel is obtained through learning, which enables it to more flexibly handle irregular and unordered point clouds, thereby extracting richer and more diverse point features. Furthermore, to overcome the dilemma in cases of low overlap, we improved the transformer with rich local geometric information embedding and graphical feature awareness. This ensures that the model focuses more on the local spatial structure and features of the points during low overlap registration. Additionally, we propose a registration evaluator with local diffusion to global (LDGR). Compared to traditional RANSAC, it achieves comparable registration quality without requiring numerous iterative computations. Finally, we conducted several experiments on publicly available datasets such as 3DMatch and 3DLoMatch, KITTI odometry, ModelNet and ModelLoNet to validate the effectiveness of our method. We achieve optimal results in all four tests on ModelNet and ModelLoNet, significantly outperforming current state-of-the-art methods. Results on the challenging 3DMatch and 3DLoMatch datasets demonstrate the robustness of our method, with our inlier ratio substantially outperforming current state-of-the-art methods. Our experiments on the KITTI dataset demonstrate that LDGR performs no worse than RANSAC, while not requiring a large number of iterations.},
  archive      = {J_NN},
  author       = {Yilin Chen and Yang Mei and Tao Lu and Lu Zou and Xiangyun Liao and Fazhi He},
  doi          = {10.1016/j.neunet.2025.107966},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107966},
  shortjournal = {Neural Netw.},
  title        = {Adaptive spatial feature extraction and graphical feature awareness for robust point cloud registration},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Major depressive disorder detection via temporal-frequency-spatial transformer with sub-domain knowledge alignment using EEG. <em>NN</em>, <em>193</em>, 107965. (<a href='https://doi.org/10.1016/j.neunet.2025.107965'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Major Depressive Disorder (MDD) is a common mental illness that seriously jeopardizes the physical and mental health of patients. Accurate detection of MDD is crucial for treatment. Currently, there are significant differences in the EEG signals of each MDD patient, leading to lower accuracy of cross-subject MDD detection. Transformer-based methods have been used by scholars to detect MDD using electroencephalogram (EEG) data, but these methods often neglect the frequency features, focusing primarily on global domain adaptation (DA) while ignoring sub-domain alignment, resulting in loss of fine-grained discriminative information. To address this, we incorporate fine-grained frequency features to improve sub-domain alignment in DA rather than relying solely on global feature alignment. Building on the above analysis, we propose the TFST-SDKA model, a temporal-frequency-spatial Transformer (TFST) integrated with a sub-domain knowledge alignment (SDKA) method for MDD detection. The SDKA module classifies subjects into distinct sub-domains based on their labels by extracting fine-grained discriminative information from each subject. This process helps bridge the gap between source and target domains, enhancing the model’s generalization. In addition, we propose a frequency attention (FA) mechanism, which uses discrete cosine transform (DCT) to convert EEG feature maps into the frequency domain. The FA extracts multiple frequency information of EEG signals associated with MDD and combines these frequency data to enhance the model’s representational capability. As a result, the TFST-SDKA model improves EEG feature representation and aligns source and target domain features. Extensive experiments conducted on the MODMA and PRED+CT datasets demonstrate that our proposed TFST-SDKA model outperforms state-of-the-art (SOTA) methods in MDD detection tasks. Specifically, our method exceeds the SOTA methods by 1.42 % on the MODMA dataset and 1.16 % on the PRED+CT dataset in terms of accuracy.},
  archive      = {J_NN},
  author       = {Chen-Yang Xu and Fei-Yi Fan and Li-Xuan Zhao and Li-Cheng Jin and Yong-Hui Zhang and Qing-Hao Meng},
  doi          = {10.1016/j.neunet.2025.107965},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107965},
  shortjournal = {Neural Netw.},
  title        = {Major depressive disorder detection via temporal-frequency-spatial transformer with sub-domain knowledge alignment using EEG},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic graph transformation with multi-task learning for enhanced spatio-temporal traffic prediction. <em>NN</em>, <em>193</em>, 107963. (<a href='https://doi.org/10.1016/j.neunet.2025.107963'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic prediction plays an essential role in intelligent transportation systems by supporting urban traffic management and public safety. A major challenge lies in addressing both the limitations of static assumptions and the inherent complexity they introduce when modeling dynamic and heterogeneous traffic systems. Traditional methods often simplify complex spatio-temporal data into a single-dimensional framework, potentially overlooking intricate node interactions and detailed network characteristics. This fundamental challenge manifests primarily in single-task approaches. When extended to multi-task learning scenarios, the complexity and limitations of this modeling challenge becomes more pronounced. To address these issues, this paper introduce a novel framework, Dynamic Graph Transformation with Multi-Task Learning (DGT-MTL) for spatio-temporal traffic prediction. DGT-MTL features a dynamic adjacency matrix generation module that balances static stability with dynamic flexibility. Additionally, it employs a multi-scale graph learning module to effectively capture fine-grained, latent features. An adaptive multi-task learning module is incorporated to uncover hidden correlations and dynamic relationships between road segments. Experiments conducted across six standard benchmarks demonstrate DGT-MTL’s superior performance compared to contemporary approaches, achieving over 15 % improvements in both ROC-AUC and F1 score metrics. Further experiments demonstrate its effectiveness and robustness in handling complex traffic prediction.},
  archive      = {J_NN},
  author       = {Nana Bu and Zongtao Duan and Wen Dang and Jianxun Zhao},
  doi          = {10.1016/j.neunet.2025.107963},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107963},
  shortjournal = {Neural Netw.},
  title        = {Dynamic graph transformation with multi-task learning for enhanced spatio-temporal traffic prediction},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A spiking network model of the cerebellum for predicting movements with diverse complex spikes. <em>NN</em>, <em>193</em>, 107962. (<a href='https://doi.org/10.1016/j.neunet.2025.107962'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smooth and coordinated motor control is believed to be achieved through prediction by forward models in the cerebellum, which generate predicted movements from motor commands. These models are acquired via supervised learning, where instruction signals, originating from the inferior olive and represented as complex spikes (CSs) in Purkinje cells, guide learning. Previous studies show that CSs represent a wide variety of motor- and nonmotor-related activities, but how this diversity contributes to forward model acquisition remains unclear. We hypothesized that predicted movements are learned through the combination of various types of CSs. To test this, we developed a spiking network model of the cerebellum as a supervised learning machine, using instruction signals based on Ca 2+ imaging data from a self-initiated lever-pull task in mice. While individual signals did not fully represent lever movements, the combination of Purkinje cell activities, trained by different instruction signals, allowed neurons in the cerebellar nucleus to represent lever trajectory. Additionally, the same set of instruction signals trained the model to generate different movement trajectories. We further confirmed that a mouse musculoskeletal model successfully reproduced lever-pulling movements. These findings suggest that forward models in the cerebellum are achieved through a combination of diverse CSs with different spatiotemporal profiles, providing an over-complete basis for movement prediction.},
  archive      = {J_NN},
  author       = {Tomohiro Mitsuhashi and Yusuke Kuniyoshi and Koji Ikezoe and Kazuo Kitamura and Tadashi Yamazaki},
  doi          = {10.1016/j.neunet.2025.107962},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107962},
  shortjournal = {Neural Netw.},
  title        = {A spiking network model of the cerebellum for predicting movements with diverse complex spikes},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Counting with ease: Class-agnostic counting via one-shot detection across diverse domains. <em>NN</em>, <em>193</em>, 107961. (<a href='https://doi.org/10.1016/j.neunet.2025.107961'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class-agnostic counting is increasingly prevalent in industrial and agricultural applications. However, most deployable methods rely on density maps, which (1) struggle with background interference in complex scenes, and (2) fail to provide precise object locations, limiting downstream usability. The advancement of class-agnostic counting is hindered by suboptimal model designs and the lack of datasets with bounding box annotations. While some studies explore text-guided methods using multimodal models, they remain impractical for edge deployment and are beyond our study’s scope. To address these limitations, we diverge from traditional counting paradigms and propose a novel Class-Agnostic Counting and Localization (CACAL) framework, which performs accurate object counting and localization using a single query image-streamlining the process for real-world use. First, we introduce a Sampling-Aware Feature Enhancement module to improve feature discriminability and mitigate confusion in shared-encoder settings. Second, we design a Split-and-Assemble Feature Matching strategy to produce structurally-aware similarity maps, boosting performance in cluttered and occluded scenarios. To further advance the field, we introduce the LOCO dataset, a large-scale benchmark with both point and bounding box annotations across industrial, agricultural, and daily-life domains. CACAL consistently outperforms existing methods across multiple benchmarks and demonstrates strong generalization across diverse domains. Our dataset will be released at: https://github.com/imMid-Star/CACAL.},
  archive      = {J_NN},
  author       = {Zhongxing Peng and Bohui Guo and Shugong Xu},
  doi          = {10.1016/j.neunet.2025.107961},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107961},
  shortjournal = {Neural Netw.},
  title        = {Counting with ease: Class-agnostic counting via one-shot detection across diverse domains},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Focusing on pedestrians like human for clothes changing person re-identification. <em>NN</em>, <em>193</em>, 107960. (<a href='https://doi.org/10.1016/j.neunet.2025.107960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current approaches focus mainly on the design of networks to learn key identity features from local body components for clothes-changing person re-identification (CC-ReID). In this paper, we propose a humanoid focus-inspired image augmentation (HFIA) method, which is intuitive image processing rather than a sophisticated network architecture designed to enhance local nuances of pedestrian images. Based on pedestrian silhouettes, we roughly divide a pedestrian image into five body components, that is, head-shoulder, upper left torso, upper right torso, lower left torso, and lower right torso. The HFIA has two key designs to deal with these components: the central emphasis strategy (CES) and the component continuity processing (CCP). For each component, leveraging the natural tendency of human visual attention towards central regions, the CES constructs an enlargement grid, where the closer the center, the greater the enlargement. To maintain the continuity of assembly, the CCP performs an overall alignment of component centers, that is, all components share the same normalized vertical coordinate and the left and right torsos have mirrored horizontal coordinates. Furthermore, the CCP implements a smoothing post-processing to uniformly erase the discontinuity between the head-shoulder, upper left torso, and upper right torso. Experiments show the state-of-the-art performance of HFIA.},
  archive      = {J_NN},
  author       = {Wenjie Pan and Jianqing Zhu and Xiaolin Cui and Huanqiang Zeng and Yibing Zhan},
  doi          = {10.1016/j.neunet.2025.107960},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107960},
  shortjournal = {Neural Netw.},
  title        = {Focusing on pedestrians like human for clothes changing person re-identification},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Concept-enhanced heterogeneous graph network for fact verification. <em>NN</em>, <em>193</em>, 107959. (<a href='https://doi.org/10.1016/j.neunet.2025.107959'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fact verification is extremely challenging in natural language processing tasks, requiring the retrieval of multiple evidence sentences from trustworthy corpora to ascertain the accuracy of a given claim. Although the current methods have achieved satisfactory performance, many of them ignore multi-granularity information or fail to fully leverage multi-granularity information, and lack inherent concept information. To tackle the issues, we propose the Concept-Enhanced Heterogeneous Graph Network (Concept-HGN) for fact verification. First, our Concept-HGN model constructs a heterogeneous graph to aggregate clues from the scattered text across multiple evidence sentences. By building different heterogeneous nodes into an integral unified graph, this hierarchical node granularity enables Concept-HGN to be more effectively applied to fact verification tasks. Then, Concept-HGN leverages the intrinsic concepts of entities from YAGO, guiding fact verification and boosting the fact verification performance. We conducted performance evaluation experiments on the FEVER and UKP Snopes datasets. On the FEVER dataset, our proposed Concept-HGN model achieved 80.26 % and 77.68 % on LA and FS, respectively. On the UKP Snopes dataset, the accuracy and macro F1 also reached 65.7 % and 61.9 %, respectively. The experimental results on these datasets indicate that the Concept-HGN model proposed in this paper outperforms the baseline models and achieves state-of-the-art performance on the task of fact verification.},
  archive      = {J_NN},
  author       = {Zhendong Chen and Lejian Liao and Siu Cheung Hui and Heyan Huang},
  doi          = {10.1016/j.neunet.2025.107959},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107959},
  shortjournal = {Neural Netw.},
  title        = {Concept-enhanced heterogeneous graph network for fact verification},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). C3aptioner: Improving change captioning by leveraging momentum cross-view and cross-modality contrastive learning. <em>NN</em>, <em>193</em>, 107957. (<a href='https://doi.org/10.1016/j.neunet.2025.107957'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary goal of change captioning is to identify subtle visual differences between two similar images and express them in natural language. Existing research has been significantly influenced by the task of vision change detection and has mainly concentrated on the identification and description of visual changes. However, we contend that an effective change captioner should go beyond mere detection and description of what has changed. Two additional aspects are crucial: 1) retaining significant and unique semantic elements that persist across both images, and 2) forging a robust link between visual cues and their concomitant descriptive linguistic elements. This paper addresses these challenges by presenting the C 3 aptioner, which seamlessly incorporates dual momentum contrastive learning objectives into change captioning. Our model architecture consists of intra-image and inter-image Transformer encoders for visual feature extraction, complemented by unimodal language and multimodal decoders. Specifically, we introduce a cross-view contrastive learning objective to capture essential invariant features by aligning cross-view representations with a momentum-updated queue of negative samples, addressing the challenge of viewpoint variations. Additionally, our cross-modality contrastive learning objective aligns and interacts visual and textual modalities using a separate momentum-maintained queue, resolving the modality gap that hampers existing methods. This dual contrastive approach enables C 3 aptioner to model both changed and unchanged elements while establishing strong vision-language correspondence, resulting in more contextually rich and human-like descriptions. Extensive experiments across five distinct datasets confirm that our approach achieves state-of-the-art performance, with particularly significant improvements in challenging scenarios involving extreme viewpoint changes. Source code is available at https://github.com/DenglinGo/C-3aptioner .},
  archive      = {J_NN},
  author       = {Lin Deng and Borui Kang and Yuzhong Zhong and Maoning Wang and Jianwei Zhang},
  doi          = {10.1016/j.neunet.2025.107957},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107957},
  shortjournal = {Neural Netw.},
  title        = {C3aptioner: Improving change captioning by leveraging momentum cross-view and cross-modality contrastive learning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CausalCOMRL: Context-based offline meta-reinforcement learning with causal representation. <em>NN</em>, <em>193</em>, 107955. (<a href='https://doi.org/10.1016/j.neunet.2025.107955'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context-based offline meta-reinforcement learning (OMRL) methods have achieved appealing success by leveragingpre-collected offline datasets to develop task representations that guide policy learning. However, current context-based OMRL methods often introduce spurious correlations, where task components are incorrectly correlated due to confounders. These correlations can degrade policy performance when the confounders in the test taskdiffer from those in the training task. To address this problem, we propose CausalCOMRL, a context-based OMRL method that integrates causal representation learning. This approach uncovers causal relationships among the task components and incorporates the causal relationships into task representations, enhancing the generalizability of RL agents. We further improve the distinction of task representations from different tasks by using mutual information optimization and contrastive learning. Utilizing these causal task representations, we employSAC to optimize policies on meta-RL benchmarks. Experimental results show that CausalCOMRL achieves better performance than other methods on most benchmarks.},
  archive      = {J_NN},
  author       = {Zhengzhe Zhang and Wenjia Meng and Haoliang Sun and Gang Pan},
  doi          = {10.1016/j.neunet.2025.107955},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107955},
  shortjournal = {Neural Netw.},
  title        = {CausalCOMRL: Context-based offline meta-reinforcement learning with causal representation},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Structure-preserving contrastive graph clustering with dual-channel label alignment. <em>NN</em>, <em>193</em>, 107954. (<a href='https://doi.org/10.1016/j.neunet.2025.107954'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past few years have witnessed the rapid development of contrastive graph clustering (CGC). Although a series of achievements have been made, there still remain two challenging problems in the literature. First, previous works typically generate different views via some pre-defined graph augmentation strategies, but inappropriate augmentations may alter the latent semantics of the original data. Second, they often overlook the discriminative unsupervised information when constructing positive and negative sample pairs, resulting in compromised clustering performance. Third, some of them are restricted to only static neighborhood connections for contrastive learning, which neglect the dynamical structural relationship via robust neighboring graph learning. To cope with these issues, this paper proposes a Structure-preserving Contrastive Graph Clustering approach with Dual-channel Label Alignment (SCGC-DLA). In terms of the high-and-low frequency issues, the low-pass and hybrid graph filters are designed for generating two views of reliable augmentations, which can supply rich and complementary information to each other. Further, we construct a structure-preserving matrix, which is derived from the edge betweenness centrality (EBC) perspective design and allows us to efficiently capture the topological relationships among different embedding representations. Under the guidance of the non-dominated sorting theory, the clustering distribution information of dual-channel is used to construct high-confidence pseudo labels. Especially, the generated high-confidence pseudo labels are aligned with latent semantic labels. Finally, the overall network is guided by a self-supervised learning scheme and therefore the final clustering could be obtained. Substantial results on five benchmarks prove the robustness and effectiveness of our approach compared to several state-of-the-arts.},
  archive      = {J_NN},
  author       = {Guang-Yu Zhang and Yan-Di Huang and Dong Huang and Chang-Dong Wang and Yang Liu and Enbo Huang},
  doi          = {10.1016/j.neunet.2025.107954},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107954},
  shortjournal = {Neural Netw.},
  title        = {Structure-preserving contrastive graph clustering with dual-channel label alignment},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). C3GAN: A brain-inspired memory consolidation for class-incremental learning. <em>NN</em>, <em>193</em>, 107952. (<a href='https://doi.org/10.1016/j.neunet.2025.107952'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human cognition excels in lifelong learning, seamlessly acquiring, retaining, and transferring knowledge. In contrast, deep neural networks suffer from catastrophic forgetting, where training on new tasks rapidly erases previously acquired knowledge. In the human brain, memory reactivation is crucial for preserving memories over time. Similarly, generative replay in artificial neural networks shows potential for addressing forgetting by reactivating learned representations. However, existing generative replay techniques struggle with complex tasks and high-dimensional data, as they shift the burden from the task-solving network to the generative network, which is also prone to catastrophic forgetting. In this paper, we propose C3GAN , a brain-inspired model that combines C ontrastive C lustering and C onditional G enerative A dversarial N etworks to emulate the memory consolidation processes of the brain. C3GAN uses contrastive class structuring to consolidate recent memories, mimicking hippocampal functions, and incorporates a conditional generative adversarial network to facilitate long-term knowledge storage, akin to the prefrontal cortex. Additionally, an amygdala-inspired module enhances selective replay of indistinguishable classes by prioritizing memory that is emotionally salient, similar to the amygdala’s role in strengthening the retention of significant experiences. C3GAN achieves state-of-the-art performance on class-incremental learning benchmarks without raw data, providing a novel solution for lifelong memory retention in artificial systems.},
  archive      = {J_NN},
  author       = {Lin Xiong and Tao Wang and Fuqing Zhang and Kangwen Zhu and Hailing Xiong},
  doi          = {10.1016/j.neunet.2025.107952},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107952},
  shortjournal = {Neural Netw.},
  title        = {C3GAN: A brain-inspired memory consolidation for class-incremental learning},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Knowledge-distillation based personalized federated learning with distribution constraints. <em>NN</em>, <em>193</em>, 107951. (<a href='https://doi.org/10.1016/j.neunet.2025.107951'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized federated learning PFL seeks to develop models that are tailored to the unique data distributions of individual clients. While some methods rely on a global server model to guide personalization, more recent methods focus on directly learn personalized models. Among these, leveraging inter-client correlations has become a widely adopted strategy for personalized model generation. PFedGraph exemplifies this by constructing client relationships based on model similarity for personalized model aggregation, achieving outstanding personalized performance. However, pFedgraph overlooks category distribution information, a critical aspect reflecting data distribution heterogeneity, although it has been extensively applied in machine learning and federated learning tasks. Category distribution can serve as a direct and informative metric for measuring inter-client data divergence. Furthermore, pFedGraph underutilizes global knowledge derived from diverse client datasets, limiting its personalized ability. To address these limitations, we incorporate category distribution constraints into the computation of client-specific aggregation weights, enabling the generation of personalized models enriched with distribution-aware information. Additionally, to mitigate the risk of overfitting to local data and enhance the use of global knowledge, we align the outputs of personalized models with those of the global model, which is obtained through the classical federated averaging algorithm, to effectively transfer shared global knowledge to personalized models. The proposed method consistently outperforms state-of-the-art approaches across diverse data types and distribution scenarios, demonstrating its effectiveness.},
  archive      = {J_NN},
  author       = {Ziyang Zhang and Chang Mu and Kailing Guo and Xiang Tian and Xiangmin Xu},
  doi          = {10.1016/j.neunet.2025.107951},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107951},
  shortjournal = {Neural Netw.},
  title        = {Knowledge-distillation based personalized federated learning with distribution constraints},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing robustness of spiking neural networks through retina-like coding and memory-based neurons. <em>NN</em>, <em>193</em>, 107950. (<a href='https://doi.org/10.1016/j.neunet.2025.107950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) are emerging as a promising alternative to traditional artificial neural networks (ANNs), offering advantages such as lower power consumption and biological interpretability. Despite recent progress in training SNNs and their performance in computer vision tasks, there remains a question of SNN robustness to corrupted images in real-world scenarios. To address this problem, we introduce CIFAR10-C and IMAGENET-C datasets from the ANN field as benchmarks and further propose novel methods to improve SNN corruption robustness. Specifically, we propose a retina-like coding to simulate dynamic human visual perception, providing a foundation for extracting robust features through varied temporal input. Meanwhile, we introduce a memory-based spiking neuron (MSN) that integrates memory units to learn robust features, along with a parallel version (MPSN) to facilitate parallel computing and achieve superior performance. Experimental results demonstrate that our method improves SNN recognition accuracy and robustness, achieving average accuracies of 87.04 % on the CIFAR10-C dataset and 40.37 the IMAGENET-C dataset, surpassing the state-of-the-art SNN method’s 85.95 % and 39.11 %, respectively. These findings highlight the potential of our approach to enhance the robustness of SNNs in real-world scenarios. Our codes will be released in https://github.com/JiaHongZ/Retina-MPSN .},
  archive      = {J_NN},
  author       = {Jiahong Zhang and Kexin Wang and Man Yao and Han Xu and Peng Zhou and Bo Xu and Guoqi Li},
  doi          = {10.1016/j.neunet.2025.107950},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107950},
  shortjournal = {Neural Netw.},
  title        = {Enhancing robustness of spiking neural networks through retina-like coding and memory-based neurons},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). G-NeuroDAVIS: A generative model for data visualization through a generalized embedding. <em>NN</em>, <em>193</em>, 107948. (<a href='https://doi.org/10.1016/j.neunet.2025.107948'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visualizing high-dimensional datasets through a generalized embedding has been a longstanding challenge. Several methods have been proposed for this purpose, but they have yet to generate a generalized embedding that not only reveals the hidden patterns present in the data but also generates realistic high-dimensional samples from it. Motivated by this aspect, in this article, a novel generative model called G-NeuroDAVIS has been developed, which is capable of visualizing high-dimensional data through a generalized embedding and thereby generating new samples. The model leverages advanced generative techniques to produce high-quality embedding that captures the underlying structure of the data more effectively compared with the existing methods. G-NeuroDAVIS can be trained in both supervised and unsupervised settings. We have rigorously evaluated our model through a series of experiments, demonstrating superior performance in several downstream tasks, which highlights the effectiveness of the learned representations. Results of an interpolation experiment reflect a smooth and meaningful transition in the generated images across various paths, which in turn depict preservation of underlying data structure. Furthermore, the conditional sample generation capability of the model has been described through both qualitative and quantitative assessments, revealing a marked improvement in generating realistic and diverse samples. G-NeuroDAVIS has outperformed Variational Autoencoder (VAE) significantly in terms of embedding quality and downstream tasks like classification. Moreover, the superior sample generation capability of G-NeuroDAVIS has been demonstrated against VAE, Deep Convolutional Generative Adversarial Network (DCGAN), Denoising Diffusion Probabilistic Models (DDPM), and Autoencoder (AE)-guided Real-valued Non-Volume Preserving (RealNVP). These results highlight the efficacy of G-NeuroDAVIS to serve as a robust tool in various applications that demand high-quality data generation and representation learning.},
  archive      = {J_NN},
  author       = {Chayan Maitra and Rajat K. De},
  doi          = {10.1016/j.neunet.2025.107948},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107948},
  shortjournal = {Neural Netw.},
  title        = {G-NeuroDAVIS: A generative model for data visualization through a generalized embedding},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A new local time-decoupled squared wasserstein-2 method for training stochastic neural networks to reconstruct uncertain parameters in dynamical systems. <em>NN</em>, <em>193</em>, 107893. (<a href='https://doi.org/10.1016/j.neunet.2025.107893'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose and analyze a new local time-decoupled squared Wasserstein-2 method for reconstructing the distribution of unknown parameters in dynamical systems from a finite number of observed temporal trajectories. Specifically, we show that a stochastic neural network model, which can be effectively trained by minimizing our proposed local time-decoupled squared Wasserstein-2 loss function, is an effective model for approximating the distribution of uncertain model parameters in dynamical systems. Through several numerical examples, we showcase the effectiveness of our proposed method in reconstructing the distribution of parameters in different dynamical systems.},
  archive      = {J_NN},
  author       = {Mingtao Xia and Qijing Shen and Philip K. Maini and Eamonn A. Gaffney and Alex Mogilner},
  doi          = {10.1016/j.neunet.2025.107893},
  journal      = {Neural Networks},
  month        = {1},
  pages        = {107893},
  shortjournal = {Neural Netw.},
  title        = {A new local time-decoupled squared wasserstein-2 method for training stochastic neural networks to reconstruct uncertain parameters in dynamical systems},
  volume       = {193},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
