<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIJ</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aij">AIJ - 3</h2>
<ul>
<li><details>
<summary>
(2026). Online POMDP planning with anytime deterministic optimality guarantees. <em>AIJ</em>, <em>350</em>, 104442. (<a href='https://doi.org/10.1016/j.artint.2025.104442'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-making under uncertainty is a critical aspect of many practical autonomous systems due to incomplete information. Partially Observable Markov Decision Processes (POMDPs) offer a mathematically principled framework for formulating decision-making problems under such conditions. However, finding an optimal solution for a POMDP is generally intractable. In recent years, there has been a significant progress of scaling approximate solvers from small to moderately sized problems, using online tree search solvers. Often, such approximate solvers are limited to probabilistic or asymptotic guarantees towards the optimal solution. In this paper, we derive a deterministic relationship for discrete POMDPs between an approximated and the optimal solution. We show that at any time, we can derive bounds that relate between the existing solution and the optimal one. We show that our derivations provide an avenue for a new set of algorithms and can be attached to existing algorithms that have a certain structure to provide them with deterministic guarantees with marginal computational overhead. In return, not only do we certify the solution quality, but we demonstrate that making a decision based on the deterministic guarantee may result in superior performance compared to the original algorithm without the deterministic certification.},
  archive      = {J_AIJ},
  author       = {Moran Barenboim and Vadim Indelman},
  doi          = {10.1016/j.artint.2025.104442},
  journal      = {Artificial Intelligence},
  month        = {1},
  pages        = {104442},
  shortjournal = {Artif. Intell.},
  title        = {Online POMDP planning with anytime deterministic optimality guarantees},
  volume       = {350},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A general theoretical framework for learning smallest interpretable models. <em>AIJ</em>, <em>350</em>, 104441. (<a href='https://doi.org/10.1016/j.artint.2025.104441'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a general algorithmic framework that allows us to obtain fixed-parameter tractability for computing smallest symbolic models that represent given data. Our framework applies to all ML model types that admit a certain extension property. By establishing this extension property for decision trees, decision sets, decision lists, and binary decision diagrams, we obtain that minimizing these fundamental model types is fixed-parameter tractable. Our framework even applies to ensembles, which combine individual models by majority decision.},
  archive      = {J_AIJ},
  author       = {Sebastian Ordyniak and Giacomo Paesani and Mateusz Rychlicki and Stefan Szeider},
  doi          = {10.1016/j.artint.2025.104441},
  journal      = {Artificial Intelligence},
  month        = {1},
  pages        = {104441},
  shortjournal = {Artif. Intell.},
  title        = {A general theoretical framework for learning smallest interpretable models},
  volume       = {350},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Kernel-bounded clustering: Achieving the objective of spectral clustering without eigendecomposition. <em>AIJ</em>, <em>350</em>, 104440. (<a href='https://doi.org/10.1016/j.artint.2025.104440'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research on spectral clustering (SC) has thus far been pursued on the same track using the same tool of eigendecomposition of a matrix since the idea was first introduced in 1973. Despite its successes, SC has been identified to have fundamental limitations that prevent SC from discovering certain types of clusters, and SC has slow runtime. We offer an alternative path that does not involve the eigendecomposition, and, more broadly, it uses no optimization. The proposed new Kernel-Bounded Clustering (KBC) is a complete metamorphosis in 50 years of research in SC in view of the fact that KBC achieves the same objective of SC without eigendecomposition or optimization. We evaluated KBC on the datasets that have been used to demonstrate the fundamental limitations of SC, genome-wide expression data, large image datasets and many commonly used real-world benchmark datasets. KBC produced better quality clusters than various variants of SC, and it ran six orders of magnitude faster than the traditional SC on a set of 5 million data points.},
  archive      = {J_AIJ},
  author       = {Hang Zhang and Kai Ming Ting and Ye Zhu},
  doi          = {10.1016/j.artint.2025.104440},
  journal      = {Artificial Intelligence},
  month        = {1},
  pages        = {104440},
  shortjournal = {Artif. Intell.},
  title        = {Kernel-bounded clustering: Achieving the objective of spectral clustering without eigendecomposition},
  volume       = {350},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
