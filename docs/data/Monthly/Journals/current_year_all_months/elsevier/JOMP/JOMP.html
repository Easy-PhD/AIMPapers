<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JOMP</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jomp">JOMP - 29</h2>
<ul>
<li><details>
<summary>
(2025). Experiment-based calibration in psychology: Foundational and data-generating model. <em>JOMP</em>, <em>127</em>, 102950. (<a href='https://doi.org/10.1016/j.jmp.2025.102950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experiment-based calibration is a novel method for measurement validation, which – unlike classical validity metrics – does not require stable between-person variance. In this approach, the latent variable to be measured is manipulated by an experiment, and its predicted scores – termed standard scores – are compared against the measured scores. Previous work has shown that under plausible boundary conditions, the correlation between standard and measured scores – termed retrodictive validity – is informative about measurement accuracy, i.e. combined trueness and precision. Here, I expand these findings in several directions. First, I formalise the approach in a probability-theoretic framework with the concept of a standardised calibration space. Second, I relate this framework to classical validity theory and show that the boundary conditions in fact apply to any form of criterion validity, including classical convergent validity. Thus, I state precise and empirically quantifiable boundary conditions under which criterion validity metrics are informative on validity. Third, I relate these boundary conditions to confounding variables, i.e. correlated latent variables. I show that in the limit, calibration will converge on the latent variable that is most closely related to the standard. Finally, I provide a framework for modelling the data-generating process with Markov kernels, and identify sufficient conditions under which the data generation model results in a calibration space. In sum, this article provides a formal probability-theoretic framework for experiment-based calibration and facilitates modelling and empirical assessment of the data generating processes.},
  archive      = {J_JOMP},
  author       = {Dominik R. Bach},
  doi          = {10.1016/j.jmp.2025.102950},
  journal      = {Journal of Mathematical Psychology},
  month        = {12},
  pages        = {102950},
  shortjournal = {J. Math. Psychol.},
  title        = {Experiment-based calibration in psychology: Foundational and data-generating model},
  volume       = {127},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On iverson’s law of similarity. <em>JOMP</em>, <em>127</em>, 102943. (<a href='https://doi.org/10.1016/j.jmp.2025.102943'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Iverson (2006b) proposed the law of similarity ξ s ( λ x ) = γ ( λ , s ) ξ η ( λ , s ) ( x ) for the sensitivity functions ξ s ( s ∈ S ) . Compared to the former models, the generality of this one lies in that here γ and η can also depend on the variables λ and s . In the literature, this model (or its special cases) is usually considered together with a given psychophysical representation (e.g. Fechnerian, subtractive, or affine). Our goal, however, is to study at first Iverson’s law of similarity on its own. We show that if certain mild assumptions are fulfilled, then ξ can be written in a rather simple form containing only one-variable functions. The obtained form proves to be very useful when we assume some kind of representation. Motivated by Hsu and Iverson (2016) , we then study the above model assuming that the mapping η is multiplicatively translational. First, we show how these mappings can be characterized. Later we turn to the examination of Falmagne’s power law. According to our results, the corresponding function ξ can have a Fechnerian representation, and also it can have a subtractive representation. We close the paper with the study of the shift invariance property.},
  archive      = {J_JOMP},
  author       = {Eszter Gselmann and Christopher W. Doble and Yung-Fong Hsu},
  doi          = {10.1016/j.jmp.2025.102943},
  journal      = {Journal of Mathematical Psychology},
  month        = {12},
  pages        = {102943},
  shortjournal = {J. Math. Psychol.},
  title        = {On iverson’s law of similarity},
  volume       = {127},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal analysis of absolute and relative risk reductions. <em>JOMP</em>, <em>127</em>, 102942. (<a href='https://doi.org/10.1016/j.jmp.2025.102942'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Any medical innovation must first prove its benefits with reliable evidence from clinical trials. Evidence is commonly expressed using two metrics, summarizing treatment benefits based on either absolute risk reductions (ARRs) or relative risk reductions (RRRs). Both metrics are derived from the same data, but they implement conceptually distinct ideas. Here, we analyze these risk reductions measures from a causal modeling perspective. First, we show that ARR is equivalent to Δ P , while RRR is equivalent to causal power, thus clarifying the implicit causal assumptions. Second, we show how this formal equivalence establishes a relationship with causal Bayes nets theory, offering a basis for incorporating risk reduction metrics into a computational modeling framework. Leveraging these analyses, we demonstrate that under dynamically varying baseline risks, ARRs and RRRs lead to strongly diverging predictions. Specifically, the inherent assumption of a linear parameterization of the underlying causal graph can lead to incorrect conclusions when generalizing treatment benefits (e.g, predicting the effect of a vaccine in new populations with different baseline risks). Our analyses highlight the shared principles underlying risk reduction metrics and measures of causal strength, emphasizing the potential for explicating causal structure and inference in medical research.},
  archive      = {J_JOMP},
  author       = {Björn Meder and Charley M. Wu and Felix G. Rebitschek},
  doi          = {10.1016/j.jmp.2025.102942},
  journal      = {Journal of Mathematical Psychology},
  month        = {12},
  pages        = {102942},
  shortjournal = {J. Math. Psychol.},
  title        = {Causal analysis of absolute and relative risk reductions},
  volume       = {127},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An alternative attribute map for polytomous assessment structures. <em>JOMP</em>, <em>126</em>, 102941. (<a href='https://doi.org/10.1016/j.jmp.2025.102941'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present paper introduces an attribute map that offers an alternative approach to modeling polytomous item–response relationships. This new attribute map is based on the principle that each available attribute can independently enable an item to reach a specific observable response level. The paper rigorously defines this attribute map and establishes the corresponding item–response function. Using these two maps, a coherent attribute structure is constructed, leading to a competence-based polytomous assessment structure. Finally, a straightforward mathematical example is provided to illustrate the validity and practical applicability of this theoretical framework.},
  archive      = {J_JOMP},
  author       = {Bo Wang and Jinjin Li and Bochi Xu and Wen Sun and Yingru Lin},
  doi          = {10.1016/j.jmp.2025.102941},
  journal      = {Journal of Mathematical Psychology},
  month        = {8},
  pages        = {102941},
  shortjournal = {J. Math. Psychol.},
  title        = {An alternative attribute map for polytomous assessment structures},
  volume       = {126},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterization of countable and continuous Richter–Peleg multi-utility representations. <em>JOMP</em>, <em>126</em>, 102940. (<a href='https://doi.org/10.1016/j.jmp.2025.102940'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper contributes to the theoretical literature on decision models where agents may encounter challenges in comparing alternatives. We introduce a characterization of countable Richter–Peleg multi-utility representations, both semicontinuous (upper and lower) and continuous, within preorders that may not be total. The proposed theorems provide a comprehensive mathematical framework, complementing previous results of Alcantud et al. and Bosi on countable multi-utility representations. Our characterizations establish necessary and sufficient conditions through topological properties and constructive methods via indicator functions. Furthermore, we introduce a topological framework aligned with the property of strong local non-satiation and provide a novel theorem containing sufficient conditions for the existence of countable upper semi-continuous multi-utility representations of a preorder. The results demonstrate that preference representations can be achieved using countably many functions rather than uncountable families, with implications for computational tractability and the identification of maximal elements in optimization contexts.},
  archive      = {J_JOMP},
  author       = {Gianni Bosi and Esteban Induráin and Ana Munárriz and Yeray R. Rincón},
  doi          = {10.1016/j.jmp.2025.102940},
  journal      = {Journal of Mathematical Psychology},
  month        = {8},
  pages        = {102940},
  shortjournal = {J. Math. Psychol.},
  title        = {Characterization of countable and continuous Richter–Peleg multi-utility representations},
  volume       = {126},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The stochastic 2-binary choice problem. <em>JOMP</em>, <em>126</em>, 102939. (<a href='https://doi.org/10.1016/j.jmp.2025.102939'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classic (to date unsolved) stochastic binary choice problem asks under what conditions a given stochastic choice function defined on pairs of alternatives derives from a random ranking. We propose a solution to the problem for the case in which at most two rankings are assigned positive probability. This case is psychologically motivated and interesting for applications. It is structurally different from the general case in that the choice functions that are derived from a random ranking do not necessarily form a convex polytope, hence they are not even in principle described by a set of linear inequalities.},
  archive      = {J_JOMP},
  author       = {Paola Manzini and Marco Mariotti and Henrik Petri},
  doi          = {10.1016/j.jmp.2025.102939},
  journal      = {Journal of Mathematical Psychology},
  month        = {8},
  pages        = {102939},
  shortjournal = {J. Math. Psychol.},
  title        = {The stochastic 2-binary choice problem},
  volume       = {126},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Random utility without regularity. <em>JOMP</em>, <em>126</em>, 102938. (<a href='https://doi.org/10.1016/j.jmp.2025.102938'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classical random utility models imply a consistency property called regularity . Decision makers who satisfy regularity are at least as likely to choose an option x from a set X of available options as from any larger set Y that contains X . In light of ample empirical evidence for context-dependent choice that violates regularity, some researchers have questioned the descriptive validity of all random utility models. In this article, we show that not all random utility models imply regularity. We propose a general framework for random utility models that accommodate context dependence and may violate regularity. Mathematically, like the classical models, context-dependent random utility models form convex polytopes. They yield behavioral predictions for those choice sets from which choices are made, by specifying combinations of preference rankings across two or more contexts. We discuss how context-dependent models can be less or more parsimonious than the classical models. Random utility models with or without regularity can be tested with contemporary methods of order-constrained inference.},
  archive      = {J_JOMP},
  author       = {Johannes Müller-Trede and Michel Regenwetter},
  doi          = {10.1016/j.jmp.2025.102938},
  journal      = {Journal of Mathematical Psychology},
  month        = {8},
  pages        = {102938},
  shortjournal = {J. Math. Psychol.},
  title        = {Random utility without regularity},
  volume       = {126},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalizing survivor interaction contrast functions for coactive systems to the linear ballistic accumulator model, inhomogeneous poisson processes, and presenting a novel ‘bare bones’ stochastic process. <em>JOMP</em>, <em>126</em>, 102937. (<a href='https://doi.org/10.1016/j.jmp.2025.102937'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A typical redundant signals experiment assesses response time (RT) performance when either of two (or more) presented signals is sufficient to make a correct response against response time to respond to either of the signals alone. In some studies perception of both signals takes place faster than either alone and even faster than what a parallel system with independent, unlimited capacity channels can predict. This behavior is referred to as super capacity (Townsend & Nozawa, 1995). In fact, J. Miller’s earlier 1982 data was interpreted as exhibiting performance that was so super capacity that it violated an upper bound on performance through a statistic known in mathematics as the Poisson Inequality, and now referred to in the literature as the race model inequality (RMI). The most popular type of explanatory model assumes that information (treated as an activation random variable in each channel) from two parallel channels is summed into a subsequent single channel where the sum is compared with a criterion activation. Such a process is dubbed coactivation and several specific such models were shown to be able to make such predictions. Then, it was shown by Townsend & Nozawa (1995) that any arbitrary counter model (i.e., with arbitrary stochastic processes for the concurrent counters) perforce predicted violation of the RMI. Further, using the systems factorial technology statistical function named the survivor interaction contrast (SIC), they proved that standard Poisson counter models predict a specific distinctive function for coactive processing. However, other architectures (e.g., parallel and serial models) are entirely general rather than being confined to Poisson counters. Subsequently, Houpt & Townsend (2011) generalized the SIC prediction to the popular Ratcliff–Wiener drift–diffusion process. Our satisfied goal here was to further extend the classes of covered coactive systems to the popular Linear Ballistic Accumulator (e.g., Brown & Heathcote, 2008), the entire class of Inhomogeneous Poisson Processes, and a novel system we call the bare bones stochastic process. In addition, we adduce a set of sufficient conditions that any monotone distribution should meet to predict for their convolution to obey the canonical SIC form.},
  archive      = {J_JOMP},
  author       = {James T. Townsend and Joseph W. Houpt},
  doi          = {10.1016/j.jmp.2025.102937},
  journal      = {Journal of Mathematical Psychology},
  month        = {8},
  pages        = {102937},
  shortjournal = {J. Math. Psychol.},
  title        = {Generalizing survivor interaction contrast functions for coactive systems to the linear ballistic accumulator model, inhomogeneous poisson processes, and presenting a novel ‘bare bones’ stochastic process},
  volume       = {126},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expected exponential discounting in inter-temporal decision making. <em>JOMP</em>, <em>126</em>, 102927. (<a href='https://doi.org/10.1016/j.jmp.2025.102927'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel interpretation of delay discounting – a theoretical mechanism by which decision-makers discount the current value of reward if it is obtained at a future time rather than immediately. The theory proposes that decision-makers rationally account for the natural phenomenon of compounded interests (use exponential discounting) but need to take an average or expected value over some uncertainty distribution for the compound interest rate. Hence, the name Expected Exponential Discounting (EED) theory of inter-temporal choice. We show that EED provides a mechanism that unifies multiple empirically discovered descriptive discounting functions and fits to key qualitative findings about delay discounting in humans under non-sequential contexts, such as for hypothetical questions about delayed rewards. The general, falsifiable and comparatively minimal EED theory provides a good sanity check for more complex accounts of delay discounting, but also supports the derivation of new empirical predictions and reference points.},
  archive      = {J_JOMP},
  author       = {Tom H. Rosenström and Alasdair I. Houston},
  doi          = {10.1016/j.jmp.2025.102927},
  journal      = {Journal of Mathematical Psychology},
  month        = {8},
  pages        = {102927},
  shortjournal = {J. Math. Psychol.},
  title        = {Expected exponential discounting in inter-temporal decision making},
  volume       = {126},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Honey, i shrunk the irrelevant effects! simple and flexible approximate bayesian regularization. <em>JOMP</em>, <em>126</em>, 102925. (<a href='https://doi.org/10.1016/j.jmp.2025.102925'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the social and behavioral sciences and related fields, statistical models are becoming increasingly complex with more parameters to explain intricate dependency structures among larger sets of variables. Regularization techniques, like penalized regression, help identify key parameters by shrinking negligible effects to zero, resulting in parsimonious solutions with strong predictive performance. This paper introduces a simple and flexible approximate Bayesian regularization (ABR) procedure, combining a Gaussian approximation of the likelihood with a Bayesian shrinkage prior to obtain a regularized posterior. Parsimonious (interpretable) solutions are obtained by taking the posterior modes. Parameter uncertainty is quantified using the full posterior. Implemented in the R package shrinkem , the method is evaluated in synthetic and empirical applications. Its flexibility is demonstrated across various models, including linear regression, relational event models, mediation analysis, factor analysis, and Gaussian graphical models.},
  archive      = {J_JOMP},
  author       = {Diana Karimova and Sara van Erp and Roger Th.A.J. Leenders and Joris Mulder},
  doi          = {10.1016/j.jmp.2025.102925},
  journal      = {Journal of Mathematical Psychology},
  month        = {8},
  pages        = {102925},
  shortjournal = {J. Math. Psychol.},
  title        = {Honey, i shrunk the irrelevant effects! simple and flexible approximate bayesian regularization},
  volume       = {126},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward a unified perspective on assessment models, part II: Dichotomous latent variables. <em>JOMP</em>, <em>125</em>, 102926. (<a href='https://doi.org/10.1016/j.jmp.2025.102926'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past years, several theories for assessment have been developed within the fields of Psychometrics and Mathematical Psychology. The most notable are Item Response Theory (IRT), Cognitive Diagnostic Assessment (CDA), and Knowledge Structure Theory (KST). In spite of their common goals, these theories have been developed largely independently, focusing on slightly different aspects. In Part I of this three-part work, a general framework was introduced with the aim of achieving a unified perspective. The framework consists of two primitives (structure and process) and two operations (factorization and reparametrization) that allow to derive the models of these theories and systematize them within a general taxonomy. In this second contribution, the framework introduced in Part I is used to derive both KST and CDA models based on dichotomous latent variables, thus achieving a two-fold result: On the one hand, it settles the relation between the frameworks; On the other hand, it provides a simultaneous generalization of both frameworks, thus providing the foundations for the analysis of more general models and situations.},
  archive      = {J_JOMP},
  author       = {Stefano Noventa and Jürgen Heller and Sangbeak Ye and Augustin Kelava},
  doi          = {10.1016/j.jmp.2025.102926},
  journal      = {Journal of Mathematical Psychology},
  month        = {5},
  pages        = {102926},
  shortjournal = {J. Math. Psychol.},
  title        = {Toward a unified perspective on assessment models, part II: Dichotomous latent variables},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using systems factorial technology for global model analysis of ACT-r’s core architectural assumptions. <em>JOMP</em>, <em>125</em>, 102924. (<a href='https://doi.org/10.1016/j.jmp.2025.102924'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive architectures (CAs) are unified theories of cognition which describe invariant properties in the structure and function of cognition, including how sub-systems (e.g., memory, vision) interact as a coherent system. One problem stemming from the size and flexibility of CAs is deriving critical tests of their core architectural assumptions. To address this issue, we combine systems factorial technology (SFT) and global model analysis (GMA) into a unified framework called SFT-GMA. In the framework, the prediction space is defined in terms of qualitative classes of SFT models, and GMA identifies constraints on this space based on core architectural assumptions. Critical tests are then derived and tested with SFT. Our application of SFT-GMA to ACT-R revealed two key insights: (1) we identified critical tests despite many degrees of freedom in model specification, and (2) ACT-R requires serial processing of perceptual stimuli under most conditions. These processing constraints on perception are at odds with data reported in several published experiments.},
  archive      = {J_JOMP},
  author       = {Christopher R. Fisher and Joseph W. Houpt and Othalia Larue and Kevin Schmidt},
  doi          = {10.1016/j.jmp.2025.102924},
  journal      = {Journal of Mathematical Psychology},
  month        = {5},
  pages        = {102924},
  shortjournal = {J. Math. Psychol.},
  title        = {Using systems factorial technology for global model analysis of ACT-r’s core architectural assumptions},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coupling quantum-like cognition with the neuronal networks within generalized probability theory. <em>JOMP</em>, <em>125</em>, 102923. (<a href='https://doi.org/10.1016/j.jmp.2025.102923'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past few years have seen a surge in the application of quantum-like (QL) modeling in fields such as cognition, psychology, and decision-making. Despite the success of this approach in explaining various psychological phenomena, there remains a potential dissatisfaction due to its lack of clear connection to neurophysiological processes in the brain. Currently, it remains a phenomenological approach. In this paper, we develop a QL representation of networks of communicating neurons. This representation is not based on standard quantum theory but on generalized probability theory (GPT), with a focus on the operational measurement framework (see section 2.1 for comparison of classical, quantum, and generalized probability theories). Specifically, we use a version of GPT that relies on ordered linear state spaces rather than the traditional complex Hilbert spaces. A network of communicating neurons is modeled as a weighted directed graph, which is encoded by its weight matrix. The state space of these weight matrices is embedded within the GPT framework, incorporating effect-observables and state updates within the theory of measurement instruments — a critical aspect of this model. Under the specific assumption regarding neuronal connectivity, the compound system S = ( S 1 , S 2 ) of neuronal networks is represented using the tensor product. This S 1 ⊗ S 2 representation significantly enhances the computational power of S . The GPT-based approach successfully replicates key QL effects, such as order, non-repeatability, and disjunction effects — phenomena often associated with decision interference. Additionally, this framework enables QL modeling in medical diagnostics for neurological conditions like depression and epilepsy. While the focus of this paper is primarily on cognition and neuronal networks, the proposed formalism and methodology can be directly applied to a broad range of biological and social networks. Furthermore, it supports the claims of superiority made by quantum-inspired computing and can serve as the foundation for developing QL-based AI systems, specifically utilizing the QL representation of oscillator networks.},
  archive      = {J_JOMP},
  author       = {Andrei Khrennikov and Masanao Ozawa and Felix Benninger and Oded Shor},
  doi          = {10.1016/j.jmp.2025.102923},
  journal      = {Journal of Mathematical Psychology},
  month        = {5},
  pages        = {102923},
  shortjournal = {J. Math. Psychol.},
  title        = {Coupling quantum-like cognition with the neuronal networks within generalized probability theory},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secure and perfect maximality. <em>JOMP</em>, <em>125</em>, 102922. (<a href='https://doi.org/10.1016/j.jmp.2025.102922'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper introduces a refinement of maximality, called secure maximality, and a refinement of secure maximality, called perfect maximality. The effectivity of these refinements and the connection with other relevant optimality notions are investigated. Furthermore, necessary and sufficient conditions are provided for the secure maximality of all maximals and for the perfect maximality of all maximals as well as for the perfect maximality of all secure maximals. Several sufficient conditions for (as well as two characterizations of) the existence of secure and perfect maximals are established. The precise structure of the entire sets of secure and perfect maximals is examined for some specific classes of relations like interval orders that admit a certain type of representability by means of two real-valued functions, relations induced by cones and relations that admit linear multi-utility representations.},
  archive      = {J_JOMP},
  author       = {Federico Quartieri},
  doi          = {10.1016/j.jmp.2025.102922},
  journal      = {Journal of Mathematical Psychology},
  month        = {5},
  pages        = {102922},
  shortjournal = {J. Math. Psychol.},
  title        = {Secure and perfect maximality},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A concise mathematical description of active inference in discrete time. <em>JOMP</em>, <em>125</em>, 102921. (<a href='https://doi.org/10.1016/j.jmp.2025.102921'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a concise mathematical description of active inference in discrete time. The main part of the paper serves as a basic introduction to the topic, including a detailed example of the action selection mechanism. The appendix discusses the more subtle mathematical details, targeting readers who have already studied the active inference literature but struggle to make sense of the mathematical details and derivations. Throughout, we emphasize precise and standard mathematical notation, ensuring consistency with existing texts and linking all equations to widely used references on active inference. Additionally, we provide Python code that implements the action selection and learning mechanisms described in this paper and is compatible with pymdp environments.},
  archive      = {J_JOMP},
  author       = {Jesse van Oostrum and Carlotta Langer and Nihat Ay},
  doi          = {10.1016/j.jmp.2025.102921},
  journal      = {Journal of Mathematical Psychology},
  month        = {5},
  pages        = {102921},
  shortjournal = {J. Math. Psychol.},
  title        = {A concise mathematical description of active inference in discrete time},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Traits and tangles: An analysis of the big five paradigm by tangle-based clustering. <em>JOMP</em>, <em>125</em>, 102920. (<a href='https://doi.org/10.1016/j.jmp.2025.102920'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using the recently developed mathematical theory of tangles, we re-assess the mathematical foundations for applications of the five factor model in personality tests by a new, mathematically rigorous, quantitative method. Our findings broadly confirm the validity of current tests, but also show that more detailed information can be extracted from existing data. We found that the big five traits appear at different levels of scrutiny. Some already emerge at a coarse resolution of our tools at which others cannot yet be discerned, while at a resolution where these can be discerned, and distinguished, some of the former traits are no longer visible but have split into more refined traits or disintegrated altogether. We also identified traits other than the five targeted in those tests. These include more general traits combining two or more of the big five, as well as more specific traits refining some of them. All our analysis is structural and quantitative, and thus rigorous in explicitly defined mathematical terms. Since tangles, once computed, can be described concisely in terms of very few explicit statements referring only to the test questions used, our findings are also directly open to interpretation by experts in psychology. Tangle analysis can be applied similarly to other topics in psychology. Our paper is intended to serve as a first indication of what may be possible.},
  archive      = {J_JOMP},
  author       = {Hanno von Bergen and Reinhard Diestel},
  doi          = {10.1016/j.jmp.2025.102920},
  journal      = {Journal of Mathematical Psychology},
  month        = {5},
  pages        = {102920},
  shortjournal = {J. Math. Psychol.},
  title        = {Traits and tangles: An analysis of the big five paradigm by tangle-based clustering},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An entropy model of decision uncertainty. <em>JOMP</em>, <em>125</em>, 102919. (<a href='https://doi.org/10.1016/j.jmp.2025.102919'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studying metacognition, the introspection of one's own decisions, can provide insights into the mechanisms underlying the decisions. Here we show that observers’ uncertainty about their decisions incorporates both the entropy of the stimuli and the entropy of their response probabilities across the psychometric function. Describing uncertainty data with a functional form permits the measurement of internal parameters not measurable from the decision responses alone. To test and demonstrate the utility of this novel model, we measured uncertainty in 11 participants as they judged the relative contrast appearance of two stimuli in several experiments employing implicit bias or attentional cues. The entropy model enabled an otherwise intractable quantitative analysis of participants’ uncertainty, which in one case distinguished two comparative judgments that produced nearly identical psychometric functions. In contrast, comparative and equality judgments with different behavioral reports yielded uncertainty reports that were not significantly different. The entropy model was able to successfully account for uncertainty in these two different types of decisions that resulted in differently shaped psychometric functions, and the entropy contribution from the stimuli, which were identical across experiments, was consistent. An observer's uncertainty could therefore be measured as the total entropy of the inputs and outputs of the stimulus-response system, i.e. the entropy of the stimuli plus the entropy of the observer's responses.},
  archive      = {J_JOMP},
  author       = {Keith A. Schneider},
  doi          = {10.1016/j.jmp.2025.102919},
  journal      = {Journal of Mathematical Psychology},
  month        = {5},
  pages        = {102919},
  shortjournal = {J. Math. Psychol.},
  title        = {An entropy model of decision uncertainty},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A boolean generalization of the information-gain model can eliminate specific reasoning errors. <em>JOMP</em>, <em>125</em>, 102918. (<a href='https://doi.org/10.1016/j.jmp.2025.102918'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Wason selection task, subjects show a tendency towards counter-logical behaviour. Evidence gained from this experiment raises questions about the role that deductive logic plays in human reasoning. A prominent explanation of the effect uses an information-gain model. Rather than reasoning deductively, it is argued that subjects seek to reduce uncertainty. The bias that is observed is seen to stem from maximizing information gain in this adaptively rational way. This theoretical article shows that a Boolean generalization of the information-gain model is potentially considered the normative foundation of reasoning, in which case several inferences traditionally considered errors are found to be valid. The article examines how this affects inferences involving both over-extension of logical implication and overestimation of conjunctive probability.},
  archive      = {J_JOMP},
  author       = {Chris Thornton},
  doi          = {10.1016/j.jmp.2025.102918},
  journal      = {Journal of Mathematical Psychology},
  month        = {5},
  pages        = {102918},
  shortjournal = {J. Math. Psychol.},
  title        = {A boolean generalization of the information-gain model can eliminate specific reasoning errors},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cognitive models of decision-making with identifiable parameters: Diffusion decision models with within-trial noise. <em>JOMP</em>, <em>125</em>, 102917. (<a href='https://doi.org/10.1016/j.jmp.2025.102917'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion Decision Models (DDMs) are a widely used class of models that assume an accumulation of evidence during a quick decision. These models are often used as measurement models to assess individual differences in cognitive processes such as evidence accumulation rate and response caution. An underlying assumption of these models is that there is internal noise in the evidence accumulation process. We argue that this internal noise is a relevant psychological construct that is likely to vary over participants and explain differences in cognitive ability. In some cases a change in noise is a more parsimonious explanation of joint changes in speed-accuracy tradeoffs and ability. However, fitting traditional DDMs to behavioral data cannot yield estimates of an individual’s evidence accumulation rate, caution, and internal noise at the same time. This is due to an intrinsic unidentifiability of these parameters in DDMs. We explored the practical consequences of this unidentifiability by estimating the Bayesian joint posterior distributions of parameters (and thus joint uncertainty) for simulated data. We also introduce methods of estimating these parameters. Fundamentally, these parameters can be identified in two ways: (1) We can assume that one of the three parameters is fixed to a constant. We show that fixing one parameter, as is typical in fitting DDMs, results in parameter estimates that are ratios of true cognitive parameters including the parameter that is fixed. By fixing another parameter instead of noise, different ratios are estimated, which may be useful for measuring individual differences. (2) Alternatively, we could use additional observed variables that we can reasonably assume to be related to model parameters. Electroencephalographic (EEG) data or single-unit activity from animals can yield candidate measures. We show parameter recovery for models with true (simulated) connections to such additional covariates, as well as some recovery in misspecified models. We evaluate this approach with both single-trial and participant-level additional observed variables. Our findings reveal that with the integration of additional data, it becomes possible to discern individual differences across all parameters, enhancing the utility of DDMs without relying on strong assumptions. However, there are some important caveats with these new modeling approaches, and we provide recommendations for their use. This research paves the way to use the deeper theoretical understanding of sequential sampling models and the new modeling methods to measure individual differences in internal noise during decision-making.},
  archive      = {J_JOMP},
  author       = {Michael D. Nunez and Anna-Lena Schubert and Gidon T. Frischkorn and Klaus Oberauer},
  doi          = {10.1016/j.jmp.2025.102917},
  journal      = {Journal of Mathematical Psychology},
  month        = {5},
  pages        = {102917},
  shortjournal = {J. Math. Psychol.},
  title        = {Cognitive models of decision-making with identifiable parameters: Diffusion decision models with within-trial noise},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The assessment of global optimization skills in procedural knowledge space theory. <em>JOMP</em>, <em>125</em>, 102907. (<a href='https://doi.org/10.1016/j.jmp.2025.102907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Procedural knowledge space theory aims to evaluate problem-solving skills using a formal representation of a problem space. Stefanutti et al. (2021) introduced the concept of the “shortest path space” to characterize optimal problem spaces when a task requires reaching a solution in the minimum number of moves. This paper takes that idea further. It expands the shortest-path space concept to include a wider range of optimization problems, where each move can be weighted by a real number representing its “value”. Depending on the application, the “value” could be a cost, waiting time, route length, etc. This new model, named the optimizing path space, comprises all the globally best solutions. Additionally, it sets the stage for evaluating human problem-solving skills in various areas, like cognitive and neuropsychological tests, experimental studies, and puzzles, where globally optimal solutions are required.},
  archive      = {J_JOMP},
  author       = {Luca Stefanutti and Andrea Brancaccio},
  doi          = {10.1016/j.jmp.2025.102907},
  journal      = {Journal of Mathematical Psychology},
  month        = {5},
  pages        = {102907},
  shortjournal = {J. Math. Psychol.},
  title        = {The assessment of global optimization skills in procedural knowledge space theory},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Models of human probability judgment errors. <em>JOMP</em>, <em>125</em>, 102906. (<a href='https://doi.org/10.1016/j.jmp.2025.102906'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of cognitive science’s core challenges is reconciling the success of probabilistic models in explaining human cognition with the observed fallacies in human probability judgments. This tutorial delves into models that address this discrepancy, shedding light on probabilistic fallacies. It encompasses earlier accounts like heuristics and averaging models, as well as contemporary, comprehensive models like quantum probability, the Probability Plus Noise model, and the Bayesian Sampler. The tutorial concludes by introducing the most recent accounts that integrate probability judgments with choice and response time, and highlighting ongoing challenges in the field.},
  archive      = {J_JOMP},
  author       = {Jiaqi Huang and Jerome Busemeyer},
  doi          = {10.1016/j.jmp.2025.102906},
  journal      = {Journal of Mathematical Psychology},
  month        = {5},
  pages        = {102906},
  shortjournal = {J. Math. Psychol.},
  title        = {Models of human probability judgment errors},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two formal notions of higher-order invariance detection in humans (A proof of the invariance equivalence principle in generalized invariance structure theory and ramifications for related computations). <em>JOMP</em>, <em>125</em>, 102905. (<a href='https://doi.org/10.1016/j.jmp.2025.102905'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Invariance and symmetry principles have played a fundamental if not essential role in the theoretical development of the physical and mathematical sciences. More recently, Generalized Invariance Structure Theory (GIST; Vigo, 2013, 2015; Vigo et al., 2022) has extended this methodological trajectory with respect to the study and formal modeling of human cognition. Indeed, GIST is the first systematic and extensively tested mathematical and computational theory of concept learning and categorization behavior (i.e., human generalization) based on such principles. The theory introduces an original mathematical and computational framework, with novel, more appropriate, and more natural characterizations, constructs, and measures of invariance and symmetry with respect to cognition than existing ones in the mathematical sciences and physics. These have proven effective in predicting and explaining empirically tested behavior in the domains of perception, concept learning, categorization, similarity assessment, aesthetic judgments, and decision making, among others. GIST has its roots in a precursor theory known as Categorical Invariance Theory (CIT; Vigo, 2009). This paper gives a basic introduction to two different notions of human invariance detection proposed by GIST and its precursor CIT: namely, a notion based on a cognitive mechanism of dimensional suppression, rapid attention shifting, and partial similarity assessment referred to as binding ( s -invariance) and a perturbation notion based on perturbations of the values of the dimensions on which categories of object stimuli are defined ( p -invariance). This is followed by the first simple formal proof of the invariance equivalence principle from GIST which asserts that the two notions are equivalent under a set of strict conditions on categories. The paper ends with a brief discussion of how GIST, unlike CIT, may be used to model probabilistic process accounts of categorization, and how it naturally and directly applies to the learning of sequential categories and to multiset-based concept learning.},
  archive      = {J_JOMP},
  author       = {Ronaldo Vigo},
  doi          = {10.1016/j.jmp.2025.102905},
  journal      = {Journal of Mathematical Psychology},
  month        = {5},
  pages        = {102905},
  shortjournal = {J. Math. Psychol.},
  title        = {Two formal notions of higher-order invariance detection in humans (A proof of the invariance equivalence principle in generalized invariance structure theory and ramifications for related computations)},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conjugate bayesian analysis of the wald model: On an exact drift-rate posterior. <em>JOMP</em>, <em>124</em>, 102904. (<a href='https://doi.org/10.1016/j.jmp.2025.102904'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cognitive psychology, simple response times are often modeled as the time required by a one-dimensional Wiener process with drift to first reach a given threshold. This stochastic process’s first-passage time follows a Wald distribution, which is a specific parameterization of the inverse-Gaussian distribution. It can be shown that the Gaussian-Gamma distribution is a conjugate prior with respect to an inverse-Gaussian likelihood, albeit under a parameterization different from that of the Wald distribution. This leads to a posterior distribution that does not directly correspond to the core parameters of the Wiener process; that is, the drift-rate and the threshold parameter. While the marginal threshold posterior under a Gaussian-Gamma prior is relatively easy to derive and turns out to be a known distribution, this is not the case for the marginal drift-rate posterior. The present work addresses this issue by providing the exact marginal posterior distributions of the drift-rate parameter under a Gaussian-Gamma prior—something that has not yet been done in the literature. Unfortunately, the probability density function of this distribution cannot be expressed in terms of elementary functions. Thus, different methods of approximation are discussed as an expedient for time-critical applications.},
  archive      = {J_JOMP},
  author       = {Constantin G. Meyer-Grant},
  doi          = {10.1016/j.jmp.2025.102904},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102904},
  shortjournal = {J. Math. Psychol.},
  title        = {Conjugate bayesian analysis of the wald model: On an exact drift-rate posterior},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic models of delay discounting: “Fixed-endpoint” psychometric curves improve plausibility and performance. <em>JOMP</em>, <em>124</em>, 102902. (<a href='https://doi.org/10.1016/j.jmp.2025.102902'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic models of delay discounting allow the estimation of discount functions without prescribing unrealistically sharp boundaries in decision making. However, existing probabilistic models have two implausible implications: first, that no reward is sometimes preferred over some reward (e.g., $0 now over $100 in 1 year), and second, that the same reward is sometimes preferred later rather than sooner (e.g., $100 in a year over $100 now). We introduce a class of “fixed-endpoint” models that assign these edge cases a probability of 0. We find that these outperform conventional models across a range of discount functions using nonlinear regression. We also introduce a series of generalized linear models that implicitly parameterize various discount functions, and demonstrate the same result for these.},
  archive      = {J_JOMP},
  author       = {Isaac Kinley and Joseph Oluwasola and Suzanna Becker},
  doi          = {10.1016/j.jmp.2025.102902},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102902},
  shortjournal = {J. Math. Psychol.},
  title        = {Probabilistic models of delay discounting: “Fixed-endpoint” psychometric curves improve plausibility and performance},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Choosing is losing: How opportunity cost influences valuations and choice. <em>JOMP</em>, <em>124</em>, 102901. (<a href='https://doi.org/10.1016/j.jmp.2025.102901'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a model of choice that accounts for opportunity costs actually suffered, as a result of renouncing the alternative not chosen. The valuation of each option is relative: The decision maker subtracts from the standard utility of any given option the psychological cost of giving up the alternative. In the presence of a default option, the final inclination of a person is the net effect of a ‘conservative’ disposition to keep the default and an ‘adventurous’ disposition toward choosing an alternative. This trait-like inclination is captured by the difference in sensitivity to giving up the default option or its alternative(s). When the options have elements in common, the conservative and adventurous dispositions operate only on their distinguishing elements. Unlike previous conceptualizations of anticipated regret, our decision maker suffers most when the foregone option is of comparable value to the chosen one. Our model can explain the empirical regularity that faced with the same choice, some people tend to favor the default option (a form of endowment effect), while others tend to favor its alternative (a form of fear of missing out). In the presence of several alternatives, the decision maker compares the default option with the best option among the alternatives.},
  archive      = {J_JOMP},
  author       = {Tomás Lejarraga and József Sákovics},
  doi          = {10.1016/j.jmp.2025.102901},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102901},
  shortjournal = {J. Math. Psychol.},
  title        = {Choosing is losing: How opportunity cost influences valuations and choice},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A class of random utility models yielding the exploded logit. <em>JOMP</em>, <em>124</em>, 102900. (<a href='https://doi.org/10.1016/j.jmp.2025.102900'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We reexamine a family of distributions introduced within the framework of random utility models by David Strauss. This family generates ranking probabilities of the exploded logit model and, de facto, the choice probabilities of the multinomial logit model. We explore the necessary and sufficient conditions for its validity within the copula theory. By specifying the minimal assumptions required for the support of the marginal utility distributions, we clarify and reinforce the fundamental structure of the model, proving that it relies on strict archimedean copulas. Additionally, we provide a new mathematical proof by induction on the number of alternatives confirming that these utility distributions indeed generate the exploded logit model.},
  archive      = {J_JOMP},
  author       = {Karim Kilani},
  doi          = {10.1016/j.jmp.2025.102900},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102900},
  shortjournal = {J. Math. Psychol.},
  title        = {A class of random utility models yielding the exploded logit},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysing the bias introduced by adaptive designs to estimates of psychometric functions. <em>JOMP</em>, <em>124</em>, 102899. (<a href='https://doi.org/10.1016/j.jmp.2025.102899'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An adaptive design adjusts dynamically as information is accrued. In psychometrics and psychophysics, a class of studies investigates a subject’s ability to perform tasks as a function of the stimulus intensity, ie the amount or clarity of information supplied for the task. The relationship between performance and intensity is represented by a psychometric function. Such experiments routinely apply adaptive designs using both previous intensities and performance to assign stimulus intensities, the strategy being to sample intensities where information about the psychometric function is maximised. We investigate the influence of adaptation on statistical inference about the psychometric function focusing on estimation, considering parametric and non-parametric estimation under both fixed and adaptive designs and under within-subject independence as well as dependence. We study the scenarios analytically and numerically through a simulation study. We show that while asymptotic properties of estimators are preserved under adaptation, the adaptive nature of the design introduces small-sample bias, in particular in the slope parameter of the psychometric function. We supply an explanation of this phenomenon that formalises and supplements the one found in the literature. We argue that this poses a dilemma for studies applying an adaptive design in the form of a trade-off between more efficient sampling and the need to increase the number of samples to ameliorate small-sample bias.},
  archive      = {J_JOMP},
  author       = {Simon Bang Kristensen and Katrine Bødkergaard and Bo Martin Bibby},
  doi          = {10.1016/j.jmp.2025.102899},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102899},
  shortjournal = {J. Math. Psychol.},
  title        = {Analysing the bias introduced by adaptive designs to estimates of psychometric functions},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dimensions of knowledge structures. <em>JOMP</em>, <em>124</em>, 102898. (<a href='https://doi.org/10.1016/j.jmp.2024.102898'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A knowledge structure is inherently one-dimensional when its collection of states forms a chain. But how to define the dimension of a knowledge structure in general? We investigate four options: (i) the ordinal dimension , which is the dimension of the poset consisting of all states ordered by inclusion; (ii) for a knowledge space, the spatial dimension which is the least number of one-dimensional knowledge spaces which generate the space (a notion extending from learning spaces to knowledge spaces the dual of the convex dimension of an antimatroid); (iii) the bidimension , which is the bidimension of the membership relation from items to states, in either the intersection or the union version of the bidimension. Our results establish or disprove inequalities among the four dimension parameters for knowledge structures, for knowledge spaces, for terse knowledge structures, for terse knowledge spaces, and finally for learning spaces. We finally list some problems for future research.},
  archive      = {J_JOMP},
  author       = {Jean-Paul Doignon and Luca Stefanutti},
  doi          = {10.1016/j.jmp.2024.102898},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102898},
  shortjournal = {J. Math. Psychol.},
  title        = {Dimensions of knowledge structures},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterizing master fringes in competence-based knowledge space theory for personalized learning applications. <em>JOMP</em>, <em>124</em>, 102897. (<a href='https://doi.org/10.1016/j.jmp.2024.102897'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a general method to directly compute the outer (inner) master fringe of the knowledge state based on the top or bottom of the equivalence class of competence state, and a general method for personalized learning guidance (reinforcement learning recommendation) based on competences and the master fringe. Two characterization theorems are mainly given: one characterizes the top (bottom) of competence states using skill functions; the other characterizes the outer (inner) master fringe of knowledge states using problem functions. As applications of two characterization theorems, the first is to provide a new method to directly obtain the corresponding competence state’s top or bottom from the knowledge state. The second application is to integrate skills into the competence-based master fringe, which takes into account the influence of students’ latent competences, resulting in more precise values.},
  archive      = {J_JOMP},
  author       = {Gongxun Wang and Jinjin Li and Bo Wang and Chenyi Tao},
  doi          = {10.1016/j.jmp.2024.102897},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102897},
  shortjournal = {J. Math. Psychol.},
  title        = {Characterizing master fringes in competence-based knowledge space theory for personalized learning applications},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
