<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ISCI</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="isci">ISCI - 122</h2>
<ul>
<li><details>
<summary>
(2026). CCBIR: A concept-based system for geospatial image retrieval. <em>ISCI</em>, <em>728</em>, 122814. (<a href='https://doi.org/10.1016/j.ins.2025.122814'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content Based Image Retrieval (CBIR) systems play a crucial role in efficiently organizing large image datasets for effective image retrieval based on visual content. In this work, we focus on Natural Disaster Management (NDM) scenarios, where rapid and accurate image retrieval can assist in monitoring disaster events and supporting effective emergency response. We present a novel Concept-Based CBIR (CCBIR) pipeline designed to enhance the CBIR process by integrating semantic image concepts derived from image features. The pipeline extracts features using a task-specific DNN backbone and applies Non-Negative Matrix Factorization (NMF) to derive semantic image concepts. For efficient image retrieval based on concept based image similarity, the FAISS library is leveraged, which enables fast approximate nearest neighbor search in high-dimensional spaces. By transforming complex, high-dimensional features into a structured and interpretable concept space, the proposed CCBIR approach facilitates a more precise alignment between computational image representations and human semantic understanding. The pipeline has been evaluated on three datasets featuring different CBIR problems in natural disaster scenarios such as forest fires and floods, comparing favorably against state-of-the-art CBIR methods. This kind of performance showcases the effectiveness and adaptability of the CCBIR system, highlighting its potential to improve disaster response and recovery operations.},
  archive      = {J_ISCI},
  author       = {Evgenios Vlachos and Ioannis Pitas},
  doi          = {10.1016/j.ins.2025.122814},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122814},
  shortjournal = {Inf. Sci.},
  title        = {CCBIR: A concept-based system for geospatial image retrieval},
  volume       = {728},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Evidential association rule learning for semi-supervised activity recognition with soft label derivation. <em>ISCI</em>, <em>728</em>, 122811. (<a href='https://doi.org/10.1016/j.ins.2025.122811'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid improvement of sensing technology and wearable devices is continuously pushing the research on wearable human activity recognition (HAR) with the advantage of privacy protection for users. Most existing work focuses on the construction of HAR systems with the assumption that all activity labels are both completely and precisely annotated in advance. However, ground truth annotations are usually both costly and error-prone for long-term activity recognition scenarios, thus greatly promoting the rise of semi-supervised HAR systems that enable dealing with unlabeled samples. In this paper, an evidential association rule learning framework is proposed for accurate and interpretable recognition under the semi-supervised conditions, in which the uncertainty inherent in unlabeled samples is quantified with soft class labels. First, procedures of associative discovery and hierarchical clustering are successively implemented for mining belief relations between sample features and classes, on which basis each unlabeled sample is assigned a related soft label with belief distribution form. To complement accuracy loss caused by missing, the derived soft-hard class information is exploited for generating effective evidential association rules in recognition. Experiments on self-collected and real-world activity datasets demonstrate the superiority of the proposal in terms of accuracy and interpretability under semi-supervised conditions.},
  archive      = {J_ISCI},
  author       = {Xiaojiao Geng and Jiangdong Zhang and Zheng Yang and Zhi-Jie Zhou and Zongfang Ma},
  doi          = {10.1016/j.ins.2025.122811},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122811},
  shortjournal = {Inf. Sci.},
  title        = {Evidential association rule learning for semi-supervised activity recognition with soft label derivation},
  volume       = {728},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sampled-data stabilization via novel looped-functional for fuzzy singular markov jump system and its applications. <em>ISCI</em>, <em>728</em>, 122810. (<a href='https://doi.org/10.1016/j.ins.2025.122810'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper researches sampled-data stabilization issue of fuzzy singular Markov jump system (FSMJS) using a novel looped-functional method. To overcome the challenges of limited continuous measurement and control in practical applications, a mode-dependent aperiodic sampled-data control approach is put forward. The key contributions of this paper are threefold. First, the FSMJS is decomposed into differential and algebraic equations via state decomposition method, reducing computational complexity compared to full-state vector approaches. Second, two novel Lyapunov-Krasovskii functionals (LKF) incorporating looped-functionals are developed. These LKF explicitly utilize both system state and fuzzy membership function information while relaxing the positivity constraint to sampling instants, thereby yielding less conservative stability conditions. Third, a design scheme for the mode-dependent sampled-data controller, utilizing state decomposition vectors, is proposed, thus establishing stability criteria with fewer decision variables. To verify the efficacy of this approach, two simulation examples are provided, namely a single-link robotic arm and a truck-trailer system. These results demonstrate that the derived maximum allowable sampling intervals are significantly larger than those from existing methods, confirming the reduced conservatism and superior performance of our approach.},
  archive      = {J_ISCI},
  author       = {Xingyue Liang and Jianwei Xia and Hao Shen},
  doi          = {10.1016/j.ins.2025.122810},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122810},
  shortjournal = {Inf. Sci.},
  title        = {Sampled-data stabilization via novel looped-functional for fuzzy singular markov jump system and its applications},
  volume       = {728},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adversarial text detection in short sentences using contextual extraction and semantic separation. <em>ISCI</em>, <em>728</em>, 122809. (<a href='https://doi.org/10.1016/j.ins.2025.122809'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid deployment of large language models (LLMs) across diverse applications has heightened concerns about their susceptibility to adversarial attacks, particularly in short-text scenarios. Short adversarial inputs are especially challenging, as their close semantic resemblance to benign texts enables them to bypass conventional defence mechanisms. To address this issue, a robust adversarial detection method is proposed, integrating a context-aware short-text extraction module with a composite loss training strategy. The extraction module identifies semantically important sentences through confidence-based ranking, thereby enhancing the reliability of downstream detection. The training process leverages a composite loss function combining binary cross-entropy for standard supervision, positive-unlabeled (PU) loss to handle ambiguous adversarial instances, and semantic loss to enforce latent space divergence between clean and adversarial samples. The proposed method is evaluated with BERT and RoBERTa across four benchmark datasets: IMDB, HC3, COCO, and YELP, under attack settings: TextFooler and a mutation-based method. Results consistently outperform state-of-the-art baselines, with BERT achieving 96.40 % accuracy and 96.33 % F1 on IMDB under TextFooler, and RoBERTa attaining 99.31 % accuracy on COCO and 95.32 % accuracy on HC3. These findings highlight the effectiveness of combining context-aware extraction with composite-loss training, providing a scalable and practical defence for enhancing LLM robustness against adversarial manipulations.},
  archive      = {J_ISCI},
  author       = {Ajay Kumar Banodhiya and Avinash Chandra Pandey},
  doi          = {10.1016/j.ins.2025.122809},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122809},
  shortjournal = {Inf. Sci.},
  title        = {Adversarial text detection in short sentences using contextual extraction and semantic separation},
  volume       = {728},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LeadGenius: Mastering opening leads in the game of bridge. <em>ISCI</em>, <em>728</em>, 122794. (<a href='https://doi.org/10.1016/j.ins.2025.122794'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bridge is an imperfect-information card game where the opening lead plays a crucial role in determining the game’s outcome. Existing algorithms for Bridge opening leads often rely on Monte Carlo search with random sampling, which do not fully utilize information from the bidding phase and thus might result in unsatisfied opening-lead decisions. This paper introduces a novel Bridge opening-lead algorithm called LeadGenius, which leverages information from the bidding phase to guide sampling strategies, thereby enhancing decision-making ability in the opening lead. Specifically, LeadGenius first generates hand probability distributions through neural networks with supervised learning. In the meantime, critical hand constraints of players are identified by analyzing bidding sequences. Then, based on derived hand probability distributions and hand constraints, an algorithm of priority-based sampling with filtering is developed for hand sampling. Finally, an opening lead is made based on sampled hands via a search algorithm named Perfect Information Monte Carlo. Experiments demonstrate that LeadGenius outperforms championship-winning Bridge software Wbridge5 and tournament-level experts.},
  archive      = {J_ISCI},
  author       = {Zhanhang Zhang and Dan You and Siya Yao and Shouguang Wang and Mengchu Zhou},
  doi          = {10.1016/j.ins.2025.122794},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122794},
  shortjournal = {Inf. Sci.},
  title        = {LeadGenius: Mastering opening leads in the game of bridge},
  volume       = {728},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GDCMAD: Graph-based dual-contrastive representation learning for multivariate time series anomaly detection. <em>ISCI</em>, <em>728</em>, 122790. (<a href='https://doi.org/10.1016/j.ins.2025.122790'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing amount of multivariate time series (MTS), coupled with scarce labeled samples, has driven the development of unsupervised anomaly detection. While contrastive learning has shown promise in learning discriminative representations, existing contrastive learning-based MTS anomaly detection methods still suffer from limited representation power and inadequate discrimination ability. In this paper, we propose a novel model, graph-based dual-contrastive representation learning for detecting anomalies in multivariate time series, called GDCMAD. GDCMAD first constructs two relational graphs for capturing inter-variable and temporal dependencies then integrates an improved Kolmogorov–Arnold network (KAN)-based attention mechanism into a reconstruction framework. Additionally, it incorporates an LSTM-based external contrastive learning module to further enhance the separation between normal and abnormal patterns. Experiments on six public datasets show that GDCMAD achieves better performance than nine state-of-the-art methods in detecting anomalies, confirming its effectiveness for MTS data. To access the source code of GDCMAD, please visit the repository located at https://github.com/Du-Team/GDCMAD .},
  archive      = {J_ISCI},
  author       = {Sheng He and Wenxuan He and Mingjing Du and Xiang Jiang and Yongquan Dong},
  doi          = {10.1016/j.ins.2025.122790},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122790},
  shortjournal = {Inf. Sci.},
  title        = {GDCMAD: Graph-based dual-contrastive representation learning for multivariate time series anomaly detection},
  volume       = {728},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficient order-based algorithms for core maintenance in weighted graph. <em>ISCI</em>, <em>728</em>, 122775. (<a href='https://doi.org/10.1016/j.ins.2025.122775'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are widely used to model a wide range of real-world applications. The k -core structure plays a key role in analysis and research of graphs. For dynamic graphs, k -core maintenance has been investigated to accelerate core decomposition—a problem that has been extensively studied in the context of unweighted graphs. Edge weights are of great significance in reality. In this paper, we address the core maintenance problem in edge-weighted graphs. Building upon an advanced order-based core maintenance algorithm, we propose efficient algorithms for edge-weighted graphs and extend single-edge maintenance to update for multiple edges. For single-edge insertion, we incorporate a priority queue within each segment to minimize unnecessary vertex traversals. For single-edge deletion, we propose the ECS (Edge Classification Structure) to classify neighbors and shrink the search space. For maintenance of multiple edges, we adopt a centralized processing strategy to handle multiple updates simultaneously, together with a dynamic segment expansion mechanism that gradually enlarges the segment range until the end. Extensive experiments are performed on real-world networks to evaluate the effectiveness and scalability of the proposed algorithms. Experimental results show that our new single-edge insertion algorithm significantly outperforms the traversal-based incremental method by up to three orders of magnitude on 12 real-world graphs.},
  archive      = {J_ISCI},
  author       = {Rongjin Yang and Zijun Chen and Wenyuan Liu},
  doi          = {10.1016/j.ins.2025.122775},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122775},
  shortjournal = {Inf. Sci.},
  title        = {Efficient order-based algorithms for core maintenance in weighted graph},
  volume       = {728},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hesitant fuzzy linguistic term set based preference representation for composite decision makers in the graph model for conflict resolution. <em>ISCI</em>, <em>728</em>, 122763. (<a href='https://doi.org/10.1016/j.ins.2025.122763'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In strategic conflicts, cautious decision-making of a stakeholder is usually collectively decided by a group of individuals, who may have complex cognitive preferences. The hesitant fuzzy linguistic term set (HFLTS) is formally for the first time incorporated into the graph model for conflict resolution (GMCR) to model and analyze the strategic conflicts involving composite decision makers (CDMs). A new preference representation based on HFLTS is first proposed, which allows each individual to present its preference in simple or complex linguistic terms. Second, a linguistic scale function is introduced to enable the transformation of uniformly or non-uniformly distributed linguistic term sets into their personalized semantics based on the psychology of individuals. Then, three behavioral characteristics of CDMs are established as conservative, aggressive, and collective. Moreover, a preference elicitation method for the collective preferences of collective CDMs is developed, which aggregates all individual preferences by objective weighting. After that, three extensions of hesitant fuzzy stability definitions are redefined. Finally, an illustrative example of 2020 Nagorno-Karabakh conflict is utilized to demonstrate the applicability of the proposed approach, and the results and comparative analysis show the proposed approach can effectively handle strategic conflicts involving CDMs under hesitant fuzzy linguistic environment.},
  archive      = {J_ISCI},
  author       = {Yuming Huang and Bingfeng Ge and Keith W. Hipel and Jichao Li and Jiang Jiang and Kewei Yang},
  doi          = {10.1016/j.ins.2025.122763},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122763},
  shortjournal = {Inf. Sci.},
  title        = {Hesitant fuzzy linguistic term set based preference representation for composite decision makers in the graph model for conflict resolution},
  volume       = {728},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ERMNF: A novel multiplex network fusion method based on edge relevance. <em>ISCI</em>, <em>728</em>, 122757. (<a href='https://doi.org/10.1016/j.ins.2025.122757'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, multiplex networks have been widely used to represent real-world complex systems. While they offer valuable insights into complex systems, their multi-layer structure poses significant challenges for network analysis tasks. Network fusion process has emerged as a powerful tool for addressing this issue; however, most existing methods are inappropriate for large-scale multiplex networks and ignore the inter-layer structure. To address this problem, we propose an edge relevance-based multiplex network fusion ( ERMNF ) model, which transforms the multiplex network into a monoplex network while preserving its essential structural properties. ERMNF operates in three main phases. First, it collects the links from all layers into a single-layer network. Next, ERMNF determines the relevance of each link in the binary aggregated network using two different edge relevance models based on the concept of shortest paths. Finally, it removes irrelevant links using an edge reduction (ER) model, while maintaining the set of nodes. We evaluated ERMNF on eight real-world multiplex networks, comparing it with five well-known fusion methods. Our experiments were two-fold. First, we assessed the fused network’s ability to preserve the original network’s topological properties. Second, we evaluated its performance on various network analysis tasks, including influence maximization, link prediction, and community detection.},
  archive      = {J_ISCI},
  author       = {Oumaima Achour and Lotfi Ben Romdhane and Giancarlo Sperlí},
  doi          = {10.1016/j.ins.2025.122757},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122757},
  shortjournal = {Inf. Sci.},
  title        = {ERMNF: A novel multiplex network fusion method based on edge relevance},
  volume       = {728},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-threshold image segmentation method for mechanical parts based on strategy-improved optimization. <em>ISCI</em>, <em>727</em>, 122807. (<a href='https://doi.org/10.1016/j.ins.2025.122807'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation is a key technology for mechanical parts defect diagnosis. As the complexity of images increases, traditional methods are difficult to achieve the expected results. Metaheuristic algorithms have the characteristics of global data optimization and can solve the problem of insufficient image segmentation accuracy. For improve the accuracy of image segmentation, this paper introduces three improvement strategies based on Eel Grouper Optimization Algorithm (EGO) and proposes an improved algorithm (MSEGO) suitable for mechanical parts image segmentation. A performance evaluation experiment was conducted on MSEGO and 9 other algorithms including the newly proposed Catch Fish Optimization Algorithm. MSEGO ranked first among the 10 algorithms, with an improvement of 24.16% compared to EGO. In addition, through comparative experiments on public image and mechanical parts image datasets, and evaluation of the experimental results, it is concluded that MSEGO has better segmentation effect than the other 9 comparative algorithms. In the above two datasets, the segmentation effect of MSEGO is improved by 55.89% and 38.59% respectively compared with EGO. The results show that MSEGO has excellent segmentation accuracy and adaptability in mechanical parts image segmentation.},
  archive      = {J_ISCI},
  author       = {Xiaoyang Yuan and Liguo Yao and Taihua Zhang and Guanghui Li and Qipeng Chen},
  doi          = {10.1016/j.ins.2025.122807},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122807},
  shortjournal = {Inf. Sci.},
  title        = {A multi-threshold image segmentation method for mechanical parts based on strategy-improved optimization},
  volume       = {727},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fuzzy community detection based on membership smoothing and enhancement. <em>ISCI</em>, <em>727</em>, 122806. (<a href='https://doi.org/10.1016/j.ins.2025.122806'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, fuzzy community detection (FCD) has garnered growing attention, and researchers have proposed various methods to determine the membership between the nodes and communities. However, in most of the existing algorithms, the node membership obtained is either too dispersed (which weakens the differences between communities for each node), or too concentrated (which causes loss of fuzzy information). To this end, a membership smoothing and enhancement alternating mechanism for fuzzy community detection is proposed to obtain membership with a reasonable distribution. Specifically, the membership smoothing strategy expands the distribution of node memberships to retain more fuzzy information. In contrast, the membership enhancement strategy narrows the distribution to strengthen the relative affiliations between nodes and communities. Based on the proposed alternating mechanism, a membership smoothing and enhancement-based fuzzy community detection algorithm (MSEFCD) is proposed. In MSEFCD, an interval reduction based membership matrix initialization strategy is designed, which enables automatic determination of the number of communities. Experiments on 17 experimental networks, compared with five state-of-the-art baselines, verified that MSEFCD achieves a superior balance with respect to community detection effectiveness and computational efficiency.},
  archive      = {J_ISCI},
  author       = {Haipeng Yang and Zishan Xiong and Yuxian Cui and Zhanpeng Wang and Lei Zhang},
  doi          = {10.1016/j.ins.2025.122806},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122806},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy community detection based on membership smoothing and enhancement},
  volume       = {727},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Federated domain generalization with source knowledge preservation via discriminative ensembles. <em>ISCI</em>, <em>727</em>, 122804. (<a href='https://doi.org/10.1016/j.ins.2025.122804'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many federated learning approaches assume that all clients have datasets within the same domain. However, in real-world scenarios, this assumption rarely holds, because clients collect data from distinct environments. Federated domain generalization attempts to address this challenge by improving model generalization to unseen domains. However, existing approaches suffer from a trade-off: they enhance performance in the unseen domains at the cost of degrading performance in the source domains due to the suppression of domain-specific features. To overcome this limitation, we propose Federated Discriminative Ensemble (FedDE) to improve generalization on both unseen and source domains by maximizing domain-invariant feature learning while minimizing domain-specific information loss. FedDE introduces two components: a common model that captures domain-invariant features and a localizer that preserves domain-specific features ignored by the common model. To ensure feature separation, we apply L2-norm regularization and adversarial training to encourage each component to learn distinct types of information. During inference, FedDE employs a client model ensemble strategy, leveraging both domain-invariant and domain-specific knowledge to enhance performance across all domains. This ensemble approach mitigates information loss and significantly boosts accuracy on both the seen and unseen domains. We conducted extensive experiments on multiple benchmark datasets and demonstrated that FedDE outperformed existing methods by achieving superior performance across both the source and unseen domains.},
  archive      = {J_ISCI},
  author       = {YongHoon Kang and Jee-Hyong Lee},
  doi          = {10.1016/j.ins.2025.122804},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122804},
  shortjournal = {Inf. Sci.},
  title        = {Federated domain generalization with source knowledge preservation via discriminative ensembles},
  volume       = {727},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A manifold embedding-based evolutionary algorithm for many-objective optimization with irregular pareto front shapes. <em>ISCI</em>, <em>727</em>, 122793. (<a href='https://doi.org/10.1016/j.ins.2025.122793'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-objective evolutionary algorithms (MaOEAs) have shown great potential for many-objective optimization problems (MaOPs). However, most existing MaOEAs struggle with problems characterized by irregular Pareto fronts (PFs), primarily due to limitations in diversity preservation. To address this challenge, this paper proposes a manifold embedding-based evolutionary algorithm tailored for MaOPs with irregular PFs. The proposed algorithm introduces a customized environmental selection mechanism using an angle-based manifold embedding approach to enhance diversity maintenance. First, hierarchical clustering is applied in a lower-dimensional embedded space to support the environmental selection process, promoting better diversity preservation. Next, a diversity quality indicator, defined in the latent manifold space, is developed to more accurately capture distances between solutions based on the intrinsic structure of the PF. Furthermore, a parameter-free comprehensive quality indicator, integrating both diversity and convergence, is introduced to guide selection within each cluster. To further improve performance, an external archive is employed to retain high-quality solutions throughout the evolutionary process. Comparative studies on 20 widely used test problems with complex and irregular PFs demonstrate that the proposed algorithm consistently outperforms state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Zhuanlian Ding and Jinyu Wang and Xihong Jiang and Xingyi Zhang and Dengdi Sun},
  doi          = {10.1016/j.ins.2025.122793},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122793},
  shortjournal = {Inf. Sci.},
  title        = {A manifold embedding-based evolutionary algorithm for many-objective optimization with irregular pareto front shapes},
  volume       = {727},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A heterogeneous data envelopment analysis for rescue route assessment incorporating best-worst method-based weight constraints. <em>ISCI</em>, <em>727</em>, 122792. (<a href='https://doi.org/10.1016/j.ins.2025.122792'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective evaluation of rescue routes is crucial for reducing casualties and property loss during emergencies. However, this task remains challenging due to vague disaster information and the need to incorporate a wide variety of diverse factors. A key gap in current approaches lies in the absence of a structured mechanism to prioritize the most vital expert-defined criteria within an assessment framework that simultaneously accommodates diverse data types. To bridge this gap, this paper introduces an innovative integrated framework named TrIF-BWMC-HDEA, which uniquely combines trapezoidal intuitionistic fuzzy (TrIF) best-worst method-based constraints (BWMCs) with heterogeneous data envelopment analysis (HDEA). Specifically, expert-judgment-based TrIF-BWMCs offer the flexibility to reflect the scenario-specific importance of different criteria in rescue operations. Meanwhile, HDEA supports the framework in assessing with various data types (i.e., TrIF numbers, crisp values, and intervals). The proposed framework makes three significant contributions. Firstly, it guarantees adequate consideration of expert-prioritized critical criteria by incorporating TrIF-BWMCs. Secondly, it greatly improves the usefulness of decision-making in complicated emergency situations. This is achieved by decreasing the number of pairwise comparisons and balancing flexibility with necessary restrictions, which prevents arbitrary weight assignments. Thirdly, it delivers a solid method for dealing with data that is not precise and comes in different forms. The framework’s effectiveness is validated through a case study, along with sensitivity and comparative analyses. These evaluations demonstrate the framework’s practical applicability, strengths, and advantages over existing methods. Consequently, TrIF-BWMC-HDEA exhibits significant potential for optimizing emergency response strategies and increasing the success rate of rescue missions.},
  archive      = {J_ISCI},
  author       = {Wen Luo and Ze-hui Chen and Deng-feng Wu and Xiao-yun Lu},
  doi          = {10.1016/j.ins.2025.122792},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122792},
  shortjournal = {Inf. Sci.},
  title        = {A heterogeneous data envelopment analysis for rescue route assessment incorporating best-worst method-based weight constraints},
  volume       = {727},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Sample-efficient multi-objective reinforcement learning for hybrid impulsive information consensus in multi-agent systems. <em>ISCI</em>, <em>727</em>, 122791. (<a href='https://doi.org/10.1016/j.ins.2025.122791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hybrid impulsive-control approach integrating multi-objective reinforcement learning is proposed in this work to tackle the information consensus regulation problem in multi-agent systems. The proposed method is developed under a hybrid impulsive control framework, which explicitly considers both time-varying communication delays and impulsive delays inherent in the system, and incorporates stabilizing impulses to mitigate instability caused by continuous dynamics. The impulsive-control sequence is dynamically adjusted by a multi-objective reinforcement learning (MORL) agent, thereby achieving balanced optimization among multiple objectives—including communication cost and state deviation. Sample efficiency is enhanced through a manually designed prior control policy, by which the agent is endowed with decision-making capabilities via early-stage imitation learning, while a dual experience-replay buffer is configured to ensure seamless transition from imitation-guided learning to autonomous exploration; these mechanisms constitute the Prior Knowledge-Guided Multi-Objective Reinforcement Learning (PKG-MORL) algorithm proposed herein. Experience utilization is improved through the Adaptive Informative Prioritized Experience Replay (AIPER) mechanism, where temporal-difference error, information gain, and sampling frequency are jointly incorporated to refine the sampling strategy, thereby accelerating policy convergence and enhancing training efficiency. Experimental evaluations verify that the proposed hybrid impulsive-control method effectively achieves information consensus control under various preference scenarios and yields higher-quality approximated Pareto fronts than prevailing MORL algorithms.},
  archive      = {J_ISCI},
  author       = {Yanlin Gu and Zhanlue Liang and Shicheng Wu and Yiwen Tao and Can Zhao and Renjie Xu},
  doi          = {10.1016/j.ins.2025.122791},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122791},
  shortjournal = {Inf. Sci.},
  title        = {Sample-efficient multi-objective reinforcement learning for hybrid impulsive information consensus in multi-agent systems},
  volume       = {727},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Explainable multivariate time series anomaly detection by feature graph structure learning. <em>ISCI</em>, <em>727</em>, 122789. (<a href='https://doi.org/10.1016/j.ins.2025.122789'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is a critical task in data mining and has received considerable attention in recent years. Traditional approaches often face challenges when dealing with multivariate time series data, while deep learning-based methods typically suffer from issues such as insufficient negative samples and limited interpretability. To address these limitations, this paper introduces a novel feature graph structure learning-based anomaly detection (FGEAD) model for multivariate time series anomaly detection. The proposed model leverages a self-attention mechanism to capture global dependencies among variables and construct informative feature graph structures, which are subsequently processed by graph attention networks for anomaly identification. Extensive experiments on six benchmark datasets—NSL_KDD, UNSW-NB15, SWaT, MSL, SMAP, and WADI—demonstrate that the self-attention-based graph learning significantly outperforms cosine similarity, yielding improvements of up to 6.29 % in F1-score and 5.19 % in AUC. Furthermore, to demonstrate practical applicability, we conducted a case study on a real industrial dataset collected from a tobacco flue-curing workshop. FGEAD achieves the highest accuracy (0.998) and F1-score (0.928) compared with several baseline methods. This case study confirms the effectiveness and robustness of FGEAD in real-world industrial scenarios.},
  archive      = {J_ISCI},
  author       = {Wei Xu and Hongbo Wang and Zhenping Xie},
  doi          = {10.1016/j.ins.2025.122789},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122789},
  shortjournal = {Inf. Sci.},
  title        = {Explainable multivariate time series anomaly detection by feature graph structure learning},
  volume       = {727},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MPathRP: A knowledge graph relationship prediction method based on cross-modal entity representation learning and path reasoning. <em>ISCI</em>, <em>727</em>, 122786. (<a href='https://doi.org/10.1016/j.ins.2025.122786'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph-based multi-hop path relationship prediction infers potential associations by analyzing multi-order relationship sequences between entities. Existing studies mainly rely on unimodal path embeddings for prediction, and the lack of explicit modeling of logical associations between path nodes in long path inference limits the prediction accuracy. To address the above shortcomings, this paper proposes a fine-grained tokenization-reconstruction entity representation and designs a higher-order path attention mechanism incorporating learnable diffusion coefficients to explicitly model long-range dependencies across hops. Specifically, the model first extracts visual and semantic feature vectors of entity nodes in multi-hop paths using a pre-trained visual modal tokenizer and a textual modal tokenizer, respectively. Subsequently, these bimodal features are deeply fused through a Transformer layer as an entity encoder to generate entity and relation representations with cross-modal correlations. Secondly, the designed higher-order path attention module models complex paths in two dimensions: within single-hop paths and across single-hop paths. Finally, the relationship prediction results are output by fusing the entity embedding and path embedding information. Experimental evaluations on three publicly available MMKG benchmark datasets demonstrate that the proposed approach enhances the MRR and Hits@10 metrics in the complex relationship prediction task by 2.1 % and 2.7 %, respectively.},
  archive      = {J_ISCI},
  author       = {Xiaofei Zhao and Qi Duan and Hongji Yang},
  doi          = {10.1016/j.ins.2025.122786},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122786},
  shortjournal = {Inf. Sci.},
  title        = {MPathRP: A knowledge graph relationship prediction method based on cross-modal entity representation learning and path reasoning},
  volume       = {727},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive sequential three-way decision-making model via dynamic fusion of incomplete mixed data considering misclassification penalty from holistic and incremental perspectives. <em>ISCI</em>, <em>727</em>, 122785. (<a href='https://doi.org/10.1016/j.ins.2025.122785'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the increasing complexity of modern data environments, the challenge of making accurate and efficient decisions in uncertain contexts has become a prominent research topic. Inspired by this, a sequential three-way decision model is proposed to dynamically fuse incomplete mixed data from both static and dynamic perspectives in this paper. Specifically, complete datasets are firstly utilized in the static perspective, employing an attention-based method to evaluate the importance of attributes, partition attribute sets, and systematically determine the order of attribute analysis. In the dynamic perspective, data processing in incremental environments is focused on, and adaptive threshold pairs are introduced. Subsequently, two distinct metrics, namely matching coefficients and Gaussian functions, are adopted to compute similarities for categorical and numerical data respectively. Moreover, four T-norm fusion methods are integrated, which are Minimum T-norm, Product T-norm, Lukasiewicz T-norm, and Cosine T-norm. In addition, a crucial cost function is constructed to incorporate hierarchical importance and misclassification penalties. Finally, comparative experiments are conducted on six datasets to evaluate our model against existing methods. Experimental results show that our method can effectively reduce decision-making costs while maintaining decision accuracy. In conclusion, this study provides effective solutions for dynamic data fusion and multi-stage decision-making in complex environments, offering significant theoretical and practical importance.},
  archive      = {J_ISCI},
  author       = {Jiali Zhang and Yan Tu and Zhongyong Wan and Linqi Cheng and Benjamin Lev},
  doi          = {10.1016/j.ins.2025.122785},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122785},
  shortjournal = {Inf. Sci.},
  title        = {An adaptive sequential three-way decision-making model via dynamic fusion of incomplete mixed data considering misclassification penalty from holistic and incremental perspectives},
  volume       = {727},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Progressive semantic refinement hashing for cross-modal retrieval. <em>ISCI</em>, <em>727</em>, 122783. (<a href='https://doi.org/10.1016/j.ins.2025.122783'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of explosive information growth, the demand for efficient cross-modal retrieval has surged, making cross-modal hashing a research hotspot for its ability to map multiple modalities into a shared binary space for fast and accurate retrieval. However, existing methods suffer from three critical issues: inadequate coarse-grained modality alignment, weak fine-grained instance discriminability, and unsound hash function construction, which significantly hinder retrieval performance. To address the above challenges, this paper proposes a novel cross-modal retrieval method, Progressive Semantic Refinement Hashing (PSRH), for large-scale cross-modal retrieval. First, through the three-stage semantic modeling of multimodal latent space learning, semantic center learning, and global-subgroup similarity learning, semantic information is mined layer by layer from coarse-grained modality alignment to fine-grained instances, and the generated discriminative hash codes can effectively capture multi-granular fine-grained semantic relationships. Second, it adopts a dual-enhanced hash function learning strategy integrating noise sample elimination and adaptive margin adjustment to build more robust hash functions. Extensive experiments conducted on three benchmark datasets and comparisons with 11 state-of-the-art methods demonstrate the superiority of the PSRH method.},
  archive      = {J_ISCI},
  author       = {Zhiying Cui and Hongbin Ma},
  doi          = {10.1016/j.ins.2025.122783},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122783},
  shortjournal = {Inf. Sci.},
  title        = {Progressive semantic refinement hashing for cross-modal retrieval},
  volume       = {727},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Customer satisfaction optimization in due-aware multi-agent path finding. <em>ISCI</em>, <em>727</em>, 122782. (<a href='https://doi.org/10.1016/j.ins.2025.122782'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we formalize the due-aware multi-agent path finding (DA-MAPF) by integrating temporal constraints into the classical multi-agent path finding problem. Finding optimal solutions for the DA-MAPF problem is NP-hard. To tackle this, we introduce two search-based algorithms: the optimal Due-Aware Conflict-Based Search (DA-CBS) and the bounded suboptimal Satisfaction-Based Search (SBS). Despite their effectiveness, both algorithms face scalability challenges in high-agent-density scenarios. To overcome these limitations, we introduce a reinforcement learning-based algorithm, called Priority-aware Dynamic Communication Learning (PDCL), which incorporates a novel multi-agent communication message aggregation mechanism, two-head priority-aware graph dynamic attention network. We conduct empirical evaluations of the DA-CBS, SBS and PDCL algorithms using a range of benchmark maps. Our evaluations demonstrate that the SBS algorithm performs nearly optimally and achieves higher success rates, particularly in environments with dense obstacles. PDCL provides acceptable solutions more quickly in dense agent scenarios. Furthermore, PDCL surpasses existing multi-agent path finding algorithms by delivering higher average customer satisfaction in the DA-MAPF problem. Additionally, the two-head priority-aware graph dynamic attention network within PDCL outperforms other methods in multi-agent communication.},
  archive      = {J_ISCI},
  author       = {Jianqi Gao and Yanjie Li and Xiongtao Shi and Kejian Yan},
  doi          = {10.1016/j.ins.2025.122782},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122782},
  shortjournal = {Inf. Sci.},
  title        = {Customer satisfaction optimization in due-aware multi-agent path finding},
  volume       = {727},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integrated LOPCOW-AROMAN framework with softmax hamacher information aggregation: Enhancing airport security screening efficiency in uncertain environment. <em>ISCI</em>, <em>727</em>, 122776. (<a href='https://doi.org/10.1016/j.ins.2025.122776'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resilient airport security systems are essential for safeguarding passengers, infrastructure, and personnel while fostering trust in air travel. Airport security efficiency requires the balance of advanced physical and cyber tools with adaptable strategies, ensuring rapid recovery and continuous operation despite disruptions. The logarithmic proportional comparison operator weighting (LOPCOW) is used for determining criteria weights of airport security, and an alternative ranking order method accounting for a two-step normalization (AROMAN) approach is used for ranking airport security alternatives by using cubic intuitionistic fuzzy information. Integrating the softmax function and Hamacher operations, new aggregation operators are developed, such as cubic intuitionistic fuzzy softmax Hamacher weighted averaging (CIFSHWA), cubic intuitionistic fuzzy softmax Hamacher ordered weighted averaging (CIFSHOWA), cubic intuitionistic fuzzy softmax Hamacher weighted geometric (CIFSHWG), and cubic intuitionistic fuzzy softmax Hamacher ordered weighted geometric (CIFSHOWG). This study introduces a robust Softmax Hamacher LOPCOW-AROMAN approach for multi-criteria decision-making (MCDM) that improves airport security screening efficiency by integrating Industry 5.0. By combining qualitative and quantitative criteria under uncertainty, these operators make it possible to evaluate airport security procedures more thoroughly, guaranteeing more equitable and realistic evaluations. A sensitivity analysis is performed to verify the robustness of the suggested framework, which demonstrates that the Softmax Hamacher LOPCOW-AROMAN approach ensures accurate, reliable, and efficient evaluations of airport security systems.},
  archive      = {J_ISCI},
  author       = {Muhammad Riaz and Tehmina Shahzadi and Muhammad Saqlain and Jose M. Merigo},
  doi          = {10.1016/j.ins.2025.122776},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122776},
  shortjournal = {Inf. Sci.},
  title        = {Integrated LOPCOW-AROMAN framework with softmax hamacher information aggregation: Enhancing airport security screening efficiency in uncertain environment},
  volume       = {727},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fuzzy variational calculus in linearly correlated space: Part II. <em>ISCI</em>, <em>727</em>, 122774. (<a href='https://doi.org/10.1016/j.ins.2025.122774'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents the theoretical basis for calculus of variations on R F ( A ) . The first paper in this series established two fundamental results essential to our objectives: a fuzzy version of the du Bois–Reymond lemma and the Lagrange lemma. Building upon these results, we continue the development of the variational calculus on R F ( A ) by extending key theorems from the classical calculus of variations to this fuzzy context. In particular, we present an existence theorem and a fuzzy version of the Euler–Lagrange equation.},
  archive      = {J_ISCI},
  author       = {Gastão S.F. Frederico and Estevão Esmi and Laécio C. Barros},
  doi          = {10.1016/j.ins.2025.122774},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122774},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy variational calculus in linearly correlated space: Part II},
  volume       = {727},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic location search for identifying maximum weighted independent sets in complex networks. <em>ISCI</em>, <em>727</em>, 122761. (<a href='https://doi.org/10.1016/j.ins.2025.122761'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Maximum Weighted Independent Set (MWIS) problem is a well-known combinatorial optimization problem with significant applications. It involves selecting a subset of non-adjacent vertices in a weighted graph while maximizing the total weight of the selected vertices. Given its NP -hard nature, exact algorithms often encounter computational difficulties, which lead to heuristic approaches becoming the primary means of finding solutions for MWIS. However, many existing heuristic algorithms suffer from slow convergence and insufficient search intensity. This paper introduces DynLS algorithm for MWIS that incorporates three key advancements. First, it employs a scores-based adaptive vertex perturbation technique to enhance convergence speed, particularly in sparse graphs. Second, it features a region location mechanism that facilitates escaping local optima by redefining the search space. Finally, it introduces a novel variable neighborhood descent strategy, ComLS, which combines vertex exchange strategies and a reward mechanism to guide the exploration toward high-quality solutions. Experimental results demonstrate the superiority of DynLS, consistently producing high-quality solutions within 1000 s. It outperforms five leading algorithms across 360 instances, achieving the best solution for 350 instances and surpassing the second-best algorithm, Cyclic-Fast, by 177 instances. Moreover, DynLS matches Cyclic-Fast’s convergence speed, underscoring its efficiency and practicality. This research marks a significant advancement in heuristic algorithms for MWIS.},
  archive      = {J_ISCI},
  author       = {Enqiang Zhu and Qiqi Bao and Chenkai Hao and Chanjuan Liu and Yongsheng Rao},
  doi          = {10.1016/j.ins.2025.122761},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122761},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic location search for identifying maximum weighted independent sets in complex networks},
  volume       = {727},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). New amplified inequalities and their application on mittag-leffler synchronization problem of fractional-order fuzzy bidirectional associative memory neural networks in octonion-valued field by using a genetic algorithm. <em>ISCI</em>, <em>727</em>, 122747. (<a href='https://doi.org/10.1016/j.ins.2025.122747'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper infers some new amplified inequalities and applies them to Mittag-Leffler synchronization problem of fractional-order fuzzy octonion-valued bidirectional associative memory neural networks (FOFOVBAMNNs) with threshold neurons. First of all, we establish the model for the system of FOFOVBAMNNs which not only contains fractional-order derivatives and octonions but also includes fuzzy weights and two interactive layers. Then, we directly separate the system of FOFOVBAMNNs into sixteen subsystems of fractional-order fuzzy real-valued BAM neural networks (FOFRVBAMNNs) and we successfully extend some new amplified inequalities that can be helpful for solving the extension of linear threshold activation functions (LTAFs) and reducing the complexity of analysis process. Next, the flexible criteria can be acquired for Mittag-Leffler synchronization problem of FOFOVBAMNNs mainly on the basis of the obtained inequalities, the new construction of LKFs, the design of the fuzzy controllers and the very recent fractional-order inequality. Further, the optimization for the flexible criteria of Mittag-Leffler synchronization for FOFOVBAMNNs can be realized by a genetic algorithm (GA). Finally, two simulations are given to demonstrate the availability and effectiveness of the theoretical achievements.},
  archive      = {J_ISCI},
  author       = {Jianying Xiao and Shiping Wen and Xiao Guo and Yongtao Li},
  doi          = {10.1016/j.ins.2025.122747},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122747},
  shortjournal = {Inf. Sci.},
  title        = {New amplified inequalities and their application on mittag-leffler synchronization problem of fractional-order fuzzy bidirectional associative memory neural networks in octonion-valued field by using a genetic algorithm},
  volume       = {727},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An efficient technique for keratoconus disease prediction by utilizing extensive feature extraction and AI method. <em>ISCI</em>, <em>727</em>, 122740. (<a href='https://doi.org/10.1016/j.ins.2025.122740'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effective management of Keratoconus, an advanced eye condition characterized by a thinning, protruding cornea and distorted vision, hinges on an initial and precise diagnosis. An accurate and initial diagnosis is vital for effective management. The primary reason AI-based ML and DL methods struggle to provide precise classification for effective management is the limitation in their feature extraction efficiency, which makes an accurate initial diagnosis difficult. This study proposes a novel hybrid Convolution Self-Attention with Feature Selection Network (CSA-FS-Net) to address these challenges. The CSA-FS-Net utilizes self-attention mechanisms combined with depth-wise separable convolution for efficient feature extraction, reducing redundancy and model complexity. Using algorithm such as ReliefF, minimum Redundancy Maximum Relevance (mRMR), and Laplacian score to rank the most critical features in a dataset, a Convolutional Neural Network then predicts and classifies them into normal, Keratoconus, and suspect Keratoconus. The CSA-FS-Net model demonstrates outstanding performance, evidenced by its evaluation metrics: 99.60% accuracy, 99.70% precision, 99.20% sensitivity, 99.50% specificity, an F-score of 99.80% and computational time of 1.33 s. These outcomes highlights that the CSA-FS-Net framework is more a more efficient and reliable way to diagnose keratoconus, representing a big step forward in ophthalmology.},
  archive      = {J_ISCI},
  author       = {Anuragh Vijjapu and A V S Surya Varma and Kapula Kalyani and Vijendra Kumar and N P Dharani and S V S N Murthy},
  doi          = {10.1016/j.ins.2025.122740},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122740},
  shortjournal = {Inf. Sci.},
  title        = {An efficient technique for keratoconus disease prediction by utilizing extensive feature extraction and AI method},
  volume       = {727},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-source control bumps suppression of switched delayed systems with quantization under hybrid switching. <em>ISCI</em>, <em>727</em>, 122729. (<a href='https://doi.org/10.1016/j.ins.2025.122729'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of bumpless transfer quantized control for continuous-time switched delayed systems in the absence of stable subsystems. First, we propose an original characterization of bumpless transfer performance called quantization-dependent bumpless transfer performance to simultaneously mitigate abrupt large multi-source control bumps resulting from both quantization and switching. Second, to overcome the limitations of the multiple Lyapunov-Krasovskii functionals method associated with the min-switching law under switched delayed systems, a novel dwell-time-dependent Lyapunov-Krasovskii functional is proposed along with a hybrid switching strategy. Sufficient conditions are established to guarantee both asymptotic stability and quantization-dependent H ∞ bumpless transfer performance of the closed-loop systems. Finally, a switched RLC circuit model is exploited to illustrate the effectiveness and applicability of our method.},
  archive      = {J_ISCI},
  author       = {Siyuan Zhang and Hong Sang and Hong Nie and Georgi M. Dimirovski and Qingyu Su},
  doi          = {10.1016/j.ins.2025.122729},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122729},
  shortjournal = {Inf. Sci.},
  title        = {Multi-source control bumps suppression of switched delayed systems with quantization under hybrid switching},
  volume       = {727},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A UAV tracking framework via motion-decoupled trajectory prediction and occlusion handling. <em>ISCI</em>, <em>726</em>, 122784. (<a href='https://doi.org/10.1016/j.ins.2025.122784'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-object tracking from UAVs has significant applications in both civilian and military domains, enabling precise tracking and trajectory prediction of specific targets. However, the inherent instability of the UAV platform causes rapid and irregular target motion in the image plane; frequent occlusions from buildings or vegetation lead to target loss; and the target’s pixel coordinates, which are a complex coupling of its individual movement and the camera’s global motion, complicate motion analysis. This paper proposes SiamMDTP, a novel tracking framework designed for UAV platforms, based on motion-decoupled trajectory prediction and occlusion handling to address these challenges. First, Motion Decoupled Trajectory Predictor (MDTP) decouples object motion from the camera motion through global motion matrices, and predicts future state of the object using Extended Kalman Filter to counter fast motion and occlusion. Second, Continuous Tracker under Occlusion (CTUO) ensures robust tracking during target loss, enhanced by a novel Angular Direction-based Weight Window Penalty mechanism (ADWWP), which dynamically adjusts the directional weights based on the predicted information to improve recapture performance. Experimental results demonstrate that the proposed framework achieves compelling performance across six datasets, including a self-constructed UAV dataset.},
  archive      = {J_ISCI},
  author       = {Tianxing Xiao and Yonghua Lu and Xinyu Di and Zhicheng Ma and Hailong Qian and Yan Liu and Yinlong Zhu},
  doi          = {10.1016/j.ins.2025.122784},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122784},
  shortjournal = {Inf. Sci.},
  title        = {A UAV tracking framework via motion-decoupled trajectory prediction and occlusion handling},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Query-guided expansion and contraction of document sets. <em>ISCI</em>, <em>726</em>, 122779. (<a href='https://doi.org/10.1016/j.ins.2025.122779'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document set expansion is a fundamental problem in information retrieval, involving the augmentation of an initial document set with additional relevant documents from a larger corpus. Query reformulation techniques, such as query expansion and refinement, offer effective means to modify initial queries and retrieve supplementary documents, but they are inherently limited by dependence on an initial query and relevance feedback. In contrast, embedding techniques represent documents in a feature space, enabling expansion or contraction by exploiting document similarities. However, existing approaches often fail to reconcile the advantages of both strategies. To address this, we propose a novel method that integrates query reformulation and embedding techniques into a unified framework. Our method aims to augment document sets—allowing both expansion and contraction—while satisfying desirable properties, including high intra-set document embedding similarity, fidelity to the initial set, and simplicity through low-complexity queries. While we show that our proposal admits a Mixed Integer Quadratic Programming formulation, which can be globally optimized for small problem sizes, we also present a computationally efficient heuristic search algorithm for larger instances. We illustrate our method using a running toy example and demonstrate its efficacy through experimental evaluation on a benchmark corpus of newspaper articles.},
  archive      = {J_ISCI},
  author       = {Arne Deloose and Bernard De Baets and Jan Verwaeren},
  doi          = {10.1016/j.ins.2025.122779},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122779},
  shortjournal = {Inf. Sci.},
  title        = {Query-guided expansion and contraction of document sets},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Large language model as meta-surrogate for offline data-driven many-task optimization: A proof-of-principle study. <em>ISCI</em>, <em>726</em>, 122762. (<a href='https://doi.org/10.1016/j.ins.2025.122762'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In offline data-driven optimization scenarios, where new evaluation data cannot be obtained in real time and each ground-truth evaluation is often costly, surrogate models become a key technology for reducing simulation or experimental overhead. This study proposes a novel meta-surrogate framework to assist many-task offline optimization, by leveraging the knowledge transfer strengths and emergent capabilities of large language models (LLMs). We formulate a unified framework for many-task fitness prediction, by defining a universal model with metadata to fit a group of problems. Fitness prediction is performed on metadata and decision variables, enabling efficient knowledge sharing across tasks and adaptability to new tasks. The LLM-based meta-surrogate treats fitness prediction as conditional probability estimation, employing a unified token sequence representation for task metadata, inputs, and outputs. This approach facilitates efficient inter-task knowledge sharing through shared token embeddings and captures complex task dependencies via many-task model training. Experimental results demonstrate the model’s emergent generalization ability, including zero-shot performance on problems with unseen dimensions. When integrated into evolutionary transfer optimization (ETO), our framework supports dual-level knowledge transfer—at both the surrogate and individual levels—enhancing optimization efficiency and robustness. This work establishes a novel foundation for applying LLMs in surrogate modeling, offering a versatile solution for many-task optimization.},
  archive      = {J_ISCI},
  author       = {Xian-Rong Zhang and Yue-Jiao Gong and Yuan-Ting Zhong and Ting Huang and Jun Zhang},
  doi          = {10.1016/j.ins.2025.122762},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122762},
  shortjournal = {Inf. Sci.},
  title        = {Large language model as meta-surrogate for offline data-driven many-task optimization: A proof-of-principle study},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). KACNet: Enhancing CNN feature representation with kolmogorov-arnold networks for medical image segmentation and classification. <em>ISCI</em>, <em>726</em>, 122760. (<a href='https://doi.org/10.1016/j.ins.2025.122760'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) often face challenges in generalizing across datasets due to edge-blurring limitations of fixed activation functions. To address this, this paper introduces a novel approach by integrating KANs into CNNs, forming a module called KANConv, to build an innovative encoder architecture. The encoder is designed to augment the CNN’s capability to effectively distinguish targets in medical image segmentation and classification tasks. Specifically, the CNN component leverages its nonlinear structure to extract hidden local features from the input image, while the KAN component captures global feature information by processing the local features via a sophisticated structure composed of B-spline functions. The proposed multi-stage architecture enables a comprehensive information fusion of local and global features, significantly improving feature representation quality. To validate our encoder’s effectiveness, we perform extensive experiments on: (1) five benchmark 2D medical image segmentation datasets, where our model achieves state-of-the-art performance; and (2) six prominent 3D medical classification datasets, consistently demonstrating superior results compared to existing methods.},
  archive      = {J_ISCI},
  author       = {Deguang Li and Zeyan Jin and Chengyue Guan and Liubing Ji and Yudong Zhang and Zhaozhao Xu and Jiyong Zhang},
  doi          = {10.1016/j.ins.2025.122760},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122760},
  shortjournal = {Inf. Sci.},
  title        = {KACNet: Enhancing CNN feature representation with kolmogorov-arnold networks for medical image segmentation and classification},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dense subgraph mining in dynamic bipartite graphs. <em>ISCI</em>, <em>726</em>, 122758. (<a href='https://doi.org/10.1016/j.ins.2025.122758'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a key type of dense subgraph, the k -bitruss refers to the maximal subgraph of a bipartite graph where each edge is contained in at least k rectangles (4-cycles). This structure has significant applications in various fields, such as community detection and maximal biclique identification. Existing studies have proposed multiple decomposition-based methods for mining k -bitrusses in bipartite graphs. However, many real-world bipartite graphs exhibit high dynamics, whose edges are continuously added or removed over time. Since edge insertions/removals typically account for a small proportion of graph changes, recomputing k -bitrusses via full decomposition is computationally inefficient. This paper focuses on maintenance strategies to update affected k -bitrusses rather than reconstructing them from scratch. To ensure accuracy, we first propose a novel bitruss update theorem. Then, we develop two parallel algorithms to handle edge insertion and removal separately. Finally, we optimize these algorithms by leveraging an auxiliary BS-index to enhance efficiency. Experimental results demonstrate that our approach outperforms the state-of-the-art methods by at least one order of magnitude.},
  archive      = {J_ISCI},
  author       = {Wen Bai and Xiaodong Zhu and Yuncheng Jiang},
  doi          = {10.1016/j.ins.2025.122758},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122758},
  shortjournal = {Inf. Sci.},
  title        = {Dense subgraph mining in dynamic bipartite graphs},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Denoising precedes enrichment: Aspect-sentiment-aware graph contrastive distillation network for review-based recommendation. <em>ISCI</em>, <em>726</em>, 122756. (<a href='https://doi.org/10.1016/j.ins.2025.122756'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research progress shows that reviews help improve the performance of recommendations. Most review-based recommendation methods model user preferences for items by directly converting reviews into embeddings. However, reviews often contain substantial irrelevant noise, which might be magnified in the message propagation of the frequent graph learning process. Some studies have attempted to extract fine-grained aspects from reviews to mitigate the noise pollution problem. Nevertheless, the upstream pre-trained models they adopted have problems of mis-detection and under-detection in aspect extraction, resulting in the recontamination of new noise and the loss of crucial information, respectively. In response to these challenges, this paper presents a novel aspect-sentiment-aware Graph Contrastive Distillation Network, shortened to GCDNet, which is essentially a framework that first reduces noise and then enhances features. Specifically, GCDNet first constructs both aspect-sentiment-aware graphs and homogeneous aspect-aware graphs, and performs contrastive learning among them to mitigate the negative impacts of mis-detection. Next, knowledge distillation is employed to transfer knowledge from modules with complete review information to aspect-based modules. This process mitigates the insufficient utilization of information due to aspect under-detection. Extensive experiments conducted on five public datasets demonstrate the state-of-the-art performance of the proposed GCDNet, achieving up to 11.11 % and an average of 7.92 % improvement over previous best models. To facilitate subsequent research, we have made the complete codes and data of GCDNet available at https://github.com/kangliu1225/GCDNet .},
  archive      = {J_ISCI},
  author       = {Tongtong Yu and Sheng Sang and Kang Liu},
  doi          = {10.1016/j.ins.2025.122756},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122756},
  shortjournal = {Inf. Sci.},
  title        = {Denoising precedes enrichment: Aspect-sentiment-aware graph contrastive distillation network for review-based recommendation},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Concept learning for algorithmic reasoning: Insights from SAT-solving GNNs. <em>ISCI</em>, <em>726</em>, 122754. (<a href='https://doi.org/10.1016/j.ins.2025.122754'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable AI and model transparency methods primarily focus on classification tasks, identifying salient input features or abstract concepts that are directly tied to the data. In contrast, algorithmic problems such as SAT solving present a deeper challenge: here, meaningful concepts depend not only on the input but also on the model’s evolving internal state; hence, such settings remain underexplored. We study concept learning in an existing model named NeuroSAT , a Graph Neural Network (GNN) trained to predict satisfiability, and uncover internal algorithmic structures, most notably the notion of support , that align with classical SAT heuristics. We then construct a significantly simplified GNN trained via a teacher–student approach: instead of learning from SAT/UNSAT labels, the student is trained to mimic NeuroSAT ’s latent representations—i.e., the concepts themselves—and achieves comparable performance using 91 % fewer parameters. For this simplified architecture, we provide a rigorous theoretical analysis that demonstrates, under certain assumptions on the input distribution and network weights, the emergence of the concept of support and its governing role in the network’s dynamics. This work bridges explainability and algorithmic reasoning by showing that classical SAT-solving strategies emerge naturally in GNNs—and can be used to simplify, compress, and formally analyze their internal dynamics.},
  archive      = {J_ISCI},
  author       = {Elad Shoham and Hadar Cohen and Khalil Wattad and Havana Rika and Dan Vilenchik},
  doi          = {10.1016/j.ins.2025.122754},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122754},
  shortjournal = {Inf. Sci.},
  title        = {Concept learning for algorithmic reasoning: Insights from SAT-solving GNNs},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mitigating malware prevalence in networks with arbitrary topologies: A flip-it cyber game approach integrated with epidemic modeling. <em>ISCI</em>, <em>726</em>, 122753. (<a href='https://doi.org/10.1016/j.ins.2025.122753'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber threats have evolved in complexity, aiming at a wide range of sectors using advanced methods and tools. This evolving threat landscape challenges existing cybersecurity frameworks, many of which lack the adaptability to counteract the complex tactics of sophisticated adversaries. Developing robust cyber defense strategies requires simulating dynamic interactions between attackers and defenders across high, moderate, and low-impact scenarios. The Flip-It cyber game serves as an intelligent framework for simulating these interactions, enabling the analysis of adaptive strategies in cybersecurity. This paper aims to address the problem of mitigating malware prevalence with full consideration of attack/defense capabilities in arbitrary network topologies. This paper proposes a sophisticated discrete-time epidemic model to characterize security state transitions over time for all three scenarios within the Flip-It game framework. On this basis, the original problem is modeled as a closed-loop control problem to seek the optimal containment strategy. Deep Reinforcement Learning (DRL) is then used to tackle the problem, generating efficient defense strategies that are well-adapted to changing cybersecurity environments. Numerical simulations based on small-world networks, scale-free networks, and router networks are then carried out to generate corresponding strategies. Additionally, we have evaluated the performance of the proposed method against the State-Of-The-Art (SOTA) in terms of attack/defense objective function, control actions, number of devices under the control of the attacker and defender, stability, execution time, and scalability. This comprehensive approach integrates epidemiological modeling, game theory, and advanced machine learning to effectively tackle the complexities of contemporary cybersecurity threats.},
  archive      = {J_ISCI},
  author       = {Mousa Tayseer Jafar and Lu-Xing Yang and Gang Li and Robin Doss and Kon Mouzakis and Rajesh Vasa and Helge Janicke and Ahmed Ibrahim and Ahmed Mohsin and Iqbal H. Sarker and Kristen Moore and Seyit Camtepe and Diksha Goel},
  doi          = {10.1016/j.ins.2025.122753},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122753},
  shortjournal = {Inf. Sci.},
  title        = {Mitigating malware prevalence in networks with arbitrary topologies: A flip-it cyber game approach integrated with epidemic modeling},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Self-triggered secure bipartite formation for MASs against byzantine attacks: A distributed unknown input observer approach. <em>ISCI</em>, <em>726</em>, 122752. (<a href='https://doi.org/10.1016/j.ins.2025.122752'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present paper studies the self-triggered secure bipartite formation for MASs against Byzantine adversaries, where an asymptotic stabilization control protocol is designed. Compared with the existing work, a more practical situation is considered where the state of each subsystem is unmeasurable and the system output is transmitted to its neighbor agents instead of the state. First of all, a distributed bipartite formation variable (DBFV) is introduced and the bipartite formation control objective turns out to be a convergence problem of the DBFV. Then, the dynamic system of the DBFV is set up where a multiple disturbance (MD) is involved. Next, the algebraic relation between the MD and the DBFV is defined, based on which a distributed unknown input observer (DUIO) is designed such that the asymptotic convergence estimates of the DBFV and the MD are obtained. Further, a DUIO-based controller is established to realize the asymptotic stabilization of the DBFV dynamic system. Finally, a Byzantine detection and defense strategy is designed based on the self-triggered mechanism with discontinuous updates of the communication topology, where nonsmooth dynamics theory is introduced into the stability analysis of the DBFV system. The proposed strategy and controller are validated by a simulation example.},
  archive      = {J_ISCI},
  author       = {Younan Zhao and Fanglai Zhu and Xufeng Ling},
  doi          = {10.1016/j.ins.2025.122752},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122752},
  shortjournal = {Inf. Sci.},
  title        = {Self-triggered secure bipartite formation for MASs against byzantine attacks: A distributed unknown input observer approach},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AG-GNN: Adaptive gating mechanism for robust node classification in graph neural networks. <em>ISCI</em>, <em>726</em>, 122750. (<a href='https://doi.org/10.1016/j.ins.2025.122750'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have revolutionized node classification tasks by leveraging graph structure and node features through message-passing schemes. However, GNNs frequently suffer from over-smoothing as the number of layers increases, causing node representations to collapse and lose discriminative power. In this paper, we propose AG-GNN, a novel architecture that addresses these challenges through a simple yet effective adaptive gating mechanism. This mechanism acts as a smart switch that dynamically controls how much information flows from the graph structure versus the node features at each layer. Our model’s dual-pathway design enables it to excel in both homophilic graphs (where connected nodes tend to share the same class) and heterophilic graphs (where connected nodes often belong to different classes). Extensive experiments demonstrate that AG-GNN consistently outperforms state-of-the-art methods, achieving up to 2.16 % improvement on heterophilic datasets like Cornell and 5.86 % improvement on large-scale networks like Penn94. Importantly, our approach maintains strong performance even with very deep architectures (up to 64 layers), demonstrating remarkable resistance to over-smoothing where traditional GNNs fail. AG-GNN scales efficiently to graphs with millions of nodes while maintaining computational tractability whereas several baseline models experience out-of-memory errors.},
  archive      = {J_ISCI},
  author       = {Ahmed Begga and Miguel Ángel Lozano and Francisco Escolano},
  doi          = {10.1016/j.ins.2025.122750},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122750},
  shortjournal = {Inf. Sci.},
  title        = {AG-GNN: Adaptive gating mechanism for robust node classification in graph neural networks},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LWDiffusion: Node role detection in complex networks via legendre wavelet diffusion model. <em>ISCI</em>, <em>726</em>, 122749. (<a href='https://doi.org/10.1016/j.ins.2025.122749'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As complex networks evolve dynamically, identifying the hierarchical roles of network nodes with precision remains a significant challenge. This study introduces LWDiffusion, a novel method for detecting node role hierarchies. It employs a wavelet diffusion model that integrates the multi-scale analysis capability of the Legendre wavelet basis with the heat kernel diffusion mechanism to create structural embedding representations for complex networks. The method leverages the decomposition of the network Laplacian matrix to construct a wavelet diffusion model, extracting low-dimensional feature representations of nodes. These features are then classified using a straightforward XGBoost algorithm to precisely identify node role hierarchies. Compared to existing approaches, LWDiffusion effectively captures multi-scale network features while offering interpretable node feature representations based on explicit mathematical models and spectral graph theory. By bypassing intricate training and tuning procedures, the method ensures enhanced reliability in practical applications. Furthermore, LWDiffusion addresses the limitations of traditional statistical methods, which often rely on local features and domain expertise, by providing a more adaptable framework for role detection. Finally, the method was rigorously validated using various real-world network datasets, including academic collaboration and aviation networks, and benchmarked against ten mainstream baseline methods. Experimental results suggest that LWDiffusion generally outperforms these baselines in accuracy, effectively capturing multi-scale and latent node features, and demonstrates extensive potential for identifying hierarchical roles in complex real-world systems.},
  archive      = {J_ISCI},
  author       = {Yanfei Liu and Dezhi Liu and Di Jin and Wenjun Wang and Xiaoyang Zheng and Chengbo Yu},
  doi          = {10.1016/j.ins.2025.122749},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122749},
  shortjournal = {Inf. Sci.},
  title        = {LWDiffusion: Node role detection in complex networks via legendre wavelet diffusion model},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-granularity spectral graph coarsening. <em>ISCI</em>, <em>726</em>, 122748. (<a href='https://doi.org/10.1016/j.ins.2025.122748'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph coarsening is the process of simplifying large-scale graph representations while preserving essential structural characteristics to improve computational efficiency in graph processing. Conventional techniques primarily reduce graph size through node and edge merging but often inadequately preserve both global spectral properties and local structural details. Real-world graphs exhibit inherent hierarchical complexity comprising critical global topological patterns and local structural features necessary for accurate analysis. To address these limitations, we present a Multi-Granularity Spectral Graph Coarsening (MGSGC) framework that systematically integrates spectral graph analysis with local structural preservation through multi-granularity operations. Our approach initiates with hierarchical graph decomposition, where node merging generates structurally homogeneous subgraphs. Spectral analysis of normalized Laplacian matrices guides iterative coarsening optimization, using spectral distance metrics to identify subgraphs requiring refinement. A dual-resolution mechanism preserves global spectral signatures and local connectivity patterns simultaneously, ensuring retention of both macroscopic and microscopic structural information. Comprehensive experiments across multiple benchmark datasets demonstrate that MGSGC outperforms recent methods, achieving higher accuracy, superior structural preservation, and strong resilience to label noise, ensuring robust performance in real-world scenarios. Code is available at https://anonymous.4open.science/r/MGSGC/ .},
  archive      = {J_ISCI},
  author       = {Jinyuan Ni and Long Chen and Ning Yu},
  doi          = {10.1016/j.ins.2025.122748},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122748},
  shortjournal = {Inf. Sci.},
  title        = {Multi-granularity spectral graph coarsening},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Information-theoretic and bayesian model selection for physics-based modeling: Balancing fit, complexity, and generalization. <em>ISCI</em>, <em>726</em>, 122743. (<a href='https://doi.org/10.1016/j.ins.2025.122743'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable model selection is a cornerstone of developing physics-based models of engineering systems. However, existing model selection criteria has not been investigated across a variety of calibration scenarios, where selection choices can be affected by (i) parameter dimensionality, (ii) model form, (iii) prior informativeness, (iv) reparameterization, and (v) data characteristics. Moreover, it remains unclear whether these criteria can reliably distinguish model fidelity that genuinely improves explanatory power. These limitations restrict the broader applicability of model selection criteria in physics-based modeling, where balancing goodness-of-fit, complexity, and generalization is critical. To address these gaps, this study systematically evaluates information-theoretic and Bayesian model selection criteria through two case studies. The first case study employs polynomial regression models to isolate the effects of calibration factors and investigate their influence on the selection behavior of criteria. The second case study extends the analysis to a hierarchy of thermal models for double-pane windows, examining the ability of selection criteria to differentiate effective complexity from superficial increases in model fidelity. Results indicate that classical information-theoretic criteria are sensitive to parameter dimensionality, while covariance-based criteria reflect changes in model form and data characteristics, and Bayesian criteria exhibit sensitivity to all examined calibration factors. Furthermore, both covariance-based and Bayesian criteria effectively identify secondary physical mechanisms as sources of ineffective complexity, penalizing redundant fidelity. These findings underscore that model selection is not a one-size-fits-all task, and the choice of model selection criteria should be informed by the calibration scenario and the modeling objective.},
  archive      = {J_ISCI},
  author       = {Xinyue Xu and Julian Wang},
  doi          = {10.1016/j.ins.2025.122743},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122743},
  shortjournal = {Inf. Sci.},
  title        = {Information-theoretic and bayesian model selection for physics-based modeling: Balancing fit, complexity, and generalization},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Passivity-based variable damped sliding mode control for cable-driven wave motion compensation device under hybrid disturbances. <em>ISCI</em>, <em>726</em>, 122742. (<a href='https://doi.org/10.1016/j.ins.2025.122742'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cable-driven wave motion compensation devices are essential for safe maritime operations, including offshore supply missions and marine engineering tasks. In suspended cable configurations, the dynamic performance is inherently constrained by payload weight, since gravity not only enables force closure but also limits the available control authority. Moreover, the system is constantly subjected to wave-induced disturbances, which exacerbate platform oscillations and further challenge controller robustness. To tackle these issues, a novel passivity-based control approach is proposed in this paper that integrates fast terminal sliding mode control with adaptive damping modulation. Specifically, a port-Hamiltonian sliding mode control framework is established to ensure finite-time convergence under energy dissipation constraints, while a bimodal damping modulation strategy is introduced to dynamically regulate system damping for balancing convergence rate and vibration suppression. In addition, a cascaded observer is proposed to reconstruct disturbances and mitigate sensor noise. The global stability of the closed-loop system is rigorously established based on Lyapunov analysis. Simulation and experimental results demonstrate that, under comparable force output levels, the proposed controller reduces the Integral of Time-weighted Absolute Error index by 58 % and 55 %, respectively, thereby achieving improved steady-state performance. The robustness of the proposed controller is further confirmed by sea trials.},
  archive      = {J_ISCI},
  author       = {Zongbin Hou and Ruihao Sui and Yuan Chen},
  doi          = {10.1016/j.ins.2025.122742},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122742},
  shortjournal = {Inf. Sci.},
  title        = {Passivity-based variable damped sliding mode control for cable-driven wave motion compensation device under hybrid disturbances},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel seasonal grey euler model with three parameter-interval grey numbers for forecasting power generation. <em>ISCI</em>, <em>726</em>, 122738. (<a href='https://doi.org/10.1016/j.ins.2025.122738'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of power generation helps to assess the stability of the supply of power generation and to better plan the use of electrical energy. China’s power generation exhibits seasonal oscillations, nonlinear growth, and uncertain fluctuations. The interval numbers can reflect the range of uncertainty fluctuations in the data. Therefore, the three-parameter interval grey numbers prediction of China’s power generation is studied. A matrixed Fourier grey Euler Bernoulli model MFGEBM(1,1) for three-parameter interval grey numbers is proposed. First, a seasonal factor is introduced into a new Caputo fractional accumulation generation operator to reduce the seasonal volatility of the sequence. Secondly, the Fourier series and Bernoulli’s equation are introduced into the grey Euler model to further improve the applicability to sequences with seasonal oscillations. Then, based on a new convergence factor and triangular walking strategy, the grey wolf algorithm is improved to optimize the model’s parameters, and its effectiveness is verified with algorithm comparison experiments. In order to test the accuracy of the model proposed in this paper, two cases with different development trends and related to power are studied, and four existing grey models for seasonal oscillation sequences are used as competing models. Finally, the proposed model is used to forecast China ’s power generation.},
  archive      = {J_ISCI},
  author       = {Feifei Huang and Xiangyan Zeng and Shuli Yan},
  doi          = {10.1016/j.ins.2025.122738},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122738},
  shortjournal = {Inf. Sci.},
  title        = {A novel seasonal grey euler model with three parameter-interval grey numbers for forecasting power generation},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AFMT:Adaptive frequency decomposition and multi-scale transformer for time series forecasting. <em>ISCI</em>, <em>726</em>, 122735. (<a href='https://doi.org/10.1016/j.ins.2025.122735'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series forecasting is essential in various fields, including power systems, transportation, and meteorology. Although many existing methods improve predictive performance by decomposing sequences into trend and seasonal components, traditional techniques, such as moving averages, often suffer from spectral aliasing between high- and low-frequency features, thereby impairing forecasting precision. Furthermore, current multi-scale frameworks frequently neglect high-frequency patterns, restricting their capacity to model complex nonlinear dependencies. To overcome these limitations, we propose AFMT, a novel time series forecasting framework that integrates Adaptive Frequency-Domain Decomposition with a multi-scale patch-wise Transformer architecture. Specifically, we design a dynamic filter capable of adaptively isolating high- and low-frequency components based on their spectral distributions, effectively mitigating feature entanglement. Subsequently, a multi-scale patching strategy enables independent modeling of these components through Transformer blocks, followed by a learnable frequency-aware fusion mechanism, thereby enhancing feature independence and boosting predictive accuracy. Extensive empirical studies on eight public datasets demonstrate that AFMT consistently surpasses state-of-the-art approaches in both forecasting accuracy and generalization ability, validating its effectiveness in frequency-domain decomposition and multi-scale temporal modeling.},
  archive      = {J_ISCI},
  author       = {Li Zhu and Wanru Xu and Chunqiang Zhu and Jingkai Gao and Lugema Mi and Fan Deng and Jinqi Qu},
  doi          = {10.1016/j.ins.2025.122735},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122735},
  shortjournal = {Inf. Sci.},
  title        = {AFMT:Adaptive frequency decomposition and multi-scale transformer for time series forecasting},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Preset-time distributed algorithm for time-varying constrained optimization on multiplex networks. <em>ISCI</em>, <em>726</em>, 122734. (<a href='https://doi.org/10.1016/j.ins.2025.122734'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the preset-time distributed time-varying (TV) constrained optimization problem on multiplex networks, where both the cost functions and constraints exhibit the TV characteristic. By leveraging the time-regulator function, the supra-Laplacian matrix and a multi-phase control framework, we develop a distributed optimization algorithm that achieves preset-time convergence on multiplex networks. In the initial phase of this algorithm, the TV constraints are satisfied within the preset time frame. Then, in the subsequent phase, while continuously maintaining compliance with these constraints, the gradient consensus for all TV objective functions is achieved within the preset time frame. The effectiveness and superiority of the proposed algorithm are substantiated via several numerical simulations.},
  archive      = {J_ISCI},
  author       = {Fengyang Zhao and Siyu Chen},
  doi          = {10.1016/j.ins.2025.122734},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122734},
  shortjournal = {Inf. Sci.},
  title        = {Preset-time distributed algorithm for time-varying constrained optimization on multiplex networks},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BufferNAS: Buffer pool sampling in neural architecture search. <em>ISCI</em>, <em>726</em>, 122731. (<a href='https://doi.org/10.1016/j.ins.2025.122731'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing One-shot NAS algorithms can efficiently deal with automatic neural architecture search problem, and have achieved good performance in the real applications. However, they generally adopt fixed sampling strategy or hand-crafted sampling strategy for hypernetwork training. This makes the sampling procedure inefficient reducing their performance. In this paper, we aim to solve this problem, and propose a biased sampling strategy based on buffer pool, named buffer pool neural architecture search (BufferNAS). BufferNAS aims to change the sampling frequency of the hypernetwork, so that the hypernetwork training is biased towards a better sub-network. In BufferNAS, the advantages of the excellent sub-network can be expanded, making it easier to find better neural architectures during the training and search processes. We embed our buffer sampling approach into the existing One-Shot approach, and achieve good results. Final experimental results show that BufferNAS can obtain an 97.4 % accuracy with 3.4 M parameters on CIFAR-10 dataset. By improving the sampling strategy, our method exhibited better performance on image classification tasks.},
  archive      = {J_ISCI},
  author       = {Hongzhi Wang and Chunnan Wang and Xintong Song and Fei Geng},
  doi          = {10.1016/j.ins.2025.122731},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122731},
  shortjournal = {Inf. Sci.},
  title        = {BufferNAS: Buffer pool sampling in neural architecture search},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A unified algebraic framework for vagueness and granularity in fuzzy and rough set theories. <em>ISCI</em>, <em>726</em>, 122726. (<a href='https://doi.org/10.1016/j.ins.2025.122726'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the identification of the Boolean algebra ℘ ( X ) of all subsets of a universe X with the set E ( X ) = { 0 , 1 } X of characteristic functions, focusing on the expression of the complement operation in three equivalent forms. Building on this, we extend the framework to fuzzy sets f : X → [ 0 , 1 ] , which form a complete distributive lattice equipped with three distinct complement operations: • the Zadeh (Kleene) complement f ′ ( x ) = 1 − f ( x ) , • the Brouwer (intuitionistic) complement f ∼ ( x ) = χ { x ∈ X : f ( x ) = 0 } , and • the anti-Brouwer complement f ♭ ( x ) = χ { x ∈ X : f ( x ) ≠ 1 } . We analyze the algebraic properties and interrelations of these complements. This leads to the study of Brouwer–Zadeh (BZ) algebras, which generalize Boolean algebras to lattices with two non-standard complements linked via a ∼ ′ = a ∼∼ , implying a ∼ ≤ a ′ . We show that any BZ algebra naturally decomposes into three non-overlapping components: a Zadeh algebra, a Brouwer algebra, and an anti-Brouwer algebra. Furthermore, we derive two significant structures from BZ algebras: • the Pawlak Rough Approximation Structure (RAS), and • the Kuratowski Abstract Topological Structure (ATS). To model information granularity and graduality, we introduce the Pawlak operator into the BZ framework, yielding the Pawlak–Brouwer–Zadeh (PBZ) lattice. This enriched structure allows us to formally distinguish between vagueness and ambiguity in RAS and to model granularity in fuzzy sets, providing an algebraic foundation for shadowed sets and related granular models.},
  archive      = {J_ISCI},
  author       = {Gianpiero Cattaneo and Salvatore Greco and Roman Słowiński},
  doi          = {10.1016/j.ins.2025.122726},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122726},
  shortjournal = {Inf. Sci.},
  title        = {A unified algebraic framework for vagueness and granularity in fuzzy and rough set theories},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The envelope of one-dimensional discrete-time quantum walk. <em>ISCI</em>, <em>726</em>, 122722. (<a href='https://doi.org/10.1016/j.ins.2025.122722'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A mathematical model is presented for a one-dimensional discrete-time quantum walk, which is initiated from a quantum initial state and governed by a coin operator. When the coin operator is a flip operator, a path analysis formula is employed to compute the position probability distribution. For a general coin operator, matrix decomposition is utilized to transform it into the equivalent flip operator. When a walker undergoes n steps of evolution, it is observed that the probability of the walker occupying any given position exhibits the existence of both maximum and minimum values, irrespective of the quantum initial state. By linking these extreme positions together, a confined region is delineated, the boundary of which is designated as the envelope of the quantum walk. Remarkably, the envelope is independent of the quantum initial state. To facilitate the computation of this envelope, the relevant formulas are transformed into rational expressions, wherein both the numerators and denominators are represented by polynomials with even integer coefficients. These polynomials are classified to determine the coefficients of the numerator polynomials. An analysis is conducted to identify the location of the maximum value of the envelope, thereby examining the maximum value of the position probability distribution.},
  archive      = {J_ISCI},
  author       = {Yunguo Lin and Shuiying Cai},
  doi          = {10.1016/j.ins.2025.122722},
  journal      = {Information Sciences},
  month        = {2},
  pages        = {122722},
  shortjournal = {Inf. Sci.},
  title        = {The envelope of one-dimensional discrete-time quantum walk},
  volume       = {726},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Four new ordered weighted averaging weights generators for regular increasingly monotonic functions. <em>ISCI</em>, <em>725</em>, 122751. (<a href='https://doi.org/10.1016/j.ins.2025.122751'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diverse normalized weight vectors for OWA aggregation can be generated using regular increasing monotonic functions, embodying bipolar optimism–pessimism preferences. Yager’s original approach has been utilized for over three decades. This work, from different perspectives, proposes and analyzes four approaches to generate weight vectors with regularly increasing monotonic functions. We systematically formulate and analyze Yager’s original method and formally define it as a generator. Furthermore, we propose and analyze four distinct generators with different features and characteristics. The first two possess attenuation properties compared to Yager’s generator. The third one offers a significant advantage of full consistency in orness, and the fourth one provides a consistent cognitive mode for the regularly increasing monotonic functions that coincide almost everywhere.},
  archive      = {J_ISCI},
  author       = {LeSheng Jin and Yi Yang and Zhen-Song Chen},
  doi          = {10.1016/j.ins.2025.122751},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122751},
  shortjournal = {Inf. Sci.},
  title        = {Four new ordered weighted averaging weights generators for regular increasingly monotonic functions},
  volume       = {725},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Bi-coalitions analysis in the rough sets conflict model. <em>ISCI</em>, <em>725</em>, 122746. (<a href='https://doi.org/10.1016/j.ins.2025.122746'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel framework for conflict analysis based on rough set theory, extending Pawlak’s classical model. We introduce the concept of bi-coalitions, defined as groups of agents that fully agree on a subset of issues. Unlike traditional alliance relations, bi-coalitions are constructed without reliance on numerical thresholds, enabling a crisp and interpretable representation of consensus. The paper proposes an algorithm for identifying bi-coalitions using an indiscernibility matrix. To quantify coalition coherence, we introduce two strength measures with optional weighting of issues to reflect domain-specific relevance. Furthermore, we develop a negotiation algorithm guiding the system toward consensus or stable partitions. The proposed model is empirically validated on two real-world conflict scenarios: the 2023 parliamentary elections in Poland and the Middle East geopolitical situation. These case studies demonstrate the model’s ability to uncover interpretable coalition structures and support dynamic consensus-building.},
  archive      = {J_ISCI},
  author       = {Rafał Deja and Małgorzata Przybyła-Kasperek},
  doi          = {10.1016/j.ins.2025.122746},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122746},
  shortjournal = {Inf. Sci.},
  title        = {Bi-coalitions analysis in the rough sets conflict model},
  volume       = {725},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed output-feedback optimization for uncertain nonlinear multi-agent systems with unknown input delay. <em>ISCI</em>, <em>725</em>, 122744. (<a href='https://doi.org/10.1016/j.ins.2025.122744'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents distributed output-feedback optimization for uncertain high-order nonlinear multi-agent systems (MASs) subject to unknown input delay. First, appropriate auxiliary systems and Lyapunov-Krasovskii functional (LKF) are implemented to counteract the effects of unknown input delay. In addition, to address the challenges posed by nonlinear uncertainties and unmeasurable system states, a neural networks (NNs)-based state observer employing radial basis function (RBF) NNs has been developed. Subsequently, distributed optimal coordinators (DOCs) are employed to reformulate output consensus as tracking problem for MASs. In the context of actor-critic reinforcement learning (RL) architecture, distributed optimal controller is designed using RL algorithm combined with backstepping technique. Leveraging Lyapunov stability theory, it is rigorously demonstrated that the tracking error of the output relative to the optimal solution can be reduced to an arbitrarily small magnitude. Finally, simulation examples are conducted to validate the efficacy of the introduced algorithm.},
  archive      = {J_ISCI},
  author       = {Liujie Du and Ping Li and Zhibao Song and Zhen Wang and Wenhui Liu},
  doi          = {10.1016/j.ins.2025.122744},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122744},
  shortjournal = {Inf. Sci.},
  title        = {Distributed output-feedback optimization for uncertain nonlinear multi-agent systems with unknown input delay},
  volume       = {725},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). HP2: Hybrid and precision-guided filter pruning for CNN compression. <em>ISCI</em>, <em>725</em>, 122741. (<a href='https://doi.org/10.1016/j.ins.2025.122741'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Filter pruning has emerged as a promising approach for compressing Convolutional Neural Network (CNN) models. However, existing methods often lack accuracy in evaluating filter importance and precision in on-demand filter pruning. In this paper, we address these limitations by proposing a novel Hybrid and Precision-guided filter Pruning method (HP 2 ) for CNN compression, driven by two key observations. In particular, our method enhances filter importance evaluation and enables targeted filter pruning, allowing flexible reduction of computational complexity (FLOPs) or memory (parameters). We introduce the Hybrid Importance Score (HIS) to assess precise filter importance by leveraging both filter weights and activations. Moreover, we quantitatively analyze the intricate relationship between FLOPs and parameters, leading to an on-demand pruning strategy that further optimizes FLOPs or parameter reduction. Extensive experiments showcase the superiority of HP 2 over state-of-the-art CNN compression methods, particularly under high pruning ratios.},
  archive      = {J_ISCI},
  author       = {Zhichao Zhao and Shangwei Guo and Jialing He and Yafei Li and Run Wang and Tao Xiang},
  doi          = {10.1016/j.ins.2025.122741},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122741},
  shortjournal = {Inf. Sci.},
  title        = {HP2: Hybrid and precision-guided filter pruning for CNN compression},
  volume       = {725},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust deep network learning of nonlinear regression tasks by parametric leaky exponential linear units (LELUs) and a diffusion metric. <em>ISCI</em>, <em>725</em>, 122739. (<a href='https://doi.org/10.1016/j.ins.2025.122739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This document proposes a parametric activation function ( ac.f ) aimed at improving multidimensional nonlinear data regression. It is an established knowledge that nonlinear ac.f s are required for learning nonlinear datasets. This work shows that smoothness and gradient properties of the ac.f further impact the performance of large neural networks in terms of overfitting and sensitivity to model parameters. Smooth but vanishing-gradient ac.f s such as ELU or SiLU (Swish) have limited performance, and non-smooth ac.f s such as RELU and Leaky-RELU further impart discontinuity in the trained model. Improved performance is demonstrated with a smooth “Leaky Exponential Linear Unit”, with non-zero gradient that can be trained. A novel diffusion-loss metric is also proposed to gauge the performance of the trained models in terms of overfitting.},
  archive      = {J_ISCI},
  author       = {Enda D.V. Bigarella},
  doi          = {10.1016/j.ins.2025.122739},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122739},
  shortjournal = {Inf. Sci.},
  title        = {Robust deep network learning of nonlinear regression tasks by parametric leaky exponential linear units (LELUs) and a diffusion metric},
  volume       = {725},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Parametrically perturbed logistic map - A new approach based on the least significant bits in the state variable’s representation. <em>ISCI</em>, <em>725</em>, 122737. (<a href='https://doi.org/10.1016/j.ins.2025.122737'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cryptography involves controlled randomization and de-randomization of digital data. In the essential cryptographic infrastructure, the role of Pseudo Random Number Generators (PRNGs) becomes significant. The present work focuses on a new method of implementing PRNGs using chaotic maps. Using this approach, the classical chaotic maps, which otherwise are found to be cryptographically inadequate, can be enhanced to meet the necessary statistical requirements. In this new approach, one of the parameters of a chaotic map can be varied using the lower bits of the floating-point representation of the map’s state variable. This methodology is demonstrated using one of the most commonly discussed chaotic maps - the logistic map. The modified logistic map is shown to have excellent chaotic characteristics across the entire range of the only remaining parameter - the map’s initial state. The resulting chaotic map is named ’Parametrically Perturbed Logistic Map (PPLM)’. The PPLM is used to implement a new Pseudo Random Bit Generator (PRBG) - the PPLM-PRBG. An extensive set of simulations is carried out on the PPLM-PRBG. Using a standard set of parametric studies, including the ’NIST test suite’, the new PRBG is found to have excellent statistical and cryptographic properties.},
  archive      = {J_ISCI},
  author       = {Madhu Sharma},
  doi          = {10.1016/j.ins.2025.122737},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122737},
  shortjournal = {Inf. Sci.},
  title        = {Parametrically perturbed logistic map - A new approach based on the least significant bits in the state variable’s representation},
  volume       = {725},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing usability in face privacy protection via vision-language guided diffusion model. <em>ISCI</em>, <em>725</em>, 122736. (<a href='https://doi.org/10.1016/j.ins.2025.122736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the Internet, a large number of images containing faces are widely shared on social media, leading to increased risks of face-based identity tracking and privacy breaches. Face de-identification serves as a privacy protection technique that conceals identifiable personal information in images. Recent advancements in generative model-based face de-identification methods have made progress in ensuring privacy while preserving image usability. However, challenges remain in enhancing the usability. Specifically, current methods often generate images with noticeable artifacts or struggle to preserve the original semantic information, which can hinder the practical applications in various computer vision tasks. In this paper, we propose a vision-language understanding-guided diffusion model for face de-identification. Our method incorporates a semantic preservation module and an identity protection module to guide the diffusion model in generating de-identified images. The semantic preservation module leverages a vision-language model to retain the sentence-level semantic information of the original image. The identity protection module perturbs the identity representation to ensure privacy. We train and evaluate our method on different datasets, and the experimental results demonstrate that, while ensuring privacy protection, our method not only surpasses existing methods in image quality but also outperforms them across multiple fine-grained utility tasks.},
  archive      = {J_ISCI},
  author       = {Zhifeng Xu and Peiyao Yuan and Yiru Zhao and Lei Zhao},
  doi          = {10.1016/j.ins.2025.122736},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122736},
  shortjournal = {Inf. Sci.},
  title        = {Enhancing usability in face privacy protection via vision-language guided diffusion model},
  volume       = {725},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FedPure: Data poisoning attack detection and purification for federated skeleton-based action recognition. <em>ISCI</em>, <em>725</em>, 122733. (<a href='https://doi.org/10.1016/j.ins.2025.122733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton-based action recognition (SAR) often requires centralized skeleton data, raising serious privacy concerns in deployment scenarios such as healthcare or surveillance. Federated learning (FL) allows SAR models to be trained without sharing raw data and has therefore become an attractive approach for privacy-sensitive, distributed applications such as camera-enabled devices, human–robot interaction, and security monitoring. However, FL-based SAR remains vulnerable to data poisoning attacks. We propose a data poisoning attack detection and purification method for federated SAR, called FedPure. FedPure introduces a fused transform prototype representation, which combines global perspective transforms with subregion transforms to capture spatiotemporal cues. This design enables precise inter-client correlation analysis for malicious client detection. Moreover, a detector comprising inter-client spatiotemporal matching is designed to analyze the correlation between pseudo skeleton data. Furthermore, FedPure improves model robustness by purifying the malicious clients using a disentangled feature-based purifier to maintain data diversity. The experimental results on diverse adversarial attacks, including FGSM, PGD, C&W, Bone Length Attack, and Hard No Box Attack, confirm that FedPure outperforms existing models in SAR accuracy. By providing an integrated detection-and-purification pipeline tailored to federated SAR, FedPure narrows a key gap in privacy-preserving training, enabling safer application of FL-based action recognition. Our code is publicly available at https://github.com/alsgur0720/fedpure .},
  archive      = {J_ISCI},
  author       = {Min Hyuk Kim and Eun-Gi Lee and Seok Bong Yoo},
  doi          = {10.1016/j.ins.2025.122733},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122733},
  shortjournal = {Inf. Sci.},
  title        = {FedPure: Data poisoning attack detection and purification for federated skeleton-based action recognition},
  volume       = {725},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adversarial attacks on industrial soft sensors: Multi-target attacks based on diffusion models. <em>ISCI</em>, <em>725</em>, 122732. (<a href='https://doi.org/10.1016/j.ins.2025.122732'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial soft sensors serve as critical instruments for real-time monitoring and quality prediction in complex industrial systems, including chemical processing and energy production. While adversarial attacks on these sensors have garnered extensive attention, a critical gap persists: existing methods are fundamentally limited to single-target objectives. They fail to address inherent multi-variable couplings in industrial processes, limiting applicability in real-world scenarios requiring coordinated control of interdependent variables. To bridge this gap, this paper introduces a multi-target adversarial example attack framework based on diffusion models (DMAA) for the first time, which integrates noise scheduling and inverse denoising processes to generate adversarial examples that are more reasonable and invisible. The framework incorporates a multi-target attack optimization module, which facilitates targeted bias control for several key variables after the noise is added. Subsequently, it leverages a multilayer perceptron to effectively predict noise and generate adversarial examples, thereby driving the multi-target prediction outcomes to diverge from the actual ground truth. In case study of the sulfur recovery unit dataset (SRU), compared to existing methods, the proposed method shows significant advantages in attack effectiveness and stealth, providing new insights for the security evaluation and defense mechanism design of industrial soft sensors.},
  archive      = {J_ISCI},
  author       = {Qingchao Jiang and Shihao Fan and Zhiying Zhu and Zhenxuan Hou and Weimin Zhong and Lei Tan and Zhenxing Qian and Xinpeng Zhang},
  doi          = {10.1016/j.ins.2025.122732},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122732},
  shortjournal = {Inf. Sci.},
  title        = {Adversarial attacks on industrial soft sensors: Multi-target attacks based on diffusion models},
  volume       = {725},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A cognitive dual-attention network with feature specificity for automated CRC polyp detection. <em>ISCI</em>, <em>725</em>, 122727. (<a href='https://doi.org/10.1016/j.ins.2025.122727'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal cancer is the foremost cause of cancer-related deaths worldwide. Thus, early diagnosis of precancerous polyps is crucial for more effective treatment outcomes. To address the persistent issues in colorectal cancer diagnosis, this study proposes a novel classification model, E-D 2 AN (Efficiently Dilated Dual Attention Network), capable of accurately distinguishing colorectal abnormalities from normal colonoscopy images. The proposed model features dual attention mechanisms of EDCAM (Efficiently Dilated Channel Attention Mechanism) and ESAM (Efficient Spatial Attention Mechanism) strategies, utilizing an extended ResNet50 as the backbone. This network prioritizes efficient attention mechanisms, enriching feature extraction through an expanded receptive field and significantly driving attention-focused learning to achieve improved precision in the classification model. This combination improves the model’s ability to locate and focus on crucial regions in images, resulting in higher diagnostic precision. Dropblock regularization is also used strategically to reduce overfitting and improve generalization to unseen images. The proposed E-D 2 AN model excels across all three benchmark datasets, demonstrating superior performance over existing approaches. Prominently, it achieves an accuracy of 83.69 % on PolypsSet, 99.74 % on CKC, and 98.75 % on Kvasir-2 datasets. These findings reveal the model’s ability to improve the accuracy and reliability of early polyp detection.},
  archive      = {J_ISCI},
  author       = {T.P. Raseena and S.R. Balasundaram and Jitendra Kumar},
  doi          = {10.1016/j.ins.2025.122727},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122727},
  shortjournal = {Inf. Sci.},
  title        = {A cognitive dual-attention network with feature specificity for automated CRC polyp detection},
  volume       = {725},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficient graph attribute protection via gradient-based adversarial perturbation: A candidate-free approach. <em>ISCI</em>, <em>725</em>, 122725. (<a href='https://doi.org/10.1016/j.ins.2025.122725'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial perturbation is an effective method in Graph Neural Networks (GNNs) to defend against attribute inference attacks. However, it often suffers from slow convergence, severe degree change and heavily compromised utility. To address these problems, we propose a Gradient-Based Adversarial Perturbation method Constrained by Degree Distribution (GBAP-CDD) to resist attribute inference attacks and reduce utility loss. Firstly, unlike traditional greedy-based methods, which need to repetitively select edges from candidate sets, our candidate-free gradient-based method perturbs edges with greater impact on the model output. Secondly, since adversarial perturbation could severely change the connectivity of nodes, we propose incorporating degree distribution along with the number of perturbations as the constraints to regulate the magnitude of fluctuations. Thirdly, to minimize the effect of such perturbations on data utility, we design a privacy-utility trade-off framework that transforms the maintenance of data utility into minimizing the difference between the perturbed and original graphs. Experimental results on four real-world datasets—Citeseer, Cora, PIT, and Recidivism—demonstrate that the GBAP-CDD method significantly outperforms existing state-of-the-art methods in resisting inference attacks on private information. Specifically, GBAP-CDD reduces privacy label inference accuracy by up to 5.1 %, while achieving competitive utility performance with a maximum accuracy of 97.3 %.},
  archive      = {J_ISCI},
  author       = {Xiaofan Shan and Jinchuan Tang and Shuping Dang and Gaojie Chen},
  doi          = {10.1016/j.ins.2025.122725},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122725},
  shortjournal = {Inf. Sci.},
  title        = {Efficient graph attribute protection via gradient-based adversarial perturbation: A candidate-free approach},
  volume       = {725},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Social-semantic enhanced dual-intent hypergraph collaborative filtering. <em>ISCI</em>, <em>725</em>, 122714. (<a href='https://doi.org/10.1016/j.ins.2025.122714'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems provide personalized recommendations by modeling user–item interactions, where disentangling users’ intents is critical for improving recommendation accuracy. While existing intent modeling methods aim to capture fine-grained intent representations, they face two challenges: 1) Neglecting the influence of social semantics on modeling fine-grained intents; 2) Implicit data sparsity and intent redundancy limiting intent characterization. To tackle these challenges, we propose a Social-Semantic Enhanced Dual-Intent Hypergraph Collaborative Filtering (SDIHGCF) model. Specifically, SDIHGCF constructs hypergraph structures to preserve social semantics among users, items, and groups. It encodes features from both social and interest perspectives to achieve user and item representations that integrate individual intent, which signifies private preferences, and collective intent, which denotes overall awareness. To mitigate data sparsity and intent redundancy, where one intent can be represented by others, we use graph contrastive regularization to enforce consistency among users, items, intents, and interactions. Additionally, a bidirectional contrastive learning loss is proposed to enhance intent alignment. Experiments on four datasets demonstrate that SDIHGCF outperforms existing methods, offering novel insights into fine-grained intent modeling.},
  archive      = {J_ISCI},
  author       = {Xianji Cui and Jinhua Zhang and Yan Lan and Shan Huang},
  doi          = {10.1016/j.ins.2025.122714},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122714},
  shortjournal = {Inf. Sci.},
  title        = {Social-semantic enhanced dual-intent hypergraph collaborative filtering},
  volume       = {725},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). NLSC: A noise-robust label shift correction framework via three-head training and class-adaptive cleaning. <em>ISCI</em>, <em>725</em>, 122706. (<a href='https://doi.org/10.1016/j.ins.2025.122706'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label shift occurs when the conditional distributions remain consistent between source and target domains, but the marginal label distributions differ. For instance, during the early stage of the COVID-19 outbreak, the proportion of pneumonia cases compared to common cold cases in hospitals may have been relatively low. This ratio could shift dramatically in later stages of the pandemic, with pneumonia cases becoming predominant, even though the symptomatic presentation of each disease remained consistent. Existing label shift methods typically aim to adapt a classifier’s output to match the target domain’s label distribution, assuming the source domain has clean labels. However, real-world scenarios often involve label noise in the source domain. For example, during COVID-19’s early phase, mild and confusable symptoms frequently led to misdiagnoses of COVID-19 as the common cold, introducing label noise. Such noise compromises the effectiveness of traditional methods, necessitating novel approaches. To address this, we analyze classifier error bounds under label shift correction using noisy source data. Based on this analysis, we propose a Noise-robust Label Shift Correction (NLSC) framework. NLSC employs a Three-Head Architecture Training (THAT) strategy for robust feature learning and a Class-Adaptive Threshold Cleaning (CATC) strategy for source data purification. Extensive experiments confirm that our method outperforms existing state-of-the-art techniques, particularly in real-world scenarios with high source domain noise rates.},
  archive      = {J_ISCI},
  author       = {Xiaowen Wu and Ruidong Fan and Tingjin Luo and Chenping Hou},
  doi          = {10.1016/j.ins.2025.122706},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122706},
  shortjournal = {Inf. Sci.},
  title        = {NLSC: A noise-robust label shift correction framework via three-head training and class-adaptive cleaning},
  volume       = {725},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). 3WD-DRT: A three-way decision enhanced dynamic routing transformer for cost-sensitive multimodal sentiment analysis. <em>ISCI</em>, <em>725</em>, 122704. (<a href='https://doi.org/10.1016/j.ins.2025.122704'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately interpreting human emotion from language, facial expressions, and vocal tones remains a fundamental challenge in artificial intelligence. Current Multimodal Sentiment Analysis (MSA) models often struggle with two key issues. First, their static fusion strategies fail to handle conflicting modalities, such as sarcasm. Second, their standard loss functions ignore the asymmetric risks of severe misjudgments. To address these limitations, we propose the Three-Way Decision Enhanced Dynamic Routing Transformer (3WD-DRT), a framework operating on a "quality-aware, decision-driven" principle. It dynamically assesses each modality’s quality using a three-way decision gate, implemented via a dedicated MLP, to partition information into acceptance, deferment, or rejection pathways. This enables the model to amplify informative signals, moderately scale uncertain ones (deferment), and attenuate noisy or misleading ones. We also introduce a novel cost-sensitive loss function that imposes greater penalties on major semantic errors, such as polarity misclassifications. This approach better aligns the model’s training objective with human perception. Extensive experiments on CH-SIMS, CH-SIMSv2, MOSI, and MOSEI datasets show that 3WD-DRT consistently outperforms state-of-the-art methods, setting new benchmarks with F1-scores of 87.08 % on MOSI and 88.26 % on MOSEI. This work provides a robust solution for MSA, fostering more nuanced and reliable emotionally-aware AI systems.},
  archive      = {J_ISCI},
  author       = {Haoyu Jiang and Xiaoliang Chen and Duoqian Miao and Hongyun Zhang and Xiaolin Qin and Shangyi Du and Peng Lu},
  doi          = {10.1016/j.ins.2025.122704},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122704},
  shortjournal = {Inf. Sci.},
  title        = {3WD-DRT: A three-way decision enhanced dynamic routing transformer for cost-sensitive multimodal sentiment analysis},
  volume       = {725},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Proactive mission-time-efficient coverage path planning using hierarchical heuristics. <em>ISCI</em>, <em>725</em>, 122696. (<a href='https://doi.org/10.1016/j.ins.2025.122696'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring efficient and reliable autonomous coverage in large-scale environments remains a persistent challenge, particularly owing to the battery limitations of robotic systems. To address this challenge, this study proposes a novel, proactive energy-aware coverage path planning (CPP) framework that considers traveling and charging durations in a unified manner. The proposed method explicitly models realistic battery dynamics, including nonlinear charging and discharging behaviors. To render the problem practically solvable, it is decomposed into a hierarchical two-stage structure. Each stage is addressed using a well-suited heuristic: Ant Colony Optimization (ACO) for generating coverage paths, and a Genetic Algorithm (GA) for scheduling recharging actions. In contrast to conventional reactive approaches that respond only after the battery level becomes critical, the proposed method schedules recharging actions in advance, aiming to reduce the overall mission time proactively and strategically. Extensive simulations in synthetic, real-world-acquired, and real-world-based obstacle-rich coverage environments validate the effectiveness of the proposed method. The results demonstrate a mission time reduction of up to 24.66 %, with consistent improvements in energy reliability across varying charging station densities. These findings highlight the practicality of the proposed method as a global scheduler for real-world deployment in energy-constrained environments. Furthermore, this framework lays the foundation for extensions to multi-robot systems, enabling scalable, adaptive, and mission-time-efficient coordination in large-scale autonomous missions.},
  archive      = {J_ISCI},
  author       = {Junghwan Gong and Moses O. Oluma and Seunghwan Lee},
  doi          = {10.1016/j.ins.2025.122696},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122696},
  shortjournal = {Inf. Sci.},
  title        = {Proactive mission-time-efficient coverage path planning using hierarchical heuristics},
  volume       = {725},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A lightweight real-time detection transformer model for surface defect detection systems. <em>ISCI</em>, <em>725</em>, 122685. (<a href='https://doi.org/10.1016/j.ins.2025.122685'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient detection of surface defects is essential for production and infrastructure monitoring. A lightweight real-time surface defect detector is proposed, the Surface Defect Detection Real-Time DEtection TRansformer (SDD-RTDETR). It builds upon the Real-Time DEtection TRansformer v2 (RT-DETRv2). Key innovations include Re-Parameterized Partial Convolution (RPConv) within the BasicBlock_RPConv, which minimizes computational workload and memory requirements while boosting performance. The model also proposes the Efficient Multi-Scale Attention-based Feature Interaction (EMSAFI) module to strengthen feature extraction capabilities and employs the lightweight fusion architecture LiteScaleNeck to optimize feature fusion. Additionally, the Inner-Minimum Point Distance Intersection over Union (Inner-MPDIoU) loss refines bounding box regression, further improving model performance. The experimental findings reveal that SDD-RTDETR excels across multiple surface defect datasets. In contrast to the benchmark model, this approach improves detection accuracy while decreasing parameters by 34.6 % and computational complexity by 23.0 %, validating its adaptability and generalization ability in surface defect testing. With its lightweight structure and superior capability, SDD-RTDETR provides an effective approach for large-scale, immediate inspection, driving automation in quality control and infrastructure monitoring.},
  archive      = {J_ISCI},
  author       = {Yingqiang Hou and Xindong Zhang},
  doi          = {10.1016/j.ins.2025.122685},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122685},
  shortjournal = {Inf. Sci.},
  title        = {A lightweight real-time detection transformer model for surface defect detection systems},
  volume       = {725},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel distributionally robust uncertain optimization method with application to bus bridging service under rail disruptions. <em>ISCI</em>, <em>725</em>, 122683. (<a href='https://doi.org/10.1016/j.ins.2025.122683'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bus bridging service (BBS), as an effective means of evacuating passengers during rail disruptions, has received significant attention. However, the BBS network under rail disruptions involves complex uncertainty. In view of this, this paper innovatively defines an uncertainty distribution set to describe this uncertainty. Based on the defined uncertainty distribution set and the best-case scenario, this paper proposes a novel distributionally robust uncertain optimization method for the BBS network under rail disruptions, and constructs the corresponding model. To overcome the computational challenges of the model, this paper clarifies the specific structural characteristics of the uncertainty distribution set. By using uncertainty theory and dual techniques, the proposed model is equivalently transformed into either a mixed-integer linear programming formulation or a mixed-integer second-order cone programming formulation. The proposed method not only extends uncertainty theory under the ambiguity of the uncertainty distribution but also provides a theoretically derived computational formulation for the model. Finally, a real-world case validates the model, while sensitivity analysis and comparative experiments demonstrate the validity and advantages of the proposed method and model.},
  archive      = {J_ISCI},
  author       = {Shize Ning and Hongguang Ma},
  doi          = {10.1016/j.ins.2025.122683},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122683},
  shortjournal = {Inf. Sci.},
  title        = {A novel distributionally robust uncertain optimization method with application to bus bridging service under rail disruptions},
  volume       = {725},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Behavioral pattern clustering for thematic user segmentation in web interaction environments. <em>ISCI</em>, <em>724</em>, 122745. (<a href='https://doi.org/10.1016/j.ins.2025.122745'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering users based on their interest is a critical component in personalized content delivery. This paper proposes a novel multi modal framework that integrates semantic video classification, contextualized caption generation, and user behavior patterns. The system combines visual and audio features which are computed using convolutional and transformer based encoders to robustly capture the complex contents of video description. User browsing profile is modelled using probabilistic distributions to reflect realistic browsing behavior across six interest categories. These profiles are then clustered using KMeans, DBSCAN, and Agglomerative clustering to identify the various user groups. The quality of clustering is evaluated using Silhouttee Score, Davies-Bouldin Index, and Calinski-Harabasz Index, with PCA and t-SNE applied for visual validation of coherence of clusters. The simulation framework addresses the issues concerning data privacy and the scarcity of real world data by producing controllable and realistic user behavior traces. Experimental results demonstrate that KMeans provides the optimal trade-off between quality of clustering solution and computational cost. These integrated efforts bring personalized content delivery to a new perspective, i.e., fine-grained user segmentation and precise video understanding, respectively. The future work will focus on adopting real-time adaptive learning and integrating with more data types, and will further deploy on large-scale multimedia applications.},
  archive      = {J_ISCI},
  author       = {Suma Srinath and Nagaraju Baydeti},
  doi          = {10.1016/j.ins.2025.122745},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122745},
  shortjournal = {Inf. Sci.},
  title        = {Behavioral pattern clustering for thematic user segmentation in web interaction environments},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automating data preparation pipeline efficiently via monte carlo tree search. <em>ISCI</em>, <em>724</em>, 122730. (<a href='https://doi.org/10.1016/j.ins.2025.122730'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a crucial step in machine learning, data preparation is the most time and energy consuming task for data scientists, entailing a number of data processing techniques to improve the performance of output results for ML models. However, end-to-end AutoML research focuses on automated machine learning pipelines consisting of algorithm selection and hyper parameter tuning, falling short in comprehensive automation of data preparation. In this paper, we propose Auto-DP, an MCTS-based framework for efficient and automated data preparation. To guide the search more effectively, a neural network is designed to estimate the subsequent maximum performance gain of each tree node. In order to reduce search space and improve system efficiency, two optimization strategies, meta-learning and accelerated training strategy, are used to determine the type and order of tasks in the data preparation process in advance, and speed up the pipeline creation process. We compare Auto-DP with the popular AutoML systems on 60 real datasets from OpenML repository. Auto-DP improves the Accuracy by up to 18.11 % on the classification task and reduces the Mse by up to 25.75 % on the regression task. Furthermore, it achieves a performance in 10 s that is better than what four popular AutoML systems achieve in 1 h.},
  archive      = {J_ISCI},
  author       = {Yiyi Zhang and Ning Wang and Qixiong Zeng and Liangwei Li},
  doi          = {10.1016/j.ins.2025.122730},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122730},
  shortjournal = {Inf. Sci.},
  title        = {Automating data preparation pipeline efficiently via monte carlo tree search},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AI-driven semantic similarity-based job matching framework for recruitment systems. <em>ISCI</em>, <em>724</em>, 122728. (<a href='https://doi.org/10.1016/j.ins.2025.122728'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a real-time online recruitment application that integrates semantic similarity and artificial intelligence (AI) to improve job-candidate matching. It addresses the growing volume of job applications and the limitations of traditional keyword-based systems, which often fail to capture contextual meaning and complex semantic relationships in job-candidate alignment. The proposed system leverages natural language processing (NLP) techniques, specifically TF-IDF vectorization, cosine similarity scoring, and domain-specific keyword weighting, to interpret conceptual relevance between resumes and job descriptions, enabling more accurate and inclusive recruitment outcomes. This research developed the system in Python and evaluated it using simulated and real-world recruitment datasets. Experimental results show that the semantic model consistently outperforms keyword-based matching across diverse job domains. For instance, in simulated tests, similarity scores reached 0.74 in the Software Engineer domain, compared to just 0.35 using keyword-based methods. Real-world evaluations further confirmed the model’s effectiveness, with semantic scores of 0.83, 0.76, and 0.74 for the Hadoop, Data Science, and PMP domains, respectively. In contrast, the corresponding keyword-based scores remained below 0.17. Additionally, the system performs well in aligning generalist and specialist profiles, achieving a score of 0.88 for Data analysis roles. These findings validate the system’s robustness, scalability, and ability to interpret varied terminology across job sectors. The research presents a scalable, AI-driven framework that supports context-aware, fair, and accurate job matching, significantly advancing intelligent recruitment technology.},
  archive      = {J_ISCI},
  author       = {Mohammed-Hassan Ajjam and Hamed S. Al-Raweshidy},
  doi          = {10.1016/j.ins.2025.122728},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122728},
  shortjournal = {Inf. Sci.},
  title        = {AI-driven semantic similarity-based job matching framework for recruitment systems},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Complex network evolution with node strategies driven by information entropy. <em>ISCI</em>, <em>724</em>, 122713. (<a href='https://doi.org/10.1016/j.ins.2025.122713'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of evolutionary strategies in dynamic networks remains a fundamental challenge in network science, hindered by computational complexity and the absence of theoretically grounded frameworks to quantify node-level decisions. Current approaches often fail to integrate strategic node behaviour with information-theoretic principles, limiting insights into network optimisation. To bridge this gap, we propose an information-entropy-driven framework for secure network evolution. First, we establish a security evolution model comprising cross-community node identification and a node strategy evolution algorithm based on strategic utility. Second, we rigorously analyse the stability and equilibrium conditions of local network dynamics driven by minimising two-dimensional structural entropy. Finally, we conduct comparative studies examining network evolution under different node strategies and node types. Theoretical analysis and extensive simulations demonstrate that information-driven networks evolve toward fully-connected structures dominated by edge-creation strategies. Critically, this not only confirms that cross-community nodes capture global dynamics but also verifies convergence to a Secure Evolution Principle, the elimination of centralised hubs minimises structural vulnerability while maximizing participation in data sharing, ensuring node safety throughout the evolution process. This entropy-game framework reduces runtime by 80 %-90 % compared with the strategy update of the Imitate Best strategy and the Fermi Rule strategy while maintaining the security of the network structure, providing a theoretically grounded foundation for designing secure, adaptive networks.},
  archive      = {J_ISCI},
  author       = {Ze Yang and Youliang Tian and Jinbo Xiong and Mengqian Li and Kun Niu and Die Zhou and Jianfeng Ma},
  doi          = {10.1016/j.ins.2025.122713},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122713},
  shortjournal = {Inf. Sci.},
  title        = {Complex network evolution with node strategies driven by information entropy},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Agricultural object detection in complex environments via co-attention and self-knowledge distillation. <em>ISCI</em>, <em>724</em>, 122711. (<a href='https://doi.org/10.1016/j.ins.2025.122711'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of fruit maturity plays a critical role in the automation of agricultural production and harvesting. However, current maturity detection models still face challenges in complex planting environments including variations in fruit size, occlusion issues, diverse lighting conditions, and inadequate handling of multi-scale information. To address these challenges, an object detection model FMD-DETR (Fruit Maturity Detection-DEtection TRansformer) is proposed for robust fruit maturity detection under varying lighting and occlusion conditions. The model integrates a multi-scale feature fusion re-weighting module to improve the detection ability for fruits of different scales. A co-attention decoder is designed as a key component of the model to refine the interaction between object queries and feature representations, thereby improving detection accuracy. In addition, self-distillation and hierarchical knowledge distillation strategies are integrated into the decoder to enhance the model’s object localization ability, further improving detection accuracy. Experiments on tomato and strawberry datasets show that the model achieves an accuracy of 75.4 % on the tomato dataset, 52.7 % on the real-world tomato dataset, 41.5 % on the strawberry dataset, and 87.1 % on the FruitRipeness dataset. Experimental results demonstrate that the model surpasses existing methods in detection accuracy and robustness in complex environments, providing an effective solution for automated production and harvesting.},
  archive      = {J_ISCI},
  author       = {Yuexing Han and Zhiyi Huang and Yan Sun and Bing Wang and Qiaochuan Chen},
  doi          = {10.1016/j.ins.2025.122711},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122711},
  shortjournal = {Inf. Sci.},
  title        = {Agricultural object detection in complex environments via co-attention and self-knowledge distillation},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fuzzy platoon control for CAVs with input constraints. <em>ISCI</em>, <em>724</em>, 122709. (<a href='https://doi.org/10.1016/j.ins.2025.122709'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper designs an adaptive fuzzy controller for connected autonomous vehicles (CAVs) subject to input saturation and model uncertainty. In particular, the continuous-time vehicle model is first discretized using a sampling-based approach combined with a first-order forward-difference method to facilitate digital implementation. Then, a fuzzy logic system is adopted to approximate the unknown nonlinear term in the discrete model, and the adaptive law is adjusted using the gradient descent method. Meanwhile, a hyperbolic tangent function is employed to mitigate input saturation. Subsequently, Lyapunov stability analysis is conducted to investigate both the stability of the vehicle state and the string stability of the vehicle platoon. Finally, the effectiveness of the proposed control method is validated through simulation and co-simulation experiments.},
  archive      = {J_ISCI},
  author       = {Xuelin Yin and Zilin Gao and Min You and Changyuan Guo},
  doi          = {10.1016/j.ins.2025.122709},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122709},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy platoon control for CAVs with input constraints},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Resilient distributed localization for mobile sensor networks under malicious attacks. <em>ISCI</em>, <em>724</em>, 122708. (<a href='https://doi.org/10.1016/j.ins.2025.122708'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the cooperative localization problems for mobile sensor networks under malicious attacks, which manipulate relative measurements to mislead the localization process. A distributed attack-resilient cooperative localization algorithm is proposed, addressing the inter-node state dependencies in relative measurements by employing the covariance intersection method. Specifically, by designing an innovation-based saturation mechanism that assigns smaller coefficients for unreasonably large innovations, the adverse impact of the attacks is confined. Within this framework, the consistency of all sensors’ estimates is maintained, and the error covariance matrices are ensured to be bounded. Compared with the existing extended Kalman filter-based positioning approaches, the employed cubature integral rules avoid evaluating Jacobian matrix and improve the performance of nonlinear state estimation. Finally, two cases are conducted to validate the presented strategy.},
  archive      = {J_ISCI},
  author       = {Yuan-Wei Lv and Guang-Hong Yang and Georgi Marko Dimirovski},
  doi          = {10.1016/j.ins.2025.122708},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122708},
  shortjournal = {Inf. Sci.},
  title        = {Resilient distributed localization for mobile sensor networks under malicious attacks},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Information suppression in large language models: Auditing, quantifying, and characterizing censorship in DeepSeek. <em>ISCI</em>, <em>724</em>, 122702. (<a href='https://doi.org/10.1016/j.ins.2025.122702'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines information suppression mechanisms in DeepSeek, an open-source large language model (LLM) developed in China. We propose an auditing framework to evaluate the censorship in the model through analyzing the response alignment with the corresponding chain of thought (CoT). By comparing model responses to 646 politically sensitive topics with those to non-politically sensitive topics, our audit unveils evidence of semantic-level information suppression in DeepSeek: sensitive content often appears within the model’s internal reasoning but is omitted or rephrased in the final output. Specifically, DeepSeek suppresses references to transparency, government accountability, and civic mobilization, while occasionally amplifying language aligned with state propaganda. This study underscores the need for systematic auditing of alignment, content moderation, information suppression, and censorship practices implemented into widely-adopted AI models, to ensure transparency, accountability, and equitable access to unbiased information obtained by means of these systems.},
  archive      = {J_ISCI},
  author       = {Peiran Qiu and Siyi Zhou and Emilio Ferrara},
  doi          = {10.1016/j.ins.2025.122702},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122702},
  shortjournal = {Inf. Sci.},
  title        = {Information suppression in large language models: Auditing, quantifying, and characterizing censorship in DeepSeek},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Language-based opacity in modular discrete event systems: Compositional secret-based verification using labeled petri nets. <em>ISCI</em>, <em>724</em>, 122701. (<a href='https://doi.org/10.1016/j.ins.2025.122701'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on verifying language-based opacity within modular discrete-event systems. We consider a distributed system that is modeled as a composition of multiple interacting modules, each modeled by a labeled Petri net. Ensuring confidentiality in such systems is critical for cyber-physical systems and industrial networks, where unauthorized inference of sensitive data can lead to security breaches. We introduce a new definition of language-based opacity for modular systems and propose three secret-based verification methods that avoid the construction of the monolithic system through parallel composition. Our approach includes three methods: (1) global secret verification via observer synchronization; (2) local, module-level secret verification; and (3) an iterative composition optimization that avoids building the entire modular system, yielding significant computational savings. Experimental results on a benchmark smart manufacturing system demonstrate the practical efficiency of our approach, showing orders-of-magnitude improvement in verification time and memory usage over traditional monolithic approaches.},
  archive      = {J_ISCI},
  author       = {Salwa Habbachi and Imen Ben Hafaiedh and Zhiwu Li},
  doi          = {10.1016/j.ins.2025.122701},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122701},
  shortjournal = {Inf. Sci.},
  title        = {Language-based opacity in modular discrete event systems: Compositional secret-based verification using labeled petri nets},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DWGNet: A dual-path wavelet guidance framework for salient object detection. <em>ISCI</em>, <em>724</em>, 122699. (<a href='https://doi.org/10.1016/j.ins.2025.122699'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object detection (SOD) is a crucial research direction in computer vision and has garnered significant attention. Despite notable progress, two key limitations remain: (1) Existing methods rely primarily on single-frequency domain features, limiting their ability to extract fine details in complex scenes and achieve accurate saliency recognition and segmentation; (2) Traditional frameworks face limitations in parameters, real-time performance, and storage overhead. To address these limitations, we propose a dual-path wavelet guidance framework (DWGNet) for SOD. The framework has two innovative designs: the wavelet-based encoder–decoder and a multi-feature prediction decoder (MFPD). Specifically, we first construct a dual-path encoder to extract multilevel features, comprising a spatial feature extractor and wavelet feature extractor to capture spatial and frequency domain representations, respectively. Second, the local wavelet fusion decoder is designed to integrate wavelet features across scales, generating decoding features rich in multi-wavelet information. Then, the MFPD processes multi-path outputs in batches, leveraging high-level semantic information to guide the fusion and refinement of low-level features. Finally, the weighted loss function is introduced for fully supervised saliency inference and prediction. Quantitative and qualitative experimental results on nine databases show that our method excels in detecting simple targets, multiple targets, and small targets in low-contrast scenes. It achieves 0.043, 0.043, 0.034, 0.063, 0.055, 0.027, 0.027, 0.149, 0.293 on MAE metrics while retaining only 3.94 M parameters and 2.01 G FLOPs.},
  archive      = {J_ISCI},
  author       = {Baoyu Wang and Mao Yang and Pingping Cao and Aihong Shen},
  doi          = {10.1016/j.ins.2025.122699},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122699},
  shortjournal = {Inf. Sci.},
  title        = {DWGNet: A dual-path wavelet guidance framework for salient object detection},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A survey of folding-based zero-knowledge proofs. <em>ISCI</em>, <em>724</em>, 122698. (<a href='https://doi.org/10.1016/j.ins.2025.122698'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This survey uniquely approaches zero-knowledge proofs (ZKPs) through the lens of folding schemes, offering a fresh framework to analyze efficiency, scalability, and post-quantum resilience. By focusing on folding, we unify diverse protocols, clarify trade-offs, and identify practical engineering constraints, providing both researchers and practitioners with actionable insights. Folding schemes have emerged as the simplest and fastest approach to incrementally verifiable computation (IVC), enabling recursive zero-knowledge arguments with constant recursion overhead. We present a unifying model of folding-based ZKPs across R1CS, Plonkish/CCS, and AIR; synthesize the state of the art from Nova, SuperNova, HyperNova, and cycle-of-curves instantiations to recent post-quantum lattice-based foldings; provide a rigorous comparison of prover time, verifier work, proof size, setup assumptions, and recursion overhead; and map real deployments—including Lurk/Nova, Sonobe-based light clients, and VIMz-style media proofs—to practical constraints. Finally, we highlight open problems such as hybrid elliptic-curve–lattice designs and engineering targets for memory-bounded provers, showing how this folding-centric view advances both theoretical understanding and real-world deployment of ZKPs.},
  archive      = {J_ISCI},
  author       = {Cyprian Omukhwaya Sakwa and Andrew Omala Anyembe and Fagen Li},
  doi          = {10.1016/j.ins.2025.122698},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122698},
  shortjournal = {Inf. Sci.},
  title        = {A survey of folding-based zero-knowledge proofs},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FGNet: Robust lane detection for autonomous driving via frequency-guided feature enhancement. <em>ISCI</em>, <em>724</em>, 122694. (<a href='https://doi.org/10.1016/j.ins.2025.122694'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lane detection is a critical component in autonomous driving perception systems. Complex road scenarios featuring varying lane appearances, challenging lighting conditions, and vehicle occlusions pose significant challenges for accurate lane detection. To address these problems, we propose FGNet, a robust lane detection framework that enhances feature representation through frequency-domain analysis and adaptive global-local fusion. We first introduce a Wavelet-enhanced Feature Pyramid Network (WLFPN) that leverages discrete wavelet decomposition and directional convolutions to capture high-frequency geometric features critical for lane structure modeling. Subsequently, a Global-Aware Feature Refinement (GAFR) module is designed to overcome insufficient global context integration in existing anchor-based methods, enabling adaptive feature enhancement through spatially-aware attention and selective fusion mechanisms. Finally, a Dynamic Loss Harmonizer (DLH) employs momentum-based dynamic weight adjustment to optimize multi-loss learning, improving training stability and convergence. Extensive experiments demonstrate that FGNet achieves state-of-the-art performance with F1 scores of 80.64 % and 97.89 % on the challenging CULane and TuSimple datasets, respectively, outperforming existing methods.},
  archive      = {J_ISCI},
  author       = {Zilong Zhou and Xuyang Lu and Ping Liu and Haibo Huang},
  doi          = {10.1016/j.ins.2025.122694},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122694},
  shortjournal = {Inf. Sci.},
  title        = {FGNet: Robust lane detection for autonomous driving via frequency-guided feature enhancement},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data-driven aviation safety risk assessment: An integrated framework combining FMEA and quantum probability theory. <em>ISCI</em>, <em>724</em>, 122689. (<a href='https://doi.org/10.1016/j.ins.2025.122689'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a complex system with multi-factor coupling, the internal risk mechanism of the aviation system is difficult to be fully analyze using traditional subjective assessment methods. Recent aviation accidents have highlighted the limitations of traditional risk assessment methods, which often assume the independence of failure modes and the scenario-independence of risk factors. To address these limitations, this study proposes an innovative data-driven aviation safety risk assessment framework that integrates Natural Language Processing (NLP), Failure Mode and Effects Analysis (FMEA), and Quantum Probability Theory (QPT). Grounded in aviation safety data from the National Transportation Safety Board (NTSB), the framework leverages NLP to extract potential failure modes and employs QPT to quantify the interference effects between them. The entropy weight method is used to calculate the initial weights of risk factors when failure modes are independent, whereas quantum probabilities based on QPT are applied to update these weights when interactions occur among failure modes. Furthermore, risk prioritization associated with failure modes is conducted using the Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS). This framework breaks through the traditional isolated risk assessment framework, advancing aviation safety management from post-incident response to preemptive coupling intervention.},
  archive      = {J_ISCI},
  author       = {Mei Cai and Shaoyue Sun},
  doi          = {10.1016/j.ins.2025.122689},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122689},
  shortjournal = {Inf. Sci.},
  title        = {Data-driven aviation safety risk assessment: An integrated framework combining FMEA and quantum probability theory},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimizing the number of floorplanning layers for stacked integrated circuits based on spiking variational graph auto-encoders. <em>ISCI</em>, <em>724</em>, 122681. (<a href='https://doi.org/10.1016/j.ins.2025.122681'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the complexity of chip design continues to increase, the stacking of multiple device layers in a three-dimensional (3D) architecture has emerged as a promising approach to improve performance, power efficiency and area (PPA). The optimization of macro-module arrangement and inter-tier connections in 3D stacked chip layout is significantly influenced by the selection of the number of layers, which affects both the feasibility of the layout optimization and the final performance of the chips. In this paper, we creatively propose the Spiking Variational Graph Auto-Encoders (S-VGAE), which aim to be applied in several varieties of stacked clustering to partition the data set comprising 22 integrated circuits. By converting graph topology into spatiotemporal pulse patterns, the Spiking Graph Convolution fundamentally enhances the representational capacity of subsequent Graph Auto-Encoders. In the layout stage for all dies, we propose the Memristive-Inspired Bottom-up Left Justified Learning (MBLJL) Strategy to determine the better performance of bi-level or tri-level stacked floorplanning layout.},
  archive      = {J_ISCI},
  author       = {Kaikai Qiao and Ai Chen and Lidan Wang and Shukai Duan},
  doi          = {10.1016/j.ins.2025.122681},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122681},
  shortjournal = {Inf. Sci.},
  title        = {Optimizing the number of floorplanning layers for stacked integrated circuits based on spiking variational graph auto-encoders},
  volume       = {724},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust partial 3D point cloud registration via confidence estimation under global context. <em>ISCI</em>, <em>723</em>, 122705. (<a href='https://doi.org/10.1016/j.ins.2025.122705'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial point cloud registration is essential for autonomous perception and 3D scene understanding, yet it remains challenging owing to structural ambiguity, partial visibility, and noise. We address these issues by proposing Confidence Estimation under Global Context (CEGC), a unified, confidence-driven framework for robust partial 3D registration. CEGC enables accurate alignment in complex scenes by jointly modeling overlap confidence and correspondence reliability within a shared global context. Specifically, the hybrid overlap confidence estimation module integrates semantic descriptors and geometric similarity to detect overlapping regions and suppress outliers early. The context-aware matching strategy mitigates ambiguity by employing global attention to assign soft confidence scores to correspondences, improving robustness. These scores guide a differentiable weighted singular value decomposition solver to compute precise transformations. This tightly coupled pipeline adaptively down-weights uncertain regions and emphasizes contextually reliable matches. Experiments on ModelNet40, ScanObjectNN, and 7Scenes 3D vision datasets demonstrate that CEGC outperforms state-of-the-art methods in accuracy, robustness, and generalization. Overall, CEGC offers an interpretable and scalable solution to partial point cloud registration under challenging conditions.},
  archive      = {J_ISCI},
  author       = {Yongqiang Wang and Weigang Li and Wenping Liu and Zhe Xu and Zhiqiang Tian},
  doi          = {10.1016/j.ins.2025.122705},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122705},
  shortjournal = {Inf. Sci.},
  title        = {Robust partial 3D point cloud registration via confidence estimation under global context},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Long- and short-term preferences modeling based on dual-frequency self-attention network for sequential recommendation. <em>ISCI</em>, <em>723</em>, 122700. (<a href='https://doi.org/10.1016/j.ins.2025.122700'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation aims to analyze users’ interaction sequences to capture their sustained long-term preferences and dynamically changing short-term preferences for the next item recommendation. Recent studies have shifted their focus to the frequency domain to further mine users’ complex historical interaction behaviors. However, most existing frequency-based methods cannot explicitly distinguish the low-frequency information associated with long-term preferences from the high-frequency information associated with short-term preferences in user sequences. Consequently, they are unable to accurately model these preferences, thereby limiting the performance of the models. To this end, we propose a novel yet simple model based on Dual-Frequency Self-Attention Network (DFSNet) for sequential recommendation. DFSNet comprises low- and high-frequency self-attention modules that separately extract the corresponding components from user sequences to model long- and short-term preferences. Additionally, considering the limited frequency information available within sequences, we introduce contrastive learning to generate self-supervised signals from the preference representations produced by DFSNet. This approach further strengthens the modeling of both long-term and short-term preferences without disrupting the sequence structure, thereby positively impacting the recommendation performance. Extensive experiments on four public datasets indicate that DFSNet outperforms strong baselines while balancing accuracy and efficiency, confirming its effectiveness.},
  archive      = {J_ISCI},
  author       = {Kaiwei Xu and Yongquan Fan and Jing Tang and Xianyong Li and Yajun Du and Xiaomin Wang},
  doi          = {10.1016/j.ins.2025.122700},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122700},
  shortjournal = {Inf. Sci.},
  title        = {Long- and short-term preferences modeling based on dual-frequency self-attention network for sequential recommendation},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FedWAPR: Bridging theory and practice in probability-driven weighted aggregation for federated learning. <em>ISCI</em>, <em>723</em>, 122697. (<a href='https://doi.org/10.1016/j.ins.2025.122697'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a machine learning paradigm emphasizing data privacy, widely adopted for handling sensitive data. Federated Averaging (FedAvg) is the most commonly implemented FL aggregation technique due to its simplicity and effectiveness. However, FedAvg suffers from information loss during the aggregation stage. This study theoretically and empirically analyzes the Weighted Aggregation via Probability-based Ranking (FedWAPR) technique, an enhancement to FedAvg that retains its simplicity while addressing its limitations. FedWAPR employs a weighted aggregation strategy based on Log-Cauchy and Exponential probability density functions, assigning weights to local models based on their performance. This approach ensures accurate aggregation that reflects the contributions of individual clients. FedWAPR was tested across various model architectures, including Dense Neural Networks, Long Short-Term Memory networks, and Convolutional Neural Networks with results showing performance equal to or surpassing FedAvg. The Log-Cauchy and Exponential distribution functions allow customization of aggregation based on the number of participating clients, with exponential distribution excelling in smaller client setups and Log-Cauchy in larger ones. FedWAPR’s ability to integrate with advanced aggregation techniques like FedProx, makes it a robust solution to enhance FL. Additionally, a theoretical analysis confirms the convergence of FedWAPR under standard FL assumptions and thereby ensuring method’s robustness and reliability.},
  archive      = {J_ISCI},
  author       = {Abdullah Abdul Sattar Shaikh and M.S. Bhargavi and Pavan Kumar C},
  doi          = {10.1016/j.ins.2025.122697},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122697},
  shortjournal = {Inf. Sci.},
  title        = {FedWAPR: Bridging theory and practice in probability-driven weighted aggregation for federated learning},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DPRO-GNN: Bridging differential privacy and advanced optimization for privacy-preserving graph learning. <em>ISCI</em>, <em>723</em>, 122695. (<a href='https://doi.org/10.1016/j.ins.2025.122695'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have demonstrated exceptional performance in modeling structured data, yet their application in sensitive domains inevitably raises privacy concerns. Existing Differentially Private GNN (DPGNN) frameworks primarily rely on Differentially Private Stochastic Gradient Descent (DP-SGD) to enforce privacy guarantees. However, DP-SGD inherits its inherent limitations, such as training instability and slow convergence, which are particularly problematic for complex graph learning tasks. Although advanced optimizers like Ranger offer a promising alternative, their naive integration into DPGNN frameworks introduces bias, specifically in the second-moment estimation, due to the additive noise required for DP. To address this challenge, we propose the Differentially Private Ranger-Optimized Graph Neural Network (DPRO-GNN) to protect users’ sensitive data when training the GNN tasks. To mitigate DP noise and capture multi-scale structure, DPRO-GNN applies hierarchical pooling to aggregate nodes into progressively coarser subgraphs, yielding robust, multi-resolution embeddings. Meanwhile, our approach introduces DP-RangerBC, a bias-corrected variant of the Ranger optimizer that mitigates the noise-induced bias in second-order moment estimation, thereby enabling more stable and efficient training under DP constraints. Furthermore, the theoretical analysis of DPRO-GNN, including its correctness and security, is also provided. Extensive experiments on real-world datasets demonstrate that DPRO-GNN achieves superior performance in terms of classification accuracy and convergence speed, compared to state-of-the-art DPGNN methods. The code of DPRO-GNN is available at the following link: https://github.com/Silbermondlel/DPRO-GNN .},
  archive      = {J_ISCI},
  author       = {Yanan Bai and Liji Xiao and Hongbo Zhao and Xiaoyu Shi},
  doi          = {10.1016/j.ins.2025.122695},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122695},
  shortjournal = {Inf. Sci.},
  title        = {DPRO-GNN: Bridging differential privacy and advanced optimization for privacy-preserving graph learning},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PUWR-TSSG: A CMAB-based post-unknown worker recruitment scheme for three-stage stackelberg games in mobile crowd sensing. <em>ISCI</em>, <em>723</em>, 122693. (<a href='https://doi.org/10.1016/j.ins.2025.122693'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous Three-Stage Stackelberg Games (TSSG) have been proposed to model the strategic interactions among the requesters, the platform, and the workers in Mobile Crowd Sensing (MCS). However, most existing studies unrealistically assume that the platform possesses prior knowledge of the workers’ credibility either beforehand or after receiving their data. Conversely, in practical scenarios, the credibility of workers remains uncertain even after the submission of their data, which is known as the Post-Unknown Worker Recruitment (PUWR) problem. Given this context, conventional models designed for TSSG cannot be applied to real-world MCS. In this paper, we present the PUWR-TSSG scheme for quality-enhanced worker recruitment in TSSG. Specifically, we avoid the unreasonable assumption in previous works and propose a Double-level Credibility Discovery (DCD) approach with bipartite graph-based matrix completion for accurate credibility verification. Subsequently, based on the DCD approach, we further propose a meticulously designed combinatorial multi-armed bandit mechanism to solve the exploration–exploitation dilemma in untrusted environments. Furthermore, we formulate the payment computation issue as a TSSG, while simultaneously considering the workers’ credibility and verification costs incurred by the PUWR problem. Theoretical analyses validate the existence of Stackelberg Equilibrium in our scheme, ensuring that no participant has an incentive to unilaterally deviate from its optimal strategy. Extensive simulations on a real-world dataset validate the effectiveness of our proposed PUWR-TSSG scheme, significantly enhancing the overall data quality and leading to a remarkable average reduction in regret of up to 85.9% compared to baseline methods.},
  archive      = {J_ISCI},
  author       = {Kejia Fan and Jianheng Tang and Yaohui Han and Yuhao Zheng and Yajiang Huang and Anfeng Liu and Neal N. Xiong and Shaobo Zhang and Tian Wang and Mianxiong Dong},
  doi          = {10.1016/j.ins.2025.122693},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122693},
  shortjournal = {Inf. Sci.},
  title        = {PUWR-TSSG: A CMAB-based post-unknown worker recruitment scheme for three-stage stackelberg games in mobile crowd sensing},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel approach for shortest optimal reduct computation. <em>ISCI</em>, <em>723</em>, 122692. (<a href='https://doi.org/10.1016/j.ins.2025.122692'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough set theory has emerged as a robust soft computing paradigm for feature selection, commonly known as reduct computation. A decision system may contain multiple reducts of varying sizes, all offering equivalent classification capabilities. However, when model performance is a critical factor, the shortest reduct is generally preferred due to its simplicity and interpretability. The discernibility matrix method is a widely used technique for computing such reducts. Despite its effectiveness, this method is computationally intensive and classified as NP-hard, limiting its scalability for datasets where discernibility matrix computation becomes infeasible. This study addresses the limitations of traditional discernibility matrix-based approaches by introducing a novel method that combines a Breadth-First Search control strategy with an incremental approach to compute the absorbed discernibility matrix. The Breadth First Search strategy enables efficient exploration of the search space to identify the shortest optimal reduct early, while the incremental absorbed discernibility matrix enhances the computational scalability of the algorithm. To validate the proposed method, an experimental evaluation was conducted against two state-of-the-art algorithms: Breadth-First Search, representing the discernibility matrix-based strategy, and MinReduct, a benchmark for absorbed discernibility matrix-based approaches. Results demonstrate superior computational performance and earlier discovery of shortest reducts without compromising correctness or optimality.},
  archive      = {J_ISCI},
  author       = {G.Y. Phani Kumar and Abhimanyu Bar and P.S.V.S. Sai Prasad},
  doi          = {10.1016/j.ins.2025.122692},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122692},
  shortjournal = {Inf. Sci.},
  title        = {A novel approach for shortest optimal reduct computation},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Existence of nash equilibrium in single-leader multiple-follower games with min-max interval payoffs. <em>ISCI</em>, <em>723</em>, 122691. (<a href='https://doi.org/10.1016/j.ins.2025.122691'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In decision-making problems with hierarchical structures, leader–follower games are highly prevalent. As a core concept in game theory, the existence of Nash equilibrium is crucial. However, in reality, complex uncertainties often lead to imprecise game outcomes, and interval representations are an effective tool for capturing such uncertainties. To address the issue of imprecise payoffs in complex environments, this paper proposes the concept of min-max interval (for short, MMI) and studies the existence of Nash equilibrium in single-leader multiple-follower (for short, SLMF) games with MMI payoffs. MMI is an appropriate extension of the traditional interval-providing a more flexible tool for representing uncertain payoffs. We propose an MMI expected payoff ranking method to address the issue of players ranking MMIs. Based on this, operational rules for MMIs and concepts such as limits, continuity, and concavity of MMI-valued functions (for short, MIVFs) are defined. After extending key theorems of real-valued functions to the case of MIVFs, we combine these extended theorems with set-valued mapping theory and Kakutani’s fixed point theorem to prove the existence of Nash equilibrium in SLMF MMI-valued games. Additionally, we compare existing works to verify the innovativeness of the proposed method and provide numerical examples to demonstrate its applicability.},
  archive      = {J_ISCI},
  author       = {Daping Zhang and Yanlong Yang and Xicai Deng},
  doi          = {10.1016/j.ins.2025.122691},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122691},
  shortjournal = {Inf. Sci.},
  title        = {Existence of nash equilibrium in single-leader multiple-follower games with min-max interval payoffs},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Data stream clustering via fuzzy similarity and diffusion-enhanced contextual affinity. <em>ISCI</em>, <em>723</em>, 122690. (<a href='https://doi.org/10.1016/j.ins.2025.122690'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data stream clustering provides an effective method for recognizing underlying patterns in potentially unbounded sequences of data objects. Existing data stream clustering methods primarily encounter two key issues: (1) the inadequate evaluation of relationships between data objects within fixed-size landmark windows, leading to degraded clustering quality; and (2) the absence of efficient mechanisms for transferring useful knowledge from previous windows to the current window, weakening the model’s adaptability to data stream evolution. To address these issues, a data stream clustering method based on axiomatic fuzzy set theory via a diffusion process is first proposed. First, the proposed method employs axiomatic fuzzy set theory to measure the relationships between data objects within the window, capturing similarity information to more accurately reveal the underlying data distribution. Second, an efficient diffusion process enhances pairwise affinities through contextual propagation, which significantly improves connectivity within clusters. Finally, the learned affinity matrix is applied to spectral clustering for data stream clustering. Over time, we update the dynamic set according to the distance between data objects and cluster centers. This dynamic set retains representative data objects and effectively transfers previously learned knowledge to the current landmark window. Experimental results on four datasets and seven algorithms demonstrate the effectiveness and robustness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Yao Li and Ming Chi and Wei Lu and Xiaodong Liu and Witold Pedrycz},
  doi          = {10.1016/j.ins.2025.122690},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122690},
  shortjournal = {Inf. Sci.},
  title        = {Data stream clustering via fuzzy similarity and diffusion-enhanced contextual affinity},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Large language model assisted hierarchical reinforcement learning training. <em>ISCI</em>, <em>723</em>, 122688. (<a href='https://doi.org/10.1016/j.ins.2025.122688'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional reinforcement learning (RL) cannot solve complex long-sequence decision tasks, especially when the environment rewards are sparse. Large language models (LLMs) can perform well in long-sequence decision tasks by leveraging their powerful inference capabilities. Although LLMs possess a large amount of general knowledge, LLM-based agents lack expertise in solving specific target problems. Considering that reinforcement learning models are smaller than LLMs and can be trained specifically to perform well on specific tasks, this paper proposes a hierarchical reinforcement learning framework assisted by a large language model, called LLMHRL. In this framework, the LLM acts as a teacher agent to guide the exploration of high-level policy in hierarchical reinforcement learning. The low-level policy consists of a library of selection-based policies. The agent executes specific actions based on the low-level policy chosen by the high-level policy. Furthermore, to reduce the action space of high-level policy, this paper decomposes it into skill options and target options. The two types of options are combined to obtain a high-level policy. This paper evaluates LLMHRL against baseline methods using both public and custom-built harder tasks across three environments: MiniGrid for key-door pairing, ManiSkill for tabletop sorting, and real-world scenarios. The results show that LLMHRL outperforms existing methods in success rate, convergence speed, and average return.},
  archive      = {J_ISCI},
  author       = {Qianxi Li and Bao Pang and Yong Song and Hongze Fu and Qingyang Xu and Xianfeng Yuan and Xiaolong Xu and Chengjin Zhang},
  doi          = {10.1016/j.ins.2025.122688},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122688},
  shortjournal = {Inf. Sci.},
  title        = {Large language model assisted hierarchical reinforcement learning training},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A relation classification and aggregation algorithm for bipartite-type multi-relational heterogeneous graphs. <em>ISCI</em>, <em>723</em>, 122687. (<a href='https://doi.org/10.1016/j.ins.2025.122687'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Heterogeneous Graph Neural Networks (HGNNs) are multi-oriented and single-relational heterogeneous graphs, and cannot effectively function on Bipartite-type Multi-relational Heterogeneous Graphs (BMHGs) with multiple relationships. At the same time, existing meta-path-based HGNNs cannot fully consider the differences between meta-paths during the aggregation process, and this difference is even more prominent in BMHGs. The main manifestation is that the number of neighbor nodes connected by various meta-relation paths differs significantly, causing some paths to carry too much noise information, which affects the algorithm performance. In order to solve the problem of the complex relationships in BMHG and the significant disparity in the number of neighbors between paths, this paper proposes a Relation Classification and Aggregation Algorithm for Bipartite-type Multi-Relational Heterogeneous Graphs (RCAA-BMHG). The RCAA-BMHG algorithm consists of three modules: the same-type aggregation module, the across-type aggregation module, and the cross-category feature aggregation layer, which perform differentiated processing of different types of association information between nodes in a Bipartite-type Multi-relational Heterogeneous Graph. Specifically, the same-type aggregation module first introduces a same-type node association filter to distinguish between the densely coupled path and the sparsely coupled path, and then uses a global average strategy and an adaptive weight allocation method to aggregate the information of the two types of coupled paths. The across-type aggregation module is filtered by an across-type node association filter, and then the weighted sum mechanism and the neighborhood feature propagation technology are used to aggregate the information of the two types of coupled paths. Finally, RCAA-BMHG uses a category-level attention mechanism to fuse the semantic and feature information of the same and cross types to generate the final node embedding for downstream tasks. Experimental verification shows that RCAA-BMHG not only performs feature aggregation and classification tasks when processing complex heterogeneous graph data, but also shows significant advantages over existing HGNNs algorithms on multiple evaluation metrics. The complete reproducible code and data have been published at: https://github.com/Dylanwsd24/RCAA-BMHG .},
  archive      = {J_ISCI},
  author       = {Hua Duan and Shiduo Wang and Yufei Zhao and Hua Liu and Xiaotong Li},
  doi          = {10.1016/j.ins.2025.122687},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122687},
  shortjournal = {Inf. Sci.},
  title        = {A relation classification and aggregation algorithm for bipartite-type multi-relational heterogeneous graphs},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust watermarking for diffusion model generated images. <em>ISCI</em>, <em>723</em>, 122686. (<a href='https://doi.org/10.1016/j.ins.2025.122686'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the wide application of diffusion models in the field of image generation, image copyright protection and traceability have become increasingly complex and challenging. To address these problems, this paper proposes a robust watermarking method for diffusion model generated images to achieve their copyright protection and traceability. The method designs an invertible mapping module to replicate and cryptographically map the watermark information into an approximately Gaussian distributed noise, which is highly consistent with the distribution of the original generation model. The mapped watermark noise serves as the latent space vector of the generative model, preserving both image generation quality and model performance. In the watermark extraction stage, the original watermark information can be accurately recovered from the generated image through the reverse extraction and voting mechanism. Experimental results show that the proposed method demonstrates excellent performance in terms of image watermark extraction accuracy, robustness and watermark image generation quality. It can still maintain 99 % true positive rate and 97.5 % bit accuracy under various attacks, and the overall performance in the detection and traceability scenarios is significantly better than the existing baseline methods.},
  archive      = {J_ISCI},
  author       = {Ziqi Liu and Yuan Guo and Liansuo Wei},
  doi          = {10.1016/j.ins.2025.122686},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122686},
  shortjournal = {Inf. Sci.},
  title        = {Robust watermarking for diffusion model generated images},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SEAD-MGFE-net: Schrödinger equation-based adaptive dropout multi-granular feature enhancement network for conversational aspect-based sentiment quadruple analysis. <em>ISCI</em>, <em>723</em>, 122684. (<a href='https://doi.org/10.1016/j.ins.2025.122684'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research focuses on enhancing the extraction of sentiment quadruples consisting of target, aspect, opinion, and sentiment from multi-turn dialogs, which remains a challenging problem in conversational sentiment analysis. Existing methods frequently encounter challenges with complex sentence structures, presence of multiple sentiment quadruples, and interference from irrelevant contextual information. These challenges often result in suboptimal performance. These limitations are addressed by introducing Schrödinger equation-based adaptive dropout multi-granular feature enhancement network (SEAD-MGFE-Net), a novel framework that synergizes multigranular feature extraction with quantum-inspired adaptive regularization. The proposed methodology incorporates a multi-layer tree structure to segment sentences into semantically coherent fragments, thereby improving the alignment between aspect and opinion terms while simultaneously mitigating noise impact. Moreover, we engineer a multi-angle dynamic adjacency learning enhancement module that adeptly captures both local and global features inherent in graph-structured representations. Additionally, we devise an adaptive dropout mechanism based on the Schrödinger equation, facilitating automatic modulation of the regularization strength throughout training. Extensive evaluations on benchmark datasets in both Chinese and English validate the state-of-the-art effectiveness of our proposed SEAD-MGFE-Net model, achieving Micro-F1 scores of 46.53 % (Chinese) and 40.97 % (English), surpassing the strongest baseline models by 2.04 % and 1.57 %, respectively. SEAD-MGFE-Net exhibits efficacy in extracting cross-utterance quadruples and managing long-range dependencies. These findings confirm the effectiveness and broad applicability of SEAD-MGFE-Net for conversational sentiment analysis.},
  archive      = {J_ISCI},
  author       = {Wei Liu and Xiaoliang Chen and Duoqian Miao and Hongyun Zhang and Xiaolin Qin and Shangyi Du and Peng Lu},
  doi          = {10.1016/j.ins.2025.122684},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122684},
  shortjournal = {Inf. Sci.},
  title        = {SEAD-MGFE-net: Schrödinger equation-based adaptive dropout multi-granular feature enhancement network for conversational aspect-based sentiment quadruple analysis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Byzantine-resilient federated learning with dynamic scoring matrix and variant PBFT consensus under differential privacy. <em>ISCI</em>, <em>723</em>, 122682. (<a href='https://doi.org/10.1016/j.ins.2025.122682'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing concerns regarding data privacy exacerbate the challenges associated with “data silos”. Federated learning (FL) effectively addresses these issues by facilitating distributed machine learning without necessitating direct data exchange. However, the dependence on a central server in conventional FL architectures exacerbates privacy risks and limits cross-domain data sharing. Existing blockchain-based FL frameworks often employ static consensus protocols, such as classical Practical Byzantine Fault Tolerance (PBFT), which typically rely on fixed weight aggregation strategies. While these methods simplify implementation, they fail to adaptively adjust aggregation weights according to heterogeneous privacy budgets. Attempts to implement adaptive weight aggregation often require achieving consensus for each individual weight, significantly reducing efficiency and creating scalability challenges in large-scale networks. To address these gaps, we propose DSM-PBFT, a variant PBFT consensus enhanced with dynamic scoring matrices (DSM), which enables parallelized validation of multiple models while adaptively adjusting aggregation weights based on differential privacy budgets. Our noise-aware aggregation mechanism dynamically reweights models through cross-validation of accuracy, F1 score, and loss-transformed metrics, effectively decoupling privacy guarantees from model utility degradation. Security analyses affirm the robustness of this framework against Byzantine attacks, with experimental results on MNIST, FashionMNIST and CIFAR-10 demonstrating superior model accuracy across diverse privacy budgets while effectively curbing accuracy degradation under attack scenarios.},
  archive      = {J_ISCI},
  author       = {Wentai Yang and Xian Xu and Kai Yu and Guoqiang Li},
  doi          = {10.1016/j.ins.2025.122682},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122682},
  shortjournal = {Inf. Sci.},
  title        = {Byzantine-resilient federated learning with dynamic scoring matrix and variant PBFT consensus under differential privacy},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Subsequence heterogeneity contrastive learning for time series anomaly detection. <em>ISCI</em>, <em>723</em>, 122680. (<a href='https://doi.org/10.1016/j.ins.2025.122680'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection is widely applied across various real-world scenarios. Recently, contrastive learning has shown remarkable ability in learning discriminative representations for detecting anomalies. However, most existing contrastive-based methods rely on complex contrastive mechanisms and specially designed model architectures, which make it difficult to maintain efficiency and flexibility across various application scenarios. To address this limitation, we introduce Subsequence-Heterogeneity that defined as the discrepancies in variation patterns and statistical characteristics between subsequences obtained through fixed-interval sampling, which are more pronounced in anomalous sequences than in normal ones. It can serve as a natural discrimination criterion and eliminate the need for complex contrastive mechanisms and specialized model architectures. Specifically, we adopt an efficient temporal hierarchical masking strategy with linear complexity to construct two branches for learning representations at different granularities. The Subsequence-Heterogeneity Contrastive Learning (SHCL) is implemented with different neural networks and enables flexible application to anomaly detection across diverse scenarios. Experiments on eight benchmark datasets demonstrate that SHCL not only achieves state-of-the-art performance with reduced time and resource costs but also significantly improves the ability of different neural networks to distinguish normal from anomalous patterns. The source code is publicly available at https://github.com/Zhangzzbzzb/SHCL/ .},
  archive      = {J_ISCI},
  author       = {Zhibin Zhang and Xiaohong Zhang and Qiang Li and Chun Huang and Tao Yin and Meng Yan},
  doi          = {10.1016/j.ins.2025.122680},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122680},
  shortjournal = {Inf. Sci.},
  title        = {Subsequence heterogeneity contrastive learning for time series anomaly detection},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Escrow-free attribute based signature with constant-size for the internet of things. <em>ISCI</em>, <em>723</em>, 122679. (<a href='https://doi.org/10.1016/j.ins.2025.122679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute based signature (ABS) provides a promising solution for anonymous authentication. However, numerous prevailing ABS algorithms are ill-suited for anonymous authentication in the Internet of Things (IoT), due to problems such as key escrow, high computational overhead, inflexible access policies, and vulnerability to collusion attacks. Considering these shortcomings, we present an escrow-free attribute based signature with constant-size signature for IoT. Our proposal uses the linear secret-sharing scheme (LSSS) and the notion of certificateless cryptography to restrict the authorities of each attribute authority and the system authority. In addition, it generates a constant-size signature and achieves high verification efficiency by aggregating attribute keys. Theoretical analyses demonstrate that our proposal achieves anonymous authentication and is provably secure under the standard model. Simulation experiments show that the execution time of our algorithm is less than 50 ms to run during both the signature and verification phases, making it well-suited for applications with limited resources.},
  archive      = {J_ISCI},
  author       = {Xudong Liu and Xiaojun Tong and Yihui Wang},
  doi          = {10.1016/j.ins.2025.122679},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122679},
  shortjournal = {Inf. Sci.},
  title        = {Escrow-free attribute based signature with constant-size for the internet of things},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep dual contrastive learning for multi-view subspace clustering. <em>ISCI</em>, <em>723</em>, 122678. (<a href='https://doi.org/10.1016/j.ins.2025.122678'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view subspace clustering (MVSC) aims to learn a consistent shared self-representation by utilizing the consistency and complementarity of all views, numerous MVSC algorithms have attempted to obtain the optimal representation directly from raw features. However, they might overlook the noisy or redundant information in raw feature space, resulting in learning suboptimal self-representation and poor performance. To address this limitation, an intuitive idea is introducing deep neural networks to eliminate the noise and redundancy, yielding a potential embedding space. Nevertheless, existing deep MVSC methods merely focus on either the embeddings or self-expressions to explore the complementary information, which hinders subspace learning. In this paper, we present a deep multi-view dual contrastive subspace clustering framework to exploit the complementarity to learn latent self-representations effectively. Specifically, multi-view encoders are constructed to eliminate noise and redundancy of the original features and capture low-dimensional subspace embeddings, from which the self-representations are learned. Moreover, two diverse specific fusion methods are conducted on the latent subspace embeddings and the self-expressions to learn shared self-representations, and dual contrastive constraints are proposed to fully exploit the complementarity among views. Extensive experiments are conducted to verify the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Xincan Lin and Jie Lian and Zhihao Wu and Jielong Lu and Shiping Wang},
  doi          = {10.1016/j.ins.2025.122678},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122678},
  shortjournal = {Inf. Sci.},
  title        = {Deep dual contrastive learning for multi-view subspace clustering},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Parameter-free discrete clustering via adaptive hypergraph fusion. <em>ISCI</em>, <em>723</em>, 122677. (<a href='https://doi.org/10.1016/j.ins.2025.122677'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based clustering has garnered significant attention due to its outstanding performance in uncovering sample structures. However, existing graph-based methods face two major challenges: 1) In graph construction, they typically focus only on direct connections between samples or an exact high-order relationship, neglecting the impact of hidden complex relationships on clustering performance; 2) The separation of spectral analysis and category acquisition into two distinct stages often results in a loss of effectiveness. To handle these problems, we propose a parameter-free discrete clustering method, called parameter-free discrete clustering via adaptive hypergraph fusion (DCAHF). Specifically, DCAHF first produces multiple different hypergraphs, each serving as a biased approximation of the data's intrinsic manifold. These complementary approximations capture distinct local-to-global geometric patterns. Then, it introduces an adaptive fusion strategy that learns optimal weights to combine them into a single consensus hypergraph on manifold space, effectively reconstructing the real manifold structure with reduced bias and improved integrity. Finally, discrete spectral analysis is performed directly on the consensus hypergraph to generate discrete sample categories, thereby avoiding the performance loss associated with two-stage approaches. Thus, DCAHF is a high-performance, parameter-free clustering model that can flexibly adapt to various clustering tasks. Since the DCAHF model cannot be solved using gradient descent methods, we develop a coordinate descent-based optimization algorithm to efficiently solve the model. Extensive experimental results demonstrate that DCAHF significantly enhances clustering effectiveness while maintaining comparable efficiency to state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Yu Zhou and Ben Yang and Xuetao Zhang and Badong Chen},
  doi          = {10.1016/j.ins.2025.122677},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122677},
  shortjournal = {Inf. Sci.},
  title        = {Parameter-free discrete clustering via adaptive hypergraph fusion},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-branch semantic alignment for few-shot image classification. <em>ISCI</em>, <em>723</em>, 122676. (<a href='https://doi.org/10.1016/j.ins.2025.122676'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable progress of deep learning in computer vision has significantly stimulated research interest in few-shot image classification. This field aims to transfer knowledge from previous experiences to recognize new concepts with limited samples. However, most existing approaches primarily concentrate on aligning semantic information at high-level features, neglecting the importance of middle-level or low-level feature representations. In this paper, we propose a novel approach called Multi-Branch Semantic Alignment (MBSA) for few-shot image classification, with the objective of investigating the role of multi-level features. Instead of using standard convolutional layers, we employ diverse convolutional layers to generate enhanced representations in each branch. These representations are then utilized by a dense classifier, which is supervised by a powerful guidance mechanism to incorporate semantic information into their spatial locations. During the inference stage, the multi-branch semantic alignment is designed to align multi-level features between query images and support images. This alignment process effectively establishes semantic correspondences between representations at different levels, thereby enhancing the ability to recognize novel categories. Comprehensive experiments are conducted on various few-shot benchmarks to demonstrate the superiority of our approach compared to those of several previous approaches, and ablation studies are performed to analyze the impact of different components.},
  archive      = {J_ISCI},
  author       = {Zijun Zheng and Heng Wu and Laishui Lv and Changchun Zhang and Hongcheng Guo and Shanzhou Niu and Gaohang Yu},
  doi          = {10.1016/j.ins.2025.122676},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122676},
  shortjournal = {Inf. Sci.},
  title        = {Multi-branch semantic alignment for few-shot image classification},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Partition-based differentially private synthetic data generation. <em>ISCI</em>, <em>723</em>, 122675. (<a href='https://doi.org/10.1016/j.ins.2025.122675'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Private synthetic data sharing is beneficial as it better retains the distribution and nuances of the original data compared to summary statistics such as means and frequencies. Current state-of-the-art methods follow a select-measure-generate paradigm, but measuring large-domain marginals often leads to significant errors, and managing the privacy budget poses challenges. Our partition-based approach addresses these issues, effectively reducing errors and improving the quality of synthetic data, even with a limited privacy budget. Experimental results show that our method outperforms existing approaches, yielding synthetic data with enhanced quality and utility, making it a preferred option for private data sharing.},
  archive      = {J_ISCI},
  author       = {Meifan Zhang and Dihang Deng and Lihua Yin},
  doi          = {10.1016/j.ins.2025.122675},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122675},
  shortjournal = {Inf. Sci.},
  title        = {Partition-based differentially private synthetic data generation},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Transferable adversarial attacks on human pose estimation: A regularization and pruning framework. <em>ISCI</em>, <em>723</em>, 122674. (<a href='https://doi.org/10.1016/j.ins.2025.122674'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Pose Estimation (HPE) is a core component in real-time decision systems, supporting critical applications such as healthcare monitoring, autonomous driving, and sports analytics. While deep learning models—particularly CNNs and Transformer-based architectures—have significantly improved HPE accuracy, they remain vulnerable to adversarial perturbations that subtly distort keypoint localization, thereby undermining system reliability. To address this challenge, we propose regularization and pruning transferable adversarial attack (RPA), a novel framework designed to enhance the transferability of adversarial samples in Transformer-based HPE models. RPA integrates two synergistic strategies: gradient regularization, which suppresses dominant feature correlations to reduce overfitting, and adaptive weight pruning, which removes redundant parameters to reduce model-specific noise. This dual mechanism enables the generation of transferable adversarial attacks that are effective across diverse model architectures. Extensive experiments on state-of-the-art HPE networks demonstrate that RPA consistently outperforms existing attack methods. In white-box settings, RPA reduces average precision (AP) by 0.05-0.30; in black-box scenarios, it yields AP drops of 0.01-0.04. These findings expose critical vulnerabilities in IoT-enabled HPE applications and establish a new benchmark for evaluating adversarial robustness in real-time perception systems.},
  archive      = {J_ISCI},
  author       = {Renguang Chen and Xuechao Yang and Xun Yi and Zhide Chen and Chen Feng and Xu Yang and Kexin Zhu and Iqbal Gondal},
  doi          = {10.1016/j.ins.2025.122674},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122674},
  shortjournal = {Inf. Sci.},
  title        = {Transferable adversarial attacks on human pose estimation: A regularization and pruning framework},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CF2M-net: Cross-feature fusion and memory-constraint network for video anomaly detection. <em>ISCI</em>, <em>723</em>, 122673. (<a href='https://doi.org/10.1016/j.ins.2025.122673'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection (VAD) aims to automatically identify anomalous events in surveillance videos that are significantly different from the normal pattern. Most existing methods learn the spatial-temporal distribution of normal features and detect deviations as anomalies. Typically, they employ autoencoders to independently learn appearance and motion features, but this separate learning limits the exploitation of their interrelation in real-world scenarios. To enhance the representation of normal patterns by capturing feature interrelation, we propose a cross-feature fusion and memory-constraint network (CF 2 M-Net) for VAD. Specifically, inspired by the representational ability of cross-attention in multimodal fusion, we design a cross-attention and memory-constraint (CM) module to enrich appearance features with motion information. To prevent overfitting to anomalous events, the memory-constraint module further constrains fused features within the distribution of normal patterns. We design an attention fusion (AF) decoder to predict normal features closer to the normal distribution, enhancing their separability from anomalies. By jointly modeling appearance and motion through feature fusion and memory constraints, CF 2 M-Net provides more discriminative normal representations for anomaly detection. Experimental evaluations on three benchmark datasets show that the CF 2 M-Net performs comparably with leading approaches. Moreover, the detailed evaluations indicate the effectiveness of normal representation based appearance-motion fusion features for VAD.},
  archive      = {J_ISCI},
  author       = {Qiming Ma and Chengyou Wang and Xiao Zhou},
  doi          = {10.1016/j.ins.2025.122673},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122673},
  shortjournal = {Inf. Sci.},
  title        = {CF2M-net: Cross-feature fusion and memory-constraint network for video anomaly detection},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Distributed data-driven event-triggered secure consensus control of MASs: A global preset-time performance constraint method. <em>ISCI</em>, <em>723</em>, 122672. (<a href='https://doi.org/10.1016/j.ins.2025.122672'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the distributed data-driven event-triggered secure consensus control issue for model-free multi-agent systems (MASs) under sensor faults and denial-of-service (DoS) attacks, while satisfying prescribed performance constraints. First, a global preset-time performance function (PTPF) is constructed to guarantee the global stability of model-free MASs within the preset time. The proposed PTPF ensures that the preset time remains unaffected by variations in the sampling period. Second, a proportional-integral-derivative (PID) sliding surface is designed to enhance MAS performance regulation, while a novel generalized fuzzy hyperbolic model (GFHM) is constructed to eliminate the dependency on fault information and achieve high-accuracy estimation of unknown fault signals. Third, a hybrid event-triggered mechanism integrating both dynamic and memory features is developed to optimize communication resource utilization while guaranteeing robust performance at extremes. Furthermore, an event-triggered secure control scheme leveraging the memory feature is proposed to reduce communication overhead while avoiding the dangerous open-loop scenario, where control inputs must be zeroed under DoS attacks as in the existing methods. Finally, the stability proof together with simulations confirms the feasibility of the control strategy.},
  archive      = {J_ISCI},
  author       = {Run-Ze Chen and Xiang-Gui Guo and Yuan-Xin Li},
  doi          = {10.1016/j.ins.2025.122672},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122672},
  shortjournal = {Inf. Sci.},
  title        = {Distributed data-driven event-triggered secure consensus control of MASs: A global preset-time performance constraint method},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MPCMO: An improved multi-population co-evolutionary algorithm for many-objective optimization. <em>ISCI</em>, <em>723</em>, 122671. (<a href='https://doi.org/10.1016/j.ins.2025.122671'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-objective optimization problems (MaOPs) are widely used in scientific research and engineering practices, which mainly consider joint optimization of multiple objectives simultaneously. Despite the numerous multi-objective evolutionary algorithms proposed in recent years, they often struggle with challenges in fitness assignment arising from objective conflicts. Meanwhile, they tend to perform well in only one aspect of convergence, diversity, and computational complexity. To address these issues, this paper proposes an improved multi-population co-evolutionary algorithm for many-objective optimization (termed MPCMO), which leverages the advantages of multi-population co-evolutionary techniques. The primary objective of MPCMO is to achieve a more balanced performance across convergence, diversity, and complexity. MPCMO comprises three essential components. Initially, an adaptive evolutionary strategy is employed to dynamically allocate evolutionary opportunities to subpopulations so as to conserve computational resources and enhance convergence. Subsequently, a migration strategy is developed to ensure a more global approximation of whole Pareto front. Additionally, an archive update-truncation strategy, based on angle selection and shift-based density estimation, is adopted to enhance diversity. We conduct comprehensive comparative experiments on a variety of many-objective benchmark problems with complicated characteristics. Experimental results demonstrate that the proposed method outperforms existing state-of-the-art algorithms in terms of both diversity and convergence.},
  archive      = {J_ISCI},
  author       = {Weichao Ding and Jiahao Liu and Wenbo Dong and Fei Luo and Chunhua Gu},
  doi          = {10.1016/j.ins.2025.122671},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122671},
  shortjournal = {Inf. Sci.},
  title        = {MPCMO: An improved multi-population co-evolutionary algorithm for many-objective optimization},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reinforced heterogeneous graphlet design for knowledge graph representation learning. <em>ISCI</em>, <em>723</em>, 122670. (<a href='https://doi.org/10.1016/j.ins.2025.122670'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) are practical tools that represent and integrate plentiful structural and semantic information in mainstream industrial scenarios. Despite their potential, the heterogeneity and complexity of KGs pose a formidable obstacle, especially for graph representation learning. Most existing KG embedding models omit dynamic high-order connectivity patterns to gain insights into heterogeneous networks and heavily rely on handcrafted patterns to handle complex semantic relationships, which limits their capability to adaptively capture the nuanced and intricate relationships of KGs in different tasks. To fill this gap, we present Reinforced Heterogeneous Graphlet Design (ReHGD)—a model designed for KGs that focuses on the adaptive design of typed graphlets (heterogeneous chains and motifs) through a cooperative multi-agent reinforcement learning algorithm. This task-driven approach can learn discriminative graph representations tailored to specific downstream tasks. Specifically, ReHGD engages in the creation of typed graphlets through a two-stage process: it (1) establishes a reinforced chain design module to generate chains without predefined rules and (2) employs a buffer-aware sampling technique to derive episodic chains from prior experiences. Subsequently, motifs are deduced through the application of commute count and Hadamard product operations to the episodic chain-based subgraphs. In the final step toward learning graph representations, ReHGD undertakes chain and motif aggregations. Experimental results and analyses reveal that ReHGD outperforms strong baselines on three real-world graph data and practical tasks.},
  archive      = {J_ISCI},
  author       = {Jibing Gong and Yuting Lin and Yi Zhao and Tianyu Lin and Xiaohan Fang and Xinchao Feng and Jiquan Peng},
  doi          = {10.1016/j.ins.2025.122670},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122670},
  shortjournal = {Inf. Sci.},
  title        = {Reinforced heterogeneous graphlet design for knowledge graph representation learning},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatio-frequency texture analysis using wavelet increment entropy: Methodology and application to MRI in multiple sclerosis. <em>ISCI</em>, <em>723</em>, 122669. (<a href='https://doi.org/10.1016/j.ins.2025.122669'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Texture analysis is crucial for understanding images by extracting features that define spatial patterns. Recently, bi-dimensional extensions of entropy measures have gained attention due to their simplicity and strong theoretical foundations. However, existing methods primarily operate in the spatial domain and thus overlook frequency-domain and multiscale information. To address this, we introduce bidimensional wavelet increment entropy (wavelet IncrEn 2 D ). A one-level discrete wavelet transform (DWT) with the Haar wavelet decomposes each image into approximation (low-frequency) and, for some neuroimaging data, detail (high-frequency) subbands; IncrEn 2 D is then applied both to capture global structural patterns and fine, detailed texture variations. We evaluated wavelet IncrEn 2 D on synthetic and real datasets, demonstrating its effectiveness in distinguishing between different noise types (white Gaussian, salt-and-pepper, and speckle noise). Comparisons between periodic and synthesized images revealed lower wavelet IncrEn 2 D values for periodic textures. Tests on real texture datasets highlight the method's ability to differentiate various patterns. In particular, wavelet IncrEn 2 D achieved 86.69% accuracy in distinguishing MRI images of healthy versus multiple sclerosis–affected brains. Overall, wavelet IncrEn 2 D offers a robust, frequency-aware descriptor that outperforms existing 2D entropy methods.},
  archive      = {J_ISCI},
  author       = {Muqaddas Abid and Muhammad Suzuri Hitam and Rozniza Ali and Hamed Azami and Anne Humeau-Heurtier},
  doi          = {10.1016/j.ins.2025.122669},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122669},
  shortjournal = {Inf. Sci.},
  title        = {Spatio-frequency texture analysis using wavelet increment entropy: Methodology and application to MRI in multiple sclerosis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved query specialization for transformer-based visual relationship detection. <em>ISCI</em>, <em>723</em>, 122668. (<a href='https://doi.org/10.1016/j.ins.2025.122668'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Relationship Detection (VRD) has significantly advanced with Transformer-based architectures. However, we identify two fundamental drawbacks in conventional label assignment methods used for training Transformer-based VRD models, where ground-truth (GT) annotations are matched to model predictions. In conventional assignment, queries are trained to detect all relations rather than specializing in specific ones, resulting in ‘unspecialized’ queries. Also, each ground-truth (GT) annotation is assigned to only one prediction under conventional assignment, suppressing other near-correct predictions by labeling them as ‘no relation’. To address these issues, we introduce a novel method called Groupwise Query Spe ci a lization and Q uality-Aware Multi-Assignment (SpeaQ). Groupwise Query Specialization clusters queries and relations into exclusive groups, promoting specialization by assigning a set of relations only to a corresponding query group. Quality-Aware Multi-Assignment enhances training signals by allowing multiple predictions closely matching the GT to be positively assigned. Additionally, we introduce dynamic query reallocation, which transfers queries from high- to low-performing groups for balanced training. Experimental results demonstrate that SpeaQ+, combining SpeaQ with dynamic query reallocation, consistently improves performance across seven baseline models on five benchmarks without additional inference cost.},
  archive      = {J_ISCI},
  author       = {Jongha Kim and Jihwan Park and Jinyoung Park and Jinyoung Kim and Sehyung Kim and Hyunwoo J. Kim},
  doi          = {10.1016/j.ins.2025.122668},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122668},
  shortjournal = {Inf. Sci.},
  title        = {Improved query specialization for transformer-based visual relationship detection},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ConvDiff: Multi-scale spatio-temporal convolutional networks with latent diffusion models for dynamic system modeling. <em>ISCI</em>, <em>723</em>, 122656. (<a href='https://doi.org/10.1016/j.ins.2025.122656'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modeling of spatio-temporal dynamic systems, tasks such as fluid dynamics, weather forecasting, and traffic flow prediction face highly complex spatio-temporal dependencies and nonlinear dynamics. These characteristics make it challenging for traditional physical models and data-driven methods to balance accuracy and computational efficiency. To address these challenges, we propose a multi-scale spatio-temporal convolutional network named ConvDiff, optimized specifically for dynamic system modeling tasks by integrating a latent space denoising diffusion model. ConvDiff effectively captures complex spatio-temporal features and handles uncertainties in physical systems by introducing multi-scale convolutional modules combined with a physics-guided diffusion mechanism. Specifically, our model incorporates eight temporal modules and four spatial modules, using a hierarchical convolutional and diffusion structure to capture the intricate dynamics of physical systems. The experiments involved different spatio-temporal data, such as those from TaxiBJ and the Navier-Stokes dataset. According to the findings, ConvDiff demonstrates substantial improvements in essential performance indicators. For example, in the TaxiBJ dataset, ConvDiff obtained a mean squared deviation of 0.29 and a PSNR value of 40.31, outperforming the best-performing models. Moreover, on the Navier-Stokes dataset, ConvDiff reduced the MSE by 51.15% compared to the best baseline model. These results indicate that ConvDiff effectively captures complex spatio-temporal dependencies and improves prediction accuracy, particularly in physics-driven dynamic systems. Our code is available at https://github.com/Ray-zyy/ConvDiff .},
  archive      = {J_ISCI},
  author       = {Yuyang Zhao and Yuhan Wu and Yongmei Wang},
  doi          = {10.1016/j.ins.2025.122656},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122656},
  shortjournal = {Inf. Sci.},
  title        = {ConvDiff: Multi-scale spatio-temporal convolutional networks with latent diffusion models for dynamic system modeling},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A semi-heterogeneous ensemble forecasting method for stock returns based on sentiment analysis. <em>ISCI</em>, <em>723</em>, 122655. (<a href='https://doi.org/10.1016/j.ins.2025.122655'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing influence of investor sentiment on market dynamics, sentiment analysis has emerged as an effective tool for enhancing financial forecasting models. This study proposes a diversity-enhanced semi-heterogeneous ensemble forecasting framework that integrates sentiment analysis into the forecasting of stock index returns. A supervised stock market sentiment index set is constructed, in which prior knowledge regarding term importance is integrated into the data augmentation process. This enables higher weights to be assigned to sentiment-related terms with superior predictive capacity, thereby allowing the model to prioritize more informative features and enhance its forecasting performance. A series of diverse base models are generated through the integration of multiple attention-PCA techniques and forecasting algorithms based on variable perturbation strategies. These base models are subsequently combined through a suite of ensemble strategies, forming a semi-heterogeneous ensemble model for forecasting S&P 500 returns. The experiment results demonstrate that the proposed approaches significantly outperform benchmark methods, with notable improvements in both accuracy and diversity.},
  archive      = {J_ISCI},
  author       = {Xiao Zhang and Peide Liu and Jing Feng},
  doi          = {10.1016/j.ins.2025.122655},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122655},
  shortjournal = {Inf. Sci.},
  title        = {A semi-heterogeneous ensemble forecasting method for stock returns based on sentiment analysis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Energy-related controllability of corona product networks. <em>ISCI</em>, <em>723</em>, 122654. (<a href='https://doi.org/10.1016/j.ins.2025.122654'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the energy-related controllability for a category of ‘large’ composite networks generated by ‘small’ simple factor networks with Laplacian dynamics under a leader-follower framework via corona product. Different from most existing literature on network controllability, this work characterizes the controllability of corona product networks (CPNs) from an energy point of view. This can quantify the difficulty of controlling CPNs based on controllability Gramian measures, involving average controllability and volumetric control energy, etc., where the energy is triggered by the leaders. The energy-related controllability of a CPN can be explored from the eigenvalues and eigenvectors of its factor networks. An algorithm for solving the maximum average controllability is provided, which can help one select the leaders to optimize network control and be applied in practice.},
  archive      = {J_ISCI},
  author       = {Qiang Zhang and Junjie Huang and Bo Liu and Housheng Su and Alatancang Chen},
  doi          = {10.1016/j.ins.2025.122654},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122654},
  shortjournal = {Inf. Sci.},
  title        = {Energy-related controllability of corona product networks},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SeqRFM: Fast RFM analysis in sequence data. <em>ISCI</em>, <em>723</em>, 122652. (<a href='https://doi.org/10.1016/j.ins.2025.122652'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, data mining technologies have been well applied to many domains, including e-commerce. In customer relationship management (CRM), the Recency-Frequency-Monetary (RFM) analysis model is one of the most effective approaches to increase the profits of major enterprises. However, with the rapid development of e-commerce, the diversity and abundance of e-commerce data pose a challenge to mining efficiency. Moreover, in actual market transactions, the chronological order of transactions reflects customer behavior and preferences. To address these challenges, we develop an effective algorithm called SeqRFM, which combines sequential pattern mining with RFM models. SeqRFM considers each customer's R, F, and M scores to represent the significance of the customer and identifies sequences with high recency, high frequency, and high monetary value. A series of experiments demonstrates the superiority and effectiveness of the SeqRFM algorithm compared to the most advanced RFM algorithms based on sequential pattern mining. Moreover, another algorithm named MSeqRFM is developed to compress the result of SeqRFM. The experiments demonstrate the effectiveness of MSeqRFM in compressing sequences. The source code and datasets are available at GitHub https://github.com/DSI-Lab1/SeqRFM .},
  archive      = {J_ISCI},
  author       = {Yanxin Zheng and Wensheng Gan and Zefeng Chen and Pinlyu Zhou and Philippe Fournier-Viger},
  doi          = {10.1016/j.ins.2025.122652},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122652},
  shortjournal = {Inf. Sci.},
  title        = {SeqRFM: Fast RFM analysis in sequence data},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic event-triggered finite-time actor-critic-identifier-based approximate optimal control for unknown nonlinear drifted systems. <em>ISCI</em>, <em>723</em>, 122651. (<a href='https://doi.org/10.1016/j.ins.2025.122651'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a finite-time dynamic event-triggered actor-critic-identifier (FT-DET-ACI) framework for the optimal control problem of nonlinear systems with uncertain drift dynamics. A theoretical foundation is established by reformulating the value function within a finite-time stable space, which facilitates system state stabilization within predetermined temporal constraints. The proposed approach derives finite-time optimal controllers through a transformed Hamilton-Jacobi-Bellman (HJB) equation. To address unknown system dynamics, an integrated actor-critic-identifier architecture is constructed to concurrently approximate the value function, synthesize the finite-time optimal controller, and identify system parameters. A dynamic event-triggering rule is designed to reduce computational and communication loads by selectively updating the control signal. Lyapunov stability analysis is provided to demonstrate the finite-time convergence properties of the closed-loop system. Numerical experiments are conducted to validate the efficacy of the proposed FT-DET-ACI methodology.},
  archive      = {J_ISCI},
  author       = {Shuangsi Xue and Junkai Tan and Zihang Guo and Qingshu Guan and Hui Cao and Badong Chen},
  doi          = {10.1016/j.ins.2025.122651},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122651},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic event-triggered finite-time actor-critic-identifier-based approximate optimal control for unknown nonlinear drifted systems},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Set membership filter with nonlinear state inequality constraints. <em>ISCI</em>, <em>723</em>, 122650. (<a href='https://doi.org/10.1016/j.ins.2025.122650'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Set membership filter is a promising method to provide a bounding estimation containing the true state for dynamic systems with unknown but bounded noises. In this paper, we investigate the state bounding estimation problem of nonlinear dynamic systems with nonlinear state inequality constraints. Three types of ellipsoidal state bounding estimation methods are proposed by incorporating nonlinear state inequality constraints into nonlinear set membership filter. They are called model reduction method, system measurement method, and constraint dimension reduction method, respectively. We analyze the computation complexity of the three methods, which decrease in the order of model reduction method, system measurement method, and constraint dimension reduction method. Due to the nonlinearity of the dynamic systems, all the three methods are approximation algorithms and the state estimation accuracy cannot be analyzed explicitly. Consequently, a typical illustrative numerical experiment is conducted to compare the performance of the three methods. The results show that the accuracy increases in the order of the model reduction method, the constraint dimension reduction method, and the system measurement method.},
  archive      = {J_ISCI},
  author       = {Xiaowei Li and Xuqi Zhang and Zhiguo Wang and Xiaojing Shen},
  doi          = {10.1016/j.ins.2025.122650},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122650},
  shortjournal = {Inf. Sci.},
  title        = {Set membership filter with nonlinear state inequality constraints},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Bi-objective optimization for electric vehicle scheduling under vehicle-to-grid integration. <em>ISCI</em>, <em>723</em>, 122649. (<a href='https://doi.org/10.1016/j.ins.2025.122649'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle-to-grid (V2G) technology leverages the distributed energy-storage potential of electric vehicles (EVs), transforming the challenges of large-scale EV integration into opportunities to enhance grid flexibility and reliability. This study investigates the optimization of EV charging-discharging schedules by exploiting V2G capabilities. First, considering the spatiotemporal distribution of EVs, a Markov chain is constructed to describe probabilistic transitions between spatiotemporal states, which is then embedded in a traffic-network-based path decision model. Second, a dynamic battery energy consumption model is established, incorporating multiple factors that influence battery performance. Using Monte Carlo simulation results, a bi-objective optimization model is formulated to schedule charging and discharging, simultaneously minimizing (i) total cost — including user recharging time and battery degradation — and (ii) grid-load fluctuation. Given the NP-hard nature of the problem, an improved multi-objective bitterling fish optimization (IMOBFO) algorithm is developed to balance global exploration and local exploitation. Empirical studies in a region of Shanghai compare three strategies: disordered charging, ordered charging, and the proposed optimized charging–discharging strategy. Experimental results confirm the feasibility of the proposed model and the effectiveness of IMOBFO. Comparative analysis with seven other algorithms further validates the superior performance and stability of IMOBFO according to multiple multi-objective evaluation metrics.},
  archive      = {J_ISCI},
  author       = {Bing Yu and Yong Liu and Liang Ma},
  doi          = {10.1016/j.ins.2025.122649},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122649},
  shortjournal = {Inf. Sci.},
  title        = {Bi-objective optimization for electric vehicle scheduling under vehicle-to-grid integration},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unified graph-based framework for visual explainability in convolutional neural networks. <em>ISCI</em>, <em>723</em>, 122648. (<a href='https://doi.org/10.1016/j.ins.2025.122648'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In deep learning, understanding the decision-making processes of complex models is essential for advancing interpretability and trust in artificial intelligence systems. We introduce Causal Relational Attribution Graph (C-RAG), designed to deliver comprehensive, multi-perspective explanations of convolutional neural networks (CNNs) via a graph representation. C-RAG integrates gradient-based local attribution with global feature importance by constructing a graph-based representation that captures hierarchical feature inter-dependencies. In this framework, feature clusters are represented as graph nodes, and their interactions are quantified through combined localized and global attribution metrics, ensuring interpretable insights into model behavior. We evaluate C-RAG across diverse benchmark datasets (ImageNet, CIFAR-10, MNIST) and CNN architectures (ResNet18, VGG19, DenseNet201, LeNet), demonstrating significant advancements over state-of-the-art explainability methods in faithfulness, robustness, and computational efficiency. The proposed approach facilitates accurate spatial feature localization, robust dependency mapping, and efficient explanation generation, making it a valuable tool for critical applications such as medical imaging and autonomous systems. We provide a novel graph-based explainability framework, which bridges the gap between local and global interpretability, C-RAG addresses key limitations in existing methods, establishing a robust foundation for explainable AI in computer vision.},
  archive      = {J_ISCI},
  author       = {Basim Azam and Pubudu Sanjeewani and Brijesh Verma and Ashfaqur Rahman and Lipo Wang},
  doi          = {10.1016/j.ins.2025.122648},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122648},
  shortjournal = {Inf. Sci.},
  title        = {Unified graph-based framework for visual explainability in convolutional neural networks},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention-based spatial-temporal interactive couple neural networks for multivariate time series forecasting. <em>ISCI</em>, <em>723</em>, 122647. (<a href='https://doi.org/10.1016/j.ins.2025.122647'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series forecasting (MTSF) has been a significant research focus across various domains. Recent studies have utilized deep neural networks to identify pattern relationships in MTSF. Despite these developments, accurately forecasting multivariate time series remains challenging due to the trend of time series and spatial-temporal heterogeneity. In this paper, we propose a unified multivariate time series forecasting framework for long-term, short-term, and spatial-temporal forecasting with attention-based spatial-temporal interactive coupled neural networks (ASTIC). Specifically, we proposed a spatial-temporal interactive couple block that contains both temporal and spatial branches to investigate the relationships between global and local patterns in temporal and spatial perspectives. In the temporal branch, we design a hybrid network module capable of enhancing representation learning using convolution and attention mechanisms, which dynamically capture the local trendiness and long-term time dependence implicit in time series. In the spatial branch, a novel dynamic graph learners are designed to learn global and local spatial patterns. Then a novel interactive coupling method is proposed to link the two branches together. ASTIC predicts time series effectively by using a multilevel structure to model the trendiness of the series and mining the spatial-temporal heterogeneity. Experimental results show that our method outperforms state-of-the-art baseline methods on nine real-world datasets.},
  archive      = {J_ISCI},
  author       = {Bingsheng Wei and Yonghua Hei and Yuan Wan},
  doi          = {10.1016/j.ins.2025.122647},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122647},
  shortjournal = {Inf. Sci.},
  title        = {Attention-based spatial-temporal interactive couple neural networks for multivariate time series forecasting},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). New solutions based on the generalized eigenvalue problem for the data collaboration analysis. <em>ISCI</em>, <em>723</em>, 122642. (<a href='https://doi.org/10.1016/j.ins.2025.122642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the data collaboration (DC) analysis, a privacy-preserving method for analyzing decentralized datasets held by multiple parties. In this method, privacy-preserving intermediate representations of original datasets are collected from multiple parties and then converted into collaboration representations for collaborative data analysis. However, conventional methods for creating collaboration representations suffer from several challenges; namely, the optimization problem being considered is not well defined, and the process of solving it is very difficult to understand. We thus propose a new solution for creating high-quality collaboration representations for the DC analysis. Specifically, we formulate a revised optimization problem for creating collaboration representations and then transform this optimization problem into a generalized eigenvalue problem. We also propose a reduction of the generalized eigenvalue problem to a singular value decomposition through the QR decomposition. Computational experiments using publicly available datasets demonstrate that our method can outperform the conventional methods for the DC analysis in terms of both prediction accuracy and computational efficiency.},
  archive      = {J_ISCI},
  author       = {Yuta Kawakami and Yuichi Takano and Akira Imakura},
  doi          = {10.1016/j.ins.2025.122642},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122642},
  shortjournal = {Inf. Sci.},
  title        = {New solutions based on the generalized eigenvalue problem for the data collaboration analysis},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Interpretable, multidimensional evaluation framework for causal discovery from observational i.i.d. data. <em>ISCI</em>, <em>723</em>, 122641. (<a href='https://doi.org/10.1016/j.ins.2025.122641'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear causal discovery from observational data imposes strict identifiability assumptions on the formulation of structural equations utilized in the data-generating process. However, in real-life settings, the ground-truth mechanism responsible for cause-effect transformations is unknown. Thus, it is impossible to verify its identifiability. This is the first research to assess the performance of structure learning algorithms from seven different families in non-identifiable settings with an increasing degree of nonlinearity. The evaluation of structure learning methods under assumption violations requires a rigorous and interpretable approach that quantifies both the structural similarity of the estimation with the ground truth and the capacity of the discovered graphs to be used for causal inference. Motivated by the lack of a unified performance assessment indicator, we propose an interpretable, multidimensional evaluation framework, specifically tailored to the field of causal discovery from i.i.d. data. In particular, we introduce a six-dimensional evaluation metric, called distance to the optimal solution, which aims at providing a holistic overview of the performance of structure learning techniques. Our large-scale simulation study, which incorporates seven experimental factors, shows that hybrid Bayesian networks outperform most recently introduced continuous optimization techniques under certain conditions. Additionally, causal order-based methods yield results with comparatively high proximity to the optimal solution.},
  archive      = {J_ISCI},
  author       = {Georg Velev and Stefan Lessmann},
  doi          = {10.1016/j.ins.2025.122641},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122641},
  shortjournal = {Inf. Sci.},
  title        = {Interpretable, multidimensional evaluation framework for causal discovery from observational i.i.d. data},
  volume       = {723},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantization-aware matrix factorization for low bit rate image compression. <em>ISCI</em>, <em>722</em>, 122646. (<a href='https://doi.org/10.1016/j.ins.2025.122646'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lossy image compression is essential for efficient transmission and storage. Traditional compression methods mainly rely on discrete cosine transform (DCT) or singular value decomposition (SVD), both of which represent image data in continuous domains and, therefore, necessitate carefully designed quantizers. Notably, these methods consider quantization as a separate step, which prevents quantization errors from being incorporated into the compression process and degrades the reconstruction quality, particularly in SVD-based methods. To address this issue, we introduce a quantization-aware matrix factorization (QMF) to develop a novel lossy image compression method. QMF provides a low-rank representation of the image data as a product of two smaller matrices, with elements constrained to bounded integer values, thereby effectively integrating quantization with low-rank approximation. We propose an efficient, provably convergent iterative algorithm for QMF using a block coordinate descent scheme, with subproblems having closed-form solutions. Our experiments demonstrate that our method consistently outperforms JPEG at low bit rates below 0.25 bits per pixel. We also demonstrated that our method has an improved capability to preserve visual semantics compared to JPEG at low bit rates by evaluating an ImageNet pre-trained classifier on compressed images. The project is available at https://github.com/pashtari/qmf .},
  archive      = {J_ISCI},
  author       = {Pooya Ashtari and Pourya Behmandpoor and Fateme Nateghi Haredasht and Jonathan H. Chen and Panagiotis Patrinos and Sabine Van Huffel},
  doi          = {10.1016/j.ins.2025.122646},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122646},
  shortjournal = {Inf. Sci.},
  title        = {Quantization-aware matrix factorization for low bit rate image compression},
  volume       = {722},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An attack detection mechanism in smart contracts based on deep learning and feature fusion. <em>ISCI</em>, <em>722</em>, 122645. (<a href='https://doi.org/10.1016/j.ins.2025.122645'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of Ethereum has spurred widespread adoption of smart contracts, enabling substantial financial transactions. Once deployed on the blockchain, smart contracts are immutable, rendering them unmodifiable even if vulnerabilities are present. In recent years, numerous attacks exploiting these vulnerabilities have caused significant financial losses. Although prior research has improved vulnerability detection in source code or bytecode before deployment, identifying attacks that exploit vulnerabilities during the execution phase after deployment remains a significant challenge. These challenges arise from the limited adaptability of predefined detection rules and an overreliance on opcode sequence names, which often neglects a comprehensive analysis of opcode sequence properties. In this study, we propose an advanced multidimensional feature fusion technique designed to detect attacks during the execution phase of smart contracts. By leveraging deep learning, our approach enhances detection accuracy through a comprehensive analysis of attack behaviors across four dimensions: operation objects, action behaviors, functional categories, and gas consumption. Extensive experiments demonstrate that our method achieves a detection accuracy of 97.21% and a weighted F1-score of 97.21%, confirming its effectiveness in identifying attacks.},
  archive      = {J_ISCI},
  author       = {Peiqiang Li and Guojun Wang and Wanyi Gu and Xubin Li and Xiangyong Liu and Yuheng Zhang},
  doi          = {10.1016/j.ins.2025.122645},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122645},
  shortjournal = {Inf. Sci.},
  title        = {An attack detection mechanism in smart contracts based on deep learning and feature fusion},
  volume       = {722},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mean square event-triggered formation control for multi-agent systems under stochastic switching topologies. <em>ISCI</em>, <em>722</em>, 122643. (<a href='https://doi.org/10.1016/j.ins.2025.122643'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the challenging issue of privacy-preserving formation control for second-order multi-agent systems under stochastic switching topologies, mainly protecting privacy of true initial formation errors. Considering the circumstances of communication noises among agents, distributed intermittent event-triggered privacy-preserving formation algorithms including the fuzzy logic system are given. Meanwhile, a novel privacy-preserving mask function is proposed, where indistinguishable space is increased by 26.2% than ones in existing literatures. Based on stochastic stability analysis and graph theory, sufficient conditions of mean square formation with the bound error are derived. Moreover, optimal controllers for the leader are proposed within the intermittent event-triggered privacy-preserving framework. In order to deal with nonlinear and unknown function, we exploit the idea of adaptive control to parameterize partial derivative of corresponding cost function, which is another different technique rather than the adaptive dynamic programming one. Finally, two simulation examples are given to indicate feasibility of our proposed theoretical results.},
  archive      = {J_ISCI},
  author       = {Guoying Miao and Yiming Zhao and Tao Li and Jinde Cao and Hanen Karamti},
  doi          = {10.1016/j.ins.2025.122643},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122643},
  shortjournal = {Inf. Sci.},
  title        = {Mean square event-triggered formation control for multi-agent systems under stochastic switching topologies},
  volume       = {722},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Particle swarm optimization with problem-aware hyperparameter design for feature selection in high dimensions. <em>ISCI</em>, <em>722</em>, 122638. (<a href='https://doi.org/10.1016/j.ins.2025.122638'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a data dimensionality reduction method commonly used to handle high-dimensional datasets. It improves classification accuracy by selecting relevant features, as well as removing irrelevant and redundant ones. However, due to the vast search space, effectively selecting features remains a challenge. Particle swarm optimization (PSO) has been successfully applied to feature selection due to its excellent global search capability and ease of implementation. Existing PSO methods typically use predefined or self-adaptive inertia weights and predefined acceleration coefficients for all datasets. The diversity across datasets means that uniform hyperparameter settings are often suboptimal. To address this, this paper introduces a novel PSO variant, termed PAPSO, which emphasizes a problem-aware hyperparameter design for improved adaptability. Specifically, PAPSO leverages each dataset's intrinsic properties via two mechanisms: an inertia weight adjustment driven by PSO's optimization process for tailored search behavior, and an initialization strategy that sets acceleration coefficients based on the dataset's specific characteristics. This data-driven approach is central to PAPSO's problem-aware' capabilities, allowing the datasets's specific properties themselves to directly guide the hyperparameter design and optimization process more effectively than predefined settings. Extensive experiments on 15 high-dimensional datasets demonstrate that PAPSO achieves a superior balance between the number of selected features and classification accuracy.},
  archive      = {J_ISCI},
  author       = {Jinrui Gao and Zhenyu Lei and Tao Zheng and Lijun Guo and Yirui Wang and Shangce Gao},
  doi          = {10.1016/j.ins.2025.122638},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122638},
  shortjournal = {Inf. Sci.},
  title        = {Particle swarm optimization with problem-aware hyperparameter design for feature selection in high dimensions},
  volume       = {722},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Durrmeyer deep neural networks: Bridging deep learning and dynamic brain functional connectivity. <em>ISCI</em>, <em>722</em>, 122623. (<a href='https://doi.org/10.1016/j.ins.2025.122623'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new family of Durrmeyer Deep Neural Networks (DDNN), characterized by its deep multi-layer architecture and the integration of Gaussian-Based Density (GBD) functions as sigmoidal activation mechanisms. Unlike shallow neural network (NN) operators, which often struggle with higher-order dependencies, this deep-layered approach significantly enhances approximation accuracy and adaptability. We rigorously analyze the convergence properties of DDNN in L p spaces, demonstrating its superior stability over Bernstein-type operators. Importantly, extensive numerical experiments consistently show that DDNN achieves significantly smaller approximation errors compared to shallow-type NN operators, confirming its superior performance in function approximation. The deep structure of DDNN enables the modeling of complex, higher-order dependencies, while the GBD-based activations provide flexibility and adaptability in capturing transient neural interactions. This design enables the operator to effectively balance signal preservation and noise reduction through integral-based smoothing techniques. By bridging classical approximation theory and deep learning, this study establishes DDNN as a powerful tool for dynamic signal processing. Moreover, we apply the DDNN framework to dynamic functional connectivity (DFC) analysis, where it effectively uncovers time-varying connectivity patterns in key brain regions by circumventing the limitations of conventional moving window techniques. The results highlight DDNN's ability to preserve low-frequency components while substantially reducing high-frequency noise, providing a more accurate representation of evolving brain states. Further, in its robust application to fMRI data for Independent Component Analysis (ICA), DDNN consistently and markedly enhanced spatial sparsity: raw component sparsity values (ranging from approximately 0.16 to 0.24) are significantly improved to a much higher range (0.77 to 0.85), representing an average increase of over 0.60 across components. This substantial improvement in spatial localization, coupled with DDNN's capacity for selective temporal modulation, provides a more accurate representation of evolving brain states, advancing the methodological landscape of functional neuroimaging and signal processing.},
  archive      = {J_ISCI},
  author       = {Ugur Kadak},
  doi          = {10.1016/j.ins.2025.122623},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122623},
  shortjournal = {Inf. Sci.},
  title        = {Durrmeyer deep neural networks: Bridging deep learning and dynamic brain functional connectivity},
  volume       = {722},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Minimum initial state estimation of labeled time petri nets in the presence of unobservable transitions. <em>ISCI</em>, <em>722</em>, 122618. (<a href='https://doi.org/10.1016/j.ins.2025.122618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the estimation of minimum initial states (MISs) for partially observable labeled time Petri net (LTPN) systems. Particularly, an MIS is defined by two components: a minimal initial marking possessing the minimum achievable total token count, and a set of timing constraints that explicitly define the static firing delays for every transition enabled under this initial marking. The number of logic transition sequences (LTSs) consistent with a given time-label sequence (TLS) can be infinite. To ensure tractability, we adopt the assumption that only a finite number of unobservable transition firings can occur prior to the firing of any observable transition. Within this framework, the initial step involves deriving the set of minimal initial markings. This derivation is based on LTSs that exhibit logical consistency with the provided TLS. Subsequently, we define a route-modified state class graph (R-MSCG) that is generated by firing the logic consistent LTSs attached to minimal initial markings. By utilizing the transitions-related timing constraints in R-MSCGs, a method is presented to detect whether these logic consistent LTSs are timing consistent with the given TLS. Moreover, we report an algorithm to implement the MISs estimation. Finally, a part processing unit is provided to illustrate how to apply the proposed algorithms to estimate the MIS that allows the specified task sequence to be completed with the least required resources while meeting the timing constraints on the task executions.},
  archive      = {J_ISCI},
  author       = {Liang Li and Chen Wang and Huimin Zhang and Ding Liu},
  doi          = {10.1016/j.ins.2025.122618},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122618},
  shortjournal = {Inf. Sci.},
  title        = {Minimum initial state estimation of labeled time petri nets in the presence of unobservable transitions},
  volume       = {722},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Environment interval type-2 fuzzy sets. <em>ISCI</em>, <em>722</em>, 122612. (<a href='https://doi.org/10.1016/j.ins.2025.122612'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that words not only have different meanings to different people, but also have different meanings in different environments. Interval type-2 fuzzy sets can effectively model intra-personal and inter-personal uncertainties, but their membership functions cannot adjust themselves with the change of environments. In this paper, a generalized interval type-2 fuzzy set called environment interval type-2 fuzzy set (EIT2 FS) is proposed firstly, which can simultaneously model intra-personal, inter-personal and environmental uncertainties well. Next, the equality, containment, intersection, union, and complement of EIT2 FSs are given, and their relationships are strictly analyzed and proven. Then, a method to encode a word into an EIT2 FS is introduced, which is based on the data collected from a group of subjects. Finally, five-word codebook examples are provided to illustrate the EIT2 FSs of the five words using the proposed method.},
  archive      = {J_ISCI},
  author       = {Xianliang Liu and Zhihuan Hu and Weidong Zhang and Mingzhi Liu},
  doi          = {10.1016/j.ins.2025.122612},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122612},
  shortjournal = {Inf. Sci.},
  title        = {Environment interval type-2 fuzzy sets},
  volume       = {722},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel framework for handling uncertainty: Intuitionistic fuzzy rough soft sets. <em>ISCI</em>, <em>722</em>, 122592. (<a href='https://doi.org/10.1016/j.ins.2025.122592'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy sets extend traditional fuzzy sets by incorporating degrees of membership, non-membership, and indeterminacy, making them particularly useful in contexts where uncertainty and hesitancy are prevalent. Rough soft sets combine rough sets' approximation capabilities with soft sets' flexible, parameterized approach to managing uncertainty. This study introduces Intuitionistic Fuzzy Rough Soft (IFRS) sets, integrating these advantages to create a robust framework for handling uncertainty, vagueness, and ambiguity in complex decision-making environments. The paper meticulously defines operations, operators, and measures between IFRS sets, establishing their characteristic properties through rigorous mathematical demonstrations. An innovative algorithm is proposed to address multi-criteria decision-making problems within this framework. The algorithm's effectiveness is thoroughly evaluated through comparisons with state-of-the-art algorithms using reputable datasets in medical consultation, agricultural land evaluation, educational support, and sensitivity analysis experiments. The results demonstrate the proposed algorithm's superior performance and robustness in complex decision-making scenarios, highlighting its potential as a valuable practical tool.},
  archive      = {J_ISCI},
  author       = {Quang-Thinh Bui and Thanh Nha Nguyen and Hung Son Nguyen and Bay Vo},
  doi          = {10.1016/j.ins.2025.122592},
  journal      = {Information Sciences},
  month        = {1},
  pages        = {122592},
  shortjournal = {Inf. Sci.},
  title        = {A novel framework for handling uncertainty: Intuitionistic fuzzy rough soft sets},
  volume       = {722},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
