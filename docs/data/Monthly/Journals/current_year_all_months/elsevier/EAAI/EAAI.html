<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EAAI</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="eaai">EAAI - 205</h2>
<ul>
<li><details>
<summary>
(2026). Exploiting implicit knowledge for streaming perception object detection. <em>EAAI</em>, <em>163</em>, 113100. (<a href='https://doi.org/10.1016/j.engappai.2025.113100'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stream perception is a more challenging task than offline perception. Existing methods perform stream perception object detection by endowing real-time detectors with the ability to predict the future. The difficulty of such methods mainly lies in perceiving complex and changing video background environments, as well as varying object speeds. In this context, we propose a real-time object detection model that utilizes implicit knowledge to enhance features. First, we use a channel implicit knowledge module to perform early fine-tuning on Argoverse-High Definition (Argoverse-HD). This allows the model to perceive the background environment and obtain rich positional features. Then, we use a spatial implicit knowledge module to refine the movement speed features of objects. These refined features are integrated with position features for final fine-tuning. In the final fine-tuning stage, we further weight the original dynamic top- k label assignment strategy to measure the importance of positive samples. Through this weighting, we aim to obtain finer-grained object localization. Our model achieves 37.8% streaming Average Precision (sAP) on Argoverse-HD ( + 0 . 9 % over baseline) with merely 0.01G additional Floating Point Operations (FLOPs) and a latency increase of less than 3 millisecond (ms). Code is available on https://github.com/GjtZ/ISYOLO.git .},
  archive      = {J_EAAI},
  author       = {Qingsong Tang and Jinting Guo and Xuexiao Zhou and Yongkang Li and Mingzhi Yang and Yang Liu},
  doi          = {10.1016/j.engappai.2025.113100},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113100},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploiting implicit knowledge for streaming perception object detection},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). KalmanTNet - Hybrid-driven kalman filter for trajectory filtering. <em>EAAI</em>, <em>163</em>, 113096. (<a href='https://doi.org/10.1016/j.engappai.2025.113096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of trajectory filtering has garnered significant attention across various domains. However, existing methods struggle with complex situations and perform poorly under model mismatch conditions. To address these limitations, this paper proposes KalmanTNet, a novel data-model hybrid driven approach that leverages the robust sequence processing capabilities of the Transformer architecture and the concise structure of the Kalman filter. Experimental results show that KalmanTNet outperforms Kalman filter, extended Kalman filter, unscented Kalman filter and KalmanNet in complex environments, achieving superior filtering accuracy.},
  archive      = {J_EAAI},
  author       = {Wenyi Zhang and Zengfu Wang and Kuilong Yang and Hua Lan},
  doi          = {10.1016/j.engappai.2025.113096},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113096},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {KalmanTNet - Hybrid-driven kalman filter for trajectory filtering},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep learning-based machine vision system for real-time edge fracture detection in the hole expansion test. <em>EAAI</em>, <em>163</em>, 113092. (<a href='https://doi.org/10.1016/j.engappai.2025.113092'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge fracture poses a critical challenge in sheet metal forming processes involving extruded holes, stretched flanges, or tight radius bends widely used in the automotive industry. Real-time detection of edge fractures in the hole expansion test, which is used to quantify the edge stretchability of sheet metal, has become both a technical challenge and an industrial necessity due to the diversity of materials. This study aims to develop an automated machine vision system for real-time detection of edge fractures and quantification of the hole expansion ratio during the hole expansion test. A deep learning-based vision pipeline is proposed, integrating dataset collection, dual-stage segmentation, and region-of-interest linearization to precisely capture the onset of cracks. This approach enables simultaneous recognizing edge fractures, quantifying the hole expansion ratio, and measuring crack gaps under varying surface reflectance and sheet thickness conditions. An ablation study evaluates the proposed approach against single-stage segmentation on the hole expansion test dataset prepared by hole punching method. Practical experimental validation confirms high segmentation accuracy and hole expansion ratio measurements with a maximum error of less than 2 % compared to manual evaluation. The findings offer a scalable and objective solution that overcomes the limitations of conventional monitoring methods and ensures consistent, real-time assessment across varying sheet materials.},
  archive      = {J_EAAI},
  author       = {Van Doi Truong and Jonghun Yoon},
  doi          = {10.1016/j.engappai.2025.113092},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113092},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning-based machine vision system for real-time edge fracture detection in the hole expansion test},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Irrelevance discriminative network for enhancing cross-center generalization in medical imaging segmentation. <em>EAAI</em>, <em>163</em>, 113086. (<a href='https://doi.org/10.1016/j.engappai.2025.113086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-center generalization in medical image segmentation (MIS) is a significant challenge due to the variability introduced by different imaging devices, operator techniques, and patient populations. In this paper, we propose the deep learning based I rrelevance D iscriminative Net work (ID-Net) method, which enhances cross-center generalization in MIS. We incorporate multiple auxiliary domain datasets (ADDs) from various centers alongside a single or limited number of target domain datasets. By training on the ADDs, the I rrelevance D iscriminative (ID) module is capable of discriminating the latent representation of input images into common features, domain-specific features, and disturbance/noise. This allows for the fusion of common features with domain-specific features from the target domain dataset while discarding irrelevant noise, thereby significantly improving the cross-center generalization ability in the target domain tasks. Our approach effectively mitigates the domain shift problem and enhances the robustness and adaptability of MIS models across different centers.},
  archive      = {J_EAAI},
  author       = {Yibin Lin and Dongming Li and Xiao Chen and Wude He and Qi Guan and Danru Chen and Anguo Zhang and Xiaorong Yan and Yang Sun},
  doi          = {10.1016/j.engappai.2025.113086},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113086},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Irrelevance discriminative network for enhancing cross-center generalization in medical imaging segmentation},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Heterogeneous-effect causal graph diffusion network for sustainable regional economic upgrading. <em>EAAI</em>, <em>163</em>, 113084. (<a href='https://doi.org/10.1016/j.engappai.2025.113084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustainable regional economic upgrading requires analytical tools that reveal causal mechanisms behind policy impacts. This study presents a new framework, the Heterogeneous Effect Causal Graph Diffusion Network, which combines causal graph discovery, heterogeneous policy effect modeling, and dynamic diffusion analysis to simulate regional policy outcomes. Using multiple real-world and semi-synthetic regional datasets, the proposed approach achieves higher forecasting accuracy and more reliable policy effect estimation than existing econometric and machine learning models. The results highlight that causal graph diffusion enables interpretable and data-driven guidance for sustainable regional development by identifying effective policies and their spillover pathways.},
  archive      = {J_EAAI},
  author       = {Libin Zhou and Wenyu Ning and Zongye Gu and Mingsen Wang and Bingtao Xu},
  doi          = {10.1016/j.engappai.2025.113084},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113084},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Heterogeneous-effect causal graph diffusion network for sustainable regional economic upgrading},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Lightweight dual-stream multi-scale feature fusion medical image multi-disease adaptation classification network based on guided enhancement. <em>EAAI</em>, <em>163</em>, 113083. (<a href='https://doi.org/10.1016/j.engappai.2025.113083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the mobile healthcare scenario, the efficient deployment of lightweight image classification models on edge devices can significantly enhance the accessibility and real-time performance of medical services, providing reliable technical support for scenarios such as scarce medical resources in remote areas, real-time diagnosis on mobile terminals, and remote image analysis. Aiming at the problems such as insufficient cross-domain adaptability and inadequate feature extraction of lightweight models in the task of medical image classification, this paper proposes a lightweight dual-stream multi-scale feature fusion medical adaptation classification network based on guided enhancement (DMF-MobileMamba). This network adopts a parallel dual stream architecture, combining the local texture extraction capability of Convolutional Neural Network (CNN) with the global remote dependency modeling advantage of the improved lightweight multi-scale adapter Mamba module, and achieving heterogeneous feature complementarity through decoupling design. The multi-scale attention modulation fusion module (MSA-Fusion) is used to dynamically and weighted fuse local and global features; Innovatively proposed the Cross-level Guided Enhancement Attention Module (CLGE), which utilizes shallow high-resolution details to dynamically correct deep semantic biases and alleviate the representation mismatch problem between model levels. Experiments show that DMF-MobileMamba only requires 4.039 million(M) parameters and 2.438 Giga Floating-point Operations Per Second(GFLOPS). On six medical datasets, its classification accuracy is significantly better than that of mainstream advanced lightweight models, and it achieves a real-time inference speed of 134.64 millisecond(ms) on mobile devices. It provides high-precision and low-cost solutions for resource-constrained scenarios.},
  archive      = {J_EAAI},
  author       = {Wenlong Shi and Long Yu and Shengwei Tian and Qimeng Yang and Dezhi Zhang and Shirong Yu and Weidong Wu},
  doi          = {10.1016/j.engappai.2025.113083},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113083},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightweight dual-stream multi-scale feature fusion medical image multi-disease adaptation classification network based on guided enhancement},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). On the mathematical background of the paper “Fractal interpolation in the context of prediction accuracy optimization, engineering applications of artificial intelligence, 133 (2024), 108380”. <em>EAAI</em>, <em>163</em>, 113081. (<a href='https://doi.org/10.1016/j.engappai.2025.113081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of the paper Fractal interpolation in the context of prediction accuracy optimization, Engineering Applications of Artificial Intelligence, 133 (2024), 108380 , authored by A. Băicoianu, C.G. Gavrilă, C.M. Păcurar, V.D. Păcurar, is to apply interpolation methods to improve the prediction quality of machine learning models. The interpolation method used is the one created by M. Barnsley, known as the fractal interpolation theory since it relies on the fractals generated by iterated function systems. This paper discusses the mathematical background on which are based the results from the above mentioned paper. It is highlighted that the fractal interpolation function concept used is not the appropriate one.},
  archive      = {J_EAAI},
  author       = {Radu Miculescu},
  doi          = {10.1016/j.engappai.2025.113081},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113081},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {On the mathematical background of the paper “Fractal interpolation in the context of prediction accuracy optimization, engineering applications of artificial intelligence, 133 (2024), 108380”},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automated crack measurement in slab tracks using deformable instance segmentation and boundary augmentation with unsupervised style transfer. <em>EAAI</em>, <em>163</em>, 113077. (<a href='https://doi.org/10.1016/j.engappai.2025.113077'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crack detection and measurement in slab tracks are critical for maintenance decision-making. Pre-trained deep learning segmentation models often struggle with cracking instances due to domain adaptation and data scarcity. This study proposes an instance segmentation framework incorporating dynamic snake convolution (DSConv) modules, combined with an unsupervised style transfer-based boundary augmentation strategy. The DSConv-enhanced architecture prioritizes linear crack features in cluttered backgrounds, while the augmentation introduces controlled perturbations to global pixels and local crack boundaries, generating structurally consistent diversified training samples. The results demonstrate that the deformable DSConv enhanced architecture achieves optimal mean average precision (mAP), improving segmentation performance by nearly 13 % compared to "fine-tuned Segment Anything Model". Its segmentation capability surpasses eight state-of-the-art models, especially for multiple intermittent microcracks. Furthermore, unsupervised style transfer-generated augmented data enhances crack instance segmentation performance by 10 % compared to non-augmented baselines, surpassing conventional methods including horizontal flipping and color jittering. Quantitative crack width distributions from segmentation-quantification analysis provide more comprehensive structural health insights than manual discrete-point measurements, facilitating precise maintenance decisions for railway infrastructure.},
  archive      = {J_EAAI},
  author       = {Wenbo Hu and Zheng Wu and Weidong Wang and Xianhua Liu and Jun Peng},
  doi          = {10.1016/j.engappai.2025.113077},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113077},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automated crack measurement in slab tracks using deformable instance segmentation and boundary augmentation with unsupervised style transfer},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FGBVD-KD: Frequency-guided bias-variance decomposition knowledge distillation for fracture detection. <em>EAAI</em>, <em>163</em>, 113075. (<a href='https://doi.org/10.1016/j.engappai.2025.113075'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fracture detection in medical imaging is a critical diagnostic task for identifying bone injuries, where deep learning achieves high accuracy using large-scale models. However, their computational cost hinders clinical deployment. Knowledge distillation (KD) addresses this challenge by compressing the high-performance teacher to the lightweight student. Nevertheless, current feature distillation methods prioritize semantic feature imitation, neglecting critical structural details like bone morphology abnormalities and biomechanical disruptions specific to bone injuries. This study identifies a fundamental limitation: prevailing distillation paradigms compel students to fit teachers’ feature means ( bias learning ) while neglecting variance alignment, which is essential for structural details. We propose FGBVD-KD, a Frequency-Guided Bias-Variance Decomposition framework that decouples distillation loss into bias (mean-fitting) and variance (distribution-alignment) terms. Leveraging the finding that semantic features concentrate in low-frequency component while structural features reside in high-frequency domains, we introduce two novel modules: 1) Feature Frequency Expectation Estimation (FFEE), a lightweight module estimating prediction expectations to bridge bias-variance computation; 2) Frequency-domain Information Decomposition (FID), splitting teacher features into low-frequency and high-frequency components. FGBVD-KD guides students to utilize low-frequency component for semantic bias learning and high-frequency component for structural variance alignment. Evaluations on two fracture detection benchmarks demonstrate state-of-the-art performance across diverse teacher-student pairs. Importantly, our framework achieves this superior accuracy while introducing negligible parameters and computational overhead during inference, maintaining identical model size and FLOPs as the student. This makes it particularly suitable for resource-constrained clinical environments. Ablation studies confirm the effectiveness of both FFEE and FID modules. Our code is available at: https://github.com/1123026073/FGBVD-KD .},
  archive      = {J_EAAI},
  author       = {Xiangchun Yu and Dingwen Zhang and Longxiang Teng and Hechang Chen and Jian Zheng and Huashuai Cai and Miaomiao Liang},
  doi          = {10.1016/j.engappai.2025.113075},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113075},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FGBVD-KD: Frequency-guided bias-variance decomposition knowledge distillation for fracture detection},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intelligent image compression based on neighborhood dynamic perception and multi-parameter optimized entropy model. <em>EAAI</em>, <em>163</em>, 113071. (<a href='https://doi.org/10.1016/j.engappai.2025.113071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the limitation of existing learned image compression models based on spatial context in handling feature’s channel redundancy, this paper proposes an image compression algorithm based on Mirror Neighborhood Attention Transformer (MNAT) and the Multi-parameter Optimized Entropy Model (MOEM). A refined two-stage Refined Multi-Scale Guide Entropy Model (RMGEM) is integrated with the channel autoregressive context model to jointly eliminate local spatial redundancy and channel redundancy in latent features. Additionally, a global spatial context model is added to capture long-range dependencies. We separately reduce local and global spatial redundancies in each channel group slice for efficient and accurate context modeling. And the MNAT network combines the variational framework with the neighborhood attention mechanism to boost performance. Evaluations show the proposed method outperforms existing influential learned and conventional image compression methods. On the Kodak, Tecnick and CLIC (CLIC is a dataset for the Challenge on Learned Image Compression) Professional Valid datasets, it achieves BD(Bjontegaard Delta)-rate gains of 5.63%, 10.55% and 5.66% against VTM (Versatile Video Coding Test Model)-17.0. Consequently, the proposed algorithm overcoming the limitations of spatial context models, achieves accurate probabilistic modeling and superior compression by precisely exploiting redundancies.},
  archive      = {J_EAAI},
  author       = {Bo Li and Yongjun Li and Jingyi He and Mengyan Lu and Chaoyue Li and Zhimin Chenjin and Yong Liang and Xuxing Zhao},
  doi          = {10.1016/j.engappai.2025.113071},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113071},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent image compression based on neighborhood dynamic perception and multi-parameter optimized entropy model},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A reinforcement learning algorithm with high-dimensional space processing for decision support in government bailout strategies during interbank risk contagion. <em>EAAI</em>, <em>163</em>, 113069. (<a href='https://doi.org/10.1016/j.engappai.2025.113069'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interbank business relationships form a complex network structure, providing potential channels for risk contagion that require timely government interventions. Determining optimal bailout strategies throughout the contagion process presents a dynamic and high-dimensional decision-making challenge due to the large number of interconnected banks with continuously evolving asset states. This paper presents a novel reinforcement learning algorithm integrating a high-dimensional space processing mechanism to address this challenge and find the long-term optimal decision during the whole contagion process. Specifically, a proximal policy optimization framework is enhanced by (i) constructing an action candidate set to improve exploration efficiency, (ii) combining immediate and final rewards to stabilize learning, and (iii) applying spatial decomposition and low-dimensional representation techniques to reduce dimensionality and improve policy robustness in previously unseen states. For the engineering application, the multi-agent-based interbank lending network simulation system was utilized to test and validate the effectiveness of the proposed bailout decision-making algorithms in dynamic contagion scenarios. Experimental results demonstrate that the proposed algorithm achieves superior long-term bailout strategies compared to conventional optimization methods and other state-of-the-art reinforcement learning approaches, with clear advantages in solution quality, convergence speed, and decision stability. This study provides practical decision-support tools for financial regulators and policymakers in managing systemic risks within interbank networks.},
  archive      = {J_EAAI},
  author       = {Yijun Chen and Huanlan Yan and Zhijun Ding},
  doi          = {10.1016/j.engappai.2025.113069},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113069},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A reinforcement learning algorithm with high-dimensional space processing for decision support in government bailout strategies during interbank risk contagion},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Event-driven emergency data dissemination in vehicular named data networking based on learning automata. <em>EAAI</em>, <em>163</em>, 113067. (<a href='https://doi.org/10.1016/j.engappai.2025.113067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergency road-safety data, such as accident notifications, can improve driving safety and efficiency, making rapid access to this data crucial. This paper proposes an event-driven emergency data dissemination method based on vehicular named data networking. The method has three key ideas: (1) When an event occurs, dissemination is triggered, leveraging a local cloud for inter-vehicle collaboration to construct a comprehensive dataset; (2) Learning automata are employed to stabilize dissemination paths; and (3) A subscription mechanism is introduced to enable path reuse for continuous, unicast-based dissemination to interested vehicles. The experimental results show the method reduces dissemination delays and overhead by nearly 40.5 % and 68.1 %, respectively, while improving success rates by nearly 11.3 %.},
  archive      = {J_EAAI},
  author       = {Xiaonan Wang and Ranran Zhang},
  doi          = {10.1016/j.engappai.2025.113067},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113067},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Event-driven emergency data dissemination in vehicular named data networking based on learning automata},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Flame detection technology for buildings safety based on wireless sensing. <em>EAAI</em>, <em>163</em>, 113065. (<a href='https://doi.org/10.1016/j.engappai.2025.113065'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sensing range of flame detection technology based on smoke, temperature, and camera can only cover the line-of-sight area, making it difficult for high-rise building residents to detect fire accidents in adjacent apartments before the fire spreads, thus wasting rescue time. This paper proposes a novel flame detection method based on Channel State Information (CSI) features extracted from Wi-Fi signals, leveraging the omnipresence of Wi-Fi networks in modern infrastructures. By utilizing machine learning to exploit the CSI features induced by environmental changes during fire events, the proposed method offers a robust and responsive engineering solution as an alternative to conventional detection methods. A machine learning-based classification algorithm is designed to differentiate between four critical scenarios: fire with human (FWH), only fire (FNH), only human (NFH), and no fire without human (NFN). The effectiveness of the method is validated through extensive experimentation under various fire conditions and diverse architectural apartment scenarios, utilizing a comprehensive dataset comprising 2100 samples. This dataset is specifically structured with 700 samples for NFN, 350 for FWH, 350 for FNH, and 700 for NFH. The method yields a classification accuracy of 96.81 % and an end-to-end response time of 13 s, demonstrating improvements over existing approaches in terms of both response time and detection accuracy. Moreover, its reliance on pre-existing Wi-Fi infrastructure facilitates seamless integration into current smart building environments, thus offering a scalable and efficient solution for enhanced fire safety. The dataset used for this study is publicly available at: https://github.com/T-bjq/WCFD-CSI-dataset .},
  archive      = {J_EAAI},
  author       = {Yike Wang and Jiaqian Bao and Kai Zhao and Yong Xiong and Shiqing Zhang and Liangliang Lou},
  doi          = {10.1016/j.engappai.2025.113065},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113065},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Flame detection technology for buildings safety based on wireless sensing},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Computer vision-based framework for automatic collection of key milestone nodes during aircraft turnaround. <em>EAAI</em>, <em>163</em>, 113063. (<a href='https://doi.org/10.1016/j.engappai.2025.113063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic collection of Key Milestone Nodes (KMN) during aircraft turnaround is of great significance for the development needs of Airport-Collaborative Decision Making (A-CDM). In order to enhance the efficiency of aircraft turnaround, it is imperative to automatically collect KMNs in airport operation. Currently, the acquisition of KMNs still relies on manual input by frontline controllers, which proves to be inefficient and labor-intensive. Therefore, this paper exploits a framework that utilizes advanced algorithms and technologies in computer vision to autonomously and instantly recognize KMNs based on surveillance images. The proposed framework effectively extracts identity and continuous trajectory information of KMN executors from the surveillance videos of the airport surface background. Subsequently, a dynamic graph-based spatial-temporal attention model is employed for classification and collection of these KMNs. Experimental results demonstrate that KMNs could be automatically collected by the proposed framework both in simulation platform and real scenes at airports. The time error of KMN collection is less than 60 s and meets reporting requirements as defined in A-CDM system.},
  archive      = {J_EAAI},
  author       = {Meng Ding and Hongyu Zhang and Jiajun Wang and Qi Li},
  doi          = {10.1016/j.engappai.2025.113063},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113063},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Computer vision-based framework for automatic collection of key milestone nodes during aircraft turnaround},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Certainty-enhanced dual-teacher fusion for source-free domain adaptation in fundus image segmentation. <em>EAAI</em>, <em>163</em>, 113062. (<a href='https://doi.org/10.1016/j.engappai.2025.113062'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise segmentation of the optic disc (OD) and optic cup (OC) is essential for glaucoma diagnosis and management. However, due to domain shifts between different data sources, existing models often struggle to generalize across datasets, making source-free domain adaptation (SFDA) an attractive solution. SFDA methods based on the Mean Teacher (MT) framework, however, frequently suffer from unstable pseudo-label quality and error accumulation, particularly in complex medical image tasks such as OD and OC segmentation. To address these challenges, we propose the Certainty-Enhanced Dual-Teacher Fusion (CEDTF) model, an innovative extension of the MT framework. CEDTF integrates a static teacher with a conventional dynamic teacher, forming a robust dual-teacher system that effectively mitigates the accumulation of common errors in SFDA. The dynamic teacher is continuously updated using the Exponential Moving Average (EMA) of the student model’s parameters, while the static teacher synchronizes updates at fixed intervals. In addition, we introduce an Uncertainty-Weighted Fusion (UWF) mechanism that adaptively combines pseudo-labels from both teachers, optimizing the fusion process based on their respective uncertainty levels to generate high-quality pseudo-labels. This dual-teacher approach not only overcomes the inherent limitations of the MT framework but also enhances the reliability of training data, thereby improving both the accuracy and stability of OD and OC segmentation. Extensive experimental results demonstrate that the proposed CEDTF model consistently improves segmentation performance and pseudo-label quality, achieving superior results compared to existing methods.},
  archive      = {J_EAAI},
  author       = {Lanyan Xue and Kaibin Li and Dawei Fan and Jiaming Yu and Jiamei Wen and Yunsheng Chen},
  doi          = {10.1016/j.engappai.2025.113062},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113062},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Certainty-enhanced dual-teacher fusion for source-free domain adaptation in fundus image segmentation},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Donor behavior in healthcare crowdfunding success: A theory-driven approach using business intelligence and supervised machine learning in pakistan. <em>EAAI</em>, <em>163</em>, 113061. (<a href='https://doi.org/10.1016/j.engappai.2025.113061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical crowdfunding has emerged as a crucial tool for bridging healthcare financing gaps in resource-constrained settings such as Pakistan. Despite its growing importance, the specific factors driving campaign success remain underexplored. This study adopts a theory-driven framework, grounded in signaling theory, to investigate the key determinants of successful campaigns on Transparent Hands, Pakistan's leading medical crowdfunding platform. Utilizing data from 1019 campaigns conducted between 2020 and 2023, we apply a multi-methodological approach. This includes statistical regression, business intelligence techniques, and a suite of supervised machine learning algorithms namely support vector regression, random forest, extreme gradient boosting, logistic regression, deep learning using convolutional neural networks, classification tree, and bootstrap aggregating ensemble. Our aim was to evaluate how campaign attributes, such as funds raised, patient demographics (gender and age), and type of medical procedure, influence donor engagement and the number of patients served. Results demonstrate that fundraising amount and patient age significantly shape donor behavior, while gender and procedure type affect both donor participation and service outreach. Significantly, the support vector regression and random forest models exhibited superior predictive accuracy, providing actionable insights for platform optimization. This study contributes substantively to the application of signaling theory in digital health financing and proposes data-driven strategies to enhance the effectiveness of health financing through medical crowdfunding.},
  archive      = {J_EAAI},
  author       = {Sardar Muhammad Usman and Huiwei You and Muhammad Zubair and Huiwen You and Usama Saleem},
  doi          = {10.1016/j.engappai.2025.113061},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113061},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Donor behavior in healthcare crowdfunding success: A theory-driven approach using business intelligence and supervised machine learning in pakistan},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Prognosticating fabric-reinforced cementitious matrix-to-masonry bond and failure mechanisms using novel tabular variational autoencoder-augmented probabilistic model. <em>EAAI</em>, <em>163</em>, 113059. (<a href='https://doi.org/10.1016/j.engappai.2025.113059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fabric-reinforced cementitious matrix (FRCM) composite strengthening has emerged as an environmentally friendly and less invasive solution, and entails material compatibility with masonry substrates, and hence emerges as the sustainable solution for structural restoration. But the performance of the FRCM system primarily depends on the bond behaviour between the masonry and composite interface, which governs stress transfer and failure mode. However, the available experimental datasets lack diversity, especially with respect to categorical characteristics, limiting predictive capability and extrapolation potential of data-driven models. Therefore, in this study, a tabular variational autoencoder model was implemented to synthetically augment the experimental database to capture a higher range of input variability. Using this enriched dataset, probabilistic modelling techniques have been utilized, including Gaussian process, Bayesian neural network, and natural gradient boosting (NGB) in predicting critical FRCM-to-masonry bond behaviour that includes bond strength, slip, and respective failure modes. Among these developed probabilistic models, the NGB model performed both better in terms of accuracy as well as uncertainty quantification and gave interpretable results on the importance of features. Mean absolute percentage error value of the testing set of the NGB model using the synthetic dataset approach was 22.72% and 23.83% for bond strength and slip, respectively. For failure modes, the accuracy of the NGB model for the testing set was 84% with the synthetic dataset. The proposed hybrid method enhances predictability and aids in formulating more precise and uncertainty-based design strategies for the sustainable rehabilitation of deteriorated masonry infrastructure.},
  archive      = {J_EAAI},
  author       = {Aman Kumar and Afshin Marani and Asim Abbas and Moncef L. Nehdi},
  doi          = {10.1016/j.engappai.2025.113059},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113059},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prognosticating fabric-reinforced cementitious matrix-to-masonry bond and failure mechanisms using novel tabular variational autoencoder-augmented probabilistic model},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Depth-aware and continuous edge curves for large-view underwater image reconstruction. <em>EAAI</em>, <em>163</em>, 113057. (<a href='https://doi.org/10.1016/j.engappai.2025.113057'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consistency of geometric features poses a major challenge in perspective reconstruction, especially in complex underwater environments where existing methods struggle to utilize linear edge features. To address this, we propose a novel Depth Restoration Feature Stitching (DRFS) approach, which integrates four core procedures such as depth estimation (D-procedure), restoration (R-procedure), feature extraction (F-procedure), and image stitching (S-procedure) to reconstruct natural-looking, large-view underwater images. Our method leverages unsupervised deep learning techniques, including Monocular Depth Estimation v2 (Monodepth2), combined with domain priors to estimate accurate depth under varying illumination conditions. The restoration procedure enhances image contrast and corrects color distortion using a complex underwater imaging model. The feature extraction procedure constructs large-scale geometric structures based on depth-guided edge curves, addressing the challenge of inconsistent or missing straight lines in underwater scenes. The stitching procedure preserves structural consistency through grid alignment, global similarity, and pyramid-based image fusion. Experimental results demonstrate that our method produces visually appealing reconstructions with improved geometric fidelity. These capabilities make it well-suited for artificial intelligence applications in underwater robotics, intelligent marine perception, autonomous exploration, environmental monitoring, and large-scale ocean mapping.},
  archive      = {J_EAAI},
  author       = {Jingchun Zhou and Qian Liu and Dehuan Zhang and Zifan Lin and Deepak Kumar Jain and Dragan Pamucar and Vladimir Simic},
  doi          = {10.1016/j.engappai.2025.113057},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113057},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Depth-aware and continuous edge curves for large-view underwater image reconstruction},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Directly utilizing video compression information for cross-attention-based optical flow estimation and occlusion feature prediction. <em>EAAI</em>, <em>163</em>, 113055. (<a href='https://doi.org/10.1016/j.engappai.2025.113055'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the significant advances achieved by deep-learning-based optical flow estimation methods, however their reliance on fully decoded video frames, thus introduces substantial unnecessary complexity. Recent approaches mitigate computational complexity by utilizing video compression format, such as motion vectors (MVs) and partially decoding frames. However, the procedure of decoding partial video frames is still a extra complexity burden for optical flow estimation. Additionally, motion occlusion remains a persistent challenge for learning-based optical flow methods. To address these limitations, we propose CoFlow, a novel optical flow estimation method which operating directly on compressed video formats no need to decode any video frames. CoFlow bridges the gap between discrete MVs and fine-grained optical flow by employing residual (RES) information as cross-attention guidance. Furthermore, CoFlow incorporates an occlusion map prediction module that leverages intra-frame coding blocks which inherent in the video compression format information. Comprehensive experiments demonstrate that CoFlow outperforms existing models, it achieving the best performance on the challenging MPI-Sintel datasets. Specifically, compared with other optical flow estimation methods, it can reduce the computational complexity by 44% while ensuring the accuracy of optical flow estimation. The code are available at https://github.com/zhntz/COFlow.git .},
  archive      = {J_EAAI},
  author       = {Ziyi Tian and Hongwei Lin and Xiangqun Li and Jianhua Wang},
  doi          = {10.1016/j.engappai.2025.113055},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113055},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Directly utilizing video compression information for cross-attention-based optical flow estimation and occlusion feature prediction},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Self-supervised learning with push-away strategies for various negative samples. <em>EAAI</em>, <em>163</em>, 113054. (<a href='https://doi.org/10.1016/j.engappai.2025.113054'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an excellent self-supervised learning method, contrastive learning has achieved superior efficiencies in various domains. The method pre-trains the embedding representations by pulling the anchor sample to its positive pair and pushing it away from the other negative samples, and those negative pairs that are more similar to the anchor sample receive a stronger pushing effect. However, this can be detrimental to those negative pairs that come from the same class as the anchor. How to give appropriate strategies to different negative pairs is a problem that needs to be solved. We therefore propose a pushing strategy using pseudo-labels and analyze its feasibility. Under our strategy, negative pairs of the same class as anchor sample are kept within the class, and the complete semantic structure is protected from destruction. On the other hand, considering the lack of ground-truth labels in self-supervised learning tasks, the strategy for determining the reliability of pseudo-labels and combining them dynamically is also given. Extensive experiments show that our proposed method can effectively make the pre-trained embedding representations more discriminative. Specifically, our approach achieves classification accuracy improvements of 0.49% over the suboptimal approach on ImageNet-1K with ResNet-34, and 3.12% on ImageNet-100 with ViT-S/16.},
  archive      = {J_EAAI},
  author       = {Ruojin Zhou and Bo Gong and Jingwen Yang and Yingyi Chen and Ling Jing},
  doi          = {10.1016/j.engappai.2025.113054},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113054},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-supervised learning with push-away strategies for various negative samples},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards smart city supervision: A detection pipeline for illegal buildings. <em>EAAI</em>, <em>163</em>, 113052. (<a href='https://doi.org/10.1016/j.engappai.2025.113052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Illegal buildings pose a significant threat to urban planning and public safety. However, current satellite remote sensing-based detection methods not only require significant human and financial resources but also suffer from prolonged detection cycles. To address these challenges, a novel pipeline utilizing high-tower cameras for monitoring building-related objects to promptly discover illegal construction is proposed. First, a camera pose error self-correction algorithm is introduced to address the installation errors in camera installations, ensuring camera stability during patrol operations. Secondly, a mapping model between physical and image space is developed to locate objects. Furthermore, a previous illegal building object dataset is improved, and a new illegal building object detection network (IBDNet) is proposed. The proposed IBDNet introduces a Visual State Space block, a frequency-aware feature fusion module, and a feature fusion enhancement module, which are used for spatiotemporal modeling and multi-level feature fusion to enhance detection accuracy and robustness. Experimental results demonstrate that the proposed detection algorithm accurately detects illegal building-related objects, achieving a mean average precision (mAP) of 86.1% and outperforming the existing state-of-the-art models. By utilizing the proposed detection pipeline, illegal buildings can be precisely detected and located, allowing for timely identification and prevention of illegal construction activities. Furthermore, this method can potentially be integrated into broader applications, such as real-time urban planning systems and smart urban governance.},
  archive      = {J_EAAI},
  author       = {Wenjin Liu and Yuheng Li and Shudong Zhang and Rui Mao},
  doi          = {10.1016/j.engappai.2025.113052},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113052},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards smart city supervision: A detection pipeline for illegal buildings},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Probabilistic modeling and prediction of far-field bedrock seismic intensity measures based on deep generative models. <em>EAAI</em>, <em>163</em>, 113048. (<a href='https://doi.org/10.1016/j.engappai.2025.113048'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bedrock seismic intensity measures play a crucial role in seismic disaster analysis and the seismic design of underground structures. However, the existing neural network-based prediction methods of seismic intensity measures mainly used deterministic models. The predicted intensity measures failed to cover the amplitude, spectrum, and duration of ground motion. These conventional approaches fail to comprehensively characterize the inherent complexity and stochastic nature of seismic ground motions. To address this issue, this study selected 24 commonly used seismic intensity measures encompassing amplitude, spectrum and duration, establishing a far-field dataset through the KiK-net strong-motion observation network for surface-bedrock motion. By considering the bedrock seismic intensity measures as high-dimensional random variables, while the surface seismic intensity measures and site condition parameters as high-dimensional conditional variables, a conditional generative adversarial network (CGAN), one of the typical deep generative models was employed to establish a probabilistic distribution model for these parameters. The trained CGAN framework exhibits robust predictive capacity for bedrock intensity measures. Additionally, two stations were selected to compare the CGAN model's prediction results with traditional empirical formulas and equivalent linearization methods. The achieved average determination coefficient (R 2 ) improvements of 38.3 % and 9.3 % respectively substantiate the theoretical validity and methodological advancement embedded in the proposed model.},
  archive      = {J_EAAI},
  author       = {Jiecheng Xiong and Yifeng Tian and Shuqian Duan and Jingwei Zhang and Yongqun Zhang},
  doi          = {10.1016/j.engappai.2025.113048},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113048},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Probabilistic modeling and prediction of far-field bedrock seismic intensity measures based on deep generative models},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhanced unsupervised domain adaptation through joint constrained classifier and feature learning. <em>EAAI</em>, <em>163</em>, 113047. (<a href='https://doi.org/10.1016/j.engappai.2025.113047'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (DA) is effective in bridging the gap between label-rich source domains and unlabeled target domains by utilizing artificial intelligence (AI) and machine learning techniques. However, two issues need to be further researched. Firstly, employing features directly for classification often leads to performance degradation, and many DA strategies ignore the value of pseudo-target labels for aligning label distributions. Secondly, only a smaller subset of the extracted features exhibit the strongest effects for the recognition task. In this paper, we propose a novel joint constrained classifier and feature learning (JCCFL) framework to enhance unsupervised DA. For the first issue, our method leverages the feature transformation matrix as a classifier and incorporates pseudo-target labels as label guidance to improve discriminant performance. For the second, the framework optimizes feature extraction and feature selection, transforming domains into a latent shared subspace where target samples are a linear combination of source samples. Cross-domain distribution is aligned in the feature space to mitigate the impact of negative transfer, while graph regularization ensures the preservation of intrinsic structural relationships. To solve the proposed model, we design an effective algorithm based on the alternative direction method of multipliers, proving its theoretical convergence. Comprehensive experiments on various cross-domain image classification tasks illustrate the enhanced performance of our proposed method by comparing state-of-the-art DA techniques.},
  archive      = {J_EAAI},
  author       = {Zuoxun Tan and Hu Yang},
  doi          = {10.1016/j.engappai.2025.113047},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113047},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced unsupervised domain adaptation through joint constrained classifier and feature learning},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A global–local relational graph attention networks for aspect-level sentiment analysis. <em>EAAI</em>, <em>163</em>, 113037. (<a href='https://doi.org/10.1016/j.engappai.2025.113037'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-level sentiment analysis pertains to a meticulous sentiment classification that aims to identify aspect terms within online reviews and forecast their associated sentiment polarities. Nevertheless, this undertaking presents difficulties primarily attributable to numerous aspect words within a sentence or intricate dependency relationships. In order to tackle these obstacles, we put forth a global–local relational graph attention network (GLR-GAT) for aspect-level sentiment analysis. This model achieves a comprehensive syntactic analysis of sentences by syntactic dependency trees. In order to improve the accuracy of sentiment analysis by capturing the interactive extraction and dependencies of aspects in a sentence, we propose a framework that considers the syntactic dependencies of a sentence, the interrelationships among aspect words, and the relationships between aspect words and the sentence, respectively. Moreover, we apply a multi-head attention mechanism to correlate these three types of relationships and highlight the important ones. Comparison experiments show that the proposed GLR-GAT model performs more remarkably than existing baseline models. The ablation study confirms that each part of the GLR-GAT model plays an important role. Compared with large language models, the GLR-GAT model also shows significant advantages on a Twitter dataset.},
  archive      = {J_EAAI},
  author       = {Maolin Zhang and Xianyong Li and Xiaoliang Chen and Yajun Du and Dong Huang and Shumin Wang and Yongquan Fan},
  doi          = {10.1016/j.engappai.2025.113037},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113037},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A global–local relational graph attention networks for aspect-level sentiment analysis},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-channel machine learning proxy for pseudo-two-dimensional model with enhanced extrapolation correction. <em>EAAI</em>, <em>163</em>, 113036. (<a href='https://doi.org/10.1016/j.engappai.2025.113036'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-based electrochemical models are essential for analyzing and predicting the performance of lithium metal batteries (LMBs), yet their high computational cost restricts their use in real-time applications. To overcome this limitation, a dual-channel agent model (DCAM) is proposed, which decouples the mapping between electrochemical parameters and discharge duration and voltage profile, serving as an efficient surrogate for the pseudo-two-dimensional (P2D) model. Unlike physics-constrained or purely data-driven approaches, DCAM does not rely on explicit physical equations but rather bypasses regions with poor generalization, enabling fast and accurate extrapolation from partial discharge data. Furthermore, a hybrid modeling framework is developed by embedding a multilayer perceptron (MLP) into the Butler–Volmer (B–V) kinetics, replacing the iterative Newton process and thereby improving computational efficiency. Experimental and simulation results demonstrate that the proposed framework accurately reproduces the P2D voltage behavior and achieves high-fidelity extrapolation and robustness under limited-data conditions.},
  archive      = {J_EAAI},
  author       = {Yue Cui and Yaxuan Wang and Shilong Guo and Liang Deng and Junfu Li and Lei Zhao and Zhenbo Wang},
  doi          = {10.1016/j.engappai.2025.113036},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113036},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-channel machine learning proxy for pseudo-two-dimensional model with enhanced extrapolation correction},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Recurrence plot and change quantile-based deep supervised and semi-supervised protection for transmission lines connected to photovoltaic plants. <em>EAAI</em>, <em>163</em>, 113034. (<a href='https://doi.org/10.1016/j.engappai.2025.113034'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional relays encounter difficulties in protecting transmission lines (TLs) connected to converter-based energy sources (CBESs) due to the influence of power electronics on fault characteristics. This article proposes a single-ended intelligent protection method for the TL segment between the grid and a Photovoltaic (PV) plant. The approach utilizes a Recurrence Matrix and an InceptionTime-based system to identify faults by using the mean change in quantiles of 3-phase currents. It determines the fault position and identifies the faulty phase. ReliefF feature selection is applied to extract the optimal quantile features. The scheme’s performance is assessed under abnormal conditions, including faults and capacitor and load-switching events, simulated in Power Systems Computer Aided Design/Electromagnetic Transients Program (PSCAD/EMTDC) on the Western System Coordinating Council (WSCC) 9-bus system, with various fault and switching parameters. The scheme is also validated on the New England IEEE 39-bus system and in presence of partially rated converters. Additionally, the validation of the proposed strategy takes into account various conditions, including double-circuit line configuration, noise, series compensation, high-impedance faults, current transformer (CT) saturation, evolving and cross-country faults, remote and local faults, as well as variations in PV capacity, sampling frequency, and data window size. To address label scarcity and improve generalization, semi-supervised learning paradigms including label spreading, label propagation, and self-training are integrated with the InceptionTime framework, enabling near-supervised performance with limited annotated fault data. The results demonstrate that the approach is effective in handling different system configurations and conditions, ensuring the protection of TLs connected to large PV plants.},
  archive      = {J_EAAI},
  author       = {Pallav Kumar Bera and Samita Rani Pani},
  doi          = {10.1016/j.engappai.2025.113034},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113034},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Recurrence plot and change quantile-based deep supervised and semi-supervised protection for transmission lines connected to photovoltaic plants},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Entity-relation enhanced bidirectional information fusion for relational triples extraction. <em>EAAI</em>, <em>163</em>, 113033. (<a href='https://doi.org/10.1016/j.engappai.2025.113033'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relational triple extraction refers to identifying triples consisting of entities and relations form unstructured texts. The existing studies usually adopt an unidirectional extraction strategy, which fails to fully explore the semantic information related to entities and relations. And they rely heavily on initial extraction results when conducting multi-step extraction. To address this issue, we propose a novel Entity-Relation Enhanced Bidirectional Information Fusion approach (ER-EBIF). Specifically, we adopt a bidirectional extraction strategy of ”entity-to-relation” and ”relation-to-entity” to identify triples. One branch extracts potential relations, then extracts entities associated with those relations. The other branch initially extracts the potential subjects and objects as well as subsequently extracts relations between pairs of entities consisting of subjects and objects. Moreover, the contextual information is enhanced with a self-attention mechanism by integrating the information of potential relations and potential entities to better exploit the semantic information of entities and relations. Extensive experimental results on various datasets show that ER-EBIF exhibits better performance than other baselines and effectiveness in addressing the issue of dependency on initial results in multi-step extraction.},
  archive      = {J_EAAI},
  author       = {Haoran Liao and Yuan Rong and Mingming Kong and Chao Zhang and Xianjun Tian and Vladimir Simic and Dragan Pamucar},
  doi          = {10.1016/j.engappai.2025.113033},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113033},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Entity-relation enhanced bidirectional information fusion for relational triples extraction},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Leveraging real-time supplement values decomposition and training strategy optimization for accurate wind power forecasting. <em>EAAI</em>, <em>163</em>, 113021. (<a href='https://doi.org/10.1016/j.engappai.2025.113021'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate wind power forecasting is crucial for grid security and efficient dispatch, but still faces challenges such as data leakage and lag in practical applications. Real-time decomposition (RTD) has been employed to address data leakage in decomposition-based wind power forecasting. However, the tail decomposed values of RTD often exhibit high noise and lag. Analysis shows that this tail deviation primarily arises from the lack of follow-up information, making the tail more susceptible to short-term fluctuations and random noise, which increases high-frequency noise and lag. To overcome this issue, this paper proposes a real-time supplement values decomposition (RTSD) method, i.e., group forecasting of subsequent values at the tail of the real-time series, supplement values and decomposition. Subsequently, the Kalman filter with optimized parameters (OKF) is applied for smoothing, balancing the requirements of single-step and multi-step forecasting. Considering that deep learning forecasting models for decomposed sub-series can adopt different training strategies, this study proposes three training strategies—independent, parallel and ensemble—and selects the optimal one through comparative analysis. Experimental results demonstrate that RTSD significantly reduces noise and lag in RTD, and the robustness of the proposed RTSD-OKF architecture and chosen training strategy is validated across various forecasting models and decomposition methods.},
  archive      = {J_EAAI},
  author       = {Zheyong Jiang and Mrutyunjaya Sahani and Sanjib Kumar Panda and Qingmei Tan and Jinxing Che and Xiukun Tan},
  doi          = {10.1016/j.engappai.2025.113021},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113021},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Leveraging real-time supplement values decomposition and training strategy optimization for accurate wind power forecasting},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Machine learning and CPU (central processing unit) scheduling co-optimization over a network of computing centres. <em>EAAI</em>, <em>163</em>, 113018. (<a href='https://doi.org/10.1016/j.engappai.2025.113018'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the rapidly evolving research on artificial intelligence (AI) the demand for fast, computationally efficient, and scalable solutions has increased in recent years. The problem of optimizing the computing resources for distributed machine learning (ML) and optimization is considered in this paper. Given a set of data distributed over a network of computing-nodes/servers, the idea is to optimally assign the CPU (central processing unit) usage while simultaneously training each computing node locally via its own share of data. This formulates the problem as a co-optimization setup to (i) optimize the data processing and (ii) optimally allocate the computing resources. The information-sharing network among the nodes might be time-varying, but with balanced weights to ensure consensus-type convergence of the algorithm. The algorithm is all-time feasible, which implies that the computing resource-demand balance constraint holds at all iterations of the proposed solution. Moreover, the solution allows addressing possible log-scale quantization over the information-sharing channels to exchange log-quantized data. For some example applications, distributed support-vector-machine (SVM) and regression are considered as the ML training models. Results from perturbation theory, along with Lyapunov stability and eigen-spectrum analysis, are used to prove the convergence towards the optimal case. As compared to existing CPU scheduling solutions, the proposed algorithm improves the cost optimality gap by more than 50%.},
  archive      = {J_EAAI},
  author       = {Mohammadreza Doostmohammadian and Zulfiya R. Gabidullina and Hamid R. Rabiee},
  doi          = {10.1016/j.engappai.2025.113018},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113018},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning and CPU (central processing unit) scheduling co-optimization over a network of computing centres},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physics-informed auto-encoder based on digital twin for rolling bearing fault diagnosis under imbalanced sample conditions. <em>EAAI</em>, <em>163</em>, 113017. (<a href='https://doi.org/10.1016/j.engappai.2025.113017'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the fault diagnosis of rolling bearings, the scarcity of fault samples results in far fewer fault data than healthy ones, leading to sample imbalance that negatively affects diagnostic accuracy. Generative neural networks can produce additional fault data, but they cannot fully ensure that the generated data capture bearing dynamics, thereby undermining reliability. This paper proposes a Physics-Informed Auto-Encoder based on Digital Twin (PIAE-DT) for interpretable data augmentation under imbalanced conditions. A dimensionless physical information module incorporating bearing dynamic characteristics was embedded into the Auto-Encoder, enabling identification of dynamic model parameters and improving interpretability by ensuring that each learned feature corresponds to a physically meaningful parameter. The identified parameters were mapped to a probability distribution, from which a fault data augmentation method in the digital twin space was developed through resampling to increase the diversity of augmented data. Furthermore, reconstructing vibration signals from these parameters enhanced the reliability of the augmented data, and the results verified the effectiveness of the physics-informed module. Finally, by applying PIAE-DT to identify dynamic parameters of known samples, fault data were augmented in the digital twin space and used to alleviate imbalance in diagnosis. The method was evaluated on both public and private datasets, achieving maximum diagnostic accuracies of 97.60 % and 99.86 %, and it outperforms other data augmentation methods.},
  archive      = {J_EAAI},
  author       = {Zhiwu Shang and Ziyu Wang and Cailu Pan and Wanxiang Li and Maosheng Gao},
  doi          = {10.1016/j.engappai.2025.113017},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113017},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physics-informed auto-encoder based on digital twin for rolling bearing fault diagnosis under imbalanced sample conditions},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A curriculum-guided and explainable reinforcement learning framework for fixed-wing unmanned aerial vehicle autopilots. <em>EAAI</em>, <em>163</em>, 113015. (<a href='https://doi.org/10.1016/j.engappai.2025.113015'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current artificial intelligence methods when used for autopilots often suffer from poor control stability and a lack of explainability. To address these challenges, this paper proposes a curriculum-guided and explainable reinforcement learning framework for fixed-wing unmanned aerial vehicle autopilots. First, a sequential proximal policy optimization algorithm is developed for autopilots’ decision-making; the designed coupled reward function refines the guidance strategy for action selection, significantly improving the control performance of autopilots. Second, to tackle sparse rewards' impact on algorithm convergence, a curriculum learning method based on difficulty coefficient matrices is introduced to effectively guide agents' training process. Third, instead of treating the policy as a “black box”, semantic-grouped Shapley additive explanations are proposed to explain the policy. Finally, the efficacy of the designed autopilot is rigorously tested by a high-fidelity simulator JSBSim. The results indicate that the autopilot can adapt to various waypoint tracking tasks while exhibiting strong policy explainability.},
  archive      = {J_EAAI},
  author       = {Yunxiao Lian and Ni Li and Pan Zhou and Ruiguang Hu and Changyin Dong},
  doi          = {10.1016/j.engappai.2025.113015},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113015},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A curriculum-guided and explainable reinforcement learning framework for fixed-wing unmanned aerial vehicle autopilots},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive hierarchical control of quadcopters via safe reinforcement learning from human demonstration. <em>EAAI</em>, <em>163</em>, 113013. (<a href='https://doi.org/10.1016/j.engappai.2025.113013'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hierarchical control framework is developed for quadcopters, enabling safe trajectory tracking by learning from human pilot demonstrations. The framework’s high-level motion planner uses dynamic movement primitives to learn a pilot’s intended trajectory, generating a similar but more efficient path. A low-level tracking controller then employs safe reinforcement learning to accurately track this path while actively avoiding obstacles. The stability of the control system is formally proven using a Lyapunov function. Hardware experiments validate the framework’s effectiveness, demonstrating successful tracking of complex, human-intended trajectories with a relative path length of over 96% while guaranteeing collision avoidance. This work presents a robust solution for intuitive and reliable human–robot interaction in complex environments.},
  archive      = {J_EAAI},
  author       = {Junkai Tan and Shuangsi Xue and Zihang Guo and Huan Li and Xiaodong Zheng and Hui Cao},
  doi          = {10.1016/j.engappai.2025.113013},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113013},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive hierarchical control of quadcopters via safe reinforcement learning from human demonstration},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Non-destructive printed circuit board layout verification using a deterministic diffusion-guided framework. <em>EAAI</em>, <em>163</em>, 113012. (<a href='https://doi.org/10.1016/j.engappai.2025.113012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-destructive Printed Circuit Board (PCB) layout verification is critical for ensuring microelectronics reliability, yet PCB X-ray images are degraded by serious artifacts resulting from surface-mounted components due to the complex structural distortions during computed tomography (CT) imaging, such as occlusion, metallic interference, and scattering, making them challenging to mitigate. This challenge remains largely unexplored with the only related method on bare PCBs degrading seriously when applied in this context. Stochastic diffusion models work poorly on structural artifacts and rely on huge resources requiring many epochs of training. Furthermore, it is impractical to obtain noisy and the corresponding clean image pairs in real-world PCB scenarios for model training. To address these challenges, this work presents the first systematic analysis of six factors degrading non-destructive PCB X-ray imaging and a deterministic diffusion-guided layout verification framework ( D2LVer ) is proposed for non-destructive PCB layout verification, reducing computational cost while improving segmentation performance. D2LVer employs a deterministic reverse diffusion-guided denoised feature extraction ( DDFE ) in a single forward-reverse diffusion cycle by directly predicting the posterior mean as denoised features, and aggregates them with the original noisy input for segmentation. DDFE eliminates the need for extensive training, reducing computational overhead by up to 80%. The overall framework D2LVer improves dice score by up to 9.33% over existing state-of-the-art.},
  archive      = {J_EAAI},
  author       = {Xue Wang and Deruo Cheng and Chai Kiat Yeo},
  doi          = {10.1016/j.engappai.2025.113012},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113012},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Non-destructive printed circuit board layout verification using a deterministic diffusion-guided framework},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semi-supervised image segmentation via selective self-ensembling and boundary uncertainty suppression. <em>EAAI</em>, <em>163</em>, 113011. (<a href='https://doi.org/10.1016/j.engappai.2025.113011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation plays a key role in many image-guided clinical applications and deep learning technology has proven effective for this task when sufficient labeled images are available. However, it is very time-consuming and labor-intensive to obtain adequate pixel-level image labels. To alleviate the scarcity of labeled images, we propose a novel semi-supervised segmentation method based on the available uncertainty-aware mean teacher (UAMT) framework by introducing two different strategies, i.e., selective self-ensembling (SSE) and boundary uncertainty suppression (BUS). The SSE dynamically selects multiple best student models across different training steps to update the teacher model's weights, while the BUS reduces boundary segmentation errors and improves the quantitative potential of loss functions through a unique uncertainty estimation function. With the two strategies, our proposed method was able to obtain promising segmentation performance with limited labeled images and abundant unlabeled ones. We trained and validated our proposed method by segmenting multiple objects from three public datasets (i.e., PROMISE, REFUGE, and RETA). Extensive experiments showed that our proposed method achieved better segmentation performance than the UAMT, along with the average Dice score (DSC) of 0.7990 for three different objects, and can compete with several existing semi-supervised methods (i.e., HCMT, SASSNet, and DTC).},
  archive      = {J_EAAI},
  author       = {Xiaoguo Yang and Yabo Wu and Shouxiang Ni and Hongmei He and Hao Zhang and Yu Chen and Ke Yan and Chuoying Tan and Xiaomin Xu and Wencan Wu and Quanyong Yi and Lei Wang},
  doi          = {10.1016/j.engappai.2025.113011},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113011},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semi-supervised image segmentation via selective self-ensembling and boundary uncertainty suppression},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A camera-light detection and ranging sensor online extrinsic calibration network based on mamba-like linear attention mechanism for unstructured off-road environments. <em>EAAI</em>, <em>163</em>, 113010. (<a href='https://doi.org/10.1016/j.engappai.2025.113010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion of heterogeneous data from cameras and Light Detection and Ranging (LiDAR) sensors is essential for robust and accurate environmental perception in robotics and autonomous vehicles. Accurate extrinsic calibration between the camera and LiDAR is a prerequisite for fusing camera images with three-dimensional (3D) point cloud data, ensuring spatial alignment between the two data modalities. The existing methods have focused primarily on the online calibration of camera-LiDAR systems in structured urban environments, while achieving accurate online calibration in unstructured, feature-degraded off-road settings remains a significant challenge. To address this, we propose a Mamba-Like Linear Attention Network (MLLANet) for camera-LiDAR extrinsic online calibration on the basis of the mamba-like linear attention model. A multilevel feature extraction module leveraging mamba-like linear attention is constructed to enhance the network's ability to represent complex terrain features. A multiscale feature fusion and matching module is then constructed to accurately perceive feature differences between two-dimensional (2D) images and LiDAR reprojected depth maps. Moreover, a hybrid loss function incorporating Huber depth map loss is designed to effectively suppress the influence of LiDAR point cloud outliers and accelerate network convergence in complex scenarios. Extensive experiments are conducted on one urban road dataset and two off-road datasets to validate the effectiveness of the proposed calibration network. The proposed method, MLLANet, achieves average translation errors of 0.289 cm (cm), 2.161 cm, and 1.333 cm and average angular errors of 0.012° (°), 0.057°, and 0.192°, respectively, on these three datasets, outperforming most existing learning-based calibration methods.},
  archive      = {J_EAAI},
  author       = {Lang Wu and Ren Xiao and Huayan Pu and Gang Wang and Mingliang Zhou and Jun Luo},
  doi          = {10.1016/j.engappai.2025.113010},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113010},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A camera-light detection and ranging sensor online extrinsic calibration network based on mamba-like linear attention mechanism for unstructured off-road environments},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FEAN: A fragments embedding and aligning network for image-text matching. <em>EAAI</em>, <em>163</em>, 113009. (<a href='https://doi.org/10.1016/j.engappai.2025.113009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most recent image-text matching methods use fragments alignment structures to achieve cross modal interaction. Although they compensate for the lack of cross modal interaction caused by overall embedding, the accuracy of image-text matching is compromised by the cross modal semantic gap and redundant alignment. To address these issues, we propose a Fragments Embedding and Aligning Network (FEAN) to achieve accurate image-text matching, which focuses on the representation of global and local image-text features and their similarity. Specifically, we embed local image and textual features into fragments to obtain global image and textual features representations and global similarity scores, and use cross modal weight calculation to obtain fragments aligned local image and textual features and local similarity matrices, in order to mitigate the cross modal semantic gap. To avoid redundant alignment in image and textual fragments, a Similarity Pooling (SP) strategy is proposed to aggregate global similarity scores and local similarity matrices. In addition, to compensate for the missing contextual semantic information on the image region features, we add the Position Weight Feature Reinforcement (PWFR) module before embedding alignment to achieve consistency with the text semantic information. Extensive experiments on two publicly available datasets for image-text matching, Flickr30K and MSCOCO, have shown that our fragments embedding and aligning network achieve the best R@1 and RSUM values in bidirectional matching with optimal accuracy.},
  archive      = {J_EAAI},
  author       = {Xianlun Tang and Lin Jiang and Yu Xia and Wuquan Deng and Bo Tang and Tianyu Xiang and Hao Zhu},
  doi          = {10.1016/j.engappai.2025.113009},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113009},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FEAN: A fragments embedding and aligning network for image-text matching},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spatial-spectral patch-based multimodal hyperspectral-X data fusion classification network. <em>EAAI</em>, <em>163</em>, 113008. (<a href='https://doi.org/10.1016/j.engappai.2025.113008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous advancement of remote sensing (RS) technology, the integration of hyperspectral (HS) and X-modality data, such as multispectral (MS), light detection and ranging (LiDAR), and synthetic aperture radar (SAR), is demonstrated to significantly improve the accuracy of land use/land cover classification, which is of great practical significance for large-scale land resource management, urban planning, and environmental monitoring. However, this process still encounters numerous challenges due to disparities in imaging mechanisms, resolutions, and content. Currently, traditional spatial patch-based methods are constrained by the challenge of coupling spatial and spectral data when processing HS images, which hinders the effective extraction of modality-specific information. Moreover, existing multimodal fusion methods lack efficient mechanisms to handle both homogeneous and heterogeneous RS data, thereby limiting their adaptability to complex and diverse feature scenes. To address these issues, a network named spatial–spectral patch-based multimodal hyperspectral-X data fusion classification network (S 2 PNet) is proposed for multimodal data classification. A novel spectral patch construction (SPC) method is designed to isolate modality-specific information from HS data while completely removing spatial information to capture spectral features more precisely. Additionally, the multi-scale differential convolution (MSDC) is designed to efficiently extract the modality-shared information of HS and X-modality for the characteristics of multimodal RS data. To tackle the common issue of sample imbalance in RS datasets, the equiangular tight frame (ETF) mechanism is introduced into the transformer architecture, which improves the robustness and adaptability of the classification task at the overall framework design level. The experimental results on benchmark datasets containing combinations of HS-MS/LiDAR/SAR demonstrate that S 2 PNet exhibits significant superiority and advancement in land cover classification tasks, highlighting both its methodological innovation and its potential for real-world RS applications. Compared with state-of-the-art methods, the proposed S 2 PNet achieves improvements in overall accuracy of 2.51%, 0.02%, 0.18%, and 0.07% on the MUUFL, Trento, Houston2013, and Augsburg datasets, respectively.},
  archive      = {J_EAAI},
  author       = {Haizhu Pan and Bopeng Ren and Xuan Li and Liguo Wang and Haimiao Ge and Cuiping Shi and Moqi Liu},
  doi          = {10.1016/j.engappai.2025.113008},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113008},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Spatial-spectral patch-based multimodal hyperspectral-X data fusion classification network},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Versatile topology optimization framework using embedded self-improving neural network. <em>EAAI</em>, <em>163</em>, 113007. (<a href='https://doi.org/10.1016/j.engappai.2025.113007'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topology optimization (TO) is a powerful design tool in the structural optimization field. Still, it is hindered by the heavy computational burden of solving state variables via the finite element method (FEM) derivation process. To address this high computational cost, we propose a pioneering method that intertwines a self-improving convolutional neural network (CNN) with the conventional topology optimization process. This method is referred to convolutional neural network embedded topology optimization framework (CNN-TO). Specifically, the CNN is embedded into the optimization procedure to learn the finite element derivation process, and it autonomously determines when to conduct prediction based on the quality of the currently generated data. By incorporating this adaptive learning mechanism, CNN-TO progressively improves its prediction capability and significantly reduces computational cost. This work directly applies CNN-TO to diverse optimization problems across heat transfer and fluid mechanics fields. Compared to the conventional method that runs FEM derivation in each iterative step, it achieves faster convergence with fewer steps, over 50 % of which are expedited by CNN's predictions. Notably, the prediction errors of the CNN instead aid in exploring augmented optimization potential, leading to smaller objective function values. In general, CNN-TO is expected to be a potentially efficient alternative to the conventional method due to its higher efficiency and further optimization.},
  archive      = {J_EAAI},
  author       = {Min Liang Wang and Dong Hee Kang and Wonoh Lee and Jihoon Jeong and Hyun Wook Kang},
  doi          = {10.1016/j.engappai.2025.113007},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113007},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Versatile topology optimization framework using embedded self-improving neural network},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hierarchical metering data imputation with multi-view learning for accurate electricity consumption prediction. <em>EAAI</em>, <em>163</em>, 113006. (<a href='https://doi.org/10.1016/j.engappai.2025.113006'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate electricity consumption prediction enables energy providers to optimize resource allocation, enhance grid stability, and meet fluctuating demands efficiently, with applications spanning across smart grids, energy management systems, and electricity markets. However, this process relies on large amounts of complete meter data, which may be missing or corrupted for various reasons during data collection. This study proposes a novel multi-view learning-based imputation model to deal with missing data in a hierarchical metering system. In this study, the hierarchical system is analyzed using two views to constitute a multi-view dataset, where the master-node view reflects the overall electricity consumption and the sub-node view provides detailed electricity consumption information. Unlike traditional single-view methods, the master-node view is developed to generate complementarity information for effective imputation of sub-nodes. Moreover, a feature alignment-based cross-view mapping is proposed to exploit the alignment relationship between views, and the adaptive multi-view graph learning is introduced to capture the distribution structure of the electricity consumption at different time points. Experimental results on real datasets from a ceramic factory show that our proposed method outperforms the other compared methods. In the prediction after imputation, when the missing rate is 50%, 70%, and 90%, the average performance improvement of our proposed method is about 10.08% in Root Mean Square Error (RMSE) and 11.9% in Mean Absolute Error (MAE) across all datasets.},
  archive      = {J_EAAI},
  author       = {Zitan Xie and Zuyuan Yang and Weifeng Zhong and Shengli Xie},
  doi          = {10.1016/j.engappai.2025.113006},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113006},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical metering data imputation with multi-view learning for accurate electricity consumption prediction},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Prediction of hydrocarbon adsorption–desorption dynamics in activated carbon columns using long short-term memory networks for intelligent removal systems. <em>EAAI</em>, <em>163</em>, 113005. (<a href='https://doi.org/10.1016/j.engappai.2025.113005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hydrocarbon (HC) emissions from the petrochemical industry pose environmental and health risks, as HCs are precursors for the generation of fine particulate matter and have carcinogenic effects. Meeting increasingly stringent environmental regulations requires accurate prediction of adsorption–desorption dynamics and effective optimization of industrial emission control systems. This study develops and evaluates long short-term memory (LSTM) models to predict HC adsorption–desorption behavior in activated carbon columns. Univariate and multivariate LSTM models were compared to assess how HC concentration and flow rate influence system dynamics. The models were trained and validated with experimental data collected at varying inlet concentrations and tested on an independent dataset to evaluate generalizability. The multivariate LSTM model achieved superior performance for system-wide dynamics, reaching an R 2 of 0.9336 for HC concentration during desorption. Both models predicted flow rate with high accuracy; however, the univariate model more effectively predicted HC concentration during adsorption (R 2 = 0.7451), underscoring its suitability for single-parameter prediction. Confusion matrix analysis further demonstrated the robust cycle identification capabilities of both approaches (accuracy >99 %), with lower misclassification rates for the multivariate model. Implementation of these models in a proposed parallel adsorption–desorption system confirmed their practical value for real-time process optimization. The LSTM framework enables dynamic adjustment of column transitions and cycle timing, while facilitating early detection of performance degradation. This approach to process modeling and control proposed in the present study thus contributes to more intelligent, efficient, and sustainable industrial emission management practices based on adaptable model selection tailored to specific applications and computational constraints.},
  archive      = {J_EAAI},
  author       = {Mita Nurhayati and Hye-Jin Lee and Jung Eun Park and Bum Ui Hong and Ho Geun Kang and Sangsik Kim and Sungyun Lee},
  doi          = {10.1016/j.engappai.2025.113005},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113005},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prediction of hydrocarbon adsorption–desorption dynamics in activated carbon columns using long short-term memory networks for intelligent removal systems},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semantic-driven seasonal data classification: An artificial intelligence-enabled cost-effective storage system. <em>EAAI</em>, <em>163</em>, 113004. (<a href='https://doi.org/10.1016/j.engappai.2025.113004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern storage systems face significant challenges in balancing energy costs and performance, especially for text-rich workloads (e.g., e-commerce logs, social media archives). Traditional frequency-based classification methods fail to exploit semantic patterns in textual metadata, leading to suboptimal resource allocation. In this paper, we propose a novel deep learning-method based on Bidirectional Encoder Representations from Transformers-Recurrent Convolutional Neural Networks (BERT-RCNN) to extract seasonal features from data for classification, enabling cost-effective storage management. Our approach addresses the limitations of traditional frequency-based classification by incorporating semantic features from data text. Additionally, we explore the long-period seasonal features embedded within the text, offering a new approach for multi-feature classification. To evaluate the practical impact of our method, we developed a cost module within CloudSimDisk to simulate storage system operating costs. By constructing models for energy consumption and operating costs and generating real-world workloads from Baidu Index data, we implement and test our solution. Experimental results show that the BERT-RCNN model outperforms traditional K-means and other deep learning methods, reducing energy consumption by 3.90%–5.69%, saving operational costs by 3.62%–6.13%, and shortening response time by 15.12%–26.09%.},
  archive      = {J_EAAI},
  author       = {Zhu Yuan and Xueqiang Lv and Yunchao Gong and Ping Xie and Xiao Qin and Xindong You},
  doi          = {10.1016/j.engappai.2025.113004},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113004},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semantic-driven seasonal data classification: An artificial intelligence-enabled cost-effective storage system},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Ranking based on average and ideal solution method for stakeholder engagement in building energy retrofitting. <em>EAAI</em>, <em>163</em>, 113003. (<a href='https://doi.org/10.1016/j.engappai.2025.113003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy retrofitting of residential buildings remains a pivotal strategy for reducing operational costs, curbing greenhouse gas emissions, and enhancing occupant well-being. Yet, existing multi-criteria decision-making approaches can struggle to capture both the complexity of technical trade-offs and the diversity of stakeholder viewpoints. In response, this paper proposes a novel framework, the ranking based on average and ideal solution (RAIS) method that addresses these challenges in a systematic and transparent manner. RAIS begins by combining subjective criterion weights, obtained through the rank order centroid (ROC) technique, with objective weights calculated via the logarithmic percentage change-driven objective weighting (LOPCOW) method. These weights are then fused using the Aczél–Alsina operator, ensuring that neither expert opinion nor data-driven measures exclusively dictate the outcome. Subsequently, each retrofit alternative is evaluated against a dual benchmark consisting of a weighted average solution and an ideal solution, thereby distinguishing retrofits that deliver high performance without deviating too far from conventional practice. This step reveals which options offer compelling benefits across cost, environmental impact, occupant comfort, and policy alignment factors that often compete in retrofit decisions. Through a residential case study, we demonstrate how RAIS can illuminate hidden opportunities, guiding decision-makers towards strategies that are simultaneously innovative and feasible. The findings underscore the method’s ability to reconcile conflicting priorities, offering a rigorously tested, adaptable tool for stakeholders. Ultimately, RAIS lays the groundwork for more nuanced retrofitting models that accommodate lifecycle analysis, equity considerations, and evolving regulatory contexts, all while preserving the clarity and balance central to robust decision-making.},
  archive      = {J_EAAI},
  author       = {Hafiz Muhammad Athar Farid and Shamaila Iram and Richard Hill and Hafiz Muhammad Shakeel and Vladimir Simic},
  doi          = {10.1016/j.engappai.2025.113003},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113003},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ranking based on average and ideal solution method for stakeholder engagement in building energy retrofitting},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Parameter identification for nonlinear hammerstein models with stacked sparse autoencoder network. <em>EAAI</em>, <em>163</em>, 113002. (<a href='https://doi.org/10.1016/j.engappai.2025.113002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel parameter identification method is addressed for Hammerstein nonlinear model with stacked sparse autoencoder (SSAE) network. The Hammerstein model presented is composed of a nonlinear block and a linear dynamic block, in which the nonlinear block is modeled by a SSAE network, and the linear dynamic block is established by an autoregression moving average model with exogenous input (ARMAX) model. To estimate the Hammerstein model parameters, step input excitation is used to decouple the nonlinear block from the linear block. Firstly, to identify the ARMAX model parameters, the multi-innovation and recursive extended theories are introduced, then a multi-innovation recursive least squares (MI-RELS) method is proposed, which improves parameter identification accuracy since the current data and past data information are utilized at each recursive computation. Secondly, parameters update of the SSAE network are implemented by layer-wise pre-training process and fine-tuning process, further employing the greedy algorithm and back propagation method to update weight and bias of the SSAE network. The simulation comparison results in numerical case and wind power systems are presented to verify that the feasibility of the developed Hammerstein model identification method.},
  archive      = {J_EAAI},
  author       = {Feng Li and Liexin Song and Tianhu Wang and Ranran Liu},
  doi          = {10.1016/j.engappai.2025.113002},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {113002},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Parameter identification for nonlinear hammerstein models with stacked sparse autoencoder network},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Vibration mechanism driven discrete wavelet hybrid attention weighted transfer network for partial domain fault diagnosis of gearboxes under data scarcity. <em>EAAI</em>, <em>163</em>, 112994. (<a href='https://doi.org/10.1016/j.engappai.2025.112994'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven intelligent fault diagnosis methods play a vital role in maintaining safe and reliable operation of gearboxes. Currently, some simulation data-driven transfer learning methods have been developed to achieve gearboxes fault diagnosis under the scarcity of high-quality labeled data. However, these methods still have problems such as insufficient domain-invariant feature extraction capabilities and negative transfer caused by large discrepancies between simulation and measured data, which poses challenges to their deployment in real-world industrial environments. To address these challenges, a vibration mechanism driven discrete wavelet hybrid attention weighted transfer network (DWAWTN) is proposed for partial domain fault diagnosis of gearboxes. Firstly, a vibration signal model that can reflect the gear failure vibration response mechanism is established, which can generate simulation data of different fault types. Secondly, a hybrid attention-guided multi-scale discrete wavelet convolutional network is proposed to extract domain-invariant features of simulation and measured data, which dynamically focuses on the multi-resolution fault features after wavelet decomposition from the channel and spatial dimensions. Then, a domain adaptation method combining the maximum likelihood weight estimation strategy and pseudo-label self-learning technology is constructed, which can not only suppress the negative transfer effect of outlier classes data in the source domain, but also reduce the uncertainty of the prediction of measured target data. Finally, comprehensive experimental verification and analysis are carried out on two gearbox datasets. Experimental results show that DWAWTN outperforms other compared methods in diagnostic performance.},
  archive      = {J_EAAI},
  author       = {Peng Zhu and Baoping Tang and Lei Deng and Jing Wei and Zihao Li and Qikang Li},
  doi          = {10.1016/j.engappai.2025.112994},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112994},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Vibration mechanism driven discrete wavelet hybrid attention weighted transfer network for partial domain fault diagnosis of gearboxes under data scarcity},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Soft likelihood-based multi-source fusion with reliability modeling and optimization under Dempster–Shafer theory. <em>EAAI</em>, <em>163</em>, 112993. (<a href='https://doi.org/10.1016/j.engappai.2025.112993'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-source data fusion plays a pivotal role in modern intelligent systems such as target recognition and fault diagnosis, where Dempster–Shafer theory (DST) is widely adopted for reasoning under uncertainty. However, conventional DST-based rules can suffer significant performance degradation when handling highly conflicting evidence. This paper presents a fusion framework that combines structured reliability modeling with a soft likelihood aggregation scheme. Source similarity is quantified through constrained nonlinear optimization solved by the sequential least squares programming (SLSQP) algorithm, while support degrees measure the overall alignment of each source with all others. These two measures are integrated to form reliability weights, which are then used to compute ordered weighted average (OWA) weights, replacing the conventional difference-based computation in existing methods. Final fusion is performed in a single step by combining the normalized evidence using an OWA-based soft likelihood function, enabling more stable and flexible probabilistic inference than conventional multiplicative rules. Extensive experiments on controlled conflict scenarios, the Iris dataset, and real-world applications demonstrate that the proposed method consistently improves target recognition accuracy by up to 0.14 percentage points over the state-of-the-art (99.12% vs. 98.98%) and enhances fault diagnosis reliability under extreme conflict. These results highlight the framework’s reliability and adaptability, making it well-suited for high-stakes decision-making tasks in uncertain environments.},
  archive      = {J_EAAI},
  author       = {Yangbing Lu and Weina Zhu},
  doi          = {10.1016/j.engappai.2025.112993},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112993},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Soft likelihood-based multi-source fusion with reliability modeling and optimization under Dempster–Shafer theory},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Application of machine learning techniques for predicting grid positions and values of geotechnical properties. <em>EAAI</em>, <em>163</em>, 112992. (<a href='https://doi.org/10.1016/j.engappai.2025.112992'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance the understanding of the spatial characteristics of geotechnical properties and improve the reliability of analysis, various methods are being proposed in the field of geostatistics. This study aims to verify whether machine learning techniques can perform spatial predictions of geotechnical properties. Both the geotechnical property values within the grid and the grid locations themselves are predicted using machine learning techniques with gaussian process regression (GPR), K-nearest neighbors (KNN), random forest (RF). Six different geotechnical properties are measured at 23 specific grid locations, and the values for the remaining grids are inferred by applying oversampling algorithms of synthetic minority over-sampling technique (SMOTE), and adaptive synthetic sampling (ADASYN). The amplified values are assigned to grid coordinates using regression algorithms. To improve reliability, a method is proposed that combines the input of a large amount of grid data with interpolation techniques. The predicted values for all grids are used to calculate the safety factor, an index that represents slope stability. When compared with the safety factors calculated using kriging—a geostatistical interpolation method—the errors are found to be nearly zero. Therefore, this study demonstrates that machine learning techniques can predict the spatial distribution of geotechnical properties and could potentially serve as an alternative to the kriging method.},
  archive      = {J_EAAI},
  author       = {Junghee Park and Hyung-Koo Yoon},
  doi          = {10.1016/j.engappai.2025.112992},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112992},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Application of machine learning techniques for predicting grid positions and values of geotechnical properties},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing data-driven three-way decision models for incomplete multiscale data: Integrating rough set theory with circular pythagorean fuzzy rough information for advanced risk assessment. <em>EAAI</em>, <em>163</em>, 112990. (<a href='https://doi.org/10.1016/j.engappai.2025.112990'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of Industry 5.0 brings unprecedented challenges and complexities in transportation and mobility systems, demanding robust and adaptive risk assessment frameworks. Traditional rough set theory examines how decision-makers respond to risks based on psychological behaviors and preferences, while three-way decision (3-WD) theory provides a structured approach to managing uncertainty through acceptance, rejection, or deferment actions. However, current methods often struggle with incomplete, multiscale data and vague failure information. In response, this study introduces a novel data-driven 3-WD model that integrates rough set theory (RST) with circular Pythagorean fuzzy sets (Cir-PyFSs) to handle missing utility values and ambiguous information in high-stakes environments. Cir-PyFSs capture membership, non-membership, and radius information, offering enhanced flexibility and precision in modeling uncertainty. The proposed model incorporates decision-theoretic rough sets (DTRSs) with a relative loss function framework, effectively addressing unexpected uncertainties and cost-sensitive decisions. To demonstrate its applicability, we present a multi-attribute decision-making (MADM) model based on newly developed operators within Cir-PyFSs settings. Our approach is applied to a real-world transportation and mobility scenario, evaluating the risks and impacts associated with Industry 5.0 adoption. The findings reveal that the proposed model provides a powerful and practical tool for advanced risk assessment, enabling Industry leaders and policymakers to make informed, resilient decisions in rapidly evolving industrial landscapes.},
  archive      = {J_EAAI},
  author       = {Muhammad Kamran and Qingyu Zhang and Chiranjibe Jana and Muhammad Tahir and Nikola Ivkovic and Dragan Pamucar},
  doi          = {10.1016/j.engappai.2025.112990},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112990},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing data-driven three-way decision models for incomplete multiscale data: Integrating rough set theory with circular pythagorean fuzzy rough information for advanced risk assessment},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep learning approach for short-term entry passenger flow forecasting in urban rail transit stations. <em>EAAI</em>, <em>163</em>, 112989. (<a href='https://doi.org/10.1016/j.engappai.2025.112989'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In short-term passenger flow forecasting for urban rail transit, Automatic Fare Collection (AFC) data serves as a crucial carrier reflecting the characteristics of passenger flow variations. Existing short-term passenger flow prediction methods primarily rely on historical time-series data from individual stations, yet similar passenger flow trends may exist across different stations. To comprehensively capture the passenger flow characteristics of various station types and enhance the interpretability of predictions, this paper proposes a CEEMDAN-TCAN (Complete Ensemble Empirical Mode Decomposition with Adaptive Noise and Temporal Convolutional Attention Network) method based on two-step clustering. First, a two-step fuzzy k -means (F k M) approach is employed to perform spatial feature extraction based on land use patterns and passenger flow characteristics around metro stations, thereby providing a more generalized dataset for station-level predictions. Subsequently, CEEMDAN is applied to deeply extract multi-scale temporal features of passenger flow, improving the prediction accuracy of station entry passenger volumes by addressing the automatic adjustment of non-stationary time-series data. Next, an encoder-decoder framework is adopted for station-level passenger flow prediction, and the model's rationality is validated using attention score heatmaps at different step lengths and partial autocorrelation coefficients. To verify the effectiveness of the proposed method and model, extensive experiments are conducted using historical passenger flow data from Suzhou Metro stations. The results demonstrate that the proposed model achieves 1.7 %–36.9 % higher prediction accuracy compared to other classical models while reducing average training time by over 55.8 %.},
  archive      = {J_EAAI},
  author       = {Shejun Deng and Jiayang Du and Jun Zhang and Xiaoying Wang},
  doi          = {10.1016/j.engappai.2025.112989},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112989},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning approach for short-term entry passenger flow forecasting in urban rail transit stations},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Optimizing location selection for foreign trade intelligence centres using spherical fuzzy methods. <em>EAAI</em>, <em>163</em>, 112988. (<a href='https://doi.org/10.1016/j.engappai.2025.112988'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This investigation focuses on a vital research topic that has significant research gaps in the literature, such as the selection of locations for foreign trade intelligence centres, which have a critical role in a country's development, a country's development and export capabilities. Previous studies have primarily addressed site selection in the context of manufacturing industries and retail outlets, focusing on strategies, and often ignored the unique requirements of foreign trade intelligence operations. This study solves the problem by considering the requirements of an innovative and integrated decision-making approach developed in the context of foreign trade intelligence centres, while at the same time filling the relevant research gap. The proposed model provides a mathematical form by extending Delphi management with spherical fuzzy sets to highlight influential evaluation criteria, as well as providing an integrated decision-making model extended with spherical fuzzy numbers to assess alternatives and determine rankings. Ten primary evaluation criteria are established to present a set of criteria for the authorities. The importance level of the criteria and assessments of alternatives for these criteria are aggregated spherical fuzzy numbers. A mixed integer non-linear multi-objective mathematical model is developed for the previous stages' outputs and different parameters. The results of the empirical application in Turkey show that Mersin is the most suitable alternative due to its attractive government incentives and strong commercial vitality compared to other options. The robustness checks verified the model's validity and reliability, proving a consistent decision-making tool for decision-makers and policymakers in the context of systematic decision-making.},
  archive      = {J_EAAI},
  author       = {Ömer Faruk Görçün and Sinan Çizmecioğlu and Esra Boz and Ahmet Çalık},
  doi          = {10.1016/j.engappai.2025.112988},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112988},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing location selection for foreign trade intelligence centres using spherical fuzzy methods},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A transformer-based approach for source code classification for heterogeneous device mapping. <em>EAAI</em>, <em>163</em>, 112987. (<a href='https://doi.org/10.1016/j.engappai.2025.112987'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization of code allocation for heterogeneous architectures, such as Central Processing Units (CPUs) and Graphics Processing Units (GPUs), remains challenging due to the limitations of traditional compiler heuristics and existing machine learning approaches. This paper presents a systematic evaluation of Large Language Models (LLMs) for classifying source code execution targets in heterogeneous device mapping. We fine-tune and compare six models: Distilled Bidirectional Encoder Representations from Transformers (DistilBERT), Code Bidirectional Encoder Representations from Transformers (CodeBERT), Code Bidirectional Encoder Representations from Transformers with RoBERTa (Robustly Optimized BERT Pretraining Approach) architecture (CodeBERTa), CodeT5, jTrans, and Deep Learning Low Level Virtual Machine (DeepLLVM), trained on Open Computing Language (OpenCL) kernels. Results show that general-purpose LLMs achieve up to 92.8% accuracy, matching or surpassing code-specific models, and outperform the previous state of the art (DeepLLVM) by up to 5%. Our findings indicate that LLMs pre-trained on general text are not necessarily inferior to code-specialized models, with tokenizer design and pre-training objectives impacting performance more than domain specialization. These results demonstrate the effectiveness of Transformer-based LLMs as a state-of-the-art approach for source code classification in heterogeneous computing contexts.},
  archive      = {J_EAAI},
  author       = {Marco Siino and Emanuele Parisi and Francesco Barchi and Andrea Acquaviva and Andrea Bartolini},
  doi          = {10.1016/j.engappai.2025.112987},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112987},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A transformer-based approach for source code classification for heterogeneous device mapping},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Large-scale stochastic production decision-making for coupled economy-environment-energy systems in sustainable industrial processes under uncertainty: A data-driven two-stage multi-objective optimization framework. <em>EAAI</em>, <em>163</em>, 112976. (<a href='https://doi.org/10.1016/j.engappai.2025.112976'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale complex industrial processes feature highly coupled production environments and complex dynamic unit operations, hindering the low-carbon decision optimization under uncertainty and ultimately limiting production schemes’ flexibility and reliability. Accordingly, this paper develops a data-driven two-stage stochastic optimization framework considering the economic-environment-energy coupling effects to support sustainable production decision-making under uncertainty. Specifically, a machine learning-assisted economic-environment-energy coupling assessment method is proposed to accurately track economic, environmental, and energy footprints. Subsequently, a large-scale multi-objective production optimization model based on the economic-environment-energy assessment mechanism is established, incorporating a carbon tax scenario to efficiently obtain optimal low-carbon production schemes. Additionally, given that existing production optimization methods generally neglect the impact of carbon tax uncertainty, a two-stage stochastic programming framework is developed to enhance the flexibility of the production systems. The first stage implements a deterministic multi-objective optimization model to obtain the baseline production schemes. The second stage builds upon this and employs data-driven techniques for intelligent identification of carbon tax scenarios, deriving their probability distributions to optimize production decisions under uncertainty, thereby enabling dynamic adjustments to production structures and material flows. A case study applying the proposed model and methods to an actual integrated refinery-petrochemical production site demonstrates that the proposed approach can identify plant-wide carbon reduction opportunities while significantly improving economic performance. Specifically, the approach leads to an 8.5% reduction in production costs and a 7% improvement in emissions assessment accuracy. The proposed method exhibits notable superiority in improving the model’s adaptability to policy fluctuations and in reinforcing the flexibility of the optimization schemes, which collectively provide reliable decision support for efficient resource utilization and sustainable development of industrial processes under uncertain environments.},
  archive      = {J_EAAI},
  author       = {Tingwei Zhang and Weimin Zhong and Shuai Tan and Feifei Shen and Yurong Liu and Xin Peng},
  doi          = {10.1016/j.engappai.2025.112976},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112976},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Large-scale stochastic production decision-making for coupled economy-environment-energy systems in sustainable industrial processes under uncertainty: A data-driven two-stage multi-objective optimization framework},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). QFTD: An efficient quantum federated learning for transformer fault diagnosis with minimal gated unit in smart grid. <em>EAAI</em>, <em>163</em>, 112974. (<a href='https://doi.org/10.1016/j.engappai.2025.112974'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum federated learning (QFL), as an emerging quantum algorithm, has been initially applied in fields such as healthcare and intelligent transportation. It can achieve efficient model training while protecting the privacy of power data. It is an excellent solution for addressing the challenges of data decentralization and privacy in fault diagnosis. To further enhance the generalization and efficiency of QFL, we propose an efficient quantum federated learning algorithm for power transformer fault diagnosis with the minimal gated unit (QFTD) in the smart grid, which is an initial application of QFL to power transformer fault diagnosis in the smart grid. We integrate a quantum orthogonal convolutional neural network with the classical minimal gated unit, forming a quantum minimal gated orthogonal convolutional neural network (QMOCNN) as the local model of QFTD. By adding the quantum orthogonal layer to the quantum convolutional neural network, the generalization ability and stability of the model improve. Experimental results demonstrate that QMOCNN achieves an accuracy of 99.48% in power transformer fault diagnosis within the smart grid, exhibiting superior convergence speed and classification accuracy compared to other methods. After introducing the federated learning framework, the QFTD can also achieve an accuracy of 95.83%. The experiment on the three types of quantum circuit noise proves that QFTD has good performance in noise resistance. Our work represents a significant exploration and advancement in applying quantum algorithms within the realm of fault diagnosis in power systems.},
  archive      = {J_EAAI},
  author       = {Guodong Li and Junjie Luo and Qingle Wang and Lin Liu and Chunyan Wei and Huawei Wang and Zhichao Zhang},
  doi          = {10.1016/j.engappai.2025.112974},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112974},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {QFTD: An efficient quantum federated learning for transformer fault diagnosis with minimal gated unit in smart grid},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-label learning research on joint ensemble strategies for predicting adverse prognosis in patients with coronary heart disease. <em>EAAI</em>, <em>163</em>, 112973. (<a href='https://doi.org/10.1016/j.engappai.2025.112973'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Major Adverse Cardiac Events (MACE), as composite endpoints in coronary heart disease (CHD) prognosis research, present a conflict between multidimensional prediction needs and the limitations of single-label modeling. While the Ensemble Multi-Label classifier (EMLC) enables simultaneous multi-outcome predictions, medical data complexity introduces dual challenges: multi-label feature selection impacts model performance, and existing methods overlook label correlations. This study proposes two innovations: First, the Dynamic Weighted Multi-Label Ensemble Feature selection (DWML-EFS) algorithm integrates information-theoretic approaches to reduce computational costs while enhancing feature selection efficiency. Second, the Multi-Label Linearly Weighted Stacked Ensemble (MLLWSE) model employs accelerated proximal gradient optimization and regularization to balance structural simplicity with predictive power, while capturing interdependencies among base classifiers. Experiments demonstrated superior performance over state-of-the-art methods on both public datasets and real-world CHD data. By incorporating SHapley Additive exPlanations (SHAP) and Local Interpretable Model-agnostic Explanations (LIME) interpretability techniques, the framework achieves synergistic optimization of precision and explainability in CHD multi-label prognosis prediction. These advancements address the critical complexities of multi-label learning in medical data, delivering an efficient and interpretable solution for MACE prediction. Importantly, this framework can identify patient groups at risk of adverse outcomes and provide prediction tools with practical value for clinical decision-making.},
  archive      = {J_EAAI},
  author       = {Hong Yang and Jing Li and Yanyan Dai and Leyi Zhang and Jing Tian and Yanbo Zhang},
  doi          = {10.1016/j.engappai.2025.112973},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112973},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-label learning research on joint ensemble strategies for predicting adverse prognosis in patients with coronary heart disease},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A new profile-agnostic sequential parametrisation method for extrusion die in transformer-based surrogate model. <em>EAAI</em>, <em>163</em>, 112972. (<a href='https://doi.org/10.1016/j.engappai.2025.112972'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aluminium extrusion is widely used in manufacturing engineering components for construction, packaging, and transportation, yet its die design remains heavily dependent on time-consuming and costly trial-and-error methods informed by empirical knowledge. This research aims to expedite the most time-intensive phase, Finite Element (FE) validation phase, by proposing a sequential parametrisation of extrusion die and developing a Transformer-based surrogate model to predict the material flow speed deviation. This work consists of two distinct contributions. First, a novel sequential representation for extrusion dies is introduced, demonstrated using a T-shaped flat extrusion die. This approach eliminates the need for profile-specific parameters while preserving all geometric information of the die. The principle of the method is to decompose an extrusion die into five layers of subsections, each of which is abstracted into top/bottom views. These views are further partitioned into multiple segments arranged in a counterclockwise sequence, producing a comprehensive list of segments without any loss of information. Second, a Transformer-based autoencoder is then employed to capture the intricate interactions among these segments and generate the corresponding flow deviation plot for the current die design. Promising results on T-shaped profile have been achieved using a compact dataset with only 256 samples of FE generated data, including for similar unseen designs that have never been used for training. Comparative analyses reveal that the proposed architecture improves the accuracy of extrusion simulation predictions by 144 % (on an internal benchmark) relative to a traditional scalar-based parametrisation method using a fully connected Neural Network (NN).},
  archive      = {J_EAAI},
  author       = {Jiangfeng Ding and Siyi Chen and Zhutao Shao and Zhusheng Shi and Jianguo Lin},
  doi          = {10.1016/j.engappai.2025.112972},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112972},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new profile-agnostic sequential parametrisation method for extrusion die in transformer-based surrogate model},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Stagnation improved adaptive differential evolution for photovoltaic model parameter identification. <em>EAAI</em>, <em>163</em>, 112971. (<a href='https://doi.org/10.1016/j.engappai.2025.112971'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photovoltaic (PV) systems reduce traditional energy consumption by converting solar energy into electricity, but their efficiency depends on the accurate identification of model parameters that are nonlinear and multimodal. Although Differential Evolution (DE) excels in complex optimization, population stagnation limits its performance, preventing consistently optimal results in practice. To address this issue and enhance both the accuracy and stability of PV model parameter identification, we propose a S tagnation- I mproved A daptive D ifferential E volution (SIADE) algorithm. First, a two-stage parameter adaptation strategy based on Euclidean distance is introduced to strengthen the algorithm’s early-stage exploration capability. Second, an improved adaptive mutation framework is proposed, which incorporates multiple mutation strategies and adaptively selects the most suitable one according to individual ranking factors and Euclidean distance. Finally, an enhanced stagnation-handling mechanism based on Lévy flight-based jumps is designed, enabling spatial jumps that allow stagnant individuals to escape from stagnation. The proposed SIADE algorithm is rigorously validated on PV model parameter identification problems as well as 72 benchmark functions from the Congress on Evolutionary Computation (CEC) 2014, CEC2017, and CEC2022 test suites. Experimental results demonstrate that, compared with state-of-the-art differential evolution algorithms, SIADE not only identifies photovoltaic model parameters effectively but also exhibits significant competitive advantages on general benchmark functions.},
  archive      = {J_EAAI},
  author       = {Shengke Lin and Huarong Xu},
  doi          = {10.1016/j.engappai.2025.112971},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112971},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Stagnation improved adaptive differential evolution for photovoltaic model parameter identification},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Simple and practical single-shot digital holography based on unsupervised diffusion model. <em>EAAI</em>, <em>163</em>, 112970. (<a href='https://doi.org/10.1016/j.engappai.2025.112970'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-shot digital holography in Gabor mode offers cost-effective quantitative phase imaging but suffers from the fundamental twin image problem, where real and conjugate images are inherently superimposed, severely limiting phase reconstruction accuracy. Traditional iterative phase retrieval methods require computationally expensive multiple propagations, while off-axis holography demands complex optical setups with precise alignment. We present the first unsupervised diffusion model for automated phase image reconstruction from single-shot in-line holograms, eliminating both twin image artifacts and the need for expensive off-axis configurations. Our framework integrates cycle-consistency and denoising modules to enable training on unpaired hologram-phase image datasets, learning the mapping between low-cost in-line measurements and high-quality phase distributions without requiring labeled data pairs. Comprehensive evaluation on diverse biological specimens demonstrates that our approach significantly outperforms conventional unsupervised methods, achieving superior Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Measure (SSIM) values for both red blood cells and cancer cells. Critically, the model maintains exceptional performance even with limited training data, consistently outperforming supervised learning approaches under data-constrained conditions. The framework exhibits remarkable generalization capabilities, successfully reconstructing phase images from holograms captured at different propagation distances and processing various cancer cell types not included in training data. This computational breakthrough enables accurate, scalable, and hardware-efficient quantitative phase imaging, democratizing access to high-quality phase microscopy for resource-constrained environments while maintaining reconstruction fidelity comparable to complex off-axis systems.},
  archive      = {J_EAAI},
  author       = {Seonghwan Park and Jaewoo Park and Youhyun Kim and Inkyu Moon and Bahram Javidi},
  doi          = {10.1016/j.engappai.2025.112970},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112970},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Simple and practical single-shot digital holography based on unsupervised diffusion model},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Artificial neural network based inverse design of organic light emitting diode structures for optimized optical properties. <em>EAAI</em>, <em>163</em>, 112969. (<a href='https://doi.org/10.1016/j.engappai.2025.112969'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organic light-emitting diode displays are characterized by their nano thin-film composition, positioning them as advanced display technology. However, this feature poses significant challenges in the optical design of the device. Achieving the targeted optical features in an organic light-emitting diode device requires controlling light interference by adjusting the nanometer-scale thin film thickness. Optical simulations for this process demand expensive computing resources, which increase exponentially with structural complexity. Additionally, the light interference within the device is too complex to be managed effectively through human experience and intuition alone. In this work, we propose a inverse design method using artificial neural networks. The inverse design was executed by varying the target spectrum for six different device structures, resulting in the successful derivation of the layer thicknesses needed to achieve the desired spectrum. We provide a mathematical proof of the operating principle of inverse design using the proposed artificial neural network. Besides, the results obtained through inverse design are verified using finite-difference time-domain simulations, which are commonly employed for optical simulations in the design process. Since the proposed method is based on backpropagation and gradient descent, which are fundamental principles of artificial neural networks, it does not require high-specification computing resources such as a graphics processing unit. Additionally, its intuitive network structure allows application to an unlimited number of organic light-emitting diode structures by adjusting the network configuration.},
  archive      = {J_EAAI},
  author       = {Jun Hee Han},
  doi          = {10.1016/j.engappai.2025.112969},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112969},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial neural network based inverse design of organic light emitting diode structures for optimized optical properties},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The role of transformer models in advancing blockchain technology: A systematic survey. <em>EAAI</em>, <em>163</em>, 112968. (<a href='https://doi.org/10.1016/j.engappai.2025.112968'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As blockchain technology evolves, the demand for improved efficiency, security, and scalability increases, with Transformer models demonstrating significant potential to address these challenges. However, a systematic review of their blockchain applications is lacking. This paper fills this gap by surveying over 200 relevant studies, offering a comprehensive analysis of Transformer applications across four key areas: anomaly detection, smart contract vulnerability detection, cryptocurrency prediction, and code summarization. We adopt a domain-oriented classification framework that systematically organizes research progress and challenges, enhancing clarity and identifying trends. Furthermore, we offer granular sub-classification within each domain based on algorithmic types, data modalities, or information sources, delivering deeper insights into methodological advancements. Additionally, we conduct a dual-layered comparative analysis, contrasting Transformers with traditional deep learning methods and assessing variations among Transformer approaches within each domain to uncover best practices. We also explore challenges such as data privacy and model complexity, propose future research directions to tailor Transformers to blockchain-specific needs. We will continue to update the latest articles and their released source codes at https://github.com/LTX001122/Transformers-Blockchain .},
  archive      = {J_EAAI},
  author       = {Tianxu Liu and Yanbin Wang and Jianguo Sun and Ye Tian and Yanyu Huang and Tao Xue and Peiyue Li and Yiwei Liu},
  doi          = {10.1016/j.engappai.2025.112968},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112968},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The role of transformer models in advancing blockchain technology: A systematic survey},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Forecasting total electricity consumption using a novel sinusoidal driving seasonal multivariable grey prediction model. <em>EAAI</em>, <em>163</em>, 112966. (<a href='https://doi.org/10.1016/j.engappai.2025.112966'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The precise forecasting of total electricity consumption can provide data support for designing the sustainable development planning. A new seasonal multivariable grey prediction model, comprising a sinusoidal driving term and a periodic correcting term, is constructed to address the seasonal and nonlinear characteristics of total electricity consumption. In the new model, the sinusoidal driving term is developed to delineate the seasonal impact of the independent variables on the dependent variable, whereas the periodic correcting term is proposed to depict the periodic variations of the dependent variable. Furthermore, the fractional-order grey generation operator (which is an important data processing method in the field of Artificial Intelligence) is employed for the data preprocessing to improve the accuracy of the prediction. In order to demonstrate the advantages of the novel model, it is used for the prediction of electricity consumption in power engineering and the results indicate that its simulation and prediction performances are better than those of the comparison models. To analyze the robustness of this model, the proposed approach is tested several times by adjusting the ratio of training and testing sets. The results of the robustness experiments mean the proposed model is more stable. In addition, the total electricity consumptions in China from the first quarter of 2024 to the fourth quarter of 2026 are forecasted.},
  archive      = {J_EAAI},
  author       = {Fengfeng Yin and Yaoguo Dang and Bo Zeng and Junjie Wang},
  doi          = {10.1016/j.engappai.2025.112966},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112966},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Forecasting total electricity consumption using a novel sinusoidal driving seasonal multivariable grey prediction model},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hybrid model and data driven approach for ballistic prediction with PINN. <em>EAAI</em>, <em>163</em>, 112965. (<a href='https://doi.org/10.1016/j.engappai.2025.112965'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ballistic prediction can effectively improve the strike effect and reduce the aiming error. However, deep learning methods mainly depend on large amount of data and take no account into the guided projectiles ballistic model constraints. In the case of small sample data, ballistic prediction faces challenges of large prediction error and poor model convergence. To address these issues, a hybrid model and data driven approach for ballistic prediction with Physics-informed neural network (PINN) is proposed. Based on the six-degree-of-freedom ballistic model, a small-sample ballistic prediction database is constructed and generated. PINN is integrated to embed ballistic boundary constraints and ballistic physical model constraints in the neural network. The model's training efficiency is enhanced through automatic differentiation techniques, thereby satisfying the requirements of ballistic prediction with limited data samples. The simulation results show that PINN method reduced the amount of CEP by 22.83 % compared with the traditional deep learning method such as Back Propagation (BP) and Long Short Term Memory (LSTM).},
  archive      = {J_EAAI},
  author       = {Li Yang and Wenjie Zheng and Qinjie Liu and Jinwen Wang},
  doi          = {10.1016/j.engappai.2025.112965},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112965},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid model and data driven approach for ballistic prediction with PINN},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A confident cross-domain mixup–based network with dynamic label-distribution-aware margin regularization for bearing fault diagnosis under variable working conditions. <em>EAAI</em>, <em>163</em>, 112964. (<a href='https://doi.org/10.1016/j.engappai.2025.112964'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Methods based on unsupervised domain adaptation have considerably advanced unsupervised cross-domain bearing fault diagnosis. Nevertheless, these methods still have some limitations. First, these approaches overlook the potential utilization of high-confidence pseudo-labeled target domain data, thereby impeding further enhancements in diagnostic performance. Second, challenging categories from the target domain have more samples distributed near the cluster boundaries, making them more prone to misclassification by the classification decision boundary learned from the source domain. The key issues mentioned above are addressed in this study by proposing a confident cross-domain mixup–based network with dynamic label-distribution-aware margin regularization. The proposed method introduces a samples repository to dynamically store high-confidence target domain samples, which are then mixed with source domain samples to generate virtual samples. These confident cross-domain mixup samples bridge the source and target domains, improving domain generalization. In addition, the proposed method reduces the error accumulation in cross-domain mixup due to unreliable pseudo labels. Finally, the proposed method dynamically adjusts classification decision boundary based on diagnostic difficulty, thereby increasing model focus and diagnostic accuracy for challenging categories. In the experimental section of the article, the effectiveness of the proposed network is demonstrated through experimental data from two bearing systems.},
  archive      = {J_EAAI},
  author       = {Changbo He and Zengyang Fu and Peng Chen and Xuefang Xu and Alessandro Paolo Daga and Siliang Lu},
  doi          = {10.1016/j.engappai.2025.112964},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112964},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A confident cross-domain mixup–based network with dynamic label-distribution-aware margin regularization for bearing fault diagnosis under variable working conditions},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). From lab to pocket: A novel continual learning-based mobile application for screening COVID-19. <em>EAAI</em>, <em>163</em>, 112960. (<a href='https://doi.org/10.1016/j.engappai.2025.112960'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) has emerged as a promising tool for predicting COVID-19 from medical images. In this paper, we propose a novel continual learning (also known as incremental learning)-based approach and present the design and implementation of a smartphone application for screening COVID-19. Our approach demonstrates the ability to adapt to evolving datasets, including data collected from different locations or hospitals, varying virus strains, and diverse clinical presentations, without retraining from scratch. We have evaluated state-of-the-art continual learning methods for detecting COVID-19 from chest X-rays and selected the best-performing model for our mobile app. We evaluated various deep learning architectures to select the best-performing one as a foundation model for continual learning. Both regularization and memory-based methods for continual learning were tested, using different memory sizes to develop the optimal continual learning model for our app. DenseNet161 emerged as the best foundation model with 96.87% accuracy, and Learning without Forgetting (LwF) was the top continual learning method with an overall performance of 71.99%. The mobile app design considers both patient and doctor perspectives. It incorporates the continual learning DenseNet161 LwF model on a cloud server, enabling the model to learn from new instances of chest X-rays and their classifications as they are submitted. The app is designed, implemented, and evaluated to ensure it provides an efficient tool for COVID-19 screening. The app is available to download from https://github.com/DannyFGitHub/COVID-19PneumoCheckApp .},
  archive      = {J_EAAI},
  author       = {Danny Falero and Muhammad Ashad Kabir and Nusrat Homaira},
  doi          = {10.1016/j.engappai.2025.112960},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112960},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {From lab to pocket: A novel continual learning-based mobile application for screening COVID-19},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A text-based hybrid transfer learning model for ternary classification in health misinformation detection. <em>EAAI</em>, <em>163</em>, 112959. (<a href='https://doi.org/10.1016/j.engappai.2025.112959'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting health misinformation is essential for protecting public health and ensuring effective communication during health crises. Significant attention has been devoted to health misinformation detection following the Coronavirus Disease 2019 (COVID-19) pandemic. Various approaches have been developed to automatically address health misinformation, often framing the problem as a binary classification task. However, these methods tend to overlook the complexity and fluidity of health-related information, where ongoing scientific research or incomplete data can complicate the definitive classification of certain claims. This paper approaches health misinformation detection as a ternary classification problem, categorizing content as uncertain, false, or true. A hybrid transfer learning model is proposed to effectively detect health misinformation by leveraging the linguistic features of general misinformation and combining multimodal features with an attention mechanism. The model is trained on both Chinese and English datasets, resulting in accuracy improvements of 6.75 % and 3.4 %, respectively.},
  archive      = {J_EAAI},
  author       = {Jia Luo and Yang Yang and Xiaoye Feng and Didier El Baz},
  doi          = {10.1016/j.engappai.2025.112959},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112959},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A text-based hybrid transfer learning model for ternary classification in health misinformation detection},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Unsupervised anomaly detection in energy storage systems using dual-view latent variable modeling. <em>EAAI</em>, <em>163</em>, 112958. (<a href='https://doi.org/10.1016/j.engappai.2025.112958'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring accurate anomaly detection in energy storage systems, particularly for critical applications such as electric vehicles and home energy storage, is essential for maintaining battery health and system safety. However, existing methods often do not consider modeling complex relationships within multi-sensor data and struggle to handle noisy inputs, limiting their effectiveness. This paper presents Dual-View Sensor Anomaly Detection (DVSAD), an unsupervised method based on multi-view latent variable modeling, which captures spatio-temporal dependencies in multi-sensor data by integrating the dual perspectives of sensor relationship graphs and time series patterns. To improve robustness, DVSAD applies diffusion-based noise perturbations for adaptive data smoothing and adopts a structure-guided anomaly scoring mechanism that incorporates physical priors, which strengthens the separation between normal and abnormal patterns. Extensive experiments on five real-world multi-sensor datasets show that DVSAD outperforms state-of-the-art (SOTA) methods, achieving an 11.51% increase in F1 score and a 5.61% increase in Area Under the Curve (AUC) for vehicle-level detection, along with a 13.14% improvement in F1 score for time-point detection. These results demonstrate its superior accuracy and robustness, enabling early risk identification and real-time anomaly monitoring in energy storage systems. Our code is available at https://github.com/willqq/DVSAD .},
  archive      = {J_EAAI},
  author       = {Zhipeng Qiu and Zhixia Zeng and Weifu Zhu and Ruliang Xiao and Shi Zhang},
  doi          = {10.1016/j.engappai.2025.112958},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112958},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised anomaly detection in energy storage systems using dual-view latent variable modeling},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph convolutional network reconstruction with high-order node information for community detection. <em>EAAI</em>, <em>163</em>, 112957. (<a href='https://doi.org/10.1016/j.engappai.2025.112957'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection is typically used to understand the community structures within networks. Most community detection methods are limited to capturing only the nodes’ first-order and second-order neighbor information. To utilize nodes’ high-order neighbor information, we propose a graph convolutional network reconstruction with high-order node information for community detection (GCNRH). Since the existing shallow graph convolutional network is difficult to capture high-order information, the GCNRH model introduces a graph convolutional network with a biaffine attention mechanism to establish a fast association of remote nodes. It utilizes the biaffine attention mechanism to capture the higher-order node information and learns the potential representation of nodes by reconstructing the modularity matrix. It also adopts a self-supervised training method to optimize the learning process. Extensive experiments on 12 real-world datasets demonstrate the superior performance of GCNRH in community detection. In particular, the modularity and normalized mutual information values of the GCNRH model improve by 0.48%–30.92% and 3.8%–19.3% on the Facebook dataset, respectively. Finally, visualizations of community divisions on different-scale networks show the effectiveness of the GCNRH model.},
  archive      = {J_EAAI},
  author       = {Yukun Wang and Xianyong Li and Yajun Du and Dong Huang and Xiaoliang Chen and Zhicheng Dong and Yujie Zhang},
  doi          = {10.1016/j.engappai.2025.112957},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112957},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph convolutional network reconstruction with high-order node information for community detection},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Decoupled multi-spatio-temporal fusion graph convolutional recurrent network for traffic prediction. <em>EAAI</em>, <em>163</em>, 112956. (<a href='https://doi.org/10.1016/j.engappai.2025.112956'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise traffic prediction is essential for building smart city transportation systems. Although significant progress has been made, there are still limitations in capturing complex spatio-temporal relationships. First, current traffic prediction methods generate static graphs that fail to adapt to time-varying traffic conditions, unable to capture how spatial dependencies evolve throughout the day or across the week. Moreover, they often process heterogeneous traffic signals uniformly without distinguishing between steady-state and non-steady-state components. In this work, we propose a Decoupled Multi-spatio-temporal Fusion Graph Convolutional Recurrent Network (DMFGCRN) to address these limitations simultaneously. Firstly, we introduce a dynamic embedding graph learner that integrates real-time traffic signals with calendar-aware temporal patterns, generating unique time-varying adjacency matrices for each time step. Further, we propose a multi-layer architecture that progressively separates steady-state from non-steady-state signals through cascaded convolutional filtering, enabling each layer to refine different signal components. Additionally, our multi-spatio-temporal fusion module combines dynamic graph convolution with bidirectional recurrent processing across multiple refinement layers, where historical context enriches future predictions at multiple abstraction levels. Experimental results on seven real traffic datasets show that DMFGCRN outperforms 24 state-of-the-art methods. Specifically, on the Performance Measurement System District 8 dataset, our model showed improvements of 7.58% in Mean Absolute Error compared to the Multi-spatio-temporal Fusion Graph Recurrent Network model. The source code for DMFGCRN is publicly available at: https://github.com/OvOYu/DMFGCRN .},
  archive      = {J_EAAI},
  author       = {Shiyu Yang and Qunyong Wu and Mengmeng Li},
  doi          = {10.1016/j.engappai.2025.112956},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112956},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Decoupled multi-spatio-temporal fusion graph convolutional recurrent network for traffic prediction},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). ESEN: Evidence-aware semantic enhancement network for fact-checking fake news detection. <em>EAAI</em>, <em>163</em>, 112955. (<a href='https://doi.org/10.1016/j.engappai.2025.112955'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fact-checking fake news detection is a challenging task that requires retrieving multiple pieces of evidence to verify the truthfulness of a claim. Despite the effectiveness of current methods, they still suffer from the following problems: (1) neglecting attentional constraints on important words related to the claim; (2) insufficiently exploring the relationships between different pieces of evidence. To address these issues, we propose an Evidence-aware Semantic Enhancement Network for Fact-checking Fake News Detection (abbreviated as ESEN). First, we model the claim and evidence as a graph structure to extract semantic information, putting the attentive guidance to closely follow the syntactic information extraction. Then, we incorporate the extracted syntactic information into the semantic information. Finally, we propose an information interaction network for evidence perception to capture multi-level interactive information and enhance the interaction between evidences by constructing three types attention layer. Evaluation experiments are performed on the Snopes and PolitiFact datasets. Experimental results and ablation studies show that our ESEN outperforms other baseline models. Our source code is available at https://github.com/makunjida/ESEN .},
  archive      = {J_EAAI},
  author       = {Yanfang Qiu and Kun Ma and Xiaoyun Liu and Ke Ji and Zhenxiang Chen and Bo Yang},
  doi          = {10.1016/j.engappai.2025.112955},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112955},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ESEN: Evidence-aware semantic enhancement network for fact-checking fake news detection},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Activated entropy with mutational feature extraction for wheel flat fault diagnosis in railway systems. <em>EAAI</em>, <em>163</em>, 112954. (<a href='https://doi.org/10.1016/j.engappai.2025.112954'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past two decades, numerous entropy-based metrics have been adopted in machinery fault diagnosis. While single-scale entropy measures often fail to capture deeper information present at other scales, multi-scale variants can become difficult to visualize effectively when the scale factor is large. This work introduces a novel entropy feature, termed Activated Entropy, integrating Root Mean Square envelope processing, adaptive activation functions, differentiation, and Sample Entropy. Compared to conventional entropy features, Activated Entropy offers two key benefits: (1) it transforms a time series into a three-dimensional feature vector, enabling direct visualization in three-dimensional space; (2) it effectively captures signal mutation information indicative of machinery faults, improving diagnostic accuracy. In simulation experiments on a high-speed trailer, Activated Entropy combined with a neural network achieved 100 % classification accuracy (82.9 % for Multiscale Permutation Entropy and 84.2 % for Generalized Composite Multiscale Weighted Permutation Entropy). In field tests on a freight wagon, Activated Entropy maintained over 96 % accuracy across all speed ranges (40–100 km per hour), outperforming Sample Entropy (85 % minimum accuracy) and other comparative entropy features.},
  archive      = {J_EAAI},
  author       = {Yunguang Ye},
  doi          = {10.1016/j.engappai.2025.112954},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112954},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Activated entropy with mutational feature extraction for wheel flat fault diagnosis in railway systems},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A review of instruction-guided image editing. <em>EAAI</em>, <em>163</em>, 112953. (<a href='https://doi.org/10.1016/j.engappai.2025.112953'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement of artificial intelligence (AI) systems such as large language models (LLMs) and multimodal learning frameworks has transformed digital content creation and manipulation. Traditional visual editing tools require significant expertise, limiting accessibility. Recent strides in instruction-guided editing have enabled intuitive interaction with visual content, using natural language as a bridge between user intent and complex editing operations. This survey reviews how AI-implemented instruction-guided image editing models – including approaches rooted in generative adversarial networks and diffusion models – empower users to achieve precise visual modifications without deep technical knowledge. By synthesizing over 100 publications, we examine multimodal integration for fine-grained content control, compare existing literature, and highlight how these AI applications support creative visual storytelling, design workflows, and multimedia production. We also identify key challenges to stimulate further research. Interested readers are encouraged to access our repository at https://github.com/tamlhp/awesome-instructional-editing .},
  archive      = {J_EAAI},
  author       = {Thanh Tam Nguyen and Zhao Ren and Trinh Pham and Phi Le Nguyen and Quoc Viet Hung Nguyen and Hongzhi Yin},
  doi          = {10.1016/j.engappai.2025.112953},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112953},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A review of instruction-guided image editing},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A robust routing protocol for energy and coverage optimization in wireless sensor networks using game theory and heuristic algorithm. <em>EAAI</em>, <em>163</em>, 112952. (<a href='https://doi.org/10.1016/j.engappai.2025.112952'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor networks (WSNs) are applied to structural health monitoring (SHM) due to their low cost and flexible installation. Reliable WSNs provide effective monitoring data for SHM, which is the foundation for structural condition assessment. However, due to energy consumption and harsh conditions such as high temperatures and corrosion, sensor nodes may run out of energy or malfunction, which can disrupt the network structure and lead to abnormal monitoring data. Cluster routing protocols and fault tolerant methods are extensively employed to reduce node energy consumption and manage sensor faults. In this study, a game theory based fault tolerant routing protocol (FTRP-GT) is proposed to reduce network energy consumption, manage faulty nodes, and extend network lifetime. This protocol offers multiple advantages. First, the optimal number of cluster heads (CHs) was derived, and a game theory based candidate CHs selection method is proposed to consider residual energy, node degree, and node importance. Second, the optimal CHs are obtained from the candidate CHs using the particle swarm optimization (PSO) algorithm. Third, the protocol designs a reusing faulty node (RFN) strategy, which uses the faulty node as a relay node to forward CH data, effectively utilizing the residual energy of faulty nodes and ensuring network stability. The proposed FTRP-GT protocol is evaluated using the monitoring network of Beijing Daxing International Airport. The results show that the FTRP-GT protocol performs better in extending network lifetime and reducing energy consumption compared to other routing protocols.},
  archive      = {J_EAAI},
  author       = {Hao Chen and Hua-Ping Wan and Hui-Bin Ge and Yaozhi Luo},
  doi          = {10.1016/j.engappai.2025.112952},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112952},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A robust routing protocol for energy and coverage optimization in wireless sensor networks using game theory and heuristic algorithm},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). From augmentation to translation: Data generation by conditional hierarchical variational autoencoder, enhancing monitoring mooring systems in floating offshore wind turbines. <em>EAAI</em>, <em>163</em>, 112951. (<a href='https://doi.org/10.1016/j.engappai.2025.112951'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integrity of mooring systems in floating offshore wind turbines (FOWTs) is crucial, as their degradation alters the platform’s dynamic behavior. A robust machine learning-based health monitoring system that continuously monitors different mooring systems for FOWTs requires data under diverse health, operational, and metocean conditions. To this end, we propose a Conditional Hierarchical Variational Autoencoder (CHVAE) generative model designed for simultaneous data augmentation and domain translation to generate the required data. We train the model to learn the nonlinear relationships between healthy and minority-damaged fairlead tension records from the source mooring system across various sea states. CHVAE generates realistic damaged responses under diverse conditions by leveraging healthy data from the target mooring system. We first assess CHVAE’s ability to augment minority data based on majority distribution, validated on the Modified National Institute of Standards and Technology (MNIST) benchmark dataset. This experiment compares the performance of CHVAE variants with conventional and recent oversampling methods. Second, the open-source software OpenFast simulates the testing and training datasets for simultaneously data augmentation and domain translation on the Offshore Code Comparison Collaboration Continuation (OC4) semi-submersible platform (DeepCwind) FOWT benchmark. OpenFast and CHVAE records are compared through visual, statistical, and behavioral methodologies. Simulations utilize diverse wave seeds to represent excitation randomness and undetected damage severities, assessing CHVAE’s one-to-all capability. Generated records for unobserved sea states and damage severities closely mimic real behavior in downstream binary classification, illustrating the versatility of CHVAE for zero-shot, real-time damage identification.},
  archive      = {J_EAAI},
  author       = {Hamed Fathnejat and Vincenzo Nava},
  doi          = {10.1016/j.engappai.2025.112951},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112951},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {From augmentation to translation: Data generation by conditional hierarchical variational autoencoder, enhancing monitoring mooring systems in floating offshore wind turbines},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automatic and accurate characterization of rock fractures based on deep learning. <em>EAAI</em>, <em>163</em>, 112950. (<a href='https://doi.org/10.1016/j.engappai.2025.112950'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fractures play a pivotal role in the hydromechanical behavior of rocks. Researchers have tried to understand the fundamental mechanisms and behavior of fractures, both theoretically and experimentally. Fractures produced in laboratory tests can be characterized using photographic images at a range of scales. Traditionally, identifying and extracting the temporal-spatial characteristics of fractures rely on meticulous manual labeling, entailing significant time and labor. Recently, Deep Learning (DL) methods have been deployed for automatic fracture extraction and characterization of fracture evolution from rock images. However, they generally necessitate a large dataset to train DL models for extracting fractures. More importantly, they cannot distinguish existing fractures or background noise and erroneously identify a continuous fracture as multiple disconnected segments, leading to significant errors in quantifying fracture evolution. This study introduces a new Deep Learning-based approach for mapping temporal sequence of images, the ‘Hybrid Fracture Mapping Method’ (HFMM). It incorporates a small training dataset using systematic sampling and employs an advanced denoising method. It is validated on a hydraulic fracturing image dataset from Massachusetts Institute of Technology (MIT) rock mechanics laboratory. The results demonstrate that the HFMM shows a notable improvement compared to the conventional DL methods in mapping hydraulic fracture evolution. It achieved a reduction in Mean Absolute Error (MAE) for quantifying fracture length and number of fracture branches, decreasing the MAE by 81 %–86 % and 69 %–93 %, respectively.},
  archive      = {J_EAAI},
  author       = {Jian Liu and Omar AlDajani and Bing Q. Li and Herbert Einstein and Zili Li},
  doi          = {10.1016/j.engappai.2025.112950},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112950},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automatic and accurate characterization of rock fractures based on deep learning},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Design of cough sound classifiers based on attention mechanism and contrastive loss for detection of coronavirus disease 2019. <em>EAAI</em>, <em>163</em>, 112949. (<a href='https://doi.org/10.1016/j.engappai.2025.112949'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel classification method for the early detection of coronavirus disease 2019 (COVID-19) utilizing cough sounds. The method integrates a convolutional neural network (CNN) with an attention mechanism, realized through a Modified SENet (MS), and employs contrastive loss (CL) to enhance feature clustering in the classification process. This approach, referred to as MSSCOL, aims to improve detection accuracy for COVID-19 from cough sounds. Experimental evaluations demonstrate that the MSSCOL achieves superior classification performance compared to existing methodologies and state-of-the-art techniques across two benchmark datasets: the imbalanced Coswara and the balanced Virufy. Notably, the MSSCOL exhibits enhanced results on the balanced Virufy dataset relative to the imbalanced Coswara dataset. The findings suggest that the MSSCOL method can significantly mitigate the risk of cross-infections by facilitating remote testing, and provide rapid access to testing results, thereby contributing to more efficient COVID-19 detection strategies.},
  archive      = {J_EAAI},
  author       = {Yin-Tzer Shih and Hung-Hsu Tsai and Yen-Ning Su and Shih-Chen Lo and Cheng-Wei Yeh and Yu-Che Chuang},
  doi          = {10.1016/j.engappai.2025.112949},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112949},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Design of cough sound classifiers based on attention mechanism and contrastive loss for detection of coronavirus disease 2019},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Neural network-driven predictive control and fractional-order nonlinear filter optimization for helicopter active vibration control. <em>EAAI</em>, <em>163</em>, 112937. (<a href='https://doi.org/10.1016/j.engappai.2025.112937'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vibration problem in helicopters is a critical factor that affects both flight safety and passenger comfort. Active control is essential for vibration reduction, but several challenges are often encountered, such as phase delay in response, low system control accuracy, and slow convergence of control signals. This study explores the use of artificial intelligence (AI) to address the helicopter vibration reduction problem by proposing an approach based on neural network-driven predictive control and fractional-order nonlinear filter (N-PC-FNF) optimization for helicopter active vibration control. The approach first employs a bidirectional long short-term memory (BiLSTM) neural network to predict the time series of helicopter vibration signals, laying the foundation for the subsequent calculation of reverse vibration reduction signals in advance. Next, a fractional-order nonlinear filter combined with variational mode decomposition (VMD) is designed to decompose the complex vibration signals into intrinsic mode functions (IMFs) with distinct frequency domain characteristics. The fractional-order parameters are flexibly adjusted to better adapt to the nonlinear dynamic variations in the vibration signals. Finally, the weights of the filter are transferred to a multilayer perceptron (MLP) network for training, enabling the calculation of the filter’s steady-state weights and the actual actuator output signals, thereby achieving active control of helicopter vibrations. The research demonstrates that the proposed approach, which integrates neural network-driven predictive control with fractional-order nonlinear filter optimization, effectively realizes helicopter active vibration control and meets the requirements of engineering applications.},
  archive      = {J_EAAI},
  author       = {Tao Li and Minqi Wang and Yaxin Zhang and Lida Wang and Rongjun Ding and Jun Yang},
  doi          = {10.1016/j.engappai.2025.112937},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112937},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural network-driven predictive control and fractional-order nonlinear filter optimization for helicopter active vibration control},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Lightweight ensemble learning based intrusion detection framework with explainable artificial intelligence. <em>EAAI</em>, <em>163</em>, 112936. (<a href='https://doi.org/10.1016/j.engappai.2025.112936'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increased dependence of individuals and organizations on the internet has contributed to significant attention to cybersecurity. Cybersecurity is essential for protecting critical infrastructure, networks, and sensitive data from rising cyber threats. The intrusion detection system is a cybersecurity solution that secures the digital world by identifying and mitigating cyberattacks. This paper proposes an explainable ensemble learning-based intrusion detection system that efficiently classifies various forms of cyberattacks. The proposed framework comprises three distinct modules: a feature selection module, a feature reduction module, and a voting ensemble learning module. The first module involves a feature importance analysis to select the most significant features. In the second module, these important features undergo dimensionality reduction to obtain an optimal dataset. The third module utilizes the optimized dataset to train an ensemble learning model to classify a broader range of cyberattacks. Further, the explainable artificial intelligence is employed in the proposed framework to provide transparent results. The proposed framework's performance is rigorously evaluated using 10-fold cross-validation on two benchmark datasets. The proposed model achieved an average accuracy of 99.95 % on both datasets. In addition to that, a comparative analysis is conducted that shows the model's superiority over existing ones. The proposed framework can be integrated with firewalls and Security Information and Event Management (SIEM) systems to enhance perimeter defense. The proposed framework is lightweight and well-suited for deployment in resource-constrained environments because it reduces the computational overhead and training time.},
  archive      = {J_EAAI},
  author       = {Swechchha Gupta and Buddha Singh},
  doi          = {10.1016/j.engappai.2025.112936},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112936},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lightweight ensemble learning based intrusion detection framework with explainable artificial intelligence},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A lightweight prior-encoding-decoding cascade framework for robust depth completion in robotic grasping of transparent objects using RGB-D sensors. <em>EAAI</em>, <em>163</em>, 112934. (<a href='https://doi.org/10.1016/j.engappai.2025.112934'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the critical steps in robotic sorting is the accurate perception of objects using RGB-D sensors, which enables the generation of precise grasping poses. Sorting transparent objects with industrial robots is challenging due to their low contrast and sparse depth information. Current transparent object perception methods (depth completion) attempt to learn multi-level feature representations from RGB and sparse depth data. However, they neglect the effective interaction of shallow RGB-D features and fail to preserve high-frequency details in deep features. To tackle these issues, we propose a lightweight Prior-Encoding-Decoding (PED) cascade depth completion framework for reconstructing complete depth data from severely sparse depth maps of transparent objects. Specifically, we design a Cross-modal Fine-grained Channel Attention Module (CFCAM) to dynamically integrate shallow RGB-D features, establishing dependencies between local and global features. Additionally, we apply the Haar Wavelet Transform (HWT) during the encoding phase and implement a Nonlinear Activation Upsampling Module (NAUM) in the decoding phase to effectively retain high-frequency details and enhance the richness and integrity of deep feature representations. PED was trained and evaluated on three mainstream datasets: TransCG, ClearGrasp, and Omniverse Object and achieved prediction accuracies of 89.48 %, 84.07 %, 80.47 %, 38.77 %, and 45.05 % on five test sets under the 1.05 threshold metric. Grasping experiments conducted on the UR5 robotic platform further demonstrate that PED achieves a transparent object grasp success rate of 84.52 % using only a low-cost RGB-D camera. The project is available at: https://sites.google.com/view/project-ped .},
  archive      = {J_EAAI},
  author       = {Ling Tong and Kun Qian and Bo Zhou and Fang Fang},
  doi          = {10.1016/j.engappai.2025.112934},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112934},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight prior-encoding-decoding cascade framework for robust depth completion in robotic grasping of transparent objects using RGB-D sensors},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Flare detection and detail compensation for nighttime flare removal. <em>EAAI</em>, <em>163</em>, 112926. (<a href='https://doi.org/10.1016/j.engappai.2025.112926'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images captured at nighttime are often impaired by flares of varying sizes and shapes, which degrade visual perception and hinder image quality. Distinguishing these flares from light sources for effective removal is challenging due to the complex pattern. In addition, the image regions affected by the flare show insufficient texture details, resulting in poor visual perception at nighttime. In this paper, we propose the flare detection and detail compensation for nighttime flare removal. Our method consists of two stages: the flare detection stage and the flare removal with detail compensation stage. Specifically, in the flare detection stage, the flare perception feature is extracted through an encoder–decoder structure composed of Multi-receptive Field Collaborative Perception Blocks (MCPBs), and then a flare mask that can distinguish flares, light sources, and other regions is generated. In the flare removal with detail compensation stage, the flare perception feature obtained in the previous stage and the edge detail information of the input image are first fused. Based on the fused informative feature, another encoder–decoder structure composed of residual blocks and MCPBs is used to achieve flare removal, light source preservation, and detail compensation at the same time. Experiments on the Flare7K dataset confirm that our method outperforms state-of-the-art models in both quantitative and qualitative evaluations, delivering superior image quality and more visually appealing results. To summarize, experimental results suggest the potential for our approach to improve nighttime imaging by removing flare degradation in various applications. Future research on the nighttime flare removal requires further improvement of its generalization capabilities, particularly in scenarios with extreme illumination conditions or severe flare interference.},
  archive      = {J_EAAI},
  author       = {Yuzhen Niu and Bolin Zhang and Yuezhou Li and Jingyuan Zheng},
  doi          = {10.1016/j.engappai.2025.112926},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112926},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Flare detection and detail compensation for nighttime flare removal},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Guided relevance attention mapping: Explainable artificial intelligence reimagined. <em>EAAI</em>, <em>163</em>, 112925. (<a href='https://doi.org/10.1016/j.engappai.2025.112925'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing use of artificial intelligence (AI) in essential domains such as healthcare, banking, and autonomous systems emphasizes the need for transparency and trust in the systems. Explainable Artificial Intelligence (XAI) has emerged in response to this, aiming to make sophisticated AI models more transparent, interpretable, and accountable to humans, thereby supporting the ethical evaluation of their decisions. By providing meaningful explanations for complex model predictions, XAI ensures that AI systems operate ethically, facilitate user trust, and support responsible decision-making in high-stakes environments. However, the current methods, such as Layer-wise Relevance Propagation (LRP), suffer from major drawbacks such as noise sensitivity or inadequate context understanding. This paper proposes a framework, named Guided Relevance Attention Mapping (GRAM). GRAM joins Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) to make definite and set importance maps, making simulated intelligence choices clearer and more dependable. By incorporating neighborhood and worldwide component extraction, GRAM successfully balances the intricacy of current artificial intelligence models along with the requirement of interpretability. We evaluate our framework using two common metrics: average drop and percentage increase. The experimental results demonstrate that the proposed approach outperforms state-of-the-art explainable AI methods, achieving a 70.67% increase and a 7.59% average drop. For comparative analysis, we confirm its superiority over other XAI techniques and test with various ViT models, highlighting VIT-G-14 as the most compatible with our approach.},
  archive      = {J_EAAI},
  author       = {Aditya Yadav and Vivek Srivastava and Aditi Yadav},
  doi          = {10.1016/j.engappai.2025.112925},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112925},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Guided relevance attention mapping: Explainable artificial intelligence reimagined},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Modelling of a multi-drone framework for trajectory prediction and deep reinforcement learning-based obstacle classification in dynamic environments. <em>EAAI</em>, <em>163</em>, 112924. (<a href='https://doi.org/10.1016/j.engappai.2025.112924'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-drone object trajectory prediction aims to collaboratively recognize objects and estimate their future actions, utilizing multiple drones with overlying observations that can overwhelm the single-drone restrictions of blur, occlusion, and longer-range clarifications. Assuming protection and consistent task execution, accurate trajectory prediction is significant for multi-drone unmanned aerial vehicle autonomous navigation (UAVAN). It enables early warning of potential collisions and path planning in drone operations, assisted by using artificial intelligence (AI) technologies. This enhances applications in intelligent transportation, smart cities, and emergency response systems. Present multi-agent collaborative perception approaches mainly depend on the bird's eye view technique, which has become essential for signifying varied observational viewpoints in a combined feature space. The prediction of collaborative trajectory can widely predict the future gesture of objects over multi-view complementary data. At present, by incorporating deep learning (DL) models, analytical obstacle modelling and adaptive motion tactics are recognized, considerably alleviating the computational burden and permitting a unified real-time process in extremely resource-limited and dynamic areas. This paper presents an Advanced Deep Reinforcement Learning for Multi-Drone Trajectory Prediction and Obstacle Classification via a Deep Q-Network (ADRL-TPOCDQN) approach in dynamic environments. The aim of the ADRL-TPOCDQN approach is to develop an effective framework for accurate multi-drone trajectory prediction and real-time obstacle classification to enhance autonomous navigation and collision avoidance. Initially, the data pre-processing stage employs the standard scaler technique to normalize the input data. Furthermore, the wavelet bidirectional long short-term memory with attention mechanism (WBiLSTM-A) model is used for the trajectory prediction process. For the obstacle classification process, the ADRL-TPOCDQN model implements the deep Q-network (DQN) model. The ADRL-TPOCDQN methodology is experimentally applied under the UAVAN dataset. The comparison study of the ADRL-TPOCDQN methodology portrayed a superior accuracy value of 99.00 % over existing models.},
  archive      = {J_EAAI},
  author       = {Manal Abdullah Alohali and Mohammed Baihan and Mohammed Aljaafari and Hamed Alqahtani and Saied Alshahrani and Ahmed Alsayat and Nouf Atiahallah Alghanmi and Abdulsamad Ebrahim Yahya},
  doi          = {10.1016/j.engappai.2025.112924},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112924},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Modelling of a multi-drone framework for trajectory prediction and deep reinforcement learning-based obstacle classification in dynamic environments},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantum-inspired neural networks with stochastic dynamics for multimodal sentiment analysis and sarcasm detection. <em>EAAI</em>, <em>163</em>, 112923. (<a href='https://doi.org/10.1016/j.engappai.2025.112923'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum-inspired neural networks have demonstrated strong potential in modeling non-classical phenomena in cognitive tasks, particularly in multimodal sentiment analysis, marking a significant advancement over traditional models. However, existing multimodal quantum-inspired neural networks fall short in fully modeling the multimodal density matrix, typically relying on simplistic neural mappings to represent quantum entanglement. This lack of explicit physical constraints, particularly those governing open quantum system dynamics, limits both the interpretability and performance. To address this limitation, we propose a novel framework grounded in quantum stochastic dynamics, introducing two quantum-inspired neural networks, which model the evolution of multimodal data as Markovian and non-Markovian open quantum systems, respectively. This approach enables the simulation of quantum system evolution to capture rich non-classical interactions between modalities. The resulting entangled multimodal density matrix is then measured through quantum projections to extract high-level features for downstream sentiment analysis and sarcasm detection. Extensive experiments on benchmark bimodal and trimodal datasets demonstrate that our models consistently outperform state-of-the-art traditional baselines, large-scale language models and quantum-inspired neural networks. Ablation studies confirm the critical role of quantum stochastic dynamics in performance gains. Furthermore, we enhance the interpretability by tracking the evolution of the density matrix using von-Neumann entanglement entropy as a quantitative metric, providing deeper insight into the internal mechanisms of the model.},
  archive      = {J_EAAI},
  author       = {Kehuan Yan and Peichao Lai and Xianghan Zheng and Yang Yang and Yi Ren and Tuyatsetseg Badarch and Yiwei Chen},
  doi          = {10.1016/j.engappai.2025.112923},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112923},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Quantum-inspired neural networks with stochastic dynamics for multimodal sentiment analysis and sarcasm detection},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hypergraph neural network with state space models for node classification. <em>EAAI</em>, <em>163</em>, 112922. (<a href='https://doi.org/10.1016/j.engappai.2025.112922'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, graph neural networks (GNNs) have gained significant attention for node classification tasks on graph-structured data. However, traditional GNNs primarily focus on adjacency relationships between nodes, often overlooking the role-based characteristics that can provide complementary insights for learning expressive node representations. Existing frameworks for extracting role-based features are largely unsupervised and often fail to translate effectively into downstream predictive tasks. To address these limitations, we propose a hypergraph neural network with a state space model (HGMN). The model integrates role-aware representations into GNNs by combining hypergraph construction with state-space modeling in a principled manner. HGMN employs hypergraph construction techniques to capture higher-order relationships and leverages a learnable mamba transformer mechanism to fuse role-based and adjacency-based embeddings. By exploring two distinct hypergraph construction strategies, degree-based and neighborhood-based, the framework reinforces connectivity among nodes with structural similarity, thereby enriching the learned representations. Furthermore, the inclusion of hypergraph convolution layers enables the model to account for complex dependencies within hypergraph structures. To alleviate the over-smoothing problem encountered in deeper networks, we incorporate residual connections, which improve stability and promote effective feature propagation across layers. Comprehensive experiments on benchmark datasets including OGB, ACM, DBLP, IIP TerroristRel, Cora, Citeseer, and Pubmed demonstrate that HGMN consistently outperforms strong baselines in node classification tasks. These results support the claim that explicitly incorporating role-based features within a hypergraph framework offers tangible benefits for node classification tasks.},
  archive      = {J_EAAI},
  author       = {A. Quadir and M. Tanveer},
  doi          = {10.1016/j.engappai.2025.112922},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112922},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hypergraph neural network with state space models for node classification},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multimodal and view image processing for three-dimensional object detection in autonomous driving. <em>EAAI</em>, <em>163</em>, 112921. (<a href='https://doi.org/10.1016/j.engappai.2025.112921'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional object detection is critical for artificial intelligence autonomous driving, as it allows vehicles to detect and accurately locate objects in complex and dynamic environments. Traditional methods that rely on light detection and ranging or camera data often face challenges in scenarios involving occlusion, varying lighting conditions, and cluttered backgrounds. This paper proposes a novel multimodal approach that integrates radar point cloud data with multiview image features, including bird’s eye view and front view, to leverage complementary information for enhanced detection accuracy and robustness. We introduced a method of integrating a “voting mechanism” to generate high-quality candidate regions, combined with a target attention mechanism to improve feature extraction and object localization, particularly in difficult environments. By effectively combining the strengths of both three-dimensional and two-dimensional data, our method addresses occlusion and noise issues while enhancing detection capabilities across diverse conditions. We validated the effectiveness of the proposed method on three object detection datasets, achieving mean average precision of 90.30%, 72.4%, and 75.1%, respectively.},
  archive      = {J_EAAI},
  author       = {Yi Wang and Hang Dong and Hua Bo},
  doi          = {10.1016/j.engappai.2025.112921},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112921},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodal and view image processing for three-dimensional object detection in autonomous driving},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Accuracy improvement of temperature measurement using a wide-spectrum visible camera based on deep learning network denoising. <em>EAAI</em>, <em>163</em>, 112920. (<a href='https://doi.org/10.1016/j.engappai.2025.112920'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wide-spectrum visible camera (WSVC) can respond to near-infrared radiation while receiving visible radiation through corresponding sensors. Combined with high image resolution and strong scalability, it can achieve temperature measurement in various high-temperature industries. Taking into account factors such as the overall temperature measurement effect, application scenarios and experimental devices, this work has developed a temperature measurement method within the temperature range of 800–1200 °C (°C). This method employs the WSVC technology with near-infrared radiation response, including the construction and calibration of the temperature measurement system. Firstly, a deep learning denoising network combining convolution block attention module (CBAM) and sparse convolution based on residual learning is proposed, which can effectively reduce the influence of image noise. Subsequently, the temperature measurement system was calibrated using a blackbody furnace, and the characteristic curve between the blackbody furnace temperature value and the image grayscale value was fitted. After denoising the image of the object to be measured, the accurate temperature of the object was calculated based on the fitted formula, completing the measurement of the temperature of the high-temperature object. The results show that the proposed network has significant advantages in denoising effect and efficiency. The average accuracy of temperature measurement increased by 0.18 %, and the mean square error of the difference between the fitted calculated temperature and the actual temperature decreased from 3.15 °C before noise reduction to 1.38 °C after noise reduction. This work has guiding significance in the temperature measurement based on visible cameras and deep network noise reduction processing.},
  archive      = {J_EAAI},
  author       = {Shuangbao Shu and Yufeng Fu and Jianhua Yang and Xiaoyue Hu and Yuzhong Zhang and Junjie Niu},
  doi          = {10.1016/j.engappai.2025.112920},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112920},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Accuracy improvement of temperature measurement using a wide-spectrum visible camera based on deep learning network denoising},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A general framework for interactive semantic segmentation refinement of point clouds. <em>EAAI</em>, <em>163</em>, 112919. (<a href='https://doi.org/10.1016/j.engappai.2025.112919'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep learning-based point cloud semantic segmentation has been extensively studied in the past decade, it is still challenging to produce high quality masks that meet high-precision downstream applications. This challenge stems from the distribution mismatch between training and testing data. The pre-trained segmentation networks optimized on the training dataset may perform sub-optimally on individual unseen testing data, resulting in performance drop. To this end, we propose a general interactive framework to enhance off-the-shelf networks. This framework integrates with off-the-shelf semantic segmentation networks in a fully test-time manner, allowing users to refine mis-segmented regions with a few corrective clicks. Specifically, we formulate a correction energy that treats user clicks as sparse training examples for test-time optimization. To mitigate catastrophic overfitting caused by sparse supervision, we formulate a stabilization energy that selectively minimizes the entropy of global points. Both the correction and stabilization energies constitute the test-time loss, promoting effective refinement of mis-segmented regions while maintaining the stability of others. Furthermore, a warm-up pre-process and an interaction simulation scheme are proposed for performance improvement and reproducible evaluation, respectively. We evaluate our framework on indoor and outdoor datasets with off-the-shelf networks, showing promising results in semantic segmentation refinement. The source code is available at https://github.com/Pengz98/ISSR .},
  archive      = {J_EAAI},
  author       = {Peng Zhang and Ting Wu and Jinsheng Sun and Weiqing Li and Zhiyong Su},
  doi          = {10.1016/j.engappai.2025.112919},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112919},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A general framework for interactive semantic segmentation refinement of point clouds},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An artificial intelligence-driven analysis of blood-based ternary nanofluid flow: A novel framework for enhanced hemorheological applications. <em>EAAI</em>, <em>163</em>, 112918. (<a href='https://doi.org/10.1016/j.engappai.2025.112918'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computational analysis of blood-integrated nanofluids offer valuable perspectives into therapeutic uses, aiding in the advancement of equipment for developing drugs and targeted administration mechanisms. However, the modelling of the physical processes related to blood-integrated nanotechnology involves considerable intricacy and holds great significance. Considering these factors, we propose computational framework utilizing artificial intelligence (AI) and machine learning (ML) to simulate the hemodynamics of blood-mediated ternary nanofluid flow through parallel plates. Moreover, to investigate the impacts of thermal radiation and Lorentz force on fluid flow, we employed an artificial neural networks (ANNs)-integrated Bayesian regularization algorithm (BRA). The efficiency of the model is maintained by partitioning the dataset into training ( 80 % ) , validation ( 10 % ) , and testing ( 10 % ) subsets to mitigate over-fitting and guarantee optimum accuracy. We convert governing non-linear partial differential equations (PDEs) into ordinary differential equations (ODEs) via similarity transformation, and then applied the improved finite difference discretization known as the Keller-box method (KBM) to evaluate it. Augmenting the squeezing parameter leads to a deceleration of the velocity distribution, whereas an elevated Hartmann number enhances heat transmission. The regression assessments of 1 signify a strong alignment across the observed data and the predicted outcomes. AI was used in this study in two main ways: first, it was used to accurately predict how nanofluids would behave at high temperatures; and second, it was used to find the best way to design nanofluid-based thermal systems that have a lot of potential for use in medicine, especially when it comes to heart health.},
  archive      = {J_EAAI},
  author       = {Mohib Hussain and Du Lin and Hassan Waqas},
  doi          = {10.1016/j.engappai.2025.112918},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112918},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An artificial intelligence-driven analysis of blood-based ternary nanofluid flow: A novel framework for enhanced hemorheological applications},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attentive contrast deep neural network for imbalanced credit scoring. <em>EAAI</em>, <em>163</em>, 112917. (<a href='https://doi.org/10.1016/j.engappai.2025.112917'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit scoring, an effective and crucial risk management tool, has gained significant popularity in the financial market. With the rapid growth of data scale and the diversification of data sources, using neural networks to build credit scoring models has become a promising approach. However, practical challenges such as data imbalance and algorithmic transparency can hinder their widespread application. To develop a balanced and interpretable credit scoring system, this paper proposes an attentive contrast deep neural network (ACNet) inspired by the concept of tree-based neural networks. ACNet incorporates a hierarchical decision-making process, dynamically selecting the most relevant features at each step using sparse attention, enabling efficient learning and improved interpretability. Credit contrastive loss function (CCL) is also specifically designed to facilitate easier differentiation between risky and non-risky loans by maximizing inter-class distance and minimizing intra-class distance. Experiments conducted on four benchmark credit datasets demonstrate that ACNet outperforms neural network-based models in terms of area under the curve (AUC) and geometric mean (G-mean), with improvements of up to 2.97% and 1.82%, respectively. It also performs competitively with advanced ensemble models. ACNet effectively reduces the misclassification rate of risky loans, which can help financial institutions mitigate the potential default risk associated with non-performing borrowers. Moreover, global and local interpretability analyses show that ACNet facilitates a more transparent decision-making process and provides valuable insights for financial institutions.},
  archive      = {J_EAAI},
  author       = {Lexuan Wang and Shengyu Xu and Longyao Zhang},
  doi          = {10.1016/j.engappai.2025.112917},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112917},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Attentive contrast deep neural network for imbalanced credit scoring},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Synchronous detection of strawberry fruit and stem in natural scene using scale edge fusion network and semi-supervised learning. <em>EAAI</em>, <em>163</em>, 112916. (<a href='https://doi.org/10.1016/j.engappai.2025.112916'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For automated strawberry harvesting, the vision-based identification of fruits and their attached stems facilitates determination of optimal picking points, minimizes fruit damage, and enhances harvesting speed and efficiency. To address the challenges in strawberry detection posed by complex backgrounds, morphological diversity, and various occlusions, we propose the Scale Edge Fusion Network (SEFNet). SEFNet incorporates Morphology Clustered Anchor, Edge-Aware Module, and Focused-Feature Pyramid Network to match structural variations between fruits and stems, improve the contour extraction of foreground targets, and strengthen the size adaptability across inter-fruit variations and fruit-stem differences. Additionally, we integrate a student-teacher mutual learning mechanism to construct the Semi-supervised Scale Edge Fusion Network (SSEFNet), which enables precise fruit and stem detection under limited labeled images. Due to the inconsistency in type classification and anchor regression of strawberries and stems, SSEFNet introduces Threshold Adjustment Module and Feature Alignment Strategy to improve the allocation accuracy of pseudo labels and ensure the feature alignment across arbitrary scales. Experiments demonstrate SSEFNet achieves the accurate detection of strawberry fruits and stems in complex scenes under the scarcity of labels with Precision of 91.1 %. In conclusion, SSEFNet effectively reduces the image labeling cost, exhibits strong detection capability of fruits and stems in intricate agricultural environment, and provides reliable support for the construction of stable agricultural intelligent sensing system.},
  archive      = {J_EAAI},
  author       = {Qi Wu and Shengyu Zhang and Junjie Wan and Xinyang Wang and Zhicheng Guo and Mingliang Liu and Shizhuang Weng and Wenshen Jia},
  doi          = {10.1016/j.engappai.2025.112916},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112916},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Synchronous detection of strawberry fruit and stem in natural scene using scale edge fusion network and semi-supervised learning},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An automated framework for converting point cloud data to building information modeling with segmentation and refinement. <em>EAAI</em>, <em>163</em>, 112915. (<a href='https://doi.org/10.1016/j.engappai.2025.112915'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building information modeling (BIM) is important for managing buildings throughout their lifecycle. However, converting point cloud data (PCD) into BIM still depends on manual work. This study proposes a four-stage framework to improve this process. The framework includes PCD preprocessing, instance segmentation, geometric parameter estimation, and industry foundation classes (IFC) model generation. A hybrid method that combines deep learning-based semantic segmentation with unsupervised clustering is used for component recognition. A boundary and corner refinement strategy further improves model consistency. Tests on a residential dataset of 145 rooms show high accuracy, with an average element detection rate of 99.1% and low geometric errors. The ablation study shows that model is sensitive to the choice of noise and voxel size, and the boundary and corner refinement strategy enhances the geometric accuracy and consistency. This method reduces manual effort and supports applications like renovation, facility maintenance, quality inspection, and digital twins.},
  archive      = {J_EAAI},
  author       = {Tianze Chen and Hongxu Wang and Dongsheng Li and Jiepeng Liu and Pengkun Liu and Zhou Wu and Chengran Xu and Meifei Zhang},
  doi          = {10.1016/j.engappai.2025.112915},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112915},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An automated framework for converting point cloud data to building information modeling with segmentation and refinement},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LightKD-MRN:Hierarchical knowledge distillation with multi-task learning for bearing fault diagnosis and damage localization. <em>EAAI</em>, <em>163</em>, 112914. (<a href='https://doi.org/10.1016/j.engappai.2025.112914'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent fault diagnosis and prediction for bearings are crucial in industrial applications. Previous methods often neglected fault severity (fault level), complicating feature extraction due to the coexistence and interference of different fault categories and levels. Additionally, large models with high computational costs hindered engineering deployment. To address these issues, this paper introduces a lightweight knowledge distillation multi-task multi-scale residual diagnostic model (LightKD-MRN). The first stage involves constructing a knowledge-rich teacher model, multi-task multi-scale residual network (MT-MRN). This model performs multi-task learning by jointly optimizing category (T1) and level feature (T2) tasks for cross-task shared feature learning. In the second stage, a lightweight student model is trained via knowledge distillation to transfer knowledge effectively and reduce model size. LightKD-MRN consists of MT-MRN-net and MT-SRN-net, employing a multi-layer Convolutional Neural Networks (CNN) structure to extract features at different scales. It inherits insights from MT-MRN-net through temperature-modulated Kullback-Leibler (KL) divergence loss and L2 regularization, achieving superior performance with fewer parameters. Experimental results demonstrate over 99 % diagnostic accuracy for the proposed LightKD-MRN model in all cases, enhancing accuracy through detailed bearing localization information and showing strong fault tolerance in engineering scenarios, offering a reliable solution for practical applications.},
  archive      = {J_EAAI},
  author       = {Lele Gao and Jinying Huang and Zhenfang Fan and Siyuan Liu and Jinfang Chang},
  doi          = {10.1016/j.engappai.2025.112914},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112914},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {LightKD-MRN:Hierarchical knowledge distillation with multi-task learning for bearing fault diagnosis and damage localization},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Vision differential transformer for brain tumor classification. <em>EAAI</em>, <em>163</em>, 112913. (<a href='https://doi.org/10.1016/j.engappai.2025.112913'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer architectures have shown remarkable success in natural language processing, and their potential in visual data is an active area of research. This study adapts the Differential Transformer (DIFF) architecture to the critical task of brain tumor classification. Using a public Kaggle dataset of 7023 magnetic resonance imaging (MRI) scans, two models are proposed: the Vision Differential Transformer (ViDT) and the Hybrid Vision Differential Transformer (HViDT). A rigorous evaluation was conducted using both a fixed train/test split and a 5-fold cross-validation protocol. The HViDT model demonstrated state-of-the-art performance, achieving 99.31 % accuracy on the fixed test set and a robust mean accuracy of 0.9866 in cross-validation. Critically, the cross-validation revealed that HViDT offers superior stability and reliability, drastically reducing the performance variance of its baseline, with the accuracy improvements being statistically significant (p < 0.05). This top-tier performance was achieved without data augmentation. Furthermore, an interpretability analysis using Gradient-weighted Class Activation Mapping (Grad-CAM) visually confirmed that the HViDT model learns to focus on clinically relevant pathological regions, enhancing its trustworthiness. The findings suggest that the DIFF Transformer architecture offers a promising direction for developing accurate, reliable, and interpretable models for critical applications like brain tumor classification.},
  archive      = {J_EAAI},
  author       = {Muhammed Celik and Ozkan Inik},
  doi          = {10.1016/j.engappai.2025.112913},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112913},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Vision differential transformer for brain tumor classification},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep reinforcement learning-based dynamic integrated scheduling of automated guided vehicles and yard cranes for container terminal loading operations. <em>EAAI</em>, <em>163</em>, 112912. (<a href='https://doi.org/10.1016/j.engappai.2025.112912'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrated scheduling of automated guided vehicles (AGVs) and yard cranes (YCs) is crucial for enhancing loading efficiency in container terminals. However, most existing integrated scheduling models are deterministic and static, which limits their effectiveness in uncertain environments. This paper attempts to find reactive scheduling policies that respond to actual observed information rather than relying on determined handling and transport times. We model the loading operation with uncertain handling and transport times as a semi-open queuing network (SOQN) known as LO-SOQN. LO-SOQN responds instantly to AGV and YC scheduling decisions, which provides quantitative metrics for optimizing dynamic scheduling policies. We formulate the problem as a Markov decision process (MDP) and propose a deep reinforcement learning (DRL) approach to find near-optimal policies. The proposed DRL approach ensures policy generalization by learning uniform state representation, which allows it to be applied to flexible equipment configurations. A series of simulation experiments evaluates the performance of our approach under both fixed and flexible equipment configurations. Compared to the inventory-based and robust fluid policies, the proposed approach reduces the long-term average turnaround time by 10.28 %–18.94 %. Furthermore, the generalization curve indicates the feasibility and effectiveness of training a policy network that generalizes to various equipment configurations.},
  archive      = {J_EAAI},
  author       = {Yuxuan Zhang and Liang Chen and Moshi Zhou and Xiangyu Bao and Funing Jia and Changhui Liu and Lei Zhang and Yu Zheng},
  doi          = {10.1016/j.engappai.2025.112912},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112912},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep reinforcement learning-based dynamic integrated scheduling of automated guided vehicles and yard cranes for container terminal loading operations},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An explainable and adaptive internet of things intrusion detection system supported by large language models. <em>EAAI</em>, <em>163</em>, 112911. (<a href='https://doi.org/10.1016/j.engappai.2025.112911'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the increasing threats targeting Internet of Things (IoT) networks, the development of IoT Intrusion Detection Systems (IDS) has accelerated in recent years. However, existing IDSs often rely on manually labeled data and lack explainability, limiting their adaptability and practical deployment. This paper proposes an Explainable and Adaptive Internet of Things Intrusion Detection System (EADL-IDS) that combines a Denoising Convolutional Autoencoder (DCAE) for unsupervised binary anomaly detection with Large Language Models (LLMs) for multi-class attack interpretation via Retrieval-Augmented Generation (RAG). Compared to prior machine learning and deep learning based IDSs, EADL-IDS eliminates the need for labeled data while achieving higher detection accuracy. Unlike conventional LLM-based IDSs, it integrates a more effective Deep Neural Network (DNN) backbone and structured knowledge retrieval to improve explainability and reduce inference delay. Experiments on the Network Security Laboratory - Knowledge Discovery and Data Mining (NSL-KDD), Canadian Institute for Cybersecurity Internet of Things 2023 (CIC-IoT-2023), and Army Cyber Institute Internet of Things Network Traffic Dataset 2023 (ACI-IoT-2023) datasets show that EADL-IDS achieves over 95% binary accuracy and over 85% multi-class accuracy without supervision, offering a scalable and robust solution for IoT security.},
  archive      = {J_EAAI},
  author       = {Yunfan Huang and Maode Ma and Wong Jee Keen Raymond and Chee-Onn Chow},
  doi          = {10.1016/j.engappai.2025.112911},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112911},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An explainable and adaptive internet of things intrusion detection system supported by large language models},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CGMAE: Self-supervised masked auto-encoder with cross-graph node alignment for node classification. <em>EAAI</em>, <em>163</em>, 112910. (<a href='https://doi.org/10.1016/j.engappai.2025.112910'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Masked Auto-Encoder (MAE) is widely adopted for node classification by recovering the randomly masked graph structure or node attributes. However, traditional MAE methods face two critical challenges: (1) features learned for reconstruction may not align with the downstream classification task, and (2) masking edges risks distorting inherent semantic relationships, degrading representation quality. To overcome these limitations, we propose a simple yet effective self-supervised M asked A uto- E ncoder with C ross- G raph node alignment (CGMAE) for node classification. It leverages labeled nodes from an auxiliary graph to enhance discriminative feature learning in an unlabeled target graph, bridging the task gap between reconstruction and classification. CGMAE introduces a node-level alignment mechanism to address distribution shifts across graphs. This design jointly learns structural patterns and node attributes through specific encoders, enabling multi-view feature matching to refine node representations. Furthermore, CGMAE innovatively predicts masked target edges using aligned nodes from the auxiliary graph, preserving the semantic relationships during reconstruction. Extensive experiments on six diverse networks (standard, complex, sparse, and large-scale graphs) verify the effectiveness and robustness of the proposed method in self-supervised/unsupervised node classification tasks, with accuracy improvements ranging from 1.5%/1.1% to 3.5%/7.0% over state-of-the-art methods. Code is available at https://github.com/songruoxian/CGMAE .},
  archive      = {J_EAAI},
  author       = {Ruoxian Song and Peng Cao and Guangqi Wen and Lanting Li and Wei Liang and Weiping Li and Jinzhu Yang and Osmar R. Zaiane},
  doi          = {10.1016/j.engappai.2025.112910},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112910},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CGMAE: Self-supervised masked auto-encoder with cross-graph node alignment for node classification},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An artificial intelligence-powered design strategy for offshore wind turbine monopiles. <em>EAAI</em>, <em>163</em>, 112909. (<a href='https://doi.org/10.1016/j.engappai.2025.112909'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monopiles support 60 % of existing offshore wind turbines (OWTs). Their effective design and modeling remains expensive and challenging due to complex nonlinear soil-structure interaction (SSI) under varying loads. This study aims to address these issues via an artificial intelligence (AI) model, named pAIle as the combination of “pile” and “AI”, using the long short-term memory (LSTM) model, trained on over 100 experimentally validated, high-fidelity finite element simulations. A new data structuring method has been introduced for LSTM training, where long-sequence data is temporally stacked via feature enrichment. This approach speeds up training by 10-fold while enhancing prediction accuracy, improving the overall R 2 from 0.983 to 0.995. Testing results showed that pAIle efficiently predicts pile head displacements and rotations both at small strains and in the post-failure flow state by reproducing nonlinear SSI, such as damping and cyclic accumulation of plastic strains. Feature importance analysis showed that pAIle correctly understands which physical parameters govern pile head deformations. Exceptional extrapolation performance, evident in an order of magnitude lower normalized mean squared error compared to similar AI models, underscores pAIle's generalization capacity. Comparative studies with other popular AI architectures further demonstrated the effectiveness of LSTM model. Finally, the paper illustrates how this approach can be integrated into existing engineering workflows by enabling rapid monopile size optimization and post-storm integrity assessments. The procedures can complete in less than 2 s on a personal computer, requiring only readily available soil or pile parameters, showing that it is a feasible novel design strategy for OWT monopiles.},
  archive      = {J_EAAI},
  author       = {Bence Kato and Ruizhi Huang and Gang Wang and Ying Wang},
  doi          = {10.1016/j.engappai.2025.112909},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112909},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An artificial intelligence-powered design strategy for offshore wind turbine monopiles},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Current trends and future directions in eye tracking technology: A literature review. <em>EAAI</em>, <em>163</em>, 112908. (<a href='https://doi.org/10.1016/j.engappai.2025.112908'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, literature on eye tracking has seen a significant rise in interest. While previous approaches were often highly intrusive, modern solutions mostly rely on non-intrusive devices such as glasses, headsets, or table cameras. These systems are increasingly reliant on self-assessing eye tracking algorithms powered by advanced machine learning techniques, and for this reason it is fundamental to identify optimized approaches which can work with good performances and reduced computational times. This work serves as a complete review of the current state of the art in available equipment and algorithms, introducing a novel taxonomy of approaches, with a particular emphasis on machine learning and neural networks. Comparative tables of the reviewed studies will also be provided, with an in-depth analysis of the current best algorithms. Additionally, the work will explore the potential applications of eye tracking in everyday life, with a focus on the medical and psychological fields, highlighting its use for both diagnostic and therapeutic purposes. A discussion of the current limitations will be provided to identify the shortcomings of state of the art in eye tracking and pinpoint the aspects which need improvements in future research. Finally, the discussion will address possible future advancements in eye tracking, particularly regarding datasets and algorithmic improvements, providing some directions.},
  archive      = {J_EAAI},
  author       = {Francesca Fiani and Christian Napoli and Cristian Randieri and Samuele Russo},
  doi          = {10.1016/j.engappai.2025.112908},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112908},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Current trends and future directions in eye tracking technology: A literature review},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deconfounding enhanced image-based knowledge distillation for fault diagnosis with an application in manufacturing process. <em>EAAI</em>, <em>163</em>, 112907. (<a href='https://doi.org/10.1016/j.engappai.2025.112907'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) models are widely adopted in fault diagnosis due to their powerful feature extraction capabilities, yet their high computational burden restricts deployment on edge devices. Knowledge distillation (KD) offers a lightweight solution by transferring knowledge from complex teacher models to lightweight student models. However, existing KD methods often fail to extract fault-specific features in images, as background features—highly correlated with labels—can mislead the model. To address this, we propose a deconfounding-enhanced knowledge distillation (DE-KD) method that integrates causal inference into KD to eliminate spurious correlations caused by background confounders. Specifically, a variational autoencoder (VAE) is incorporated to reconstruct the background of input images, enabling the teacher model to isolate and focus on fault-relevant features. The background reconstruction error is used to extract causal feature maps, which are then aligned with intermediate representations in the student model. The student model is trained using a multi-loss function incorporating hard labels, soft labels from the teacher, and deconfounded intermediate features. Applied to carbon accumulation diagnosis in automotive conductor rails, DE-KD achieveshigher accuracy (95.63 %)and improved interpretability compared to state-of-the-art lightweight methods, demonstrating its effectiveness in industrial scenarios.},
  archive      = {J_EAAI},
  author       = {Jianping Zhang and Jie Liu},
  doi          = {10.1016/j.engappai.2025.112907},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112907},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deconfounding enhanced image-based knowledge distillation for fault diagnosis with an application in manufacturing process},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reliability-centered approach to artificial intelligence-driven predictive maintenance for industrial internet of things. <em>EAAI</em>, <em>163</em>, 112906. (<a href='https://doi.org/10.1016/j.engappai.2025.112906'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the integration of artificial intelligence (AI) into predictive maintenance systems within the Industrial Internet of Things (IIoT) to enhance operational efficiency, reduce downtime, and address implementation challenges such as data quality, device interoperability, and cybersecurity risks. The research employs an ordinary least squares (OLS) regression model with fixed effects, supplemented by robustness analysis across varying confidence intervals (p < 0.01 to p < 0.1). Key variables include AI concentration (HHI_D), borrowed AI elements (FGearingratio), and equipment age (lnage), among others. The analysis leverages real-world data from 67 industrial enterprises in China, encompassing 1895 know-how applications from 2020 to 2023, sourced via the China Stock Market & Accounting Research (CSMAR) database. Regression coefficients reveal significant relationships: AI implementation (0.242–0.348), production process impact (0.226–0.247), and equipment age (0.174–0.197). Robustness testing confirms model stability, demonstrating the framework's adaptability to dynamic industrial environments. The study bridges theoretical AI models with practical IIoT deployment, offering actionable insights for predictive maintenance optimization.},
  archive      = {J_EAAI},
  author       = {Wei Wu},
  doi          = {10.1016/j.engappai.2025.112906},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112906},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reliability-centered approach to artificial intelligence-driven predictive maintenance for industrial internet of things},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Ensemble modeling of nanoscale thermal drift in high-precision linear axes for photonic integrated circuit testing. <em>EAAI</em>, <em>163</em>, 112905. (<a href='https://doi.org/10.1016/j.engappai.2025.112905'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The consistently growing demand for robust automated assembly, testing and packaging of photonic integrated circuits, is increasingly oriented towards high volume and continuously sets new challenges to overcome concerning throughput and cost-efficiency. Among the predominant positioning error sources in high-precision robots used in this market, thermally induced position drift is often a major cause of deviation from operational conditions required to meet this demand. Environmental temperature fluctuations and the excess heat generated by the machine itself, can induce position drifts upwards of 100 nanometer per minute that prevent axis systems from meeting positional precision and repeatability required for optimal functioning, eventually imposing the integration of expensive temperature control systems and hardware changes that minimize the impact of thermally induced errors. In this paper, a data driven approach for modeling the temperature induced position drift and its dependency on the underlying temperature gradients is proposed. We suggest a formulation that allows to identify temperature gradients calculated over time windows of variable, optimal widths, that capture longer and shorter term drift components, introducing the concept of dynamic-range thermal features . By extracting several features from a single sensor, it is possible to reduce the amount of sensors required for an accurate reconstruction, resulting in significant hardware simplification and robustness towards variable field conditions. Additionally, an auto-weighted voting regression algorithm is proposed to separate the modeling of transient states from static and quasi-static states; an auto-regressive model of the position gradients with exogenous temperature gradients and a linear regression model of temperature gradients, are trained independently and combined in a voting ensemble paradigm. Experimental results are presented to quantify the effects of a model-based position compensation schema. Under high ambient temperature fluctuations of ± 1 degree Celsius, position drift is reduced from 23 nanometer per minute to 8.7 nanometer per minute root mean squared error. The proposed approach is validated in the context of photonic die testing with a heated chuck hosting the chip. Correction actions reduce thermal effects from 53 nanometer per minute to 10 nanometer per minute root mean squared error under normal working conditions. Finally, effects on the optical coupling loss and the system settle time are evaluated. Optical losses over 5 min measurement time of components with mode field diameters under 3 micrometer, can be reduced below 0.05 decibel for chuck temperatures up to 50 degree Celsius and a two-sided optical alignment; for chuck temperatures above 50 degree Celsius, the settle time to reach sufficient stability for optical measurements is reduced from 82 min to 32 min.},
  archive      = {J_EAAI},
  author       = {Lorenzo Mandelli and Colin Dankwart and Christian Napoli},
  doi          = {10.1016/j.engappai.2025.112905},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112905},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ensemble modeling of nanoscale thermal drift in high-precision linear axes for photonic integrated circuit testing},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Restart mechanism-based multilevel gravitational search algorithm for global optimization and image segmentation. <em>EAAI</em>, <em>163</em>, 112904. (<a href='https://doi.org/10.1016/j.engappai.2025.112904'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a multilevel gravitational search algorithm with a restart mechanism designed to enhance the adaptability and performance of the standard gravitational search algorithm (GSA) in complex optimization tasks. While GSA has been successfully applied in various domains, it often suffers from premature convergence and poor diversity, especially in multimodal landscapes. The proposed algorithm addresses these limitations through three key innovations: (i) a multilevel hierarchical structure based on individual fitness, enabling targeted learning and guidance across layers; (ii) a competition-collaboration mechanism within each layer that classifies individuals as winners or losers and drives differential learning behavior; and (iii) a stagnancy detection and restart mechanism using estimation of distribution and differential mutation strategies to reintroduce diversity and accelerate convergence. Ablation studies confirm that the hierarchical layer design and the control parameter significantly influence the algorithm’s exploration–exploitation balance. In particular, we observed that the restart mechanism improves the average convergence speed on the CEC 2017 benchmark suite compared to baseline GSA. Across 30-, 50-, and 100-dimensional problems, the proposed algorithm consistently outperforms GSA variants and other metaheuristic algorithms, delivering superior accuracy, stability, and convergence rates. Furthermore, the proposed algorithm achieves competitive results in multilevel image thresholding tasks using the Berkeley Segmentation Dataset and Benchmark (BSDS300). These findings highlight the effectiveness of combining hierarchical guidance with adaptive restart strategies in enhancing the robustness and efficiency of GSA in high-dimensional, multimodal optimization scenarios.},
  archive      = {J_EAAI},
  author       = {Dikshit Chauhan},
  doi          = {10.1016/j.engappai.2025.112904},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112904},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Restart mechanism-based multilevel gravitational search algorithm for global optimization and image segmentation},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhance multi-modal structured representations with open information extraction. <em>EAAI</em>, <em>163</em>, 112903. (<a href='https://doi.org/10.1016/j.engappai.2025.112903'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current large-scale vision-language models are expanding their range of applications and have achieved impressive performance in multi-modal tasks. However, the performance of existing models in expressing structured semantic information is of concern, as they have difficulty distinguishing the relationship between subjects and objects in some scene-specific images. This is because the feature learning process in multi-modal task scenarios does not incorporate structured knowledge into the model. In this study, we propose an enhanced end-to-end contrastive language-image pre-training (CLIP) model with open information extraction (OIE-CLIP), which is used to assist in the training of multi-modal models for short texts by integrating structured knowledge representations to enhance the ability of multi-modal representation of structured information. OIE-CLIP leverages the construction of effective negative examples to enhance contrastive learning. In addition, we propose a triple knowledge encoder (TKE) based on the output of open information extraction (OIE) to further boost the structured representation capability of the multi-modal model. To verify the validity of our approach, we pre-trained the model with the above method and downstream experiments in multi-modal tasks. The experimental results show that our method performs best on the public datasets visual genome attribution (VG-Attribution) and visual genome relation (VG-Relation), outperforming the multi-modal state-of-the-art model by 2.2% and 1.8%, respectively. Furthermore, our experimental results on the Microsoft Common Objects in Context (MSCOCO) dataset further demonstrate that our method can effectively improve the structured representations.},
  archive      = {J_EAAI},
  author       = {Jiabao Han and Wei Zhong and Cheng Wang and Ying Zhang and Cheng Ding and Luwei Luo},
  doi          = {10.1016/j.engappai.2025.112903},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112903},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhance multi-modal structured representations with open information extraction},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Exploring magnetic actuation automation: Learning from noisy demonstrations via adaptive sampling policy. <em>EAAI</em>, <em>163</em>, 112902. (<a href='https://doi.org/10.1016/j.engappai.2025.112902'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic actuation enables contactless manipulation of miniaturized objects and holds great potential for vascular interventional surgery. Achieving effective operation in such complex environments requires robust and adaptable control algorithms. Data-driven approaches offer a promising avenue, but collecting sufficient high-quality demonstrations is costly and challenging. As a result, available training data are often sparse and noisy, limiting the robustness, generalization, and direct applicability of learning-based methods in real-world vascular procedures. To overcome these challenges, we propose a learning-based framework that leverages noisy demonstrations to automate dual-arm magnetic actuation in simulated vascular environments. The framework integrates multimodal inputs, including visual, pose, and force information, and employs an adaptive sampling policy to identify the most informative demonstrations. This design enables end-to-end control of robotic joints while reducing data requirements and enhancing robustness. Extensive experiments show that our method outperforms mainstream learning algorithms in offline benchmarks and achieves zero-shot deployment on a magnetic actuation prototype, successfully performing in-vitro aortic vascular intervention procedures using only 20 noisy demonstration trajectories. Quantitatively, compared with the uniform sampling baseline, our method reduces task completion time by 6.5 s and increases valid magnetic actuation steps by 5.44% in real-world execution, highlighting its superior robustness, sample efficiency, and clinical applicability in vascular interventional tasks.},
  archive      = {J_EAAI},
  author       = {Xutian Deng and Jianhui Zhao and Zhiyong Yuan and Bo Du and Miao Li and Zhijian Yang},
  doi          = {10.1016/j.engappai.2025.112902},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112902},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploring magnetic actuation automation: Learning from noisy demonstrations via adaptive sampling policy},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An explainable machine learning framework for long-term spatiotemporal incident modeling in expanding urban rail networks. <em>EAAI</em>, <em>163</em>, 112900. (<a href='https://doi.org/10.1016/j.engappai.2025.112900'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban rail transit has become a cornerstone of public transportation in major cities. However, as these systems have grown more complex, incidents disrupting operations have become more frequent, reducing travel efficiency and posing risks to passenger safety. This study introduces an interpretable machine learning framework for analyzing trends in transit incidents over the past decade, using data from the Beijing Subway collected from 2013 to 2022. Twelve indicators across four categories—structural, topological, operational, and weather-related—were examined, and both traditional regression and advanced machine learning models were applied to model long-term trends. Model evaluation indicates that the eXtreme Gradient Boosting (XGBoost) model best captures the relationships between these factors and line safety, achieving a coefficient of determination (R 2 ) of 0.8167 and a Root Mean Square Error (RMSE) of 4.6929. Interpretability analyses reveal the spatiotemporal dynamics and mechanisms driving incident occurrences. Operational characteristics and network centrality are the primary determinants of incident frequency, accounting for 37.6 % and 26.1 %, respectively. Temporal patterns show that the influence of operational features grew by about 3 % before 2019 but declined by 8 % from 2019 to 2022, while structural features have steadily increased by about 6 % in importance over the past decade. These insights can guide the optimal allocation of safety resources, ultimately enhancing the security and efficiency of urban rail transit systems.},
  archive      = {J_EAAI},
  author       = {Pengcheng Li and Linmu Zou and Zijia Wang and Yadi Zhu and Lu Zhao and Feng Chen},
  doi          = {10.1016/j.engappai.2025.112900},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112900},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An explainable machine learning framework for long-term spatiotemporal incident modeling in expanding urban rail networks},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Intelligent prediction framework for thermogravimetric behavior of cement-based materials with theoretical model embedding. <em>EAAI</em>, <em>163</em>, 112899. (<a href='https://doi.org/10.1016/j.engappai.2025.112899'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermogravimetric analysis (TGA) offers valuable insights into hydration phase composition and reaction kinetics, but traditional experimental methods are time-consuming and labor-intensive for comprehensive multi-variable studies. This study introduces a novel hybrid framework that utilizes the output results of theoretical models as input features for machine learning to predict thermogravimetric behavior under various environmental conditions and different cement types. The dimensionality of the input features is reduced by converting the chemical composition of cement into the theoretical maximum calcium hydroxide content (CH 0 %) and theoretical maximum calcium carbonate content (C max %) based on stoichiometric relationships. In addition, the thermogravimetric curves are segmented based on the decomposition ranges of specific hydration products, ranging from calcium hydroxide to calcium carbonate segments (TG CH-CC ), which facilitates a more targeted analysis. The results demonstrate that the machine learning models achieve high accuracy, as evidenced by their strong performance metrics on the test dataset. The proposed framework demonstrates strong generalization capability, providing reliable predictions for different cement types and conditions within the trained range of features. This hybrid approach enables a systematic study of the effects of environmental variables and mineral compositions on cement hydration mechanisms. And it significantly reduces reliance on repetitive experimental measurements, thereby promoting more efficient and sustainable practices in cement research.},
  archive      = {J_EAAI},
  author       = {Kechang Wu and Yaozhi Luo and Dianchao Wang and Qingkai Chen and Qiliang Zhao and Takafumi Noguchi and Weijian Zhao and Bochao Sun},
  doi          = {10.1016/j.engappai.2025.112899},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112899},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent prediction framework for thermogravimetric behavior of cement-based materials with theoretical model embedding},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physical and virtual safety evaluation in autonomous driving systems using three-dimensional adversarial implementations. <em>EAAI</em>, <em>163</em>, 112898. (<a href='https://doi.org/10.1016/j.engappai.2025.112898'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensuring the safety of autonomous driving systems against adversarial attacks is a critical challenge, especially when such attacks occur in the physical world. Existing methods typically focus on assessing safety in isolated images, failing to address the continuous operation of autonomous vehicles under adversarial conditions. To overcome this limitation, this study introduces a comprehensive framework that evaluates both physical and virtual safety to ensure sustained vehicle safety during continuous operation. The framework consists of two key innovations: the three-dimensional (3D) physical implementation of adversarial textures and a safety evaluation framework using novel metrics. The 3D physical implementation provides a robust platform to test the system response to physical threats. The second and primary innovation, the safety evaluation, introduces the Safety Score to quantify physical safety and the Collaborative Efficiency Deterioration Rate (CEDR) to assess virtual safety, with the ultimate objective of improving driving safety under adversarial conditions. Simulated experiments validate the effectiveness of these metrics in identifying security vulnerabilities and provide insights into improving the resilience of autonomous driving technologies. Although the evaluation is conducted in simulation, it is designed to reflect real-world constraints. This research provides a reference for the safety evaluation of automatic driving in practical applications.},
  archive      = {J_EAAI},
  author       = {Yixun Zhang and Jianqin Yin and Yiyang Ma and Yingchun Niu and Xubo Zhang},
  doi          = {10.1016/j.engappai.2025.112898},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112898},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Physical and virtual safety evaluation in autonomous driving systems using three-dimensional adversarial implementations},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Highway slope stability evaluation model based on similarity measures of spherical single-valued neutrosophic sets. <em>EAAI</em>, <em>163</em>, 112897. (<a href='https://doi.org/10.1016/j.engappai.2025.112897'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Highway slope stability is a critical factor for transportation safety. However, its reliable evaluation remains challenging due to the complexity and uncertainty of highway slope influencing factors. This paper presents a highway slope stability evaluation (HSSE) model based on similarity measures of spherical single-valued neutrosophic sets (S-SVNSs). First, the concept of S-SVNSs is proposed, where each element consists of a sphere of a specified radius and a single-valued neutrosophic value (SVNV). The uncertainty and ambiguity of the object are represented using the true, indeterminate, and false membership degrees, each associated with corresponding uncertainties. Furthermore, the relationships between S-SVNSs, as well as the Hamming and Euclidean distances and their corresponding similarity measures, are defined. Based on this, an HSSE model is developed. This model characterizes highway slope data based on the S-SVNSs and quantifies the proximity between the target slope and the benchmark case, thereby enabling more accurate classification of highway slopes. The efficacy of the proposed HSSE model has been validated on practical highway slopes in Zhejiang Province. Results based on the confusion matrix show that the model achieves an accuracy of 95.0 %, outperforming existing methods. These results demonstrate that the proposed HSSE model based on the similarity measures of S-SVNSs provides a reliable and effective tool for highway slope stability assessment under uncertain environments.},
  archive      = {J_EAAI},
  author       = {Jun Ye and Rui Yong and Jibo Qin},
  doi          = {10.1016/j.engappai.2025.112897},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112897},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Highway slope stability evaluation model based on similarity measures of spherical single-valued neutrosophic sets},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rapid gyroscope calibration: A deep learning approach. <em>EAAI</em>, <em>163</em>, 112896. (<a href='https://doi.org/10.1016/j.engappai.2025.112896'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-cost gyroscope calibration is essential for ensuring the accuracy and reliability of gyroscope measurements. Stationary calibration estimates the deterministic parts of measurement errors. To this end, a common practice is to average the gyroscope readings during a predefined period and estimate the gyroscope bias. Calibration duration plays a crucial role in performance, therefore, longer periods are preferred. However, some applications require quick startup times and calibration is therefore allowed only for a short time. In this work, we focus on reducing low-cost gyroscope calibration time using deep learning methods. We propose an end-to-end convolutional neural network for the application of gyroscope calibration. We explore the possibilities of using multiple real and virtual gyroscopes to improve the calibration performance of single gyroscopes. To train and validate our approach, we recorded a dataset consisting of 186.6 h of gyroscope readings, using 36 gyroscopes of four different brands. We also created a virtual dataset consisting of simulated gyroscope readings. The six datasets were used to evaluate our proposed approach. One of our key achievements in this work is reducing gyroscope calibration time by up to 89% using three low-cost gyroscopes. Our dataset is publicly available to allow reproducibility of our work and to increase research in the field.},
  archive      = {J_EAAI},
  author       = {Yair Stolero and Itzik Klein},
  doi          = {10.1016/j.engappai.2025.112896},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112896},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Rapid gyroscope calibration: A deep learning approach},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel deep learning model for defect detection in photovoltaic panels using visible light imaging. <em>EAAI</em>, <em>163</em>, 112895. (<a href='https://doi.org/10.1016/j.engappai.2025.112895'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photovoltaic panel defects are the primary cause of failure in photovoltaic power generation. Visible light imaging offers broad coverage and low cost, enabling extensive inspections. To address the current limitations of low precision and high image data requirements in defect detection algorithms based on visible light imaging, this paper proposes a novel visible light image defect detection algorithm for photovoltaic panels. This algorithm builds upon the popular deep learning framework You Only Look Once (YOLO), proposing a new module that integrates a hybrid attention transformer into the cross-stage partial bottleneck with two convolutional backbones to achieve super-resolution functionality specifically for photovoltaic panel defect images, improving detection accuracy. Subsequently, an efficient layer aggregation network was constructed to enhance the efficiency of feature extraction from target images. Finally, a selective kernel network is added before the detection head to enhance the model’s ability to recognize multi-scale targets on photovoltaic panel defects. Compared to previous models, the proposed tool demonstrates superior efficiency, accuracy, and robustness in identifying defects from visible light images of photovoltaic panels. On the photovoltaic panel visible light image dataset, the proposed algorithm shows outstanding performance, achieving a mean average precision of 88.98% and outperforming the original model and other state-of-the-art models across four performance metrics. This identification algorithm provides automated inspection and monitoring capabilities for photovoltaic panels under visible light conditions.},
  archive      = {J_EAAI},
  author       = {Ling Zhu and Jianyu Cheng and Guangyu Liu},
  doi          = {10.1016/j.engappai.2025.112895},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112895},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel deep learning model for defect detection in photovoltaic panels using visible light imaging},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive time series classification using virtual adversarial domain adaptation techniques. <em>EAAI</em>, <em>163</em>, 112894. (<a href='https://doi.org/10.1016/j.engappai.2025.112894'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proposed work explores Time Series Classification (TSC) across various applications, including human activity recognition, healthcare, and machine fault diagnosis. These temporal data from disparate domains pose a significant challenge in TSC due to the inherent variability in their distributions. Unsupervised Domain Adaptation (UDA) methods are an effective solution for addressing these distribution disparities. The proposed work initially utilizes a norm-distance and correlation alignment to achieve feature similarity and statistical alignment between the source and target domains. However, these techniques may not capture the domain’s persistent features due to the complex characteristics of the temporal data. Hence, domain and virtual adversarial training are applied to acquire invariant feature representations across domains globally, ensuring local smoothness in the model’s output distribution. Therefore, we put forward a unified approach to Virtual Adversarial and Statistical unsupervised domain adaptation for TSC (VASAD) . As a result, the model learns the intrinsic relationships among the temporal data points, enhances the model’s robustness to perturbations, and aligns the domains into a shared subspace, thereby minimizing distribution discrepancies. A thorough experimental analysis is done using different datasets related to human activity, fault diagnosis, and sleep classification. The results are compared against state-of-the-art methods, and the proposed approach consistently outperforms them.},
  archive      = {J_EAAI},
  author       = {Lekshmi R. and Babita Roslind Jose and Jimson Mathew},
  doi          = {10.1016/j.engappai.2025.112894},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112894},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive time series classification using virtual adversarial domain adaptation techniques},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Progressive information integration in lightweight image super-resolution. <em>EAAI</em>, <em>163</em>, 112893. (<a href='https://doi.org/10.1016/j.engappai.2025.112893'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based models have considerably improved image super-resolution (SR). However, these networks fail to design multi-operations aggregation architecture with guidance of SR knowledge. To tackle these drawbacks, we propose a novel progressive information integration (PII) module. It extracts the input features from progressive perspectives: a dense region, sparse region, and three-dimensional space. We employ a local convolution block to access pixels in the dense region and window-based self-attention for those in the sparse region. To leverage the advantages of both channel-attention and spatial-attention schemes, we introduce a Hybrid Attention block (HAB). This block enables the effective use of pixels in three-dimensional space by combining the complementary benefits of the two attention schemes. As an artificial intelligence (AI) -driven approach, our method is applied to lightweight image super-resolution tasks, aiming to balance performance and computational efficiency. Extensive experiments demonstrate that our PII-based super-resolution (PII-SR) achieves the superior results on lightweight SR benchmarks with fewer parameters (e.g., 26.81 dB (dB)@Urban100 × 4 with only 652 thousand (K) parameters).},
  archive      = {J_EAAI},
  author       = {Longfeng Shen and Jiacong Chen and Liangjin Diao and Lei Liu and Fenglan Qin and Fangzhen Ge},
  doi          = {10.1016/j.engappai.2025.112893},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112893},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Progressive information integration in lightweight image super-resolution},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Time-series clustering: A benchmark study on energy data with insights into demand response. <em>EAAI</em>, <em>163</em>, 112892. (<a href='https://doi.org/10.1016/j.engappai.2025.112892'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a comprehensive benchmarking framework for time-series clustering, addressing the lack of standardized guidelines for selecting appropriate approach for clustering tasks. The framework derives and evaluates 15 clustering pipelines comprising multiple well-known clustering techniques and diverse distance metrics, with the constraint of using the same number of clusters for all pipelines to ensure comparability and consistency in the evaluation process. The procedure for standardizing clustering labels, generating ensemble outcomes, and incorporating a stability score is introduced to provide a comprehensive and rigorous evaluation of clustering pipelines. The challenge posed by arbitrary label assignments across different pipelines is resolved through a standardization process that aligns the clusters for meaningful comparison. The ensemble approach mitigates inconsistencies in clustering results and addresses the limitations of traditional clustering validity metrics, leading to more stable and reliable groupings. Additionally, the inclusion of a novel stability score adds a critical layer of evaluation, enabling the identification of the most consistent and accurate clustering outcomes. The results highlight limitations of traditional quality metrics, while showcasing the strong performance for various pipelines with more than 90% of similarity with ensemble results. This would aid in informed selection of the best pipelines for specific applications. The framework is further discussed in the context of optimizing clustering for demand response strategies in smart grids, highlighting its real-world relevance. To support transparency and reproducibility, the study provides open-source code for validating and applying it to various time-series datasets, offering a robust tool for benchmarking clustering across domains.},
  archive      = {J_EAAI},
  author       = {Rajesh K. Ahir and Benoit Delinchant and Arvind Easwaran},
  doi          = {10.1016/j.engappai.2025.112892},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112892},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Time-series clustering: A benchmark study on energy data with insights into demand response},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Vector attention-based point cloud network for semantic segmentation of sewer sonar data. <em>EAAI</em>, <em>163</em>, 112891. (<a href='https://doi.org/10.1016/j.engappai.2025.112891'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sonar technology is unaffected by lighting or water conditions, making it ideal for inspecting water-filled sewers. Nonetheless, significant challenges remain in utilizing sonar point clouds effectively. This research introduces the Vector Attention-based Point Cloud Network (VAPCNet), a deep learning method for semantic segmentation of sewer sonar point clouds. It is based on a U-Net style encoder-decoder architecture and consists of the attention module, the contraction module, and the expansion module. Additionally, to mitigate data imbalance, a weighted focal loss was employed during training. VAPCNet demonstrates excellent performance on a sewer dataset collected by a sonar robot, achieving an overall accuracy of 95.9 % and a mean Intersection over Union (mIoU) of 86.4 %. It demonstrates robustness to point perturbations and supports a lightweight design by adjusting encoder stages without sacrificing accuracy. These advantages make VAPCNet an innovative solution for employing sonar technology in sewer detection, emphasizing its practical potential.},
  archive      = {J_EAAI},
  author       = {Wenli Liu and Yueming Jiang and Hanlin Li and Lei Yang and Hanbin Luo},
  doi          = {10.1016/j.engappai.2025.112891},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112891},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Vector attention-based point cloud network for semantic segmentation of sewer sonar data},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel attention-based long short-term memory latency prediction model for stream processing applications. <em>EAAI</em>, <em>163</em>, 112890. (<a href='https://doi.org/10.1016/j.engappai.2025.112890'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of the Internet of Things has led to a significant increase in the number and types of smart devices, resulting in an exponential growth of streaming data volume and types. Consequently, many fields have adopted stream processing application (SPA) to handle real-time processing scenarios. Practitioners and scientists across various domains rely on latency prediction of these applications, which is essential for performance analysis and proactive optimization. However, predicting the latency of SPAs remains challenging due to their diverse types and internal complexity. To accurately predict the latency, this paper explores related work extensively and investigates the directed acyclic graph characteristics of such applications. Three kinds of features (i.e., application features, data features, and system features) are identified and summarized as major factors influencing latency. Furthermore, we propose and implement a artificial intelligence-based real-time prediction framework in Apache Flink, a popular stream processing system, for application latency prediction. This framework collects three types of real-time metrics, constructs features, and utilizes an attention-based long short-term memory recurrent neural network model to accurately predict latency at run-time. Experimental results from six benchmarks show that the proposed model accurately predicts latency using the identified features. More importantly, our model outperforms the state-of-the-art model in terms of prediction error and accuracy due to the proposed real-time framework and attention mechanism. Furthermore, our model can achieve high prediction accuracy for newly developed applications in a short time.},
  archive      = {J_EAAI},
  author       = {Zheng Chu and Dongwen Chen and Xinfeng Zhang and Baozhu Li and Jiong Yu and Xusheng Du and Jian Zhou and Weiyun Li},
  doi          = {10.1016/j.engappai.2025.112890},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112890},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel attention-based long short-term memory latency prediction model for stream processing applications},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhanced you only look once model with frequency feature enhancement and illumination perception for duck behavior recognition in dynamic light scenarios. <em>EAAI</em>, <em>163</em>, 112889. (<a href='https://doi.org/10.1016/j.engappai.2025.112889'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern intensive duck farming has improved production efficiency while facing health problems for ducks. As duck behaviors are closely related to their health status, accurately monitoring their behaviors is necessary. With the development of artificial intelligence (AI), the application of AI offers an effective approach to animal behavior recognition. Currently, accurately recognizing duck behaviors consistently from day to night remains a challenge. This challenge stems from the persistent dynamic changes in light, which can lead to significant performance degradation in conventional behavior recognition methods. To overcome this challenge, this study proposes an enhanced You Only Look Once version 11 small (YOLOv11s) with frequency feature enhancement and illumination perception for duck behavior recognition in dynamic light scenarios (FIY4DBR). Specifically, to tackle the problem of unclear edge, texture, and behavior characteristics of ducks in the low-light condition, a frequency feature enhancement mechanism (FFEM) is designed, which effectively enhances the duck feature representation ability. Additionally, to improve the model’s robustness to light variations, an illumination perception mechanism (IPM) is developed, which adjusts the contrast of objects and background features according to different brightness conditions, thereby enhancing the model’s generalization capability across different brightness scenarios. Experimental simulations on the self-built dataset show that FIY4DBR achieves an average recognition precision of 92.0% and recall of 88.8%, representing improvements of 1.8 and 3.6 percentage points over the baseline YOLOv11s. This demonstrates that the proposed FIY4DBR provides a high-precision and highly adaptive solution for intelligent livestock behavior monitoring, contributing to advancing the development of intelligent farming technologies.},
  archive      = {J_EAAI},
  author       = {Gen Zhang and Chuntao Wang and Deqin Xiao},
  doi          = {10.1016/j.engappai.2025.112889},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112889},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced you only look once model with frequency feature enhancement and illumination perception for duck behavior recognition in dynamic light scenarios},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A high-precision and efficient method for coal–rock characteristic identification utilizing coal wall temperature field. <em>EAAI</em>, <em>163</em>, 112888. (<a href='https://doi.org/10.1016/j.engappai.2025.112888'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coal-rock characteristic identification is a crucial technology for realizing shearers intelligent control. To enhance the intelligence level of shearers, this paper presents a novel approach for identifying coal–rock characteristics using the temperature field of the coal wall. First, we introduce an enhanced You Only Look Once (YOLO) model, termed Temperature sensitive region-YOLO (TSR-YOLO), specifically designed to extract temperature-sensitive regions within the coal wall temperature field. In terms of structural design, TSR-YOLO innovatively incorporates the Cross Stage Partial FasterNet (C3k2-FasterNet) into the backbone network to accelerate feature extraction and devises the Cross-Stage Partial Kolmogorov–Arnold Network (C3k2-KAN) to enhance detailed feature representation. In the bottleneck network, it integrates the Dynamic Convolution (DynamicConv) module to capture broader and more complex feature, as well as the Variational Overlapping Vision-Generalized Spatial Cross-Stage Partial (VoV-GSCSP) module to enhance computational efficiency and optimize feature extraction performance. Subsequently, we propose a coal–rock characteristic identification method utilizing the ConvNeXt model. To validate its effectiveness, we conduct ablation and comparative experiments using experimental data obtained from infrared images of the coal wall during the shearer cutting process. The results indicate that proposed approach achieves a mean Average Precision (mAP) reaching 98.1% and an inference speed of 2 ms per image in identifying temperature-sensitive regions of the coal wall temperature field, surpassing other comparative models. Furthermore, the accuracy of coal–rock property identification reaches 97.6%. This study presents a new approach to coal–rock characteristic identification methods.},
  archive      = {J_EAAI},
  author       = {Futao Li and Zhongbin Wang and Dong Wei and Xin Li and Lei Si and Jinheng Gu and Jialiang Dai},
  doi          = {10.1016/j.engappai.2025.112888},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112888},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A high-precision and efficient method for coal–rock characteristic identification utilizing coal wall temperature field},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The moderating effect of income and training on design engineers’ adoption of artificial intelligence: An extended unified theory of acceptance and use of technology approach. <em>EAAI</em>, <em>163</em>, 112887. (<a href='https://doi.org/10.1016/j.engappai.2025.112887'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The world is increasingly embracing Artificial Intelligence (AI) as a transformative force in the construction industry. AI adoption offers benefits such as improved design processes, increased speed and accuracy, and cost reduction. Given the importance of this issue, the present study aims to investigate the role of moderators, including income, training courses, gender, and age, among the factors affecting the acceptance of AI within the relationships of the Unified Theory of Acceptance and Use of Technology 2 (UTAUT2) model among design engineers in the construction industry. Partial Least Squares Structural Equation Modeling (PLS-SEM) was used to examine the model of this study. Data were collected from 268 design engineers through a structured survey instrument and validated for reliability and content adequacy. Results indicate that monthly income significantly moderates the relationships between Social Influence (SI) and Performance Expectancy (PE), Price Value (PV) and PE, Hedonic Motivation (HM) and Effort Expectancy (EE), HM and Habit (HT), and SI and HM. Moreover, construction-design training courses taken in the last year significantly moderate the relationships between Behavioral Intention (BI) and Use Behavior (USE), SI and USE, Facilitating Conditions (FC) and BI, and SI and PE. Furthermore, the mediating pathways of various variables were examined within the research model. The findings of this research contribute to a deeper understanding of the factors driving AI adoption in construction design, providing valuable insights for policymakers.},
  archive      = {J_EAAI},
  author       = {Ali Katebi and Mahdi Tehrani},
  doi          = {10.1016/j.engappai.2025.112887},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112887},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The moderating effect of income and training on design engineers’ adoption of artificial intelligence: An extended unified theory of acceptance and use of technology approach},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Upsampling graph convolutional neural networks enhanced multimodal multi-objective evolutionary algorithm. <em>EAAI</em>, <em>163</em>, 112886. (<a href='https://doi.org/10.1016/j.engappai.2025.112886'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, neural networks have been widely adopted to solve multimodal multi-objective optimization problems (MMOPs) due to their good learning ability. However, general neural networks are not good at dealing with population data with non-Euclidean structure. Therefore, this paper proposes a graph convolutional networks (GCN) enhanced multimodal multi-objective evolutionary algorithm, which can utilize GCN to learn the complex distribution of Pareto optimal solution set in the decision space and generate diversified offspring with good convergence through upsampling operation to balance the diversity and the convergence. Specifically, the population is represented as the graph-structured data based on the Euclidean distance in the decision space, and GCN is employed to aggregate the features of solutions and neighbors. Moreover, a linear interpolation is utilized to upsample the aggregation results of GCN, and the offspring with good exploitation performance are obtained. Subsequently, a maximum difference selection mechanism is designed to select solutions in the less dense regions by measuring the distribution similarity between the parent and the offspring, thereby enhancing the diversity. The proposed algorithm is compared with eight advanced algorithms on 56 MMOPs and the location planning problem. The results show that the proposed algorithm performs well in maintaining the diversity and the convergence and finds many best locations in the location planning problem.},
  archive      = {J_EAAI},
  author       = {Lei Yang and Qianlong Dang and Erlei Zhang},
  doi          = {10.1016/j.engappai.2025.112886},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112886},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Upsampling graph convolutional neural networks enhanced multimodal multi-objective evolutionary algorithm},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Tissue-contrastive semi-masked autoencoders for segmentation pretraining on chest computed tomography. <em>EAAI</em>, <em>163</em>, 112885. (<a href='https://doi.org/10.1016/j.engappai.2025.112885'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Masked Image Modeling (MIM) depends on a spatial patch-based masking-reconstruction strategy to perceive objects’ features from unlabeled images, which may face two limitations when applied to chest Computed Tomography (CT): (1) inefficient feature learning due to complex anatomical details presented in CT images, and (2) suboptimal knowledge transfer owing to input disparity between upstream and downstream models. To address these issues, we propose a new MIM method named Tissue-Contrastive Semi-Masked Autoencoder (TCS-MAE) for modeling chest CT images. Our method has two novel designs: (1) a tissue-based masking-reconstruction strategy to capture more fine-grained anatomical features, and (2) a dual-AE architecture with contrastive learning between the masked and original image views to bridge the gap between the upstream and downstream models. Through these strategies, the pretrained model can learn homogeneous tissue representations to improve the segmentation of heterogeneous lesions. To validate our method, we systematically investigate representative contrastive, generative, and hybrid self-supervised learning methods on top of tasks involving segmenting pneumonia, mediastinal tumors, and various organs. The results demonstrate that, compared to existing methods, our TCS-MAE more effectively learns tissue-aware representations, thereby significantly enhancing segmentation performance across all tasks. The code and datasets is available at: https://github.com/zhengjjjjie/TCS-MAE .},
  archive      = {J_EAAI},
  author       = {Jie Zheng and Ru Wen and Can Han and Wei Chen and Chen Liu and Jun Wang and Kui Su},
  doi          = {10.1016/j.engappai.2025.112885},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112885},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Tissue-contrastive semi-masked autoencoders for segmentation pretraining on chest computed tomography},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A combined short-term power load forecasting system based on generative adversarial networks. <em>EAAI</em>, <em>163</em>, 112884. (<a href='https://doi.org/10.1016/j.engappai.2025.112884'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate electricity load forecasting is essential for supporting economic growth and achieving carbon peak objectives. Many conventional prediction models overlook the necessity of data preprocessing and rely on single forecasting structures, resulting in limited prediction accuracy. This paper presents a novel framework that combines data preprocessing, generative adversarial networks forecasting, and intelligent weighting to enhance prediction performance. The data preprocessing phase utilizes optimized decomposition layers and penalty factors to achieve intelligent denoising. The generative adversarial networks component captures highly complex nonlinear relationships in load sequences through adversarial learning, improving system robustness. Intelligent weighting further refines the forecasting results by integrating point predictions with residual values. Experimental results demonstrate that the proposed system significantly outperforms benchmark models in prediction accuracy.},
  archive      = {J_EAAI},
  author       = {Jinze Li and Jianzhou Wang and Ahmed M. El-Sherbeeny and Zhiwu Li},
  doi          = {10.1016/j.engappai.2025.112884},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112884},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A combined short-term power load forecasting system based on generative adversarial networks},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive spatial–temporal graph attention network for real-time traffic forecasting. <em>EAAI</em>, <em>163</em>, 112883. (<a href='https://doi.org/10.1016/j.engappai.2025.112883'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient Multivariate Time Series Forecasting (MTSF) plays a critical role in intelligent transportation systems by supporting real-time traffic management. However, achieving reliable forecasting remains challenging due to complex and dynamically evolving spatial–temporal patterns. Existing forecasting methods often fail to adapt effectively to these dynamic traffic conditions and typically incur high computational costs, significantly limiting their deployment in real-time traffic management scenarios. To address these engineering challenges, this study proposes a novel Attention-based Spatial-Temporal Network (ASTNet), explicitly designed for adaptive and efficient real-time traffic forecasting. ASTNet introduces two innovative Artificial Intelligence (AI)-driven modules: an Adaptive Spatial Graph Encoder (ASGE), which dynamically models evolving spatial dependencies from real-time traffic data, thus overcoming the limitations of static graph structures; and a Temporal Attention-Gated Unit (TAGU), which efficiently captures critical temporal dependencies through the integration of recurrent gating mechanisms and self-attention techniques. Extensive evaluations conducted on widely-used traffic benchmark datasets (PEMS04, METR-LA, etc.) confirm that ASTNet achieves superior predictive accuracy and robustness compared to state-of-the-art methods, while significantly reducing inference latency. Ablation studies further validate that the combined innovations of ASGE and TAGU are crucial for ASTNet’s outstanding performance, highlighting its practical suitability and strong potential for deployment in real-time intelligent transportation applications.},
  archive      = {J_EAAI},
  author       = {Hao Huang and Jee-Hyong Lee and Yanling Ge and Seok-Beom Roh and Xue Zhao},
  doi          = {10.1016/j.engappai.2025.112883},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112883},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive spatial–temporal graph attention network for real-time traffic forecasting},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Symbolic representation of objects relative poses for robotic manipulation tasks. <em>EAAI</em>, <em>163</em>, 112882. (<a href='https://doi.org/10.1016/j.engappai.2025.112882'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative robots (cobots) are democratizing industrial automation with their user-friendly programming approaches. Nevertheless, the Blockly-like interfaces typically available on cobots still require the user to define the program logic flow. Recent advancements in robotics research provide the robotic system with the reasoning capabilities given by symbolic artificial intelligence. This way, the cobot can acquire a new skill from a user demonstration, understand its semantics, and use symbolic planning for grounding and sequencing. Such methodologies rely on a symbolic description of the scene that should adequately represent how the cobot’s actions modify the environment. The symbols employed in the literature, however, either lack descriptive accuracy or are too specific for the targeted task, resulting in the application of the proposed teaching methodologies only to simple scenarios. This paper addresses these issues by introducing a methodology for symbolically describing general-purpose spatial relations between entities in a workspace, enhancing the flexibility and the range of application of cobots symbolic reasoning for complex manipulation tasks. The proposed approach involves defining a tunable set of predicates for relative positions and orientations, enabling precise symbolic representations, necessary for real-world tasks. The adoption of these symbols into a Programming by Demonstration framework empowers non-expert users to teach skills and deploy cobots in complex industrial tasks without coding. Experimental results demonstrate the effectiveness of this method, showing that first-time users can deploy cobots for a complex machine tending task comprising parts reorientations.},
  archive      = {J_EAAI},
  author       = {Isacco Zappa and Sara Vignali and Andrea Maria Zanchettin and Paolo Rocco},
  doi          = {10.1016/j.engappai.2025.112882},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112882},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Symbolic representation of objects relative poses for robotic manipulation tasks},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). BeltTear-seg: A lightweight model for belt tear segmentation with multi-scale feature squeeze attention and enhanced classification decision. <em>EAAI</em>, <em>163</em>, 112881. (<a href='https://doi.org/10.1016/j.engappai.2025.112881'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the challenges of small target tear omission and false detections, complex background interference, and strict real-time requirements in belt tear segmentation for industrial production, this study proposes an improved instance segmentation model based on You Only Look Once version 8 nano (YOLOv8n) for segmentation (YOLOv8n-seg), named BeltTear-seg. First, a Multi-scale Feature Squeeze Attention mechanism (MFSA) is introduced to enhance the model’s capability in capturing small target tear regions, effectively reducing the omission rate. Second, an Enhanced Classification Decision (ECD) layer is incorporated into the model head, working in conjunction with Bidirectional Feature Pyramid Network(BiFPN) to reduce the false detection rate. Finally, a lightweight designed Cross Stage Partial with 2 convolutions and feature fusion (Light-C2f) is introduced to significantly enhance computational efficiency while maintaining high segmentation accuracy. Experimental results demonstrate that the BeltTear-seg model performs exceptionally well on a custom-built belt tear instance segmentation dataset, which includes 4,050 images (1,800 negative and 2,250 positive samples) of conveyor belt surfaces collected from real industrial sites, achieving a classification accuracy of 95.9%, which represents a 5.8% improvement over the original model YOLOv8n-seg on the custom dataset. Meanwhile the model’s detection time per frame is shortened by 15.1%. When compared with other mainstream instance segmentation models, this model also demonstrates significant advantages. The proposed improvements not only significantly enhance the accuracy of the instance segmentation model but also simultaneously boost segmentation speed, thereby meeting the dual industrial requirements of high precision and real-time detection for belt tear inspection.},
  archive      = {J_EAAI},
  author       = {Li Yuan and Hebin Zhou and Yuqi Kong and Li Liu and Jiangyun Li},
  doi          = {10.1016/j.engappai.2025.112881},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112881},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {BeltTear-seg: A lightweight model for belt tear segmentation with multi-scale feature squeeze attention and enhanced classification decision},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AutoMedTS: Automated modeling of physiological time series for surgical suturing action recognition. <em>EAAI</em>, <em>163</em>, 112880. (<a href='https://doi.org/10.1016/j.engappai.2025.112880'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In laparoscopic surgical training and evaluation, real-time recognition of surgical actions with transparency outputs is crucial for automated, objective, and immediate instructional feedback to support skills improvement. However, we face challenges due to limited dataset sizes and variability in surgical environments. This study presents AutoMedTS , an end-to-end automated machine learning framework customized for medical time-series data, enabling rapid deployment using surgical suturing trajectories collected from both expert and novice surgeons. The proposed method features key improvements including: (i) a novel temperature-scaled Softmax resampling technique effectively addressing severe class imbalance, and (ii) an uncertainty-aware ensemble selection mechanism ensuring robust predictions across surgeons with varying skill levels. Additionally, the approach emphasizes model transparency to meet the high standards of reliability and transparency required in medical applications. Compared to deep learning methods, traditional machine learning models not only facilitate efficient rapid deployment but also offer significant transparency advantages. Experimental results demonstrate that our method provides fast, stable, and reliable real-time surgical action recognition in clinical training environments. Code and data are publicly available at https://github.com/baobingzhang/AutoMedTS .},
  archive      = {J_EAAI},
  author       = {Baobing Zhang and Paul Sullivan and Benjie Tang and Ghulam Nabi and Mustafa Suphi Erden},
  doi          = {10.1016/j.engappai.2025.112880},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112880},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {AutoMedTS: Automated modeling of physiological time series for surgical suturing action recognition},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Automatic estimation of lactate threshold heart rate and pace in real-world running based on transfer learning. <em>EAAI</em>, <em>163</em>, 112879. (<a href='https://doi.org/10.1016/j.engappai.2025.112879'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel transfer learning-based approach for automatically estimating lactate threshold heart rate (LTHR) and pace (LTP) during real-world running. We first designed a graded exercise test (GXT) to collect physiological data. The model, constructed using a Recurrent Neural Network (RNN), employs hierarchical sampling during training to enhance accuracy. The model achieves mean absolute error (MAE) values of 4.37 beats per minute (bpm) for LTHR and 0.36 km per hour (km/h) for LTP. Subsequently, real-world running data undergo segmentation, filtering, and similarity-based selection to construct features, achieving the MAE of 9.18 bpm and 1.23 km/h for LTHR and LTP. Additionally, longitudinal tracking was conducted for several participants over 28 days, utilizing their daily running records to monitor the longitudinal changes in LTHR and LTP.},
  archive      = {J_EAAI},
  author       = {Zheng Zhu and Wei Cui and Changda Lu and Yanfei Shen and Bingyu Pan},
  doi          = {10.1016/j.engappai.2025.112879},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112879},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automatic estimation of lactate threshold heart rate and pace in real-world running based on transfer learning},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GMFIMamba: Remote sensing change detection based on group mamba feature interaction. <em>EAAI</em>, <em>163</em>, 112878. (<a href='https://doi.org/10.1016/j.engappai.2025.112878'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of satellite technology, high-resolution remote sensing images have been widely used in the field of change detection. Building Change Detection (BCD) and Building Damage Assessment (BDA) are both sub-tasks of change detection. BCD aims to detect structural changes in buildings over time, whereas BDA focuses on assessing the level of building damage after a disaster. BCD is of great value for urban planning, while BDA plays a crucial role in post-disaster rescue efforts. To address these tasks, we propose a change detection method based on Mamba, named GMFIMamba. Specifically, we design a Convolution–Visual State Space (Conv-VSS) block, which combines the local feature extraction capability of Convolutional Neural Networks (CNNs) with the global feature modeling ability of Mamba. By integrating local and global features, our approach improves the accuracy of change region detection. To tackle the issue of insufficient feature extraction for small-scale buildings in existing models, we introduce the Multi-branch Dilated Convolution Feature Enhancement Module (MCFEM). In addition, we design the Grouped Mamba-Based Bitemporal Features Interaction Module (GMBFIM) to facilitate effective interaction between bitemporal images, leading to more accurate change feature extraction. Experiments on three public datasets demonstrate that the proposed method achieves superior performance in both BCD and BDA tasks, proving its effectiveness.},
  archive      = {J_EAAI},
  author       = {Wenliang Xu and Suting Chen and Feilong Bi and Chao Wang and Xiao Shu},
  doi          = {10.1016/j.engappai.2025.112878},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112878},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {GMFIMamba: Remote sensing change detection based on group mamba feature interaction},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Electric bus energy prediction and factors interactions using explainable machine learning models. <em>EAAI</em>, <em>163</em>, 112877. (<a href='https://doi.org/10.1016/j.engappai.2025.112877'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Battery electric buses (BEBs) are pivotal for sustainable urban transportation, yet their energy consumption is influenced by complex, interrelated factors that challenge accurate estimation and optimization. While machine learning models excel in energy prediction, their "black-box" nature limits practical deployment. This study addresses this gap by developing an interpretable machine learning framework integrating several machine learning models with SHapley Additive exPlanations (SHAP) and partial dependence plots (PDP). Using a high-fidelity simulation dataset of 169,344 scenarios generated via a validated MATrix LABoratory (MATLAB) Simulink model, we systematically analyze energy consumption under diverse driving conditions: covering extreme gradients (−8 % to 8 %), passenger loads (0–75), and Heating Ventilation and Air Condition (HVAC) usage (1.25–22.3 kW) as a proxy for temperature effects. The eXtreme Gradient Boosting (XGBoost) was selected as the best-performing machine learning model. SHAP analysis identified road gradient, initial state of charge (SoC), and Heating Ventilation and Air Condition (HVAC) usage as dominant factors, with nonlinear interactions between average speed and stop density ratio significantly impacting energy use. A human-machine interface (HMI) was developed to translate these insights into actionable recommendations for route optimization and driver training, enabling energy savings with minimal data acquisition costs. This study bridges the gap between theoretical energy models and practical decision-making, offering a robust framework for BEB fleet management while highlighting future directions for integrating real-world environmental data.},
  archive      = {J_EAAI},
  author       = {Wanying Wang and Moataz Mohamed and Bingzhe Zhang and Qiang Zhang and Hatem Abdelaty},
  doi          = {10.1016/j.engappai.2025.112877},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112877},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Electric bus energy prediction and factors interactions using explainable machine learning models},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel color marker-based target tracking and motion intent detection method. <em>EAAI</em>, <em>163</em>, 112876. (<a href='https://doi.org/10.1016/j.engappai.2025.112876'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the limitations of conventional target tracking methods—such as reliance on external devices, poor robustness, and low accuracy in motion intent detection under complex scenarios—this study proposes a novel color marker-based target tracking and motion intent detection method (CMTT). Specifically, the target object is first annotated using color markers. Then, color segmentation and occlusion modeling techniques are applied for image preprocessing, enabling preliminary localization of the target region. Building on this, the method integrates GoogLeNet with gradient-weighted class activation mapping (Grad-CAM) for fine-grained binary classification within the identified region, enhancing the detection of key target areas. A Kalman filter is subsequently employed to perform dynamic system state estimation, achieving real-time tracking performance. To further improve robustness under varying lighting conditions, an image reconstruction strategy based on average grayscale values is introduced, effectively mitigating the impact of illumination interference on tracking accuracy. Experimental results demonstrate that the proposed CMTT method achieves substantial performance gains across several benchmark datasets. On the visual object tracking (VOT) dataset, compared to the baseline model, adaptive target classification and interaction strategy (ATCAIS), CMTT achieves a 34.3 % increase in expected average overlap (EAO), an 8.0 % improvement in accuracy (ACC), and a 23.8 % enhancement in Robustness (ROB). On the depth-based tracking benchmark (DepthTrack) dataset, CMTT achieves 31.9 %, 38.7 %, and 25.6 % in EAO, ACC, and ROB, respectively, highlighting its superior stability and adaptability in complex environments. An empirical study with 15 participants confirmed the consistency between the proposed method and data from inertial measurement units (IMU).},
  archive      = {J_EAAI},
  author       = {Zhenyu Wang and Zenan Lu and Simin Tang and Jianmin Wang},
  doi          = {10.1016/j.engappai.2025.112876},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112876},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel color marker-based target tracking and motion intent detection method},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Pseudo-central feature matching: An adaptive semisupervised fault diagnosis method for knowledge transfer under variable working conditions. <em>EAAI</em>, <em>163</em>, 112875. (<a href='https://doi.org/10.1016/j.engappai.2025.112875'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the continuous advancement of industrialization, fault diagnosis technology for industrial equipment has developed rapidly. Semisupervised domain adaptation (SSDA) can improve the generalization ability of models by utilizing a small portion of labeled data alongside a large quantity of unlabeled data, achieving cross-domain fault diagnosis. Consequently, SSDA is widely applied. However, previous SSDA methods often misalign target data with incorrect labeled source data during spatial mapping, leading to erroneous classifications. To solve this problem, this study draws inspiration from the idea of noisy label learning and provides an adaptive semisupervised fault diagnosis method, pseudo-central feature matching (PCFM) for knowledge transfer under variable working conditions. First, a novel semisupervised adaptive correction framework is proposed, which treats the labeled source domain data as noisy approximations of the target domain data and adaptively refines them using feedback from the target domain. The misalignment problem encountered in traditional SSDA methods is then effectively mitigated. A prototype network with dynamically updated pseudo-centers is subsequently introduced to guide the feature alignment between source and target domains, enhancing robustness in cross-domain scenarios. The proposed adaptive correction framework treats source labels as noisy approximations and refines them adaptively through dynamic pseudo-center updates, which effectively improves feature alignment and label reliability. Finally, the effectiveness of PCFM is validated through experiments. Results show that this approach not only aligns data between the source and target domains but also significantly enhances the accuracy of existing advanced methods, yielding more than a 6 % performance gain over MME and DANN.},
  archive      = {J_EAAI},
  author       = {Changqing Shen and Hangqi Ge and Hao Yang and Juanjuan Shi and Dong Wang and Zhongkui Zhu},
  doi          = {10.1016/j.engappai.2025.112875},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112875},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Pseudo-central feature matching: An adaptive semisupervised fault diagnosis method for knowledge transfer under variable working conditions},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Detection-driven adaptive semantic feature weight for multi-modality image fusion. <em>EAAI</em>, <em>163</em>, 112874. (<a href='https://doi.org/10.1016/j.engappai.2025.112874'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared and visible image fusion aims to generate high-quality fused images with salient targets for subsequent object detection tasks, and the semantic features obtained from the detection tasks can provide target a priori information for the infrared and visible image fusion task. Therefore, the use of detection features to facilitate the fusion process has received increasing attention. However, existing fusion methods have limitations in certain aspects, such as the spatial resolution of detection and fusion features, which greatly prevent their practical applications. To this end, this paper proposes a method to embed infrared and visible image detection features into the fusion process and to optimize the fusion network by detecting losses. A key novelty of our framework is the introduction of an adaptive semantic weighting mechanism, the detection features generated during the detection process provide the target semantic information, based on which the target attention score is computed, and the attention score can be weighted by the features in the fusion process through the adaptive semantic weight generation module to enhance the fused semantic features. In addition, the detection loss and fusion loss applied in this paper can jointly motivate the fusion network to learn detection-related feature representations. Extensive experiments on widely used fusion datasets demonstrate the effectiveness and superiority of the proposed method, and the model achieves excellent performance on high-level detection tasks.},
  archive      = {J_EAAI},
  author       = {Xingze Du and Huizhou Liu and Bowen Shen and Junfeng Zhang and Mengxing Huang},
  doi          = {10.1016/j.engappai.2025.112874},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112874},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detection-driven adaptive semantic feature weight for multi-modality image fusion},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Formation efficacy assessment of high-speed air vehicle swarms via the continuous belief rule base with heterogeneous data augmentation. <em>EAAI</em>, <em>163</em>, 112873. (<a href='https://doi.org/10.1016/j.engappai.2025.112873'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To date, high-speed air vehicle swarm (AVS) formations have been widely applied to military missions, while the attention paid to formation efficacy assessment of AVSs has been increasing due to its significant instruction. On the one hand, it is almost impractical to acquire complete formation efficacy data of high-speed AVSs through repetitive trial flights considering the excessive cost. On the other hand, the considerable importance military departments attach to explainability makes the application of numerous popular artificial intelligence (AI) models limited despite their advantage in terms of accuracy. Focused on the challenges of incomplete formation efficacy data and inexplicable AI models, in this paper, the continuous belief rule base with heterogeneous data augmentation is proposed as a framework. The heterogeneous data augmentation strategy is constructed as the auxiliary component to overcome the first challenge, while the continuous belief rule base (CBRB) model is established as the core component to conquer the second challenge. Besides, a module based on an improved version of the grey wolf optimizer is devised for tuning the hyperparameters of the CBRB model. Relevant computational experiments are carried out, demonstrating the validity and superiority of our proposal. It should be noted that this paper is the first piece that discusses the application of belief rule-based systems such a representative of symbolic AI in the engineering of high-speed AVS formation efficacy assessment. More in-depth work will be further undertaken.},
  archive      = {J_EAAI},
  author       = {Haoran Zhang and Ruohan Yang and Wei He and Xiaobo Lv and Lining Xing},
  doi          = {10.1016/j.engappai.2025.112873},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112873},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Formation efficacy assessment of high-speed air vehicle swarms via the continuous belief rule base with heterogeneous data augmentation},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Machine learning solutions with deep multilayer exogenous networks for distributed denial of service attacks model on networked resources in critical infrastructure. <em>EAAI</em>, <em>163</em>, 112872. (<a href='https://doi.org/10.1016/j.engappai.2025.112872'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing dependency on critical infrastructure and the vulnerability to cyber-attacks, particularly Distributed Denial of Service attacks, pose significant challenges and threats in this cold warfare era. This paper explores an epidemic model based distributed denial of service attacks system to analyze the impact of seclusion strategies on protecting critical infrastructure against cyber-attacks by leveraging machine learning knowledge with non-linear exogenous networks supported with Levenberg-Marquardt backpropagation. The proposed information security model presents the critical infrastructure nodes into susceptible, infected, quarantined and recovered differential compartments for the targeted population to portray the attack's dynamics and quarantine measures effectively. To analyze the rates for infection, efficiency in the quarantine and the recovery state, the synthetic data is acquired to carry out processes on various scenarios with Adams numerical solver and the said information is fed to intelligent supervised nonlinear autoregressive exogenous neural networks to decipher the attack patterns. The efficacy of the proposed stochastic computing paradigm is established on mean squared error-based convergence trends, error in time series illustrations, error-histogram, and error distribution in histograms, statistics on correlation and autocorrelation metrics based on an exhaustive simulation study for an information security model. The validation of the performance of the design nonlinear networks is further endorsed from counterpart's backpropagation schemes of Bayesian regularization and scaled conjugate gradient, based on the results of statistics in terms of mean, standard deviation, worst, and best of the convergence arcs, error distribution on heat map, inference on median with box plots, plot-matrix analysis, violin plots dynamics and computational time analysis, on exhaustive autonomous executions for solving cyber-attack model in information security.},
  archive      = {J_EAAI},
  author       = {Rana Abdullah Zaeem and Chuan-Yu Chang and Maryam Pervaiz Khan and Muhammad Shoaib and Chi-Min Shu and Muhammad Asif Zahoor Raja},
  doi          = {10.1016/j.engappai.2025.112872},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112872},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning solutions with deep multilayer exogenous networks for distributed denial of service attacks model on networked resources in critical infrastructure},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Adaptive nonlinear recursive control based on normalized advantage neural network learning for large-scale cyber-physical power systems. <em>EAAI</em>, <em>163</em>, 112871. (<a href='https://doi.org/10.1016/j.engappai.2025.112871'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deployment of communication infrastructure in large-scale power systems brings substantial benefits in remote regulation, monitoring, and energy management. However, the utilization of such technologies introduces cyber security issues that highly threaten the system’s operation. In this paper, a resilient defense mechanism is developed to tackle with False Data Injection (FDI) attacks in the cyber–physical power systems (CPPSs). The main objective of proposed cyber protection is realized in The defense mechanism is designed in two separate phases: (i) a detection mechanism based on model-independent state observer (MISO) is adopted to recognize the FDI attacks, and (ii) a Nonlinear Recursive Control (NRC) is also developed to mitigate the identified anomaly in the CPPS system. The main task of the NRC controller is to compensate for the effect of FDI attacks with the aim of alleviating the frequency deviations. To dynamically respond to cyber threats, the parameters of the NRC controller are adjusted by the new version of deep Q-network (DQN) which is combined with the Normalized Advantage Function (DQN-NAF). The deep neural networks (DNNs) of the DQN-NAF are trained to adaptively tune the NRC controller by solving Bellman’s equation. To do this, a reward function is defined according to the system requirements to maintain the frequency deviation at pre-defined intervals and to ensure the system’s stability. The DQN-NAF utilizes this reward function to update its policy and generate optimal control actions in response to the FDI attacks. Comprehensive simulations under typical scenarios of cyber-attacks confirm the feasibility and robustness of the proposed defense scheme (realized by DQN-NAF) to tackle high levels of anomaly. Comparative analysis of the CPPS system also reveals the superior outcomes of the proposed scheme to the prevalent state-of-the-art methodologies.},
  archive      = {J_EAAI},
  author       = {Zhongliang Xiang and Armand Jean Noel Irangabiye and Shuguang Li},
  doi          = {10.1016/j.engappai.2025.112871},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112871},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive nonlinear recursive control based on normalized advantage neural network learning for large-scale cyber-physical power systems},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Smart home healthcare using artificial intelligence of things: Emergency prediction and prevention for cerebrovascular disease patients. <em>EAAI</em>, <em>163</em>, 112870. (<a href='https://doi.org/10.1016/j.engappai.2025.112870'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cerebrovascular disease (CeVD) is a major cause of mortality and disability, necessitating continuous monitoring for timely intervention. Home environments are effective for contactless health monitoring, as CeVD risk factors can be continuously tracked without obtrusion. This study leveraged smart home data and artificial intelligence (AI) to predict CeVD emergencies early. The dataset included individual health conditions and sequential lifelogs, such as physical activity, sleep, and thermal environment, from 1130 CeVD patients, including 130 emergencies. We achieved an area under the precision-recall curve (AUPRC) of 0.94 with 28 days of data, corresponding to an accuracy of 98.2 %, precision of 97.1 %, recall of 87.2 %, and an F1-score of 91.9 %, using the CrossNet architecture, which integrates static and time-series data while handling missing values by cross-modal imputation. We further identified emergency prevention strategies, including: increasing both low and high active time by 1 and 1.5 h/day, while decreasing inactive time for patients aged 85+; limiting high active time while increasing low active time for patients aged under 85; maintaining 7 h of sleep for cardiovascular patients (8 h if cardiovascular); minimizing sleep fragmentation for patients aged 85+ and with diabetes; and in general, cold indoor temperatures increase the emergency risk, while hot indoor temperatures are risky in cold weather. These findings highlight the potential of smart home monitoring based on the artificial intelligence of things (AIoT) to predict emergencies and identify prevention strategies. This study provides insights into scalable, contactless, AI-enabled home healthcare solutions for continuous management of CeVD.},
  archive      = {J_EAAI},
  author       = {Jeongyeop Baek and Jo Woon Chong and Kyung-Hee Cho and Lisa Lim},
  doi          = {10.1016/j.engappai.2025.112870},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112870},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Smart home healthcare using artificial intelligence of things: Emergency prediction and prevention for cerebrovascular disease patients},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Semantic-geometric dual knowledge guided instance segmentation for vehicle components. <em>EAAI</em>, <em>163</em>, 112869. (<a href='https://doi.org/10.1016/j.engappai.2025.112869'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection and segmentation of vehicle components are crucial steps in intelligent vehicle damage assessment. However, due to the wide variety of vehicle components with diverse shapes and the high similarity between mirror-symmetric components, missed detections and false positives remain common challenges in vehicle component detection and segmentation. To address these challenges, this paper proposes a deep learning-based dual-knowledge guided vehicle component instance segmentation network. The proposed method fuses implicit multi-scale semantic knowledge by the enhanced semantic knowledge network, thereby improving the model’s capability to filter and capture critical component information. This design enhances focus on key foreground features while suppressing interference from background features. Furthermore, the proposed embedded geometric knowledge module synergizes geometric constraint knowledge of vehicle components with the model’s intrinsic learning capability. By reasoning about positions among three types of landmark components, it explicitly supplements the model with spatial relationship information of components that are inherently challenging to learn from data alone. We evaluate the detection and segmentation performance of the proposed method on a dataset comprising 59 classes of vehicle components. Compared with the baseline model, our method achieves significant improvements of 19.3% and 19.1% in detection mean average precision and segmentation mean average precision, respectively. Additionally, we evaluate the generalization capability of the proposed method on an independent public dataset. Compared with state-of-the-art instance segmentation methods, the proposed method demonstrates superior performance in both detection and segmentation tasks for vehicle components.},
  archive      = {J_EAAI},
  author       = {Zhenqi Zhang and Xunqi Zhou and Yongjie Zhai and Nianhao Chen and Qianming Wang and Xinying Wang},
  doi          = {10.1016/j.engappai.2025.112869},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112869},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semantic-geometric dual knowledge guided instance segmentation for vehicle components},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Hybrid framework of penetration resistance analysis by machine learning and finite element simulation. <em>EAAI</em>, <em>163</em>, 112868. (<a href='https://doi.org/10.1016/j.engappai.2025.112868'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A comprehensive understanding of projectile penetration in reinforced concrete (RC) structures is essential for developing resilient defense and infrastructure systems. Such investigations provide valuable insights into the behavior of structural components under extreme loading conditions. However, accurately modeling penetration resistance remains challenging due to the complex interaction among projectile velocity, geometry, and the nonlinear behavior of concrete. To address this challenge, this study applies artificial intelligence (AI) techniques in combination with finite element (FE) simulations to enhance predictive modeling. The AI framework incorporates deep neural networks (DNN), support vector machines (SVM), and random forests (RF) for prediction and classification tasks, while Bayesian neural networks (BNN) are employed for uncertainty quantification, providing statistically reliable confidence bounds for the depth of penetration (DoP). Damage categorization is further optimized through K-means clustering, enabling clear differentiation between minor and severe damage states. The analysis is based on 540 data samples generated from a validated FE model calibrated with experimental results. The hybrid DNN–RF model achieved an R 2 of 0.994 for DoP prediction, while the SVM attained 99.08 % precision in damage classification and the RF achieved 98.16 % accuracy in ballistic limit prediction. The BNN yielded a 95 % confidence interval, confirming the reliability of the AI-based predictions. Among various clustering algorithms, including Density-Based Spatial Clustering of Applications with Noise, Gaussian Mixture Models, and hierarchical clustering, K-means demonstrated the best performance. The proposed AI-driven framework provides a reliable and efficient tool for rapid RC design assessment and optimization, contributing to advancements in defense, infrastructure resilience, and high-performance structural engineering.},
  archive      = {J_EAAI},
  author       = {Xu Long and Irfan Ali and Khawaja Haseeb Maqbool and Muhammad Muaz Khan},
  doi          = {10.1016/j.engappai.2025.112868},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112868},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid framework of penetration resistance analysis by machine learning and finite element simulation},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An adaptive image dehazing network with multi-color feature for complex real-world hazy scenes. <em>EAAI</em>, <em>163</em>, 112867. (<a href='https://doi.org/10.1016/j.engappai.2025.112867'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world hazy scenes can be broadly categorized into four types based on haze distribution and concentration: light homogeneous haze, dense homogeneous haze, light non-homogeneous haze, and dense non-homogeneous haze. However, many existing dehazing models are tailored for specific haze types, struggling to generalize effectively across these diverse conditions. Additionally, these models commonly extract feature information in the Red, Green, and Blue (RGB) color space, which makes it challenging to extract sufficient feature information in various hazy scenes. To address this issue, we propose an Adaptive Network (AdaNet) for multiple hazy scenes. The network includes two sub-networks: a color-guided feature extraction network and a scene reconstruction network. The color-guided feature extraction network is used to capture sufficient color, detail, and other feature information in both RGB and Luminance, Chroma Red, Chroma Blue (YCrCb) color spaces. For light and dense non-homogeneous hazy scenes, we enhance the scene reconstruction network with the Feature Selection Units (FSU) to filter out less relevant information, ensuring precise recovery of critical local details. Additionally, to tackle dehazing in light and dense homogeneous hazy scenes, we integrate the Feature Fusion Units (FFU) that combine multi-level features to improve overall feature utilization. Extensive experiments on multiple datasets with diverse hazy scenes demonstrate that our AdaNet outperforms state-of-the-art dehazing models, producing high-quality dehazed images in quadruple haze scenarios and ensuring reliability for high-level visual tasks in real-world hazy scenes.},
  archive      = {J_EAAI},
  author       = {Zhiyu Lyu and Qi An and Yan Chen},
  doi          = {10.1016/j.engappai.2025.112867},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112867},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptive image dehazing network with multi-color feature for complex real-world hazy scenes},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Segmentation-enhanced medical visual question answering with mask-prompt alignment using contrastive learning and multitask object grounding. <em>EAAI</em>, <em>163</em>, 112866. (<a href='https://doi.org/10.1016/j.engappai.2025.112866'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical Visual Question Answering (MedVQA) aims to provide clinical suggestions by analyzing medical images in response to textual queries. However, existing methods struggle to accurately identify anatomical structures and pathological abnormalities, leading to unreliable predictions. Many deep learning-based approaches also lack interpretability, making their diagnostic reasoning opaque. To address these challenges, this paper proposes Mask-Prompt Aligned Visual Question Answering (MPA-VQA), a two-stage framework that integrates segmentation information into the MedVQA process. First, a segmentation model is trained to detect key structures within medical images. To mitigate the issue of limited segmentation annotations, this paper introduces an improved CutMix-based data augmentation strategy. Second, segmentation masks are used to generate prompts, which are incorporated into the question-answering process for the first time to enhance interpretability. Third, to improve the alignment between image, mask, and prompt representations, this paper proposes a dual-granularity mask-prompt alignment (MPA) method. At the image level, MPA employs contrastive learning to encourage global consistency, while at the object level, it leverages multi-task object grounding to enhance localization accuracy. A mask-guided attention mechanism is also introduced to ensure the model focuses on clinically relevant image regions. Finally, the proposed MPA-VQA is validated on the SLAKE and MedVQA-GI datasets, demonstrating state-of-the-art performance. Notably, MPA-VQA improves location-related question accuracy by 6.37% on MedVQA-GI. MPA-VQA is also a plug-and-play framework that can be seamlessly integrated into existing MedVQA architectures without requiring major modifications.},
  archive      = {J_EAAI},
  author       = {Qishen Chen and Huahu Xu and Wenxuan He and Xingyuan Chen and Minjie Bian and Honghao Gao},
  doi          = {10.1016/j.engappai.2025.112866},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112866},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Segmentation-enhanced medical visual question answering with mask-prompt alignment using contrastive learning and multitask object grounding},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A cosmetic packaging design method based on online reviews. <em>EAAI</em>, <em>163</em>, 112865. (<a href='https://doi.org/10.1016/j.engappai.2025.112865'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the transformation of user experience and packaging iteration in cosmetics due to the diversification of usage scenarios and demands, this study capitalizes on the advancements in artificial intelligence across user analysis, data analysis, and generative design domains, and proposes a cosmetic packaging design approach centered around online reviews. In this study, 124,879 pieces of user review data were collected from JingDong (JD), a Chinese e-commerce platform, using Python programming technology. Five topics are clustered through the application of the Latent Dirichlet Allocation (LDA) topic model. By integrating the coding of Grounded Theory, 18 demand elements within six core categories are summarized. The Kano model and the Analytic Hierarchy Process (AHP) are employed to classify and rank these demands. Notably, aspects such as strong brand recognition (M1, 0.2182), strong brand value perception (M5, 0.1129), and visually appealing and refined aesthetics (A5, 0.0983) exhibit relatively high weights. Subsequently, six lipstick packaging design schemes are developed by combining traditional software with the MidJourney generative artificial intelligence tool. Through comprehensive evaluation using the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) method, the optimal Scheme c is identified and further optimized. This study constructs a comprehensive design strategy with user online reviews at its core, encompassing data collection, analysis, scheme design, artificial intelligence (AI)-assisted design, and evaluation. It is recommended that the application of artificial intelligence (AI)-assisted design be significantly enhanced throughout the entire design process, enabling precise and rapid generation of design schemes, streamlining the process, and shortening the development cycle.},
  archive      = {J_EAAI},
  author       = {Zhan Gao and Zhenyu Li},
  doi          = {10.1016/j.engappai.2025.112865},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112865},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A cosmetic packaging design method based on online reviews},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Building a multi-class short message service dataset for smishing detection using agglomerative clustering and dataset fusion. <em>EAAI</em>, <em>163</em>, 112864. (<a href='https://doi.org/10.1016/j.engappai.2025.112864'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smishing is a phishing technique in which a cybercriminal sends an SMS (Short Message Service) to a user impersonating a legitimate organization, aiming to steal personal or financial information. Although binary classification of smishing helps protect the user, a multi-class approach provides additional information, allowing to analyze the type of fraud, detect smishing campaigns or develop specific solutions targeting the riskiest types of smishing. In this paper, we introduce a sMishIng MultIClasS dataset: MIMICS-3500. The dataset was created in four phases: data selection, automatic clustering, inter-annotator agreement, and manual labeling. Firstly, we gathered smishing messages from five sources: Kaggle, Mendeley, SmishTank, SpamHunter, and data provided by the Spanish National Cybersecurity Institute (INCIBE). Secondly, we applied agglomerative clustering to analyze how samples are grouped. This led to the identification of seven classes for a general categorization and thirteen classes for a fine-grained categorization. Then, we performed an inter-annotator agreement assessment of the manual labeling on a subset of the dataset to evaluate the definition of the classes. Finally, we manually labeled the entire dataset for seven and thirteen classes of smishing. We evaluated eleven state-of-the-art classification models on MIMICS-3500, achieving 86.94% and 82.43% F1-score with Robustly Optimized Bidirectional Encoder Representations from Transformers (RoBERTa) for the seven-class and thirteen-class proposals, respectively. This result validates the consistency of the labeling and sets a benchmark for future research on multi-class smishing.},
  archive      = {J_EAAI},
  author       = {Alicia Martínez-Mendoza and Eduardo Fidalgo and Enrique Alegre and Laura Fernández-Robles},
  doi          = {10.1016/j.engappai.2025.112864},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112864},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Building a multi-class short message service dataset for smishing detection using agglomerative clustering and dataset fusion},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Identifying high-risk pregnancies in rural areas with machine-manifold learning. <em>EAAI</em>, <em>163</em>, 112852. (<a href='https://doi.org/10.1016/j.engappai.2025.112852'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maternal mortality remains unacceptably high, particularly in developing countries, where 99% of cases occur, most of which are preventable. In Guatemala, disparities in maternal healthcare quality between urban and rural areas exacerbate this issue. The Healthy Pregnancy project, initiated by the EHAS Foundation, sought to address this gap by equipping rural nurses with prenatal care kits, enabling them to perform screenings comparable to those in urban settings. This study presents a retrospective secondary analysis of data collected during the project (2014–2016), encompassing 10,108 cases and 108 features. Using Data Science and machine learning (ML) methodologies, we compared Support Vector Machines (SVM) and Random Forest (RF) algorithms to classify pregnancies requiring referral to higher-level care, where the referral decision was defined based on the retrospective assessment of obstetric specialists using clinical, laboratory, and ultrasound data. Their performance was evaluated against the benchmark sensitivity (0.62) and specificity (0.98) of trained nurses. SHAP (Shapley Additive exPlanations) values were employed to interpret model predictions and identify the most critical features influencing classification. Furthermore, manifold learning techniques, specifically Uniform Manifold Approximation and Projection (UMAP), were utilized to uncover latent structures within the data, offering additional interpretability via SHAP analysis. Our results show that both models (RF and SVM) achieve sensitivity and specificity values comparable to those obtained by trained nurses when techniques such as SMOTE (Synthetic Minority Oversampling Technique) and cost-sensitive learning are applied to address the imbalanced dataset. UMAP and SHAP analyses revealed the most globally relevant features. These findings demonstrate the potential of ML-driven approaches to support clinical decision-making in resource-limited settings, enhancing the detection of high-risk pregnancies, reducing training demands, and facilitating the monitoring of prenatal checkups in such contexts.},
  archive      = {J_EAAI},
  author       = {Ignacio Prieto-Egido and Alicia Guerrero-Curieses and Andrés Martínez-Fernández and José Luis Rojo-Álvarez},
  doi          = {10.1016/j.engappai.2025.112852},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112852},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identifying high-risk pregnancies in rural areas with machine-manifold learning},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integrated scheduling of pallets and vehicles for automated warehouses with multi-tier racks. <em>EAAI</em>, <em>163</em>, 112851. (<a href='https://doi.org/10.1016/j.engappai.2025.112851'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of integrated scheduling of pallets and transport vehicles in an automated warehouse with multi-layer racks and two storage locations. The considered automated transport vehicles include automated guided vehicles (AGVs), unit loaders, pallet lifts, and shuttles. A mixed integer programming (MIP) model is used to handle the inbound operations of pallet allocation, transportation and storage, and vehicle scheduling. A three-step heuristic algorithm is proposed to verify and supplement the proposed model. Computational experiments on large instances with more than three million constraints and variables show that the heuristic algorithm can obtain solutions in a reasonable time, significantly outperforming the exact MIP solver. The comparison results indicate that the proposed algorithm achieves excellent solution quality and convergence performance while significantly reducing the risk of falling into local optimum. In addition, sensitivity analysis is conducted to provide managerial insights to improve the overall operational efficiency of automated warehouses.},
  archive      = {J_EAAI},
  author       = {Hanzhao Wu and Zhenyong Wu and Yuan Wang and Mark Goh},
  doi          = {10.1016/j.engappai.2025.112851},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112851},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Integrated scheduling of pallets and vehicles for automated warehouses with multi-tier racks},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Three-dimensional geometric deep learning for reaction prediction with equivariant graph transformer. <em>EAAI</em>, <em>163</em>, 112850. (<a href='https://doi.org/10.1016/j.engappai.2025.112850'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organic synthesis, a critical process in drug and material development, often involves complex reactions that can be time-consuming and costly to explore experimentally. Recent advances in machine learning have shown promise in predicting reaction outcomes, but challenges remain in capturing the full complexity of molecular interactions, particularly in three-dimensional space. To this end, we propose an Equivariant Graph Transformer (termed EGT) that predicts organic reactions by learning the three-dimensional (3D) geometric characteristics of molecules. We employed the equivariant graph neural network to extract geometric spatial information and a pairwise distance fed to position embedding to capture long-range interactions, to finely delineate the spatial structure of chemical molecules, making stereochemical information of reactions learnable. To benchmark our model's performance, we conducted reaction prediction experiments on the USPTO_STEREO and USPTO_FULL datasets as well as retrosynthesis prediction on the USPTO_50k and USPTO_MIT datasets. In addition, we conducted case studies focusing on synthesis planning and reaction prediction, and compared the results with those of human evaluations. The proposed EGT model has outperforms all existing algorithms with a Top-1 accuracy of 79.4 % for forward reaction prediction on the USPTO_STEREO dataset, and excels in predicting both forward reactions and retrosynthesis. Moreover, we demonstrated the model's capability to conduct forward total synthesis planning, showcasing its reliability and accuracy in achieving high Top-1 predictions. Molecular 3D geometry learning positions our model as a leading tool in the field of organic synthesis, paving the way for more efficient and accurate drug development.},
  archive      = {J_EAAI},
  author       = {Zhouxiang Wang and Haicheng Yi and Zhuhong You and Qiangguo Jin},
  doi          = {10.1016/j.engappai.2025.112850},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112850},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-dimensional geometric deep learning for reaction prediction with equivariant graph transformer},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-domain attentions for unmanned aerial vehicle small object detection. <em>EAAI</em>, <em>163</em>, 112849. (<a href='https://doi.org/10.1016/j.engappai.2025.112849'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images captured by unmanned aerial vehicles (UAVs) often suffer from severe degradation in small object quality and resolution due to environmental constraints, posing significant challenges in preserving the dual-domain characteristics of spatial details and frequency components. While large-scale models attempt to address this through complex architectures, aggressive down-sampling and successive convolution operations inevitably erase fine-grained patterns that are essential for detecting small objects. To overcome these challenges, we propose a dual-domain attention mechanism for small object detection, which focuses on both spatial and frequency domains. In the spatial domain, the proposed step-free triple-attention convolution (SFTAConv) reduces information loss during feature propagation by combining spatial–channel interactions and a lossless space-to-depth transform, thereby enhancing subtle object patterns while suppressing background interference. In the frequency domain, the frequency-domain hybrid attention (FD-HAT) jointly recalibrates high- and low-frequency components, moving beyond single-domain recalibration to recover discriminative representations of occluded or blurred small objects. Additionally, a classification-assisted localization (CAL) branch with classification-guided localization further refines detection accuracy. After extensive experiments conducted on the vision meets drone 2019 object detection (VisDrone2019Det), dataset for object detection in aerial (DOTA), and pascal visual object classes (PASCAL VOC) datasets, the results demonstrate that our model achieved the significant gains of 2.2%, 1.7%, 5.3% at A P s metric on three datasets, respectively, and being competitive with the state-of-the-art (SOTA) detectors.},
  archive      = {J_EAAI},
  author       = {Chunmei Wang and Yunxiao Chang and Shan Xie and Xiaobao Yang and Yadong Tian and Wei Sun and Junyan Hu},
  doi          = {10.1016/j.engappai.2025.112849},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112849},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-domain attentions for unmanned aerial vehicle small object detection},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Assessing voltage and power prediction in vibrating cylinders using machine learning algorithms: Insights from wind tunnel experiments. <em>EAAI</em>, <em>163</em>, 112848. (<a href='https://doi.org/10.1016/j.engappai.2025.112848'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flow-induced vibrations (FIV) of circular cylinders offer a promising mechanism for low-power energy harvesting, but accurately predicting the resulting voltage and power is challenging due to the nonlinear nature of fluid–structure interactions. In this study, wind tunnel experiments were conducted to generate three datasets based on different configurations of tandem circular cylinders. The datasets were used to evaluate the performance of three machine learning regression algorithms including Support Vector Regression (SVR), Gradient Boosting Regression (GBR), and Extreme Gradient Boosting (XGBoost), in predicting the root mean square (RMS) voltage and harvested power. Sobol sensitivity analysis was applied to quantify the influence of input parameters. XGBoost showed the best performance, with R 2 values of 0.91, 0.98, and 0.86 for datasets 1, 2, and 3. Despite using 1000 estimators, the XGBoost model demonstrated efficient training time due to its parallel tree boosting structure and built-in regularization, offering a favorable balance between accuracy and computational complexity. Sensitivity analysis revealed that the displacement between cylinders and upstream cylinder diameter were the most influential parameters depending on the configuration. The results show that machine learning techniques, particularly XGBoost, can successfully model complex nonlinear relationships in FIV-based energy harvesting systems, providing a data-driven tool for improving design and efficiency.},
  archive      = {J_EAAI},
  author       = {Amir Hossein Rabiee and Mostafa Esmaeili and Matin Rajabi},
  doi          = {10.1016/j.engappai.2025.112848},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112848},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Assessing voltage and power prediction in vibrating cylinders using machine learning algorithms: Insights from wind tunnel experiments},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Explainable stacking-based hybrid machine learning for predicting uni-axial creep deformation in concrete. <em>EAAI</em>, <em>163</em>, 112843. (<a href='https://doi.org/10.1016/j.engappai.2025.112843'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the complexity of modeling concrete creep behavior and the limitations of traditional models, this study proposes a data-driven hybrid machine learning model for accurate prediction of creep deformation. The Northwestern University creep database is preprocessed to identify the most influential factors, and a stacking-based hybrid model is developed by combining five ensemble tree-based algorithms with an artificial neural network. Bayesian optimization, implemented via the Hyperopt library, is employed for hyperparameter tuning, ensuring optimal model performance. A 10-fold cross-validation is conducted to demonstrate the model's strong generalization capability. The hybrid model outperforms standalone base estimators, achieving a coefficient of determination (R 2 ) of 0.960 on the testing set. SHapley Additive exPlanations are used to interpret the model's predictions globally and locally, revealing factor importance consistent with experimental findings. A comparison with three widely used traditional models, the Comité Européen du Béton (CEB) Model Code 90–99, Fédération Internationale du Béton (fib) Model Code 2010, and the B4 model on selected testing subsets demonstrates the superiority of the proposed model across six evaluation metrics. The prediction of various creep strains closely aligns with experimentally measured values, further validating the model's accuracy and effectiveness in predicting different types of creep deformations.},
  archive      = {J_EAAI},
  author       = {Mahamadou Djibo Zakari and Jing Wu and Luqi Xie and Abdoul Razak Abdou Harouna},
  doi          = {10.1016/j.engappai.2025.112843},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112843},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable stacking-based hybrid machine learning for predicting uni-axial creep deformation in concrete},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards learning-based gyrocompassing. <em>EAAI</em>, <em>163</em>, 112842. (<a href='https://doi.org/10.1016/j.engappai.2025.112842'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inertial navigation systems (INS) are foundational to navigation in both manned and autonomous platforms, with overall performance critically dependent on accurate initial alignment. This process, typically performed while stationary, establishes a reference orientation for subsequent navigation. However, traditional gyrocompassing methods often fail with low-performance gyroscopes due to limited sensitivity to Earth’s rotation rate. To overcome these limitations, we present a deep learning-based framework that significantly improves heading estimation using mid-tier inertial sensors. By learning to model and correct sensor errors, our method enables accurate gyrocompassing without reliance on extended filtering or long stationary periods. Theoretical analysis and experimental validation reveal a tenfold reduction in waiting times and over 50% lower alignment errors, substantially narrowing the gap between consumer-grade and tactical-grade systems. This establishes a new lower error bound for affordable gyros and offers a practical path towards scalable, high-precision navigation.},
  archive      = {J_EAAI},
  author       = {Daniel Engelsman and Itzik Klein},
  doi          = {10.1016/j.engappai.2025.112842},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112842},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards learning-based gyrocompassing},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fake news detection based on shared information and cross-feature ambiguity learning. <em>EAAI</em>, <em>163</em>, 112841. (<a href='https://doi.org/10.1016/j.engappai.2025.112841'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of social media has accelerated the spread of information and facilitated the rapid spread of false information. We introduce a novel approach to fake news detection that leverages shared information and cross-feature ambiguity—two aspects often overlooked by existing methods. Unlike prior models that treat features independently, our method captures inter-feature correlations and shared semantics through a Shared Information and Cross-Feature Ambiguity Learning (SI-CFAL) framework. SI-CFAL employs a shared information extraction mechanism to uncover relationships among text, attributes, and numerical data, and incorporates cross-feature ambiguity learning to adjust feature weights, improving discrimination adaptively. Additionally, a Product of Experts (PoE) strategy fuses multiple distributions to reduce bias from single features. Experiments on LIAR, CHEF-2, and CHEF-3 datasets achieve accuracy of 48.1%, 94.3%, and 86.1%, respectively, demonstrating SI-CFAL’s effectiveness in detecting fake news.},
  archive      = {J_EAAI},
  author       = {ShaoDong Cui and Kaibo Duan and Zexing Hao and Hiroyuki Shinnou},
  doi          = {10.1016/j.engappai.2025.112841},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112841},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fake news detection based on shared information and cross-feature ambiguity learning},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Review of physics-informed neural networks in hemodynamics. <em>EAAI</em>, <em>163</em>, 112834. (<a href='https://doi.org/10.1016/j.engappai.2025.112834'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The circulatory system sustains physiological function through oxygen transport, nutrient delivery, and waste clearance, all of which rely on efficient blood flow. Accurate characterization and quantification of hemodynamics are essential for the diagnosis and treatment of cardiovascular diseases. However, assessing blood flow in a noninvasive and real-time manner remains a major challenge, as current imaging modalities often suffer from limited spatial and temporal resolution, while traditional computational fluid dynamics algorithms are computationally intensive and sensitive to anatomical and physiological uncertainties. Physics-informed neural networks (PINNs), combining physical laws with data-driven learning, provide a promising framework to connect computational modeling with clinical applications. In this review, we provide a comprehensive overview of recent advances in the application of PINNs to hemodynamics. We introduce theoretical foundations, highlight methodological innovations, and discuss applications in simulating blood flow under physiological and pathological conditions, as well as in estimating clinically relevant hemodynamic parameters. Importantly, our analysis highlights that PINNs achieve comparable accuracy to traditional methods while unlocking novel opportunities for patient-specific diagnosis and risk prediction. We conclude with a discussion of the benefits, current limitations, and future directions of PINNs in cardiovascular research, underscoring the transformative potential to accelerate clinical translation through interdisciplinary collaboration.},
  archive      = {J_EAAI},
  author       = {Xianglong Yu and Yu Hu and Rui Guo and Lei Fan and Haiyan Ding and Jingjing Xiao},
  doi          = {10.1016/j.engappai.2025.112834},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112834},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Review of physics-informed neural networks in hemodynamics},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A fuzzy multi-criteria decision-making approach for public projects–bidders matching under heterogeneous information. <em>EAAI</em>, <em>163</em>, 112833. (<a href='https://doi.org/10.1016/j.engappai.2025.112833'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents an intelligent decision-support framework for addressing the Projects–Bidders Matching (PBM) problem in public procurement, designed to handle heterogeneous and uncertain information. The approach employs fuzzy set theory, through triangular fuzzy numbers, intuitionistic fuzzy sets, and linguistic evaluations, to capture vagueness, hesitancy, and imprecision in expert judgments. To determine the relative importance of criteria from project and bidder perspectives, we employ a hybrid weighting mechanism that combines deviation from a reference point with entropy-based measures to derive data-driven weights. By combining fuzzy modeling, objective weighting, and behavioral decision theory within an artificial intelligence framework, the model enhances explainability and supports data-driven decision-making under uncertainty. From an engineering perspective, the framework is applied to optimize bidder assignments in real-world Indian public procurement scenarios. A multi-objective optimization model is formulated to (i) maximize cumulative prospect values that jointly reflect individual preferences and socially influenced preferences for both bidders and projects, (ii) minimize the absolute deviation between these cumulative prospect values, ensuring fairness, transparency, and alignment and (iii) satisfy a stability constraint to ensure that no bidder–project pair has an incentive to deviate from the assigned matching. The framework’s effectiveness is demonstrated through a practical case study, and its robustness is validated through extensive sensitivity and variation analyses.},
  archive      = {J_EAAI},
  author       = {Faizan Ahemad and Mukesh Kumar Mehlawat and Pankaj Gupta and Shilpi Verma and Dragan Pamucar},
  doi          = {10.1016/j.engappai.2025.112833},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112833},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fuzzy multi-criteria decision-making approach for public projects–bidders matching under heterogeneous information},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Accurate multi-step wind and solar power forecasting based on multi-scale convolutional kolmogorov-arnold network and improved lemming-optimized attention fusion. <em>EAAI</em>, <em>163</em>, 112832. (<a href='https://doi.org/10.1016/j.engappai.2025.112832'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the deepening of power market reform, the increasing share of wind and solar energy introduces significant challenges for power system stability due to the high volatility and uncertainty of weather-dependent generation. Accurate multi-step ultra-short-term forecasting is therefore essential for ensuring power balance and effective dispatch coordination in smart grids. To address this issue, we propose a novel hybrid deep learning framework that integrates a multi-scale convolutional Kolmogorov-Arnold network (MCKAN) to improve forecasting performance. This network is specifically designed to capture high-dimensional spatial and temporal features across multiple levels of abstraction. To improve feature selection and scale-specific weight allocation, we integrate an Efficient Additive Attention (EAA) mechanism, which is applied for the first time in the context of renewable energy forecasting. In addition, a Chaotic Quasi-Reverse Artificial Lemming Algorithm (CQALA) is proposed to automatically optimize the complex multivariate hyperparameters, enabling optimal hyperparameter selection and improving the model's overall predictive performance. Extensive experiments on a two-year wind and photovoltaic power dataset from the State Grid of China demonstrate that the proposed method outperforms several state-of-the-art models. For multi-step forecasting, the mean absolute error is reduced by up to 27.6 percent for photovoltaic power and 33.4 percent for wind power, highlighting the practical value of the proposed approach in real-world renewable energy management.},
  archive      = {J_EAAI},
  author       = {Siyuan Chen and Hang Wan and Botao Peng and Rui Quan and Yufang Chang and William Derigent},
  doi          = {10.1016/j.engappai.2025.112832},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112832},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Accurate multi-step wind and solar power forecasting based on multi-scale convolutional kolmogorov-arnold network and improved lemming-optimized attention fusion},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Generative artificial intelligence method for vibration data of rolling bearing with multi-domain joint loss and interpretable physical laws. <em>EAAI</em>, <em>163</em>, 112831. (<a href='https://doi.org/10.1016/j.engappai.2025.112831'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction and health management (PHM) of rolling bearings have evolved toward data-driven transformation under Industry 4.0. Generative artificial intelligence, which generates content with logical consistency and coherence based on the multimodal large models, provides a novel data generation technology for intelligent PHM of rolling bearing that suffers from insufficient samples of incomplete measurement. However, the generated data lacks physical interpretability due to the black-box nature. The rolling bearing fault or degradation features represented by the generated data can only be recognized by intelligent models and cannot be explained manually. To address this issue, a generative artificial intelligence method for vibration data of rolling bearing with multi-domain joint loss and interpretable physical laws is proposed. Small samples measured from the fault stage of the rolling bearing are input into the multilayer perceptron (MLP) to fit the parameter of stiffness and damping ratio, the simulated data can be obtained by solving the dynamic model of rolling bearing with fitted parameters, and the physical laws of the rolling bearing working in the fault stage are described by the impulse response and fault frequency features of the simulated data. In the degradation stage of rolling bearings, the parameters' sequence of stiffness and damping ratio are fitted, respectively, by inputting a small sample of measured degradation data into MLP, and the future trends of parameter sequences are predicted by the temporal convolutional network (TCN) with single-step iterative prediction method. The simulated degradation data is produced by solving the dynamic model with fitted parameter sequences, which follow the physical laws of the rolling bearing working in the degradation stage. Experimental validation, ablation, and comparison experiments are carried out based on the Case Western Reserve University (CWRU) and XJTU-SY bearing datasets. The results show that the simulated data exhibit similar distribution characteristics to the measured data in time and frequency domains, which corresponds to physical laws and provides clear interpretability.},
  archive      = {J_EAAI},
  author       = {Qiwu Zhao and Xiaoli Zhang and Xin Luo and Shuangxuan Liang and Erick Mbeka},
  doi          = {10.1016/j.engappai.2025.112831},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112831},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generative artificial intelligence method for vibration data of rolling bearing with multi-domain joint loss and interpretable physical laws},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mutual risk prompt learning with multi-objective optimization for collaborative tumor and peritumor segmentation. <em>EAAI</em>, <em>163</em>, 112824. (<a href='https://doi.org/10.1016/j.engappai.2025.112824'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early radical surgery, radiotherapy, and other treatments may offer curative effects for tumors. However, the proximity of the tumor to surrounding organs-at-risk (OARs) significantly influences both the surgical outcome and prognosis. For benign tumors, the risk is primarily associated with the tumor's boundaries. In contrast, for malignant tumors, the main challenge lies in balancing the preservation of surrounding organ function while minimizing the risk of tumor recurrence. Therefore, understanding the tumor's characteristics and its anatomical relationships with OARs are essential. Most of the existing studies neglect the constrained interrelations and the potential optimization conflicts between tumor and OARs and easily introduce risks and uncertainties in tumor treatment and OARs protection. Here, we propose a novel multi-objective segmentation network for tumor and OARs, called ROJS-Net, which incorporates mutual risk prompt learning and multi-gate mixture of experts to achieve risk-optimized collaborative segmentation. A multi-task learning framework with shared encoder and multiple expert decoders are employed as the network backbone. Mutual risk prompt learning module is developed to obtain the target-specific features and perform mutual risk recalibration between features of different targets, enabling a comprehensive understanding of the anatomical environment. The risk-recalibrated features are then fed into the task-specific gating network to adaptively activate the highly-correlated expert decoders, generating the final segmentation results. Extensive experiments conducted on both benign and malignant tumor datasets demonstrate the effectiveness of the proposed ROJS-Net. These results validate that ROJS-Net effectively resolves the optimization divergence, facilitating risk-controllable treatment planning in various clinical settings.},
  archive      = {J_EAAI},
  author       = {Nuo Tong and Qingyang Meng and Chunsheng Xu and Changhao Liu and Shuiping Gou and Mei Shi and Mengbin Li},
  doi          = {10.1016/j.engappai.2025.112824},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112824},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mutual risk prompt learning with multi-objective optimization for collaborative tumor and peritumor segmentation},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Translating regulatory clauses into executable codes for building design checking via large language model driven function matching and composing. <em>EAAI</em>, <em>163</em>, 112823. (<a href='https://doi.org/10.1016/j.engappai.2025.112823'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Translating clauses into executable code is a vital stage of automated rule checking (ARC) and is essential for effective building design compliance checking, particularly for rules with implicit properties or complex logic requiring domain knowledge. Thus, by systematically analyzing building clauses, 66 atomic functions are defined first to encapsulate common computational logics. Then, LLM-FuncMapper is proposed, a large language model (LLM)-based approach with rule-based adaptive prompts that match clauses to atomic functions. Finally, executable code is generated by composing functions through the LLMs. Experiments show LLM-FuncMapper outperforms fine-tuning methods by 19 % in function matching while significantly reducing manual annotation efforts. Case study demonstrates that LLM-FuncMapper can automatically compose multiple atomic functions to generate executable code, boosting rule-checking efficiency. To our knowledge, this research represents the first application of LLMs for interpreting complex design clauses into executable code, which may shed light on further adoption of LLMs in the construction domain.},
  archive      = {J_EAAI},
  author       = {Zhe Zheng and Jin Han and Ke-Yin Chen and Xin-Yu Cao and Xin-Zheng Lu and Jia-Rui Lin},
  doi          = {10.1016/j.engappai.2025.112823},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112823},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Translating regulatory clauses into executable codes for building design checking via large language model driven function matching and composing},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The integration of emerging technologies in defense: A scientometric overview. <em>EAAI</em>, <em>163</em>, 112822. (<a href='https://doi.org/10.1016/j.engappai.2025.112822'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid adoption of emerging technologies such as Artificial Intelligence, Machine Learning, Internet of Things, Digital Twin, and fifth and sixth-generation communication networks has significantly transformed defense strategies across land, airborne, maritime, and domestic surveillance domains. The study conducts a comprehensive scientometric and systematic literature analysis of around 3,500 records retrieved from Scopus (2015–2025) to examine research trends, collaboration networks, and thematic developments in both core and supporting defense technologies. Keyword co-occurrence and document co-citation analyses reveal 42 thematic clusters spanning domains such as unmanned aerial vehicle coordination, smart surveillance, maritime autonomy, and emergency response. Results show a publication growth rate of around fourfold in artificial intelligence enabled land combat systems and around twofold increase in domestic surveillance applications over the decade. Additionally, China and the United States lead in total publication output and citation centrality, while institutions in the European Union demonstrate strong cross-domain collaboration. The analysis also shows a consistent increase in citation volume, particularly in recent years, reflecting growing research engagement in emerging defense technologies. The study highlights significant research concentration in latency-sensitive, edge artificial intelligence applications and identifies critical gaps in infrastructure equity and ethical artificial intelligence governance. All findings offer valuable insights for defense researchers, policymakers, and system architects aiming to shape future-ready, technology-integrated defense ecosystems.},
  archive      = {J_EAAI},
  author       = {Munish Bhatia and Pallvi},
  doi          = {10.1016/j.engappai.2025.112822},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112822},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The integration of emerging technologies in defense: A scientometric overview},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multitasking optimization for personalized exercise group recommendation in E-learning environments. <em>EAAI</em>, <em>163</em>, 112820. (<a href='https://doi.org/10.1016/j.engappai.2025.112820'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized exercise group recommendation (PEGR) is to select a set of exercises from a large exercise bank for students, which plays an important role in E-learning. Due to the complexity of real application scenarios, PEGR is usually modeled as a large-scale constrained multi-objective optimization problem and solved by multi-objective evolutionary algorithms (MOEAs). However, the “curse of dimensionality” and the complex constraints handling are the two challenges encountered when designing MOEAs to solve the PEGR problem. To this end, we propose a novel evolutionary tri-tasking algorithm named ETT-PEGR to tackle the challenges of solving the PEGR, in which two auxiliary tasks are constructed to help solve the original task through knowledge transfer. Specifically, the first concept-recommended auxiliary task is designed to recommend knowledge concepts instead of exercises to students, which can help accelerate the convergence speed of the original task since the number of concepts is much smaller than that of exercises. The second constraint-ignored auxiliary task is designed to help the solutions of the original task to cross the infeasible region. In addition, a novel knowledge transfer mechanism based on different encoding strategies is proposed for the original task and the two auxiliary tasks, which can effectively realize the knowledge transfer between them. Experimental results on four popular datasets show that ETT-PEGR outperforms the state-of-the-art algorithms for PEGR.},
  archive      = {J_EAAI},
  author       = {Haipeng Yang and Sibo Liu and Zihao Chen and Yuanyuan Ge and Lei Zhang},
  doi          = {10.1016/j.engappai.2025.112820},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112820},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multitasking optimization for personalized exercise group recommendation in E-learning environments},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A decision-making method based on optimal evaluation index function and aggregation direction under unknown weights. <em>EAAI</em>, <em>163</em>, 112819. (<a href='https://doi.org/10.1016/j.engappai.2025.112819'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to improve the accuracy of decision results by examining three critical aspects: evaluation index function, weight method, and aggregation direction. Utilizing the interval-valued q -rung orthopair fuzzy set, which possesses strong generalization capabilities, as the fuzzy aggregation environment, the power average (PA) and Maclaurin symmetric mean (MSM) operators are employed to enhance the data processing capabilities of the aggregation operator. Meanwhile, to improve the discriminant accuracy between fuzzy numbers, two new evaluation index functions are induced according to the interval membership degree relationship, subsequently, evaluation criteria under the interval-valued q -rung orthopair fuzzy environment are constructed. Then, considering the determination of relevant weight information in decision problems, a weight determination method based on subjective/objective weight fusion is proposed. Further, according to the actual problems, the influence of different data aggregation directions is analyzed, and a more factual decision scheme is formulated to improve decision accuracy. Finally, the proposed method is applied to specific examples, and qualitative and quantitative methods are used to analyze the decision results to prove its validity and superiority. In summary, the method can provide a novel way to explore and explain the decision framework and aggregation direction in the decision process, which helps promote the development of decision science and artificial intelligence.},
  archive      = {J_EAAI},
  author       = {Weijia Ren and Xinlong Li and Yuhong Du and Di Zhao},
  doi          = {10.1016/j.engappai.2025.112819},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112819},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A decision-making method based on optimal evaluation index function and aggregation direction under unknown weights},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Trustworthy distributed mirror learning for secure and private multi-agent coordination. <em>EAAI</em>, <em>163</em>, 112812. (<a href='https://doi.org/10.1016/j.engappai.2025.112812'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world deployment of Multi-Agent Reinforcement Learning (MARL) in Internet of Things (IoT) systems requires convergence, verifiability, and privacy to be jointly guaranteed, a capability absent in current approaches. While Multi-Agent Trust Region Learning (MATRL) ensures Nash equilibrium convergence, it risks data exposure and malicious attacks. To address this, we propose Trustworthy Distributed Mirror Learning (TDML), the first method to unify convergence, verifiability, and privacy in MARL. TDML theoretically breaks MATRL’s centralized architecture into agent-local learning and inter-agent communication. This allows key data to be secured with advanced techniques without compromising the theoretical properties of trust-region learning. Specifically, TDML introduces three core innovations: (1) an information functional that unifies all communication behaviors in distributed MATRL and enables flexible integration of security mechanisms; (2) split advantage computation, which decouples raw inputs from global advantages via intermediate representations to protect local data privacy; and (3) a security scheme that ensures verifiable message exchange by attaching zero-knowledge proofs to inter-agent communications. We prove TDML converges to a Nash equilibrium while providing verifiability and privacy guarantees. More importantly, it constructs a mirror space for trustworthy MARL, where derivative algorithms inherit these theoretical guarantees. Experiments show TDML outperforms state-of-the-art methods, improving attack resilience by up to 76% (sign-flipping attack) and achieving a 90+% privacy reconstruction error, while reducing communication overhead by up to 99% compared to homomorphic encryption. TDML establishes a foundational framework for trustworthy MARL, from which derivative algorithms inherit core guarantees for secure, real-world IoT deployment.},
  archive      = {J_EAAI},
  author       = {Suhang Wei and Jinfang Jia and Xiang Feng and Huiqun Yu},
  doi          = {10.1016/j.engappai.2025.112812},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112812},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Trustworthy distributed mirror learning for secure and private multi-agent coordination},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel framework for segmenting open-pit mining road. <em>EAAI</em>, <em>163</em>, 112811. (<a href='https://doi.org/10.1016/j.engappai.2025.112811'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of open-pit mine road networks presents a critical challenge for mine digitization and autonomous driving applications. These roads are prone to mechanical compaction, geological erosion, and coverage by gravel dust, resulting in segmentation outcomes characterized by blurred boundaries, holes, fractures, and geometric deformations, which severely compromise measurement accuracy. To address these challenges, this paper proposes the Mining Road Segmentation Network (MRS-Net), which integrates local features with global semantics. First, a Residual Network Version 2 (ResNetV2)-Transformer cascaded encoder is constructed, employing residual connections to preserve sub-pixel-level edge details and multi-head self-attention to establish long-range dependencies, thereby enhancing the representation of weak texture features. Second, the Road Multi-scale Features Fusion Module (RMFF) was designed to extract local geometric features and global continuity features through progressive hollow convolution, enabling the model to extract multi-scale features and effectively suppress interference from gravel dust. Finally, a progressive decoding architecture incorporating bilinear interpolation is adopted to improve edge smoothness. MRS-Net is evaluated on an Unmanned Aerial Vehicle (UAV)-acquired road dataset from the Anshan open-pit iron mine in Liaoning Province, China. Results demonstrate that MRS-Net achieves superior segmentation performance compared to models such as DeepLabV3+ and TransUNet across three distinct scenarios: main roads, temporary roads, and abandoned roads. Specifically, it achieves Intersection over Union (IoU), Dice coefficient(Dice), and Kappa coefficient (Kappa) values of 89.4 % / 94.1 % / 87.2 %, 75.7 % / 83.3 % / 75.1 %, and 83.8 % / 90.0 % / 84.85 % respectively for these scenarios.},
  archive      = {J_EAAI},
  author       = {Shuo Fan and Yachun Mao and Shuai Zhen and Jing Liu and Liming He and Xinqi Mao},
  doi          = {10.1016/j.engappai.2025.112811},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112811},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel framework for segmenting open-pit mining road},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Time-dependent compressibility characteristics of soil: Experimental and integrated machine learning framework. <em>EAAI</em>, <em>163</em>, 112809. (<a href='https://doi.org/10.1016/j.engappai.2025.112809'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mechanical performance of clay as a geomaterial is influenced by its time-dependent stress-strain characteristics. It is a complex phenomenon triggered by the viscous nature of adsorbed pore water and the internal arrangement of soil structure. This research emphasizes the significance of creep deformation characteristics of soil in both its natural and reconstituted states, utilizing the Elasto-Viscoplastic Swelling (EVPS) model. Various predictive machine learning models were presented to determine the creep parameters. To optimize model performance, Extreme Gradient Boosting (XGBoost) and Bayesian optimization were used. The findings observed that incorporating admixtures significantly influences the compressibility characteristics of clay, leading to a reduction in time-dependent parameters such as the creep coefficient and creep strain limit. Notably, the study finds that creep effects are most pronounced during the second cycle, with a gradual reduction occurring in subsequent cycles. Among the predictive models, the Random Forest exhibited the highest predictive accuracy, while Linear Regression and Support Vector Regression showed comparatively lower performance. Additionally, SHapley Additive exPlanations (SHAP) were utilized to explore feature importance and revealed that approximately 74.24% of the total mean absolute SHAP values were attributed to water content and plasticity behavior, highlighting a pivotal role in prediction, followed by applied stress. Moreover, the study also highlights integrated approaches of the EVPS model and machine learning modeling for accurately determining creep behavior.},
  archive      = {J_EAAI},
  author       = {Moirangthem Johnson Singh and Lalit Borana and Mahdia Hattab and Jian-Hua Yin},
  doi          = {10.1016/j.engappai.2025.112809},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112809},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Time-dependent compressibility characteristics of soil: Experimental and integrated machine learning framework},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Estimation of time-dependent darcy-forchheimer flow through artificial intelligence-based technique for chemically reactive trihybrid nanofluid configured by rotating sphere invoked bioconvection analysis. <em>EAAI</em>, <em>163</em>, 112808. (<a href='https://doi.org/10.1016/j.engappai.2025.112808'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, the application of Levenberg–Marquardt backpropagation scheme is used to demonstrate the importance of viscous dissipation, Joule heating, and magnetic field on the stagnation point Darcy–Forchheimer flow of ternary hybrid nanofluid around a rotating sphere containing oxytactic and gyrotactic microorganisms. The present analysis additionally includes higher-order biochemical reactions and heat generating effects. In this paper, the performance of each nanofluid is compared using the Hamilton–Crosser model. This model can be using to optimize and construct complex cooling systems. The result is a statistical matrix data set and a linear graphical representation of the established model on several parameters. The results are thoroughly verified and cross-checked until they align with the Levenberg–Marquardt backpropagation model, utilizing a stochastic, artificial intelligent driven neural network approach. This blend of artificial intelligence allows for precise predictions of nonlinear flow parameters and is beneficial for applications in both biomedical and industrial heat transfer systems. An analysis of the findings indicates that an increase in the Forchheimer and Darcy parameters lowers primary velocity and that a stronger magnetic field boosts the velocity. Changing the Prandtl number leads to temperature decreasing in the profile and changing the Schmidt and chemistry parameters tends to reduce the concentration profile. The profiles of gyrotactic and oxytactic microorganisms are reduced as the Schmidt numbers grow larger. The model is very accurate, reaching values close to zero regression and having a mean square error of 10 −6 , confirming it is effective for predicting complicated fluid movements.},
  archive      = {J_EAAI},
  author       = {Muhammad Habib Ullah Khan and Amjad Ali Pasha and Hamid Qureshi and Salem Algarni and Talal Alqahtani and Nashwan Adnan Othman and Waqar Azeemn Khan and Kashif Irshad and M. Waqas},
  doi          = {10.1016/j.engappai.2025.112808},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112808},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Estimation of time-dependent darcy-forchheimer flow through artificial intelligence-based technique for chemically reactive trihybrid nanofluid configured by rotating sphere invoked bioconvection analysis},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Zero-velocity update -aided navigation method for miniature quadruped robot based on adapted virtual inertial measurement unit. <em>EAAI</em>, <em>163</em>, 112807. (<a href='https://doi.org/10.1016/j.engappai.2025.112807'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing the challenges associated with installing inertial measurement units (IMUs) on the feet of miniature quadruped robots, this paper proposes a zero-velocity update (ZUPT) method based on adaptive virtual inertial measurement unit (VIMU). This approach eliminates the reliance of existing ZUPT method for inertial navigation systems on foot-mounted IMUs and gait recognition. By utilizing the IMU outputs from legs and feet of a quadruped robot as the training dataset, an innovative Convolutional Neural Network (CNN)- Bidirectional gated recurrent unit neural network (BiGRU)-Attention hybrid network is constructed to establish a nonlinear mapping relationship between the multiple IMUs. In practical applications, the foot-mounted VIMU can be generated solely from the leg-mounted IMU data, and the modified navigation parameters are then output through a ZUPT algorithm to achieve accurate positioning of the quadruped robot. Experimental results demonstrate that the positioning errors of this method is about 1.34 % of the total path under diverse terrain conditions, including slopes, stairs, and grasslands, outperforming gait recognition-dependent methods in terms of accuracy. This approach effectively implements the inertial navigation function of quadruped robots and enhances the adaptability of ZUPT method to unstructured and unknown terrains. This approach has great potential to improve Global Navigation Satellite Systems (GNSS)-denied positioning performance of quadruped robots in complex environments without the assistance of visual sensor and LightLaser Detection and Ranging (LiDAR).},
  archive      = {J_EAAI},
  author       = {Siwei Tang and Weixing Qian and Sen Wang and Feng Yang and Xinyuan Wang and Weinan Gao and Pengyu Liu},
  doi          = {10.1016/j.engappai.2025.112807},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112807},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Zero-velocity update -aided navigation method for miniature quadruped robot based on adapted virtual inertial measurement unit},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fuzzy fixed-time multi-source fusion with attention-based neural networks for reliable navigation under satellite signal loss. <em>EAAI</em>, <em>163</em>, 112806. (<a href='https://doi.org/10.1016/j.engappai.2025.112806'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and reliable navigation is critical for autonomous systems, particularly in environments with sensor errors, unknown dynamic variations, global navigation satellite system (GNSS) outages, and complex maneuvers. This paper presents an innovative navigation framework that combines an adaptive observer with fixed-time convergence and a deep learning model based on an attention-equipped convolutional neural network (CNN) and a gated recurrent unit (GRU) with conditional fusion of air-data sensors in both GNSS-available and GNSS-denied conditions. At the core of the system lies a nonlinear observer with theoretical guarantees for fixed-time convergence, capable of estimating both the system state and perturbations independently of initial conditions. To enhance resilience against noise, sensor drift, and the limitations of low-cost inertial measurement units (IMUs), a fuzzy logic-based mechanism is employed to adaptively adjust observer gains using the normalized estimation error and its variance. During GNSS outages, the deep learning predictor — based on CNN and GRU with an attention mechanism — is used to estimate horizontal position changes from IMU data. Convolutional neural network layers extract local features, GRU layers capture temporal dependencies, and the attention mechanism prioritizes informative segments, enabling accurate and reliable predictions. In addition, a conditional sensor fusion strategy is proposed, which selectively utilizes pitot tube velocity and barometric altitude only during GNSS-denied phases, effectively mitigating the drift of the strap-down inertial navigation system (SINS). Field experiments across complex trajectories — including several GNSS interruptions — demonstrate that the proposed hybrid artificial intelligence-based framework offers improved estimation accuracy and real-time autonomous navigation in challenging real-world environments.},
  archive      = {J_EAAI},
  author       = {Elahe Sadat Abdolkarimi and Sadra Rafatnia},
  doi          = {10.1016/j.engappai.2025.112806},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112806},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuzzy fixed-time multi-source fusion with attention-based neural networks for reliable navigation under satellite signal loss},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Long time series prediction of milling force via a hybrid multi neuro-network-based algorithm. <em>EAAI</em>, <em>163</em>, 112805. (<a href='https://doi.org/10.1016/j.engappai.2025.112805'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of machine learning and deep learning has significantly improved the accuracy and efficiency of cutting force prediction in machining processes. However, challenges such as short prediction period, degradation in accuracy over time, and the risk of overfitting remains. These limitations collectively hinder the reliability and generalizability of artificial intelligence-based force prediction models. To address these issues, this study proposed a novel hybrid multi-neural-network algorithm that integrates convolutional neural networks, long short-time memory, and residual networks to enhance both the accuracy and duration of cutting force prediction. Prior to model training, raw force signals are pre-processed using particle swarm optimization-based variational mode decomposition to effectively eliminate noise and reduce uncertainty. The training and testing datasets are derived from milling experiments conducted under varying cutting parameters, tool types, and sensor configurations to better emulate real-world industrial conditions. Experimental results demonstrate that the hybrid model model can accurately predict cutting forces over a duration exceeding 1 s. The model's higher mean absolute error under varying test conditions suggests good robustness. The proposed data pre-processing phase contributes to a 6.38 % improvement in prediction accuracy. Furthermore, increasing the hyperparameter “timestep” helps mitigate overfitting, with only a minor trade-off in accuracy (less than 5 %). These findings demonstrate the effectiveness of the hybrid algorithm in addressing key limitations of existing models and highlight its potential for robust and generalizable prediction using AI in manufacturing applications.},
  archive      = {J_EAAI},
  author       = {Meng Liu and Hui Xie and Xiangkun He and Wencheng Pan and Fengling Han and Guangxian Li and Songlin Ding},
  doi          = {10.1016/j.engappai.2025.112805},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112805},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Long time series prediction of milling force via a hybrid multi neuro-network-based algorithm},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A metaheuristic-driven categorical boosting framework with interpretability for high-precision prediction of mechanical properties in corroded reinforced concrete beams. <em>EAAI</em>, <em>163</em>, 112804. (<a href='https://doi.org/10.1016/j.engappai.2025.112804'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The degradation of mechanical properties in corroded reinforced concrete (RC) beams presents a major challenge for assessing structural durability. To address this issue, this study proposes an integrated machine learning (ML) framework to predict the mechanical properties of such beams. First, a database of 464 samples was established, including 12 input parameters and 2 output parameters, followed by correlation analysis of the inputs. On this basis, the applicability of existing design codes and empirical models was evaluated. Subsequently, eight ML models were trained, with their hyperparameters optimized via Bayesian optimization (BO) to enhance prediction accuracy. The Categorical Boosting (CatBoost) model was identified as the most accurate, and its hyperparameters were further optimized using Particle Swarm Optimization (PSO) and Genetic Algorithm (GA) for improved performance. Results show the PSO-optimized CatBoost model achieves the highest prediction accuracy to date: for the flexural strength test set, the coefficient of determination ( R 2 ) is 0.984 and root mean square error ( RMSE ) is 3.1602; for the deflection test set, R 2 is 0.975 and RMSE is 0.6259. Compared with design codes, flexural strength test set R 2 increases by 27.3 % and RMSE decreases by 72.8 %; versus traditional models like Support Vector Regression (SVR), R 2 rises by 5.4 % and RMSE drops by 43.5 %. Additionally, SHapley Additive exPlanations (SHAP) analysis reveals geometric parameters (beam height, beam width) dominate flexural strength, while elastic stiffness and beam length drive deflection. Finally, a user-friendly graphical user interface (GUI) was developed for rapid mechanical property assessment of corroded RC beams.},
  archive      = {J_EAAI},
  author       = {Yuzhuo Zhang and Zheng Wang and Jinlong Liu and Yalin Li and Zhenqin Huang and Xiaohu Yu},
  doi          = {10.1016/j.engappai.2025.112804},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112804},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A metaheuristic-driven categorical boosting framework with interpretability for high-precision prediction of mechanical properties in corroded reinforced concrete beams},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A physics-penalized neural network with asynchronous propagation and localization embedding for dynamic plantar pressure prediction in older adults. <em>EAAI</em>, <em>163</em>, 112802. (<a href='https://doi.org/10.1016/j.engappai.2025.112802'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For older adults, the early identification of foot complications depends significantly on the ability to predict plantar pressure accurately. Existing methods for this prediction are often expensive and fail to provide the localized accuracy and biomechanical consistency needed for reliable diagnosis. To solve these issues, we propose the Asynchronous Propagation Physics-Penalized Neural Network (AP-PPNN) with Localization Embedding, which thus predicts dynamic plantar pressure from an image of the foot imprint. Data collection with ink-based footprints and sensor-based pressure values forms the basis of pre-processing normalization, noise reduction, and segmentation. The Adaptive Causal Decision Transformers (ACDT) read the quantitative relationship obtained between the pressure patterns. At the same time, the Localization Embedding module refines the heatmap-based localization of pressure with physics-guiding constraints. The model AP-PPNN incorporates Asynchronous Propagation to improve computational efficiency and applies physics-penalized constraints for biomechanical accuracy. Additionally, it classifies footprints into nine foot types (Normal (N), Plantar Load (PL), Toe-Emphasized (TE), and their hybrid combinations) for refined risk assessment. Hyperparameters have been optimized using the Migration-Crossover Algorithm to increase precision. The performance evaluation has shown that the proposed method outperforms existing models in terms of accuracy, obtaining the highest accuracy of 98.6 %, precision of 97.8 %, recall of 98.4 %, and F1 of 98.1 % with the least error of 1.4 % and computational time of 4.5 s. Finally, we deploy the system in a user-friendly application for clinical and home-based monitoring, providing a cost-effective, non-invasive solution for early detection and prevention of foot disorders.},
  archive      = {J_EAAI},
  author       = {Madhumitha Sekaran and Kamalraj Subramaniam},
  doi          = {10.1016/j.engappai.2025.112802},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112802},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A physics-penalized neural network with asynchronous propagation and localization embedding for dynamic plantar pressure prediction in older adults},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep learning-based on-site identification and volume measurement of bulk material in construction industry. <em>EAAI</em>, <em>163</em>, 112797. (<a href='https://doi.org/10.1016/j.engappai.2025.112797'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bulk materials are important raw construction materials, the adequate and precise supply of which enables a smooth construction process. Two conventional techniques for controlling the quantity of bulk materials on-site along the supply chain are: 1) estimation based on the cone-shape of the material pile, but the accuracy is low; 2) calculation by using bulk density and weighing stations, which are not available in all facilities. To address this issue, we propose a novel hybrid camera-based method combining a red-green-blue (RGB) camera and a light detection and ranging (LiDAR) sensor for automatic material type identification and volume measurement. The data from two-dimensional pictures and three-dimensional point cloud were segmented and extracted with two Deep Learning models: “You Only Look Once“ (YOLO) v5 and PointNet++for the identification of material type and volume measurement. This novel hybrid camera-based method was developed as an Industry 4.0 solution to enable the automatic and accurate evaluation of the volume of bulk materials. With a precision of 81.6 % in object recognition and a volume estimation deviation of less than 8 %, it provides a reliable and efficient alternative to conventional, labour-intensive measurement techniques.},
  archive      = {J_EAAI},
  author       = {Zhen Cai and Ghaith Allah Chebil and Yuan Tan and Stephan Kessler and Johannes Fottner},
  doi          = {10.1016/j.engappai.2025.112797},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112797},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning-based on-site identification and volume measurement of bulk material in construction industry},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-robot collaborative obstacle avoidance based on hierarchical path planning methods. <em>EAAI</em>, <em>163</em>, 112796. (<a href='https://doi.org/10.1016/j.engappai.2025.112796'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve collision-free cooperative obstacle avoidance in complex dynamic environments, this paper proposes a hierarchical path planning method considering three-dimensional spatiotemporal characteristics. The framework consists of two levels. At the global level, the Jump Point Search algorithm is improved by introducing a safety distance constraint between robots and obstacles and an angle-based priority search strategy, enabling the generation of globally optimal paths with improved safety and efficiency. At the local level, a three-dimensional spatiotemporal grid model replaces the traditional two-dimensional plane graph to predict potential conflicts between robots and dynamic obstacles. Different coordination strategies are then applied according to conflict types, ensuring safe and efficient avoidance. Simulation results show that, compared with the A-star algorithm, the improved Jump Point Search reduces path length by about 13 % and turning points by 50 %, while computation time decreases by nearly 89 %. Compared with the original Jump Point Search, path length is shortened by 8 %, turning points by 36 %, and computation time by 49 %. In the coordination stage, robots can dynamically adjust trajectories to achieve collision-free planning. These results demonstrate that the proposed hierarchical method not only improves planning efficiency and generates smoother, safer paths, but also effectively resolves inter-robot conflicts in dynamic environments, ensuring high levels of safety, real-time performance, and collaboration.},
  archive      = {J_EAAI},
  author       = {Yanjuan Wu and Hui Li},
  doi          = {10.1016/j.engappai.2025.112796},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112796},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-robot collaborative obstacle avoidance based on hierarchical path planning methods},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Investigation of stochastic deep learning path planning methods for mobile robots. <em>EAAI</em>, <em>163</em>, 112795. (<a href='https://doi.org/10.1016/j.engappai.2025.112795'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning is essential for mobile robot navigation, especially in complex environments. Traditional methods like RRT* (Rapidly Exploring Random Tree) explore known spaces effectively but lack time efficiency. Recent neural planners generate paths quickly on unseen maps, though often unreliably. This work proposes two stochastic neural planners: Noise, Displacement, Map-Generative Adversarial Network (NDM-GAN) and Stochastic-Long Short-Term Memory (S-LSTM) which integrate structured randomness to enhance generalization. NDM-GAN uses convolutions over random noise, start/goal points, and map data and S-LSTM leverages dropout in latent map-encoded LSTMs. Tested on unseen maps, they achieve up to 93.40% success and generate paths up to 13,793.18% faster than RRT*, with shorter lengths and greater obstacle clearance. Compared to similar planners, they show a 28.3% gain in viable path rates. While not probabilistically complete, these models demonstrate the power of stochasticity in neural planning, offering a strong basis for further work.},
  archive      = {J_EAAI},
  author       = {Spencer Ploeger and Aidan Holvik and Rachael Mohl and Mohammad Biglarbegian and Ryan Myers},
  doi          = {10.1016/j.engappai.2025.112795},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112795},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Investigation of stochastic deep learning path planning methods for mobile robots},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A twin-level feature synthesis and long-term coherence framework for multi-object animal tracking in outdoor farm environments. <em>EAAI</em>, <em>163</em>, 112794. (<a href='https://doi.org/10.1016/j.engappai.2025.112794'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tracking animal activity in outdoor farm environments is crucial for livestock management, yet it remains a challenging task due to dynamic changes in cow appearance, variable lighting and unpredictable animal movements. Traditional vision-based systems, while effective indoors, often fail outdoors as they rely on consistent visual cues, leading to unstable tracking and poor identity association. This paper introduces TwinTrack, a multi-object tracking framework designed to address these challenges. The proposed framework leverages a Twin-Level Contextual Feature Synthesizer (TLCFS) to extract both fine-grained visual details and high-level semantic features, ensuring robustness under diverse environmental conditions. Additionally, a Dynamic Long-Term Temporal Consistency Module (DLTC) improves tracking stability by mitigating the effects of dynamic behaviours and scene fluctuations. The application of TwinTrack to outdoor farm environments demonstrates its ability to monitor livestock effectively, with experimental results showing stable, long-term tracking performance.},
  archive      = {J_EAAI},
  author       = {Renhui Ying and Jinjin Wang and Chongxiao Liu and Bao Kha Nguyen},
  doi          = {10.1016/j.engappai.2025.112794},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112794},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A twin-level feature synthesis and long-term coherence framework for multi-object animal tracking in outdoor farm environments},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An improved graph attention network for semantic segmentation of industrial point clouds in automotive battery sealing nail defect detection. <em>EAAI</em>, <em>163</em>, 112793. (<a href='https://doi.org/10.1016/j.engappai.2025.112793'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate defect detection in automotive battery sealing nails is vital for safety and reliability. Traditional methods combine two-dimensional (2D) vision for localization with three-dimensional (3D) vision for measurement, resulting in complex workflows and reduced efficiency. We propose Local Graph Attention for Semantic Segmentation (LGASS), an end-to-end 3D point cloud segmentation model. LGASS processes raw point cloud data from structured-light systems, performing simultaneous defect localization and geometric quantification in a single stage. By leveraging a graph attention mechanism in an encoder–decoder architecture, LGASS captures local geometric features and long-range dependencies, excelling on industrial metallic surfaces. Experiments show LGASS achieves 99.47% Overall Accuracy (OA), 92.37% mean Accuracy (mAcc), and 79.23% mean Intersection over Union (mIoU), offering a robust solution for automated sealing nail inspection.},
  archive      = {J_EAAI},
  author       = {Wei Pan and Yuhao Wu and Wenming Tang and Qinghua Lu and Yunzhi Zhang},
  doi          = {10.1016/j.engappai.2025.112793},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112793},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improved graph attention network for semantic segmentation of industrial point clouds in automotive battery sealing nail defect detection},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Inverse compensation and adaptive fuzzy integral sliding-mode control for the underactuated soft massage physiotherapy robot. <em>EAAI</em>, <em>163</em>, 112792. (<a href='https://doi.org/10.1016/j.engappai.2025.112792'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acupoint massage physiotherapy is a kind of effective method to prevent and remedy diseases. Soft robotics technology is thriving, which has potential applications in the field of acupoint massage physiotherapy. Soft massage physiotherapy robot (SMPR) uses the soft robotics technology to realize the acupoint massage physiotherapy function. In this paper, an SMPR consisting of a wearable armor and several pneumatic physiotherapy actuators (PPAs) is design and fabricated. In order to describe complex hysteresis behavior of SMPR, the dynamic model of its PPA is established and identified, which includes two parts: a linear model and an asymmetric Prandtl–Ishlinskii hysteresis (APIH) model. An inverse compensator is then designed to compensate for the hysteresis behavior of the SMPR based on the APIH model, and an approximately linearized system is obtained. Then, by dint of the artificial intelligence method, a fuzzy approximator is designed to approximate the control system’s lumped uncertainty, which includes external disturbances, modeling errors and parameter perturbations. Further, an adaptive fuzzy integral sliding-mode control (AFISMC) is employed to handle the lump uncertainty. Moreover, based on the back-stepping control method, a nominal controller is designed to realize the control of the approximately linearized system. By combining the inverse compensator, fuzzy approximator, AFISMC and nominal controller, the control of the SMPR is realized and the acupoint massage physiotherapy can be controlled accurately. The stabilization to a control systems is theoretically demonstrated. Finally, the experimental results from multiple test scenarios conclusively demonstrate the efficacy and trajectory tracking capability of the developed control strategy.},
  archive      = {J_EAAI},
  author       = {Zixin Huang and Chengsong Yu and Junjie Lu and Hao Liu and Peng Huang},
  doi          = {10.1016/j.engappai.2025.112792},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112792},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inverse compensation and adaptive fuzzy integral sliding-mode control for the underactuated soft massage physiotherapy robot},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Secure and energy-efficient unmanned aerial vehicle-enabled visible light communication via a multi-objective optimization approach. <em>EAAI</em>, <em>163</em>, 112791. (<a href='https://doi.org/10.1016/j.engappai.2025.112791'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research investigates a unique approach for providing communication service to terrestrial receivers via using unmanned aerial vehicle-enabled visible light communication. Specifically, we consider a scenario involving multiplex transmitters, multiplex receivers, and a single eavesdropper, each of which is equipped with a single photodetector. Then, a unmanned aerial vehicle deployment multi-objective optimization problem is formulated to simultaneously enhance the uniformity of the optical power received by the receivers, minimize the amount of information collected by the eavesdropper, and minimize the energy consumption of unmanned aerial vehicles, by jointly optimizing the locations and transmission power of unmanned aerial vehicles under specific constraints. Due to the complexity and nonlinearity of the formulated unmanned aerial vehicle deployment multi-objective optimization problem, conventional methods are inadequate for solving it efficiently. Therefore, a multi-objective evolutionary algorithm based on decomposition with chaos initiation and crossover mutation is proposed. Simulation outcomes demonstrate that the proposed approach outperforms other approaches, providing significant improvements in both security and energy efficiency for visible light communication systems. In addition, extensive simulations are conducted to verify the convergence, robustness, adaptability, and scalability of the proposed method under various influencing factors, including terrestrial receiver distributions, unmanned aerial vehicle height variations, visible light communication channel uncertainty, unmanned aerial vehicle position dynamics, as well as scenario scale changes. The results show that the proposed method exhibits superior convergence, robustness, adaptability and scalability, and can flexibly adapt to the dynamic changes of channels and unmanned aerial vehicle positions. Moreover, it ensures coverage fairness, system security and energy efficiency of unmanned aerial vehicles, which further makes it well-suited for practical unmanned aerial vehicle-enabled visible light communication systems operating in dynamic and uncertain environments.},
  archive      = {J_EAAI},
  author       = {Lingling Liu and Aimin Wang and Jing Wu and Jiao Lu and Jiahui Li and Geng Sun},
  doi          = {10.1016/j.engappai.2025.112791},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112791},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Secure and energy-efficient unmanned aerial vehicle-enabled visible light communication via a multi-objective optimization approach},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An innovative optimization strategy based on mamba and generative adversarial networks for efficient and high-performance multimodal image fusion. <em>EAAI</em>, <em>163</em>, 112788. (<a href='https://doi.org/10.1016/j.engappai.2025.112788'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal image fusion (MIF) integrates multisource data into a single high-quality image with minimal redundancy. While deep learning has advanced MIF by improving fusion quality, convolutional neural networks (CNNs) struggle with long-range dependencies, and Transformers incur high computational costs. Additionally, preserving fine textures, suppressing noise, and achieving high efficiency remain challenges, particularly for infrared and visible image fusion (IVIF). This paper proposes MMGFuse, a novel MIF framework based on a Multi-Parallel Vision Mamba Generative Adversarial Network. MMGFuse leverages the Mamba model's efficiency and generative adversarial networks' realism, introducing a residual parallel vision Mamba (ResPViM4) module to enhance texture and detail preservation and a multi-parallel vision Mamba (MPViM) module to capture both global and local features across scales. A dual-modality image discriminator further optimizes visual quality. Experiments show that MMGFuse outperforms state-of-the-art methods in subjective visual quality and objective metrics for IVIF and medical image fusion, demonstrating its effectiveness, efficiency, and broad applicability in advancing image fusion. The codes are available at https://github.com/sunyichen1994/MMGFuse .},
  archive      = {J_EAAI},
  author       = {Yichen Sun and Mingli Dong and Lianqing Zhu},
  doi          = {10.1016/j.engappai.2025.112788},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112788},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An innovative optimization strategy based on mamba and generative adversarial networks for efficient and high-performance multimodal image fusion},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Detection and localization of false data injection attacks based on multi-scale feature fusion and attention enhancement network in smart grid. <em>EAAI</em>, <em>163</em>, 112787. (<a href='https://doi.org/10.1016/j.engappai.2025.112787'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel framework based on the multi-scale feature fusion and attention enhancement network (MSFF-AEN) for detecting and localizing false data injection attacks (FDIAs) in smart grid. The model innovatively designs improved residual block with convolutional block attention module (CBAM) after the second convolutional layer, reducing early noise interference, and enhancing interpretability. It also incorporates a bidirectional long short-term memory network (BiLSTM) and multi-head attention (MHA) to capture temporal features and global dependencies respectively. Additionally, hierarchical feature fusion (HFF) with learnable weights optimizes and integrates multi-scale features, thereby enhancing feature representation and model interpretability. Experimental results on the IEEE 14-bus and IEEE 118-bus systems show that the proposed model outperforms existing conventional models and deep learning methods across multiple evaluation metrics, including accuracy, precision, recall, and F1-score. Particularly, the model performs exceptionally well on the large-scale IEEE 118-bus power system, achieving an accuracy of 98.73%, precision of 98.48%, recall of 97.45%, and F1-score of 97.95%. Furthermore, the model demonstrates strong robustness to various Gaussian noise conditions, maintaining high localization accuracy.},
  archive      = {J_EAAI},
  author       = {Jian Li and Hanting Lu and Qingyu Su},
  doi          = {10.1016/j.engappai.2025.112787},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112787},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detection and localization of false data injection attacks based on multi-scale feature fusion and attention enhancement network in smart grid},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Posture stability control of a beaver-like bipedal robot based on the deep interactive twin delayed deep deterministic policy gradient algorithm. <em>EAAI</em>, <em>163</em>, 112781. (<a href='https://doi.org/10.1016/j.engappai.2025.112781'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The underwater environment presents a complex and variable dynamic that challenges the modeling process and is crucial for ensuring the swimming stability of underwater bionic robots. This paper focuses on the biological beaver as a model for developing a new configuration of an underwater bionic rigid-flexible coupled serial-parallel hybrid mechanism. A bionic beaver bipedal robot is designed following this model. To enhance training efficiency and avoid ineffective exploration, we propose a deep interactive reinforcement learning algorithm that leverages human experience, informed by the movement trajectories of the biological beaver. This algorithm facilitates pitch stability motion control in an underwater bionic beaver bipedal robot without complex modeling and reduces training duration substantially. The implementation of this deep interactive reinforcement learning method on a beaver-like bipedal robot prototype has demonstrated successful pitch stability motion control. Experimental results confirm the efficacy of this control strategy, providing novel perspectives and methodologies for stable motion control in underwater webbed-footed robots.},
  archive      = {J_EAAI},
  author       = {Gang Chen and Hanhan Xue and Zhihan Zhao and Yuwang Lu and Guangke Cao and Chenguang Yang and Huosheng Hu and Chuanyu Wu and Jinfeng Zeng and Lichun Weng and Pingyu Yang},
  doi          = {10.1016/j.engappai.2025.112781},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112781},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Posture stability control of a beaver-like bipedal robot based on the deep interactive twin delayed deep deterministic policy gradient algorithm},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Shaping Q-values right: A distributional normalized actor–critic approach. <em>EAAI</em>, <em>163</em>, 112779. (<a href='https://doi.org/10.1016/j.engappai.2025.112779'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) has achieved remarkable success in a wide range of tasks. However, unavoidable errors in value estimation can lead to suboptimal policy performance, particularly in challenging continuous control tasks. To address this challenge, we propose the distributional normalized actor–critic (DNAC) framework. A central idea of DNAC is the introduction of an approximate upper bound on the estimation error between the estimated Q -values and the optimal values. This upper bound allows us to reshape the loss function, which scales and shifts the estimated Q -value distribution toward the optimal value, effectively normalizing it. With this normalization, DNAC is expected to improve both the stability of training and the final policy performance in RL. Simulation results on six MuJoCo benchmarks show that DNAC consistently achieves higher-performing policies compared to other popular RL baselines. Moreover, by tuning its key parameters — capable of reproducing some existing RL algorithms — we identify key factors that influence RL policy performance.},
  archive      = {J_EAAI},
  author       = {Jonghyeok Park and Jangwon Kim and Soohee Han},
  doi          = {10.1016/j.engappai.2025.112779},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112779},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Shaping Q-values right: A distributional normalized actor–critic approach},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dual-scale adaptive attention-based vision transformer with iterative refinement for clarity and consistency in multi-focus image fusion. <em>EAAI</em>, <em>163</em>, 112777. (<a href='https://doi.org/10.1016/j.engappai.2025.112777'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-focus Image Fusion (MFIF) has become a prominent role in combining focused regions of several source images into a single all-in-focus fused image. However, existing approaches have the limitation of maintaining global spatial coherence and sharp details. To overcome these limitations, the Dual-Scale Adaptive Attention-Based Vision Transformer (DAA-ViT) model is proposed, which integrates fine-scale and coarse-scale attention, with the aim of maintaining local high-resolution information along with structural coherence. Additionally, an Iterative Refinement Fusion (IRF) is introduced to refine focus boundaries through multiple iterations for enhancing overall image definition, while mitigating fusion artifacts and focus selection errors. Especially, this Artificial Intelligence (AI)-based approach is efficient in complex scenes with inconsistent depth levels, which is suitable for applications like remote sensing and medical image processing. Experimental results of several benchmark datasets demonstrate that the proposed method attains better results than existing methods with a Mutual Information (MI) of 8.9671, Structural Similarity Index Measure (SSIM) of 0.9211, Peak Signal-To-Noise Ratio (PSNR) of 36.728 dB, and Lower Root Mean Square Error (RMSE) of 1.5482. Compared to the existing Swin Transformer and Convolutional Neural Network (STCU-Net) model, the proposed model attains 2.65 % improvement in PSNR, 1.99 % improvement in MI, 1.11 % improvement in Structural Similarity Index Measure, and 5.13 % reduction in RMSE. These findings demonstrate the efficiency of AI-based fusion strategies in delivering high-quality all-in-focus images and emphasize their applications in medical imaging and remote sensing processing.},
  archive      = {J_EAAI},
  author       = {Gengrui Li and Daoyun Tang and Jinhuan Huang and Shaoning Zhu and Jiangtao Cao},
  doi          = {10.1016/j.engappai.2025.112777},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112777},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-scale adaptive attention-based vision transformer with iterative refinement for clarity and consistency in multi-focus image fusion},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel lightweight multi-path learning with explainable artificial intelligence technique based on ovarian cancer detection framework. <em>EAAI</em>, <em>163</em>, 112772. (<a href='https://doi.org/10.1016/j.engappai.2025.112772'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in computer vision have improved medical diagnosis, including ovarian cancer detection, but deep learning models are often complex and difficult to interpret. We propose a multi-path learning framework that captures both local and global features from ovarian cancer images. Built on DenseNet, the model uses five parallel paths to extract diverse features: (1) Mobile Inverted Bottleneck Convolution (MBConv) blocks for efficient local feature extraction, (2) Cascaded Self-Attention Pyramid Pooling (CSAPP) for capturing multi-scale global context, (3) deformable convolutions for spatially flexible features, (4) dilated convolutions to expand the receptive field, and (5) channel attention modules to emphasize discriminative feature channels. Outputs from all paths are fused into a multi-level feature map. Monte Carlo Sampling (MCS) enhances statistical feature learning and estimates prediction uncertainty, while dynamic entropy-based thresholding removes low-information activations. An dynamic adaptive weighted loss function mitigates class imbalance and overfitting. For interpretability, Gradient-weighted Class Activation Mapping (Grad-CAM) highlights important image regions, and Shapley Additive Explanations (SHAP) quantifies feature contributions. Experiments demonstrate superior performance, achieving 99.28 % accuracy, 98.2 % sensitivity, and a false negative rate of 1.8 %, outperforming existing methods. This framework provides an interpretable and reliable tool for early-stage ovarian cancer detection.},
  archive      = {J_EAAI},
  author       = {Padmalal S. and Nelson Kennedy Babu C.},
  doi          = {10.1016/j.engappai.2025.112772},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112772},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel lightweight multi-path learning with explainable artificial intelligence technique based on ovarian cancer detection framework},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Missing microseismic data imputation in tunnel monitoring using a transformer model with an integrated gaussian mixture model. <em>EAAI</em>, <em>163</em>, 112771. (<a href='https://doi.org/10.1016/j.engappai.2025.112771'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microseismic (MS) monitoring is essential for early warning and evaluation of structural safety in tunnel engineering. However, data loss due to environmental interference often compromises the reliability of such systems. To address this challenge, a data imputation model that integrates the Gaussian Mixture Model (GMM) with a transformer-based neural network, referred to as the GMM–Transformer model, was developed. Its performance was evaluated using real-world MS monitoring data from a deep-buried tunnel project in southwestern China. The proposed method achieves high accuracy in reconstructing missing data, with the imputed results closely matching observed values across multiple characteristic parameters. By leveraging the probabilistic nature of the Gaussian mixture distribution and Monte Carlo Dropout, the model can also quantify predictive uncertainty, yielding narrow confidence intervals that reinforce its reliability. The influence of missing data duration on the imputation quality was examined. The results imply that a missing window of approximately 3.5 h yields optimal results. A comparison between direct and indirect imputation strategies indicates that the direct approach significantly reduces reconstruction errors, from 25.73 % to 13.37 %. Additionally, benchmark comparisons with models such as random forest and long short-term memory networks show that the proposed model offers superior accuracy in recovering spatial characteristic critical to MS analysis. Overall, the GMM–Transformer model provides an effective, robust solution for dealing with data loss in MS monitoring. This work provides a forward-looking methodology and theoretical foundation for advancing artificial intelligence–based MS monitoring technologies in complex tunnel environments.},
  archive      = {J_EAAI},
  author       = {Zhihao Kuang and Shaojun Li and Shili Qiu and Yong Huang and Shuaipeng Chang},
  doi          = {10.1016/j.engappai.2025.112771},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112771},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Missing microseismic data imputation in tunnel monitoring using a transformer model with an integrated gaussian mixture model},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-stage evidence fusion underwater target recognition method based on multivariate variational mode decomposition feature optimization and conflict handling. <em>EAAI</em>, <em>163</em>, 112769. (<a href='https://doi.org/10.1016/j.engappai.2025.112769'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater acoustic target recognition plays a critical role in marine safety, environmental monitoring, and national security. However, the complex and dynamic nature of underwater environments — characterized by noise interference, signal attenuation, and multi-path propagation — poses significant challenges to reliable and accurate target identification. To address these issues, this paper proposes a novel, robust framework for underwater target recognition by integrating an enhanced signal decomposition technique with a conflict-aware evidence fusion strategy. We first introduce MVMD-CSFR (Multivariate Variational Mode Decomposition with Component-Specific Feature Refinement), which combines MVMD with grey relational analysis for adaptive mode decomposition and effective component selection. This step significantly improves signal clarity by eliminating noise-dominated and redundant modes. High-dimensional features are then extracted from the refined modes through time–frequency, spectral, auditory, and waveform analyses, followed by Fisher score-based feature selection to reduce redundancy and enhance discriminability. To further improve decision reliability in uncertain environments, we propose a Two-Stage Conflict-Aware Evidence Theory (TSCAET) fusion framework that dynamically identifies and corrects conflicting evidence from heterogeneous mode components. Evaluated on real-world underwater acoustic datasets, the proposed method achieves a recognition accuracy of 90.64%, representing a 13.07% improvement over baseline approaches. Ablation studies confirm the individual contributions of MVMD-CSFR (improvement: 0.97%–8.26%) and TSCAET (improvement: 1.51%–10.37%) across diverse conditions. This work advances the state-of-the-art in underwater acoustic recognition by offering a principled, data-driven pipeline that enhances both feature quality and decision fusion under uncertainty.},
  archive      = {J_EAAI},
  author       = {Jiahui Dai and Yibo Zou and ZhongZhe Xiao and Min Huang},
  doi          = {10.1016/j.engappai.2025.112769},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112769},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A two-stage evidence fusion underwater target recognition method based on multivariate variational mode decomposition feature optimization and conflict handling},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Predicting tourism demand using data based on a two-stage feature selection: A hybrid deep learning approach incorporating Time2Vec. <em>EAAI</em>, <em>163</em>, 112768. (<a href='https://doi.org/10.1016/j.engappai.2025.112768'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate tourism demand forecasting is important for regional tourism planning, management, and industry development. However, existing models often struggle with the complexity of external variables or fail to capture essential temporal patterns and multi-scale temporal correlations, directly limiting their accuracy and robustness. Therefore, we propose a predictor with Two-Stage Feature Selection and Time2Vec-enhanced Extraction Mechanisms (TFS-T2VEM). The model employs a two-stage feature selection strategy to refine predictive variables and integrates a Time2Vec-driven temporal pattern extraction module to effectively capture key temporal patterns across multiple scales. By leveraging multi-scale features from intermediate layers of Convolutional Neural Networks (CNN), it captures both mid-short-term fluctuations and long-term trends. Time2Vec further serves as an implicit temporal decomposition module, replacing traditional methods by embedding temporal information directly into the network. This enables dynamic attention adjustment based on intrinsic periodicity and external disturbances, enhancing the temporal attention mechanism by focusing on critical time points and reducing noise from irrelevant features. These improvements ultimately contribute to higher predictive accuracy and robustness. Extensive experiments on three datasets show that our model consistently outperforms baseline methods, confirming its effectiveness in tourism demand forecasting.},
  archive      = {J_EAAI},
  author       = {Jinghui Wei and Sheng Wu and Qiangwen Zheng},
  doi          = {10.1016/j.engappai.2025.112768},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112768},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting tourism demand using data based on a two-stage feature selection: A hybrid deep learning approach incorporating Time2Vec},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Health indicator modeling leveraging time-independent and time-dependent subtasks with adaptive standardization and physics-based bayesian optimization for aeronautical structures. <em>EAAI</em>, <em>163</em>, 112767. (<a href='https://doi.org/10.1016/j.engappai.2025.112767'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring the structural integrity of aeronautical structures is critical for safety, reducing maintenance costs, and enabling predictive maintenance. However, raw structural health monitoring (SHM) data are often noisy, high-dimensional, and difficult to interpret. To enable condition-based maintenance, it is essential to extract health indicators (HIs)—quantitative representations of structural degradation that evolve consistently over time. Accurately extracting HIs for composite structures is particularly challenging due to complex material behavior and multiple damage sources. While deep learning models offer potential, their application is limited by the lack of run-to-failure data and ground-truth HI labels. To address these challenges, this study proposes a novel approach that divides HI modeling into two tasks: time-independent (spatial) and time-dependent (temporal). This separation allows more effective data utilization, especially in the time-independent case. A semi-supervised spatial model is first developed and fine-tuned using a Bayesian algorithm with a coupled physics-based loss function that integrates both prognostic criteria and simulated labels—explicitly through the former and implicitly through the latter—embedding degradation physics into training. The study also introduces a new adaptive standardization technique for fatigue-based SHM and systematically evaluates principal component analysis (PCA)-based methods for dimensionality reduction prior to spatial and temporal modeling, simplifying subsequent network architectures. In the final stage, following time-based resampling, a semi-supervised temporal model captures HI evolution, with ensemble learning enhancing robustness. Validation on single-stiffener composite panels under fatigue loading, monitored via acoustic emission sensors, confirms the framework's generalizability and performance—achieving up to 90% (±2%) accuracy in prognostic metrics.},
  archive      = {J_EAAI},
  author       = {Morteza Moradi and Juan Chiachío and Dimitrios Zarouchas},
  doi          = {10.1016/j.engappai.2025.112767},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112767},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Health indicator modeling leveraging time-independent and time-dependent subtasks with adaptive standardization and physics-based bayesian optimization for aeronautical structures},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A risk assessment framework for online transactions via graph neural networks and efficient probabilistic prediction. <em>EAAI</em>, <em>163</em>, 112766. (<a href='https://doi.org/10.1016/j.engappai.2025.112766'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transactions are integral to daily life, but the occurrence of abnormal behaviors can lead to significant risks. Online transaction risk is characterized by the accumulation of abnormal behaviors, where their frequency surpasses a predefined threshold, resulting in measurable probabilities and consequences. Therefore, the assessment of online transaction risk heavily depends on probabilistic predictions of the accumulated frequency of abnormal behaviors, presenting two major challenges. Firstly, abnormal behaviors across different instances (e.g., behavior types, product categories, regions, and platforms) exhibit temporal correlations, such as co-occurrence and concomitance, which most probabilistic models fail to identify and utilize effectively. Additionally, these models do not fully address the real-time demands. To address these challenges, we propose a novel risk assessment framework based on Graph Neural Network (GNN) and probabilistic prediction, named GNN-Probformer. The framework uses Dynamic Time Warping to capture temporal correlations between abnormal behavior frequency sequences and constructs a graph structure through clustering. It then employs Graph Neural Networks to aggregate features and learn representations through a novel embedding module. A sparse self-attention mechanism and an efficient encoder–decoder architecture are incorporated to further enhance performance, while probabilistic predictions are generated through Monte Carlo sampling and cumulative distribution functions. Experimental results on a real-world dataset demonstrate that GNN-Probformer achieves substantial performance gains, with a 15% reduction in normalized deviation. At the 90th percentile, it further reduces normalized quantile loss by 15% and improves the F1-score by 16%, while also reducing training time and inference time by 47% and 38%, respectively.},
  archive      = {J_EAAI},
  author       = {Jicai Chang and Xuejing Fu and Zhen Chen and Li Pan and Shijun Liu},
  doi          = {10.1016/j.engappai.2025.112766},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112766},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A risk assessment framework for online transactions via graph neural networks and efficient probabilistic prediction},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Nonlinear extended state observer-based model-free near-optimal sliding mode water level controller of an inverted U-tube steam generator. <em>EAAI</em>, <em>163</em>, 112755. (<a href='https://doi.org/10.1016/j.engappai.2025.112755'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water level control in the inverted U-tube steam generator (UTSG) is crucial for nuclear power plant safety. Conventional proportional–integral–derivative (PID) systems suffer from slow response and poor robustness, while recent intelligent control approaches generally rely on uncertain models, leading to degraded performance under long-term conditions. To this end, this paper proposes a nonlinear extended state observer (NESO)-based model-free near-optimal sliding mode control (MFNOSMC) strategy, aiming to achieve the near-optimal water level control performance with near-minimal control energy consumption, without relying on explicit UTSG models. In the field of nuclear engineering, this is the first attempt to investigate the model-free, near-optimal water level controller and its practical application for the UTSG, subject to uncertainties and perturbations; in the field of control engineering, this work effectively solves the Hamilton–Jacobi–Bellman equation by leveraging the estimation capability of the NESO, while developing a novel neural network-based sliding mode surface that eliminates the reaching phase. A rigorous Lyapunov-based theoretical analysis verifies that the water level control error converges to a small residual set around zero with the near-optimal control response and near-minimal control cost. Finally, comprehensive simulation studies, comparing the proposed NESO-based MFNOSMC strategy with the existing PID control system, fixed-time disturbance observer-based fractional-order sliding mode controller, and active disturbance rejection controller, further demonstrate its superior performance in significantly improving transient response characteristics, enhancing perturbation robustness, and reducing energy consumption.},
  archive      = {J_EAAI},
  author       = {Jiuwu Hui},
  doi          = {10.1016/j.engappai.2025.112755},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112755},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Nonlinear extended state observer-based model-free near-optimal sliding mode water level controller of an inverted U-tube steam generator},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cross-species animal pose estimation via feature map orthogonal decomposition decoder. <em>EAAI</em>, <em>163</em>, 112749. (<a href='https://doi.org/10.1016/j.engappai.2025.112749'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate animal pose estimation represents a pivotal challenge in deciphering animal behavior and neural correlates, primarily stemming from cross-species morphological heterogeneity, the stability of pose estimation models, and the complexity of animal locomotion. In this paper, we propose a robust and scalable model that serves as a foundational baseline for cross-species animal pose estimation. Our work advances the field by leveraging the vision transformer as the backbone for feature extraction and integrating a novel feature map orthogonal decomposition decoder (FMODD), which substantially enhances the model’s scalability, diversity, stability, and accuracy. Specifically, the model achieves scalability through multi-scale variants, enabling adaptation to diverse experimental scenarios. It exhibits diversity by supporting tasks including single-animal, multi-animal, cross-species, and few-shot pose estimation. It demonstrates stability with robust performance in adapting to cross-species variations. Moreover, it attains high accuracy with state-of-the-art results on multiple benchmark datasets—outperforming most existing models even when utilizing its smallest-scale variant. In practical applications, it shows promising potential for deployment in natural environments, which is particularly valuable for research in zoology, ecology, and conservation biology, where precise and reliable pose estimation is indispensable for studying animal behavior in their natural habitats. Further details regarding the model configuration and datasets will be available on the project website .},
  archive      = {J_EAAI},
  author       = {Xin Wu and Yanmei Wang and Lianming Wang and Jipeng Huang},
  doi          = {10.1016/j.engappai.2025.112749},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112749},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cross-species animal pose estimation via feature map orthogonal decomposition decoder},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Secure breast cancer imaging: A novel advanced generative model encryption approach. <em>EAAI</em>, <em>163</em>, 112747. (<a href='https://doi.org/10.1016/j.engappai.2025.112747'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proposed work presents a novel Artificial Intelligence (AI) technique, specifically a Cyclic-Generative Adversarial Network (Cyclic GAN)-based encryption framework, for securing breast cancer medical images, leveraging AI's ability to learn from unpaired datasets. Unlike traditional chaotic encryption methods requiring aligned input-output pairs, this proposal employs dual generators and discriminators to transform images while preserving features, ensuring secure and high-quality encryption. The model is optimized using binary cross-entropy loss for precise adversarial training and evaluated on breast cancer datasets. The integration of a Structural Similarity Index Metric (SSIM) optimized loss function of 0.9944 (Surpassing conventional chaotic encryption by 21.3 %) ensures exceptional preservation of structural integrity, brightness, and contrast in decrypted images. Quantitative evaluation demonstrates outstanding reconstruction quality with Peak Signal-to-Noise Ratio (PSNR) values reaching 39.08 dB (exceeding wavelet-based methods by 41 %). A comprehensive security analysis confirms the system's resistance to statistical and discriminative attacks while maintaining efficient encryption and decryption performance. The system's dual generator-discriminator architecture optimized with Binary Cross Entropy loss provides following three key advantages over state-of-art techniques: 40 % faster encryption/decryption than pixel-scrambling methods, 92 % resistance to statistical attacks compared to 78 % for Advanced Encryption Standard based approaches elimination of the paired data requirement that hinders conventional deep learning solutions. The Number of Pixel Change Rate (NPCR) > 99.2 % and Unified Average Changing Intensity (UACI) ≈ 33.4 % confirm protection against differential attacks.},
  archive      = {J_EAAI},
  author       = {Saba Inam and Shamsa Kanwal and Fahima Hajjej and Ala Saleh Alluhaidan},
  doi          = {10.1016/j.engappai.2025.112747},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112747},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Secure breast cancer imaging: A novel advanced generative model encryption approach},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph neural networks for per- and poly-fluoroalkyl substances concentration prediction in water supply wells. <em>EAAI</em>, <em>163</em>, 112746. (<a href='https://doi.org/10.1016/j.engappai.2025.112746'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The persistence and widespread contamination of per- and poly-fluoroalkyl substances (PFAS) in water resources poses serious public health and environmental monitoring challenges. To address the need for more sophisticated predictive tools, we present the first watershed-scale application of Graph Neural Networks (GNNs) for estimating PFAS concentrations in unmonitored wells. Our approach leverages 1650 samples from 303 public wells collected between 2018 and 2023 within a 2300 km 2 study area containing over 179 suspected or confirmed PFAS sites. The GNN models capture intricate geospatial and lithological relationships to predict PFAS levels at more than 1330 unsampled locations. We further examine how hyperparameter optimization affects model accuracy and apply uncertainty analysis to ensure the reliability of predictions. Six heterogeneous-convolution architectures featuring various attention schemes and edge embeddings were assessed across 28 graph configurations, consistently demonstrating strong predictive capabilities and highlighting the potential of GNNs to enhance environmental monitoring and inform risk management.},
  archive      = {J_EAAI},
  author       = {Vahid Rafiei and A. Pouyan Nejadhashemi},
  doi          = {10.1016/j.engappai.2025.112746},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112746},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph neural networks for per- and poly-fluoroalkyl substances concentration prediction in water supply wells},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Temporal diffuser: Timing scale-aware modulation for sign language production. <em>EAAI</em>, <em>163</em>, 112739. (<a href='https://doi.org/10.1016/j.engappai.2025.112739'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in Sign Language Production (SLP) highlight denoising diffusion models as promising alternatives to traditional autoregressive methods. Most existing approaches follow a two-stage pipeline that encodes sign motion into discrete latent codes, often sacrificing Space–Time fidelity and requiring gloss annotations or complex codebooks. Transformer-based models aim to simplify this, but often produce overly smooth, unnatural motions. We introduce Sign Language Production with Scale-Aware Modulation (SignSAM), a novel single-stage, gloss-free SLP framework that directly synthesizes motion in continuous space, preserving fine temporal details. At its core is a Space–Time U-Net that learns compact temporal features by jointly downscaling the frame and sign feature dimensions, thereby reducing computational cost compared to a no-pyramid UNet or a pyramid UNet without consistency between dimensions. To further enhance temporal precision, we propose a Timing Scale-Aware Modulation module that fuses multiscale temporal resolutions for better motion coherence. Experiments on PHOENIX14T and How2Sign show that SignSAM achieves state-of-the-art (SOTA) fluency, accuracy, and naturalness, offering an efficient and expressive solution for SLP. Our project homepage is https://kha-kim-thuy.github.io/SLP-Demo/ .},
  archive      = {J_EAAI},
  author       = {Kim-Thuy Kha and Anh H. Vo and Van-Vang Le and Oh-Young Song and Yong-Guk Kim},
  doi          = {10.1016/j.engappai.2025.112739},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112739},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Temporal diffuser: Timing scale-aware modulation for sign language production},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). AFEformer: An adaptive frequency enhancement transformer for time series prediction. <em>EAAI</em>, <em>163</em>, 112736. (<a href='https://doi.org/10.1016/j.engappai.2025.112736'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term time series forecasting (LTSF), as a key research domain with pervasive applications in real-world scenarios, has garnered sustained interest from both academic and industrial communities. Although transformer-based models have demonstrated high predictive capability in capturing long-term temporal dependencies, most of them directly process raw data in the time domain while ignoring the representation of features in the frequency domain. Additionally, transformer models with frequency domain often learn weights directly but overlook frequency statistics for time series, leading to the impact of low-quality interference frequencies. Moreover, Transformer’s self-attention captures correlations solely within sequences but neglects correlations among different sequences, increasing susceptibility to overfitting. To address these issues, we innovatively design an adaptive frequency enhancement transformer (AFEformer) with temporal external attention for time series forecasting, which focuses on enhancing important frequency domain features to provide more accurate forecasting. Specifically, a frequency domain enhancement module with an adaptive threshold strategy is proposed , using frequency statistics to selectively extract key spectral components and strengthen frequency domain features. Furthermore, the temporal external attention enhancement module with Infinite Norm and dropout layer is presented to explore potential correlations between different sample sequences and mitigate overfitting. Regarding long-term forecasting, comprehensive experiments demonstrate that AFEformer achieves state-of-the-art forecasting performance on nine time series forecasting benchmarks.},
  archive      = {J_EAAI},
  author       = {Zhiyong An and Lanlan Dong},
  doi          = {10.1016/j.engappai.2025.112736},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112736},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {AFEformer: An adaptive frequency enhancement transformer for time series prediction},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An improved retrieval-augmented long-term grouting power prediction method: Rejecting low-similarity retrievals. <em>EAAI</em>, <em>163</em>, 112733. (<a href='https://doi.org/10.1016/j.engappai.2025.112733'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grouting power long-term prediction is beneficial to regulating power output. Traditional long-term prediction methods require iterative updates with newly accumulated data during construction, which is time-consuming. Retrieval-augmented methods not only achieve higher prediction accuracy but also enable more efficient performance upgrades through database updates, avoiding the need to retrain models. However, conventional retrieval augmented frameworks unconditionally incorporate retrieved sequences into the prediction process, even when their similarity to the query is low. This design choice can introduce noisy or irrelevant historical patterns, misleading the fusion mechanism and degrading overall performance. To address this issue, this study proposes a retrieval-augmented method for long-term grouting power prediction with a rejection-substitution mechanism. Compared with the naive retrieval augmented prediction method, this mechanism enables selective fusion of retrievals by evaluating the similarity of each retrieved sequence before integration. If the similarity falls below a predefined threshold, the corresponding result is substituted with a prediction from the TimeXer model. Otherwise, the retrieved result is retained. The processed results are then fused by a Gate Recurrent Unit network to generate the final prediction. To validate the effectiveness of the proposed method, experiments were conducted on both a grouting power dataset and a publicly accessible dataset. The results indicate that incorporating a rejection-substitution mechanism enhances the prediction accuracy compared to the traditional retrieval-augmented prediction approach.},
  archive      = {J_EAAI},
  author       = {Baoxi Liu and Liangsi Xu and Bingyu Ren and Chengyu Yu and Hongling Yu and Xiangyu Chen and Xinyu Liu},
  doi          = {10.1016/j.engappai.2025.112733},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112733},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improved retrieval-augmented long-term grouting power prediction method: Rejecting low-similarity retrievals},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Novel supervised neuro-stochastic nonlinear autoregressive exogenous networks: A tool for fractional cyber warfare modeling. <em>EAAI</em>, <em>163</em>, 112724. (<a href='https://doi.org/10.1016/j.engappai.2025.112724'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ominous choreography of keystrokes, the clashing of code, and the unseen maneuvers of ghostly hackers, compose a symphony of chaos, reminding us the threat of cyber war. This research aims to exploit the AI methodologies by utilizing nonlinear autoregressive with exogenous inputs (NARX) networks for numerical treatment of fractional cyber warfare model, to tackle the challenges posed by inherent complexity and stiffness associated with the system involving fractional derivatives. The fractional cyber warfare model offers a versatile approach to simulate a wide range of attack surfaces with multifaceted attack patterns. This enables the depiction of multiple attack scenarios with greater accuracy and flexibility. The synthetic data for NARX was generated by utilizing Adams numerical solver to simulate various scenarios associated with the model, providing a reliable basis for training, testing and validating of the neural networks. The generated data was segmented into three parts for the purposes of training, testing, and validation. This segmentation allows us for enabling the successful execution of the designed NARX networks for calculating the approximate solution of the fractional order cyber warfare model. Comparing the outcomes of the Grünwald–Letnikov (GL) backward finite difference solver with obtained solutions verify the accuracy, consistency, and efficacy of the developed NARX methodology for simulating the cyber warfare system. This demonstrates the effectiveness of the methodology as an advanced computational tool for analyzing and addressing the challenges of cyber warfare. The comprehensive simulation-based performance of the predictive neural network was further verified and endorsed by analyzing the learning curves through mean squared error based fitness, autocorrelation, crosscorrelation, histograms and regression metrics for the system.},
  archive      = {J_EAAI},
  author       = {Z.M. Waraich and Muhammad Asif Zahoor Raja},
  doi          = {10.1016/j.engappai.2025.112724},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112724},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Novel supervised neuro-stochastic nonlinear autoregressive exogenous networks: A tool for fractional cyber warfare modeling},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A lightweight deep learning network for the precise detection and classification of variable plankton. <em>EAAI</em>, <em>163</em>, 112719. (<a href='https://doi.org/10.1016/j.engappai.2025.112719'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a diverse community of organisms, plankton plays a crucial role in the marine ecosystem. The application of deep learning techniques facilitates the rapid detection and classification of vast amounts of plankton images at minimal cost. However, the existing plankton classification models struggle to achieve a balance between classification accuracy and lightweight design. To address this, a lightweight plankton classification network (Plankton-LiNet) was proposed. Firstly, a hybrid dual depth network (H2GDNet) was designed as a lightweight backbone to enhance feature extraction efficiency. Secondly, an adaptive downsampling module (ADown) was integrated into the feature fusion network to strengthen the network's ability to learn features while minimizing detail loss. Thirdly, considering plankton phenotypes of varying scales, a lightweight shared convolutional detection head (LSCD-Detect) was implemented to elevate overall classification accuracy, avoid cumbersome computations, and further streamline the model. The findings demonstrate that Plankton-LiNet offers substantial advantages in model size (2.7 megabytes, MB), computational complexity (4.4 giga-floating-point operations, GFLOPs), number of parameters (1.24 million, M), and inference speed (122.2 frames per second, FPS) compared to other mainstream classification models on a plankton dataset comprising 15 categories. Additionally, evaluation of its actual classification performance on a test set with more complex scenarios revealed an overall category Precision, Recall, and F1-score of 98.0 %, 98.4 %, and 98.2 %, respectively, indicating significant effectiveness. This positions Plankton-LiNet as a reliable technical tool for routine plankton detection and classification, while also laying the groundwork for the further development of intelligent real-time in situ observation systems in the future.},
  archive      = {J_EAAI},
  author       = {Xinquan Ye and Hangzhou Wang and Junhao Yao},
  doi          = {10.1016/j.engappai.2025.112719},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112719},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight deep learning network for the precise detection and classification of variable plankton},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Acoustic based leak location detection for water supply pipelines in urban areas via multi-task deep learning. <em>EAAI</em>, <em>163</em>, 112718. (<a href='https://doi.org/10.1016/j.engappai.2025.112718'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expeditious and precise localization of leaks holds paramount importance for water utility providers to ensure the timely rectification of damaged pipes. This study introduces an innovative approach to address challenges for leak detection and localization, capitalizing on noise loggers to capture acoustic emissions from real field and forming the bedrock of the database for deep learning. First, the discrete wavelet transform-based denoising technique is applied to acoustic signals captured by noise loggers, mitigating susceptibility to noise interference. Second, a novel multi-task deep learning framework is devised to enhance the efficacy and accuracy of leak detection and localization, incorporating a variational autoencoder to obtain latent representations housing essential yet compact information. Finally, to enhance generalization in data-scarce scenarios, transfer learning is invoked to capitalize on the acquired latent representations to ensure optimal performance. Upon evaluation against an independent test, best leak detection accuracies of 100 % and 98.5 % are achieved for non-metallic and metallic water supply pipelines, respectively, with corresponding leak localization errors (MAE, Mean Absolute Error) being 0.273 m and 0.096 m.},
  archive      = {J_EAAI},
  author       = {Rui Zhang and Ali Fares and Ibrahim A. Tijani and Tarek Zayed and Zeren Jin and Abdul-Mugis Yussif},
  doi          = {10.1016/j.engappai.2025.112718},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112718},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Acoustic based leak location detection for water supply pipelines in urban areas via multi-task deep learning},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing surrogate model accuracy in ship design optimization through intelligent constraint-aware sample selection. <em>EAAI</em>, <em>163</em>, 112716. (<a href='https://doi.org/10.1016/j.engappai.2025.112716'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the hull form optimization design problem based on numerical simulation, constructing a surrogate model is usually required to reduce computational cost and time. However, since the existing sample point selection methods do not consider the influence of constraint conditions on the sampling space, the effectiveness of their sample point selection is not high, which is also one of the main reasons for the high cost of constructing a high-precision surrogate model. Therefore, this paper proposes an improved sampling method to achieve effective selection of sample points in the feasible region and improve the efficiency of the surrogate model development. The proposed method uses data mining to identify the potential mapping relationship between optimization variables and constraint conditions, realizes the selection of sample points in the space satisfying constraints, and then constructs an surrogate model in the feasible region to achieve efficient hull form optimization. Applying this method to the actual hull form optimization process of a 7500 Deadweight Tonnage (DWT) bulk carrier shows that under the same sample size, the prediction accuracy of the surrogate model is significantly improved, and the optimization result similar to that of the traditional method is obtained, verifying the engineering applicability of the intelligent sampling process proposed in this paper. This paper proposes an intelligent sampling framework integrating data mining, innovatively embeds data mining technology into the sampling process, realizes the reduction of sampling space and optimization space from the full space to the constraint subspace, leading to ship intelligent optimization.},
  archive      = {J_EAAI},
  author       = {Chang HaiChao and Hou Wenlong and Liu Zuyuan and Feng Baiwei and Zheng Qiang},
  doi          = {10.1016/j.engappai.2025.112716},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112716},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing surrogate model accuracy in ship design optimization through intelligent constraint-aware sample selection},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancement of apple defect identification with semantic segmentation and label-efficient data generation. <em>EAAI</em>, <em>163</em>, 112679. (<a href='https://doi.org/10.1016/j.engappai.2025.112679'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for automated fruit-sorting systems has driven the development of machine vision and deep learning technologies for postharvest grading of fruit defects. Effective sorting requires identifying not only the presence of defects but also their types and severity to avoid unnecessary rejection of marketable fruits with minor defects. This study applied deep learning-based semantic segmentation models to Fuji apple images, focusing on four defect types: cracks, bruises, diseases, and scars. Model performance was evaluated for both defect classification and severity estimation. To further improve performance, a label-efficient approach using generative adversarial networks was proposed to generate synthetic apple images and defect masks, reducing the need for extensive manual labeling to create a larger dataset. Qualitative and quantitative analyses of the generated results showed that the synthetic dataset successfully mimicked the biological characteristics of apples as well as the shape, position, and size of the defects. The segmentation model's ability to identify defects was enhanced by the proposed synthetic dataset. The R 2 values for defect severity estimation increased to 0.82, 0.85, 0.75, and 0.92 for cracks, bruises, diseases, and scars respectively, while F1-scores for defect classification reached 100, 94.3, 94.1, and 89.7 %. Furthermore, per-sample classification performance was enhanced with a binary F1-score of 95.9 % for defect presence and a multi-label accuracy of 93.9 % for defect types. This study clearly demonstrates that synthetic datasets generated using generative adversarial networks can substantially enhance both defect type classification and severity estimation in semantic segmentation-based apple defect identification models.},
  archive      = {J_EAAI},
  author       = {Jiwon Ryu and Sang-Yeon Kim and Chang-Hyup Lee and Gyumin Kim and Harin Jang and Taehyeong Kim and Suk-Ju Hong and Geon Hee Kim and Ghiseok Kim},
  doi          = {10.1016/j.engappai.2025.112679},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112679},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancement of apple defect identification with semantic segmentation and label-efficient data generation},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A new multi-object tracking algorithm based on sparse detection transformer. <em>EAAI</em>, <em>163</em>, 112666. (<a href='https://doi.org/10.1016/j.engappai.2025.112666'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-object tracking (MOT) is crucial for intelligent surveillance and autonomous driving. However, existing Transformer-based methods often suffer from an accuracy-efficiency trade-off due to high computational complexity, limiting real-time applicability. To address this, we propose SparseDeTrack (Sparse Detection Tracking), an efficient MOT framework based on the tracking-by-detection (TBD) paradigm. In detection, we employ a sparse token Transformer with a 30 % token retention rate, effectively reducing computational cost while retaining essential features. In tracking, we remove the Re-Identification (ReID) module and enhance the Extended Kalman Filter (EKF) by directly predicting the width and height instead of the aspect ratio of bounding boxes, improving both localization accuracy and nonlinear motion modeling. Furthermore, ByteTrack (Multi-Object Tracking by Associating Every Detection Box) is integrated for secondary association, increasing robustness under occlusion. We conduct extensive experiments on MOTChallenge 17 (MOT17), MOTChallenge 20 (MOT20), and DanceTrack benchmarks. On the MOT17 test set, SparseDeTrack achieves a Multiple Object Tracking Accuracy (MOTA) of 75.4, outperforming Transformer-based methods such as MOTR (End-to-End Multiple-Object Tracking with Transformer), Trackformer (Multi-Object Tracking with Transformers), and TransTrack (Multiple Object Tracking with Transformer) by 2.0, 1.3, and 0.2 points, respectively, while attaining a high inference speed of 44.5 frames per second (FPS), balancing accuracy and efficiency. It reaches 65.6 MOTA on crowded MOT20 and 89.1 MOTA on nonlinear-motion DanceTrack, comparable to state-of-the-art methods. These results confirm that SparseDeTrack delivers both high-precision tracking and real-time inference in complex scenarios, making it a promising solution for real-world applications in intelligent surveillance and autonomous driving.},
  archive      = {J_EAAI},
  author       = {Jun Miao and Maoxuan Zhang and Yuanhua Qiao},
  doi          = {10.1016/j.engappai.2025.112666},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112666},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new multi-object tracking algorithm based on sparse detection transformer},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Classification and detection of direct current power quality disturbances for grid operation implications using deep learning models. <em>EAAI</em>, <em>163</em>, 112644. (<a href='https://doi.org/10.1016/j.engappai.2025.112644'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In direct current power systems, the introduction of new energy generation and non-linear loads can cause power quality disturbances, which can degrade power quality and jeopardise the system's functionality. Due to the dearth of research on direct current power quality disturbance standards, this paper identifies seven essential direct current power quality disturbances. This study proposes hybrid solutions for classifying direct current power quality disturbances based on deep learning. The method first augments the dataset with a generative adversarial network, then transforms the one-dimensional data into two-dimensional data using the Gramian angular field and finally feeds the data into a convolutional neural network based on the GoogleNet framework to identify and classify disturbances and introduces an attention mechanism to enhance the network's efficiency. The mathematical models are used to generate 50 disturbances for the training phase dataset, while the microgrid simulation system is sampled to produce the inference phase dataset. The proposed model attained 98.66 % classification accuracy during the training phase and maintained classification accuracy of 98.41 %, 98.11 % and 97.84 % despite 70 dB, 60 dB and 50 dB noise interference respectively. In addition, the classification precision of the inference phase is 92.18 %. The experimental outcomes demonstrate that the proposed model has outstanding performance and real-time grid operation implications.},
  archive      = {J_EAAI},
  author       = {Hui Hwang Goh and Haozhe Xu and Dongdong Zhang and Wei Dai and Shen Yuong Wong and Tonni Agustiono Kurniawan and Kai Chen Goh},
  doi          = {10.1016/j.engappai.2025.112644},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112644},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Classification and detection of direct current power quality disturbances for grid operation implications using deep learning models},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention dynamic graph convolutional network for traffic flow prediction. <em>EAAI</em>, <em>163</em>, 112642. (<a href='https://doi.org/10.1016/j.engappai.2025.112642'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is crucial for intelligent transportation systems, enabling effective urban planning, traffic management, and emergency response. Existing methods rely on adjacency matrices to model traffic network connections, often failing to capture real-time dynamics and complex spatiotemporal dependencies due to static or data-limited dynamic matrices. To address these challenges, we propose an Attention Dynamic Graph Convolutional Network (ADGCN) that integrates an adaptive dynamic graph convolutional network with a novel lightweight Gated Recurrent Unit and an enhanced attention mechanism. The lightweight gated recurrent unit offers significant efficiency gains over the standard gated recurrent unit. By optimizing its gating mechanism and shrinking the hidden layer dimension, it features a lower number of parameters and achieves a 19 %–47 % reduction in training time. These improvements make it highly suitable for deployment on resource-constrained devices and for use in real-time traffic applications. The dynamic graph generation method, leveraging input features and node embeddings with normalization and nonlinear transformations, effectively captures evolving spatial dependencies without predefined graph structures, enhancing adaptability to fluctuating traffic conditions. The improved attention mechanism strengthens inter-channel feature dependencies, enabling the model to focus on task-critical features and boosting prediction accuracy. Validated on six real-world datasets, ADGCN outperforms most state-of-the-art models on key metrics. It also demonstrates remarkable efficiency, with up to a 47 % reduction in training time and excellent real-time performance, making it highly suitable for Intelligent Transportation Systems.},
  archive      = {J_EAAI},
  author       = {Chenhui Wei and Chuanming Chen and Xiang Wu and Dongmei Pan and Qingying Yu and Xiaoyao Zheng and Yonglong Luo},
  doi          = {10.1016/j.engappai.2025.112642},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112642},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Attention dynamic graph convolutional network for traffic flow prediction},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multimodal fusion in speech emotion recognition: A comprehensive review of methods and technologies. <em>EAAI</em>, <em>163</em>, 112624. (<a href='https://doi.org/10.1016/j.engappai.2025.112624'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech emotion recognition (SER) plays a crucial role in human–computer interaction, enhancing numerous applications such as virtual assistants, healthcare monitoring, and customer support by identifying and interpreting emotions conveyed through spoken language. While unimodal SER systems demonstrate notable simplicity and computational efficiency, excelling in extracting critical features like vocal prosody and linguistic content, there is a pressing need to improve their performance in challenging conditions, such as noisy environments and the handling of ambiguous expressions or incomplete information. These challenges underscore the necessity of transitioning to multimodal approaches, which integrate complementary data sources to achieve more robust and accurate emotion detection. With advancements in artificial intelligence, especially in neural networks and deep learning, many studies have employed advanced deep learning and feature fusion techniques to enhance SER performance. This review synthesizes a comprehensive collection of publications from 2020 to 2024, exploring prominent multimodal fusion strategies, including early fusion, late fusion, deep fusion, and hybrid fusion methods, while also examining data representation, data translation, attention mechanisms, and graph-based fusion technologies. We assess the effectiveness of various fusion techniques across standard SER datasets, highlighting their performance in diverse tasks and addressing challenges related to data alignment, noise management, and computational demands. Furthermore, we highlight real-world applications of multimodal SER and provide critical research challenges that must be addressed for practical deployment, offering insights into optimal fusion strategies and guiding future developments in multimodal SER.},
  archive      = {J_EAAI},
  author       = {Nhut Minh Nguyen and Thanh Trung Nguyen and Phuong-Nam Tran and Chee Peng Lim and Nhat Truong Pham and Duc Ngoc Minh Dang},
  doi          = {10.1016/j.engappai.2025.112624},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112624},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodal fusion in speech emotion recognition: A comprehensive review of methods and technologies},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhanced information measures using q-rung orthopair fuzzy sets for improved criminal investigation techniques. <em>EAAI</em>, <em>163</em>, 112622. (<a href='https://doi.org/10.1016/j.engappai.2025.112622'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Criminal investigations frequently consist of handling inadequate and ambiguous data, which can hamper the accuracy of crime investigation and profiling. This study presents innovative methods, based on the q-Rung Orthopair Fuzzy Set, to boost crime linkage investigation. By developing novel separation, distance, and entropy measures derived from the q-Rung Orthopair Fuzzy Set, we offer an effective technique that advances data differentiation and improves the accuracy of distance assessments. These methods efficiently address uncertainty and ambiguity, providing a dependable outline for explaining difficult challenges in forensic examinations. Comprehensive comparative analysis, runtime analysis, and case studies endorse the applicability of q-Rung Orthopair Fuzzy Set approaches in tasks, predominantly those concerning ambiguous data. Furthermore, the incorporation of expert valuations advances the trustworthiness of outcomes, indicating the importance of interdisciplinary association in decision-making methods. This study highlights the potential of q-Rung Orthopair Fuzzy Set-based methods to significantly contribute to applied sciences, offering new insights into how they can be applied to real-world, data-driven problems like forensic investigations.},
  archive      = {J_EAAI},
  author       = {Abhilash Kangsha Banik and Palash Dutta and Dragan Pamucar and Vladimir Simic},
  doi          = {10.1016/j.engappai.2025.112622},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112622},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced information measures using q-rung orthopair fuzzy sets for improved criminal investigation techniques},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel road damage detection model with efficient attention and dynamic snake convolution. <em>EAAI</em>, <em>163</em>, 112618. (<a href='https://doi.org/10.1016/j.engappai.2025.112618'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Road damages detection is crucial for ensuring traffic safety, optimizing maintenance costs, and extending the service life of roads. However, it faces three key challenges: (1) damages and background often have similar pixel intensities, making them hard to distinguish; (2) damage types vary greatly in shape and size, increasing the difficulty of robust feature extraction; and (3) road interferences such as water stains, shadows, or markings can easily cause false detections. To address these problems, we propose B i-level Routing Attention, S nake Convolution, and W ise Intersection over Union enhanced Y ou O nly L ook O nce version 8 (BSW-YOLO), which integrates three targeted modules into the You Only Look Once version 8 (YOLOv8) framework. First, the Bi-level Routing Attention with DropKey (BRA-DropKey) highlights true damage features and suppresses background noise, solving the similarity in pixel intensities between damages and surroundings. Second, dynamic Snake Convolution (SnakeConv) captures geometric contours for fine-grained features, improving adaptability to diverse shapes and sizes. Third, Wise Intersection over Union (Wise-IoU) loss refines anchor box quality, reducing false detections from road interferences such as water stains and shadows. Experiments conducted on the Road Damage Dataset (RDD) 2022, a benchmark dataset for road damage detection, demonstrate that BSW-YOLO achieves a mean Average Precision at an intersection over union threshold of 0.5 (mAP@0.5) of 90.5%, significantly outperforming other baseline models and road damage detection methods.},
  archive      = {J_EAAI},
  author       = {Zhen Wang and Zhengyao Ma and Zhan Wang and Shunqi Gao and Jinjia Peng},
  doi          = {10.1016/j.engappai.2025.112618},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112618},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel road damage detection model with efficient attention and dynamic snake convolution},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A machine learning–Powered digital twin framework for adaptive management of urban air quality in chiang mai, northern thailand. <em>EAAI</em>, <em>163</em>, 112597. (<a href='https://doi.org/10.1016/j.engappai.2025.112597'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban air quality management in topographically and meteorologically complex regions such as Chiang Mai, Northern Thailand, is increasingly challenged by diverse emission sources and the limitations of conventional reactive response systems. This study introduces a multi-layer digital twin framework powered by artificial intelligence (AI), integrating real-time Internet of Things (IoT) sensing, deep learning–based spatiotemporal forecasting, and simulation-driven policy optimization to enable predictive and adaptive air quality control. Specifically, a Temporal–Spatial Graph Neural Network (TS-GNN) is employed to capture nonlinear dependencies across both spatial and temporal dimensions, achieving high predictive accuracy (root mean square error, RMSE = 2.8 μg/m 3 ; coefficient of determination, R 2 = 0.96). For adaptive intervention planning, a hybrid Generative Adversarial Network–Deep Reinforcement Learning (GAN–DRL) algorithm is implemented—resulting in a 57.1 % reduction in fine particulate matter (PM2.5) concentrations, and outperforming state-of-the-art metaheuristics such as the Coot Optimization Algorithm and Red Deer Optimization. These AI-driven policy interventions are assessed through coupled agent-based modeling (ABM) and computational fluid dynamics (CFD) simulations, enabling high-fidelity, multi-source policy testing under realistic urban dynamics. The proposed framework exhibits strong scalability across spatial units, rapid inference capability, and robustness under high-pollution scenarios. Economic analysis confirms its cost-efficiency and policy feasibility. Seasonal simulations further validate sustained environmental benefits across emissions from agricultural, industrial, and transportation sectors. Overall, this work establishes an AI-enhanced, real-time decision-support paradigm combining digital twin technologies, urban simulation, and adaptive environmental governance—contributing a transferable model for data-driven urban air quality management.},
  archive      = {J_EAAI},
  author       = {Natthapong Nanthasamroeng and Peerawat Luesak and Rapeepan Pitakaso and Surajet Khonjun and Ganokgarn Jirasirilerd and Surasak Matitopanum},
  doi          = {10.1016/j.engappai.2025.112597},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112597},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A machine learning–Powered digital twin framework for adaptive management of urban air quality in chiang mai, northern thailand},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A comprehensive survey of machine learning–based techniques for anomaly detection in ship behavior within maritime transportation systems. <em>EAAI</em>, <em>163</em>, 112596. (<a href='https://doi.org/10.1016/j.engappai.2025.112596'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Maritime transportation system (MTS) plays a vital role in facilitating global trade. However, it also has a wide variety of risks, such as illegal fishing, smuggling, and piracy. Traditional surveillance methods, such as satellite or radar imaging, exist but tend to have limited coverage at any one time and short duration of coverage. This is where data-driven approaches can be useful to provide alternative pathways to automatically detect ships, interpret their behavior, and identify anomalous activities across a vast geographical area. This paper presents a comprehensive survey of current trends in the field of ship behavior abnormality detection. Our focus is on features that indicate behaviors posing a potential threat, such as unusual changes in course or speed, suspicious stops in open water, or erratic changes in speed. The survey will assist researchers and practitioners in getting a feel for the direction of the field and will be well organized so readers have a clear and structured understanding. Additionally, this review focuses on four broad categories: statistical methods, clustering, machine learning, and neural networks. For each group, we explain its potential for improving maritime safety and efficiency, along with its limitations.},
  archive      = {J_EAAI},
  author       = {Najeh Abdeladhim and Bechir Alaya and Haifa Touati},
  doi          = {10.1016/j.engappai.2025.112596},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112596},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A comprehensive survey of machine learning–based techniques for anomaly detection in ship behavior within maritime transportation systems},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Differential evolution with dimensionally adaptive inheritance. <em>EAAI</em>, <em>163</em>, 112587. (<a href='https://doi.org/10.1016/j.engappai.2025.112587'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of differential evolution heavily depends on its mutation and crossover. Mutation perturbs a base vector to generate new genetic material while crossover controls the amount of inherited materials. However, dimensionally adaptive information inheritance, potentially enhancing performance, has not been well-studied in the classic differential evolution and its variants. To fill the gap, this paper proposes a dimensionally adaptive inheritance method to facilitate a flexible dimension-oriented evolution, which consists of the dimension-varying crossover and the crossover rate guided adaptation mechanisms. The dimension-varying crossover allocates different crossover rates for different dimensions, enabling adjustable dimension inheritance, and is significantly different from commonly adopted individual-level crossover rate. To further adapt the inheritance, the crossover rate guided adaptation adjusts exploitative and explorative inheritances by taking advantage of the natural structure of differential evolution and is simple and computationally efficient. Effectiveness of the proposed mechanisms is validated by comparative experiments with state-of-the-art parameter control methods, classic strategy adaptation methods and state-of-the-art multi-strategy utilization methods on benchmark functions as well as real-world problems. The rationale behind the performance improvement is also analyzed.},
  archive      = {J_EAAI},
  author       = {Sheng Xin Zhang and Yu Hong Liu and Xin Rou Hu and Jun Ting Luo and Li Ming Zheng and Shao Yong Zheng},
  doi          = {10.1016/j.engappai.2025.112587},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112587},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Differential evolution with dimensionally adaptive inheritance},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Spiking neural networks with uncertainty model of stochastic sampling for circuit yield enhancement. <em>EAAI</em>, <em>163</em>, 112523. (<a href='https://doi.org/10.1016/j.engappai.2025.112523'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In semiconductor manufacturing, yield analysis plays a critical role in optimizing production processes, but traditional methods, such as Monte Carlo simulations, often rely on idealized models and require extensive computational resources. These approaches struggle to account for the inherent uncertainties of real-world manufacturing, limiting their practical applicability. Spiking Neural Networks (SNNs), inspired by biological neural processes, offer a promising solution by efficiently handling large-scale data while maintaining low power consumption and real-time processing capabilities. This paper introduces an uncertainty-aware spiking learning model that reduces the impact of non-ideal simulation results by incorporating input uncertainties through stochastic sampling, where neuron firing states are influenced by both input noise and neuronal characteristics. To further improve yield, the model leverages reinforcement learning to optimize process parameters iteratively. Extensive experiments on two circuit yield simulation datasets demonstrate that the proposed method outperforms traditional approaches in handling uncertainties and provides more reliable and accurate yield predictions, offering a robust and efficient alternative for semiconductor process optimization.},
  archive      = {J_EAAI},
  author       = {Zenan Huang and Wenrun Xiao and Haojie Ruan and Shan He and Donghui Guo},
  doi          = {10.1016/j.engappai.2025.112523},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112523},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Spiking neural networks with uncertainty model of stochastic sampling for circuit yield enhancement},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Predictive typing for the persian language: A survey. <em>EAAI</em>, <em>163</em>, 112459. (<a href='https://doi.org/10.1016/j.engappai.2025.112459'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-resource languages, such as Persian, have difficulties in adopting the most recent predictive typing methods. This study serves a practical guidance for understanding and developing text prediction methods tailored for the Persian language. It presents predictive typing and its applications through a systematic survey of studies, encompassing approaches ranging from simple calculations to generative models, across three categories: statistical methods, neural networks, and deep learning models. Finally, it assesses these methods under consistent conditions. This paper is valuable for both academia and industry, as it addresses about 99% of the world's languages and low-resource data.},
  archive      = {J_EAAI},
  author       = {Boshra Nouraei and Jamshid Shanbehzadeh and Parvaneh Asghari},
  doi          = {10.1016/j.engappai.2025.112459},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {112459},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predictive typing for the persian language: A survey},
  volume       = {163},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
