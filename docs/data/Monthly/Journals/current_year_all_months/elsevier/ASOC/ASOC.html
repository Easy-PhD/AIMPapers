<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ASOC</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="asoc">ASOC - 82</h2>
<ul>
<li><details>
<summary>
(2026). Robust image watermarking for diverse channels with template-forming neural network. <em>ASOC</em>, <em>186</em>, 114125. (<a href='https://doi.org/10.1016/j.asoc.2025.114125'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Watermarking is a key tool in combating unauthorized content distribution, but its effectiveness is often challenged by the wide range of communication channels that can degrade or remove the watermark. We propose a block neural network-based watermarking scheme for digital images that is robust against diverse transmission channels, including compression, pre-processing, and digital-to-analog conversions such as screen photographing and print-scan processes. Instead of using a more conventional encoder-decoder, a neural network with two inputs and inter-layer connectivity is used for forming block templates that are later superimposed into a cover image, while a classification neural network is used for extraction. The method achieves reliable extraction, with an average bit error rate below 20 % even in challenging conditions. It also preserves visual quality (PSNR > 30 dB) and supports a payload of 2 bits per 32 × 32 block, enabling watermark lengths sufficient for unique identification within a single image frame.},
  archive      = {J_ASOC},
  author       = {Kristina Dzhanashia and Oleg Evsutin},
  doi          = {10.1016/j.asoc.2025.114125},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114125},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Robust image watermarking for diverse channels with template-forming neural network},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multiscale separable convolution network with lightweight spatiotemporal attention for remaining useful life prediction. <em>ASOC</em>, <em>186</em>, 114122. (<a href='https://doi.org/10.1016/j.asoc.2025.114122'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of remaining useful life (RUL) for critical equipment guides operational strategy formulation, making it a pivotal challenge in prognostics and health management (PHM). Existing temporal convolutional networks (TCNs) address limitations in spatial feature representation by integrating attention mechanisms or multiscale architecture. However, these integrations exhibit a critical limitation: prohibitive computational burden limiting the deployment in resource-constrained conditions. Here, we propose a multiscale separable convolution network with lightweight spatiotemporal attention (MSSN-LST) for RUL prediction of the aero engine. First, a multiscale 1D separable dilated causal convolutional network (MSSN) is developed to extract multiscale temporal degradation features. By introducing varying kernel sizes and dilation factors within 1D separable convolution, the MSSN captures multiscale degradation features while preserving temporal directionality. Besides, the introduction of dilation factor efficiently expands the receptive field, which helps to reduce the network depth of separable convolution. Subsequently, a lightweight spatiotemporal attention layer (LST) is constructed to enhance feature representation across both temporal and spatial dimensions. By utilizing non-parametric computational structure to enhance spatiotemporal feature representation, the LST maintains the minimal computational burden. This lightweight attention model enhances the ability of the model to be deployed on edge devices. Finally, a regression layer incorporating a separable convolution layer and a linear layer outputs the RUL prediction. Results on the C-MAPSS dataset demonstrate that the proposed model achieves superior prediction accuracy with light computational burden.},
  archive      = {J_ASOC},
  author       = {Ping Zhou and Fanfan Gan and Baizhan Xia},
  doi          = {10.1016/j.asoc.2025.114122},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114122},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multiscale separable convolution network with lightweight spatiotemporal attention for remaining useful life prediction},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Image splicing localization based on dual-stream spatial-noise learning and hierarchical frequency fusion. <em>ASOC</em>, <em>186</em>, 114121. (<a href='https://doi.org/10.1016/j.asoc.2025.114121'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In splicing localization, the original image’s semantics are changed by the insertion of objects, and the propagation of these spliced images may have adverse impacts. Researchers have proposed various convolutional neural network-based forgery detection techniques to address this problem. However, most dual-stream deep learning models use the same backbone to process different branches, which overlooks the differences between these branches. Additionally, during the decoding process, they often rely on simple upsampling or deconvolution techniques, which fail to effectively utilize context information. To address these issues, image splicing localization based on dual-stream spatial-noise learning and hierarchical frequency fusion is proposed in this work. This model combines HR-Net’s ability to capture high resolution texture details with ResNet-50’s deep noise modeling, allowing the two networks to complement each other effectively. Furthermore, a new module named the Multi-scale High Frequency Enhancement (MHFE) module is provided to enhance the detection of manipulated borders. The decoding phase incorporates the Multi-scale Progressive Attention Fusion (MPAF) module, which systematically exploits spatial-channel correlations within feature maps to optimize segmentation precision. This architectural configuration synergistically integrates HR-Net’s capacity for fine-grained spatial pattern modeling with ResNet’s hierarchical feature abstraction capabilities, thereby establishing a dual-stream network that generates comprehensive feature representations for forgery identification. The model outperforms single-modality or homogeneous dual-stream approaches in localization accuracy, interference resistance, and adaptability to different scenarios. Experiments on several public datasets demonstrate that this proposed method achieves significantly superior performance compared to current manipulated image localization techniques.},
  archive      = {J_ASOC},
  author       = {Zhentao Hu and Fuyi Liu and Shengjia Zhang and Yujie Su},
  doi          = {10.1016/j.asoc.2025.114121},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114121},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Image splicing localization based on dual-stream spatial-noise learning and hierarchical frequency fusion},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Attention augmented recurrent architectures for solar energy production forecasting. <em>ASOC</em>, <em>186</em>, 114119. (<a href='https://doi.org/10.1016/j.asoc.2025.114119'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The limited availability and non-sustainability of fossil fuels have led to the increasing interest in renewable energy alternatives. Significant obstacles must be addressed to fully integrate renewable energy into the existing power distribution grids. While reliability is a key factor in ensuring sustainable energy generation, solar power plants heavily depend on weather conditions which pose a challenge to maintain consistent and uninterrupted output without incurring substantial energy storage costs. As a result, accurate prediction of photovoltaic power production is crucial for efficient grid control and energy market operations. Traditional forecasting methods often struggle with nonlinear dependencies, while deep learning approaches are highly sensitive to hyperparameter tuning. This study proposes the application of metaheuristic optimization techniques to improve different lightweight recurrent neural network models and also considers attention mechanisms to forecast photovoltaic power generation. Additionally, an adapted metaheuristic optimizer is introduced to effectively overcome the obstacles of hyperparameter tuning. Extensive simulations are conducted using real-world dataset. The best-produced model in the simulations, which combines the gated recurrent unit with an attention mechanism, obtained a promising mean squared error score of 0.007713, indicating a significant perspective for further use in this area, with potential for deployment in resource-constrained environments like embedded and TinyML platforms.},
  archive      = {J_ASOC},
  author       = {Vladimir Markovic and Luka Jovanovic and Miodrag Zivkovic and Branislav Radomirovic and Angelina Njegus and Mahmoud Abdel-Salam and Vladimir Simic and Nebojsa Bacanin},
  doi          = {10.1016/j.asoc.2025.114119},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114119},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Attention augmented recurrent architectures for solar energy production forecasting},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Applying a particle swarm optimizer controlled by a fuzzy logic controller in a multi-pivot means clustering algorithm. <em>ASOC</em>, <em>186</em>, 114118. (<a href='https://doi.org/10.1016/j.asoc.2025.114118'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fuzzy c-means clustering algorithm (FCM) has been successfully applied in different fields. However, previous studies showed that data points near boundaries between different clusters are easily misclustered. It becomes crucial to improving the clustering results of the boundary data points. Considering that a single center in each cluster does not contain comprehensive distribution information of the cluster, we hybrid a m ulti- p ivots strategy with FCM, and propose a multi-pivots means algorithm (MPM). In MPM, we firstly utilize the basic FCM to perform the clustering. Then, a controversial area ( C A ) concept is introduced to describe the overlapping area between different clusters. Based on the C A , all data points can be divided into controversial points ( C P s ) and deterministic points ( D P s ), which are inside or outside of the C A , respectively. Moreover, a particle swarm optimization algorithm with adaptive learning weights by a multiple-input multiple-output fuzzy logic controller (MFCPSO) is used to optimize multiple pivots in each cluster. Lastly, based on the optimal multiple pivots, the C P s , which are easily misclustered, are reclustered, intending to improve their classification accuracy. The experimental results and comparisons between MPM and other 6 clustering algorithms on 10 popular datasets suggest that MPM exhibits auspicious performance on different datasets. Furthermore, the effectiveness and efficiency of the introduced strategies are also discussed based on a set of experiments.},
  archive      = {J_ASOC},
  author       = {Xuewen Xia and Minghan Li and Haojie Song and Xing Xu and Yinglong Zhang},
  doi          = {10.1016/j.asoc.2025.114118},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114118},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Applying a particle swarm optimizer controlled by a fuzzy logic controller in a multi-pivot means clustering algorithm},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A neighborhood-aware semi-supervised intuitionistic fuzzy clustering method with multi-level weighting. <em>ASOC</em>, <em>186</em>, 114117. (<a href='https://doi.org/10.1016/j.asoc.2025.114117'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy c-means clustering (IFCM) is a helpful approach for dealing with uncertain data. However, it still suffers from noise and center initialization, and difficulty discerning the relative impacts of samples, features, or clusters during clustering. On the other hand, semi-supervised learning improves clustering by using class-label information that is available only for some data samples. This integration creates semi-supervised clustering, a concept not extensively explored in intuitionistic fuzzy clustering. In light of the challenges mentioned for IFCM, this paper proposes a novel semi-supervised IFCM-based approach. A new semi-supervised intuitionistic fuzzy objective function is presented, which is composed of (1) sample weighting to reduce the effect of outliers, (2) a feature weighting to distinguish between the importance of different features, (3) cluster weighting to reduce the initialization sensitivity, (4) a neighborhood information term reflecting the extent of label homogeneity in the neighboring samples. Considering the above factors in designing the objective function leads to the formation of an optimal clustering structure, insensitivity to noise/outliers, and insensitivity to the initialization. Extensive experiments on various UCI benchmark datasets demonstrate that the proposed method outperforms competing methods by an average accuracy improvement of 11.22 % across all datasets. Furthermore, statistical tests confirm the significance of these improvements. The source code and detailed instructions for reproducing the experiments are available on GitHub at https://github.com/Amin-Golzari-Oskouei/NA-SSIFCM-MLW .},
  archive      = {J_ASOC},
  author       = {Amin Golzari Oskouei and Negin Samadi and Asgarali Bouyer and Bahman Arasteh},
  doi          = {10.1016/j.asoc.2025.114117},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114117},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A neighborhood-aware semi-supervised intuitionistic fuzzy clustering method with multi-level weighting},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-tasking evolutionary learning for constrained multi-modal multi-objective optimization. <em>ASOC</em>, <em>186</em>, 114116. (<a href='https://doi.org/10.1016/j.asoc.2025.114116'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constraint optimization and multimodal optimization have always been significant issues in industrial production. Currently, numerous constrained evolutionary algorithms have been proposed. However, research on multimodal constrained optimization problems is relatively scarce. Many real-world problems are inherently multimodal. To address these issues, this paper proposes a multi-stage constrained multi-objective and multimodal multi-objective evolutionary algorithm based on multitask evolutionary prediction, called M3TMO. To comprehensively explore the entire solution space, the algorithm does not control the exchange of information between tasks in the first stage. In the second stage, we designed an information transfer success rate prediction function, which assesses the effectiveness of the information to predict the degree of dependency between tasks, thus controlling the information exchange between tasks and effectively improving the algorithm’s diversity. The proposed M3TMO algorithm has been tested on multiple benchmark problems. Experimental results indicate that this algorithm is highly competitive in solving constrained multi-objective and multimodal multi-objective problems.},
  archive      = {J_ASOC},
  author       = {Lingyu Wu and Zenglin Qiao and Xinchao Zhao and Lingjuan Ye and Xingquan Zuo},
  doi          = {10.1016/j.asoc.2025.114116},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114116},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-tasking evolutionary learning for constrained multi-modal multi-objective optimization},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EAD-net: Multi-scale wavelet mamba network for early alzheimer’s disease diagnosis. <em>ASOC</em>, <em>186</em>, 114115. (<a href='https://doi.org/10.1016/j.asoc.2025.114115'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is the most prevalent neurodegenerative disorder among older adults. Early diagnosis, particularly the identification of Mild Cognitive Impairment (MCI), is crucial for effective AD management. Current research in AD diagnosis primarily relies on positron emission tomography (PET), which is not widely accessible and requires contrast media. Moreover, the misdiagnosis rate for MCI remains significantly high. Therefore, there is an urgent need to develop a rapid and accurate screening model for MCI based on conventional magnetic resonance imaging (MRI). To address these challenges, this study proposes an early diagnosis network (EAD-Net) for the detection of AD using T1-weighted MRI (T1WI). EAD-Net incorporates a multi-scale wavelet transform (MWT) module to perform image denoising and generate high- and low-frequency subbands that capture edge and detail information. Next, we propose a layer-alternating feature encoder that integrates Mamba and CNN. This design extracts and optimizes multi-level feature representations more effectively. Finally, we propose a class-independent multi-binary (CIR) classifier to enhance flexibility of EAD-Net and improve classification accuracy across different groups. Extensive experiments conducted on multicenter clinical and public datasets demonstrate that EAD-Net outperforms state-of-the-art (SOTA) methods, making it a valuable tool for the early detection of AD. The source code and pretrained weights of EAD-Net are available at https://github.com/zhoukunz/EAD-Net.git .},
  archive      = {J_ASOC},
  author       = {Kun Zhou and Xiao Liu and Siyu Liu and Hongyi Chen and Zhiji Zheng and Xiao Luo and Daoying Geng},
  doi          = {10.1016/j.asoc.2025.114115},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114115},
  shortjournal = {Appl. Soft. Comput.},
  title        = {EAD-net: Multi-scale wavelet mamba network for early alzheimer’s disease diagnosis},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Fuzzy natural neighbors for outlier detection. <em>ASOC</em>, <em>186</em>, 114114. (<a href='https://doi.org/10.1016/j.asoc.2025.114114'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural neighbors, inspired by human friendship, define a relationship in which two individuals consider each other mutual neighbors. Based on this concept, Zhu et al. (2016) introduced the Natural Neighbor Search Algorithm to automatically determine the optimal number of neighbors in the K-Nearest Neighbors (KNN) algorithms. Although this method has been applied in various data mining tasks, it faces limitations with datasets of varying density. Specifically, points in dense regions may be incorrectly flagged as outliers, while those in sparse regions may go undetected. In this paper, we extend the concept of Boolean natural neighbors into a fuzzy framework, offering a more nuanced understanding of neighborhood relations. This leads to the development of four novel outlier detection algorithms. One of these integrates the ideas of having “few friends” and being “far away” from other data points, providing a robust solution to the ambiguity inherent in outlier detection. Since both concepts (“few” and “far”) are fuzzy by nature, their aggregation using fuzzy operators is a natural choice, improving both the flexibility and the accuracy of detecting outliers. Benchmarking on 18 datasets demonstrates that our proposed methods outperform state-of-the-art techniques in terms of AUC and Precision.},
  archive      = {J_ASOC},
  author       = {Ramiro Saltos and Richard Weber and Witold Pedrycz},
  doi          = {10.1016/j.asoc.2025.114114},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114114},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Fuzzy natural neighbors for outlier detection},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A linguistic granular computing approach for failure mode and effect analysis. <em>ASOC</em>, <em>186</em>, 114113. (<a href='https://doi.org/10.1016/j.asoc.2025.114113'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failure mode and effects analysis (FMEA) is a type of proactive approaches to prioritize potential failures in a system or process. Existing FMEA approaches are typically categorized into numerical and linguistic ones. Compared with numerical FMEA approaches, linguistic ones allow participants to express their assessments using natural language terms rather than numerical values, thereby offering a more flexible and intuitive way of information representation, which makes them particularly well-suited for handling the complexity of real-world FMEA scenarios and the inherent ambiguity of human judgment. However, existing linguistic FMEA approaches struggle to effectively integrate diverse assessments from multiple participants and transform linguistic data into computationally operable formats. To address these limitations, this study proposes a granular computing approach for linguistic FMEA. Firstly, distributed linguistic preference relations are introduced into linguistic FMEA to enable representation of integrated assessments from multiple FMEA participants. Secondly, a bi-objective optimization model is developed to granulate linguistic terms into personalized intervals by simultaneously considering individual consistency and group consensus. Two case studies, namely FMEA of aeroengine turbine blades and of a supercritical water gasification system, were conducted to validate the proposed approach. Compared with three representative FMEA approaches, the results obtained by the proposed approach improve the individual consistency and group consensus by more than 16.3 % and 3.4 %, respectively.},
  archive      = {J_ASOC},
  author       = {Zhengyang Cai and Ting Huang and Qiang Zhang and Shanlin Yang},
  doi          = {10.1016/j.asoc.2025.114113},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114113},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A linguistic granular computing approach for failure mode and effect analysis},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic dominance-based three-way decision approach in incomplete hybrid ordered data under variation of attribute values. <em>ASOC</em>, <em>186</em>, 114112. (<a href='https://doi.org/10.1016/j.asoc.2025.114112'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the digital and network era, data frequently exhibits the characteristics of high-level dynamism, significant incompleteness, complex heterogeneity and partial ordering, which undoubtedly bring huge challenges to efficient knowledge discovery. Three-Way Decisions (TWD), as an emerging triarchic theory in granular computing, have found extensive applications across diverse fields by adopting an idea of trisecting-acting to tackle complex and indeterminate matters. Although a multitude of extended three-way decision models have been developed to deal with dynamic incomplete or ordered data, research on knowledge mining of dynamic incomplete hybrid ordered data is still relatively lacking. To fill this gap, this paper focuses on constructing a novel dominance-based three-way decision framework for dynamic incomplete hybrid ordered data. Firstly, a generalized dominance relation for handling incomplete hybrid ordered data is defined by combining a preference measure with data-driven idea, and a new dominance-based three-way decision model is proposed according to the justifiable granularity principle. Then, an effective matrix method is formulated to characterize dominance-based three-way decision model by combining with matrix expressions for both conditional probability and aggregated loss functions. In addition, an efficient matrix-based incremental mechanism is proposed for maintaining three-way regions when updating missing attribute values. Based on this, the relevant incremental algorithm is developed for maintenance of three-way regions. Comparative experiments across multiple data sets are performed to assess computational efficiency with regard to the proposed approach.},
  archive      = {J_ASOC},
  author       = {Qianqian Huang and Jiayin Tang and Yanyong Huang and Mengtian Cui},
  doi          = {10.1016/j.asoc.2025.114112},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114112},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic dominance-based three-way decision approach in incomplete hybrid ordered data under variation of attribute values},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing environmental modeling and maximum diffusion reinforcement learning using evolutionary computation for optimal performance. <em>ASOC</em>, <em>186</em>, 114111. (<a href='https://doi.org/10.1016/j.asoc.2025.114111'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal correlation in reinforcement learning often limits the performance of its algorithms. Maximum diffusion reinforcement learning (MaxDiff RL) mitigates this issue by optimizing action sequences through entropy maximization of the agent’s trajectory. However, as a model-based method, the accuracy of the environment model is critical to the overall performance of MaxDiff RL. We propose a novel method that incorporates evolutionary algorithms into the MaxDiff RL framework. This is achieved by periodically generating a population of environment models through the application of perturbations with varying magnitudes, which facilitates the search for more accurate models. The best-performing model is selected and used to update the original environment model. The proposed method was evaluated on three robotic continuous control tasks and compared with three baseline algorithms. The results demonstrate that the proposed method outperforms the baseline algorithms in terms of overall performance and sample efficiency.},
  archive      = {J_ASOC},
  author       = {Ying Zhao and Yan Pei},
  doi          = {10.1016/j.asoc.2025.114111},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114111},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enhancing environmental modeling and maximum diffusion reinforcement learning using evolutionary computation for optimal performance},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Metaheuristic-driven feature selection with dual feedback mechanisms for imbalanced cancer classification. <em>ASOC</em>, <em>186</em>, 114110. (<a href='https://doi.org/10.1016/j.asoc.2025.114110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inherent complexity of high-dimensional, imbalanced microarray cancer data presents two major challenges: redundant features that obscure biomarkers, and skewed distributions that impair model generalizability. To address these issues, this study proposes DVFF (Double Value Feedback Framework), a novel bacterial heuristic-based feature selection method designed to simultaneously reduce dimensionality and mitigate class imbalance through three key innovations. First, it employs a borderline-sensitive fitness function that dynamically adjusts class boundaries using local density information, prioritizing discriminative features near class margins to reduce information loss. Second, a dual-phase feedback mechanism integrates progressive feature pruning via threshold learning with real-time population diversity monitoring, enabling efficient exploration of feature subspaces while preserving representative subsets. Third, a probabilistic multi-division iteration strategy facilitates concurrent exploration of diverse feature subsets using subpopulations with adaptive thresholds and varying lengths, significantly improving search coverage. Extensive experiments on 14 microarray datasets (ranging from 2000 to 10,000 features with imbalance ratios between 1.4 and 20) show that DVFF outperforms six state-of-the-art methods, achieving over 15 % improvement in macro-F1, faster convergence, and feature subsets smaller than 10 % of the original size. Statistical tests confirm significantly enhanced class separation in the reduced feature space, demonstrating DVFF’s effectiveness in addressing both high dimensionality and class imbalance in microarray cancer data.},
  archive      = {J_ASOC},
  author       = {Chen Yang and Jie Peng and Tongtong Xing and Hong Wang and Ben Niu},
  doi          = {10.1016/j.asoc.2025.114110},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114110},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Metaheuristic-driven feature selection with dual feedback mechanisms for imbalanced cancer classification},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A multi-path time-series generation and prediction model for financial markets using discriminator-filtered monte carlo TimeGAN. <em>ASOC</em>, <em>186</em>, 114106. (<a href='https://doi.org/10.1016/j.asoc.2025.114106'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces the Discriminator-Filtered Monte Carlo TimeGAN (DFMC-TimeGAN), a novel model that combines Monte Carlo simulation with the discriminator of Time-series Generative Adversarial Networks (TimeGAN) to generate and filter multiple realistic time-series paths. The hypothesis is that leveraging GAN-based discrimination can improve the plausibility and predictive utility of Monte Carlo-generated scenarios. Unlike traditional models limited to single-path predictions, DFMC-TimeGAN generates diverse time-series paths, capturing the complexity and uncertainty inherent in financial markets. The methodology integrates a Conditional Monte Carlo Generator with the TimeGAN discriminator, using Binary Cross-Entropy (BCE) loss to select the most realistic paths, which are then applied to scenario-based asset allocation and investment strategy optimization. Using real-world data from representative assets including the S&P 500, Tesla, US Dollar Index, US 10-year Treasury Yield, copper, and crude oil, our empirical analysis shows that DFMC-TimeGAN achieves high predictive accuracy and outperforms both market benchmarks and an LSTM baseline, achieving an average reduction of 2.55 % in RMSE and 4.81 % in MAPE. Notably, the model demonstrates strong performance in short- and mid-term forecasts while preserving asset correlations and reflecting historical dynamics, offering an innovative and empirically validated approach to improving risk management and decision-making in dynamic financial environments.},
  archive      = {J_ASOC},
  author       = {Ho Sun Ryou and Sang Hoe Kim and Hee Soo Lee and Kyong Joo Oh},
  doi          = {10.1016/j.asoc.2025.114106},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114106},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-path time-series generation and prediction model for financial markets using discriminator-filtered monte carlo TimeGAN},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A fuzzy logistic-based ensemble framework with heterogeneous weighting effects for credit risk evaluation. <em>ASOC</em>, <em>186</em>, 114105. (<a href='https://doi.org/10.1016/j.asoc.2025.114105'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subjectivity, uncertainty and fuzzy relationships between variables contribute to fuzziness in credit data. Interpretability and class imbalance are also important considerations when developing efficient credit scoring models. Fuzzy logistic regression utilizes fuzzy logic to handle data fuzziness while retaining strong interpretability by inheriting the transparent coefficient structure of classical logistic regression. This paper introduces an ensemble framework based on fuzzy logistic regression and fuzzy heterogeneous weighting effects, referred to as the Fuzzy logistic-FWE model. First, a sample balancing algorithm generates training subsets with varying imbalance ratios, and fuzzy logistic classifiers are trained on each subset. Next, based on the performance of each sub-model during the validation phase, the final predictions are calculated using a novel fuzzy heterogeneous weighting method. Empirical results show that the Fuzzy logistic-FWE model outperforms ten benchmark models across five public datasets with varying characteristics in terms of Sensitivity , Specificity , AUC , F1-score and MCC . Further tests show that the proposed model’s superiority in identifying default samples is statistically significant. Finally, the interpretability of the model is quantitatively evaluated using the SHapley Additive exPlanations(SHAP). The findings show that the model is more practically applicable since it correctly identifies the main factors affecting credit scoring and explains how they affect the final predictions.},
  archive      = {J_ASOC},
  author       = {Jianan Xu and Yuntao Mao and Lichun Wang},
  doi          = {10.1016/j.asoc.2025.114105},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114105},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A fuzzy logistic-based ensemble framework with heterogeneous weighting effects for credit risk evaluation},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FuBAKE: Bayesian gamified fuzzy ant colony optimization for semantic-driven unsupervised keyphrase extraction. <em>ASOC</em>, <em>186</em>, 114104. (<a href='https://doi.org/10.1016/j.asoc.2025.114104'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keyphrase extraction is essential for information retrieval and knowledge systems, enabling effective document indexing and summarization. Existing methods, such as statistical, graph-based, and machine-learning approaches, suffer from limitations in scalability and domain generalization, as well as reliance on labeled data. In this study, we propose Fuzzy Bayesian Ant Optimization for Keyphrase Extraction (FuBAKE), a novel unsupervised framework that enhances Ant Colony Optimization with fuzzification and gamification through Bayesian game theory. Our approach constructs a semantic co-occurrence graph, where keyphrase candidates are initialized using BERT embeddings to capture deep contextual relationships. Ants explore paths strategically using a Bayesian game framework, dynamically updating pheromone intensity, desirability, and Bayesian belief to optimize selection. The Roulette Wheel Selection mechanism enhances adaptive learning, guiding exploration toward highly relevant keyphrases while maintaining diversity. We evaluate FuBAKE on Inspec, SemEval2017 Task 10, and DUC2001, comparing it against traditional ACO and state-of-the-art keyphrase extraction models. Our results show a total F1-score improvement of 109.7 % over state-of-the-art baselines, computed by averaging FuBAKE and baseline performances across all N values and datasets with similarity threshold of 0.9. A two-tailed Z-test confirms the statistical significance of our findings, and trend analysis on similarity thresholds highlights the robustness of our approach across varying datasets. By integrating semantic learning, probabilistic decision-making, and adaptive exploration, FuBAKE advances scalable, domain-agnostic keyphrase extraction.},
  archive      = {J_ASOC},
  author       = {Reetika Singh and Goonjan Jain},
  doi          = {10.1016/j.asoc.2025.114104},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114104},
  shortjournal = {Appl. Soft. Comput.},
  title        = {FuBAKE: Bayesian gamified fuzzy ant colony optimization for semantic-driven unsupervised keyphrase extraction},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Overview of the multi-dimensional taylor network algorithm in control, prediction, data fitting and diagnosis. <em>ASOC</em>, <em>186</em>, 114103. (<a href='https://doi.org/10.1016/j.asoc.2025.114103'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper conducts a systematic review of the applications of Multi-dimensional Taylor Network (MTN) in multiple fields such as control, prediction, data fitting and diagnosis. As an emerging nonlinear system modeling method, MTN integrates the advantages of classical control, modern control and intelligent control, and features a simple structure, high computational efficiency and strong nonlinear approximation ability. This paper first introduces the basic principles and typical structures of MTN, and then sorts out its development context and classification system. Furthermore, it elaborates in detail on the wide application of MTN in practical scenarios such as motor position control, unmanned aerial vehicle flight, permanent magnet synchronous motor speed regulation, lithium battery state estimation, HVAC system fault diagnosis, and air quality monitoring, demonstrating its significant advantages in enhancing system accuracy, robustness, and real-time performance. In terms of prediction and fitting, MTN also demonstrates superior performance compared to traditional neural networks in nonlinear time series prediction and high-dimensional data fitting. Based on over 90 relevant literatures from 2013 to 2025, this paper systematically summarizes the research progress of MTN in different fields. It is pointed out that MTN still faces challenges in terms of scalability, parameter optimization, uncertainty handling, and integration with other artificial intelligence methods. Finally, this paper looks forward to the future development trend of MTN, providing theoretical references and application directions for further research in this field.},
  archive      = {J_ASOC},
  author       = {Jun Cai and Zhiyong Zhang and Ying Yan and Edmond Qi Wu},
  doi          = {10.1016/j.asoc.2025.114103},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114103},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Overview of the multi-dimensional taylor network algorithm in control, prediction, data fitting and diagnosis},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Natural sea-based materials SBM-ECCs: Experimental, analytical, and machine learning approaches to early-age behavior and modulating factors. <em>ASOC</em>, <em>186</em>, 114101. (<a href='https://doi.org/10.1016/j.asoc.2025.114101'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the early-age behavior of Engineered Cementitious Composites (ECCs) incorporating natural, unprocessed sea-based materials (SBMs) such as seawater and sea sand is essential for advancing sustainable construction in marine environments. This study systematically examines the ionic load introduced through seawater and sea sand on flowability, shrinkage, and mortar chloride content, and further explores the role of fiber type (PE, PVA) and dosage in mitigating shrinkage under varying ionic concentrations. Using raw materials sourced from Dapeng Bay, South China Sea, experimental results show that seawater incorporation increases chloride ion concentrations, reduces flowability, and intensifies autogenous and total shrinkage, while rinsing sea sand partially mitigates these effects. Fiber reinforcement was found to be crucial: PE fibers were more effective in high-salt conditions, whereas the hydrophilic nature of PVA fibers delayed evaporation and reduced shrinkage potential in low-salt environments. To complement these findings, a novel artificial intelligence-enabled shrinkage model based on the Gompertz distribution was developed to decompose shrinkage into shrinkage potential, peak shrinkage time, and maximum shrinkage rate, while a machine learning framework revealed seawater replacement as the dominant driver (>90 %) of shrinkage behavior. Additionally, in low-salt scenarios, increasing the fiber content further decreased the shrinkage potential in the model, highlighting the importance of fiber type and dosage in modulating SBM-ECCs behavior under varying ionic concentrations. By integrating experimental data with soft computing and multi-scale material testing, this research advances predictive understanding of SBM-ECCs and provides a foundation based on soft computing techniques for designing sustainable, durable, and environmentally resilient marine infrastructures.},
  archive      = {J_ASOC},
  author       = {Avik Kumar Das},
  doi          = {10.1016/j.asoc.2025.114101},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114101},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Natural sea-based materials SBM-ECCs: Experimental, analytical, and machine learning approaches to early-age behavior and modulating factors},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Drift-plus-penalty guided graph reinforcement learning for stable content caching in fog-cloud continuum. <em>ASOC</em>, <em>186</em>, 114099. (<a href='https://doi.org/10.1016/j.asoc.2025.114099'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exponential growth in the usage of smart and IoT computing devices has increased the waiting span of delay-tolerant applications at the cloud end due to increased user request processing and resource provisioning requirements. To manage this issue and meet the continuous content demands, there is a need for efficient and stable caching strategies in fog-edge computing environments. The fog-edge environment provides a computational layer between end devices and centralized cloud services that aims to improve data processing and content delivery at the edge of network. However, the varying demand for content and the dynamic nature of network conditions lead to content caching problem. This article introduces a novel approach, leveraging Graph Reinforcement Learning (GRL) guided by a Drift-Plus-Penalty (DPP) mechanism, to address the challenge of content caching in fog environments. In this context, the Fog-Edge-Cloud architecture is considered as a graph, featuring with fog community layout. Within this framework, content popularity prediction is facilitated by an adaptive Quantized Federated Learning approach to estimate the accurate popularity. The GRL framework is utilized to learn and make decisions about caching demands by analyzing the overall structure of these graphs and the patterns of interaction among nodes. Simultaneously, the DPP strategy directs the learning process towards a trade-off between optimizing immediate rewards and sustaining future system states by effectively mitigating the impact of temporal fluctuations in content demand and network conditions. The performance of proposed DPGRL approach is evaluated against other conventional caching techniques and the most recent advancements in caching prevalent in fog-edge continuum. The outcomes of this research demonstrate substantial enhancements in cache hit ratio of up to 26 % and latency reduction of up to 21.24 %, all while maintaining the stability of content caching decisions under dynamic scenarios.},
  archive      = {J_ASOC},
  author       = {Nilesh Kumar Verma and K.Jairam Naik},
  doi          = {10.1016/j.asoc.2025.114099},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114099},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Drift-plus-penalty guided graph reinforcement learning for stable content caching in fog-cloud continuum},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Driver fatigue detection using EEG-based graph attention convolutional neural networks: An end-to-end learning approach with mutual information-driven connectivity. <em>ASOC</em>, <em>186</em>, 114097. (<a href='https://doi.org/10.1016/j.asoc.2025.114097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to driver-specific and vehicle-specific characteristics, physiological signal features exhibit superior efficacy in detecting driver fatigue, particularly electroencephalogram (EEG) signals, which are less influenced by subjective human factors and directly reflect brain neural activity. Currently, many detection methods primarily focus on the analysis of EEG signals but fail to consider the interdependencies between signal acquisition channels. To improve the accuracy of driver state detection, a Graph Attention Convolutional Neural Network (GAT-CNN) is proposed in this study. The method incorporates channel relationships and performs an end-to-end learning process, which eliminates the need for manual feature extraction. The preprocessed EEG signals and the adjacency matrix based on mutual information serving as the input to the GAT-CNN. Finally, the EEG signals are classified into two states namely alert and fatigued by fully connected layers and a softmax classification layer. The performance of the method is validated on the SEED-VIG dataset with an average accuracy of 90.14 %, a peak accuracy of 99.23 % and an average F1 score of 91.54 %. Additionally, the Brier Score, used as an evaluation metric, yields an average value of 0.0841, which indicates high predictive accuracy and strong generalization ability. Compared to existing state-of-the-art methods, the GAT-CNN demonstrates superior performance.},
  archive      = {J_ASOC},
  author       = {Jichi Chen and Yuguo Cui and Chunfeng Wei and Kemal Polat and Fayadh Alenezi},
  doi          = {10.1016/j.asoc.2025.114097},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114097},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Driver fatigue detection using EEG-based graph attention convolutional neural networks: An end-to-end learning approach with mutual information-driven connectivity},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Chaotic dual-feature graph convolutional network (CDF-GCN) for traffic speed forecasting. <em>ASOC</em>, <em>186</em>, 114096. (<a href='https://doi.org/10.1016/j.asoc.2025.114096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic speed forecasting uses graph data to simulate real-time traffic’s chaotic and nonlinear nature conditions in smart cities are crucial tasks in Intelligent Transportation System (ITS). But there are two challenges: 1) current research on single direction features to capture correlations across all nodes hinder to extract bidirectional interactions of global feature dependencies 2) spatial and temporal data are handled with two distinct modules for each feature neglect their inherent dynamic relationships with anomaly i.e. traffic accidents. This paper proposes an innovative Chaotic Dual-Feature Graph Convolution Network (CDF-GCN) model which integrates self-features to enhance temporal periodic patterns characteristics, and neighbor-features with chaotic spatial features for accurate traffic speed forecasting. It is motivated by the backpropagation mechanism and Lee oscillator with retrograde signaling (LORS) for chaos state control and retrograde signal tracking, to oscillate the weight projection in bidirectional states for adjacency matrix and time-series feature matrix updates, and to simplify the flow of bidirectional information through simulated nonlinear diffusion relationships. Experimental results show that CDF-GCN outperforms other GNN baselines and state-of-the-art models on six real-world traffic datasets for speed detection and route planning, notably up to 80 % improvement over traditional GCN evaluated by MAE, RMSE and MAPE.},
  archive      = {J_ASOC},
  author       = {Nuobei Shi and Haoyuan Chen and Ling Chen and Raymond S.T. Lee},
  doi          = {10.1016/j.asoc.2025.114096},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114096},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Chaotic dual-feature graph convolutional network (CDF-GCN) for traffic speed forecasting},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Disentangling multi-factor effects via graph contrastive learning for travel recommendation. <em>ASOC</em>, <em>186</em>, 114095. (<a href='https://doi.org/10.1016/j.asoc.2025.114095'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Travel recommendation aims to efficiently match personalized products or services to users’ needs, playing a vital role in enhancing tourists’ experiences. Previous studies have shown that the selection of a suitable travel product is influenced by several factors, such as departure, destination, and price. However, due to the lack of clearly annotated labels identifying the predominant influencing factors in the travel recommendation process, prior approaches often conflate these factors. This entanglement can lead to suboptimal recommendation performance. To the best of our knowledge, this work presents the first disentangled framework specifically designed for travel recommendation, called DisenTravel (short for Disen tangled Graph Contrastive Learning for Travel Recommendation), which learns the relationships among destination, departure and price using three heterogeneous graphs. Through a self-supervised framework, DisenTravel disentangles these factors by independently modeling user preferences for each one. Specifically, it constructs separate graphs for departure, destination, and price, utilizing node-level and metapath-level attention networks to capture preferences. From these graphs, proxy representations are derived to serve as pseudo-indicators of user preferences. Pairwise contrastive learning is then employed to align the learned preference representations with their corresponding proxies. Extensive experiments demonstrate that DisenTravel consistently outperforms strong baselines across multiple evaluation metrics, validating its effectiveness. Furthermore, to offer interpretability into its recommendation behavior, a case study based on three randomly selected examples is provided.},
  archive      = {J_ASOC},
  author       = {Lei Chen and Weichao Liang},
  doi          = {10.1016/j.asoc.2025.114095},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114095},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Disentangling multi-factor effects via graph contrastive learning for travel recommendation},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Large language model augmented joint learning framework for entity-relation extraction. <em>ASOC</em>, <em>186</em>, 114094. (<a href='https://doi.org/10.1016/j.asoc.2025.114094'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity-relation extraction aims to analyze the unstructured text content to identify subject-relation-object triplets. It is significant for various natural language processing (NLP) applications, including constructing knowledge graphs, designing question-answering systems, and developing text summarizations. Researchers have developed joint learning approaches for entity-relation extraction, effectively addressing challenges related to entity-relation overlap. However, as the number of relation categories increases, the aforementioned methods face difficulties associated with redundant computations, which hinder the efficiency of the extraction process. While existing large language models (LLMs) exhibit impressive NLP performance, they face challenges in extracting all potential triplets without specialized adjustments. We propose a novel LLM augmented joint learning framework, named Reamend , for entity-relation extraction. By leveraging the LLM, it is capable of simultaneously recognizing potential entities and the corresponding relations from the text content. Additionally, the entity-relation amendment is introduced to eliminate redundant triplets, enhancing the overall effectiveness. Moreover, the proposed framework incorporates adversarial training to enhance robustness and generalization. This research represents a progressive effort to integrate a joint learning framework with adversarial training grounded in the LLM for entity–relation extraction. Experimental results on benchmark datasets demonstrate the superior performance of the proposed framework compared to state-of-the-art baseline methods.},
  archive      = {J_ASOC},
  author       = {Haochen Zou and Yongli Wang and Anqi Huang},
  doi          = {10.1016/j.asoc.2025.114094},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114094},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Large language model augmented joint learning framework for entity-relation extraction},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Audiovisual-cognition-inspired network with explainability for oil price forecasting. <em>ASOC</em>, <em>186</em>, 114093. (<a href='https://doi.org/10.1016/j.asoc.2025.114093'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of the oil price is crucial for stabilizing the energy economy and improving investment and government decision-making. However, due to the complex nonlinear fluctuations in oil price series, this task is extremely challenging. Furthermore, most deep forecasting networks struggle to handle the impact of emergencies on oil prices and lack model explainability, which reduces their credibility and applicability. Inspired by biomimetic principles, this paper develops an audiovisual-cognition-inspired network (AC-Net) for oil price forecasting during the COVID-19 pandemic and the Russia-Ukraine conflict. Specifically, the audiovisual cognition offers the useful framework to design AC-Net with audiovisual extraction, brain analysis, and forecasting components, further enhancing the model structure rationality. Imitating the process by which light and sound stimulus are transmitted into electricity signals by neurons, the audiovisual extraction employs multi-kernel convolution operations and parallel gated mechanisms to extract features at different scales and identify key features, aiding in the detection of nonlinear changes. Simulating the independent processing of electrical signals by the left and right hemispheres, the brain analysis utilizes two structures activated by self-attention and gated mechanisms to capture time dependencies, increasing the feature completeness. Simulating the process of transmitting processed information to the higher cerebral cortices for environmental comprehension, the forecasting component compares three fusion strategies with attention, gated, and concatenate, and the best one generates forecasts. Moreover, the kernel loss function reveals nonlinear errors in a higher-dimensional space and trains the proposed network, and two post-hoc explainability technologies analyses model global and local explainability. Overall, the combination of the above components not only ensures that the proposed method can effectively address emergency oil price shocks but also increases safety and trustworthiness. Finally, the experiments and discussions present that the proposed method significantly outperforms benchmark models, achieving mean absolute percent error values of 2.8768%, 1.1796%, and 2.0625% on datasets from the COVID-19 shock period, the COVID-19 stabilization period, and the Russia-Ukraine conflict period, respectively, showcasing high-performance oil price forecasting.},
  archive      = {J_ASOC},
  author       = {Han Wu and Xiao-Zhi Gao and Zhong Li and Jia-Ni Heng and Pei Du},
  doi          = {10.1016/j.asoc.2025.114093},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114093},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Audiovisual-cognition-inspired network with explainability for oil price forecasting},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficient and rapid attribute reduction based on local T-spherical fuzzy granular ball neighborhood rough sets. <em>ASOC</em>, <em>186</em>, 114091. (<a href='https://doi.org/10.1016/j.asoc.2025.114091'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the age of big data, the diverse range of data types presents significant challenges for effective processing and decision-making. While current granular ball neighborhood rough set (GBNRS) methods can generate neighborhood radii to approximate target concepts, their performance is suboptimal in complex, uncertain, and high-dimensional datasets. This paper presents an attribute reduction method applicable to various data types within a unified framework, specifically for T-spherical fuzzy sets. We propose a T-spherical fuzzy granular ball neighborhood rough set (T-SFGBNRS) model based on k -means + + and develop a rapid generation algorithm for T-spherical fuzzy granular balls (T-SFGBs) to improve computational efficiency. This model also integrates local neighborhood rough sets (LNRS), resulting in the local T-spherical fuzzy granular ball neighborhood rough set (LT-SFGBNRS). To tackle the randomness in generating T-SFGBs, we created two new attribute reduction algorithms: one based on dependency degree and another based on conditional entropy. Our method significantly improves attribute reduction processing accuracy and computational efficiency for 19 public datasets compared to existing approaches, demonstrating exceptional robustness and parameter sensitivity for complex datasets.},
  archive      = {J_ASOC},
  author       = {Shihai Deng and Tingting Zheng and Longxiang Lai},
  doi          = {10.1016/j.asoc.2025.114091},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114091},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Efficient and rapid attribute reduction based on local T-spherical fuzzy granular ball neighborhood rough sets},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic pricing and energy management for shore side electricity in a port microgrid: A deep reinforcement learning approach. <em>ASOC</em>, <em>186</em>, 114089. (<a href='https://doi.org/10.1016/j.asoc.2025.114089'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the economic challenges associated with operating shore side electricity (SSE) in ports, a critical measure for reducing greenhouse gas emissions in the maritime industry. Although SSE offers significant environmental benefits, its widespread adoption is hindered by operational costs and the volatility of electricity prices. To ensure the sustainable operation of SSE, we propose a dynamic pricing and energy management strategy integrated within a port microgrid to maximize operational profit. We leverage an actor-critic reinforcement learning approach and propose a reward shaping technique based on a myopic algorithm to enhance performance and stability. Through several experiments, we show that the proposed algorithm improves the port’s profit by approximately 4.4 % compared to the rule-based heuristic algorithm, while also exhibiting greater stability and robustness in the learning process. We also demonstrate that integrating SSE with port microgrids can increase SSE utilization and benefit the entire system.},
  archive      = {J_ASOC},
  author       = {Chungkwon Oh and Ilkyeong Moon},
  doi          = {10.1016/j.asoc.2025.114089},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114089},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic pricing and energy management for shore side electricity in a port microgrid: A deep reinforcement learning approach},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing risk management efficiency for building information modelling application via basic uncertain linguistic large-scale group decision making. <em>ASOC</em>, <em>186</em>, 114086. (<a href='https://doi.org/10.1016/j.asoc.2025.114086'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current research on building information modeling (BIM) has offered preliminary insights into the risks that arise in construction projects. Nevertheless, existing work is mainly qualitative and lacks a systematic, adaptable evaluation framework; this is especially true in the operation and maintenance (O&M) phase, where uncertainty and behavioral complexity are more pronounced. To address this shortfall, we develop a behavior-aware large-scale group decision making (LSGDM) framework that focuses on BIM application risks during O&M. The framework captures both linguistic uncertainty and evaluator behavioral features and consists of two main components: risk identification and risk evaluation. For linguistic uncertainty, we propose a preference relation information with self-confidence (PRI-SC) representation that overcomes the limitation of traditional fuzzy linguistic models by coupling preference information with confidence levels. This allows evaluators to express their certainty flexibly with either precise numbers or linguistic terms, thereby improving the realism and accuracy of information capture. To address behavioral bias, which conventional LSGDM handles poorly, we introduce an over-confidence detection mechanism grounded in the coefficient of variation that dynamically detects and corrects biases during consensus formation, thereby enhancing convergence efficiency. Finally, the framework is validated through an empirical case study of the Mandarin Oriental Hotel in Suzhou. The results demonstrate that the proposed method more effectively pinpoints key BIM application risks and provides a novel quantitative tool for BIM risk management.},
  archive      = {J_ASOC},
  author       = {Han Wang and Zhen-Song Chen and Yaya Liu and Luis Martínez and Zengqiang Wang},
  doi          = {10.1016/j.asoc.2025.114086},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114086},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enhancing risk management efficiency for building information modelling application via basic uncertain linguistic large-scale group decision making},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A problem transformation method based on elite-inspired evolutionary algorithm for large-scale multi-objective optimization. <em>ASOC</em>, <em>186</em>, 114085. (<a href='https://doi.org/10.1016/j.asoc.2025.114085'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale multi-objective optimization problems (LSMOPs) pose significant challenges in evolutionary computation, primarily due to the exponential increase in search space with the rise in decision variables. This rapid growth makes it difficult for existing algorithms to effectively explore the entire search space within limited computational resources. To address this issue, we propose a problem transformation method based on the elite-inspired evolutionary algorithm (EIEAPT). Specifically, EIEAPT employs the elite-inspired evolutionary algorithm (EIEA) to update reference solutions within the problem transformation process. This transformation accelerates convergence, and we apply an opposition-based learning (OBL) strategy during the initialization and population information exchange stages of EIEAPT, while also improving the individual learning mechanism within EIEA to enhance the algorithm’s exploration capabilities. Additionally, during the environmental selection phase, EIEAPT combines the transformed and original populations to balance convergence and diversity, enabling a more comprehensive search of high-dimensional spaces. Experimental results indicate that EIEAPT achieves competitive performance across various large-scale optimization benchmarks, including the LSMOP and DTLZ test suites, and demonstrates effectiveness even in ultra-high-dimensional scenarios with up to 5000 decision variables. These findings highlight the potential of EIEAPT for complex optimization problems.},
  archive      = {J_ASOC},
  author       = {Du Cheng and Zhiguo Xu and Fanhua Yu and Qingliang Li and Ning Zhou},
  doi          = {10.1016/j.asoc.2025.114085},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114085},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A problem transformation method based on elite-inspired evolutionary algorithm for large-scale multi-objective optimization},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-period scheduling and fleet management in agricultural production logistics: A novel reinforcement learning approach. <em>ASOC</em>, <em>186</em>, 114084. (<a href='https://doi.org/10.1016/j.asoc.2025.114084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient scheduling and fleet management are essential for optimizing agricultural production logistics, particularly in sugarcane bale operations, which involve complex, large-scale activities. However, most existing studies rely on static or single-period models that assume homogeneous fleets and fixed schedules, while overlooking essential factors such as machine breakdowns, setup times, and time-varying resource availability. These traditional deterministic or heuristic approaches often lack the adaptability needed to handle real-time disturbances and dynamic operating conditions. To address these challenges, this study introduces a novel optimization framework that integrates Reinforcement Learning (RL) with the Artificial Multiple Intelligence System (AMIS). The proposed approach is specifically designed to handle multi-period scheduling and heterogeneous fleet management, offering a robust and scalable solution for complex agricultural logistics systems. What distinguishes this framework is its hybrid mechanism: AMIS is used to generate diverse initial solutions, while mathematically derived improvement equations—drawn from various metaheuristics—are applied to refine those solutions. These improvement equations function independently across iterations and solutions, enhancing both local exploration and global search capabilities. RL is then employed to intelligently select the most effective improvement methods based on historical performance, allowing the system to adaptively discover optimal solution pathways over time. When implemented in a real-world sugarcane bale logistics scenario, the framework delivered notable economic benefits—reducing logistics costs by 25 % and increasing operational profit by 10.83 % compared to conventional methods. These outcomes are attributed to the framework’s ability to dynamically learn and refine its search strategies for optimal performance. The findings offer important contributions to production economics. First, they demonstrate how intelligent optimization can significantly enhance resource utilization and cost efficiency in agricultural operations. Second, the framework establishes a scalable solution for complex, multi-period scheduling that remains effective across varying production contexts. Third, it presents a novel integration of machine learning and traditional optimization, setting a foundation for future advances in smart agricultural logistics. Together, these contributions strengthen both theoretical insights and practical applications in the field of agricultural production management.},
  archive      = {J_ASOC},
  author       = {Kanchana Sethanan and Rapeepan Pitakaso and Chettha Chamnanlor and Kuo-Jui Wu},
  doi          = {10.1016/j.asoc.2025.114084},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114084},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-period scheduling and fleet management in agricultural production logistics: A novel reinforcement learning approach},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). TFETformer: A temporal-frequency enhanced transformer for tool wear monitoring. <em>ASOC</em>, <em>186</em>, 114083. (<a href='https://doi.org/10.1016/j.asoc.2025.114083'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tool wear monitoring (TWM) plays a crucial role in ensuring machining quality reliability and operational safety. To achieve accurate TWM, a novel deep learning framework called temporal-frequency enhanced Transformer (TFETformer) is proposed. Firstly, the multi-dimensional signals collected from various sensors are segmented to form a long-term feature sequence. Additionally, a novel attention module is introduced, which consists of a temporal attention mechanism (TAM) and a frequency attention mechanism (FAM), to enhance features in both the frequency and temporal domains. The proposed FAM leverages information across all frequency bands, overcoming the limitations of traditional pooling strategies (e.g., global pooling or fully-connected-based attention mechanisms) that rely only on low frequency band information. To further enrich feature diversity and improve model generalization, a multi-head feature fusion mechanism (MHFFM) is designed to replace traditional multi-head attention mechanism (MHAM). Moreover, to enhance the feature extraction capability of the Transformer, a residual convolution block (RCB) with pointwise convolutions is introduced, replacing the standard feed forward block. Finally, a fully connected (FC) regression sub-network is designed to establish the mapping relationship between learned features and tool wear values. The effectiveness of the proposed methods is validated on the PHM 2010 benchmark dataset and carbon fiber reinforced plastics (CFRP) dataset. A comparison with state-of-the-art (SOTA) methods and an ablation study demonstrate the superiority of the proposed design and the effectiveness of each component.},
  archive      = {J_ASOC},
  author       = {Zhixiang Chen and Fengze Qin and Junhui Lu and Guibao Tao and Huajun Cao},
  doi          = {10.1016/j.asoc.2025.114083},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114083},
  shortjournal = {Appl. Soft. Comput.},
  title        = {TFETformer: A temporal-frequency enhanced transformer for tool wear monitoring},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Generalized additive models for mixed-data regression using informal data. <em>ASOC</em>, <em>186</em>, 114082. (<a href='https://doi.org/10.1016/j.asoc.2025.114082'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a Generalized Additive Model for Mixed-Data Sampling (GAM-MIDAS) that integrates nonlinear relationships in mixed-frequency data. The model combines GAMs’ flexibility with MIDAS regression efficiency to capture complex temporal dependencies in high-frequency predictors. We evaluate GAM-MIDAS by forecasting US GDP growth using financial news sentiment scores and Industrial Production Index data. Our quantitative analysis demonstrates that GAM-MIDAS significantly outperforms conventional MIDAS, reducing the relative squared error (RSE) by 12.2 % for one-step-ahead forecasts and improving the relative root mean squared error (RRMSE) by 2.2 % on average across forecast horizons. The model also achieves substantial improvements over benchmark models, including ARIMA (59.4 % RSE reduction), LSTM (12.1 %), DeepVAR (6.4 %), and PatchTST (57.1 %). GAM-MIDAS executes in 0.84 s, making it computationally efficient for practical applications. Our findings confirm that GAM-MIDAS effectively leverages informal data sources to enhance economic forecasting accuracy while maintaining interpretability and efficiency.},
  archive      = {J_ASOC},
  author       = {Nathaniel Kang and Hyun Hak Kim and Jongho Im},
  doi          = {10.1016/j.asoc.2025.114082},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114082},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Generalized additive models for mixed-data regression using informal data},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-stage symbolic regression method for discovering mathematical formulas. <em>ASOC</em>, <em>186</em>, 114081. (<a href='https://doi.org/10.1016/j.asoc.2025.114081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a two-stage symbolic regression method with hybrid optimization for discovering mathematical formulas. Unlike existing approaches such as genetic programming, which attempt to optimize both model structure and parameters simultaneously, the proposed method decouples the process into two distinct stages. In the first stage, a genetic algorithm is employed to generate a diverse and high-quality pool of candidate terms from the given variables and operators. In the second stage, simulated annealing (SA) and a reinforcement learning-enhanced SA (RLSA) method are jointly utilized to solve a subset selection problem—aiming to identify the optimal subset of terms that best fit an equation via linear regression. The effectiveness of the proposed method was evaluated on five benchmark datasets comprising 56 widely used instances. Experimental results show that our method consistently outperforms five state-of-the-art baselines in accurately recovering ground-truth formulas. Furthermore, in a case study on triangle area formula discovery, the proposed method successfully identified 295 valid formulas, surpassing the 251 known formulas reported in the literature. These findings suggest that the proposed hybrid optimization design, leveraging the complementary strengths of different metaheuristics, is well-suited for navigating complex search spaces and achieving competitive performance in symbolic regression tasks.},
  archive      = {J_ASOC},
  author       = {Zeyu Zeng and Xicheng Peng and Mao Chen and Sannyuya Liu},
  doi          = {10.1016/j.asoc.2025.114081},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114081},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A two-stage symbolic regression method for discovering mathematical formulas},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Subpixel attention and frequency-domain cross modulation network for multimodal remote sensing image classification. <em>ASOC</em>, <em>186</em>, 114073. (<a href='https://doi.org/10.1016/j.asoc.2025.114073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multimodal remote sensing image classification, limited spatial resolution often leads to blurred boundaries and unclear land cover distributions. Although subpixel features can compensate for missing spatial details, subpixel decomposition results may contain noise or heterogeneous components, and the feature distribution is relatively scattered and has potential redundancy that affects model performance. Additionally, current fusion methods between hyperspectral image (HSI) and LiDAR data typically rely on simple weighted superposition in the frequency domain, failing to achieve explicit interaction. To address these issues, this paper proposes a subpixel attention and frequency-domain cross modulation network (SA-FCM) for multimodal remote sensing image classification. First, a subpixel attention aggregation (SAA) module is designed to extract discriminative subpixel features by leveraging subpixel convolution and attention mechanisms, effectively reducing redundancy and enhancing feature representation. Second, a frequency-domain cross modulation (FCM) module is designed to explicitly fuse HSI and LiDAR features by crosswise combining the amplitude and phase information of HSI and LiDAR data, thereby bridging the gap between spectral and geometric information. Extensive experiments demonstrate that our proposed SA-FCM model, using a simple and efficient dual-branch structure, outperforms the state-of-the-art methods for comparison, with improvement of overall accuracy up to 19.18 percentage points.},
  archive      = {J_ASOC},
  author       = {Yi Liu and Jiajie Feng and Caihong Mu and Xinyu He},
  doi          = {10.1016/j.asoc.2025.114073},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114073},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Subpixel attention and frequency-domain cross modulation network for multimodal remote sensing image classification},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A transformer-based dual-branch feature extraction for printed circuit board defect detection with enhanced spatial attention mechanism. <em>ASOC</em>, <em>186</em>, 114072. (<a href='https://doi.org/10.1016/j.asoc.2025.114072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integrity of Printed Circuit Boards (PCBs) is critical to the performance and reliability of electronic devices. However, existing deep learning-based detection methods often struggle to accurately identify small and complex defects in challenging industrial environments, primarily due to their inability to effectively model irregular defect morphologies, sensitivity to background noise, insufficient multi-scale feature fusion, and difficulties in achieving efficient detection under limited computational resources. To address these issues, we propose a novel object detection framework based on YOLOv8, which integrates a dual-branch feature extraction module, a deformable attention mechanism, and an enhanced spatial attention head. Specifically, we design a Dual-Transformer downsampling module that effectively captures both global context and local details of PCB defects. We also introduce a deformable attention mechanism into the C2f module to handle irregular defect shapes adaptively. Furthermore, we propose a lightweight detection head that employs multi-scale spatial attention and depthwise separable convolutions to enhance feature representation while reducing computational cost. To improve the localization accuracy of small defects, we introduce a new loss function that combines Normalized Wasserstein Distance with Wise-IoUv3. Extensive experiments on the publicly available PKU-Market-PCB dataset demonstrate that YOLO-DTS achieves a precision of 88.4 %, a recall of 69.9 %, and an m A P 50 of 77.5 %, outperforming the baseline YOLOv8 by 4.9 %, 7.5 %, and 7.5 %, respectively. The parameters used have been reduced by 13.4 % compared to the baseline model. Additional experiments on DeepPCB and aluminum profile defect datasets further validate the strong generalization capability of our method. The results indicate that YOLO-DTS is a robust and efficient solution for PCB defect detection in real-world industrial scenarios.},
  archive      = {J_ASOC},
  author       = {Yufeng Ou and Chia-Hung Wang},
  doi          = {10.1016/j.asoc.2025.114072},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114072},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A transformer-based dual-branch feature extraction for printed circuit board defect detection with enhanced spatial attention mechanism},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Modified genetic algorithms for constructing new quaternary hermitian LCD codes. <em>ASOC</em>, <em>186</em>, 114071. (<a href='https://doi.org/10.1016/j.asoc.2025.114071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose two systematic methods for an efficient construction of quaternary Hermitian linear complementary dual (LCD) codes using two algorithms, called Iteration Search Algorithms I and II, which are modified genetic algorithms . Our algorithms include operators such as mutation, crossover, modified crossover, and complement to make the search space more effective. Using our algorithms, we obtain many new quaternary Hermitian LCD codes with best known minimum distances, including at least 133 such codes with several parameters, which are verified to be inequivalent to the currently known codes. Our methods demonstrate significantly efficient complexity in finding quaternary Hermitian LCD codes, contributing to the expansion of the current database for quaternary Hermitian LCD codes.},
  archive      = {J_ASOC},
  author       = {Byung-Sun Won and Jon-Lark Kim and Yoonjin Lee},
  doi          = {10.1016/j.asoc.2025.114071},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114071},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Modified genetic algorithms for constructing new quaternary hermitian LCD codes},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A scalable AI-driven approach for burned-area mapping using U-net and landsat imagery. <em>ASOC</em>, <em>186</em>, 114070. (<a href='https://doi.org/10.1016/j.asoc.2025.114070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring wildfires is essential to mitigating their widespread environmental, economic, and social impacts. Recent advances in remote sensing technology, combined with the growing use of artificial intelligence, have significantly enhanced the ability to perform real-time, high-resolution fire monitoring. Motivated by the limitations of traditional methods in dealing with spatial heterogeneity and class imbalance, this study proposes two scalable, AI-based approaches built on the U-Net convolutional neural network for automated burned-area segmentation using multispectral Landsat imagery. We present two model variants: the 128-Crop approach, which processes fixed-size image patches, and the AllSizes (AS) strategy, which uses variable-sized crops to improve contextual understanding and dataset balance. Both models are trained on time-series Landsat imagery from two fire-prone regions in Chile—Biobío and Valparaíso—using pre- and post-fire composites along with high-resolution fire scar labels. The training pipeline includes preprocessing, data augmentation, and hyperparameter optimization, employing Dice Loss to address class imbalance. A quantitative evaluation on 195 representative test images shows that the AS model outperforms the 128-Crop variant, achieving a Dice Coefficient (DC) of 0.93, an Omission Error (OE) of 0.086, and a Commission Error (CE) of 0.045, while the 128-Crop model reached DC = 0.86, OE = 0.12, and CE = 0.12. Additionally, a QGIS plugin named “FireScar-Mapper-Plugin” has been developed to enable user-friendly access and integration of the models. The plugin supports batch processing of new imagery and is designed for non-programmers, enhancing the framework’s scalability and applicability for large-scale wildfire monitoring and management across diverse regions. These contributions—combining a novel scalable U-Net strategy with an open-source QGIS implementation—make this study a distinctive step toward practical, automated burned-area mapping.},
  archive      = {J_ASOC},
  author       = {Ian Mancilla-Wulff and Diego Terán and Carla Vairetti and José Ramón González-Olabarria and Andrés Weintraub and Jaime Carrasco-Barra},
  doi          = {10.1016/j.asoc.2025.114070},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114070},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A scalable AI-driven approach for burned-area mapping using U-net and landsat imagery},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A sequential flow UNet for MRI brain tumor segmentation based on state-space-model. <em>ASOC</em>, <em>186</em>, 114069. (<a href='https://doi.org/10.1016/j.asoc.2025.114069'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation of brain tumors is one of the most extensively discussed challenges in medical image processing, aiming to differentiate various tumor regions from background regions in MRI scans. While UNet and its variants have demonstrated exceptional performance in 2D and 3D image segmentation, existing methods often neglect the temporal sequence associations between brain tumor MRI slices, which contain crucial information about lesion characteristics. To address this limitation, we propose the SF-SSM UNet (Sequential Flow State Space Model UNet), featuring the Sequential Flow Selective Scanning Module Group (SF-SSM Group). Our approach transcends traditional 2D and 3D models by treating MRI brain tumor slices as serialized image flow inputs. In the SF-SSM UNet, sequence flow is constructed through feature dimensional rearrangement, and Mamba SSM is applied across both sequence and channel dimensions, enabling the model to effectively capture temporal dependencies and feature interactions between slices. We further introduce the Shuffled-Ordered Sequential Flow Training Strategy (SOSF), a Fourier transform-based approach that enhances sequential feature learning and evaluates fine-grained performance using Frequency-domain Mean Error Ratio (FMER) and Frequency-domain Mean Error Number (FMEN). Experiments on BraTS-2019 show that SF-SSM UNet achieves Dice scores of 88.45, 90.55, and 91.44 for WT, TC, and ET regions, respectively, with corresponding Hausdorff95 distances all below 1.3. On MSD Task01, it further attains Dice scores of 89.26, 88.74, and 90.35. These results demonstrate clear performance gains across multiple benchmarks, establishing SF-SSM UNet as a state-of-the-art approach for sequential medical image segmentation.},
  archive      = {J_ASOC},
  author       = {Jiacheng Lu and Hui Ding and Qirun Huo and Kaiwen Wang and Xinyu Sun and Shiyu Zhang},
  doi          = {10.1016/j.asoc.2025.114069},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114069},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A sequential flow UNet for MRI brain tumor segmentation based on state-space-model},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multiscale convolutional attention transformer based on transfer learning for temperature forecasting of ultra-supercritical coal-fired power plant reheater. <em>ASOC</em>, <em>186</em>, 114068. (<a href='https://doi.org/10.1016/j.asoc.2025.114068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate reheater temperatures can help ultra-supercritical coal-fired power plants improve power generation efficiency and security. To ensure the efficient and safe operation of reheaters, this study proposes multi-scale convolutional attention Transformer (MSCAT) model based on transfer learning, for online incremental prediction. After offline training, the trained model parameters are fed into the online MSCAT through transfer learning, and combined with incremental learning for online multi-step forecasting. Considering the delayed nature of the reheater temperature change, this study applies mutual information to determine the delay time of the reheater temperature. MSCAT efficiently extracts global and local features in reheater temperature by multi-scale convolutional attention. By parameter fine-tuning strategies for transfer learning, the MSCAT can be quickly and directly applied in online temperature forecasting for new reheaters without retraining again. Incremental learning solves the problems of not adapting to new data when online forecasting and forgetting previous knowledge when learning new knowledge. The proposed delayed MSCAT achieves mean squared error (MSE), root mean squared error (RMSE), mean absolute error (MAE), mean absolute percentage error (MAPE), and R² of 15.61, 3.95, 2.64, 0.44 %, and 0.92, respectively, on offline data. For online prediction, the proposed MSCAT achieves MSE, RMSE, MAE, MAPE, and R² of 18.2, 4.27, 3.25, 0.54 %, and 0.87, respectively. Thus, the proposed MSCAT shows excellent online prediction performance, meeting the requirements for practical applications.},
  archive      = {J_ASOC},
  author       = {Linfei Yin and Hang Zhou},
  doi          = {10.1016/j.asoc.2025.114068},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114068},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multiscale convolutional attention transformer based on transfer learning for temperature forecasting of ultra-supercritical coal-fired power plant reheater},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An integrated fuzzy decision model for potential digital transformation overcoming circular food consumption and production promotion. <em>ASOC</em>, <em>186</em>, 114067. (<a href='https://doi.org/10.1016/j.asoc.2025.114067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital transformation is being increasingly acknowledged as a pivotal strategy for fostering the circular economy in the realm of food consumption and production. Previous studies focus on revealing the effect of digital transformation on implementing circular economy within food supply chain sector, however, a gap remains in understanding the comprehensive potential of digital transformation overcoming circular consumption and production (CFCP) promotion. This concerns the scalability of the digital transformation and the expansion of CFCP. Thus, this work introduces a comprehensive evaluation framework that integrates various advantages of digital transformation along with barriers derived from the Technology-Organization-Environment (TOE) theory. To measure the significance of these barriers, an extended picture q-rung orthopair fuzzy sets (PqROFSs) based-Cronbach’s coefficient, combined with weighted Heronian mean aggregation operator, is utilized to determine the barrier weights, considering the uncertain conditions and interdependent relationships. After that, through the integration of PqROFSs, the Cronbach’s coefficient, and CoCoSo’B, this framework offers a quantifiable utility index for assessing the potential of digital transformation advantages. Upon applying this framework to an illustrative example, the findings suggest that the advantage, namely “Predicting food demand accurately”, with a utility index of 1.7618, exhibits the greatest potential for overcoming the identified barriers. A validation test, comprising sensitivity and comparison studies, is conducted to assess the reliability of the evaluation framework. The findings of this research are expected to be advantageous for relevant stakeholders in implementing effective digital advantage construction strategies and resource orchestration methods, thereby facilitating the promotion of CFCP models. From a theoretical perspective, employing this framework can enhance our comprehension of digitalization as a driving force for adopting CFCP practices.},
  archive      = {J_ASOC},
  author       = {Yu Chen and Weizhong Wang and Muhammet Deveci and Zelin Wang and Huiqin Xiong and Jurgita Antucheviciene},
  doi          = {10.1016/j.asoc.2025.114067},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114067},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An integrated fuzzy decision model for potential digital transformation overcoming circular food consumption and production promotion},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The effect of elitist fitness-based selection on the escape from local optima. <em>ASOC</em>, <em>186</em>, 114066. (<a href='https://doi.org/10.1016/j.asoc.2025.114066'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random Search is the baseline that a metaheuristic must improve upon to be worth its added complexity. Random Search, in the form of Hill Climbing, cannot escape from local optima. A key claim of many metaheuristics is that they are able to escape from local optima. However, these claims are poorly tested and often based on imprecise definitions of what it means to escape from a local optimum in continuous domain search spaces. A practical and precise definition for an escape from a local optimum is developed. It is then shown how elitist fitness-based selection can lead to the rejection of exploratory search solutions, and this can cause many popular metaheuristics to degrade into (localized) Random Search in their attempts to escape from local optima. The explosion of new metaheuristics has often been just a repeated re-invention of localized Random Search for the key task of escaping from local optima.},
  archive      = {J_ASOC},
  author       = {Stephen Chen},
  doi          = {10.1016/j.asoc.2025.114066},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114066},
  shortjournal = {Appl. Soft. Comput.},
  title        = {The effect of elitist fitness-based selection on the escape from local optima},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Representation embedded learning via autoencoder for large-scale multi-objective optimization. <em>ASOC</em>, <em>186</em>, 114065. (<a href='https://doi.org/10.1016/j.asoc.2025.114065'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing studies for large-scale multi-objective optimization problems (LSMOPs) mainly focus on the search mechanism in the decision space, while often overlooking the population distribution in the objective space. This can limit the ability to guide the search process toward promising regions, thereby reducing the algorithm’s search efficiency and the quality of the solution set. Based on these observations, this paper proposes a Representation Embedded Learning via Autoencoders (RELA) algorithm to enhance the targeted evolution process for solving LSMOPs. Firstly, a representation embedding learning strategy is proposed, which clusters populations into different sub-populations according to their distribution in the objective space, and uses the non-dominated solution sets of the sub-populations to train autoencoders. The strategy can learn the latent representations from intra and inter sub-populations in the objective space, which implicitly realizes the information exchange and knowledge sharing across sub-populations. Secondly, an encoding reconstruction strategy is proposed to further fuse the embedded representations of different sub-populations, and then map them back to the decision space through the solution set reconstruction strategy to generate a higher-quality solution set to guide the evolutionary process of the population. Finally, two offspring generation strategies are proposed to balance convergence and diversity. Extensive experiments are conducted on two LSMOP benchmark suites (up to 5000 decision variables) and a real-world problem. Statistical tests show that the proposed RELA outperforms several state-of-the-art algorithms, and achieves the best performance on 39 and 40 out of 54 test problems in terms of inverted generational distance and hypervolume, respectively.},
  archive      = {J_ASOC},
  author       = {Xia Wang and Hongwei Ge and Zhi Zheng and Yaqing Hou and Jiancheng Tong and Mengyue Wang and Guozhi Tang},
  doi          = {10.1016/j.asoc.2025.114065},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114065},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Representation embedded learning via autoencoder for large-scale multi-objective optimization},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Class-conditional unbiased loss for single-positive multi-label learning. <em>ASOC</em>, <em>186</em>, 114064. (<a href='https://doi.org/10.1016/j.asoc.2025.114064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of multi-label learning, the high cost of annotation remains an unavoidable challenge in the development of machine learning. To address the critical issue of difficulty in collecting complete labels, this paper investigates the Single-Positive Multi-Label (SPML) learning paradigm, which requires only one relevant label to be annotated for each sample. Previous studies have demonstrated that the SPML framework can significantly reduce supervision requirements while maintaining acceptable performance levels. However, existing methods have neither proposed unbiased loss functions nor provided corresponding theoretical guarantees. To this end, this paper introduces two corrected and improved unbiased loss functions based on two typical multi-label loss functions, along with rigorous theoretical proofs. Furthermore, by leveraging the global high-rank property of multi-label matrices, the proposed method effectively captures label correlations. Experimental results on three image datasets and three multi-label benchmark datasets demonstrate that the proposed method exhibits significant performance advantages compared to existing SPML techniques.},
  archive      = {J_ASOC},
  author       = {Xinpei Su and Zhuojun Han and Yitian Xu},
  doi          = {10.1016/j.asoc.2025.114064},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114064},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Class-conditional unbiased loss for single-positive multi-label learning},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A review of patent analysis based on machine learning. <em>ASOC</em>, <em>186</em>, 114063. (<a href='https://doi.org/10.1016/j.asoc.2025.114063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, as machine learning approaches have demonstrated success across various domains, the application of machine learning to patent analysis has garnered significant attention. To understand the current status and explore the future trends of patent analysis based on machine learning, in this paper, we conduct a systematic review of the related articles recently recorded by Web of Science. We identify 91 representative papers published from 2018 to 2025 and categorize machine learning-based patent analysis approaches into four classes: patent classification, retrieval, recommendation, and assessment. We extract and compare the fundamental methods in these publications and delineate the workflow of the conventional approaches. Particularly, as there are still no clear standards for patent assessment, we also categorize the evaluation indicators used in the patent assessment literature into four dimensions: technical, economic, legal, and others. In addition, we meticulously dissect the technical challenges encountered when applying machine learning techniques, providing a nuanced understanding of the complexities involved. Finally, we present three new perspectives on the potential efficacy of machine learning and deep learning techniques in future patent analysis.},
  archive      = {J_ASOC},
  author       = {Zhenhai Chi and Wuquan Lin and Zhanhao Xiao and Huihui Li and Weiqi Chen and Xiaoyong Liu},
  doi          = {10.1016/j.asoc.2025.114063},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114063},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A review of patent analysis based on machine learning},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A spatiotemporal model for future fundus image prediction with irregularly sampled sequential data. <em>ASOC</em>, <em>186</em>, 114062. (<a href='https://doi.org/10.1016/j.asoc.2025.114062'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fundus images play a crucial role in diagnosing and monitoring eye diseases, and the progression of these diseases is a gradual process. Predicting fundus images using longitudinal data can help ophthalmologists provide personalized treatment for better therapeutic effects. In this paper, a spatiotemporal prediction method for future fundus image prediction using longitudinal historical images is proposed. In clinical practice, the collected longitudinal images are usually irregularly sampled. To address this problem, a motion estimation block based on the ordinary differential equation is proposed by modeling the evolution of longitudinal fundus images over time dynamically. Additionally, the collected longitudinal images have different styles. To ensure the prediction network focuses on the intrinsic changes in the sequential input, the style transfer strategy is integrated into the prediction framework to mitigate the interference caused by style differences. Experimental results demonstrate that the image quality of the fundus images predicted by our method is higher compared with those generated by the state-of-the-art methods.},
  archive      = {J_ASOC},
  author       = {Mengxuan Li and He Zhao and Weihang Zhang and Jie Xu and Huiqi Li},
  doi          = {10.1016/j.asoc.2025.114062},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114062},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A spatiotemporal model for future fundus image prediction with irregularly sampled sequential data},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Physics-informed neural control for mitigating flood effects: A case study based on a simulated hydrographic basin. <em>ASOC</em>, <em>186</em>, 114061. (<a href='https://doi.org/10.1016/j.asoc.2025.114061'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel flood mitigation strategy in hydrographic basins that integrates Physics-Informed Neural Networks (PINNs) with Model Predictive Control (MPC). The PINN-based MPC computes optimal dam floodgate (opening and closing) signals to minimize water level excess at critical downstream points while ensuring reservoir management during flood events. The methodology uses PINNs as surrogate models for the Saint-Venant equations in the modeling process, producing accurate hydrodynamic descriptions of river channels with reduced computational demand for optimal control. The PINN model predicts water levels and flows across space and time, assisting control decisions without the high costs typically associated with solving complex partial differential equations. The proposed control framework is evaluated in a simulated hydrographic basin composed of two reservoirs and four interconnected channels with lengths ranging from 10 to 68 km, bed slopes of 0.0025, and Manning coefficients of 0.02. The channels feature variable cross-sections, varying from 45 to 95 m widths. In the modeling process, PINNs accurately approximate the hydrodynamic behavior in each channel, achieving MAPE between 0.63 % and 2.74 % for water levels and 0.03 %–0.42 % for flow rates, even under initial and boundary conditions not present in the training dataset. In extreme inflow scenarios for the case study, the PINN-based MPC framework effectively managed flood conditions by dynamically adjusting control signals, preventing flooding in downstream urban areas. The experiments revealed that the PINN-MPC approach provides a scalable, computationally efficient alternative for real-time flood control, with the potential for broader applications in hydrological management.},
  archive      = {J_ASOC},
  author       = {Luis Fernando Nazari and Eduardo Camponogara and Laio Oriel Seman},
  doi          = {10.1016/j.asoc.2025.114061},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114061},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Physics-informed neural control for mitigating flood effects: A case study based on a simulated hydrographic basin},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Enhancing confidence level in decision-making frameworks using fermatean fuzzy rough sets: Application in industry 4.0. <em>ASOC</em>, <em>186</em>, 114059. (<a href='https://doi.org/10.1016/j.asoc.2025.114059'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multidimensional decision-making has substituted traditional decision-making due to the increased risk and complexity involved in the decision processes and cognitive behaviors. Moreover, uncertainty management is necessary in the decision-making processes that involve the degree of confidence of the experts. Conflict assessment and resolution are paramount to the smooth functioning of the industrial ecosystem in such an automated dynamic environment. This research aims to create a multi-attribute decision-making (MADM) model in a hybrid fuzzy frame to evaluate and resolve conflicts in Industry 4.0. The MADM model dwells on three primary points, i.e., (i) how to efficiently manage ambiguity and interrelationships in MADM issues; (ii) how to encompass the mindset of the decision maker in all areas concerned; and (iii) how to demonstrate results in terms of acceptance and rejection rather than ranking issues when more than one factor is involved. The test data of a fermatean fuzzy set (FFS) with rough relations, which addresses upper and lower approximations, demonstrates the possible uncertainty of the information. A fermatean fuzzy rough set (FFRS) is initially defined within the model. Subsequently, an FFRS incorporating the operator’s confidence level is delineated. This demonstrates the importance of FFRS in MADM contexts and suggests that they require further examination of their data processing regulations. Furthermore, we evaluate the accuracy and validity of the results by employing mean absolute errors, cosine similarity of the operators, and Spearman rank correlation. To illustrate the accuracy and validity of our method in the MADM context, we performed a comparative analysis. Finally, a practical illustration of the selection of Industry 4.0 technologies within the healthcare sector exemplifies the efficacy and potential of this innovative approach for future applications of MADM. The intricate multi-stakeholder conflicts and data uncertainties presented by Industry 4.0 environments, especially regarding healthcare technology implementation, will be examined using the research framework illustrated in Fig. 1 .},
  archive      = {J_ASOC},
  author       = {Muhammad Kamran and Qingyu Zhang and Dragan Pamucar and Muhammad Tahir and Vladimir Simic},
  doi          = {10.1016/j.asoc.2025.114059},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114059},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enhancing confidence level in decision-making frameworks using fermatean fuzzy rough sets: Application in industry 4.0},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Advancements in data-driven evolving fuzzy and neuro-fuzzy control: A comprehensive survey. <em>ASOC</em>, <em>186</em>, 114058. (<a href='https://doi.org/10.1016/j.asoc.2025.114058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an era of increasing system complexity and growing demands for autonomy and efficiency, control systems must continuously adapt to dynamic and uncertain environments. This study presents a comprehensive survey of evolving fuzzy and neuro-fuzzy controllers, with emphasis on data-driven control systems that adapt in real time in both structure and parameters. As the demand for adaptive and flexible control solutions grows alongside the increasing complexity of systems, evolving model-free and model-based fuzzy, neural, and neuro-fuzzy controllers have emerged as robust approaches, allowing models and controllers to integrate new patterns from data streams. Incremental machine learning methods enable control systems to autonomously detect and track new behaviors, improving their effectiveness in time-varying and unknown environments. Based on a rigorous bibliometric analysis using the Web of Science database, 2760 related papers were identified of which 97 were manually selected for detailed review due to their direct relevance to closed-loop evolving fuzzy or neuro-fuzzy control systems. These papers cover a wide range of methods, including basic parameter tuning, adaptive gain scheduling, and structural modifications grounded in constrained optimization and Lyapunov stability analysis. Such advances mark significant progress in the control of unknown, time-varying systems, with the surveyed literature demonstrating promising results in various applications. The abstracted findings reveal an increase in publications since 2013, confirming the relevance of evolving control in engineering. This review provides a comprehensive analysis of methodologies and achievements in the field, highlighting emerging trends, challenges, and research directions within evolving data-driven control. The novelty of this study lies in its focus on the structural evolution of controllers under real-time constraints, consolidating incremental machine learning for partition-based closed-loop architectures.},
  archive      = {J_ASOC},
  author       = {Goran Andonovski and Daniel Leite and Radu-Emil Precup and Fernando Gomide and Mahardhika Pratama and Igor Škrjanc},
  doi          = {10.1016/j.asoc.2025.114058},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114058},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Advancements in data-driven evolving fuzzy and neuro-fuzzy control: A comprehensive survey},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph-embedded reinforcement learning for dynamic pricing and advertising under network effects. <em>ASOC</em>, <em>186</em>, 114056. (<a href='https://doi.org/10.1016/j.asoc.2025.114056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Firms increasingly rely on both price discounts and advertising campaigns to shape product diffusion in socially connected markets, yet existing models rarely treat these levers jointly or account for network heterogeneity. This study develops an integrated, network-aware framework for dynamic pricing and advertising control. A stochastic compartmental model of the consumer decision-making model (CDM) is formulated on a social graph, with transition intensities modulated by price, advertising spend, and peer influence. A deterministic mean-field approximation yields closed-form expressions for a trade-free equilibrium (TFE) and a reproduction number threshold that delineates when adoption dies out versus persists. Building on this analytical core, the paper introduces twin delayed deep deterministic policy gradient with encoded state (TD3ES), a reinforcement learning (RL) controller that couples an actor-critic architecture with a graph-convolutional autoencoder, thereby compressing high-dimensional network states into a tractable latent representation. A custom GPU-accelerated simulator facilitates large-scale training. Numerical experiments on Erdős-Rényi and heavy-tailed exponential networks show that twin delayed deep deterministic policy gradient with encoded state (TD3ES) swiftly converges to profit-maximizing joint policies and, on heterogeneous graphs, outperforms a TD3 baseline that lacks network-structural information. Error analysis reveals that the autoencoder naturally prioritizes high-degree hubs in dominant CDM compartments, explaining its superior performance. Managerially, the results demonstrate that ignoring topology can forfeit substantial revenue and that adaptive, network-aware coordination of price and advertising is both feasible and valuable. The framework thus unites rigorous diffusion theory with scalable learning, offering a practical tool for data-driven marketing in connected consumer ecosystems.},
  archive      = {J_ASOC},
  author       = {Ehsan Ardjmand and Esmaeil Izadi and Ali Tavasoli and Behnaz Moradi-Jamei and Heman Shakeri},
  doi          = {10.1016/j.asoc.2025.114056},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114056},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Graph-embedded reinforcement learning for dynamic pricing and advertising under network effects},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Differentiable architecture search for GANs with rollback mechanism. <em>ASOC</em>, <em>186</em>, 114055. (<a href='https://doi.org/10.1016/j.asoc.2025.114055'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing effective architectures for Generative Adversarial Networks (GANs) remains a challenging task due to training instability and the complexity of balancing generator and discriminator performance. While Neural Architecture Search (NAS) has shown promise in automating architecture design, existing NAS-GAN approaches often suffer from limited design flexibility and high computational demands. This paper introduces a gradient-based NAS framework, termed Differentiable Architecture Search for GANs with Rollback Mechanism (RASGAN), aimed at addressing these limitations. RASGAN incorporates a hyperparameter rollback to indirectly optimise evaluation metrics such as the Inception Score (IS) and Fréchet Inception Distance (FID), leading to higher-quality generative models. Moreover, the search space integrates lightweight convolutional operations to reduce computational and storage overhead without compromising performance. On unconditional image generation tasks, the proposed method achieves competitive results: on CIFAR-10, RASGAN attains IS = 8.98 and FID = 10.31; on STL-10, IS = 10.55 and FID = 22.37. Compared to existing NAS-GAN methods, the architectures discovered by RASGAN are not only more effective but also significantly more efficient, exhibiting reduced parameter size while maintaining strong generative performance.},
  archive      = {J_ASOC},
  author       = {Ferrante Neri and Lingzhen Liao and Yu Xue and Márcio P. Basgalupp},
  doi          = {10.1016/j.asoc.2025.114055},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114055},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Differentiable architecture search for GANs with rollback mechanism},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-time scale feature extraction and attention networks for automatic depression level prediction. <em>ASOC</em>, <em>186</em>, 114052. (<a href='https://doi.org/10.1016/j.asoc.2025.114052'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression impairs functioning across personal and professional domains, and early detection is essential for timely intervention. Existing clinical assessments rely on specialists, limiting accessibility and scalability. This paper proposes an automated, video-based approach that estimates depression severity directly from full-length interviews. Facial markers evolve over micro- to macro- timescales; therefore, focusing solely on short clips risks missing long-range cues. This paper introduces a Multi-Timescale Feature Extraction and Channel-Temporal Attention network (MSFE–CTA) that learns dependencies across milliseconds, seconds, and minutes from complete recordings. The MSFE module employs stacks of Inception-TCN blocks with logarithmically scaled dilations to efficiently capture long-range structure, while the CTA module integrates dilated channel attention with multi-kernel depthwise temporal attention to highlight salient features. Window-level predictions are aggregated into a video-level score without requiring manual annotations at inference. Evaluated on the AVEC2013, AVEC2014 datasets, MSFE-CTA achieves MAE/RMSE of 5.75/6.23 and 5.72/6.91, respectively, with only 0.85 M parameters and 1.85 GFLOPs. To assess generalizability across benchmarks, the framework was evaluated on AVEC2017 and AVEC2019 using the official splits, reaching MAE/RMSE of 4.85/5.20 and 5.30/6.44, respectively. Ablation studies confirm that multi-timescale extraction and channel-temporal attention contribute to accuracy, and that dilated operations outperform fixed-scale or squeeze-and-excitation alternatives. The results demonstrate state-of-the-art performance at substantially lower computational cost, enabling practical, full-video depression assessment on standard frame-rates. The method is robust to short occlusions through median aggregation and may support scalable screening in clinical and community settings.},
  archive      = {J_ASOC},
  author       = {Sarmad Al-Gawwam and Aleksandr Zaitcev and Mohammad R. Eissa and Noor Alshwilli and Mohammed Benaissa},
  doi          = {10.1016/j.asoc.2025.114052},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114052},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-time scale feature extraction and attention networks for automatic depression level prediction},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Application of electoral systems for decision making in ensembles of heuristics generated by genetic programming. <em>ASOC</em>, <em>186</em>, 114050. (<a href='https://doi.org/10.1016/j.asoc.2025.114050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores improving hyper-heuristics, algorithms for designing heuristics, by integrating ensemble learning and democratic electoral systems for decision aggregation. While hyper-heuristics solve various optimisation problems, their solution quality remains limited. Ensemble learning, which combines decisions from multiple heuristics, can address this limitation, but aggregation methods are often simplistic. Inspired by democratic election systems, 25 electoral methods were tested for aggregating heuristic decisions in ensembles. Experiments on four combinatorial optimization problems demonstrate that electoral systems effectively aggregate decisions, offering alternative approaches to enhance current ensemble methods.},
  archive      = {J_ASOC},
  author       = {Marko Đurasević and Francisco J. Gil-Gala and Mateja Đumić},
  doi          = {10.1016/j.asoc.2025.114050},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114050},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Application of electoral systems for decision making in ensembles of heuristics generated by genetic programming},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Medical image classification with KAN-integrated transformers and dilated neighborhood attention. <em>ASOC</em>, <em>186</em>, 114045. (<a href='https://doi.org/10.1016/j.asoc.2025.114045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional networks, Transformers, hybrid models, and Mamba-based architectures have demonstrated strong performance across various medical image classification tasks. However, these methods were primarily designed to classify clean images using labeled data. In contrast, real-world clinical data often involve image corruptions that are unique to multi-center studies and stem from variations in imaging equipment across manufacturers. In this paper, we introduce the Medical Vision Transformer (MedViTV2), a novel architecture incorporating Kolmogorov-Arnold Network (KAN) layers into the Transformer architecture for the first time, aiming for generalized medical image classification. We have developed an efficient KAN block to reduce computational load while enhancing the accuracy of the original MedViT. Additionally, to counteract the fragility of our MedViT when scaled up, we propose an enhanced Dilated Neighborhood Attention (DiNA), an adaptation of the efficient fused dot-product attention kernel capable of capturing global context and expanding receptive fields to scale the model effectively and address feature collapse issues. Moreover, a hierarchical hybrid strategy is introduced to stack our Local Feature Perception and Global Feature Perception blocks in an efficient manner, which balances local and global feature perceptions to boost performance. Extensive experiments on 17 medical image classification datasets and 12 corrupted medical image datasets demonstrate that MedViTV2 achieved state-of-the-art results in 27 out of 29 experiments with reduced computational complexity. MedViTV2 is 44 % more computationally efficient than the previous version and significantly enhances accuracy, achieving improvements of 4.6 % on MedMNIST, 5.8 % on NonMNIST, and 13.4 % on the MedMNIST-C benchmark.},
  archive      = {J_ASOC},
  author       = {Omid Nejati Manzari and Hojat Asgariandehkordi and Taha Koleilat and Yiming Xiao and Hassan Rivaz},
  doi          = {10.1016/j.asoc.2025.114045},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114045},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Medical image classification with KAN-integrated transformers and dilated neighborhood attention},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UDA-SD: Unsupervised domain adaptation based on self-distillation for cross-domain audio anti-spoofing. <em>ASOC</em>, <em>186</em>, 114044. (<a href='https://doi.org/10.1016/j.asoc.2025.114044'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio anti-spoofing algorithms perform well in in-domain scenarios, but their performance deteriorates significantly under domain mismatch conditions. Some studies have incorporated domain adversarial training strategy to encourage the learning of domain-invariant representations, reducing domain differences. However, this strategy could compromise the model’s ability to distinguish between bona fide and spoofed audio, limiting its effectiveness in mitigating domain mismatch. To address this problem, we propose a novel U nsupervised D omain A daptation algorithm based on S elf- D istillation, termed UDA-SD. We introduce a Siamese framework with two branches tailored for the source and target domains, including three key modules: (i) The source branch leverages pre-trained audio representations to enhance spoofing discrimination capability, encouraging the model to capture the common differences between bona fide and spoofed audio. (ii) The target branch captures domain-specific and intrinsic features through a self-distillation module, thereby reducing domain discrepancies. (iii) Within the self-distillation module, we align the student model’s predictions for varying-duration audio segments with the teacher model’s predictions for long-duration segments. This design enhances the feature exploration of target samples by capturing both global and local representations, uncovering comprehensive differences between categories. To evaluate the effectiveness of the proposed UDA-SD, we conducted eight cross-domain anti-spoofing tasks. Experimental results showed the effectiveness of our approach with respect to source-only audio anti-spoofing models, achieving a relative 54.31 % to 85.14 % performance improvement in cross-domain scenarios.},
  archive      = {J_ASOC},
  author       = {Ruiteng Zhang and Xiaohuan Chen and Wenhuan Lu and Xugang Lu and Junhai Xu and Jianguo Wei},
  doi          = {10.1016/j.asoc.2025.114044},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114044},
  shortjournal = {Appl. Soft. Comput.},
  title        = {UDA-SD: Unsupervised domain adaptation based on self-distillation for cross-domain audio anti-spoofing},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantile deep learning models for multi-step ahead time series prediction. <em>ASOC</em>, <em>186</em>, 114043. (<a href='https://doi.org/10.1016/j.asoc.2025.114043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty quantification is crucial in time series prediction, and quantile regression offers a valuable mechanism for uncertainty quantification, which is useful for extreme value forecasting. Although deep learning models have been prominent in multi-step ahead prediction, the development and evaluation of quantile deep learning models have been limited. We present a novel quantile regression deep learning framework for multi-step time series prediction. In this way, we elevate the capabilities of deep learning models by incorporating quantile regression, thus providing a more nuanced understanding of predictive values. We provide an implementation of prominent deep learning models for multi-step ahead time series prediction and evaluate their performance under high volatility and extreme conditions. We include multivariate and univariate modelling, strategies, and provide a comparison with conventional deep learning models from the literature. Our models are tested on two cryptocurrencies: Bitcoin and Ethereum, using daily close-price data and selected benchmark time series datasets. The results show that integrating a quantile loss function with deep learning provides additional predictions for selected quantiles without a loss in prediction accuracy. Our quantile model can handle volatility more effectively and provides uncertainty quantification through the use of quantiles when compared to conventional deep learning models.},
  archive      = {J_ASOC},
  author       = {Jimmy Cheung and Smruthi Rangarajan and Amelia Maddocks and Rohtiash Chandra},
  doi          = {10.1016/j.asoc.2025.114043},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114043},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Quantile deep learning models for multi-step ahead time series prediction},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cancelable binary face templates generation based on density-sensitive hashing and feature hashing. <em>ASOC</em>, <em>186</em>, 114041. (<a href='https://doi.org/10.1016/j.asoc.2025.114041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing utilization of face recognition technology prompts concerns about the security of stored templates. Nevertheless, existing biometric template protection methods often incur high computational overhead or depend on two-factor input. To address these issues, we propose a cancelable template generation strategy that integrates density-sensitive hashing and feature hashing. The density-sensitive hashing transforms the facial feature vector into binary codes by leveraging the geometric characteristics of the data. Feature hashing then derives a permutation seed from the facial features to shuffle a random key, which is encoded using the binary codes, producing an encoded key retained within the cancelable template. Experimental results on the LFW, FEI and CASIA-FaceV5 databases show that our method achieves an EER below 0.72 %, a GAR exceeding 97.5 % at a FAR= 0.01 % and an average template generation time of 5.3 ms, confirming its efficiency and recognition performance. Furthermore, related experimental and theoretical evaluations prove that the proposed method guarantees the characteristics of irreversibility, revocability unlinkability, and resilience against various attacks.},
  archive      = {J_ASOC},
  author       = {Zifeng Huang and Yuxing Li and Qikang Zhang},
  doi          = {10.1016/j.asoc.2025.114041},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114041},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cancelable binary face templates generation based on density-sensitive hashing and feature hashing},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Polarimetric SAR image classification based on superpixel content-aware and semi-supervised ViT network. <em>ASOC</em>, <em>186</em>, 114040. (<a href='https://doi.org/10.1016/j.asoc.2025.114040'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PolSAR image classification faces key challenges, including complex scattering mechanisms, speckle noise, and scarcity of labeled data. Although Vision Transformer (ViT) and its variants are powerful, they require large labeled datasets and struggle with semantic misalignment in fixed patch tokenization. To address these issues under low-sample conditions, this paper proposes the superpixel content-aware and semi-supervised ViT network (SPSE-ViT). Firstly, superpixels are introduced into the ViT for the first time, and a content-aware token generation method is designed. During pre-training, superpixels of random sizes are selected, regularized, divided into blocks, and randomly masked to generate token sequences, improving spatial consistency and reducing noise. Secondly, a semi-supervised ViT network is constructed by integrating supervised and unsupervised learning. Classification loss guides learning with a small number of labeled samples, while reconstruction and contrastive loss enhance generalization by supplementing spatial structure. Finally, a pre-training and fine-tuning strategy is applied. The model is pre-trained with a few labeled samples, and fine-tuned for final classification results. Experimental results show that SPSE-ViT outperforms seven state-of-the-art methods in PolSAR classification, significantly improving performance with limited labeled samples. The code is available at: https://github.com/githubltqc/SPSE-ViT .},
  archive      = {J_ASOC},
  author       = {Jinhong Ren and Keyao Zhu and Mingwei Hu and Ronghua Shang and Mengxuan Zhang},
  doi          = {10.1016/j.asoc.2025.114040},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114040},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Polarimetric SAR image classification based on superpixel content-aware and semi-supervised ViT network},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Embracing data irregularities in multivariate time series. <em>ASOC</em>, <em>186</em>, 114039. (<a href='https://doi.org/10.1016/j.asoc.2025.114039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data collection in many engineering fields involves multivariate time series gathered from a collection of sensors that operate independently of each other. These sensors often display various irregularities, such as different sampling rates and missing data. To manage these issues, complex preprocessing mechanisms are required, which become coupled with any statistical model trained with the transformed data. Modeling the motion of floating platforms anchored on seabeds from measurements acquired from sensors is a typical example. We propose and analyze a model in which each sensor is encoded using an independent time-informed recurrent neural network, information is propagated in a common latent space by a graph neural network, and a modified training method is used to induce temporal generalization of the model. Our method can generate forecasts at unseen frequencies, which provides empirical evidence that the model learns an implicit representation of the system’s time derivatives and is able to flexibly integrate the signal over the time domain.},
  archive      = {J_ASOC},
  author       = {Marcel Barros and Lucas P. Fontenele and Mariana S. Silva and Thiago Rissi and Eduardo Cabrera and Eduardo A. Tannuri and Edson S. Gomi and Rodrigo A. Barreira and Anna H. Reali Costa},
  doi          = {10.1016/j.asoc.2025.114039},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114039},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Embracing data irregularities in multivariate time series},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FViT: A focal vision transformer with gabor filter. <em>ASOC</em>, <em>186</em>, 114032. (<a href='https://doi.org/10.1016/j.asoc.2025.114032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision transformers have achieved encouraging progress in various computer vision tasks. A common belief is that this is attributed to the ability of self-attention mechanisms to capture global dependencies among feature tokens. However, in dense prediction tasks, self-attention continues to pose challenges, including high computational cost and lack of desirable inductive bias. To alleviate these limitations, the potential advantages of combining vision transformers with Gabor filters are revisited, and a learnable Gabor filter (LGF) is proposed using depthwise convolution. The LGF does not rely on self-attention, and it is used to simulate the response patterns of fundamental cells in the biological visual system to input images. This enables vision transformers to focus on discriminative feature representations of targets across varying scales and orientations. Based on the LGF, a neuroscience inspired Bionic Focal Vision (BFV) block is developed. It incorporates a Dual-Path Feed-Forward Network (DPFFN) to emulate the parallel and cascaded information processing scheme of the biological visual cortex. Furthermore, a unified and efficient family of pyramid backbone networks called Focal Vision Transformers (FViTs) is developed by stacking BFV blocks. Experimental results demonstrate that FViTs achieve superior performance across various vision tasks while exhibiting significant advantages in computational efficiency and scalability compared with other counterparts. The code is available at https://github.com/nkusyl/FViT},
  archive      = {J_ASOC},
  author       = {Yulong Shi and Mingwei Sun and Yongshuai Wang and Zengqiang Chen},
  doi          = {10.1016/j.asoc.2025.114032},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114032},
  shortjournal = {Appl. Soft. Comput.},
  title        = {FViT: A focal vision transformer with gabor filter},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Imitation-assisted safe reinforcement learning strategy for microgrid fault restoration. <em>ASOC</em>, <em>186</em>, 114031. (<a href='https://doi.org/10.1016/j.asoc.2025.114031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microgrid physical faults triggered by equipment failures and extreme weather often lead to significant losses, which makes it imperative for microgrids to enhance their fault restoration capabilities and efficiency. Prior benchmarks including rule-based and MILP methods struggle to simultaneously satisfy solution time, power cost and safety. Furthermore, the application of traditional reinforcement learning approaches for fault restoration faces low learning efficiency and undesirable behaviors during the learning phase. This study introduces an imitation-assisted safe Soft Actor-Critic strategy for microgrid fault restoration to address these challenges. Firstly, the offline optimization strategy of Dynamic Programming is leveraged as expert guidance and the adversarial network is used to approximate the behavior of agent to the optimal fault restoration strategy. This addresses the problem of slow learning in microgrid fault restoration. Secondly, incorporating Lagrangian penalty terms for safety constraints into the reward function, which effectively mitigates undesirable behaviors during the learning phase and ensures secure microgrid operation. Thirdly, simulations under summer and winter conditions validate the strategy’s superiority, showing faster restoration and improved operational efficiency. Results demonstrate that the proposed method can accelerate the training by 25.26 % while enhancing the reward by 23.96 % compared with other imitation reinforcement learning methods. Under different test conditions, the proposed method can further reduce the power cost by 20.78 % to 38.22 %. The proposed strategy is further evaluated in a modified IEEE 33-bus microgrid, where it shows enhanced performance in fault restoration and overall system efficiency.},
  archive      = {J_ASOC},
  author       = {Jieqi Rong and Weirong Liu and Fu Jiang and Yingze Yang},
  doi          = {10.1016/j.asoc.2025.114031},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114031},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Imitation-assisted safe reinforcement learning strategy for microgrid fault restoration},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integrating AR-SVR and distortion risk measures for mortality risk forecasting. <em>ASOC</em>, <em>186</em>, 114030. (<a href='https://doi.org/10.1016/j.asoc.2025.114030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate mortality risk forecasting is critical for life insurance and pension systems. A hybrid modeling framework is introduced, combining stochastic processes and machine learning for improved mortality risk assessment. Specifically, an autoregressive model captures temporal dependencies, while support vector regression addresses nonlinear and heteroscedastic patterns. Tail distortion risk measures are incorporated to refine extreme risk forecast. Model performance is assessed through bayesian information criterion, coverage probability, and (conditional) tail-calibration using U.S. mortality data. The results confirm that this integrated approach effectively captures mortality dynamics, providing a reliable tool for actuarial and financial risk management.},
  archive      = {J_ASOC},
  author       = {Aniq Rohmawati and Arief Hakim and Atina Ahdika and Khreshna Syuhada and Octavina},
  doi          = {10.1016/j.asoc.2025.114030},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114030},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Integrating AR-SVR and distortion risk measures for mortality risk forecasting},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). End-to-end mid-term load forecasting framework based on multi-channel technique and time-frequency domain fusion. <em>ASOC</em>, <em>186</em>, 114029. (<a href='https://doi.org/10.1016/j.asoc.2025.114029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Load forecasting profoundly impacts power supply reliability and economy. Accurate mid-term forecasting is crucial for power system planning, operation, and management. However, factors like weather, season, and electricity price cause power load data to exhibit significant volatility and nonlinearity, limiting the accuracy of traditional forecasting models. While artificial intelligence methods have improved accuracy, extending the forecast horizon increases task complexity. Moreover, non-end-to-end forecasting frameworks use multi-module systems for forecasting, and there is often a lack of effective collaborative optimization mechanisms between modules, which makes it difficult to achieve global optimization of the entire forecasting system, limiting the further improvement of forecasting performance. To address these challenges, this paper proposes an innovative end-to-end load forecasting framework to enhance accuracy and robustness. The framework comprises two subsystems: a data decomposition system and a high-precision forecasting system. In the data decomposition system, the variational mode decomposition method is used to decompose the original load data into two modes with different central frequencies. In the high-precision prediction system, multi-channel prediction technology is adopted. The two components obtained by the decomposition module are input into two independent feature extraction channels respectively, and then the output vectors of the two are feature fused. Finally, the fused data is input into the prediction channel to obtain the final prediction result. Additionally, to mitigate label autocorrelation in the time series, a time-frequency domain fusion loss function is introduced during model training, further boosting performance. This paper uses two real data sets from Queensland and New South Wales, Australia to conduct four sets of experiments. The results show that the prediction performance of the framework is better than the state-of-the-art time series prediction models (e.g., Patch-based Time Series Transformer, Decomposition Linear, and Informer) in different prediction tasks (day-ahead (48 steps) and four days-ahead (192 steps)). Demonstrating improvements of at least 7.87 % in short-term accuracy and 13.7 % in medium-term accuracy, the framework’s stability and ease of use are validated through rigorous numerical testing. Its capability for accurate medium-term forecasting supports more efficient, economical, and reliable power system operation.},
  archive      = {J_ASOC},
  author       = {Wenyu Gao and Zhirui Tian},
  doi          = {10.1016/j.asoc.2025.114029},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114029},
  shortjournal = {Appl. Soft. Comput.},
  title        = {End-to-end mid-term load forecasting framework based on multi-channel technique and time-frequency domain fusion},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LLM-centric collaborative computing framework: Leveraging industry specified knowledge for open-set visual recognition. <em>ASOC</em>, <em>186</em>, 114028. (<a href='https://doi.org/10.1016/j.asoc.2025.114028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To promote intelligent capability of manufacturing, researchers propose lots of methods to obtain task-specified knowledge. Recently, the appearance of Large Language Models (LLMs) offers a paradigm by transforming knowledge learned from massive data to the specified industry scenarios. Focusing on involving LLMs to perform open-set visual recognition, we believe there exist two major issues to resolve, i.e., the usage of generalized knowledge from LLMs to identify unknown categories, and efficient architecture design for LLM-centric industrial deployment. In this paper, we propose a LLM-centric collaborative computing framework for open-set visual recognition, which consists of device-edge-cloud architecture, multi-server microservice deployment strategy and multiple LLM collaboration scheme. Specifically, the proposed architecture rationally allocates computation burden brought by LLMs to improve recognition efficiency. Embedded in the edge layer, the proposed microservice strategy helps balance the computation cost and achieve minimal device delay. Last but not least, the proposed scheme involves multiple LLMs and knowledge graph to generate and enhance the task-specified knowledge in a cycling workflow, thus boosting robustness and accuracy in recognizing unseen industrial objects. Extensive experiments on public datasets demonstrate the outstanding performance of the proposed framework regarding effectiveness and efficiency.},
  archive      = {J_ASOC},
  author       = {Yirui Wu and Xinfu Liu and Qi Yan and Cheng Zhen and Lixin Yuan and Wenxiao Zhang},
  doi          = {10.1016/j.asoc.2025.114028},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114028},
  shortjournal = {Appl. Soft. Comput.},
  title        = {LLM-centric collaborative computing framework: Leveraging industry specified knowledge for open-set visual recognition},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Transformer-based dynamics model for sim-to-real reinforcement learning control of a quadrotor with limited experimental data. <em>ASOC</em>, <em>186</em>, 114024. (<a href='https://doi.org/10.1016/j.asoc.2025.114024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep reinforcement learning is a promising technique for robotic applications, the considerable amount of data required through interactions with the environment hinders the large-scale adoption of this method. Collecting extensive real-world training data for robots is challenging due to safety concerns, periodic battery replacements, and actuator wear. In this study, we propose a novel strategic, data-efficient modeling scheme based on a transformer to effectively replicate a real-world environment and ensure that policies learned in the transformer-based simulation can operate effectively in real-world scenarios without significant performance degradation. The proposed transformer-based modeling scheme was demonstrated using a quadrotor. The transformer-based quadrotor model was first trained to approximate real-world dynamics accurately and subsequently used to train a low-level controller for the target quadrotor.The Soft Actor-Critic algorithm was utilized for policy training. To facilitate training of the dynamic model, both simulated and real flight data were used together in the pretraining step, while only real flight data were used in the fine-tuning step. The proposed method outperformed conventional policies trained using domain randomization. The proposed transformer-based quadrotor model facilitates smooth sim-to-real policy transfer by significantly reducing the time and effort required for additional tuning tasks.},
  archive      = {J_ASOC},
  author       = {Yoonsu Jang and Seongwon Yoon and Jongchan Baek and Changhyeon Lee and Jangwon Kim and Soohee Han},
  doi          = {10.1016/j.asoc.2025.114024},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114024},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Transformer-based dynamics model for sim-to-real reinforcement learning control of a quadrotor with limited experimental data},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mixed convolutional network via homogeneity map guided adaptive fusion for polarimetric SAR image classification. <em>ASOC</em>, <em>186</em>, 114020. (<a href='https://doi.org/10.1016/j.asoc.2025.114020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the complexity of polarimetric SAR images in different regions, convolutional neural networks find it difficult to extract non-Euclidean heterogeneous features. Graph convolutional networks struggle to extract fine features due to the dual influence of superpixel segmentation accuracy and classification accuracy. To address these problems, this paper proposes a mixed convolutional network based on homogeneous map guided network fusion (HM-MCN). Firstly, a double-branch network is designed to extract two kinds of feature maps respectively. The channel-spatial denoising branch embeds an attention module to learn feature weights and uses two-dimensional dilated convolution to improve the receptive field. The homogeneous weighted branch calculates the superpixel homogeneous, and constructs a homogeneous weight matrix to aggregate nodes. Secondly, in order to adaptively fuse these two features, a method for generating a homogeneous map is designed. Three convolution kernels are used to extract complexity features, and a coupling operator is constructed to generate a homogeneous map so that the complexity of different regions can be quantified more accurately as weights. Finally, a fusion operator is designed at the end of the mixed convolutional network to realize the fusion of fine features and heterogeneous features, which generates the final feature map, and the feature map is classified through the fully connected layer. The experimental results on three different datasets with seven state-of-the-art methods show that the proposed HM-MCN achieves higher classification performance on polarimetric SAR classification.},
  archive      = {J_ASOC},
  author       = {Ronghua Shang and Mingwei Hu and Keyao Zhu and Jinhong Ren and Jie Feng},
  doi          = {10.1016/j.asoc.2025.114020},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114020},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Mixed convolutional network via homogeneity map guided adaptive fusion for polarimetric SAR image classification},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficient multiple density-based models over large datasets with data stream applications. <em>ASOC</em>, <em>186</em>, 114019. (<a href='https://doi.org/10.1016/j.asoc.2025.114019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density-based hierarchical clustering offers comprehensive insight into the clusters and outlier structures within datasets through density functions. These algorithms construct a hierarchical graph representation, where edges are weighted by the minimum density required for connected data points to form clusters; this density threshold depends on the minimum number of objects within a neighborhood, denoted m p t s , which acts as a smoothing parameter for the density estimate. CORE-SG, a spanning graph for the fast computation of HDBSCAN* results, allows efficient and seamless extraction of multiple hierarchical solutions with varying densities and across an arbitrary range of density smoothing levels, surpassing its predecessors in computational performance. However, much like its predecessors, CORE-SG requires neighborhood estimation based on pairwise similarity calculations that are constrained by a quadratic asymptotic complexity relative to dataset size, which can be impractical for scenarios involving large volumes of data. This paper proposes a streamlined version of CORE-SG, designed to achieve computational efficiency through data abstraction, and investigates the impact of data summarization on the quality of unsupervised hierarchical models across multiple density levels. Our goal is to improve the scalability of CORE-SG while preserving its core properties. We evaluated our approach on clustering and outlier detection tasks, comparing it to the original version. Furthermore, we adapted and evaluated its effectiveness in a data stream scenario, where data arrives continuously and indefinitely, requiring ongoing model updates. Our algorithm was benchmarked against the latest HDBSCAN*-based algorithm for data streams, demonstrating superior performance and improved clustering quality.},
  archive      = {J_ASOC},
  author       = {Natanael F.D. Batista and Bruno L. Nunes and Murilo C. Naldi},
  doi          = {10.1016/j.asoc.2025.114019},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114019},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Efficient multiple density-based models over large datasets with data stream applications},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A survey on particle swarm optimization: Evolution, adaptations and practical implementations. <em>ASOC</em>, <em>186</em>, 114016. (<a href='https://doi.org/10.1016/j.asoc.2025.114016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle Swarm Optimization (PSO) is widely recognized in the literature as a leading swarm-based algorithm. Since its inception in the mid-1990s, PSO has undergone significant advancements, including various enhancements, extensions, and modifications, particularly in the years following the turn of the century. As a result, research in this area has reached a remarkable level of sophistication. This paper presents a comprehensive and systematic review that organizes and synthesizes current knowledge on PSO. It offers an in-depth examination of the core concepts of the algorithm, neighborhood topologies, and historical and recent variants of the PSO. In addition, it highlights the significant engineering applications of PSO and discusses ongoing challenges in the field. By systematically arranging and summarizing the latest research, this review serves as a valuable resource for both researchers and practitioners interested in the development and application of PSO.},
  archive      = {J_ASOC},
  author       = {Rashmi Sharma and Jagjit Singh Matharu and Kulwinder Singh Parmar},
  doi          = {10.1016/j.asoc.2025.114016},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114016},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A survey on particle swarm optimization: Evolution, adaptations and practical implementations},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A transformer-based sequential analysis methodology for trajectory tracking at safety surveillance in manufacturing. <em>ASOC</em>, <em>186</em>, 114012. (<a href='https://doi.org/10.1016/j.asoc.2025.114012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing safety surveillance is critical to ensuring worker safety in factories. A vision-based safety surveillance solution can facilitate the monitoring of the unsafe behaviors of workers and vehicles to reduce the occurrence of incidents. However, in practice, making violation judgments involves several ambiguities, mainly due to challenges associated with judging whether workers are decelerating before reaching an intersection. To address these challenges, this study proposes a transformer-based sequential analysis algorithm for tracking the trajectories of objects passing through intersections to enhance safety surveillance in factories. The proposed algorithm extracts speed profiles from surveillance footage and uses a data preprocessing procedure that transforms the trajectory tracking task into a time-series classification problem, thus unifying behavioral analysis for both walking and driving workers. It accurately identifies stopping positions, eliminating phase differences between pedestrians and vehicles. Additionally, the proposed algorithm conducts perspective transformation to ensure fair speed calculations by allowing adjustments for camera distance. It also uses an attention mechanism to quantify the ambiguity in violation decisions to achieve automated violation detection. The proposed algorithm was validated by applying it to surveillance videos from factories to conduct safety surveillance assessments. It achieved the highest F 1 score (0.751), demonstrating its accuracy in identifying workers’ successful or unsuccessful stopping behavior at intersections. In summary, this study provides a cost-effective approach using existing cameras for comprehensive, real-time surveillance, addressing blind spots. Factory managers can transition from reactive to proactive safety in practice, thus facilitating the enforcement of environmental, safety, and health practices for worker protection.},
  archive      = {J_ASOC},
  author       = {Hwai-Jung Hsu and Che-Wei Chou and Guo-Lun Gao},
  doi          = {10.1016/j.asoc.2025.114012},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114012},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A transformer-based sequential analysis methodology for trajectory tracking at safety surveillance in manufacturing},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantum FP-growth algorithm using GPU simulation- application to digital soil mapping. <em>ASOC</em>, <em>186</em>, 114011. (<a href='https://doi.org/10.1016/j.asoc.2025.114011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel quantum version of the FP-growth algorithm for frequent itemset mining, leveraging the combined strengths of classical FP-growth and quantum machine learning. Key contributions include the theoretical and practical framework for Quantum FP-growth, along with a comprehensive analysis of its time and space complexity. We implemented Quantum FP-growth using IBM Qiskit and conducted a comparative evaluation of various quantum amplitude estimation (QAE) methods, including Canonical QAE, Faster QAE, Maximum Likelihood QAE, and Iterative QAE for support estimation. Our findings reveal that Iterative QAE surpasses the other methods in both accuracy and speed. Additionally, we explored the advantages of GPU simulation with IBM Qiskit and NVIDIA cuQuantum. Notably, this research marks the first application of a quantum frequent itemset mining algorithm to a real-world dataset in Digital Soil Mapping (DSM), pioneering the use of quantum technologies in soil science. This study underscores the potential of quantum computing to revolutionize data mining and promote sustainable soil management practices.},
  archive      = {J_ASOC},
  author       = {Widad Hassina Belkadi and Yassine Drias and Habiba Drias},
  doi          = {10.1016/j.asoc.2025.114011},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114011},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Quantum FP-growth algorithm using GPU simulation- application to digital soil mapping},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Neural network with reject option for error correction in data packets. <em>ASOC</em>, <em>186</em>, 114010. (<a href='https://doi.org/10.1016/j.asoc.2025.114010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Networks (NNs) have been applied in various fields with remarkable advancements due to their significant potential to enable new applications. The use of NNs for signal identification is becoming increasingly important for communication systems. However, current approaches involve Error-Correcting Codes (ECC) that increase the data overhead in packets to achieve better results. In this paper, we propose an error correction approach for data packets based on neural networks with reject option, which aims to correct slightly corrupted data packets. Our proposed method involves the integration of three systems: (i) an Extreme Learning Machine (ELM) neural network to mitigate the distortion that occurs in the communication channel, (ii) the Cyclic Redundancy Check (CRC) algorithm to detect packets with errors, and (iii) classification with reject option to identify and correct bit errors in data packets. Through simulations involving packets of different sizes and under various channel conditions, we evaluated the performance of our proposed method with real data for the Internet of Things (IoT) and Bluetooth Low Energy (BLE). The experimental results demonstrate its capability to effectively correct errors without the need for ECC algorithms or the addition of redundant data. Furthermore, when compared to error correction approaches using CRC, our method shows the potential to process error corrections without relying on a lookup table, and it surpasses the performance of state-of-the-art models that use statistical estimators for multiple errors.},
  archive      = {J_ASOC},
  author       = {Wellington D. Almeida and Ajalmar R. Rocha Neto},
  doi          = {10.1016/j.asoc.2025.114010},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114010},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Neural network with reject option for error correction in data packets},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Parallel chaotic bi-objective evolutionary algorithms for scalable feature subset selection via migration strategy. <em>ASOC</em>, <em>186</em>, 114009. (<a href='https://doi.org/10.1016/j.asoc.2025.114009'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature subset selection for classification is inherently a bi-objective optimization problem, where the task is to obtain a feature subset yielding maximum possible area under the receiver operating characteristic curve by minimizing cardinality. In today’s world, an humungous amount of data is generated in all human activities. To mine such voluminous data, which is often high-dimensional, there is a need to develop parallel and scalable frameworks. In the first-of-its-kind study, we proposed and developed three chaotic bi-objective evolutionary algorithms based wrappers with a migration strategy under Spark, namely, (i) parallel chaotic non-dominated sorting algorithm (P-C-NSGA-II-IS), (ii) parallel chaotic non-dominated sorting particle swarm optimization (P-C-NSPSO-IS), and (iii) parallel chaotic multi-objective evolutionary algorithm based on decomposition (P-C-MOEA/D-IS). We employed logistic map and tent map for each of the parallel chaotic algorithm. The performance of the chaotic variants is compared with their corresponding parallel, non-chaotic algorithms. Throughout the study, AUC is computed by invoking the logistic regression classifier on various datasets. The experimental results demonstrate that P-C-NSGA-II-LM-IS, P-NSPSO-IS and P-NSGA-II-IS secured top-3 in terms of mean HV and Formula 1 racing based ranking. We also presented the statistical test of significance, empirical attainment plots, speedup analysis, and mean AUC obtained by the most repeated feature subset, and diversity analysis using hypervolume.},
  archive      = {J_ASOC},
  author       = {Yelleti Vivek and Vadlamani Ravi and P. Radha Krishna},
  doi          = {10.1016/j.asoc.2025.114009},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114009},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Parallel chaotic bi-objective evolutionary algorithms for scalable feature subset selection via migration strategy},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A distributed flexible job shop scheduling problem considering rush order insertion using a two-stage memetic algorithm. <em>ASOC</em>, <em>186</em>, 114008. (<a href='https://doi.org/10.1016/j.asoc.2025.114008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To date, existing research on the distributed flexible job shop scheduling problem typically overlooks the insertion of rush orders, i.e., it is assumed that once an order starts processing, other jobs cannot be inserted. However, in actual production, with the increasing demand for multiple varieties, small batches, and personalization, order insertion has become very common. In this paper, we propose a distributed flexible job shop scheduling problem considering rush order insertion (DFJSPR) for the first time; and design a two-stage memetic algorithm (TMA) to solve the DFJSPR with the optimization objectives of minimizing the makespan, total energy consumption, and total delay of jobs. In the TMA, a four-layer encoding operator and an effective initialization method for balancing load and transportation are designed to improve the quality of initial population. Some effective crossover, mutation, and local search operators are also designed to fully exploit the algorithm's solution space as well as improve its convergence speed. Finally, a new insertion rescheduling method is presented to reduce the total delay of jobs and makespan by making full use of the machine’s idle time. Sixty DFJSPR benchmark instances are constructed, and comprehensive experiments are conducted to demonstrate the superiority of the TMA. These studies will provide a theoretical basis for practical production scheduling in distributed flexible job shops and help production decision-makers obtain optimal scheduling schemes when considering rush order insertion problems.},
  archive      = {J_ASOC},
  author       = {Dian Lu and Guiliang Gong and Zhongliang Gong and Ningtao Peng and Dan Huang and Qiang Luo and Xiaoqiang Li},
  doi          = {10.1016/j.asoc.2025.114008},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114008},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A distributed flexible job shop scheduling problem considering rush order insertion using a two-stage memetic algorithm},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PFADet: A few-shot prompt-guided fabric anomaly detection network using large vision-language models. <em>ASOC</em>, <em>186</em>, 114005. (<a href='https://doi.org/10.1016/j.asoc.2025.114005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fabric anomaly detection (FAD) is crucial in guaranteeing fabric quality and optimizing production processes. Despite the progress of fully supervised methods in FAD tasks, the scarcity of anomaly samples and the difficulty of high-quality pixel-level labeling have motivated the attention on few-shot learning. Meanwhile, Large Vision-Language Models (LVLMs) excel with strong cross-modal understanding, whereas detection accuracy and adaptability are limited in FAD due to insufficient prior knowledge and missing multimodal data. To this end, we propose a few-shot prompt-guided fabric anomaly detection network (PFADet), based on LVLMs for efficient detection and fine-grained localization. Specifically, adaptive fabric text description templates construct customized descriptions for different fabric types to achieve cross-modal feature alignment, effectively capturing the subtle differences between local and global anomaly features. Integrated Prompt Module leverages the Weight Dynamic Distribution Network (DDNet) to achieve multi-scale feature fusion, providing interpretive feedback and interactive queries that support the anomaly detection results. Additionally, combined with the improved loss function, the discrimination between normal and abnormal features is enhanced by dynamically adjusting the sample boundary weights. Extensive experiments on fabric datasets and generalization analysis on publicly available industrial benchmark datasets demonstrate that PFADet outperforms existing methods in both image-level localization and pixel-level segmentation under few-shot settings, achieving image-AUC of 98.6 %/93.0 %, pixel-AUC of 91.4 %/87.2 %, accuracy of 90.4 %/92.0 %, and F1-score of 0.4441/0.5656 on Color-F and Rollei datasets under 1-shot setting.},
  archive      = {J_ASOC},
  author       = {Xin Zhang and Junfeng Jing and Yongbo Wang},
  doi          = {10.1016/j.asoc.2025.114005},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114005},
  shortjournal = {Appl. Soft. Comput.},
  title        = {PFADet: A few-shot prompt-guided fabric anomaly detection network using large vision-language models},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel spatio-temporal adaptive network considering time-delay effect for traffic flow forecasting. <em>ASOC</em>, <em>186</em>, 114004. (<a href='https://doi.org/10.1016/j.asoc.2025.114004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of urbanization, traffic congestion has become a hot spot widely concerned by society. Effective prediction of traffic flow can help the relevant departments to regulate in advance and alleviate the problem of traffic congestion. It is worth noting that there is an interesting phenomenon in traffic scenarios: When a significant change in flow occurs at a traffic node (e.g., a junction or a stretch of road), this change does not immediately affect its neighboring nodes, but occurs with some delay. Furthermore, even nodes geographically distant can exhibit similar flow changes after some time. This time-delay phenomenon can seriously affect model predictions, but is often overlooked in existing studies. To address this problem, we propose a novel traffic flow prediction model, called Spatio-Temporal Adaptive Network Considering Time-Delay Effect (STATD). Firstly, time-delay can be classified into two main types: periodic time-delay caused by daily congestion and sudden time-delay caused by unexpected events. Secondly, the spatial features of different nodes and the temporal features filled with time-delay are modeled by a spatio-temporal attention mechanism, which enables the model to adaptively establish correlations to different nodes. Furthermore, a new time-delay reaction module is proposed to predict the sudden time-delay effect on traffic flow through the perception phase and the capturing phase. The perception phase is used to aggregate all the nodes where the abnormal event occurs, while the capturing phase is used to propagate the abnormal state to neighboring nodes, adaptively updating the traffic flow at neighboring nodes without identifying the specific event. Extensive experimental results on the four real datasets show that our model improves the mean absolute error, mean absolute percentage error, and root mean square error by about 1.21 %, 0.91 %, and 1.13 %, respectively.},
  archive      = {J_ASOC},
  author       = {Zhuang Wu and Tianqi Zhang and Yifan Li and Zhaohe Liu and Fangfang Guo and Yuanyuan Wang and Shuo Zhang and Lina Yu},
  doi          = {10.1016/j.asoc.2025.114004},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114004},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A novel spatio-temporal adaptive network considering time-delay effect for traffic flow forecasting},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep state space models for remaining useful life estimation. <em>ASOC</em>, <em>186</em>, 114003. (<a href='https://doi.org/10.1016/j.asoc.2025.114003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been used to train neural networks to estimate the Remaining Useful Life (RUL) of a machine given sensor signals from that machine. This has resulted in some accurate state-of-the-art RUL estimation models. Here we present a novel way to construct a generative model to estimate the RUL and quantify its uncertainty. It takes the form of a Linear Gaussian State Space Model (LGSSM) and is trained using the Kalman Filter; hence, uncertainty is quantified using this LGSSM instead of by other popular methods like Monte Carlo Dropout or Deep Ensembles. This means we can train by directly using the marginal log-likelihood loss and don’t require multiple samples to represent the uncertainty. However, this method is limited to using Gaussian distributions to quantify uncertainty. We avoid needing to use non-linear variants of the filter by processing the sensors using a neural network to represent noncausal sensor sequences as a “control variable” in the LGSSM. This noncausal representation is shown to be important for achieving state-of-the-art performance. The model is tested on a turbofan engine and dust filter dataset. The code can be found on GitHub. 1},
  archive      = {J_ASOC},
  author       = {Marco Star and Kristoffer McKee},
  doi          = {10.1016/j.asoc.2025.114003},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114003},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep state space models for remaining useful life estimation},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Gradual machine learning for medical image classification via evolutionary feature fusion. <em>ASOC</em>, <em>186</em>, 114002. (<a href='https://doi.org/10.1016/j.asoc.2025.114002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image classification (MIC) is a critical task in the medical imaging field. Recently, deep learning (DL) techniques, represented by convolutional neural networks (CNNs), have achieved remarkable success in MIC. However, in many medical fields, the scarcity of labeled data makes DL models highly sensitive to data distribution. Moreover, most MIC methods rely on a single DL backbone, resulting in limited robustness. To address these issues, we propose a learning paradigm that does not assume independent and identically distributed (i.i.d.) data, gradual machine learning (GML), via evolutionary feature fusion for MIC. It leverages the optimized feature vectors to construct factors for test images and iteratively labels them through factor graph inference. Specifically, we first use multiple DL backbones to extract multi-view complementary feature vectors from medical images and effectively concatenate them. We then propose a novel multi-population evolutionary algorithm (MPEA) to perform feature selection (FS) on the concatenated feature vectors, effectively removing redundant features to achieve deep fusion. Finally, GML extracts evidence factors for test images from the optimized feature vectors to facilitate gradual inference. The proposed MPEA optimizes the population initialization strategy, environmental selection strategy and evolutionary operators to enhance the efficacy of the resulting features as a mechanism for gradual inference. Extensive experiments conducted on eight medical datasets demonstrate that our method achieves higher and more stable classification performance compared to the existing SOTA methods.},
  archive      = {J_ASOC},
  author       = {Wangwang Li and Qun Chen and Fengjin Zhou},
  doi          = {10.1016/j.asoc.2025.114002},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114002},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Gradual machine learning for medical image classification via evolutionary feature fusion},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UPTM-LLM: Large language models-powered urban pedestrian travel modes recognition for intelligent transportation system. <em>ASOC</em>, <em>186</em>, 113999. (<a href='https://doi.org/10.1016/j.asoc.2025.113999'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the progression of urbanization and information technology, Intelligent Transportation Systems (ITS) are increasingly crucial for improving urban efficiency and reducing traffic congestion. A key element within ITS is Urban Pedestrian Travel Mode (UPTM) recognition, which aids traffic management through data-driven optimization and congestion mitigation. Deep learning (DL) has advanced transportation research but struggles with the complex semantics of pedestrian movement, including temporal context (e.g., peak/off-peak hours, workdays/weekends), origin-destination POI categories, and the underlying characteristics of GPS trajectories (encompassing kinematics and GIS features). The emergence of large language models (LLMs), known for their large-scale parameters and deep architectures, has enhanced the capacity to interpret such complex semantics. Leveraging this capability, we propose UPTM-LLM, a novel framework that significantly improves UPTM recognition accuracy. It integrates: (1) a temporal awareness module for interpreting time-related traits, (2) a POI Embedding Network (PEN) encoding semantic features of POIs, and (3) a Trajectory Embedding Network (TEN) extracting kinematic and GIS features. Experimental comparisons show that UPTM-LLM outperforms classical models, offering a robust solution for fine-grained UPTM recognition and contributing to more effective urban transportation analytics and planning.},
  archive      = {J_ASOC},
  author       = {Yan Li and Yang Zhan and Maohan Liang and Yu Zhang and Jinhao Liang},
  doi          = {10.1016/j.asoc.2025.113999},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {113999},
  shortjournal = {Appl. Soft. Comput.},
  title        = {UPTM-LLM: Large language models-powered urban pedestrian travel modes recognition for intelligent transportation system},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Addressing key challenges of adversarial attacks and defenses in the tabular domain: A methodological framework for coherence and consistency. <em>ASOC</em>, <em>186</em>, 113998. (<a href='https://doi.org/10.1016/j.asoc.2025.113998'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models trained on tabular data are vulnerable to adversarial attacks, even in realistic scenarios where attackers only have access to the model’s outputs. Since tabular data contains complex dependencies among features, it presents a unique challenge for adversarial samples which must maintain coherence and respect these dependencies to remain indistinguishable from benign data. Moreover, existing attack evaluation metrics—such as the success rate, perturbation magnitude, and query count—fail to account for this challenge. To address these gaps, we propose a technique for perturbing dependent features while preserving sample coherence. In addition, we introduce Class-Specific Anomaly Detection (CSAD), an effective and novel anomaly detection approach, along with concrete metrics for assessing the quality of tabular adversarial attacks. CSAD evaluates adversarial samples relative to their predicted class distribution, rather than a broad benign distribution. This ensures that subtle adversarial perturbations, which may appear coherent in other classes, are correctly identified as anomalies. We extend CSAD for importance-based anomaly detection by integrating SHAP explainability techniques to detect inconsistencies in model decision-making. Our evaluation of adversarial sample quality incorporates both anomaly detection rates and importance-based assessments to provide a more comprehensive measure. We evaluate various attack strategies, examining black-box query-based and transferability-based gradient attacks across four target classification models. Experiments on benchmark tabular datasets reveal key differences in the attacker’s risk effort and attack quality, offering insights into the strengths, limitations, and trade-offs faced by attackers and defenders. Our findings lay the groundwork for future research on adversarial attacks and defense development in the tabular domain.},
  archive      = {J_ASOC},
  author       = {Yael Itzhakev and Amit Giloni and Yuval Elovici and Asaf Shabtai},
  doi          = {10.1016/j.asoc.2025.113998},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {113998},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Addressing key challenges of adversarial attacks and defenses in the tabular domain: A methodological framework for coherence and consistency},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RL-HCP: A reinforcement learning-based heuristic controller placement algorithm for dynamic SDN environments. <em>ASOC</em>, <em>186</em>, 113997. (<a href='https://doi.org/10.1016/j.asoc.2025.113997'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-Defined Networking (SDN) enables centralized network management through programmable control planes. However, in dynamic and large-scale deployments, static controller placement strategies often lead to increased latency, limited fault tolerance, and degraded scalability. Existing heuristic methods lack adaptability, while reinforcement learning (RL)-based approaches face challenges such as slow convergence, complex state representations, and poor generalization. To address these limitations, this paper proposes RL-HCP: a Reinforcement Learning-based Heuristic Controller Placement framework designed for real-time and scalable controller deployment in dynamic SDN environments. RL-HCP integrates domain-specific heuristics into the RL training loop to guide action selection, reduce convergence time, and improve decision quality. The framework models the Controller Placement Problem (CPP) as a Markov Decision Process (MDP) and employs a Dueling Double Deep Q-Network (DDDQN) with heuristic-enhanced reward shaping and action space pruning. A dynamic reconfiguration module enables real-time adaptation to traffic fluctuations, link failures, and topology changes, while minimizing switch migration overhead. Experimental evaluation across diverse topologies—including Fat-tree, Barabási–Albert, and Random Graphs—demonstrates that RL-HCP outperforms traditional heuristics and state-of-the-art RL methods in latency, load balancing, reactivity, and scalability. The framework achieves faster convergence, maintains performance under dynamic conditions, and generalizes well to large-scale networks with up to 1000 nodes. These results highlight RL-HCP’s potential as a robust and intelligent solution for controller placement in next-generation SDN infrastructures.},
  archive      = {J_ASOC},
  author       = {Anil Ram and Swarnendu Kumar Chakraborty and Uddalak Chatterjee},
  doi          = {10.1016/j.asoc.2025.113997},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {113997},
  shortjournal = {Appl. Soft. Comput.},
  title        = {RL-HCP: A reinforcement learning-based heuristic controller placement algorithm for dynamic SDN environments},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A hierarchical collaborative multi-agent deep reinforcement learning framework for distributed flexible job shop scheduling problems considering energy efficiency and dynamic disruption in IIoTs. <em>ASOC</em>, <em>186</em>, 113992. (<a href='https://doi.org/10.1016/j.asoc.2025.113992'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the paradigm shift toward industrial intelligence-enabled flexible manufacturing systems (FMS), real-time scheduling for the distributed flexible job shop problems (DFJSP) with dynamic disruptions and energy efficiency has attracted increasing interest. In this study, the DFJSP with energy efficiency and dynamic disruption (DFJSP_ED) is investigated, with the objective of minimizing total tardiness. First, a mixed integer linear programming (MILP) model is established to formally characterize the mathematical properties of DFJSP_ED, along with a hierarchical collaborative multi-agent deep reinforcement learning (HCMARL) framework designed to address this highly coupled scheduling problem. The HCMADRL framework comprises of two collaborative agents: An Assigning Agent (AA) and a Scheduling Agent (SA). The AA is dedicated to dynamically assigning jobs to suitable factories according to the unallocated job set and the real-time status of each factory. The SA handles specific job scheduling tasks. Upon the arrival of a new job, the SA conducts prescheduling, updates factory states, and passes states to the AA. After aggregating the updated status information of all factories, the AA reassigns the remaining unallocated jobs based on the global states. Two agents interact and make collaborative decisions based on preset priority rules. The SA performs scheduling actions only after the AA finishes job allocation. Conversely, the AA’s decisions are highly dependent on the real-time state information provided by the SA. Second, a two-stage double deep Q -network (TSDDQN) algorithm is proposed to train the HCMARL framework. Furthermore, a tardiness-based speed adjustment strategy (TSAS) is introduced to account for potential delays. This strategy reduces energy consumption without increasing the original delay value. Finally, the accuracy of the MILP model is validated via the Gurobi solver and compared against the TSDDQN algorithm. The effectiveness of the TSDDQN is further verified through multi-scenario testing experiments and statistical comparisons against composite scheduling rules (CDR), priority scheduling rules (PDR), reinforcement learning based algorithms, and metaheuristic algorithms. The results demonstrate that TSDDQN surpasses all baseline methods across all evaluation metrics, exhibiting superior performance and robustness. Additionally, practical case validation reveals that TSDDQN achieves lower tardiness values (yielding an approximate 4 % performance improvement) compared to the current best-performing PDRs, confirming its strong practicality in real-world manufacturing environments.},
  archive      = {J_ASOC},
  author       = {Zi-Qi Zhang and Ming-Huang Fang and Bin Qian and Rong Hu and Wei Chen},
  doi          = {10.1016/j.asoc.2025.113992},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {113992},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A hierarchical collaborative multi-agent deep reinforcement learning framework for distributed flexible job shop scheduling problems considering energy efficiency and dynamic disruption in IIoTs},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-source strategy adaptation network for time-triggered flow scheduling in unknown environments. <em>ASOC</em>, <em>186</em>, 113988. (<a href='https://doi.org/10.1016/j.asoc.2025.113988'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional Ethernet, based on event-triggered scheduling, often suffers from resource contention, queuing delays, and jitter, which can degrade the efficiency and sustainability of modern engineering systems under dynamic environmental conditions. Time-triggered (TT) mechanisms–such as those in Time-Triggered Ethernet (TTE) and Time-Sensitive Networking (TSN)–address these limitations by enabling precise scheduling of data flows, thereby ensuring high predictability and real-time performance. These capabilities are essential in safety-critical domains including aerospace, smart grids, and industrial automation. However, generating a static schedule table (SST) for TT flows is an NP-hard problem. While Deep Reinforcement Learning (DRL) has shown promise in handling large-scale TT scheduling, its high training overhead limits applicability in time-sensitive and resource-constrained environments. To overcome this challenge, we propose the Multi-Source Strategy Adaptation Network (MSAN), a soft computing framework that integrates multiple DRL agents for collaborative decision-making and adaptive exploration. MSAN accelerates training convergence, balances exploration and exploitation more effectively, and demonstrates improved scalability–with training time growing nearly linearly with the number of TT flows. Extensive experiments across diverse network topologies and unseen test environments demonstrate that MSAN finds feasible scheduling solutions significantly faster than conventional DRL approaches. The results highlight its potential for rapid adaptation, reduced computational cost, and enhanced support for sustainable engineering practices through intelligent soft computing. Our codes are available at: https://github.com/CodeZenTao/MSAN .},
  archive      = {J_ASOC},
  author       = {Wentao Zhang and JunSheng Wu and Anrong Zhao and Qunbo Wang and Changsheng Chen and Tao Zhang and Peng Zhang},
  doi          = {10.1016/j.asoc.2025.113988},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {113988},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-source strategy adaptation network for time-triggered flow scheduling in unknown environments},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SiamWT-CRNet: A siamese wavelet network with cross-domain feature fusion for dynamic coal-rock recognition in top-coal caving systems. <em>ASOC</em>, <em>186</em>, 113984. (<a href='https://doi.org/10.1016/j.asoc.2025.113984'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the limitations of traditional deep learning methods due to strong data dependency and insufficient interpretability when recognizing “under-releasing" and “over-releasing" phenomena during top-coal caving in longwall mining, this study proposes an intelligent recognition framework, SiamWT-CRNet, based on joint time-frequency domain analysis of vibration signals. It leverages wavelet-domain Siamese network architecture combined with a cross-wavelet feature enhancement mechanism to achieve high-precision dynamic identification of the coal-rock interface. It introduces a cross-scale feature fusion strategy based on multi-family wavelet bases, constructing a physically interpretable enhanced feature space through heterogeneous wavelet decomposition. A lightweight Siamese wavelet convolution module, ECWT, is designed to integrate recursive wavelet decomposition with an improved attention mechanism, enabling focused extraction of critical frequency-band features while reducing parameter complexity. Furthermore, a cross-wavelet contrastive learning paradigm is adopted, where a dual-branch network is employed to mine the intrinsic differential features of coal and rock vibration signals. This is coupled with a hard-voting classifier to achieve efficient decision-making. Experimental results demonstrate that the proposed method significantly outperforms traditional models in terms of recognition robustness under strong noise interference. Moreover, the decision-making mechanism has been validated through frequency-domain interpretability analysis, aligning well with engineering expertise.},
  archive      = {J_ASOC},
  author       = {Faming Lu and Yi Liu and Zedong Lin and Xiangqi Han and Cong Liu},
  doi          = {10.1016/j.asoc.2025.113984},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {113984},
  shortjournal = {Appl. Soft. Comput.},
  title        = {SiamWT-CRNet: A siamese wavelet network with cross-domain feature fusion for dynamic coal-rock recognition in top-coal caving systems},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rethinking unsupervised time series anomaly detection: Dynamic attention based on route inverse-masking. <em>ASOC</em>, <em>186</em>, 113971. (<a href='https://doi.org/10.1016/j.asoc.2025.113971'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised time series anomaly detection holds significant importance for the development of modern industries. Hard-to-Detect Time series Anomalous points (HDTA) represent a core challenge in this field. Existing methods show limited effectiveness in handling subtle fluctuation anomalies and fail to fully exploit the periodic characteristics of time series. This paper proposes a R oute Inverse- M asking D ynamic A ttention (RMDA) framework for anomaly detection. The core innovations of RMDA include: designing a dynamic routing mechanism that identifies strongly correlated regions based on statistical differences in attention weight distributions, proposing an inverse masking strategy that amplifies discriminative capability by exploiting the difference between periodicity in normal points and non-periodicity in anomalous points, and constructing a normal-abnormal amplifier that enhances anomaly features by filtering out low-fluctuation regular components. This method establishes a new anomaly detection criterion based on periodic differences in attention distributions. Extensive experiments on four benchmark datasets demonstrate that RMDA reduces F1-score error rates by 14.52 %, 23.33 %, 35.45 %, and 7.82 % on MSL, SMAP, PSM, and SMD datasets respectively compared to state-of-the-art methods, significantly improving HDTA detection performance.},
  archive      = {J_ASOC},
  author       = {Enguang Zuo and Jie Zhong and Chen Chen and Cheng Chen and Kurban Ubul and Xiaoyi Lv},
  doi          = {10.1016/j.asoc.2025.113971},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {113971},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Rethinking unsupervised time series anomaly detection: Dynamic attention based on route inverse-masking},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
