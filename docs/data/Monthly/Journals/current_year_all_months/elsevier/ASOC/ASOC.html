<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ASOC</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="asoc">ASOC - 47</h2>
<ul>
<li><details>
<summary>
(2026). Metaheuristic-driven feature selection with dual feedback mechanisms for imbalanced cancer classification. <em>ASOC</em>, <em>186</em>, 114110. (<a href='https://doi.org/10.1016/j.asoc.2025.114110'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inherent complexity of high-dimensional, imbalanced microarray cancer data presents two major challenges: redundant features that obscure biomarkers, and skewed distributions that impair model generalizability. To address these issues, this study proposes DVFF (Double Value Feedback Framework), a novel bacterial heuristic-based feature selection method designed to simultaneously reduce dimensionality and mitigate class imbalance through three key innovations. First, it employs a borderline-sensitive fitness function that dynamically adjusts class boundaries using local density information, prioritizing discriminative features near class margins to reduce information loss. Second, a dual-phase feedback mechanism integrates progressive feature pruning via threshold learning with real-time population diversity monitoring, enabling efficient exploration of feature subspaces while preserving representative subsets. Third, a probabilistic multi-division iteration strategy facilitates concurrent exploration of diverse feature subsets using subpopulations with adaptive thresholds and varying lengths, significantly improving search coverage. Extensive experiments on 14 microarray datasets (ranging from 2000 to 10,000 features with imbalance ratios between 1.4 and 20) show that DVFF outperforms six state-of-the-art methods, achieving over 15 % improvement in macro-F1, faster convergence, and feature subsets smaller than 10 % of the original size. Statistical tests confirm significantly enhanced class separation in the reduced feature space, demonstrating DVFF’s effectiveness in addressing both high dimensionality and class imbalance in microarray cancer data.},
  archive      = {J_ASOC},
  author       = {Chen Yang and Jie Peng and Tongtong Xing and Hong Wang and Ben Niu},
  doi          = {10.1016/j.asoc.2025.114110},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114110},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Metaheuristic-driven feature selection with dual feedback mechanisms for imbalanced cancer classification},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Driver fatigue detection using EEG-based graph attention convolutional neural networks: An end-to-end learning approach with mutual information-driven connectivity. <em>ASOC</em>, <em>186</em>, 114097. (<a href='https://doi.org/10.1016/j.asoc.2025.114097'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to driver-specific and vehicle-specific characteristics, physiological signal features exhibit superior efficacy in detecting driver fatigue, particularly electroencephalogram (EEG) signals, which are less influenced by subjective human factors and directly reflect brain neural activity. Currently, many detection methods primarily focus on the analysis of EEG signals but fail to consider the interdependencies between signal acquisition channels. To improve the accuracy of driver state detection, a Graph Attention Convolutional Neural Network (GAT-CNN) is proposed in this study. The method incorporates channel relationships and performs an end-to-end learning process, which eliminates the need for manual feature extraction. The preprocessed EEG signals and the adjacency matrix based on mutual information serving as the input to the GAT-CNN. Finally, the EEG signals are classified into two states namely alert and fatigued by fully connected layers and a softmax classification layer. The performance of the method is validated on the SEED-VIG dataset with an average accuracy of 90.14 %, a peak accuracy of 99.23 % and an average F1 score of 91.54 %. Additionally, the Brier Score, used as an evaluation metric, yields an average value of 0.0841, which indicates high predictive accuracy and strong generalization ability. Compared to existing state-of-the-art methods, the GAT-CNN demonstrates superior performance.},
  archive      = {J_ASOC},
  author       = {Jichi Chen and Yuguo Cui and Chunfeng Wei and Kemal Polat and Fayadh Alenezi},
  doi          = {10.1016/j.asoc.2025.114097},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114097},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Driver fatigue detection using EEG-based graph attention convolutional neural networks: An end-to-end learning approach with mutual information-driven connectivity},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Chaotic dual-feature graph convolutional network (CDF-GCN) for traffic speed forecasting. <em>ASOC</em>, <em>186</em>, 114096. (<a href='https://doi.org/10.1016/j.asoc.2025.114096'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic speed forecasting uses graph data to simulate real-time traffic’s chaotic and nonlinear nature conditions in smart cities are crucial tasks in Intelligent Transportation System (ITS). But there are two challenges: 1) current research on single direction features to capture correlations across all nodes hinder to extract bidirectional interactions of global feature dependencies 2) spatial and temporal data are handled with two distinct modules for each feature neglect their inherent dynamic relationships with anomaly i.e. traffic accidents. This paper proposes an innovative Chaotic Dual-Feature Graph Convolution Network (CDF-GCN) model which integrates self-features to enhance temporal periodic patterns characteristics, and neighbor-features with chaotic spatial features for accurate traffic speed forecasting. It is motivated by the backpropagation mechanism and Lee oscillator with retrograde signaling (LORS) for chaos state control and retrograde signal tracking, to oscillate the weight projection in bidirectional states for adjacency matrix and time-series feature matrix updates, and to simplify the flow of bidirectional information through simulated nonlinear diffusion relationships. Experimental results show that CDF-GCN outperforms other GNN baselines and state-of-the-art models on six real-world traffic datasets for speed detection and route planning, notably up to 80 % improvement over traditional GCN evaluated by MAE, RMSE and MAPE.},
  archive      = {J_ASOC},
  author       = {Nuobei Shi and Haoyuan Chen and Ling Chen and Raymond S.T. Lee},
  doi          = {10.1016/j.asoc.2025.114096},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114096},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Chaotic dual-feature graph convolutional network (CDF-GCN) for traffic speed forecasting},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-period scheduling and fleet management in agricultural production logistics: A novel reinforcement learning approach. <em>ASOC</em>, <em>186</em>, 114084. (<a href='https://doi.org/10.1016/j.asoc.2025.114084'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient scheduling and fleet management are essential for optimizing agricultural production logistics, particularly in sugarcane bale operations, which involve complex, large-scale activities. However, most existing studies rely on static or single-period models that assume homogeneous fleets and fixed schedules, while overlooking essential factors such as machine breakdowns, setup times, and time-varying resource availability. These traditional deterministic or heuristic approaches often lack the adaptability needed to handle real-time disturbances and dynamic operating conditions. To address these challenges, this study introduces a novel optimization framework that integrates Reinforcement Learning (RL) with the Artificial Multiple Intelligence System (AMIS). The proposed approach is specifically designed to handle multi-period scheduling and heterogeneous fleet management, offering a robust and scalable solution for complex agricultural logistics systems. What distinguishes this framework is its hybrid mechanism: AMIS is used to generate diverse initial solutions, while mathematically derived improvement equations—drawn from various metaheuristics—are applied to refine those solutions. These improvement equations function independently across iterations and solutions, enhancing both local exploration and global search capabilities. RL is then employed to intelligently select the most effective improvement methods based on historical performance, allowing the system to adaptively discover optimal solution pathways over time. When implemented in a real-world sugarcane bale logistics scenario, the framework delivered notable economic benefits—reducing logistics costs by 25 % and increasing operational profit by 10.83 % compared to conventional methods. These outcomes are attributed to the framework’s ability to dynamically learn and refine its search strategies for optimal performance. The findings offer important contributions to production economics. First, they demonstrate how intelligent optimization can significantly enhance resource utilization and cost efficiency in agricultural operations. Second, the framework establishes a scalable solution for complex, multi-period scheduling that remains effective across varying production contexts. Third, it presents a novel integration of machine learning and traditional optimization, setting a foundation for future advances in smart agricultural logistics. Together, these contributions strengthen both theoretical insights and practical applications in the field of agricultural production management.},
  archive      = {J_ASOC},
  author       = {Kanchana Sethanan and Rapeepan Pitakaso and Chettha Chamnanlor and Kuo-Jui Wu},
  doi          = {10.1016/j.asoc.2025.114084},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114084},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-period scheduling and fleet management in agricultural production logistics: A novel reinforcement learning approach},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A two-stage symbolic regression method for discovering mathematical formulas. <em>ASOC</em>, <em>186</em>, 114081. (<a href='https://doi.org/10.1016/j.asoc.2025.114081'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a two-stage symbolic regression method with hybrid optimization for discovering mathematical formulas. Unlike existing approaches such as genetic programming, which attempt to optimize both model structure and parameters simultaneously, the proposed method decouples the process into two distinct stages. In the first stage, a genetic algorithm is employed to generate a diverse and high-quality pool of candidate terms from the given variables and operators. In the second stage, simulated annealing (SA) and a reinforcement learning-enhanced SA (RLSA) method are jointly utilized to solve a subset selection problem—aiming to identify the optimal subset of terms that best fit an equation via linear regression. The effectiveness of the proposed method was evaluated on five benchmark datasets comprising 56 widely used instances. Experimental results show that our method consistently outperforms five state-of-the-art baselines in accurately recovering ground-truth formulas. Furthermore, in a case study on triangle area formula discovery, the proposed method successfully identified 295 valid formulas, surpassing the 251 known formulas reported in the literature. These findings suggest that the proposed hybrid optimization design, leveraging the complementary strengths of different metaheuristics, is well-suited for navigating complex search spaces and achieving competitive performance in symbolic regression tasks.},
  archive      = {J_ASOC},
  author       = {Zeyu Zeng and Xicheng Peng and Mao Chen and Sannyuya Liu},
  doi          = {10.1016/j.asoc.2025.114081},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114081},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A two-stage symbolic regression method for discovering mathematical formulas},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Subpixel attention and frequency-domain cross modulation network for multimodal remote sensing image classification. <em>ASOC</em>, <em>186</em>, 114073. (<a href='https://doi.org/10.1016/j.asoc.2025.114073'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multimodal remote sensing image classification, limited spatial resolution often leads to blurred boundaries and unclear land cover distributions. Although subpixel features can compensate for missing spatial details, subpixel decomposition results may contain noise or heterogeneous components, and the feature distribution is relatively scattered and has potential redundancy that affects model performance. Additionally, current fusion methods between hyperspectral image (HSI) and LiDAR data typically rely on simple weighted superposition in the frequency domain, failing to achieve explicit interaction. To address these issues, this paper proposes a subpixel attention and frequency-domain cross modulation network (SA-FCM) for multimodal remote sensing image classification. First, a subpixel attention aggregation (SAA) module is designed to extract discriminative subpixel features by leveraging subpixel convolution and attention mechanisms, effectively reducing redundancy and enhancing feature representation. Second, a frequency-domain cross modulation (FCM) module is designed to explicitly fuse HSI and LiDAR features by crosswise combining the amplitude and phase information of HSI and LiDAR data, thereby bridging the gap between spectral and geometric information. Extensive experiments demonstrate that our proposed SA-FCM model, using a simple and efficient dual-branch structure, outperforms the state-of-the-art methods for comparison, with improvement of overall accuracy up to 19.18 percentage points.},
  archive      = {J_ASOC},
  author       = {Yi Liu and Jiajie Feng and Caihong Mu and Xinyu He},
  doi          = {10.1016/j.asoc.2025.114073},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114073},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Subpixel attention and frequency-domain cross modulation network for multimodal remote sensing image classification},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A transformer-based dual-branch feature extraction for printed circuit board defect detection with enhanced spatial attention mechanism. <em>ASOC</em>, <em>186</em>, 114072. (<a href='https://doi.org/10.1016/j.asoc.2025.114072'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integrity of Printed Circuit Boards (PCBs) is critical to the performance and reliability of electronic devices. However, existing deep learning-based detection methods often struggle to accurately identify small and complex defects in challenging industrial environments, primarily due to their inability to effectively model irregular defect morphologies, sensitivity to background noise, insufficient multi-scale feature fusion, and difficulties in achieving efficient detection under limited computational resources. To address these issues, we propose a novel object detection framework based on YOLOv8, which integrates a dual-branch feature extraction module, a deformable attention mechanism, and an enhanced spatial attention head. Specifically, we design a Dual-Transformer downsampling module that effectively captures both global context and local details of PCB defects. We also introduce a deformable attention mechanism into the C2f module to handle irregular defect shapes adaptively. Furthermore, we propose a lightweight detection head that employs multi-scale spatial attention and depthwise separable convolutions to enhance feature representation while reducing computational cost. To improve the localization accuracy of small defects, we introduce a new loss function that combines Normalized Wasserstein Distance with Wise-IoUv3. Extensive experiments on the publicly available PKU-Market-PCB dataset demonstrate that YOLO-DTS achieves a precision of 88.4 %, a recall of 69.9 %, and an m A P 50 of 77.5 %, outperforming the baseline YOLOv8 by 4.9 %, 7.5 %, and 7.5 %, respectively. The parameters used have been reduced by 13.4 % compared to the baseline model. Additional experiments on DeepPCB and aluminum profile defect datasets further validate the strong generalization capability of our method. The results indicate that YOLO-DTS is a robust and efficient solution for PCB defect detection in real-world industrial scenarios.},
  archive      = {J_ASOC},
  author       = {Yufeng Ou and Chia-Hung Wang},
  doi          = {10.1016/j.asoc.2025.114072},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114072},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A transformer-based dual-branch feature extraction for printed circuit board defect detection with enhanced spatial attention mechanism},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Modified genetic algorithms for constructing new quaternary hermitian LCD codes. <em>ASOC</em>, <em>186</em>, 114071. (<a href='https://doi.org/10.1016/j.asoc.2025.114071'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose two systematic methods for an efficient construction of quaternary Hermitian linear complementary dual (LCD) codes using two algorithms, called Iteration Search Algorithms I and II, which are modified genetic algorithms . Our algorithms include operators such as mutation, crossover, modified crossover, and complement to make the search space more effective. Using our algorithms, we obtain many new quaternary Hermitian LCD codes with best known minimum distances, including at least 133 such codes with several parameters, which are verified to be inequivalent to the currently known codes. Our methods demonstrate significantly efficient complexity in finding quaternary Hermitian LCD codes, contributing to the expansion of the current database for quaternary Hermitian LCD codes.},
  archive      = {J_ASOC},
  author       = {Byung-Sun Won and Jon-Lark Kim and Yoonjin Lee},
  doi          = {10.1016/j.asoc.2025.114071},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114071},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Modified genetic algorithms for constructing new quaternary hermitian LCD codes},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A scalable AI-driven approach for burned-area mapping using U-net and landsat imagery. <em>ASOC</em>, <em>186</em>, 114070. (<a href='https://doi.org/10.1016/j.asoc.2025.114070'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring wildfires is essential to mitigating their widespread environmental, economic, and social impacts. Recent advances in remote sensing technology, combined with the growing use of artificial intelligence, have significantly enhanced the ability to perform real-time, high-resolution fire monitoring. Motivated by the limitations of traditional methods in dealing with spatial heterogeneity and class imbalance, this study proposes two scalable, AI-based approaches built on the U-Net convolutional neural network for automated burned-area segmentation using multispectral Landsat imagery. We present two model variants: the 128-Crop approach, which processes fixed-size image patches, and the AllSizes (AS) strategy, which uses variable-sized crops to improve contextual understanding and dataset balance. Both models are trained on time-series Landsat imagery from two fire-prone regions in Chile—Biobío and Valparaíso—using pre- and post-fire composites along with high-resolution fire scar labels. The training pipeline includes preprocessing, data augmentation, and hyperparameter optimization, employing Dice Loss to address class imbalance. A quantitative evaluation on 195 representative test images shows that the AS model outperforms the 128-Crop variant, achieving a Dice Coefficient (DC) of 0.93, an Omission Error (OE) of 0.086, and a Commission Error (CE) of 0.045, while the 128-Crop model reached DC = 0.86, OE = 0.12, and CE = 0.12. Additionally, a QGIS plugin named “FireScar-Mapper-Plugin” has been developed to enable user-friendly access and integration of the models. The plugin supports batch processing of new imagery and is designed for non-programmers, enhancing the framework’s scalability and applicability for large-scale wildfire monitoring and management across diverse regions. These contributions—combining a novel scalable U-Net strategy with an open-source QGIS implementation—make this study a distinctive step toward practical, automated burned-area mapping.},
  archive      = {J_ASOC},
  author       = {Ian Mancilla-Wulff and Diego Terán and Carla Vairetti and José Ramón González-Olabarria and Andrés Weintraub and Jaime Carrasco-Barra},
  doi          = {10.1016/j.asoc.2025.114070},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114070},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A scalable AI-driven approach for burned-area mapping using U-net and landsat imagery},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A sequential flow UNet for MRI brain tumor segmentation based on state-space-model. <em>ASOC</em>, <em>186</em>, 114069. (<a href='https://doi.org/10.1016/j.asoc.2025.114069'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation of brain tumors is one of the most extensively discussed challenges in medical image processing, aiming to differentiate various tumor regions from background regions in MRI scans. While UNet and its variants have demonstrated exceptional performance in 2D and 3D image segmentation, existing methods often neglect the temporal sequence associations between brain tumor MRI slices, which contain crucial information about lesion characteristics. To address this limitation, we propose the SF-SSM UNet (Sequential Flow State Space Model UNet), featuring the Sequential Flow Selective Scanning Module Group (SF-SSM Group). Our approach transcends traditional 2D and 3D models by treating MRI brain tumor slices as serialized image flow inputs. In the SF-SSM UNet, sequence flow is constructed through feature dimensional rearrangement, and Mamba SSM is applied across both sequence and channel dimensions, enabling the model to effectively capture temporal dependencies and feature interactions between slices. We further introduce the Shuffled-Ordered Sequential Flow Training Strategy (SOSF), a Fourier transform-based approach that enhances sequential feature learning and evaluates fine-grained performance using Frequency-domain Mean Error Ratio (FMER) and Frequency-domain Mean Error Number (FMEN). Experiments on BraTS-2019 show that SF-SSM UNet achieves Dice scores of 88.45, 90.55, and 91.44 for WT, TC, and ET regions, respectively, with corresponding Hausdorff95 distances all below 1.3. On MSD Task01, it further attains Dice scores of 89.26, 88.74, and 90.35. These results demonstrate clear performance gains across multiple benchmarks, establishing SF-SSM UNet as a state-of-the-art approach for sequential medical image segmentation.},
  archive      = {J_ASOC},
  author       = {Jiacheng Lu and Hui Ding and Qirun Huo and Kaiwen Wang and Xinyu Sun and Shiyu Zhang},
  doi          = {10.1016/j.asoc.2025.114069},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114069},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A sequential flow UNet for MRI brain tumor segmentation based on state-space-model},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multiscale convolutional attention transformer based on transfer learning for temperature forecasting of ultra-supercritical coal-fired power plant reheater. <em>ASOC</em>, <em>186</em>, 114068. (<a href='https://doi.org/10.1016/j.asoc.2025.114068'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate reheater temperatures can help ultra-supercritical coal-fired power plants improve power generation efficiency and security. To ensure the efficient and safe operation of reheaters, this study proposes multi-scale convolutional attention Transformer (MSCAT) model based on transfer learning, for online incremental prediction. After offline training, the trained model parameters are fed into the online MSCAT through transfer learning, and combined with incremental learning for online multi-step forecasting. Considering the delayed nature of the reheater temperature change, this study applies mutual information to determine the delay time of the reheater temperature. MSCAT efficiently extracts global and local features in reheater temperature by multi-scale convolutional attention. By parameter fine-tuning strategies for transfer learning, the MSCAT can be quickly and directly applied in online temperature forecasting for new reheaters without retraining again. Incremental learning solves the problems of not adapting to new data when online forecasting and forgetting previous knowledge when learning new knowledge. The proposed delayed MSCAT achieves mean squared error (MSE), root mean squared error (RMSE), mean absolute error (MAE), mean absolute percentage error (MAPE), and R² of 15.61, 3.95, 2.64, 0.44 %, and 0.92, respectively, on offline data. For online prediction, the proposed MSCAT achieves MSE, RMSE, MAE, MAPE, and R² of 18.2, 4.27, 3.25, 0.54 %, and 0.87, respectively. Thus, the proposed MSCAT shows excellent online prediction performance, meeting the requirements for practical applications.},
  archive      = {J_ASOC},
  author       = {Linfei Yin and Hang Zhou},
  doi          = {10.1016/j.asoc.2025.114068},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114068},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multiscale convolutional attention transformer based on transfer learning for temperature forecasting of ultra-supercritical coal-fired power plant reheater},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). An integrated fuzzy decision model for potential digital transformation overcoming circular food consumption and production promotion. <em>ASOC</em>, <em>186</em>, 114067. (<a href='https://doi.org/10.1016/j.asoc.2025.114067'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital transformation is being increasingly acknowledged as a pivotal strategy for fostering the circular economy in the realm of food consumption and production. Previous studies focus on revealing the effect of digital transformation on implementing circular economy within food supply chain sector, however, a gap remains in understanding the comprehensive potential of digital transformation overcoming circular consumption and production (CFCP) promotion. This concerns the scalability of the digital transformation and the expansion of CFCP. Thus, this work introduces a comprehensive evaluation framework that integrates various advantages of digital transformation along with barriers derived from the Technology-Organization-Environment (TOE) theory. To measure the significance of these barriers, an extended picture q-rung orthopair fuzzy sets (PqROFSs) based-Cronbach’s coefficient, combined with weighted Heronian mean aggregation operator, is utilized to determine the barrier weights, considering the uncertain conditions and interdependent relationships. After that, through the integration of PqROFSs, the Cronbach’s coefficient, and CoCoSo’B, this framework offers a quantifiable utility index for assessing the potential of digital transformation advantages. Upon applying this framework to an illustrative example, the findings suggest that the advantage, namely “Predicting food demand accurately”, with a utility index of 1.7618, exhibits the greatest potential for overcoming the identified barriers. A validation test, comprising sensitivity and comparison studies, is conducted to assess the reliability of the evaluation framework. The findings of this research are expected to be advantageous for relevant stakeholders in implementing effective digital advantage construction strategies and resource orchestration methods, thereby facilitating the promotion of CFCP models. From a theoretical perspective, employing this framework can enhance our comprehension of digitalization as a driving force for adopting CFCP practices.},
  archive      = {J_ASOC},
  author       = {Yu Chen and Weizhong Wang and Muhammet Deveci and Zelin Wang and Huiqin Xiong and Jurgita Antucheviciene},
  doi          = {10.1016/j.asoc.2025.114067},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114067},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An integrated fuzzy decision model for potential digital transformation overcoming circular food consumption and production promotion},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The effect of elitist fitness-based selection on the escape from local optima. <em>ASOC</em>, <em>186</em>, 114066. (<a href='https://doi.org/10.1016/j.asoc.2025.114066'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random Search is the baseline that a metaheuristic must improve upon to be worth its added complexity. Random Search, in the form of Hill Climbing, cannot escape from local optima. A key claim of many metaheuristics is that they are able to escape from local optima. However, these claims are poorly tested and often based on imprecise definitions of what it means to escape from a local optimum in continuous domain search spaces. A practical and precise definition for an escape from a local optimum is developed. It is then shown how elitist fitness-based selection can lead to the rejection of exploratory search solutions, and this can cause many popular metaheuristics to degrade into (localized) Random Search in their attempts to escape from local optima. The explosion of new metaheuristics has often been just a repeated re-invention of localized Random Search for the key task of escaping from local optima.},
  archive      = {J_ASOC},
  author       = {Stephen Chen},
  doi          = {10.1016/j.asoc.2025.114066},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114066},
  shortjournal = {Appl. Soft. Comput.},
  title        = {The effect of elitist fitness-based selection on the escape from local optima},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Representation embedded learning via autoencoder for large-scale multi-objective optimization. <em>ASOC</em>, <em>186</em>, 114065. (<a href='https://doi.org/10.1016/j.asoc.2025.114065'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing studies for large-scale multi-objective optimization problems (LSMOPs) mainly focus on the search mechanism in the decision space, while often overlooking the population distribution in the objective space. This can limit the ability to guide the search process toward promising regions, thereby reducing the algorithm’s search efficiency and the quality of the solution set. Based on these observations, this paper proposes a Representation Embedded Learning via Autoencoders (RELA) algorithm to enhance the targeted evolution process for solving LSMOPs. Firstly, a representation embedding learning strategy is proposed, which clusters populations into different sub-populations according to their distribution in the objective space, and uses the non-dominated solution sets of the sub-populations to train autoencoders. The strategy can learn the latent representations from intra and inter sub-populations in the objective space, which implicitly realizes the information exchange and knowledge sharing across sub-populations. Secondly, an encoding reconstruction strategy is proposed to further fuse the embedded representations of different sub-populations, and then map them back to the decision space through the solution set reconstruction strategy to generate a higher-quality solution set to guide the evolutionary process of the population. Finally, two offspring generation strategies are proposed to balance convergence and diversity. Extensive experiments are conducted on two LSMOP benchmark suites (up to 5000 decision variables) and a real-world problem. Statistical tests show that the proposed RELA outperforms several state-of-the-art algorithms, and achieves the best performance on 39 and 40 out of 54 test problems in terms of inverted generational distance and hypervolume, respectively.},
  archive      = {J_ASOC},
  author       = {Xia Wang and Hongwei Ge and Zhi Zheng and Yaqing Hou and Jiancheng Tong and Mengyue Wang and Guozhi Tang},
  doi          = {10.1016/j.asoc.2025.114065},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114065},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Representation embedded learning via autoencoder for large-scale multi-objective optimization},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Class-conditional unbiased loss for single-positive multi-label learning. <em>ASOC</em>, <em>186</em>, 114064. (<a href='https://doi.org/10.1016/j.asoc.2025.114064'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of multi-label learning, the high cost of annotation remains an unavoidable challenge in the development of machine learning. To address the critical issue of difficulty in collecting complete labels, this paper investigates the Single-Positive Multi-Label (SPML) learning paradigm, which requires only one relevant label to be annotated for each sample. Previous studies have demonstrated that the SPML framework can significantly reduce supervision requirements while maintaining acceptable performance levels. However, existing methods have neither proposed unbiased loss functions nor provided corresponding theoretical guarantees. To this end, this paper introduces two corrected and improved unbiased loss functions based on two typical multi-label loss functions, along with rigorous theoretical proofs. Furthermore, by leveraging the global high-rank property of multi-label matrices, the proposed method effectively captures label correlations. Experimental results on three image datasets and three multi-label benchmark datasets demonstrate that the proposed method exhibits significant performance advantages compared to existing SPML techniques.},
  archive      = {J_ASOC},
  author       = {Xinpei Su and Zhuojun Han and Yitian Xu},
  doi          = {10.1016/j.asoc.2025.114064},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114064},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Class-conditional unbiased loss for single-positive multi-label learning},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A review of patent analysis based on machine learning. <em>ASOC</em>, <em>186</em>, 114063. (<a href='https://doi.org/10.1016/j.asoc.2025.114063'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, as machine learning approaches have demonstrated success across various domains, the application of machine learning to patent analysis has garnered significant attention. To understand the current status and explore the future trends of patent analysis based on machine learning, in this paper, we conduct a systematic review of the related articles recently recorded by Web of Science. We identify 91 representative papers published from 2018 to 2025 and categorize machine learning-based patent analysis approaches into four classes: patent classification, retrieval, recommendation, and assessment. We extract and compare the fundamental methods in these publications and delineate the workflow of the conventional approaches. Particularly, as there are still no clear standards for patent assessment, we also categorize the evaluation indicators used in the patent assessment literature into four dimensions: technical, economic, legal, and others. In addition, we meticulously dissect the technical challenges encountered when applying machine learning techniques, providing a nuanced understanding of the complexities involved. Finally, we present three new perspectives on the potential efficacy of machine learning and deep learning techniques in future patent analysis.},
  archive      = {J_ASOC},
  author       = {Zhenhai Chi and Wuquan Lin and Zhanhao Xiao and Huihui Li and Weiqi Chen and Xiaoyong Liu},
  doi          = {10.1016/j.asoc.2025.114063},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114063},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A review of patent analysis based on machine learning},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Advancements in data-driven evolving fuzzy and neuro-fuzzy control: A comprehensive survey. <em>ASOC</em>, <em>186</em>, 114058. (<a href='https://doi.org/10.1016/j.asoc.2025.114058'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an era of increasing system complexity and growing demands for autonomy and efficiency, control systems must continuously adapt to dynamic and uncertain environments. This study presents a comprehensive survey of evolving fuzzy and neuro-fuzzy controllers, with emphasis on data-driven control systems that adapt in real time in both structure and parameters. As the demand for adaptive and flexible control solutions grows alongside the increasing complexity of systems, evolving model-free and model-based fuzzy, neural, and neuro-fuzzy controllers have emerged as robust approaches, allowing models and controllers to integrate new patterns from data streams. Incremental machine learning methods enable control systems to autonomously detect and track new behaviors, improving their effectiveness in time-varying and unknown environments. Based on a rigorous bibliometric analysis using the Web of Science database, 2760 related papers were identified of which 97 were manually selected for detailed review due to their direct relevance to closed-loop evolving fuzzy or neuro-fuzzy control systems. These papers cover a wide range of methods, including basic parameter tuning, adaptive gain scheduling, and structural modifications grounded in constrained optimization and Lyapunov stability analysis. Such advances mark significant progress in the control of unknown, time-varying systems, with the surveyed literature demonstrating promising results in various applications. The abstracted findings reveal an increase in publications since 2013, confirming the relevance of evolving control in engineering. This review provides a comprehensive analysis of methodologies and achievements in the field, highlighting emerging trends, challenges, and research directions within evolving data-driven control. The novelty of this study lies in its focus on the structural evolution of controllers under real-time constraints, consolidating incremental machine learning for partition-based closed-loop architectures.},
  archive      = {J_ASOC},
  author       = {Goran Andonovski and Daniel Leite and Radu-Emil Precup and Fernando Gomide and Mahardhika Pratama and Igor Škrjanc},
  doi          = {10.1016/j.asoc.2025.114058},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114058},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Advancements in data-driven evolving fuzzy and neuro-fuzzy control: A comprehensive survey},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Graph-embedded reinforcement learning for dynamic pricing and advertising under network effects. <em>ASOC</em>, <em>186</em>, 114056. (<a href='https://doi.org/10.1016/j.asoc.2025.114056'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Firms increasingly rely on both price discounts and advertising campaigns to shape product diffusion in socially connected markets, yet existing models rarely treat these levers jointly or account for network heterogeneity. This study develops an integrated, network-aware framework for dynamic pricing and advertising control. A stochastic compartmental model of the consumer decision-making model (CDM) is formulated on a social graph, with transition intensities modulated by price, advertising spend, and peer influence. A deterministic mean-field approximation yields closed-form expressions for a trade-free equilibrium (TFE) and a reproduction number threshold that delineates when adoption dies out versus persists. Building on this analytical core, the paper introduces twin delayed deep deterministic policy gradient with encoded state (TD3ES), a reinforcement learning (RL) controller that couples an actor-critic architecture with a graph-convolutional autoencoder, thereby compressing high-dimensional network states into a tractable latent representation. A custom GPU-accelerated simulator facilitates large-scale training. Numerical experiments on Erdős-Rényi and heavy-tailed exponential networks show that twin delayed deep deterministic policy gradient with encoded state (TD3ES) swiftly converges to profit-maximizing joint policies and, on heterogeneous graphs, outperforms a TD3 baseline that lacks network-structural information. Error analysis reveals that the autoencoder naturally prioritizes high-degree hubs in dominant CDM compartments, explaining its superior performance. Managerially, the results demonstrate that ignoring topology can forfeit substantial revenue and that adaptive, network-aware coordination of price and advertising is both feasible and valuable. The framework thus unites rigorous diffusion theory with scalable learning, offering a practical tool for data-driven marketing in connected consumer ecosystems.},
  archive      = {J_ASOC},
  author       = {Ehsan Ardjmand and Esmaeil Izadi and Ali Tavasoli and Behnaz Moradi-Jamei and Heman Shakeri},
  doi          = {10.1016/j.asoc.2025.114056},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114056},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Graph-embedded reinforcement learning for dynamic pricing and advertising under network effects},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Differentiable architecture search for GANs with rollback mechanism. <em>ASOC</em>, <em>186</em>, 114055. (<a href='https://doi.org/10.1016/j.asoc.2025.114055'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing effective architectures for Generative Adversarial Networks (GANs) remains a challenging task due to training instability and the complexity of balancing generator and discriminator performance. While Neural Architecture Search (NAS) has shown promise in automating architecture design, existing NAS-GAN approaches often suffer from limited design flexibility and high computational demands. This paper introduces a gradient-based NAS framework, termed Differentiable Architecture Search for GANs with Rollback Mechanism (RASGAN), aimed at addressing these limitations. RASGAN incorporates a hyperparameter rollback to indirectly optimise evaluation metrics such as the Inception Score (IS) and Fréchet Inception Distance (FID), leading to higher-quality generative models. Moreover, the search space integrates lightweight convolutional operations to reduce computational and storage overhead without compromising performance. On unconditional image generation tasks, the proposed method achieves competitive results: on CIFAR-10, RASGAN attains IS = 8.98 and FID = 10.31; on STL-10, IS = 10.55 and FID = 22.37. Compared to existing NAS-GAN methods, the architectures discovered by RASGAN are not only more effective but also significantly more efficient, exhibiting reduced parameter size while maintaining strong generative performance.},
  archive      = {J_ASOC},
  author       = {Ferrante Neri and Lingzhen Liao and Yu Xue and Márcio P. Basgalupp},
  doi          = {10.1016/j.asoc.2025.114055},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114055},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Differentiable architecture search for GANs with rollback mechanism},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Application of electoral systems for decision making in ensembles of heuristics generated by genetic programming. <em>ASOC</em>, <em>186</em>, 114050. (<a href='https://doi.org/10.1016/j.asoc.2025.114050'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores improving hyper-heuristics, algorithms for designing heuristics, by integrating ensemble learning and democratic electoral systems for decision aggregation. While hyper-heuristics solve various optimisation problems, their solution quality remains limited. Ensemble learning, which combines decisions from multiple heuristics, can address this limitation, but aggregation methods are often simplistic. Inspired by democratic election systems, 25 electoral methods were tested for aggregating heuristic decisions in ensembles. Experiments on four combinatorial optimization problems demonstrate that electoral systems effectively aggregate decisions, offering alternative approaches to enhance current ensemble methods.},
  archive      = {J_ASOC},
  author       = {Marko Đurasević and Francisco J. Gil-Gala and Mateja Đumić},
  doi          = {10.1016/j.asoc.2025.114050},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114050},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Application of electoral systems for decision making in ensembles of heuristics generated by genetic programming},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Medical image classification with KAN-integrated transformers and dilated neighborhood attention. <em>ASOC</em>, <em>186</em>, 114045. (<a href='https://doi.org/10.1016/j.asoc.2025.114045'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional networks, Transformers, hybrid models, and Mamba-based architectures have demonstrated strong performance across various medical image classification tasks. However, these methods were primarily designed to classify clean images using labeled data. In contrast, real-world clinical data often involve image corruptions that are unique to multi-center studies and stem from variations in imaging equipment across manufacturers. In this paper, we introduce the Medical Vision Transformer (MedViTV2), a novel architecture incorporating Kolmogorov-Arnold Network (KAN) layers into the Transformer architecture for the first time, aiming for generalized medical image classification. We have developed an efficient KAN block to reduce computational load while enhancing the accuracy of the original MedViT. Additionally, to counteract the fragility of our MedViT when scaled up, we propose an enhanced Dilated Neighborhood Attention (DiNA), an adaptation of the efficient fused dot-product attention kernel capable of capturing global context and expanding receptive fields to scale the model effectively and address feature collapse issues. Moreover, a hierarchical hybrid strategy is introduced to stack our Local Feature Perception and Global Feature Perception blocks in an efficient manner, which balances local and global feature perceptions to boost performance. Extensive experiments on 17 medical image classification datasets and 12 corrupted medical image datasets demonstrate that MedViTV2 achieved state-of-the-art results in 27 out of 29 experiments with reduced computational complexity. MedViTV2 is 44 % more computationally efficient than the previous version and significantly enhances accuracy, achieving improvements of 4.6 % on MedMNIST, 5.8 % on NonMNIST, and 13.4 % on the MedMNIST-C benchmark.},
  archive      = {J_ASOC},
  author       = {Omid Nejati Manzari and Hojat Asgariandehkordi and Taha Koleilat and Yiming Xiao and Hassan Rivaz},
  doi          = {10.1016/j.asoc.2025.114045},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114045},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Medical image classification with KAN-integrated transformers and dilated neighborhood attention},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantile deep learning models for multi-step ahead time series prediction. <em>ASOC</em>, <em>186</em>, 114043. (<a href='https://doi.org/10.1016/j.asoc.2025.114043'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty quantification is crucial in time series prediction, and quantile regression offers a valuable mechanism for uncertainty quantification, which is useful for extreme value forecasting. Although deep learning models have been prominent in multi-step ahead prediction, the development and evaluation of quantile deep learning models have been limited. We present a novel quantile regression deep learning framework for multi-step time series prediction. In this way, we elevate the capabilities of deep learning models by incorporating quantile regression, thus providing a more nuanced understanding of predictive values. We provide an implementation of prominent deep learning models for multi-step ahead time series prediction and evaluate their performance under high volatility and extreme conditions. We include multivariate and univariate modelling, strategies, and provide a comparison with conventional deep learning models from the literature. Our models are tested on two cryptocurrencies: Bitcoin and Ethereum, using daily close-price data and selected benchmark time series datasets. The results show that integrating a quantile loss function with deep learning provides additional predictions for selected quantiles without a loss in prediction accuracy. Our quantile model can handle volatility more effectively and provides uncertainty quantification through the use of quantiles when compared to conventional deep learning models.},
  archive      = {J_ASOC},
  author       = {Jimmy Cheung and Smruthi Rangarajan and Amelia Maddocks and Rohtiash Chandra},
  doi          = {10.1016/j.asoc.2025.114043},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114043},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Quantile deep learning models for multi-step ahead time series prediction},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Cancelable binary face templates generation based on density-sensitive hashing and feature hashing. <em>ASOC</em>, <em>186</em>, 114041. (<a href='https://doi.org/10.1016/j.asoc.2025.114041'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing utilization of face recognition technology prompts concerns about the security of stored templates. Nevertheless, existing biometric template protection methods often incur high computational overhead or depend on two-factor input. To address these issues, we propose a cancelable template generation strategy that integrates density-sensitive hashing and feature hashing. The density-sensitive hashing transforms the facial feature vector into binary codes by leveraging the geometric characteristics of the data. Feature hashing then derives a permutation seed from the facial features to shuffle a random key, which is encoded using the binary codes, producing an encoded key retained within the cancelable template. Experimental results on the LFW, FEI and CASIA-FaceV5 databases show that our method achieves an EER below 0.72 %, a GAR exceeding 97.5 % at a FAR= 0.01 % and an average template generation time of 5.3 ms, confirming its efficiency and recognition performance. Furthermore, related experimental and theoretical evaluations prove that the proposed method guarantees the characteristics of irreversibility, revocability unlinkability, and resilience against various attacks.},
  archive      = {J_ASOC},
  author       = {Zifeng Huang and Yuxing Li and Qikang Zhang},
  doi          = {10.1016/j.asoc.2025.114041},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114041},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cancelable binary face templates generation based on density-sensitive hashing and feature hashing},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Polarimetric SAR image classification based on superpixel content-aware and semi-supervised ViT network. <em>ASOC</em>, <em>186</em>, 114040. (<a href='https://doi.org/10.1016/j.asoc.2025.114040'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PolSAR image classification faces key challenges, including complex scattering mechanisms, speckle noise, and scarcity of labeled data. Although Vision Transformer (ViT) and its variants are powerful, they require large labeled datasets and struggle with semantic misalignment in fixed patch tokenization. To address these issues under low-sample conditions, this paper proposes the superpixel content-aware and semi-supervised ViT network (SPSE-ViT). Firstly, superpixels are introduced into the ViT for the first time, and a content-aware token generation method is designed. During pre-training, superpixels of random sizes are selected, regularized, divided into blocks, and randomly masked to generate token sequences, improving spatial consistency and reducing noise. Secondly, a semi-supervised ViT network is constructed by integrating supervised and unsupervised learning. Classification loss guides learning with a small number of labeled samples, while reconstruction and contrastive loss enhance generalization by supplementing spatial structure. Finally, a pre-training and fine-tuning strategy is applied. The model is pre-trained with a few labeled samples, and fine-tuned for final classification results. Experimental results show that SPSE-ViT outperforms seven state-of-the-art methods in PolSAR classification, significantly improving performance with limited labeled samples. The code is available at: https://github.com/githubltqc/SPSE-ViT .},
  archive      = {J_ASOC},
  author       = {Jinhong Ren and Keyao Zhu and Mingwei Hu and Ronghua Shang and Mengxuan Zhang},
  doi          = {10.1016/j.asoc.2025.114040},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114040},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Polarimetric SAR image classification based on superpixel content-aware and semi-supervised ViT network},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Embracing data irregularities in multivariate time series. <em>ASOC</em>, <em>186</em>, 114039. (<a href='https://doi.org/10.1016/j.asoc.2025.114039'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data collection in many engineering fields involves multivariate time series gathered from a collection of sensors that operate independently of each other. These sensors often display various irregularities, such as different sampling rates and missing data. To manage these issues, complex preprocessing mechanisms are required, which become coupled with any statistical model trained with the transformed data. Modeling the motion of floating platforms anchored on seabeds from measurements acquired from sensors is a typical example. We propose and analyze a model in which each sensor is encoded using an independent time-informed recurrent neural network, information is propagated in a common latent space by a graph neural network, and a modified training method is used to induce temporal generalization of the model. Our method can generate forecasts at unseen frequencies, which provides empirical evidence that the model learns an implicit representation of the system’s time derivatives and is able to flexibly integrate the signal over the time domain.},
  archive      = {J_ASOC},
  author       = {Marcel Barros and Lucas P. Fontenele and Mariana S. Silva and Thiago Rissi and Eduardo Cabrera and Eduardo A. Tannuri and Edson S. Gomi and Rodrigo A. Barreira and Anna H. Reali Costa},
  doi          = {10.1016/j.asoc.2025.114039},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114039},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Embracing data irregularities in multivariate time series},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FViT: A focal vision transformer with gabor filter. <em>ASOC</em>, <em>186</em>, 114032. (<a href='https://doi.org/10.1016/j.asoc.2025.114032'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision transformers have achieved encouraging progress in various computer vision tasks. A common belief is that this is attributed to the ability of self-attention mechanisms to capture global dependencies among feature tokens. However, in dense prediction tasks, self-attention continues to pose challenges, including high computational cost and lack of desirable inductive bias. To alleviate these limitations, the potential advantages of combining vision transformers with Gabor filters are revisited, and a learnable Gabor filter (LGF) is proposed using depthwise convolution. The LGF does not rely on self-attention, and it is used to simulate the response patterns of fundamental cells in the biological visual system to input images. This enables vision transformers to focus on discriminative feature representations of targets across varying scales and orientations. Based on the LGF, a neuroscience inspired Bionic Focal Vision (BFV) block is developed. It incorporates a Dual-Path Feed-Forward Network (DPFFN) to emulate the parallel and cascaded information processing scheme of the biological visual cortex. Furthermore, a unified and efficient family of pyramid backbone networks called Focal Vision Transformers (FViTs) is developed by stacking BFV blocks. Experimental results demonstrate that FViTs achieve superior performance across various vision tasks while exhibiting significant advantages in computational efficiency and scalability compared with other counterparts. The code is available at https://github.com/nkusyl/FViT},
  archive      = {J_ASOC},
  author       = {Yulong Shi and Mingwei Sun and Yongshuai Wang and Zengqiang Chen},
  doi          = {10.1016/j.asoc.2025.114032},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114032},
  shortjournal = {Appl. Soft. Comput.},
  title        = {FViT: A focal vision transformer with gabor filter},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Imitation-assisted safe reinforcement learning strategy for microgrid fault restoration. <em>ASOC</em>, <em>186</em>, 114031. (<a href='https://doi.org/10.1016/j.asoc.2025.114031'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microgrid physical faults triggered by equipment failures and extreme weather often lead to significant losses, which makes it imperative for microgrids to enhance their fault restoration capabilities and efficiency. Prior benchmarks including rule-based and MILP methods struggle to simultaneously satisfy solution time, power cost and safety. Furthermore, the application of traditional reinforcement learning approaches for fault restoration faces low learning efficiency and undesirable behaviors during the learning phase. This study introduces an imitation-assisted safe Soft Actor-Critic strategy for microgrid fault restoration to address these challenges. Firstly, the offline optimization strategy of Dynamic Programming is leveraged as expert guidance and the adversarial network is used to approximate the behavior of agent to the optimal fault restoration strategy. This addresses the problem of slow learning in microgrid fault restoration. Secondly, incorporating Lagrangian penalty terms for safety constraints into the reward function, which effectively mitigates undesirable behaviors during the learning phase and ensures secure microgrid operation. Thirdly, simulations under summer and winter conditions validate the strategy’s superiority, showing faster restoration and improved operational efficiency. Results demonstrate that the proposed method can accelerate the training by 25.26 % while enhancing the reward by 23.96 % compared with other imitation reinforcement learning methods. Under different test conditions, the proposed method can further reduce the power cost by 20.78 % to 38.22 %. The proposed strategy is further evaluated in a modified IEEE 33-bus microgrid, where it shows enhanced performance in fault restoration and overall system efficiency.},
  archive      = {J_ASOC},
  author       = {Jieqi Rong and Weirong Liu and Fu Jiang and Yingze Yang},
  doi          = {10.1016/j.asoc.2025.114031},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114031},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Imitation-assisted safe reinforcement learning strategy for microgrid fault restoration},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integrating AR-SVR and distortion risk measures for mortality risk forecasting. <em>ASOC</em>, <em>186</em>, 114030. (<a href='https://doi.org/10.1016/j.asoc.2025.114030'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate mortality risk forecasting is critical for life insurance and pension systems. A hybrid modeling framework is introduced, combining stochastic processes and machine learning for improved mortality risk assessment. Specifically, an autoregressive model captures temporal dependencies, while support vector regression addresses nonlinear and heteroscedastic patterns. Tail distortion risk measures are incorporated to refine extreme risk forecast. Model performance is assessed through bayesian information criterion, coverage probability, and (conditional) tail-calibration using U.S. mortality data. The results confirm that this integrated approach effectively captures mortality dynamics, providing a reliable tool for actuarial and financial risk management.},
  archive      = {J_ASOC},
  author       = {Aniq Rohmawati and Arief Hakim and Atina Ahdika and Khreshna Syuhada and Octavina},
  doi          = {10.1016/j.asoc.2025.114030},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114030},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Integrating AR-SVR and distortion risk measures for mortality risk forecasting},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). End-to-end mid-term load forecasting framework based on multi-channel technique and time-frequency domain fusion. <em>ASOC</em>, <em>186</em>, 114029. (<a href='https://doi.org/10.1016/j.asoc.2025.114029'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Load forecasting profoundly impacts power supply reliability and economy. Accurate mid-term forecasting is crucial for power system planning, operation, and management. However, factors like weather, season, and electricity price cause power load data to exhibit significant volatility and nonlinearity, limiting the accuracy of traditional forecasting models. While artificial intelligence methods have improved accuracy, extending the forecast horizon increases task complexity. Moreover, non-end-to-end forecasting frameworks use multi-module systems for forecasting, and there is often a lack of effective collaborative optimization mechanisms between modules, which makes it difficult to achieve global optimization of the entire forecasting system, limiting the further improvement of forecasting performance. To address these challenges, this paper proposes an innovative end-to-end load forecasting framework to enhance accuracy and robustness. The framework comprises two subsystems: a data decomposition system and a high-precision forecasting system. In the data decomposition system, the variational mode decomposition method is used to decompose the original load data into two modes with different central frequencies. In the high-precision prediction system, multi-channel prediction technology is adopted. The two components obtained by the decomposition module are input into two independent feature extraction channels respectively, and then the output vectors of the two are feature fused. Finally, the fused data is input into the prediction channel to obtain the final prediction result. Additionally, to mitigate label autocorrelation in the time series, a time-frequency domain fusion loss function is introduced during model training, further boosting performance. This paper uses two real data sets from Queensland and New South Wales, Australia to conduct four sets of experiments. The results show that the prediction performance of the framework is better than the state-of-the-art time series prediction models (e.g., Patch-based Time Series Transformer, Decomposition Linear, and Informer) in different prediction tasks (day-ahead (48 steps) and four days-ahead (192 steps)). Demonstrating improvements of at least 7.87 % in short-term accuracy and 13.7 % in medium-term accuracy, the framework’s stability and ease of use are validated through rigorous numerical testing. Its capability for accurate medium-term forecasting supports more efficient, economical, and reliable power system operation.},
  archive      = {J_ASOC},
  author       = {Wenyu Gao and Zhirui Tian},
  doi          = {10.1016/j.asoc.2025.114029},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114029},
  shortjournal = {Appl. Soft. Comput.},
  title        = {End-to-end mid-term load forecasting framework based on multi-channel technique and time-frequency domain fusion},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). LLM-centric collaborative computing framework: Leveraging industry specified knowledge for open-set visual recognition. <em>ASOC</em>, <em>186</em>, 114028. (<a href='https://doi.org/10.1016/j.asoc.2025.114028'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To promote intelligent capability of manufacturing, researchers propose lots of methods to obtain task-specified knowledge. Recently, the appearance of Large Language Models (LLMs) offers a paradigm by transforming knowledge learned from massive data to the specified industry scenarios. Focusing on involving LLMs to perform open-set visual recognition, we believe there exist two major issues to resolve, i.e., the usage of generalized knowledge from LLMs to identify unknown categories, and efficient architecture design for LLM-centric industrial deployment. In this paper, we propose a LLM-centric collaborative computing framework for open-set visual recognition, which consists of device-edge-cloud architecture, multi-server microservice deployment strategy and multiple LLM collaboration scheme. Specifically, the proposed architecture rationally allocates computation burden brought by LLMs to improve recognition efficiency. Embedded in the edge layer, the proposed microservice strategy helps balance the computation cost and achieve minimal device delay. Last but not least, the proposed scheme involves multiple LLMs and knowledge graph to generate and enhance the task-specified knowledge in a cycling workflow, thus boosting robustness and accuracy in recognizing unseen industrial objects. Extensive experiments on public datasets demonstrate the outstanding performance of the proposed framework regarding effectiveness and efficiency.},
  archive      = {J_ASOC},
  author       = {Yirui Wu and Xinfu Liu and Qi Yan and Cheng Zhen and Lixin Yuan and Wenxiao Zhang},
  doi          = {10.1016/j.asoc.2025.114028},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114028},
  shortjournal = {Appl. Soft. Comput.},
  title        = {LLM-centric collaborative computing framework: Leveraging industry specified knowledge for open-set visual recognition},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Transformer-based dynamics model for sim-to-real reinforcement learning control of a quadrotor with limited experimental data. <em>ASOC</em>, <em>186</em>, 114024. (<a href='https://doi.org/10.1016/j.asoc.2025.114024'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep reinforcement learning is a promising technique for robotic applications, the considerable amount of data required through interactions with the environment hinders the large-scale adoption of this method. Collecting extensive real-world training data for robots is challenging due to safety concerns, periodic battery replacements, and actuator wear. In this study, we propose a novel strategic, data-efficient modeling scheme based on a transformer to effectively replicate a real-world environment and ensure that policies learned in the transformer-based simulation can operate effectively in real-world scenarios without significant performance degradation. The proposed transformer-based modeling scheme was demonstrated using a quadrotor. The transformer-based quadrotor model was first trained to approximate real-world dynamics accurately and subsequently used to train a low-level controller for the target quadrotor.The Soft Actor-Critic algorithm was utilized for policy training. To facilitate training of the dynamic model, both simulated and real flight data were used together in the pretraining step, while only real flight data were used in the fine-tuning step. The proposed method outperformed conventional policies trained using domain randomization. The proposed transformer-based quadrotor model facilitates smooth sim-to-real policy transfer by significantly reducing the time and effort required for additional tuning tasks.},
  archive      = {J_ASOC},
  author       = {Yoonsu Jang and Seongwon Yoon and Jongchan Baek and Changhyeon Lee and Jangwon Kim and Soohee Han},
  doi          = {10.1016/j.asoc.2025.114024},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114024},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Transformer-based dynamics model for sim-to-real reinforcement learning control of a quadrotor with limited experimental data},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Mixed convolutional network via homogeneity map guided adaptive fusion for polarimetric SAR image classification. <em>ASOC</em>, <em>186</em>, 114020. (<a href='https://doi.org/10.1016/j.asoc.2025.114020'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the complexity of polarimetric SAR images in different regions, convolutional neural networks find it difficult to extract non-Euclidean heterogeneous features. Graph convolutional networks struggle to extract fine features due to the dual influence of superpixel segmentation accuracy and classification accuracy. To address these problems, this paper proposes a mixed convolutional network based on homogeneous map guided network fusion (HM-MCN). Firstly, a double-branch network is designed to extract two kinds of feature maps respectively. The channel-spatial denoising branch embeds an attention module to learn feature weights and uses two-dimensional dilated convolution to improve the receptive field. The homogeneous weighted branch calculates the superpixel homogeneous, and constructs a homogeneous weight matrix to aggregate nodes. Secondly, in order to adaptively fuse these two features, a method for generating a homogeneous map is designed. Three convolution kernels are used to extract complexity features, and a coupling operator is constructed to generate a homogeneous map so that the complexity of different regions can be quantified more accurately as weights. Finally, a fusion operator is designed at the end of the mixed convolutional network to realize the fusion of fine features and heterogeneous features, which generates the final feature map, and the feature map is classified through the fully connected layer. The experimental results on three different datasets with seven state-of-the-art methods show that the proposed HM-MCN achieves higher classification performance on polarimetric SAR classification.},
  archive      = {J_ASOC},
  author       = {Ronghua Shang and Mingwei Hu and Keyao Zhu and Jinhong Ren and Jie Feng},
  doi          = {10.1016/j.asoc.2025.114020},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114020},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Mixed convolutional network via homogeneity map guided adaptive fusion for polarimetric SAR image classification},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Efficient multiple density-based models over large datasets with data stream applications. <em>ASOC</em>, <em>186</em>, 114019. (<a href='https://doi.org/10.1016/j.asoc.2025.114019'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density-based hierarchical clustering offers comprehensive insight into the clusters and outlier structures within datasets through density functions. These algorithms construct a hierarchical graph representation, where edges are weighted by the minimum density required for connected data points to form clusters; this density threshold depends on the minimum number of objects within a neighborhood, denoted m p t s , which acts as a smoothing parameter for the density estimate. CORE-SG, a spanning graph for the fast computation of HDBSCAN* results, allows efficient and seamless extraction of multiple hierarchical solutions with varying densities and across an arbitrary range of density smoothing levels, surpassing its predecessors in computational performance. However, much like its predecessors, CORE-SG requires neighborhood estimation based on pairwise similarity calculations that are constrained by a quadratic asymptotic complexity relative to dataset size, which can be impractical for scenarios involving large volumes of data. This paper proposes a streamlined version of CORE-SG, designed to achieve computational efficiency through data abstraction, and investigates the impact of data summarization on the quality of unsupervised hierarchical models across multiple density levels. Our goal is to improve the scalability of CORE-SG while preserving its core properties. We evaluated our approach on clustering and outlier detection tasks, comparing it to the original version. Furthermore, we adapted and evaluated its effectiveness in a data stream scenario, where data arrives continuously and indefinitely, requiring ongoing model updates. Our algorithm was benchmarked against the latest HDBSCAN*-based algorithm for data streams, demonstrating superior performance and improved clustering quality.},
  archive      = {J_ASOC},
  author       = {Natanael F.D. Batista and Bruno L. Nunes and Murilo C. Naldi},
  doi          = {10.1016/j.asoc.2025.114019},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114019},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Efficient multiple density-based models over large datasets with data stream applications},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A survey on particle swarm optimization: Evolution, adaptations and practical implementations. <em>ASOC</em>, <em>186</em>, 114016. (<a href='https://doi.org/10.1016/j.asoc.2025.114016'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle Swarm Optimization (PSO) is widely recognized in the literature as a leading swarm-based algorithm. Since its inception in the mid-1990s, PSO has undergone significant advancements, including various enhancements, extensions, and modifications, particularly in the years following the turn of the century. As a result, research in this area has reached a remarkable level of sophistication. This paper presents a comprehensive and systematic review that organizes and synthesizes current knowledge on PSO. It offers an in-depth examination of the core concepts of the algorithm, neighborhood topologies, and historical and recent variants of the PSO. In addition, it highlights the significant engineering applications of PSO and discusses ongoing challenges in the field. By systematically arranging and summarizing the latest research, this review serves as a valuable resource for both researchers and practitioners interested in the development and application of PSO.},
  archive      = {J_ASOC},
  author       = {Rashmi Sharma and Jagjit Singh Matharu and Kulwinder Singh Parmar},
  doi          = {10.1016/j.asoc.2025.114016},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114016},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A survey on particle swarm optimization: Evolution, adaptations and practical implementations},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A transformer-based sequential analysis methodology for trajectory tracking at safety surveillance in manufacturing. <em>ASOC</em>, <em>186</em>, 114012. (<a href='https://doi.org/10.1016/j.asoc.2025.114012'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing safety surveillance is critical to ensuring worker safety in factories. A vision-based safety surveillance solution can facilitate the monitoring of the unsafe behaviors of workers and vehicles to reduce the occurrence of incidents. However, in practice, making violation judgments involves several ambiguities, mainly due to challenges associated with judging whether workers are decelerating before reaching an intersection. To address these challenges, this study proposes a transformer-based sequential analysis algorithm for tracking the trajectories of objects passing through intersections to enhance safety surveillance in factories. The proposed algorithm extracts speed profiles from surveillance footage and uses a data preprocessing procedure that transforms the trajectory tracking task into a time-series classification problem, thus unifying behavioral analysis for both walking and driving workers. It accurately identifies stopping positions, eliminating phase differences between pedestrians and vehicles. Additionally, the proposed algorithm conducts perspective transformation to ensure fair speed calculations by allowing adjustments for camera distance. It also uses an attention mechanism to quantify the ambiguity in violation decisions to achieve automated violation detection. The proposed algorithm was validated by applying it to surveillance videos from factories to conduct safety surveillance assessments. It achieved the highest F 1 score (0.751), demonstrating its accuracy in identifying workers’ successful or unsuccessful stopping behavior at intersections. In summary, this study provides a cost-effective approach using existing cameras for comprehensive, real-time surveillance, addressing blind spots. Factory managers can transition from reactive to proactive safety in practice, thus facilitating the enforcement of environmental, safety, and health practices for worker protection.},
  archive      = {J_ASOC},
  author       = {Hwai-Jung Hsu and Che-Wei Chou and Guo-Lun Gao},
  doi          = {10.1016/j.asoc.2025.114012},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114012},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A transformer-based sequential analysis methodology for trajectory tracking at safety surveillance in manufacturing},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Quantum FP-growth algorithm using GPU simulation- application to digital soil mapping. <em>ASOC</em>, <em>186</em>, 114011. (<a href='https://doi.org/10.1016/j.asoc.2025.114011'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel quantum version of the FP-growth algorithm for frequent itemset mining, leveraging the combined strengths of classical FP-growth and quantum machine learning. Key contributions include the theoretical and practical framework for Quantum FP-growth, along with a comprehensive analysis of its time and space complexity. We implemented Quantum FP-growth using IBM Qiskit and conducted a comparative evaluation of various quantum amplitude estimation (QAE) methods, including Canonical QAE, Faster QAE, Maximum Likelihood QAE, and Iterative QAE for support estimation. Our findings reveal that Iterative QAE surpasses the other methods in both accuracy and speed. Additionally, we explored the advantages of GPU simulation with IBM Qiskit and NVIDIA cuQuantum. Notably, this research marks the first application of a quantum frequent itemset mining algorithm to a real-world dataset in Digital Soil Mapping (DSM), pioneering the use of quantum technologies in soil science. This study underscores the potential of quantum computing to revolutionize data mining and promote sustainable soil management practices.},
  archive      = {J_ASOC},
  author       = {Widad Hassina Belkadi and Yassine Drias and Habiba Drias},
  doi          = {10.1016/j.asoc.2025.114011},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114011},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Quantum FP-growth algorithm using GPU simulation- application to digital soil mapping},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Neural network with reject option for error correction in data packets. <em>ASOC</em>, <em>186</em>, 114010. (<a href='https://doi.org/10.1016/j.asoc.2025.114010'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Networks (NNs) have been applied in various fields with remarkable advancements due to their significant potential to enable new applications. The use of NNs for signal identification is becoming increasingly important for communication systems. However, current approaches involve Error-Correcting Codes (ECC) that increase the data overhead in packets to achieve better results. In this paper, we propose an error correction approach for data packets based on neural networks with reject option, which aims to correct slightly corrupted data packets. Our proposed method involves the integration of three systems: (i) an Extreme Learning Machine (ELM) neural network to mitigate the distortion that occurs in the communication channel, (ii) the Cyclic Redundancy Check (CRC) algorithm to detect packets with errors, and (iii) classification with reject option to identify and correct bit errors in data packets. Through simulations involving packets of different sizes and under various channel conditions, we evaluated the performance of our proposed method with real data for the Internet of Things (IoT) and Bluetooth Low Energy (BLE). The experimental results demonstrate its capability to effectively correct errors without the need for ECC algorithms or the addition of redundant data. Furthermore, when compared to error correction approaches using CRC, our method shows the potential to process error corrections without relying on a lookup table, and it surpasses the performance of state-of-the-art models that use statistical estimators for multiple errors.},
  archive      = {J_ASOC},
  author       = {Wellington D. Almeida and Ajalmar R. Rocha Neto},
  doi          = {10.1016/j.asoc.2025.114010},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114010},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Neural network with reject option for error correction in data packets},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A distributed flexible job shop scheduling problem considering rush order insertion using a two-stage memetic algorithm. <em>ASOC</em>, <em>186</em>, 114008. (<a href='https://doi.org/10.1016/j.asoc.2025.114008'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To date, existing research on the distributed flexible job shop scheduling problem typically overlooks the insertion of rush orders, i.e., it is assumed that once an order starts processing, other jobs cannot be inserted. However, in actual production, with the increasing demand for multiple varieties, small batches, and personalization, order insertion has become very common. In this paper, we propose a distributed flexible job shop scheduling problem considering rush order insertion (DFJSPR) for the first time; and design a two-stage memetic algorithm (TMA) to solve the DFJSPR with the optimization objectives of minimizing the makespan, total energy consumption, and total delay of jobs. In the TMA, a four-layer encoding operator and an effective initialization method for balancing load and transportation are designed to improve the quality of initial population. Some effective crossover, mutation, and local search operators are also designed to fully exploit the algorithm's solution space as well as improve its convergence speed. Finally, a new insertion rescheduling method is presented to reduce the total delay of jobs and makespan by making full use of the machine’s idle time. Sixty DFJSPR benchmark instances are constructed, and comprehensive experiments are conducted to demonstrate the superiority of the TMA. These studies will provide a theoretical basis for practical production scheduling in distributed flexible job shops and help production decision-makers obtain optimal scheduling schemes when considering rush order insertion problems.},
  archive      = {J_ASOC},
  author       = {Dian Lu and Guiliang Gong and Zhongliang Gong and Ningtao Peng and Dan Huang and Qiang Luo and Xiaoqiang Li},
  doi          = {10.1016/j.asoc.2025.114008},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114008},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A distributed flexible job shop scheduling problem considering rush order insertion using a two-stage memetic algorithm},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PFADet: A few-shot prompt-guided fabric anomaly detection network using large vision-language models. <em>ASOC</em>, <em>186</em>, 114005. (<a href='https://doi.org/10.1016/j.asoc.2025.114005'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fabric anomaly detection (FAD) is crucial in guaranteeing fabric quality and optimizing production processes. Despite the progress of fully supervised methods in FAD tasks, the scarcity of anomaly samples and the difficulty of high-quality pixel-level labeling have motivated the attention on few-shot learning. Meanwhile, Large Vision-Language Models (LVLMs) excel with strong cross-modal understanding, whereas detection accuracy and adaptability are limited in FAD due to insufficient prior knowledge and missing multimodal data. To this end, we propose a few-shot prompt-guided fabric anomaly detection network (PFADet), based on LVLMs for efficient detection and fine-grained localization. Specifically, adaptive fabric text description templates construct customized descriptions for different fabric types to achieve cross-modal feature alignment, effectively capturing the subtle differences between local and global anomaly features. Integrated Prompt Module leverages the Weight Dynamic Distribution Network (DDNet) to achieve multi-scale feature fusion, providing interpretive feedback and interactive queries that support the anomaly detection results. Additionally, combined with the improved loss function, the discrimination between normal and abnormal features is enhanced by dynamically adjusting the sample boundary weights. Extensive experiments on fabric datasets and generalization analysis on publicly available industrial benchmark datasets demonstrate that PFADet outperforms existing methods in both image-level localization and pixel-level segmentation under few-shot settings, achieving image-AUC of 98.6 %/93.0 %, pixel-AUC of 91.4 %/87.2 %, accuracy of 90.4 %/92.0 %, and F1-score of 0.4441/0.5656 on Color-F and Rollei datasets under 1-shot setting.},
  archive      = {J_ASOC},
  author       = {Xin Zhang and Junfeng Jing and Yongbo Wang},
  doi          = {10.1016/j.asoc.2025.114005},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114005},
  shortjournal = {Appl. Soft. Comput.},
  title        = {PFADet: A few-shot prompt-guided fabric anomaly detection network using large vision-language models},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel spatio-temporal adaptive network considering time-delay effect for traffic flow forecasting. <em>ASOC</em>, <em>186</em>, 114004. (<a href='https://doi.org/10.1016/j.asoc.2025.114004'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of urbanization, traffic congestion has become a hot spot widely concerned by society. Effective prediction of traffic flow can help the relevant departments to regulate in advance and alleviate the problem of traffic congestion. It is worth noting that there is an interesting phenomenon in traffic scenarios: When a significant change in flow occurs at a traffic node (e.g., a junction or a stretch of road), this change does not immediately affect its neighboring nodes, but occurs with some delay. Furthermore, even nodes geographically distant can exhibit similar flow changes after some time. This time-delay phenomenon can seriously affect model predictions, but is often overlooked in existing studies. To address this problem, we propose a novel traffic flow prediction model, called Spatio-Temporal Adaptive Network Considering Time-Delay Effect (STATD). Firstly, time-delay can be classified into two main types: periodic time-delay caused by daily congestion and sudden time-delay caused by unexpected events. Secondly, the spatial features of different nodes and the temporal features filled with time-delay are modeled by a spatio-temporal attention mechanism, which enables the model to adaptively establish correlations to different nodes. Furthermore, a new time-delay reaction module is proposed to predict the sudden time-delay effect on traffic flow through the perception phase and the capturing phase. The perception phase is used to aggregate all the nodes where the abnormal event occurs, while the capturing phase is used to propagate the abnormal state to neighboring nodes, adaptively updating the traffic flow at neighboring nodes without identifying the specific event. Extensive experimental results on the four real datasets show that our model improves the mean absolute error, mean absolute percentage error, and root mean square error by about 1.21 %, 0.91 %, and 1.13 %, respectively.},
  archive      = {J_ASOC},
  author       = {Zhuang Wu and Tianqi Zhang and Yifan Li and Zhaohe Liu and Fangfang Guo and Yuanyuan Wang and Shuo Zhang and Lina Yu},
  doi          = {10.1016/j.asoc.2025.114004},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114004},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A novel spatio-temporal adaptive network considering time-delay effect for traffic flow forecasting},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Deep state space models for remaining useful life estimation. <em>ASOC</em>, <em>186</em>, 114003. (<a href='https://doi.org/10.1016/j.asoc.2025.114003'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been used to train neural networks to estimate the Remaining Useful Life (RUL) of a machine given sensor signals from that machine. This has resulted in some accurate state-of-the-art RUL estimation models. Here we present a novel way to construct a generative model to estimate the RUL and quantify its uncertainty. It takes the form of a Linear Gaussian State Space Model (LGSSM) and is trained using the Kalman Filter; hence, uncertainty is quantified using this LGSSM instead of by other popular methods like Monte Carlo Dropout or Deep Ensembles. This means we can train by directly using the marginal log-likelihood loss and don’t require multiple samples to represent the uncertainty. However, this method is limited to using Gaussian distributions to quantify uncertainty. We avoid needing to use non-linear variants of the filter by processing the sensors using a neural network to represent noncausal sensor sequences as a “control variable” in the LGSSM. This noncausal representation is shown to be important for achieving state-of-the-art performance. The model is tested on a turbofan engine and dust filter dataset. The code can be found on GitHub. 1},
  archive      = {J_ASOC},
  author       = {Marco Star and Kristoffer McKee},
  doi          = {10.1016/j.asoc.2025.114003},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114003},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep state space models for remaining useful life estimation},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Gradual machine learning for medical image classification via evolutionary feature fusion. <em>ASOC</em>, <em>186</em>, 114002. (<a href='https://doi.org/10.1016/j.asoc.2025.114002'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image classification (MIC) is a critical task in the medical imaging field. Recently, deep learning (DL) techniques, represented by convolutional neural networks (CNNs), have achieved remarkable success in MIC. However, in many medical fields, the scarcity of labeled data makes DL models highly sensitive to data distribution. Moreover, most MIC methods rely on a single DL backbone, resulting in limited robustness. To address these issues, we propose a learning paradigm that does not assume independent and identically distributed (i.i.d.) data, gradual machine learning (GML), via evolutionary feature fusion for MIC. It leverages the optimized feature vectors to construct factors for test images and iteratively labels them through factor graph inference. Specifically, we first use multiple DL backbones to extract multi-view complementary feature vectors from medical images and effectively concatenate them. We then propose a novel multi-population evolutionary algorithm (MPEA) to perform feature selection (FS) on the concatenated feature vectors, effectively removing redundant features to achieve deep fusion. Finally, GML extracts evidence factors for test images from the optimized feature vectors to facilitate gradual inference. The proposed MPEA optimizes the population initialization strategy, environmental selection strategy and evolutionary operators to enhance the efficacy of the resulting features as a mechanism for gradual inference. Extensive experiments conducted on eight medical datasets demonstrate that our method achieves higher and more stable classification performance compared to the existing SOTA methods.},
  archive      = {J_ASOC},
  author       = {Wangwang Li and Qun Chen and Fengjin Zhou},
  doi          = {10.1016/j.asoc.2025.114002},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {114002},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Gradual machine learning for medical image classification via evolutionary feature fusion},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). UPTM-LLM: Large language models-powered urban pedestrian travel modes recognition for intelligent transportation system. <em>ASOC</em>, <em>186</em>, 113999. (<a href='https://doi.org/10.1016/j.asoc.2025.113999'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the progression of urbanization and information technology, Intelligent Transportation Systems (ITS) are increasingly crucial for improving urban efficiency and reducing traffic congestion. A key element within ITS is Urban Pedestrian Travel Mode (UPTM) recognition, which aids traffic management through data-driven optimization and congestion mitigation. Deep learning (DL) has advanced transportation research but struggles with the complex semantics of pedestrian movement, including temporal context (e.g., peak/off-peak hours, workdays/weekends), origin-destination POI categories, and the underlying characteristics of GPS trajectories (encompassing kinematics and GIS features). The emergence of large language models (LLMs), known for their large-scale parameters and deep architectures, has enhanced the capacity to interpret such complex semantics. Leveraging this capability, we propose UPTM-LLM, a novel framework that significantly improves UPTM recognition accuracy. It integrates: (1) a temporal awareness module for interpreting time-related traits, (2) a POI Embedding Network (PEN) encoding semantic features of POIs, and (3) a Trajectory Embedding Network (TEN) extracting kinematic and GIS features. Experimental comparisons show that UPTM-LLM outperforms classical models, offering a robust solution for fine-grained UPTM recognition and contributing to more effective urban transportation analytics and planning.},
  archive      = {J_ASOC},
  author       = {Yan Li and Yang Zhan and Maohan Liang and Yu Zhang and Jinhao Liang},
  doi          = {10.1016/j.asoc.2025.113999},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {113999},
  shortjournal = {Appl. Soft. Comput.},
  title        = {UPTM-LLM: Large language models-powered urban pedestrian travel modes recognition for intelligent transportation system},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Addressing key challenges of adversarial attacks and defenses in the tabular domain: A methodological framework for coherence and consistency. <em>ASOC</em>, <em>186</em>, 113998. (<a href='https://doi.org/10.1016/j.asoc.2025.113998'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models trained on tabular data are vulnerable to adversarial attacks, even in realistic scenarios where attackers only have access to the model’s outputs. Since tabular data contains complex dependencies among features, it presents a unique challenge for adversarial samples which must maintain coherence and respect these dependencies to remain indistinguishable from benign data. Moreover, existing attack evaluation metrics—such as the success rate, perturbation magnitude, and query count—fail to account for this challenge. To address these gaps, we propose a technique for perturbing dependent features while preserving sample coherence. In addition, we introduce Class-Specific Anomaly Detection (CSAD), an effective and novel anomaly detection approach, along with concrete metrics for assessing the quality of tabular adversarial attacks. CSAD evaluates adversarial samples relative to their predicted class distribution, rather than a broad benign distribution. This ensures that subtle adversarial perturbations, which may appear coherent in other classes, are correctly identified as anomalies. We extend CSAD for importance-based anomaly detection by integrating SHAP explainability techniques to detect inconsistencies in model decision-making. Our evaluation of adversarial sample quality incorporates both anomaly detection rates and importance-based assessments to provide a more comprehensive measure. We evaluate various attack strategies, examining black-box query-based and transferability-based gradient attacks across four target classification models. Experiments on benchmark tabular datasets reveal key differences in the attacker’s risk effort and attack quality, offering insights into the strengths, limitations, and trade-offs faced by attackers and defenders. Our findings lay the groundwork for future research on adversarial attacks and defense development in the tabular domain.},
  archive      = {J_ASOC},
  author       = {Yael Itzhakev and Amit Giloni and Yuval Elovici and Asaf Shabtai},
  doi          = {10.1016/j.asoc.2025.113998},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {113998},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Addressing key challenges of adversarial attacks and defenses in the tabular domain: A methodological framework for coherence and consistency},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RL-HCP: A reinforcement learning-based heuristic controller placement algorithm for dynamic SDN environments. <em>ASOC</em>, <em>186</em>, 113997. (<a href='https://doi.org/10.1016/j.asoc.2025.113997'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-Defined Networking (SDN) enables centralized network management through programmable control planes. However, in dynamic and large-scale deployments, static controller placement strategies often lead to increased latency, limited fault tolerance, and degraded scalability. Existing heuristic methods lack adaptability, while reinforcement learning (RL)-based approaches face challenges such as slow convergence, complex state representations, and poor generalization. To address these limitations, this paper proposes RL-HCP: a Reinforcement Learning-based Heuristic Controller Placement framework designed for real-time and scalable controller deployment in dynamic SDN environments. RL-HCP integrates domain-specific heuristics into the RL training loop to guide action selection, reduce convergence time, and improve decision quality. The framework models the Controller Placement Problem (CPP) as a Markov Decision Process (MDP) and employs a Dueling Double Deep Q-Network (DDDQN) with heuristic-enhanced reward shaping and action space pruning. A dynamic reconfiguration module enables real-time adaptation to traffic fluctuations, link failures, and topology changes, while minimizing switch migration overhead. Experimental evaluation across diverse topologies—including Fat-tree, Barabási–Albert, and Random Graphs—demonstrates that RL-HCP outperforms traditional heuristics and state-of-the-art RL methods in latency, load balancing, reactivity, and scalability. The framework achieves faster convergence, maintains performance under dynamic conditions, and generalizes well to large-scale networks with up to 1000 nodes. These results highlight RL-HCP’s potential as a robust and intelligent solution for controller placement in next-generation SDN infrastructures.},
  archive      = {J_ASOC},
  author       = {Anil Ram and Swarnendu Kumar Chakraborty and Uddalak Chatterjee},
  doi          = {10.1016/j.asoc.2025.113997},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {113997},
  shortjournal = {Appl. Soft. Comput.},
  title        = {RL-HCP: A reinforcement learning-based heuristic controller placement algorithm for dynamic SDN environments},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). SiamWT-CRNet: A siamese wavelet network with cross-domain feature fusion for dynamic coal-rock recognition in top-coal caving systems. <em>ASOC</em>, <em>186</em>, 113984. (<a href='https://doi.org/10.1016/j.asoc.2025.113984'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the limitations of traditional deep learning methods due to strong data dependency and insufficient interpretability when recognizing “under-releasing" and “over-releasing" phenomena during top-coal caving in longwall mining, this study proposes an intelligent recognition framework, SiamWT-CRNet, based on joint time-frequency domain analysis of vibration signals. It leverages wavelet-domain Siamese network architecture combined with a cross-wavelet feature enhancement mechanism to achieve high-precision dynamic identification of the coal-rock interface. It introduces a cross-scale feature fusion strategy based on multi-family wavelet bases, constructing a physically interpretable enhanced feature space through heterogeneous wavelet decomposition. A lightweight Siamese wavelet convolution module, ECWT, is designed to integrate recursive wavelet decomposition with an improved attention mechanism, enabling focused extraction of critical frequency-band features while reducing parameter complexity. Furthermore, a cross-wavelet contrastive learning paradigm is adopted, where a dual-branch network is employed to mine the intrinsic differential features of coal and rock vibration signals. This is coupled with a hard-voting classifier to achieve efficient decision-making. Experimental results demonstrate that the proposed method significantly outperforms traditional models in terms of recognition robustness under strong noise interference. Moreover, the decision-making mechanism has been validated through frequency-domain interpretability analysis, aligning well with engineering expertise.},
  archive      = {J_ASOC},
  author       = {Faming Lu and Yi Liu and Zedong Lin and Xiangqi Han and Cong Liu},
  doi          = {10.1016/j.asoc.2025.113984},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {113984},
  shortjournal = {Appl. Soft. Comput.},
  title        = {SiamWT-CRNet: A siamese wavelet network with cross-domain feature fusion for dynamic coal-rock recognition in top-coal caving systems},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rethinking unsupervised time series anomaly detection: Dynamic attention based on route inverse-masking. <em>ASOC</em>, <em>186</em>, 113971. (<a href='https://doi.org/10.1016/j.asoc.2025.113971'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised time series anomaly detection holds significant importance for the development of modern industries. Hard-to-Detect Time series Anomalous points (HDTA) represent a core challenge in this field. Existing methods show limited effectiveness in handling subtle fluctuation anomalies and fail to fully exploit the periodic characteristics of time series. This paper proposes a R oute Inverse- M asking D ynamic A ttention (RMDA) framework for anomaly detection. The core innovations of RMDA include: designing a dynamic routing mechanism that identifies strongly correlated regions based on statistical differences in attention weight distributions, proposing an inverse masking strategy that amplifies discriminative capability by exploiting the difference between periodicity in normal points and non-periodicity in anomalous points, and constructing a normal-abnormal amplifier that enhances anomaly features by filtering out low-fluctuation regular components. This method establishes a new anomaly detection criterion based on periodic differences in attention distributions. Extensive experiments on four benchmark datasets demonstrate that RMDA reduces F1-score error rates by 14.52 %, 23.33 %, 35.45 %, and 7.82 % on MSL, SMAP, PSM, and SMD datasets respectively compared to state-of-the-art methods, significantly improving HDTA detection performance.},
  archive      = {J_ASOC},
  author       = {Enguang Zuo and Jie Zhong and Chen Chen and Cheng Chen and Kurban Ubul and Xiaoyi Lv},
  doi          = {10.1016/j.asoc.2025.113971},
  journal      = {Applied Soft Computing},
  month        = {1},
  pages        = {113971},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Rethinking unsupervised time series anomaly detection: Dynamic attention based on route inverse-masking},
  volume       = {186},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
