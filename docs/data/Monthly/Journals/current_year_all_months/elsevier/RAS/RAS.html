<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>RAS</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ras">RAS - 46</h2>
<ul>
<li><details>
<summary>
(2026). Design and development of a novel desktop robot for orthodontic archwire forming. <em>RAS</em>, <em>196</em>, 105243. (<a href='https://doi.org/10.1016/j.robot.2025.105243'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Orthodontic archwires are crucial for effective straightening teeth and improved oral health, leveraging their memory rebound properties to deliver consistent corrective forces. Manual archwire bending by orthodontists is time-consuming and prone to inaccuracies due to skill variability and the inherent complexity of three-dimensional wire manipulation. While automated archwire bending systems hold promise, current solutions struggle to simultaneously achieve the necessary accuracy, flexibility, cost-effective, and versatility for patient-specific customization. Acknowledging that the fundamental bending mechanism employs established principles, this paper presents a novel and cost-effective desktop robot specifically designed to overcome these limitations and automatically tailor the specific demands of orthodontic archwire formation. The system features bending node planning, a die-changing mechanism for versatile wire manipulation, precise wire feeding and rotation, and accurate bending and cutting capabilities. The key innovations include intelligent bending node planning for creating complex archwire geometries, overcoming the difficulty of visualizing and executing multi-planar bends, and the formulation of a quantitative bending angle model coupled with alloy-specific springback compensation, enabling precise control over archwire formation. This, along with optimized bending node planning, enables efficient generation of complex archwire shapes. A functional prototype of the desktop archwire bending robot has been developed and rigorously tested, demonstrating its ability to form both labial and hyperbolic lip archwires. While the robot exhibits strong performance, deviations were observed in the test samples, with discrepancies between designed and formed labial archwires of 1.92 % in width and 4.29 % in height. Hyperbolic lip archwire parameters showed errors ranging from 1.51 % to 6.94 %. These results highlight the robot's potential and provide a basis for future refinements to further enhance accuracy and robustness.},
  archive      = {J_RAS},
  author       = {Zhengdong Zhou and Zeyi Yang and Zefeng Song and Yuan Gong and Zhaozhao Li and Zhi Cai and Mengyao Yuan and Xiaoxi Yuan},
  doi          = {10.1016/j.robot.2025.105243},
  journal      = {Robotics and Autonomous Systems},
  month        = {2},
  pages        = {105243},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Design and development of a novel desktop robot for orthodontic archwire forming},
  volume       = {196},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Design and motion stability analysis of a straddle-type live working robot for power distribution lines. <em>RAS</em>, <em>196</em>, 105241. (<a href='https://doi.org/10.1016/j.robot.2025.105241'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The motion stability of live working robots on power cables is a key factor influencing operational efficiency. Currently, most of these robots employ a suspended structure, which limits the accuracy of position localization and impairs the clarity of cable condition observation. Additionally, most stability analyses focus solely on the effects of external loads, while overlooking the impact of cable stiffness variations on the robot’s motion stability along the cable. This study first proposes a straddle-type live working robot and develops its control system, enabling safer and more reliable live operations directly on power cables. Subsequently, the robot’s tipping stability during cable traversal is analyzed, and dynamic models are established under three different cable stiffness conditions, leading to the identification of key factors influencing the robot’s motion stability. Finally, a simulated utility pole test bench is constructed to conduct experiments on motion control performance, tipping performance, and motion stability. Experimental results show that the robot’s control error remains below 6%, the minimum tipping angle ranges from 29° to 32°, and the average Jerk is less than 2 m/s ³. These findings are expected to contribute to substantial advancements in the development of live working robots.},
  archive      = {J_RAS},
  author       = {Shangkun Cheng and Daozhu Wei and Zhaowen Hu and Hui Song and Qi Chen and Wei Wang},
  doi          = {10.1016/j.robot.2025.105241},
  journal      = {Robotics and Autonomous Systems},
  month        = {2},
  pages        = {105241},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Design and motion stability analysis of a straddle-type live working robot for power distribution lines},
  volume       = {196},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A model-based approach for co-simulation-driven digital twins in robotics. <em>RAS</em>, <em>196</em>, 105240. (<a href='https://doi.org/10.1016/j.robot.2025.105240'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A digital twin (DT) for a robot can support its development and deployment; it is a valuable resource for simulation and monitoring. Creating a DT for a robot, however, is not an easy task, involving heterogeneous simulation models potentially developed by several stakeholders. This paper proposes a systematic and highly automated approach to develop a DT for a robot based on diagrammatic models and on an industry standard for co-simulation: the Functional Mockup Interface (FMI). Our modelling notation is RoboSim, a tool-independent framework to model, verify, and generate code for control software and for simulations of physical robotic platforms. We take advantage of RoboSim’s facilities for structured modelling and code generation to obtain results that help bridge the reality gap and produce DTs with less engineering effort. We present here our technique, using a manufacturing cell as a case study, and its assessment based on existing criteria for DT frameworks. The evaluation establishes that our technique provides significant coverage (specifically, 60%) of the Digital Twinning spectrum.},
  archive      = {J_RAS},
  author       = {Santiago Gil and Arjun Badyal and Alvaro Miyazawa and Peter Gorm Larsen and Ana Cavalcanti},
  doi          = {10.1016/j.robot.2025.105240},
  journal      = {Robotics and Autonomous Systems},
  month        = {2},
  pages        = {105240},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A model-based approach for co-simulation-driven digital twins in robotics},
  volume       = {196},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). GBAGC-RL: Goal-based arm-gripper coordination reinforcement learning approach for robotic manipulation skills. <em>RAS</em>, <em>196</em>, 105239. (<a href='https://doi.org/10.1016/j.robot.2025.105239'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research on robotic manipulation via reinforcement learning (RL) has garnered significant attention. However, RL faces hurdles in complex tasks because of high state–action dimensions and reward design complexities. It is important to find an easy-to-use framework to quickly achieve the representation, learning and generalization of robotic manipulation skills. This article proposes a novel manipulation learning method for complex robotic tasks. The key insight is that all complex manipulation tasks involve coordinated arm-gripper collaborative movements in the task space. By using a task representation and subgoal extraction algorithm to discern motion patterns and subgoals, this method addresses the “what to do” aspect of robotic manipulation tasks. Subsequently, it integrates goal-based hierarchical reinforcement learning (HRL) with pretrained foundational skills to address the challenge of “how to do”. This framework, called “goal-based arm-gripper coordination RL” (GBAGC-RL), integrates task representation, subgoal extraction, and goal-based hierarchical reinforcement learning to attain efficient and transferable robotic manipulation skills while drastically simplifying the design of the reward function. Simulation evaluations on multiple complex manipulation tasks demonstrate that the proposed framework exhibits strong generalization and transfer capabilities, outperforms many leading RL methods, and achieves higher task success rates with more stable manipulation skills.},
  archive      = {J_RAS},
  author       = {Xiaofan Yang and Yubin Liu and Guoqing Chu and Junyu Wu and Zhuoqi Man and Xuanming Cao and Jie Zhao},
  doi          = {10.1016/j.robot.2025.105239},
  journal      = {Robotics and Autonomous Systems},
  month        = {2},
  pages        = {105239},
  shortjournal = {Robot. Auton. Syst.},
  title        = {GBAGC-RL: Goal-based arm-gripper coordination reinforcement learning approach for robotic manipulation skills},
  volume       = {196},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Emergency obstacle avoidance trajectory planning under dynamics characteristics constraints of corner module architecture intelligent electric vehicle. <em>RAS</em>, <em>196</em>, 105238. (<a href='https://doi.org/10.1016/j.robot.2025.105238'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The corner module architecture intelligent electric vehicle (CAV) exhibits superior dynamics characteristics advantages. However, existing trajectory planning methods fail to exploit these advantages, making it difficult to simultaneously ensure the intended trajectory safety and vehicle stability in response to emergency scenarios. To address the above issues, a model predictive trajectory planning integrating CAV dynamics characteristics constraints (MPTP-IDCC) method is proposed. First, a three-degree-of-freedom vehicle dynamics model incorporating the four-wheel independent steering and four-wheel independent driving (4WIS-4WID) characteristics of CAV is established as the predictive model, while a kinematic model is developed for dynamic obstacle trajectory prediction. Subsequently, collision detection is implemented using a three-circle approximation of the vehicle contour, and an obstacle avoidance cost function is designed based on the spatial distribution characteristics of obstacles along the global path. Next, the path-velocity planning problem is addressed within the model predictive trajectory planning framework, and a dynamic lateral stability region is constructed based on the dynamics characteristics constraints of the CAV, with penalties imposed on vehicle state points deviating from the stability region within the prediction horizon. Finally, the effectiveness of MPTP-IDCC is verified through simulations and hardware-in-the-loop (HIL) experiments, the results indicate that the proposed method can effectively handle sudden obstacle avoidance scenarios, and the planned local obstacle avoidance trajectories ensure both trajectory safety and vehicle stability.},
  archive      = {J_RAS},
  author       = {Minghui Zhao and Pan Gao and Lipeng Zhang and Shuangji Yao and Minghao Zhang and Junda Zhang},
  doi          = {10.1016/j.robot.2025.105238},
  journal      = {Robotics and Autonomous Systems},
  month        = {2},
  pages        = {105238},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Emergency obstacle avoidance trajectory planning under dynamics characteristics constraints of corner module architecture intelligent electric vehicle},
  volume       = {196},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Design and testing of a universal platform for search and rescue operation: Exploring indoor and outdoor potentials. <em>RAS</em>, <em>196</em>, 105237. (<a href='https://doi.org/10.1016/j.robot.2025.105237'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale natural and human-caused disasters have created significant challenges for worldwide Search and Rescue (SAR) operations, highlighting persisting concerns related to the efficiency and technical limitations of existing technologies. To address these challenges, the proposed Universal Platform for Search and Rescue integrates various technologies, including a voice-guided control system, advanced 3D reconstruction techniques, and a people tracker and follower system. A central feature of our work is the platform’s universality: our system acts as an additional, modular controller that can connect to any robotic platform—commercial or custom—that supports text-based command communication via network or cable. The system does not replace original robot logic, but rather extends capabilities with minimal integration. Tests showed that the platform can effectively execute voice commands and track a specified route even in high-wind (23 km/h) and noisy environments (70–100 dB for the Drone, 65–99.6 dB for the Quadruped), providing a user-friendly and intuitive interaction for users across different skill levels. Performance metrics indicated strong quality in 3D scene reconstruction with significant similarity between the reconstructed images and reference images (Drone: indoor: 0.82 SSIM, outdoor: 0.81 SSIM; Quadruped: indoor: 0.79 SSIM, outdoor: 0.58 SSIM). Consequently, the immersive 3D mapping reconstruction facilitated prompt and precise terrain assessments for both internal and external operations. Furthermore, the integration of real-time video streaming and cloud-based connectivity optimized the data flow and strengthened communication during operations, allowing person face identification, 3D tracking, and following.},
  archive      = {J_RAS},
  author       = {D. Cafolla and B.D.M. Chaparro-Rico and X. Xie},
  doi          = {10.1016/j.robot.2025.105237},
  journal      = {Robotics and Autonomous Systems},
  month        = {2},
  pages        = {105237},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Design and testing of a universal platform for search and rescue operation: Exploring indoor and outdoor potentials},
  volume       = {196},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A review of visual perception for robotic bin-picking. <em>RAS</em>, <em>196</em>, 105236. (<a href='https://doi.org/10.1016/j.robot.2025.105236'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic bin-picking is a critical operation in modern industry, which is characterised by the detection, selection, and placement of items from a disordered and cluttered environment, which can be boundary limited or not, e.g. bins, boxes or containers. In this context, perception systems are employed to localise, detect and estimate grasping points. Despite the considerable progress made, from analytical approaches to recent deep learning methods, challenges still remain. This is evidenced by the growing innovation proposing distinct solutions. This paper aims to review perception methodologies developed since 2009, providing detailed descriptions and discussions of their implementation. Additionally, it presents an extensive study, detailing each work, along with a comprehensive overview of the advancements in bin-picking perception.},
  archive      = {J_RAS},
  author       = {Artur Cordeiro and Luís Freitas Rocha and José Boaventura-Cunha and Daniel Figueiredo and João Pedro Souza},
  doi          = {10.1016/j.robot.2025.105236},
  journal      = {Robotics and Autonomous Systems},
  month        = {2},
  pages        = {105236},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A review of visual perception for robotic bin-picking},
  volume       = {196},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multisensory mastery: Unleashing the power of vision and touch for contact-rich task learning. <em>RAS</em>, <em>196</em>, 105234. (<a href='https://doi.org/10.1016/j.robot.2025.105234'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contact-rich manipulation in unstructured environments requires effective fusion of tactile and visual feedback. This paper introduces a deep learning framework that enhances robotic intelligence and compliance for such tasks. Central to our approach are a memory block to capture historical patterns and an auxiliary loss function to refine motion trajectory predictions. Simulations on door-opening and drawer-pulling tasks demonstrate that motion deviation amplifies harmful interactions. Real-world experiments on Steering Wheel Turning, Handle Turning, and Drawer Pulling confirm that our framework compliantly adapts to force variations to complete the tasks. Our method outperforms baselines by achieving superior motion accuracy and reducing harmful components. Visualizations of the model’s attention scores further validate its interpretable fusion of multisensory data.},
  archive      = {J_RAS},
  author       = {Yibo Hu and Lai Wei and Yanzhe Wang and Yanding Wei and Qiang Fang},
  doi          = {10.1016/j.robot.2025.105234},
  journal      = {Robotics and Autonomous Systems},
  month        = {2},
  pages        = {105234},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Multisensory mastery: Unleashing the power of vision and touch for contact-rich task learning},
  volume       = {196},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). PentaFusion: Differentiable attention weighting for real-time LiDAR-camera fusion in edge autonomous vehicles. <em>RAS</em>, <em>196</em>, 105233. (<a href='https://doi.org/10.1016/j.robot.2025.105233'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LiDAR and camera data provide complementary advantages for autonomous vehicle systems. While various sensor fusion methods exist, current approaches suffer from information loss, which impedes navigation in complex driving scenarios. When integrating camera and LiDAR data, conventional late fusion often discards critical details. To address this, we employ convolutional neural networks for feature fusion. However, existing fusion techniques are inefficient for real-world autonomous driving tasks due to scenario complexity. To enhance context fusion efficiency and effectiveness in high-density traffic, we propose PentaFusion, a novel architecture leveraging attention mechanisms to combine multi-modal features extracted from LiDAR and camera inputs. Our method dynamically allocates feature-level attention weights to prioritize critical information. Experimental validation demonstrates that PentaFusion increases the average composite score from 40.72 to 53.12 – a statistically significant 30.45% improvement over baseline models. Notably, PentaFusion reduces computational complexity by 14.6% in FLOPs compared to the baseline, demonstrating its suitability for resource-constrained edge deployment while maintaining real-time performance},
  archive      = {J_RAS},
  author       = {Jie Zhang and Yu Lu and Xinghang Xu},
  doi          = {10.1016/j.robot.2025.105233},
  journal      = {Robotics and Autonomous Systems},
  month        = {2},
  pages        = {105233},
  shortjournal = {Robot. Auton. Syst.},
  title        = {PentaFusion: Differentiable attention weighting for real-time LiDAR-camera fusion in edge autonomous vehicles},
  volume       = {196},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A cooperative approach to range-only SLAM with undelayed initialization. <em>RAS</em>, <em>196</em>, 105230. (<a href='https://doi.org/10.1016/j.robot.2025.105230'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A 2D cooperative Range-Only SLAM problem is considered in this paper. In addition to odometry, available through noisy encoder readings on the actuated wheels, the robots measure the distances to a set of landmarks in unknown positions within the environment, as well as to other robots. Inter-landmark distances are not assumed to be available. The robots start at unknown locations, with their relative positions also assumed unknown. A Multi-Hypotheses Extended Kalman Filter, endowed with a Federated Information Sharing mechanism, is proposed to solve the problem in a computationally efficient way, without any delay in the initialization of landmark and robot position estimates. Simulation and experimental results are reported in the paper to demonstrate the effectiveness of the proposed approach, showing significant improvements in both steady-state and transient performance compared to the single-robot scenario.},
  archive      = {J_RAS},
  author       = {Lorenzo Bianchi and Francesco Martinelli},
  doi          = {10.1016/j.robot.2025.105230},
  journal      = {Robotics and Autonomous Systems},
  month        = {2},
  pages        = {105230},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A cooperative approach to range-only SLAM with undelayed initialization},
  volume       = {196},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Online planar inverse kinematics for superelastic nitinol rod driven discrete continuum robot units. <em>RAS</em>, <em>196</em>, 105227. (<a href='https://doi.org/10.1016/j.robot.2025.105227'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the actuation of discrete continuum robotic units, tendons or superelastic rods are favored over joint motor actuators due to the spatial constraints inherent in continuum robots, particularly in the context of medical robotics applications. Superelastic rods generally exhibit significantly higher tensile strength compared to tendons, enabling the development of more reliable and safe designs for continuum robots. Nonetheless, the inverse kinematics associated with superelastic rod-actuated discrete continuum robot units remain less explored in comparison to their tendon-driven counterparts. Consequently, this manuscript delineates the online calculation of planar inverse kinematics for discrete continuum robotic units aimed at controlling the bending angle of the robot through Elastica-based analysis. Utilizing the proposed methodology, the displacement of a Nitinol rod can be calculated with respect to the bending angle of a discrete continuum robotic unit. The efficacy of the proposed approach is substantiated through ANSYS simulation and experiment.},
  archive      = {J_RAS},
  author       = {Yeoun-Jae Kim and Daehan Wi},
  doi          = {10.1016/j.robot.2025.105227},
  journal      = {Robotics and Autonomous Systems},
  month        = {2},
  pages        = {105227},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Online planar inverse kinematics for superelastic nitinol rod driven discrete continuum robot units},
  volume       = {196},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A comprehensive survey of lower limb assistive exoskeleton robots: Models, dynamics, mechanics, and control. <em>RAS</em>, <em>195</em>, 105232. (<a href='https://doi.org/10.1016/j.robot.2025.105232'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Movement disorders of the lower limbs due to stroke lead to abnormal walking and affect life, which requires the rehabilitation of patients to improve treatment. Lower limb exoskeleton robots are used to reduce the burden of therapists in rehabilitation. This comprehensive review addresses the multidisciplinary realm of lower limb assistive exoskeleton robots and extensively explores their models, dynamics, mechanics, sensors, actuators, and control. This survey examines various modeling approaches, including musculoskeletal dynamics, human–robot interaction, and complex interactions between the mechanical structure of the exoskeleton and the human body. In addition, it deals with the dynamics and mechanics underlying design and covers areas such as kinematics, energy transfer mechanisms, and the innovative application of adaptive mechanisms. The report also goes into great detail about the control systems built into these exoskeletons, talking about things like complex control architectures, real-time adaptation, and smooth coordination with the user’s movements. Also, the study goes into great detail about human aspects and user experience, which helps us understand the important link between technology and human interaction. This survey is an important tool for researchers, doctors, and engineers that will help them make progress and generate new ideas in assistive robotics.},
  archive      = {J_RAS},
  author       = {Ali Foroutannia and Masoud Mohammadian},
  doi          = {10.1016/j.robot.2025.105232},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105232},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A comprehensive survey of lower limb assistive exoskeleton robots: Models, dynamics, mechanics, and control},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Reinforcement learning-driven heuristic path planning method for automated special vehicles in unstructured environment. <em>RAS</em>, <em>195</em>, 105231. (<a href='https://doi.org/10.1016/j.robot.2025.105231'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at improving the adaptability of global path planning method for the Automated Special Vehicles (ASVs) in a variety of unstructured environments, a reinforcement learning (RL)-driven heuristic path planning method is proposed. The introduction of traditional heuristic algorithm avoids inefficiency of RL in the early learning phase, and it provides a preliminary planning path to be adjusted by RL. Furthermore, a reward function is designed based on vehicle dynamics to generate a smooth, stable, and efficient path. The simulation environments are established based on real terrain data. The algorithm's performance is evaluated by testing various starting and ending points across different terrains. This paper also examines how obstacle distributions and ground conditions affect ASV path planning. Results demonstrate that the proposed method generates collision-free, efficient paths while maintaining excellent adaptability to diverse complex terrains.},
  archive      = {J_RAS},
  author       = {Fei-xiang Xu and Yan-chen Wang and De-qiang Cheng and Wei-guang An and Chen Zhou and Qi-qi Kou},
  doi          = {10.1016/j.robot.2025.105231},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105231},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Reinforcement learning-driven heuristic path planning method for automated special vehicles in unstructured environment},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MMSeg: A multimodal multi-scale point cloud segmentation model for navigable areas in complex field environments. <em>RAS</em>, <em>195</em>, 105229. (<a href='https://doi.org/10.1016/j.robot.2025.105229'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on advanced navigable area perception technology to address critical applications such as battlefield support and emergency rescue for autonomous ground intelligent agents. It emphasizes its application in complex field environments characterized by unstructured, diverse, and intricate features. Current methods predominantly target structured environments, neglecting the unique challenges presented by unstructured terrains essential for critical applications such as battlefield support and emergency rescue missions. To address this gap, we propose three key contributions through a Multimodal Multi-scale point cloud Segmentation (MMSeg) model. First, we introduce a multimodal ground feature fusion technique that integrates geometric information from LiDAR point clouds with visual texture features from images, enhancing the recognition capabilities of heterogeneous ground surfaces. Second, we propose a local–global terrain geometry information enhancement method that utilizes a dual-attention mechanism to effectively capture and analyze both local and global geometric features in complex terrain conditions. Third, we design a multi-scale classifier framework that effectively processes the multimodal fused information of ground materials and terrain structures, enabling precise segmentation of navigable areas. An experiment on a dedicated platform demonstrates that the MMSeg model achieves mIoU 6% higher than commonly used point cloud segmentation models. These findings suggest that the MMSeg model significantly enhances the perception capabilities of autonomous ground intelligent agents in challenging environments, providing a promising and novel solution to improve their operational effectiveness in complex field conditions.},
  archive      = {J_RAS},
  author       = {Yifang Huang and Hongdou He and Peng Shi and Xiaobing Hao and Haitao He and Pei Miao},
  doi          = {10.1016/j.robot.2025.105229},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105229},
  shortjournal = {Robot. Auton. Syst.},
  title        = {MMSeg: A multimodal multi-scale point cloud segmentation model for navigable areas in complex field environments},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Trajectory control for a quadrotor unmanned aerial vehicle: Adaptive super-twisting terminal sliding mode with adjustable recurrent neural network. <em>RAS</em>, <em>195</em>, 105228. (<a href='https://doi.org/10.1016/j.robot.2025.105228'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores how to control the trajectory of a quadrotor UAV (Unmanned Aerial Vehicle) in unpredictable environments with external disturbances. We address the challenge of designing a controller when the UAV’s mass and inertia are unknown, which makes real-time modeling difficult. To solve this problem, we developed an adjustable recurrent neural network (ARNN) that more accurately approximates the necessary control actions. There are actually some problems when using an RNN in the design of UAV control algorithms: it produces insufficiently accurate control approximations, it is difficult to generalize across different tasks for various UAVs, and the neural network’s own gradient disappears during the training process. To improve its performance, we designed the ARNN with a flexible activation function controlled by an adjustable parameter, which improves its adaptability to different data types and reduces training problems. We also refined the self-feedback mechanism to increase the accuracy of the control approximation. The whole system combines a super-twisting sliding mode control algorithm with the ARNN. We introduce a new super-twisting algorithm that accelerates convergence and reduces the chattering problem in sliding mode controllers through an exponential nonlinear term. Using Lyapunov functions and the Lassalle invariance principle, we show that our method ensures global convergence in finite time. Simulation results confirm the effectiveness and advantages of our approach for UAV trajectory tracking.},
  archive      = {J_RAS},
  author       = {Peike Huang and Zhanshan Zhao and Xinghao Qin and Hua Wang},
  doi          = {10.1016/j.robot.2025.105228},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105228},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Trajectory control for a quadrotor unmanned aerial vehicle: Adaptive super-twisting terminal sliding mode with adjustable recurrent neural network},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Individualized continuous lower-limb joint kinematics modeling enhanced by discrete cosine transform. <em>RAS</em>, <em>195</em>, 105226. (<a href='https://doi.org/10.1016/j.robot.2025.105226'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective joint trajectory planning is critical in prosthetic control systems, as coordinated, continuous locomotion trajectories not only improve wearer comfort but also facilitate the restoration of normative biomechanics across a wide range of locomotor tasks. This paper proposes a novel approach to predict joint trajectories for continuous locomotion tasks. First, Fourier series are used to fit the multi-cycle gait data, addressing the potential phase shift issues and mitigating the influence of outlier data. Next, the human locomotion data are transformed into Discrete Cosine Transform Coefficients (DCTCs) via the Discrete Cosine Transform (DCT). Subsequently, different regression models—including Gaussian Process Regression (GPR) and Least Squares - Support Vector Machine (LS‑SVM)—are then trained to capture the relationship between each DCTC and its associated task. This combination of DCT with either GPR or LS-SVM can significantly reduce the computational complexity, thus improving computational speed and prediction accuracy. Furthermore, based on the consistency of the difference between individual joint locomotion trajectories and inter-subject mean trajectories at the same incline, we propose a gait trajectory personalization method to enable kinematic models to match individual joint kinematics. Using a publicly available gait dataset with multiple subjects, we validate the effectiveness of the proposed approach. The results show that the GPR‑based model yields lower root‑mean‑square error (RMSE), while the LS‑SVM–based model produces fewer clusters of data points with significant deviations from the true data. The personalized model can efficiently and accurately predict gait trajectories over continuously varying tasks, even with limited gait data.},
  archive      = {J_RAS},
  author       = {Xiaoguang Wu and Zhihui Dong and Xiaochen Niu and Hongbin Lin and Yihao Du},
  doi          = {10.1016/j.robot.2025.105226},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105226},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Individualized continuous lower-limb joint kinematics modeling enhanced by discrete cosine transform},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Effect of efficiently computed explanations for robot motion planning failures in human–robot interaction. <em>RAS</em>, <em>195</em>, 105224. (<a href='https://doi.org/10.1016/j.robot.2025.105224'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transparent interaction between an operator and a robotic system is essential for successful task completion. This requires a mutual understanding of decisions and processes in order to provide accurate diagnoses and troubleshooting suggestions in the event of an error. In the motion planning domain, a deep understanding of the decisions made by the system is essential for the successful navigation of a robot in dynamic environments. Due to inaccuracies in the environment perception or in the configuration of the motion planner, robot motion planning incidents can occur that are difficult for the operator to understand. In this work, we present a method that is able to quickly provide explanations for motion planning failures. In the context of optimization-based planners, failures related to planning constraints can be identified using an adaptation of the diagnosis algorithm FastDiag. It is able to provide a preferred minimal diagnosis in logarithmic time, even for large sets of constraints. To evaluate the potential of the proposed method, we conduct a user study to investigate the impact of the provided explanations of motion planning failures on the operator’s performance, trust, and workload. The results show that quickly providing additional explanations for failed motion planning improves task completion time, overall trust in the system, and reduces the number of interactions required. However, no effect was found on perceived workload.},
  archive      = {J_RAS},
  author       = {Matthias Eder and Bettina Kubicek and Gerald Steinbauer-Wagner},
  doi          = {10.1016/j.robot.2025.105224},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105224},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Effect of efficiently computed explanations for robot motion planning failures in human–robot interaction},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Finger flow: Reactive reach-while-grasp generation for robotic arms with multi-fingered hands. <em>RAS</em>, <em>195</em>, 105222. (<a href='https://doi.org/10.1016/j.robot.2025.105222'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans effortlessly grasp both stationary and moving objects in one-shot motions, fluidly adapting to disturbances and automatically recovering from failed attempts. In contrast, robots with multi-fingered hands often rely on pre-planned, sequential “reach-then-grasp” strategies, which result in slow, unnatural motions and restrict the robot’s ability to react dynamically to changes in the object’s location. Moreover, open-loop execution oftentimes leads to grasp failures. To address these challenges, we introduce Finger Flow (FF), a reactive motion generator that uses the visual feedback from an onboard camera and position feedback from fingers and arms to robustly reach and grasp stationary and moving objects with unpredictable behavior. During the reaching, FF continuously guides the hand to avoid finger-object collisions and adjusts the hand’s reactive opening and closure based on its relative position to the object. This state-dependent behavior results in automatic recovery from failed grasp attempts. We also provide formal guarantees of convergence and collision avoidance for stationary spherical objects. We evaluate FF on the DLR humanoid robot neoDavid , equipped with a multi-fingered hand, and quantitatively assess its performance in a series of grasping experiments involving fast and reactive grasping of a stationary or unpredictable spatially moving object. Running in a closed loop at 3 kHz, FF achieves an 87 % grasp success rate on the stationary object placed at random positions over 130 attempts. Interactive and adversarial human-to-robot handover experiments further demonstrate the robustness and effectiveness of FF.},
  archive      = {J_RAS},
  author       = {Xuming Meng and Henry Maurenbrecher and Alin Albu-Schäffer and Manuel Keppler},
  doi          = {10.1016/j.robot.2025.105222},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105222},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Finger flow: Reactive reach-while-grasp generation for robotic arms with multi-fingered hands},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Research on surface fitting technology for aircraft point cloud feature region based on adaptive complete natural segmentation. <em>RAS</em>, <em>195</em>, 105221. (<a href='https://doi.org/10.1016/j.robot.2025.105221'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional point cloud processing and recognition technologies are gaining increasing importance in industrial applications. Efficient processing of aircraft point cloud is critical for automated inspection and 3D reconstruction in maintenance, repair, and overhaul (MRO) operations. This paper presents a systematic framework for aircraft point cloud processing with four key technical innovations: First, leveraging the geometric characteristics of aircraft surfaces, we develop a Constrained Principal Component Analysis (CPCA) method to automatically align the raw coordinate system with the aircraft's airframe coordinate system. Second, we propose an Adaptive Complete Natural Segmentation (ACNS) algorithm that achieves complete partitioning of aircraft point cloud into natural partitions using adaptively computed curvature and angle thresholds. Experimental results demonstrate the superior performance of ACNS, completing segmentation 3 minutes and 5 seconds faster than hierarchical clustering while achieving 88.86 % overall accuracy - a 19.91 % improvement over hierarchical clustering, 37.06 % over K-means, and 4.22 % over Parallel PointNet (PPN). Third, an automated partition identification system is established to streamline surface fitting and enhance visualization for maintenance operations. Fourth, we present an enhanced Random Sample Consensus (RANSAC) algorithm with adaptive distance thresholds, reducing average fitting errors by 64.94 % in fuselage surface reconstruction. The proposed framework significantly improves point cloud processing in aviation, particularly for automated inspection. Experimental validation confirms the advancement of the proposed framework in both computational efficiency and geometric accuracy over conventional methods.},
  archive      = {J_RAS},
  author       = {Wei Zhang and Aoxin Xiong and Boli Zhang},
  doi          = {10.1016/j.robot.2025.105221},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105221},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Research on surface fitting technology for aircraft point cloud feature region based on adaptive complete natural segmentation},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Smooth motion planning method for mobile robots in dynamic environments. <em>RAS</em>, <em>195</em>, 105220. (<a href='https://doi.org/10.1016/j.robot.2025.105220'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smooth motion planning methods are essential for efficient, safe, and real-time navigation of nonholonomic mobile robots in dynamic and complex environments while avoiding obstacles. This paper presents a novel smooth motion planning method, combining two main parts: a path planner integrating the Two Way D ∗ algorithm and clothoids, and a trajectory planner. Our proposed method generates continuous, collision-free, and near time-optimal trajectories for nonholonomic mobile robots. It is capable of working in real-time because of algorithmic simplicity and the ability to rapidly determine new replanned paths in the presence of unknown obstacles. Simulation results demonstrate that our method, compared to similar methods, can achieve a shorter trajectory length, shorter traveling time, and shorter path planning time. We have validated the efficiency of our method through experiments conducted on a Husky mobile robot.},
  archive      = {J_RAS},
  author       = {Ana Šelek and Marija Seder},
  doi          = {10.1016/j.robot.2025.105220},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105220},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Smooth motion planning method for mobile robots in dynamic environments},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A novel digital twin model based bio-heuristic sliding mode control algorithm for trajectory tracking control of USV in the presence of complex marine environment disturbance. <em>RAS</em>, <em>195</em>, 105219. (<a href='https://doi.org/10.1016/j.robot.2025.105219'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The trajectory tracking control problem of unmanned surface vessel (USV) under the complex marine environmental disturbance is discussed in this paper, and a novel digital twin model based bio-heuristic sliding mode control (SMC) algorithm integrated with a radial basis function neural network (RBFNN) disturbance compensation module is proposed. An adaptive forgetting factor, which varies with the prediction errors of state variables, is introduced and integrated into the recursive least squares (RLS) algorithm. Meanwhile, a digital twin model of USV is established by applying the proposed adaptive forgetting factor recursive least squares (AFF-RLS) algorithm, and utilizing state variable data and control commands. An improved bio-heuristic approximation function is presented to approach the virtual velocity control laws, avoiding abrupt change and jittering of the SMC algorithm designed based on the digital twin model. Set the angular and linear velocity variables as inputs, environment disturbances and modeling errors compensation as outputs, the RBFNN based integrated control compensator is presented, where the minimum parameter learning method is implemented by replacing the adjustment of neural network weights with parameter estimation to reduce redundant parameters. The effectiveness of the proposed algorithm is validated through extensive simulation experiments, demonstrating its robustness in real marine environment disturbance.},
  archive      = {J_RAS},
  author       = {Zaopeng Dong and Sihang Lu and Zhihao Hu and Wangsheng Liu and Yilun Ding and Yuanchang Liu},
  doi          = {10.1016/j.robot.2025.105219},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105219},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A novel digital twin model based bio-heuristic sliding mode control algorithm for trajectory tracking control of USV in the presence of complex marine environment disturbance},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A new SMART gripper with soft fingers and integrated force sensors for adaptive robotic tasks. <em>RAS</em>, <em>195</em>, 105218. (<a href='https://doi.org/10.1016/j.robot.2025.105218'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decades, robotic manipulation has been treated as a cornerstone research topic to improve, accelerate but also safeguard human work in industrial, medical and everyday activities. For this reason, robotic hands are increasingly devoted to mimicking or augmenting human abilities. In particular, the two main operations performed by a human hand are precision and power grasping with the possibility of dosing the right grasping force to avoid breaks, deformations, or drops of the grasped objects. This paper presents the design, characterization and testing of a novel underactuated tendon-driven soft robotic gripper with sensing fingertips to regulate the applied contact force mimicking the ability of the human hand. The evolution of the design phases is presented and discussed together with the characterization procedures. Results of the grasping tests show the successful application of the new gripper in different tasks.},
  archive      = {J_RAS},
  author       = {Virginia Burini and Silvia Logozzo and Maria Cristina Valigi},
  doi          = {10.1016/j.robot.2025.105218},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105218},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A new SMART gripper with soft fingers and integrated force sensors for adaptive robotic tasks},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A behavior architecture for fast humanoid robot door traversals. <em>RAS</em>, <em>195</em>, 105217. (<a href='https://doi.org/10.1016/j.robot.2025.105217'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Towards the role of humanoid robots as squad mates in urban operations and other domains, we identified doors as a major area lacking capability development. In this paper, we focus on the ability of humanoid robots to navigate and deal with doors. Human-sized doors are ubiquitous in many environment domains and the humanoid form factor is uniquely suited to operate and traverse them. We present an architecture which incorporates GPU accelerated perception and a tree based interactive behavior coordination system with a whole body motion and walking controller. Our system is capable of performing door traversals on a variety of door types. It supports rapid authoring of behaviors for unseen door types and techniques to achieve re-usability of those authored behaviors. The behaviors are modeled using trees and feature logical reactivity and action sequences that can be executed with layered concurrency to increase speed. Primitive actions are built on top of our existing whole body controller which supports manipulation while walking. We include a perception system using both neural networks and classical computer vision for door mechanism detection outside of the lab environment. We present operator-robot interdependence analysis charts to explore how human cognition is combined with artificial intelligence to produce complex robot behavior. Finally, we present and discuss real robot performances of fast door traversals on our Nadia humanoid robot. Videos online at https://www.youtube.com/playlist?list=PLXuyT8w3JVgMPaB5nWNRNHtqzRK8i68dy .},
  archive      = {J_RAS},
  author       = {Duncan Calvert and Luigi Penco and Dexton Anderson and Tomasz Bialek and Arghya Chatterjee and Bhavyansh Mishra and Geoffrey Clark and Sylvain Bertrand and Robert Griffin},
  doi          = {10.1016/j.robot.2025.105217},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105217},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A behavior architecture for fast humanoid robot door traversals},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). FG-PE: Factor-graph approach for multi-robot pursuit–evasion. <em>RAS</em>, <em>195</em>, 105216. (<a href='https://doi.org/10.1016/j.robot.2025.105216'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing use of robots in daily life, there is a growing need to provide robust collaboration protocols for robots to tackle more complicated and dynamic problems effectively. This paper presents a novel, factor graph-based approach to address the pursuit–evasion problem, enabling accurate estimation, planning, and tracking of an evader by multiple pursuers working together. It is assumed that there are multiple pursuers and only one evader in this scenario. The proposed method significantly improves the accuracy of evader estimation and tracking, allowing pursuers to capture the evader in the shortest possible time and distance compared to existing techniques. In addition to these primary objectives, the proposed approach effectively minimizes uncertainty while remaining robust, even when communication issues lead to some messages being dropped or lost. Through a series of comprehensive experiments, this paper demonstrates that the proposed algorithm consistently outperforms traditional pursuit–evasion methods across several key performance metrics, such as the time required to capture the evader and the average distance traveled by the pursuers. Additionally, the proposed method is tested in real-world hardware experiments, further validating its effectiveness and applicability.},
  archive      = {J_RAS},
  author       = {Messiah Abolfazli Esfahani and Ayşe Başar and Sajad Saeedi},
  doi          = {10.1016/j.robot.2025.105216},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105216},
  shortjournal = {Robot. Auton. Syst.},
  title        = {FG-PE: Factor-graph approach for multi-robot pursuit–evasion},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Dynamic model and performance assessment of the natural motion of a SCARA-like manipulator in pick-and-place tasks. <em>RAS</em>, <em>195</em>, 105215. (<a href='https://doi.org/10.1016/j.robot.2025.105215'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The energy efficiency of manipulators performing cyclic motions can be enhanced by utilizing the so-called natural motion, namely, the natural oscillations that occur when elastic elements are placed in series or parallel with the actuators. In this paper, the natural motion of the RR-4R-R robot is discussed. This manipulator exhibits a 4-DOF mobility similar to that of the widespread SCARA robot, but the vertical prismatic joint is replaced by a four-bar mechanism. This modification, along with the adoption of a direct-drive actuator for the four-bar mechanism, makes it easier to achieve the elastic balancing of the robot, allowing the exploitation of its natural motion. The robot dynamics is analysed using the Lagrangian approach. Two types of elastic balancing are considered: one using a torsional spring and one using a linear coil spring. A simplified model of the vertical motion is then proposed, decoupled from the inertial effects of the horizontal motion, and used to estimate the vertical natural period. The behaviour of the manipulator with natural elastic balancing is compared with that obtained with exact elastic balancing, which provides an indifferent equilibrium in any robot position. This comparison is first carried out in the time domain, and then the space of the robot operating conditions is sampled through multibody simulations, performed to investigate the threshold of convenience between exact and natural balancing. Simulation results indicate that exploiting the natural motion of the RR-4R-R manipulator can significantly reduce energy consumption in a wide range of industrial applications involving pick-and-place tasks.},
  archive      = {J_RAS},
  author       = {Luca Bruzzone and Matteo Verotti and Pietro Fanghella},
  doi          = {10.1016/j.robot.2025.105215},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105215},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Dynamic model and performance assessment of the natural motion of a SCARA-like manipulator in pick-and-place tasks},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Towards trajectory following and vision-based collision avoidance for micro aerial vehicles with deep reinforcement learning. <em>RAS</em>, <em>195</em>, 105214. (<a href='https://doi.org/10.1016/j.robot.2025.105214'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enabling Micro Aerial Vehicles to autonomously follow a reference position trajectory while effectively avoiding collisions is a task of paramount importance in many aerial applications. Most of the approaches adopted to address this problem employ modular navigation architectures. These suffer from inherent drawbacks, including the dependence on costly sensing equipment and the reliance on detailed information about the environmental characteristics and the shape and distribution of obstacles. On the other hand, most of the modern data-driven approaches exhibit numerous limitations and primarily address simplified versions of the task, which often entail tight constraints on the mobility of the drone. In this paper, we employ the Deep Reinforcement Learning framework to train a control policy that addresses the trajectory following and the collision avoidance problem in a unified manner using visual data. Differently from most of the existing methods, our model requires only pose measurements and depth maps captured by a front-looking camera. Moreover, it operates without assumptions about the shape, size and placement of obstacles and permits the drone to freely navigate the three-dimensional space. Through comprehensive evaluations in photo-realistic simulated environments and in a mixed-reality setting, both involving a variety of static obstacles, we validate the effectiveness and generalization capabilities of our strategy against different state-of-the-art baselines.},
  archive      = {J_RAS},
  author       = {Raffaele Brilli and Alberto Dionigi and Marco Legittimo and Francesco Crocetti and Mirko Leomanni and Mario Luca Fravolini and Gabriele Costante},
  doi          = {10.1016/j.robot.2025.105214},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105214},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Towards trajectory following and vision-based collision avoidance for micro aerial vehicles with deep reinforcement learning},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Ellipsoid uncertainty tether model for collision avoidance in a fleet of remotely operated vehicles. <em>RAS</em>, <em>195</em>, 105213. (<a href='https://doi.org/10.1016/j.robot.2025.105213'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During collision avoidance, the tether of Remote Operated Vehicle (ROV) is subject to entanglement with obstacles or other ROVs’ tether. This specificity renders traditional multi-robot obstacle avoidance approaches inadequate for tethered multi-robot scenarios. This paper proposes a guaranteed ellipsoid model for representing the ROV’s tether and its nearby obstacles, enabling an efficient, low-computation collision avoidance method for a fleet of ROVs. The model ensures that if the ellipsoid encompassing the tether remains entirely outside the ellipsoid encompassing an obstacle, there is no risk that the tether collides with it. The approach requires only the two attachment points of the tether and its length, without needing any information about the tether’s shape, dynamics, or external disturbances such as underwater currents. A collision avoidance strategy is developed based on potential field methods combined with tether length management. When multiple ROVs are involved, personalities are added to ROV to obtain different behaviors, reducing the likelihood of deadlocks during avoidance maneuvers. Simulations demonstrate the method’s effectiveness across various scenarios, and its limitations are also discussed.},
  archive      = {J_RAS},
  author       = {Christophe Viel},
  doi          = {10.1016/j.robot.2025.105213},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105213},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Ellipsoid uncertainty tether model for collision avoidance in a fleet of remotely operated vehicles},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Rolling mechanism and performance of a soft robot driven by local curvature loading. <em>RAS</em>, <em>195</em>, 105212. (<a href='https://doi.org/10.1016/j.robot.2025.105212'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous rolling soft robots are usually hard to achieve balanced rolling performance (terrain adaptability, rolling velocity and energy efficiency). This paper proposes a rolling soft robot driven by local curvature loading, which demonstrates good rolling velocity, small deformation rate, good energy efficiency and excellent terrain adaptability. A theory based on the energy method is established to analyze the rolling mechanism of the soft robot and to determine the critical loading curvature, which is validated by experiments. The local curvature loading causes the deformation of the entire robot configuration and results in the shift of the gravity center, which generates a gravity torque to drive the rolling of the soft robot when the critical loading curvature is reached. The proposed soft robot has good average rolling velocity (182.9 mm/s or 0.938 body length per second, BL/s) and can adapt to a variety of complex terrains such as the stairs (stair height 15 mm), the slope (slope angle 12.4 °) and the wide broken bridge (gap length 100 mm or 0.526 BL). The study in this work demonstrates broad application prospect in the fields of biomedical therapy, exploration, searching and rescuing, which provides a new idea for the structural design and performance improvement of rolling soft robots.},
  archive      = {J_RAS},
  author       = {Pengfei Yang and Luyu Gao and Ruixing Huang and Yuyang Xiong and Yuqing Mao and Feng Huang and Fei Dang},
  doi          = {10.1016/j.robot.2025.105212},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105212},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Rolling mechanism and performance of a soft robot driven by local curvature loading},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Online learning for agile underwater maneuvering: Gaussian processes and sparse regression for data-driven model predictive control. <em>RAS</em>, <em>195</em>, 105211. (<a href='https://doi.org/10.1016/j.robot.2025.105211'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous underwater vehicles (AUVs) show much promise in environmental sensing, aquaculture, and security applications. Robust and adaptive control strategies can immensely benefit these scenarios by increasing autonomy and endurance. However, AUVs are nonlinear systems whose dynamics are challenging to model, especially during agile maneuvers at high angles of attack. To better capture these nonlinear effects, this paper proposes a physics-informed system identification scheme that combines prior knowledge of the system dynamics with data-driven regression. Strategies including Sparse Identification of Nonlinear Dynamics (SINDy), nonlinear least squares regression, and Gaussian processes (GPs) are used to learn the AUV dynamics online from measured data. These data-driven models are then implemented in an adaptive model predictive controller (MPC) for agile maneuvering that drives the system to a set point while updating the prediction model when new measurements are available. The performance of these three system identification strategies is evaluated on two different 6-DOF AUV platforms. All three strategies show good real-time performance, while the GP model offers the best balance between accuracy, speed and robustness. Field experimental data from the SAM AUV and the MOLA AUV are used for performance evaluation.},
  archive      = {J_RAS},
  author       = {Sriharsha Bhat and Giancarlo Troni and Ivan Stenius},
  doi          = {10.1016/j.robot.2025.105211},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105211},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Online learning for agile underwater maneuvering: Gaussian processes and sparse regression for data-driven model predictive control},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). OVGrasp: Target-oriented open-vocabulary robotic grasping in clutter. <em>RAS</em>, <em>195</em>, 105210. (<a href='https://doi.org/10.1016/j.robot.2025.105210'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic recognizing and grasping of novel-category objects in cluttered environments presents a significant challenge due to occlusions and complex object arrangements. In addition, the ability to integrate language instructions is crucial for obtaining target object. In this work, we propose OVGrasp, an open-vocabulary grasping framework that seamlessly integrates vision and language to enhance robotic manipulation capabilities. Our approach leverages a unified integration of pretrained vision-language and grasping models, incorporates cross-modality alignment modules to enhance visual-linguistic perception, and uses a multi-scale voxel based point cloud representation for precise grasp-pose estimation in cluttered environments. By jointly modeling vision, language, and action, OVGrasp eliminates the reliance on predefined object labels and handcrafted rules, enabling more adaptable and efficient grasping. Extensive experiments in both simulation and real-world settings demonstrate that our method can achieve better task success rate by less times of motion, outperforming state-of-the-art methods under open-vocabulary language instructions in cluttered scenarios.},
  archive      = {J_RAS},
  author       = {Xiaomei Zhang and Hanyue Ling and Xiao Huang and Qiwen Jin and Jiwei Hu},
  doi          = {10.1016/j.robot.2025.105210},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105210},
  shortjournal = {Robot. Auton. Syst.},
  title        = {OVGrasp: Target-oriented open-vocabulary robotic grasping in clutter},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Robust walking motion generation for biped robots using manipulability-based reinforcement learning. <em>RAS</em>, <em>195</em>, 105209. (<a href='https://doi.org/10.1016/j.robot.2025.105209'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In reinforcement learning, designing an effective reward function is essential for developing and controlling humanoid robots. The criteria for replicating human learning and achieving human-like responses in bipedal robots remain unclear. Integrating kinematic and dynamic characteristics into the reward function, along with the use of detailed models, can enhance efficiency and robustness. This study proposes a novel manipulability-based reward function within an end-to-end learning framework, enabling the agent to autonomously generate robust, real-time movements. Incorporating the kinematic manipulability index into the proposed reward function significantly improves the robot's locomotion behavior and ability to handle disturbances. Results indicate that incorporating kinematic manipulability into training enhances the robot's forward speed and improves its ability to handle sagittal and lateral disturbances, as well as uncertainties in length and weight distribution. Furthermore, compared to a classical hierarchical controller, the trained agent attained higher speeds and demonstrated superior disturbance handling, validating the effectiveness of the proposed learning-based approach. These findings highlight the significance of incorporating kinematic manipulability into the reward function to enhance the agility and adaptability of bipedal robots.},
  archive      = {J_RAS},
  author       = {Amin Tadayyoni and Behnam Miripour Fard and Ali Jamali},
  doi          = {10.1016/j.robot.2025.105209},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105209},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Robust walking motion generation for biped robots using manipulability-based reinforcement learning},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Context-aware proactive and adaptive conversation for human–robot interaction. <em>RAS</em>, <em>195</em>, 105207. (<a href='https://doi.org/10.1016/j.robot.2025.105207'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social robots are coming into our daily life. Existing conversational robots are mostly reactive in that the interactions are usually initiated by the users. With the knowledge of the environmental context such as people’s daily activities, robots can be more intelligent and proactive. In this paper, we proposed a context-aware conversation adaptation system (CACAS) for human–robot interaction (HRI). First, a context recognition module and a language processing module are developed to obtain the context information, user intent and slots, which become part of the system state. Second, a reinforcement learning algorithm is utilized to train an initial policy in a simulated HRI environment. User feedback data is collected through HRI using the initial policy. Third, a new policy that combines the reinforcement learning-based policy and a supervised learning-based policy is adapted based on the user feedback. We conducted both simulated user tests and real human subject tests to evaluate the proposed CACAS. The results show that the CACAS achieved a success rate of 85% in the real human subject test and 87.5% of participants were satisfied with the adaptation results. For the simulation test, the CACAS had the highest success rate compared with the baseline methods.},
  archive      = {J_RAS},
  author       = {Zhidong Su and Weihua Sheng},
  doi          = {10.1016/j.robot.2025.105207},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105207},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Context-aware proactive and adaptive conversation for human–robot interaction},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). MATdiff: Learning diffusion policy with multi-auxiliary task for mobile robot visual exploration. <em>RAS</em>, <em>195</em>, 105199. (<a href='https://doi.org/10.1016/j.robot.2025.105199'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of diffusion models into the field of robotics is gaining increasing attention due to its advantages in modeling complex data distributions. In the visual navigation task of mobile robots based on diffusion policy, existing frameworks use the current observation as the guidance condition and adopt a classifier free guidance mode for joint training. However, using diffusion models for end-to-end training may result in feature loss, as the learned features are not well understood, which leading to poor generalization in unknown environments and low navigation success rates. To address the issue of generalization, we proposed a new visual navigation framework called MATdiff from the perspective of visual representation. Our framework utilizes two auxiliary tasks to enhance the representation capability of the Conditioned Observation Network. It leverages depth estimation to extract the geometric features of the environment and employs free-space segmentation to identify safely drivable regions, which are defined as areas free from obstacles and suitable for safe navigation. After the fusion of those features, we use a conditional diffusion model to model the distribution under observation conditions and generate a fixed number of consecutive waypoints. This design of auxiliary tasks ensures that the conditional features pays attention to both geometric and semantic information simultaneously. We conduct experiments in both simulation environments and the real world. Compared with the state-of-the-art methods, our method not only has lighter model parameters but also achieves the highest navigation success rate and a longer average travel distance before collision.},
  archive      = {J_RAS},
  author       = {Qifei Tang and Zengmao Wang and Wei Gao},
  doi          = {10.1016/j.robot.2025.105199},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105199},
  shortjournal = {Robot. Auton. Syst.},
  title        = {MATdiff: Learning diffusion policy with multi-auxiliary task for mobile robot visual exploration},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Asymmetric bounded fuzzy adaptive control for uncertain coordinative multiple robot manipulators. <em>RAS</em>, <em>195</em>, 105198. (<a href='https://doi.org/10.1016/j.robot.2025.105198'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a fuzzy adaptive control technology for determining the desired trajectory of collaborative robot manipulators when grasping a general object. While the classical fuzzy logic systems (FLSs) are commonly used to compensate for some unknown nonlinear continuous functions, their approximation accuracies are often limited. To address this issue, a non-zero time-varying parameter is introduced in the input of Mamdani type or Takagi–Sugeno (T–S) type FLSs. This parameter allows for universal approximation, enabling the system to automatically adjust the approximation precision through adaptive rules. The unknown nonlinear continuous functions are represented using a combined form of homogeneous functions, which are then approximated using FLSs. Unlike previous fuzzy adaptive control schemes, this approach overcomes the limitation of a finite universal approximation domain. Additionally, the proposed method can calculate the coefficients of consequents in T–S type FLSs, reducing the computational load of the controller. The effectiveness of the proposed sliding mode surface is demonstrated in ensuring the required tracking performance, with all signals in the closed-loop system being uniformly ultimately bounded (UUB). The efficiency of the control scheme is further demonstrated through various simulation results.},
  archive      = {J_RAS},
  author       = {Yongqing Fan and Lin Yang and Zhen Li},
  doi          = {10.1016/j.robot.2025.105198},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105198},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Asymmetric bounded fuzzy adaptive control for uncertain coordinative multiple robot manipulators},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Integrative AI framework for robotics: LLM-enabled reinforcement learning in object manipulation and task planning. <em>RAS</em>, <em>195</em>, 105197. (<a href='https://doi.org/10.1016/j.robot.2025.105197'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper develops an innovative hybrid AI framework that combines contextual reasoning of a large language model (LLM) with adaptivity of reinforcement learning (RL) for improved robotic object manipulation and task execution. In particular, the proposed system integrates high-level task planning, where GPT-4 and an RL submodule collaboratively generate optimized task strategies, with low-level real-time control through RL, allowing for enhanced adaptability in dynamic environments. The experimental results demonstrate significant improvements in task success rates and operational efficiency compared to standalone RL and GPT-4 approaches. In static environments, the integrative approach achieved a 90% task success rate, with an average completion time of 42.1 s and only 1.1 retries, outperforming RL-only (72%) and GPT-4-only (78%) methods. In dynamic environments, our integrative system maintained an 85% success rate, compared to 65% for RL-only and 70% for GPT-4-only. For complex tasks, the hybrid model showed a substantial advantage, with an 80% success rate, highlighting its superior performance in tasks requiring both high-level reasoning and low-level precision control.},
  archive      = {J_RAS},
  author       = {Truong Nhut Huynh and Kim-Doang Nguyen},
  doi          = {10.1016/j.robot.2025.105197},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105197},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Integrative AI framework for robotics: LLM-enabled reinforcement learning in object manipulation and task planning},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). DWA-3D: A reactive planner for robust and efficient autonomous UAV navigation in confined environments. <em>RAS</em>, <em>195</em>, 105196. (<a href='https://doi.org/10.1016/j.robot.2025.105196'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the growing impact of Unmanned Aerial Vehicles (UAVs) across various industries, most of the current available solutions lack a robust autonomous navigation system to deal with the appearance of obstacles safely. This work presents an approach to perform autonomous UAV planning and navigation in indoor or confined scenarios where a safe and high maneuverability is required, due to the cluttered environment and narrow rooms. The system combines an RRT* global planner with a newly proposed reactive planner, DWA-3D, which is an extension of the well-known DWA method for 2D robots. We provide a theoretical-empirical method for adjusting the parameters of the objective function to optimize, which eases the classical difficulty for tuning them. An onboard LiDAR provides a 3D point cloud, which is projected on an OctoMap in which the planning and navigation decisions are made. There is not a prior map; the system builds and updates the map online, from the current and the past LiDAR information included in the OctoMap. Extensive real-world experiments were conducted to validate the system and to obtain a fine-tuning of the involved parameters. These experiments allowed us to provide a set of values that ensure safe operation across all the tested scenarios. Just by weighting two parameters, it is possible to prioritize either horizontal path alignment or vertical (height) tracking, resulting in enhancing vertical or lateral avoidance, respectively. Additionally, our DWA-3D proposal is able to navigate successfully even in absence of a global planner or with one that does not consider the drone’s size. Finally, the conducted experiments show that computation time with the proposed parameters is not only bounded but also remains stable at around 40 ms, regardless of the scenario complexity.},
  archive      = {J_RAS},
  author       = {Jorge Bes and Juan Dendarieta and Luis Riazuelo and Luis Montano},
  doi          = {10.1016/j.robot.2025.105196},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105196},
  shortjournal = {Robot. Auton. Syst.},
  title        = {DWA-3D: A reactive planner for robust and efficient autonomous UAV navigation in confined environments},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Behavior-based navigation of a two-wheeled self-balancing robot using a modified hybrid automaton. <em>RAS</em>, <em>195</em>, 105195. (<a href='https://doi.org/10.1016/j.robot.2025.105195'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to advances in robotics science, mobile robots are being used in more and more applications worldwide, and the autonomous navigation of these robots is an important topic in their discussion. This paper focuses on the autonomous navigation of a two-wheeled self-balancing robot (TWSBR) in an unknown environment using behavior-based control in the form of a hybrid automaton. This hybrid automaton includes the behaviors “Go To Goal” and “Avoid Obstacle,” and to avoid the Zeno phenomenon between these two behaviors, another behavior is considered in between, called “Follow Wall,” which the robot uses to move around the obstacle. However, two bugs are identified in the conventional hybrid automaton. The first bug causes the robot to not follow the optimal path. Another bug is that the Zeno phenomenon occurs between the two behaviors “Follow Wall” and “Go To Goal,” causing odometry errors in the experimental environment. The results show that the modified hybrid automaton successfully corrects the bugs and works as intended. The navigation algorithm is designed for the point mass model, so it is transformed to the unicycle model using a transformation, which can be used as input to the TWSBR controller. After linearizing the dynamic equations of the robot around its equilibrium point, the pole placement method is used to create the TWSBR controller. By adding the Luenberger observer to estimate the state variables, the non-full-state feedback system is also controlled. The results of the simulations demonstrate that the whole system is functioning properly so that the robot follows the path determined by the navigation algorithm while maintaining its equilibrium.},
  archive      = {J_RAS},
  author       = {Mohsen Heydari Khalili and Majid Sadedel},
  doi          = {10.1016/j.robot.2025.105195},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105195},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Behavior-based navigation of a two-wheeled self-balancing robot using a modified hybrid automaton},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). A path planning decision system for unknown pipeline detection using UAVs. <em>RAS</em>, <em>195</em>, 105194. (<a href='https://doi.org/10.1016/j.robot.2025.105194'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Pipeline-Aimed path Planner (PAPlanner), a sampling-based path planner for UAVs in unknown oil/gas pipelines. Its key contributions include a dynamic anchor point update strategy and path optimization that adapts to bends and diameter changes, eliminating redundant backtracking and enabling continuous exploration. By integrating real-time voxel maps, the algorithm optimizes paths to stay near the pipeline axis. Simulation results show that PAPlanner reduces average path length by 26.4% compared to the advanced MBPlanner method in the elbow scene experiment, demonstrating efficient safe trajectory maintenance. In the variable diameter scene experiment, where MBPlanner fails frequently, PAPlanner achieves a 0% failure rate. Real flight experiments validate its robustness with a 0.309 m average trajectory deviation from the axis, confirming reliable navigation. This work presents a novel framework enhancing UAV exploration efficiency in pipelines, overcoming limitations of existing algorithms for autonomous inspection in sensor-degraded confined environments.},
  archive      = {J_RAS},
  author       = {Dekai Lin and Ruitao Ma and Yin Zhao and Jiakuo Zhang and Shubin Liu and Hang Zhu},
  doi          = {10.1016/j.robot.2025.105194},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105194},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A path planning decision system for unknown pipeline detection using UAVs},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). CPP-DIP: Multi-objective coverage path planning for MAVs in dispersed and irregular plantations. <em>RAS</em>, <em>195</em>, 105193. (<a href='https://doi.org/10.1016/j.robot.2025.105193'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coverage Path Planning (CPP) is vital in precision agriculture to improve efficiency and resource utilization. In irregular and dispersed plantations, traditional grid-based CPP often causes redundant coverage over non-vegetated areas, leading to waste and pollution. To overcome these limitations, we propose CPP-DIP, a multi-objective CPP framework designed for Micro Air Vehicles (MAVs). The framework transforms the CPP task into a Traveling Salesman Problem (TSP) and optimizes flight paths by minimizing travel distance, turning angles, and intersection counts. Unlike conventional approaches, our method does not rely on GPS-based environmental modeling. Instead, it uses aerial imagery and a Histogram of Oriented Gradients (HOG)-based approach to detect trees and extract image coordinates. A density-aware waypoint strategy is applied: Kernel Density Estimation (KDE) is used to reduce redundant waypoints in dense regions, while a greedy algorithm ensures complete coverage in sparse areas. To verify the generality and scalability of the framework, TSP instances of varying sizes are solved using three methods: Greedy Heuristic Insertion (GHI), Ant Colony Optimization (ACO), and Monte Carlo Reinforcement Learning (MCRL). An object-based optimization is subsequently applied to further refine the paths. Additionally, CPP-DIP integrates ForaNav, our insect-inspired navigation method, for accurate tree localization and tracking. Experimental results show that MCRL provides a balanced solution, reducing travel distance by 16.9 % compared to ACO while maintaining comparable performance to GHI. It also improves path smoothness by reducing turning angles by 28.3 % and 59.9 % relative to ACO and GHI, respectively, and eliminates intersections. Computational resource comparisons further highlight that GHI scales efficiently with increasing waypoints, whereas ACO and MCRL incur higher computational costs. These results confirm the robustness, efficiency, and scalability of the proposed CPP-DIP.},
  archive      = {J_RAS},
  author       = {Weijie Kuang and Hann Woei Ho and Ye Zhou},
  doi          = {10.1016/j.robot.2025.105193},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105193},
  shortjournal = {Robot. Auton. Syst.},
  title        = {CPP-DIP: Multi-objective coverage path planning for MAVs in dispersed and irregular plantations},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). EM-LSD: A lightweight and efficient model for multi-scale line segment detection. <em>RAS</em>, <em>195</em>, 105192. (<a href='https://doi.org/10.1016/j.robot.2025.105192'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the challenges of detecting line segments in dynamic and geometrically complex environments, EM-LSD, a lightweight and efficient line segment detection model, is introduced. Accurate and efficient detection of line segments is critical for tasks such as environmental modeling and localization in SLAM, where the failure to extract robust line features can result in unreliable mapping and trajectory estimation. The design of EM-LSD is guided by the limitations of existing methods: traditional approaches often fail to capture multi-scale and global features in noisy scenes, while deep learning models with multi-stage architectures impose high computational costs, making them unsuitable for real-time applications. Inspired by the observation that multi-scale feature extraction is essential for handling diverse geometric structures, EM-LSD incorporates a Dense Atrous Convolution (DAC) module to effectively capture multi-scale information with minimal computational overhead. Additionally, the need for robustness against structural complexities and noise led to the integration of dual decoders with a Channel-Spatial Multi-scale Attention (CSMA) module and a Multi-scale Atrous Deformable Block (MADB), enabling adaptive feature representation. Experimental results on the Wireframe and YorkUrban datasets validate EM-LSD’s superior accuracy, robustness, and real-time performance, emphasizing its capability to support resource-constrained SLAM applications. This model not only addresses the limitations of existing methods but also enhances the reliability of environment modeling and localization, offering inspiration for the development of lightweight and efficient detection frameworks.},
  archive      = {J_RAS},
  author       = {Shuo Hu and Liye Zhao and Qing Wang},
  doi          = {10.1016/j.robot.2025.105192},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105192},
  shortjournal = {Robot. Auton. Syst.},
  title        = {EM-LSD: A lightweight and efficient model for multi-scale line segment detection},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Neuromorphic visuotactile slip perception for robotic manipulation. <em>RAS</em>, <em>195</em>, 105191. (<a href='https://doi.org/10.1016/j.robot.2025.105191'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visuotactile sensing technology has received extensive attention in the tactile sensing community due to its stable high-resolution deformation sensing capabilities. However, the existing visuotactile sensing methods are far from humanoid neural information processing mechanism. To address this gap, we propose a neuromorphic visuotactile slip detection method named VT-SNN using Tactile Address-Event Representation (TAER) encoding combined with brain-inspired Spiking Neural Network (SNN) modeling in this paper. Our extensive experimental results demonstrate that the VT-SNN achieves slip detection accuracy of 99.59% and F1 score of 99.28%, which is comparable to Artificial Neural Networks (ANNs) while exhibiting significant advantages in power dissipation and inference time. Furthermore, we deployed the VT-SNN on Intel neuromorphic computing chip–Loihi and performed closed-loop slip-feedback robotic manipulation tasks such as bottle-cap tightening and loosening. Our closed-loop neuromorphic visuotactile sensing system shows significant promise for high accuracy, low latency, and low power dissipation for robotic dexterous manipulation.},
  archive      = {J_RAS},
  author       = {Yiming Qiao and Chaofan Zhang and Shaowei Cui and Lu Cao and Zhigang Wang and Peng Wang and Shuo Wang},
  doi          = {10.1016/j.robot.2025.105191},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105191},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Neuromorphic visuotactile slip perception for robotic manipulation},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). RRT-based CPC: A configuration planning method for continuum robots using rapidly-exploring random tree algorithm. <em>RAS</em>, <em>195</em>, 105190. (<a href='https://doi.org/10.1016/j.robot.2025.105190'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obstacle-aware configuration control represents a critical challenge in the deployment of continuum robots for advanced applications such as robotic-assisted laparoscopic surgery and intelligent industrial grasping systems. At present, in order to realize the obstacle avoidance function of flexible robots, inverse kinematic calculations are usually unavoidable. The problems of large amount of computation, long solution time, and non-convergence of results make the configuration control for flexible robots still challenging. Most of the current studies use the inverse kinematics calculation of end tracking, and for flexible robots with multiple degrees of freedom, the success rate of obstacle avoidance is low and the computational cost is large. In this paper, a three-segment continuum configuration planning method based on Rapidly-exploring Random Tree (RRT) algorithm is proposed, in which the rough obstacle avoidance path is obtained by RRT algorithm, then the three-segment fitting is carried out by using the second-order Bézier curve, and the length error is evaluated to meet the planning requirements. Experiments such as obstacle avoidance tests, the arrival of target endpoints at different positions and different obstacle environments show that the proposed method can effectively map the feasible solution to the actual configuration. Compared with the inverse kinematics method, the proposed approach improves the success rate of obtaining feasible solutions by at least 14.8% and reduces the solution time by at least 55%. In addition, no prior curvature information and traditional inverse kinematics calculation are needed for the configuration control.},
  archive      = {J_RAS},
  author       = {Qiqi Pan and Hongbo Wang and Yongfei Feng and Shijie Guo and Jingjing Luo},
  doi          = {10.1016/j.robot.2025.105190},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105190},
  shortjournal = {Robot. Auton. Syst.},
  title        = {RRT-based CPC: A configuration planning method for continuum robots using rapidly-exploring random tree algorithm},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Formation control of multiple AUVs using decentralized self-attention based soft actor–critic model. <em>RAS</em>, <em>195</em>, 105187. (<a href='https://doi.org/10.1016/j.robot.2025.105187'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of most important topics studied in the field of multiple robots is cooperative formation control. Formation structure is a combination in which agents maintain the desired form and at the same time execute the assigned commands. This article deals with the formation control of multiple Autonomous Underwater Vehicles (AUVs) based on a distributed reinforcement learning algorithm. The proposed Decentralized Self-Attention based Soft Actor–Critic (DEC-ASAC in short) method uses an attention mechanism and maximum entropy reinforcement learning control, so as to enable AUVs to learn formation control independently. The corresponding environmental states, action space and reward schemes are designed for leader and follower AUVs. Simulations and lake test verify that the proposed DEC-ASAC algorithm can stably and effectively learn control policies during training process, achieving effective control of multiple AUVs to keep different formation shapes.},
  archive      = {J_RAS},
  author       = {Meiyan Zhang and Ziqiang Liu and Wenyu Cai},
  doi          = {10.1016/j.robot.2025.105187},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105187},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Formation control of multiple AUVs using decentralized self-attention based soft actor–critic model},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). The sequences of bundles of line segments for autonomous robots with limited vision range to escape from blind alley regions. <em>RAS</em>, <em>195</em>, 105185. (<a href='https://doi.org/10.1016/j.robot.2025.105185'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the following problem: A robot operating in a 2D environment with a limited vision range finds a path to a goal in an unknown environment containing obstacles. In this paper, we propose a novel algorithm to solve the problem. In some special cases, our algorithm is convergent with respect to ‖ . ‖ . The problem involves discovering the environmental map and blind alley regions, that are bounded by obstacles, and it provides no possible passage for robots except in and out of their path entry occur, the robot has to return back to some positions outside to escape from such regions such that the returned path is not longer than the path entry (Blind Alley Region problem, (BAR) problem, in short). To solve the (BAR) problem, sequences of bundles of line segments during the robot’s traveling are constructed in our algorithm. Some advantages of our algorithm are that (a) It reduces search space in blind alley regions because it only works on the sequences of bundles of the line segments built by the robot’s limited vision range. (b) Our algorithm ensures that the returned path to escape from the regions is not longer than the previous path of the robot. (c) Due to the construction of the sequences of bundles of line segments, our paths are not always “close” obstacles and the number of turns of such paths is smaller ones determined by other shortest path algorithms (e.g., A*, RRT*). Our algorithm is implemented in Python and we experience the algorithm on some autonomous robots with different vision ranges in real environment. We also compare our result with RRTX, a state-of-art local path-planning algorithm, and A ∗ , a basic one. The experimental results show that our algorithm provides better solutions than RRTX and A* results in some specific circumstances.},
  archive      = {J_RAS},
  author       = {Phan Thanh An and Pham Hoang Anh and Tran Thanh Binh and Tran Van Hoai},
  doi          = {10.1016/j.robot.2025.105185},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105185},
  shortjournal = {Robot. Auton. Syst.},
  title        = {The sequences of bundles of line segments for autonomous robots with limited vision range to escape from blind alley regions},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Improved prescribed performance control for multi-quadrotor payload transport under unknown disturbances. <em>RAS</em>, <em>195</em>, 105184. (<a href='https://doi.org/10.1016/j.robot.2025.105184'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a robust and enhanced control strategy for a multi-quadrotor suspended payload system, which is characterized by complex nonlinear dynamics and unknown external disturbances. A precise dynamic model of the system is formulated using the Udwadia–Kalaba method. A distributed cooperative planning framework, based on graph theory, is employed to enable effective information exchange and cooperative control among multiple quadrotors. To mitigate the impact of unknown disturbances, such as wind fields and variations in payload mass, a disturbance observer is developed to estimate and compensate for these disturbances, thereby enhancing system robustness. Furthermore, an improved prescribed performance control method is proposed to address the issue of exceeding performance boundaries. The steady-state error of the system is effectively reduced by adaptively adjusting the prescribed performance boundary and combining it with integral backstepping, and real-time constraints on tracking errors and closed-loop stability are achieved. Simulation results validate that the proposed control strategy significantly enhances the control performance and disturbance rejection capability of the multi-quadrotor suspended payload system, demonstrating superior robustness.},
  archive      = {J_RAS},
  author       = {Xinyu Chen and Yunsheng Fan and Guofeng Wang and Dongdong Mu},
  doi          = {10.1016/j.robot.2025.105184},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105184},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Improved prescribed performance control for multi-quadrotor payload transport under unknown disturbances},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
<li><details>
<summary>
(2026). Multi-agent reinforcement learning for zero-shot coverage path planning with dynamic UAV networks. <em>RAS</em>, <em>195</em>, 105163. (<a href='https://doi.org/10.1016/j.robot.2025.105163'>www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in autonomous systems have enabled the development of intelligent multi-robot systems for dynamic environments. Unmanned Aerial Vehicles play an important role in multi-robot applications such as precision agriculture, search-and-rescue, and wildfire monitoring, all of which rely on solving the coverage path planning problem. While Multi-Agent Coverage Path Planning approaches have shown potential, many existing methods lack the scalability and adaptability needed for diverse and dynamic scenarios. This paper presents a decentralized Multi-Agent Coverage Path Planning framework based on Multi-Agent Reinforcement Learning with parameter sharing and Centralized Training with Decentralized Execution. The framework incorporates a customized Rainbow Deep-Q Network, a size-invariant reward function, and a robustness and safety filter to ensure completeness and reliability in dynamic environments. Our training pipeline combines curriculum learning, domain randomization, and transfer learning, enabling the model to generalize to unseen scenarios. We demonstrate zero-shot generalization on scenarios with significantly larger maps, an increased number of obstacles, and a varying number of agents compared to what is seen during training. Furthermore, the models can also adapt to more structured maps and handle different tasks, such as search-and-rescue, without the need for retraining.},
  archive      = {J_RAS},
  author       = {José P. Carvalho and A. Pedro Aguiar},
  doi          = {10.1016/j.robot.2025.105163},
  journal      = {Robotics and Autonomous Systems},
  month        = {1},
  pages        = {105163},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Multi-agent reinforcement learning for zero-shot coverage path planning with dynamic UAV networks},
  volume       = {195},
  year         = {2026},
}
</textarea>
</details></li>
</ul>

</body>
</html>
